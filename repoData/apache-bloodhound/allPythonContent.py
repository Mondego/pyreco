__FILENAME__ = admin
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Administration commands for Bloodhound Dashboard.
"""
import json
import re
from sys import stdout

from trac.admin.api import IAdminCommandProvider, AdminCommandError
from trac.core import Component, implements
from trac.db_default import schema as tracschema
from trac.util.text import printout
from trac.wiki.admin import WikiAdmin
from trac.wiki.model import WikiPage
from bhdashboard import wiki
from bhdashboard.util.translation import _

try:
    from multiproduct.model import Product, ProductResourceMap, ProductSetting
except ImportError:
    Product = ProductResourceMap = ProductSetting = None

schema = tracschema[:]
if Product is not None:
    schema.extend([Product._get_schema(), ProductResourceMap._get_schema(),
                   ProductSetting._get_schema()])

structure = dict([(table.name, [col.name for col in table.columns])
                  for table in schema])

# add product for any columns required
for table in ['ticket']:
    structure[table].append('product')

# probably no point in keeping data from these tables
ignored = ['auth_cookie', 'session', 'session_attribute', 'cache']
IGNORED_DB_STRUCTURE = dict([(k, structure[k]) for k in ignored])
DB_STRUCTURE = dict([(k, structure[k]) for k in structure if k not in ignored])


class BloodhoundAdmin(Component):
    """Bloodhound administration commands.
    """

    implements(IAdminCommandProvider)

    # IAdminCommandProvider methods
    def get_admin_commands(self):
        """List available commands.
        """
        yield ('wiki bh-upgrade', '',
               'Move Trac* wiki pages to %s/*' % wiki.GUIDE_NAME,
               None, self._do_wiki_upgrade)

        yield ('devfixture dump', '[filename]',
               """Dumps database to stdout in a form suitable for reloading

               If a filename is not provided, data will be sent standard out.
               """,
               None, self._dump_as_fixture)

        yield ('devfixture load', '<filename> <backedup>',
               """Loads database fixture from json dump file

               You need to specify a filename and confirm that you have backed
               up your data.
               """,
               None, self._load_fixture_from_file)

    def _do_wiki_upgrade(self):
        """Move all wiki pages starting with Trac prefix to unbranded user
        guide pages.
        """
        wiki_admin = WikiAdmin(self.env)
        pages = wiki_admin.get_wiki_list()
        for old_name in pages:
            if old_name.startswith('Trac'):
                new_name = wiki.new_name(old_name)
                if not new_name:
                    continue
                if new_name in pages:
                    printout(_('Ignoring %(page)s : '
                               'The page %(new_page)s already exists',
                               page=old_name, new_page=new_name))
                    continue
                try:
                    wiki_admin._do_rename(old_name, new_name)
                except AdminCommandError, exc:
                    printout(_('Error moving %(page)s : %(message)s',
                               page=old_name, message=unicode(exc)))
                else:
                    # On success, rename links in other pages
                    self._do_wiki_rename_links(old_name, new_name)
                    # On success, insert redirection page
                    redirection = WikiPage(self.env, old_name)
                    redirection.text = _('See [wiki:"%(name)s"].', name=new_name)
                    comment = 'Bloodhound guide update'
                    redirection.save('bloodhound', comment, '0.0.0.0')
        self._do_wiki_rename_links('[[TracGuideToc]]', '[[UserGuideToc]]')

    def _do_wiki_rename_links(self, old_name, new_name):
        if old_name.startswith('[[') and old_name.endswith(']]'):
            pattern = r'%s'
        else:
            pattern = r'\b%s\b'
        with self.env.db_transaction as db:
            pages = db("""SELECT name, text FROM wiki
                          WHERE text %s
                       """ % db.like(),
                       ('%' + db.like_escape(old_name) + '%',))
            for name, text in pages:
                db("""UPDATE wiki
                      SET text=%s
                      WHERE name=%s
                    """, (re.sub(pattern % re.escape(old_name),
                                 new_name, text), name))

    def _get_tdump(self, db, table, fields):
        """Dumps all the data from a table for a known set of fields"""
        return db("SELECT %s from %s" % (','.join([db.quote(f) for f in fields]),
                                         db.quote(table)))

    def _dump_as_fixture(self, *args):
        """Dumps database to a json fixture"""
        def dump_json(fp):
            """Dump to json given a file"""
            with self.env.db_query as db:
                data = [(k, v, self._get_tdump(db, k, v))
                        for k, v in DB_STRUCTURE.iteritems()]
                jd = json.dumps(data, sort_keys=True, indent=2,
                                separators=(',', ':'))
                fp.write(jd)

        if len(args):
            f = open(args[0], mode='w+')
            dump_json(f)
            f.close()
        else:
            dump_json(stdout)

    def _load_fixture_from_file(self, fname):
        """Calls _load_fixture with an open file"""
        try:
            fp = open(fname, mode='r')
            self._load_fixture(fp)
            fp.close()
        except IOError:
            printout(_("The file '%(fname)s' does not exist", fname=fname))

    def _load_fixture(self, fp):
        """Extract fixture data from a file like object, expecting json"""
        # Only delete if we think it unlikely that there is data to lose
        with self.env.db_query as db:
            if db('SELECT * FROM ' + db.quote('ticket')):
                printout(_("This command is only intended to run on fresh "
                           "environments as it will overwrite the database.\n"
                           "If it is safe to lose bloodhound data, delete the "
                           "environment and re-run python bloodhound_setup.py "
                           "before attempting to load the fixture again."))
                return
        data = json.load(fp)
        with self.env.db_transaction as db:
            for tab, cols, vals in data:
                db("DELETE FROM " + db.quote(tab))
            for tab, cols, vals in data:
                printout("Populating %s table" % tab)
                db.executemany("INSERT INTO %s (%s) VALUES (%s)"
                               % (db.quote(tab),
                                  ','.join([db.quote(c) for c in cols]),
                                  ','.join(['%s']*len(cols))),
                               vals)
                printout("%d records added" % len(vals))

########NEW FILE########
__FILENAME__ = api
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

The core of the dashboard architecture.
"""
__metaclass__ = type

from datetime import date, time, datetime, timedelta
from inspect import isclass
from sys import version_info

from genshi.builder import tag

from trac.core import Component, ExtensionPoint, implements, \
        Interface, TracError
from trac.perm import IPermissionRequestor
from trac.resource import get_resource_url, Resource, resource_exists
from trac.util.compat import set
from trac.util.datefmt import parse_date
from trac.web.chrome import add_stylesheet
from bhdashboard.util.translation import _

#--------------------------------------
# Core classes and interfaces
#--------------------------------------

class IWidgetProvider(Interface):
    r"""Extension point interface for components providing widgets.
    These may be seen as web parts more sophisticated than WikiMacro
    as they expose much more meta-data, but more simple than gadgets
    because they belong in the environment and are built on top of Trac
    architecture. This makes them more suitable to be used in
    environments where flexibility and configurability is needed
    (i.e. dashboards).
    """
    def get_widgets():
        """Return an iterable listing the names of the provided widgets."""

    def get_widget_description(name):
        """Return plain text description of the widget with specified name."""

    def get_widget_params(name):
        """Return a dictionary describing wigdet preference for the widget
        with specified name. Used to customize widget behavior."""

    def render_widget(name, context, options):
        """Render widget considering given options."""

    # TODO: Add methods to specify widget metadata (e.g. parameters)

class ILayoutProvider(Interface):
    """Extension point interface implemented by components adding layouts
    to the dashboard.

    PS: Such components should implement `trac.mimeview.api.IContentConverter`
    interface so as to save and load layout definition when necessary.
    The pseudo-mimetype identifying layout data will be
    `application/x-trac-layout-<layout_name>`.
    Nonetheless they can delegate that task to other components too.
    Let's all hail the Trac component model !
    """
    def get_layouts():
        """Return an iterable listing the names of the provided layouts."""

    def get_layout_description(name):
        """Return plain text description of the layout with specified name."""

    def expand_layout(name, context, options):
        """Provide the information needed to render layout identified by
        `name`.

        :param context: rendering context
        :param options: additional options supplied in so as to adapt layout
                considering data specific to this request. This allows to
                customize (parts of) the layout for a given request.
                Suported options are :

                :field schema:  data to be used in order to populate layout
                :field embed:   embed layout inside another page (true / false)
        """

class DashboardSystem(Component):
    implements(IPermissionRequestor, IWidgetProvider)

    widget_providers = ExtensionPoint(IWidgetProvider)
    layout_providers = ExtensionPoint(ILayoutProvider)

    # IPermissionRequestor methods
    def get_permission_actions(self):
        return ['DASHBOARD_VIEW',
                # 'DASHBOARD_CREATE', 'DASHBOARD_EDIT' <= Coming soon ;)
               ]

    # IWidgetProvider methods

    def get_widgets(self):
        """List the name of the widgets that will always be available
        """
        yield 'WidgetDoc'

    def get_widget_description(self, name):
        """Return plain text description of the widget with specified name.
        """
        try:
            return {
                    'WidgetDoc' : """Display widget documentation"""
                    }[name]
        except KeyError:
            raise InvalidIdentifier('Widget name MUST match any of ' +
                        ', '.join(self.get_widgets()),
                    title='Invalid widget identifier')

    def get_widget_params(self, name):
        """Return a dictionary describing wigdet preference for the widget
        with specified name. Used to customize widget behavior.
        """
        try:
            return {
                    'WidgetDoc': {
                        'urn': {
                                'desc': """Widget name. If missing then """
                                        """documentation for all widgets """
                                        """will be displayed."""
                                }
                        }
                   }[name]
        except KeyError:
            raise InvalidIdentifier('Widget name MUST match any of ' +
                        ', '.join(self.get_widgets()),
                    title='Invalid widget identifier')

    def render_widget(self, name, context, options):
        """Render widget considering given options.
        """
        if name == 'WidgetDoc':
            add_stylesheet(context.req, 'dashboard/css/docs.css')
            widget_name, = self.bind_params(options,
                    self.get_widget_params(name), 'urn')
            if widget_name is not None:
                try:
                    providers = [([widget_name],
                            self.resolve_widget(widget_name))]
                except LookupError:
                    return 'widget_alert.html', {
                            'title': _('Widget documentation'),
                            'data': {
                                    'msglabel': 'Alert',
                                    'msgbody': 'Unknown identifier',
                                    'msgdetails': [
                                            ('Widget name', widget_name)
                                        ]
                                  }
                        }, context
            else:
                providers = [(provider.get_widgets(), provider) \
                        for provider in self.widget_providers]
            metadata = [self._prepare_doc_metadata(self.widget_metadata(wnm, p)) \
                    for widgets, p in providers for wnm in widgets]
            docs_resource = Resource('wiki', 'BloodhoundWidgets')
            insert_docs = resource_exists(self.env, docs_resource) and \
                    not (context.resource and \
                    docs_resource == context.resource)
            return 'widget_doc.html', {
                        'title': _('Widget documentation'),
                        'data': {
                                'items': metadata
                            },
                        'ctxtnav': [tag.a(tag.i(class_='icon-info-sign'),
                                    ' ', _('Help'),
                                    href=get_resource_url(
                                            self.env, docs_resource,
                                            context.href)
                                )] if insert_docs else [],
                    }, context
        else:
            raise InvalidIdentifier('Widget name MUST match any of ' +
                        ', '.join(self.get_widgets()),
                    title='Invalid widget identifier')

    # Public API
    def widget_metadata(self, nm, provider=None):
        """Retrieve widget metadata.

        :param nm:        Wid
        get name
        :param provider:  Widget provider. If omitted it will be resolved.
        """
        if provider is None:
            provider = self.resolve_widget(nm)
        return {
                'urn': nm,
                'desc': provider.get_widget_description(nm),
                'params': provider.get_widget_params(nm),
            }

    def _prepare_doc_metadata(self, spec):
        """Transform widget metadata into a format suitable to render
        documentation.
        """
        def plabel(p):
            v = p.get('type', str)
            module = getattr(v, '__module__', None)
            if module in (None, '__builtin__'):
                return getattr(v, '__name__', None) or v
            else:
                # FIXME: Improve e.g. for enum fields
                if not isclass(v):
                    v = v.__class__
                return tag.span(v.__name__, title='in ' + module)

        return {
                'title': spec['urn'],
                'desc': '\n'.join(l.strip()
                                   for l in spec['desc'].splitlines()),
                'sections': [
                        {
                            'title': _('Parameters'),
                            'entries': [
                                    {
                                        'caption': pnm,
                                        'summary': '\n'.join(
                                                l.strip() for l in \
                                                p.get('desc').splitlines()),
                                        'details': [
                                                ('Type', plabel(p)),
                                                ('Required', p.get('required',
                                                                   False)),
                                                ('Default', p.get('default')),
                                            ]
                                    }
                                for pnm, p in spec['params'].iteritems()]
                        }
                    ]
            }


    def bind_params(self, options, spec, *params):
        """Extract values for widget arguments from `options` and ensure
        they are valid and properly formatted.
        """
        # Should this helper function be part of public API ?
        def get_and_check(p):
            try:
                param_spec = spec[p]
            except KeyError:
                raise InvalidWidgetArgument("Unknown parameter `%s`" % (p,))
            try:
                argtype = param_spec.get('type') or unicode
                return argtype(options['args'][p])
            except KeyError:
                if param_spec.get('required'):
                    raise InvalidWidgetArgument(p,
                            "Required parameter expected")
                elif param_spec.get('default') is not None:
                    return param_spec['default']
                else:
                    return None
        return (get_and_check(param) for param in params)

    def _resolve(self, objnm, epnm, accessor, errmsg='Invalid object name %s'):
        """Determine the provider implementing a given widget / layout / ...

        :param objnm:     name used to lookup provider
        :param epnm:      attribute name used for entry point
        :param accessor:  function used to determine names bound to provider
        """
        for p in getattr(self, epnm):
            if objnm in accessor(self, p):
                return p
        else:
            raise LookupError(errmsg % (objnm,))

    def resolve_layout(self, nm):
        return self._resolve(nm, 'layout_providers',
                lambda _, lp: lp.get_layouts() , "No provider for layout %s")

    def resolve_widget(self, nm):
        return self._resolve(nm, 'widget_providers',
                lambda _, wp: wp.get_widgets() , "No provider for widget %s")

#--------------------------------------
# Exception classes
#--------------------------------------

# Maybe it is better to move these to a separate file
# (if this gets as big as it seems it will be)

class WidgetException(TracError):
    """Base class for all errors related to Trac widgets"""

class InvalidIdentifier(WidgetException):
    """Invalid value for a field used to identify an internal object"""

    title = 'Invalid identifier'

class InvalidWidgetArgument(WidgetException):
    """Something went wrong with widget parameter"""

    title = 'Invalid Argument'

    def __init__(self, argname, message, title=None, show_traceback=False):
        message = _("Invalid argument") + " `" + argname + "`. " + message
        TracError.__init__(self, message, title, show_traceback)
        self.argname = argname

    def __unicode__(self):
        return unicode(
                self.message)

#--------------------------------------
# Default field types
#--------------------------------------

class DateField:
    """Convert datetime field
    """
    def __init__(self, fmt="%Y-%m-%d %H:%M:%S", tz=None):
        """Initialize datetime field converter

        :param fmt:       format string used to interpret dates and times
        """
        self.fmt = fmt
        self.tz = tz

    def __call__(self, value, fmt=None):
        """Perform the actual conversion
        """
        if isinstance(value, (date, time, datetime, timedelta)):
            return value
        elif isinstance(value, basestring):
            try:
                return parse_date(value, self.tz)
            except TracError, exc:
                try:
                    fmt = fmt or self.fmt
                    return datetime.strptime(value, fmt)
                except:
                    raise InvalidWidgetArgument(
                            error=exc, title=_('Datetime conversion error'))
        elif isinstance(value, int):
            return datetime.utcfromtimestamp(value)
        else:
            raise InvalidWidgetArgument(
                    "Invalid format `%s` for value `%s`" % (fmt, value),
                    title=_('Datetime conversion error'))

class ListField:
    """Convert list field
    """
    def __init__(self, sep=','):
        """Initialize list field converter

        :param sep:       character used to delimit list items
        """
        self.sep = sep

    def __call__(self, value):
        """Perform the actual conversion
        """
        if isinstance(value, basestring):
            return value.split(self.sep)
        else:
            try:
                return list(value)
            except Exception, exc:
                raise InvalidWidgetArgument(error=exc,
                        title=_('List conversion error'))

class EnumField:
    """Convert enum field
    """
    def __init__(self, *choices):
        """Initialize enum field converter

        :param choices:       allowed values
        """
        self.choices = set(choices)

    def __call__(self, value):
        """Perform the actual conversion
        """
        if value not in self.choices:
            raise InvalidWidgetArgument('',
                _('Expected one of `%s` but got `%s`') % (self.choices, value),
                title=_('Enum conversion error'))
        return value

class JsonField:
    """Deserialize JSON string
    """
    def __init__(self):
        """Initialize JSON field converter
        """
        # TODO: Add further options

    def __call__(self, value):
        """Perform the actual conversion
        """
        try:
            if version_info < (2, 6):
                from simplejson import loads
            else:
                from json import loads
        except ImportError:
            raise TracError('Unable to load library to parse JSON string')
        else:
            return loads(value)

########NEW FILE########
__FILENAME__ = bootstrap
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widgets displaying ticket data.
"""

from uuid import uuid4

from trac.core import Component, implements, TracError
from trac.web.chrome import add_stylesheet, add_script

from bhdashboard.api import ILayoutProvider

class BootstrapLayout(Component):
    """Implement some basic bootstrap layouts
    """
    implements(ILayoutProvider)

    # ILayoutProvider methods
    def get_layouts(self):
        """Supported layouts.
        """
        yield 'bootstrap_grid'
        yield 'bootstrap_btnbar'

    def get_layout_description(self, name):
        """Return plain text description of the layout with specified name.
        """
        return {
                'bootstrap_grid' : "Bootstrap grid system " \
                    "http://twitter.github.com/bootstrap/scaffolding.html#layouts",
                'bootstrap_btnbar' : "Button toolbar acting as tabs nav"
            }[name]

    def expand_layout(self, name, context, options):
        """Specify bootstrap layout template
        """
        req = context.req
        add_stylesheet(req, 'dashboard/css/bootstrap.css')
        add_stylesheet(req, 'dashboard/css/bootstrap-responsive.css')

        if name == 'bootstrap_btnbar':
            self._process_btnbar(req, options)

        results = {
                ('bootstrap_grid', False) : {
                        'template' : 'bs_grid_full.html',
                    },
                ('bootstrap_grid', True) : {
                        'template' : 'bs_grid.html',
                    },
                ('bootstrap_btnbar', False) : {
                        'template' : 'bs_btnbar_full.html',
                    },
                ('bootstrap_btnbar', True) : {
                        'template' : 'bs_btnbar.html',
                    },
            }
        return results[( name , bool(options.get('embed')) )]

    # Internal methods
    def _process_btnbar(self, req, options):
        """Determine toolbar groups
        """
        layout_data = options['schema']
        orig_tb = layout_data.get('toolbar', [])
        ready = layout_data.get('ready')
        if not ready:
            layout_data['toolbar'] = tb = [[]]
            last_group = tb[0]
            active = layout_data.get('active')
            for i, (caption, idx) in enumerate(orig_tb):
                if caption == '|' :
                    last_group = []
                    tb.append(last_group)
                else:
                    last_group.append(
                            { 'caption' : caption, 'widget' :idx,
                              'id' : uuid4().hex, 'active' : i == active })
        layout_data['ready'] = True

########NEW FILE########
__FILENAME__ = macros
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Bloodhound Macros"""

from genshi.builder import tag
from trac.util.translation import cleandoc_
from trac.wiki.api import WikiSystem
from trac.wiki.macros import WikiMacroBase

from bhdashboard.wiki import GUIDE_NAME
from bhdashboard.util.translation import _

class UserGuideTocMacro(WikiMacroBase):
    _description = cleandoc_("""Display a Guide table of contents

    This macro provides the table-of-contents specific to the user Guide
    """
    )
    TOC = [('%(guide)s/Index',                    'Index'),
           ('%(guide)s/Install',                  'Installation'),
           ('%(guide)s/InterfaceCustomization',   'Customization'),
           ('%(guide)s/Plugins',                  'Plugins'),
           ('%(guide)s/Upgrade',                  'Upgrading'),
           ('%(guide)s/Ini',                      'Configuration'),
           ('%(guide)s/Admin',                    'Administration'),
           ('%(guide)s/Backup',                   'Backup'),
           ('%(guide)s/Logging',                  'Logging'),
           ('%(guide)s/Permissions' ,             'Permissions'),
           ('%(guide)s/Wiki',                     'The Wiki'),
           ('WikiFormatting',               'Wiki Formatting'),
           ('%(guide)s/Timeline',                 'Timeline'),
           ('%(guide)s/Browser',                  'Repository Browser'),
           ('%(guide)s/RevisionLog',              'Revision Log'),
           ('%(guide)s/Changeset',                'Changesets'),
           ('%(guide)s/Tickets',                  'Tickets'),
           ('%(guide)s/Workflow',                 'Workflow'),
           ('%(guide)s/Roadmap',                  'Roadmap'),
           ('%(guide)s/Query',                    'Ticket Queries'),
           ('%(guide)s/BatchModify',              'Batch Modify'),
           ('%(guide)s/Reports',                  'Reports'),
           ('%(guide)s/Rss',                      'RSS Support'),
           ('%(guide)s/Notification',             'Notification'),
          ]

    def expand_macro(self, formatter, name, args):
        curpage = formatter.resource.id

        # scoped TOC (e.g. TranslateRu/Guide or 0.X/Guide ...)
        prefix = ''
        guideprefix =  GUIDE_NAME + '/'
        data = {'guide': GUIDE_NAME,}
        idx = curpage.find('/')
        if idx > 0:
            prefix = curpage[:idx+1]
        if prefix.endswith(guideprefix):
            prefix = prefix[:len(prefix)-len(guideprefix)]
        ws = WikiSystem(self.env)
        return tag.div(
            tag.h4(_('Table of Contents')),
            tag.ul([tag.li(tag.a(title,
                                 href=formatter.href.wiki(prefix+ref % data),
                                 class_=(not ws.has_page(prefix+ref % data) and
                                         'missing')),
                           class_=(prefix+ref % data== curpage and 'active'))
                    for ref, title in self.TOC]),
            class_='wiki-toc')

########NEW FILE########
__FILENAME__ = model
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.db import Table, Column
from trac.core import TracError
from trac.resource import ResourceNotFound, ResourceSystem
from trac.ticket.api import TicketSystem

def dict_to_kv_str(env, data=None, sep=' AND '):
    """Converts a dictionary into a string and a list suitable for using as part
    of an SQL where clause like:
        ('key0=%s AND key1=%s', ['value0','value1'])
    The sep argument allows ' AND ' to be changed for ',' for UPDATE purposes
    """
    if data is None:
        return ('', [])
    qfn = env.get_read_db().quote
    return (sep.join('%s=%%s' % qfn(k) for k in data.keys()),
            data.values())

def fields_to_kv_str(env, fields, data, sep=' AND '):
    """Converts a list of fields and a dictionary containing those fields into a
    string and a list suitable for using as part of an SQL where clause like:
        ('key0=%s,key1=%s', ['value0','value1'])
    """
    return dict_to_kv_str(env, dict((f, data[f]) for f in fields),sep)

class ModelBase(object):
    """Base class for the models to factor out common features
    Derived classes should provide a meta dictionary to describe the table like:

    _meta = {'table_name':'mytable',
             'object_name':'WhatIWillCallMyselfInMessages',
             'key_fields':['id','id2'],
             'non_key_fields':[
                'thing',
                {
                    name:"field_name_x",
                    type='int64',
                    size=None,
                    key_size=None,
                    auto_increment=False
                }],
             'auto_inc_fields': ['id',],
             }
    key_fields and non_key_fields parameters may contain field name only (for
    text columns) or dict with detailed column specification. In case of
    detailed column specification 'name' parameter is obligatory).
    """

    def __init__(self, env, keys=None):
        """Initialisation requires an environment to be specified.
        If keys are provided, the Model will initialise from the database
        """
        # make this impossible to instantiate without telling the class details
        # about itself in the self.meta dictionary
        self._old_data = {}
        self._data = {}
        self._exists = False
        self._env = env
        self._key_fields = self._get_field_names(self._meta['key_fields'])
        self._non_key_fields = self._get_field_names(
            self._meta['non_key_fields'])
        self._all_fields = self._key_fields + self._non_key_fields
        self._unique_fields = self._meta['unique_fields']
        self._auto_inc_fields = self._get_auto_inc_field_names()

        if keys is not None:
            self._get_row(keys)
        else:
            self._update_from_row(None)

    def update_field_dict(self, field_dict):
        """Updates the object's copy of the db fields (no db transaction)"""
        self._data.update(field_dict)

    def __getattr__(self, name):
        """Overridden to allow table.field style field access."""
        try:
            if name in self._all_fields:
                return self._data[name]
        except KeyError:
            raise AttributeError(name)
        raise AttributeError(name)

    def __setattr__(self, name, value):
        """Overridden to allow table.field = value style field setting."""
        data = self.__dict__.get('_data')
        fields = self.__dict__.get('_all_fields')
        if data and fields and name in fields:
            self._data[name] = value
        else:
            dict.__setattr__(self, name, value)

    @classmethod
    def get_table_name(cls):
        return cls._meta["table_name"]

    def _update_from_row(self, row = None):
        """uses a provided database row to update the model"""
        fields = self._all_fields
        self._exists = row is not None
        if row is None:
            row = [None]*len(fields)
        self._data = dict([(fields[i], row[i]) for i in range(len(row))])
        self._old_data = {}
        self._old_data.update(self._data)

    def _get_row(self, keys):
        """queries the database and stores the result in the model"""
        row = None
        where, values = fields_to_kv_str(self._env, self._key_fields, keys)
        fields = ','.join(self._all_fields)
        sdata = {'fields':fields,
                 'where':where}
        sdata.update(self._meta)

        sql = """SELECT %(fields)s FROM %(table_name)s
                 WHERE %(where)s""" % sdata
        with self._env.db_query as db:
            for row in db(sql, values):
                self._update_from_row(row)
                break
            else:
                raise ResourceNotFound(
                        ('No %(object_name)s with %(where)s' % sdata)
                                % tuple(values))

    def delete(self):
        """Deletes the matching record from the database"""
        if not self._exists:
            raise TracError('%(object_name)s does not exist' % self._meta)
        where, values = fields_to_kv_str(self._env, self._key_fields,
                                         self._data)
        sdata = {'where': where}
        sdata.update(self._meta)
        sql = """DELETE FROM %(table_name)s
                 WHERE %(where)s""" % sdata
        with self._env.db_transaction as db:
            db(sql, values)
            self._exists = False
            TicketSystem(self._env).reset_ticket_fields()
        ResourceSystem(self._env).resource_deleted(self)
        self._data = dict([(k, None) for k in self._data.keys()])
        self._old_data.update(self._data)


    def insert(self):
        """Create new record in the database"""
        sdata = None
        if self._exists or len(self.select(self._env, where =
                                dict([(k,self._data[k])
                                      for k in self._key_fields]))):
            sdata = {'keys':','.join(["%s='%s'" % (k, self._data[k])
                                     for k in self._key_fields])}
        elif self._unique_fields and len(self.select(self._env, where =
                                dict([(k,self._data[k])
                                      for k in self._unique_fields]))):
            sdata = {'keys':','.join(["%s='%s'" % (k, self._data[k])
                                     for k in self._unique_fields])}
        if sdata:
            sdata.update(self._meta)
            sdata['values'] = self._data
            raise TracError('%(object_name)s %(keys)s already exists %(values)s' %
                            sdata)

        for key in self._key_fields:
            if self._data[key] is None and key not in self._auto_inc_fields:
                sdata = {'key':key}
                sdata.update(self._meta)
                raise TracError('%(key)s required for %(object_name)s' %
                                sdata)

        fields = [field for field in self._all_fields
                  if field not in self._auto_inc_fields]
        sdata = {'fields':','.join(fields),
                 'values':','.join(['%s'] * len(fields))}
        sdata.update(self._meta)

        sql = """INSERT INTO %(table_name)s (%(fields)s)
                 VALUES (%(values)s)""" % sdata
        with self._env.db_transaction as db:
            cursor = db.cursor()
            cursor.execute(sql, [self._data[f] for f in fields])
            for auto_in_field in self._auto_inc_fields:
                self._data[auto_in_field] = db.get_last_id(
                    cursor, sdata["table_name"], auto_in_field)

            self._exists = True
            self._old_data.update(self._data)
            TicketSystem(self._env).reset_ticket_fields()
        ResourceSystem(self._env).resource_created(self)

    def _update_relations(self, db, author=None):
        """Extra actions due to update"""
        pass

    def update(self, author=None):
        """Update the matching record in the database"""
        if self._old_data == self._data:
            return
        if not self._exists:
            raise TracError('%(object_name)s does not exist' % self._meta)
        for key in self._meta['no_change_fields']:
            if self._data[key] != self._old_data[key]:
                raise TracError('%s cannot be changed' % key)
        for key in self._key_fields + self._unique_fields:
            if self._data[key] != self._old_data[key]:
                if len(self.select(self._env, where = {key:self._data[key]})):
                    raise TracError('%s already exists' % key)

        setsql, setvalues = fields_to_kv_str(self._env, self._non_key_fields,
                                             self._data, sep=',')
        where, values = fields_to_kv_str(self._env, self._key_fields,
                                         self._data)

        sdata = {'where': where,
                 'values': setsql}
        sdata.update(self._meta)
        sql = """UPDATE %(table_name)s SET %(values)s
                 WHERE %(where)s""" % sdata

        old_values = dict((k, v) for k, v in self._old_data.iteritems()
                          if self._data.get(k) != v)
        with self._env.db_transaction as db:
            db(sql, setvalues + values)
            self._update_relations(db, author)
            self._old_data.update(self._data)
            TicketSystem(self._env).reset_ticket_fields()

        ResourceSystem(self._env).resource_changed(self, old_values)

    @classmethod
    def select(cls, env, db=None, where=None, limit=None, order_by=None):
        """
        Query the database to get a set of records back
        * order_by: is list of fields with optional sort direction
            ("asc" or "desc") e.g. ["field1", "field2 desc"]
        """
        rows = []
        fields = cls._get_all_field_names()

        sdata = {'fields': ','.join(env.get_read_db().quote(f)
                                    for f in fields),}
        sdata.update(cls._meta)
        sql = r'SELECT %(fields)s FROM %(table_name)s' % sdata
        wherestr, values = dict_to_kv_str(env, where)
        if wherestr:
            wherestr = ' WHERE ' + wherestr
        final_sql = sql + wherestr
        if limit is not None:
            final_sql += ' LIMIT ' + str(int(limit))
        if order_by:
            final_sql += "\nORDER BY " + ', '.join(order_by)
        for row in env.db_query(final_sql, values):
            # we won't know which class we need until called
            model = cls.__new__(cls)
            data = dict([(fields[i], row[i]) for i in range(len(fields))])
            model.__init__(env, data)
            rows.append(model)
        return rows

    @classmethod
    def _get_all_field_names(cls):
        return cls._get_field_names(
            cls._meta['key_fields']+cls._meta['non_key_fields'])

    @classmethod
    def _get_field_names(cls, field_specs):
        def get_field_name(field_spec):
            if isinstance(field_spec, dict):
                return field_spec["name"]
            return field_spec
        return [get_field_name(field_spec) for field_spec in field_specs]

    @classmethod
    def _get_all_field_columns(cls):
        auto_inc =  cls._meta.get('auto_inc_fields', [])
        columns = []
        all_fields_spec = cls._meta['key_fields'] + cls._meta['non_key_fields']
        for field_spec in all_fields_spec:
            #field_spec can be field name string or dictionary with detailed
            #column specification
            if isinstance(field_spec, dict):
                column_spec = field_spec
            else:
                column_spec = dict(
                    name = field_spec,
                    auto_increment=field_spec in auto_inc)
            columns.append(column_spec)
        return columns

    @classmethod
    def _get_auto_inc_field_names(cls):
        return [field_spec["name"] for field_spec
                in cls._get_all_field_columns()
                if field_spec.get("auto_increment")]

    @classmethod
    def _get_schema(cls):
        """Generate schema from the class meta data"""
        fields =  [Column(
                    column_spec["name"],
                    type=column_spec.get("type", "text"),
                    size=column_spec.get("size"),
                    key_size=column_spec.get("key_size"),
                    auto_increment=column_spec.get("auto_increment", False))
                   for column_spec in cls._get_all_field_columns()]
        return Table(cls._meta['table_name'], key=set(cls._meta['key_fields'] +
                            cls._meta['unique_fields'])) [fields]

########NEW FILE########
__FILENAME__ = test_report
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

In this file you'll find part of the tests written to ensure that
widgets displaying contents generated by TracReports behave as expected.

Only the tests requiring minimal setup effort are included below.
This means that the environment used to run these tests contains the
barely minimal information included in an environment (i.e. only the
data specified by `trac.db_default.get_data`.).

Once the tests are started all built-in components (except
trac.versioncontrol.* ) as well as widget system and extensions
are loaded. Besides the following values are (auto-magically)
made available in the global namespace (i.e. provided that
the test name be written like `|widget_name: Descriptive message`):

  - __tester__  An instance of `unittest.TestCase` representing the
                test case for the statement under test. Useful
                when specific assertions (e.g. `assertEquals`)
                are needed.
  - req         A dummy request object setup for anonymous access.
  - auth_req    A dummy request object setup like if user `murphy` was
                accessing the site.
  - env         the Trac environment used as a stub for testing purposes.
                This object is an instance of
                `bhdashboard.tests.EnvironmentStub`.
  - widget      the widget provider under test.
  - ctx         context used to render widget for anonymous user.
  - ctx_auth    context used to render widget for `murphy` user.
  - ticket_data A set of tickets used for testing purposes.
"""

#------------------------------------------------------
#    Test artifacts
#------------------------------------------------------

import sys

from bhdashboard.tests import trac_version


def test_suite():
    from doctest import NORMALIZE_WHITESPACE, ELLIPSIS, REPORT_UDIFF
    from dutest import MultiTestLoader
    from unittest import defaultTestLoader

    from bhdashboard.tests import DocTestWidgetLoader, ticket_data

    magic_vars = dict(ticket_data=ticket_data)
    if trac_version < (0, 13):  # FIXME: Should it be (0, 12) ?
        kwargs = {'enable': ['trac.[a-uw-z]*', 'tracrpc.*', 'bhdashboard.*']}
    else:
        kwargs = {
            'enable': ['trac.*', 'tracrpc.*', 'bhdashboard.*'],
            'disable': ['trac.versioncontrol.*']
        }

    l = MultiTestLoader(
        [defaultTestLoader,
         DocTestWidgetLoader(extraglobs=magic_vars,
                             default_data=True,
                             optionflags=ELLIPSIS | REPORT_UDIFF |
                                         NORMALIZE_WHITESPACE,
                             **kwargs)
        ])

    return l.loadTestsFromModule(sys.modules[__name__])

#------------------------------------------------------
#    Helper functions
#------------------------------------------------------

from datetime import datetime, time, date
from itertools import izip
from pprint import pprint

from bhdashboard.tests import clear_perm_cache


def print_report_metadata(report_desc):
    for attrnm in ('id', 'title', 'description', 'query'):
        print attrnm.capitalize()
        print '-' * len(attrnm)
        print report_desc[attrnm]


def print_report_columns(cols):
    for coldsc in cols:
        print 'Column:', coldsc[0], 'Type:', coldsc[1] or '_', \
            'Label:',
        try:
            print coldsc[2] or '_'
        except IndexError:
            print '_'


def print_report_result(cols, data):
    for i, row in enumerate(data):
        print '= Row', i, '='
        for coldsc in cols:
            colnm = coldsc[0]
            print 'Column:', colnm, 'Value:', row.get(colnm) or None, ''


TICKET_ATTRS = ('summary', 'description', 'priority',
                'milestone', 'type', 'owner', 'status',
                'component', 'version')


def prepare_ticket_workflow(tktrpc, ticket_data, auth_req):
    r"""Set ticket status considering the actions defined in standard
    ticket workflow. Needed for TracRpc>=1.0.6
    """
    from time import sleep

    TICKET_ACTIONS = {'accepted': 'accept', 'closed': 'resolve',
                      'assigned': 'reassign'}
    sleep(1)
    for idx, (_, __, td) in enumerate(ticket_data):
        action = TICKET_ACTIONS.get(td.get('status'))
        if action is not None:
            aux_attrs = {'action': action}
            aux_attrs.update(td)
            tktrpc.update(auth_req, idx + 1, "", aux_attrs)
    sleep(1)
    for idx, (_, __, td) in enumerate(ticket_data):
        tktrpc.update(auth_req, idx + 1, "", td)


__test__ = {
    'Initialization: Report widgets': r"""
      >>> from trac.core import ComponentMeta
      >>> from bhdashboard.api import IWidgetProvider
      >>> from bhdashboard.widgets.report import *
      >>> allcls = ComponentMeta._registry.get(IWidgetProvider, [])
      >>> [wpcls in allcls for wpcls in (TicketReportWidget,)]
      [True]
      """,
    '|TicketReport: Metadata': r"""
      >>> list(widget.get_widgets())
      ['TicketReport']
      >>> params = widget.get_widget_params('TicketReport')
      >>> pprint(params)
      {'id': {'desc': 'Report number',
                  'required': True,
                  'type': <type 'int'>},
       'page': {'default': 1,
                  'desc': 'Retrieve results in given page.',
                  'type': <type 'int'>},
       'user': {'desc': 'Render the report for a given user.'}}
      """,
    '|TicketReport: Render My Tickets report': r"""

      Add tickets

      >>> from tracrpc.ticket import TicketRPC
      >>> tcktrpc = TicketRPC(env)
      >>> for td in ticket_data :
      ...   tcktrpc.create(auth_req, *td)
      ...
      1
      2
      3
      4
      5
      6
      7
      8
      9

      >>> if all(tcktrpc.get(auth_req, tid)[-1].get('status') == 'new' \
      ...            for tid in xrange(1, 10)):
      ...   # RPC considers ticket workflow
      ...   prepare_ticket_workflow(tcktrpc, ticket_data, auth_req)
      ...

      Check everything is ok with tickets

      >>> for tid in xrange(1, 10):
      ...   d = tcktrpc.get(auth_req, tid)[-1]
      ...   print tuple(d.get(attr) or '' for attr in TICKET_ATTRS)
      ...
      (u'Ticket 1', u'Description 1', u'major', u'milestone1',
          u'defect', u'murphy', u'accepted', u'component1', u'1.0')
      (u'Ticket 2', u'Description 2', u'major', u'milestone4',
          u'task', u'murphy', u'accepted', '', '')
      (u'Ticket 3', u'Description 3', u'critical', u'milestone3',
          u'enhancement', u'tester', u'new', '', u'2.0')
      (u'Ticket 4', u'Description 4', u'minor', u'milestone3',
          u'task', u'murphy', u'closed', u'component1', u'1.0')
      (u'Ticket 5', u'Description 5', u'minor', u'milestone3',
          u'task', u'murphy', u'new', '', u'2.0')
      (u'Ticket 6', u'Description 6', u'minor', u'milestone1',
          u'task', u'tester', u'assigned', u'component2', u'1.0')
      (u'Ticket 7', u'Description 7', u'critical', '', u'enhancement',
          u'murphy', u'closed', '', '')
      (u'Ticket 8', u'Description 8', u'major', '', u'task',
          u'murphy', u'closed', u'component1', '')
      (u'Ticket 9', u'Description 9', u'minor', '', u'enhancement',
          u'tester', u'closed', '', u'2.0')

      >>> pprint(widget.render_widget('TicketReport', ctx, {
      ...     'args' : {'id' : 7}
      ...   }))
      ...
      ('widget_grid.html',
       {'data': {'action': 'view',
                 'args': {'USER': 'anonymous'},
                 'context': <...Context <Resource u'report:7'>>,
                 'description': u'\nThis report demonstrates the use of the automatically set \nUSER dynamic variable, replaced with the username of the\nlogged in user when executed.\n',
                 'email_map': {},
                 'header_groups': [[{'asc': False,
                                     'col': u'__color__',
                                     'hidden': True,
                                     'title': u'Color'},
                                    {'asc': False,
                                     'col': u'__group__',
                                     'hidden': True,
                                     'title': u'Group'},
                                    {'asc': False,
                                     'col': u'ticket',
                                     'hidden': False,
                                     'title': u'Ticket'},
                                    {'asc': False,
                                     'col': u'summary',
                                     'hidden': False,
                                     'title': u'Summary'},
                                    {'asc': False,
                                     'col': u'component',
                                     'hidden': False,
                                     'title': u'Component'},
                                    {'asc': False,
                                     'col': u'version',
                                     'hidden': False,
                                     'title': u'Version'},
                                    {'asc': False,
                                     'col': u'milestone',
                                     'hidden': False,
                                     'title': u'Milestone'},
                                    {'asc': False,
                                     'col': u'type',
                                     'hidden': False,
                                     'title': u'Type'},
                                    {'asc': False,
                                     'col': u'priority',
                                     'hidden': False,
                                     'title': u'Priority'},
                                    {'asc': False,
                                     'col': u'created',
                                     'hidden': False,
                                     'title': u'Created'},
                                    {'asc': False,
                                     'col': u'_changetime',
                                     'hidden': True,
                                     'title': u'Changetime'},
                                    {'asc': False,
                                     'col': u'_description',
                                     'hidden': True,
                                     'title': u'Description'},
                                    {'asc': False,
                                     'col': u'_reporter',
                                     'hidden': True,
                                     'title': u'Reporter'}]],
                 'message': None,
                 'numrows': 0,
                 'paginator': <trac.util.presentation.Paginator object at ...>,
                 'report': {'id': 7, 'resource': <Resource u'report:7'>},
                 'row_groups': [],
                 'sorting_enabled': False,
                 'title': u'{7} My Tickets'},
        'title': <Element "a">},
       <...Context <Resource u'report:7'>>)

      >>> template, data, rptctx = widget.render_widget('TicketReport', auth_ctx, {
      ...     'args' : {'id' : 7}
      ...   })
      ...
      >>> data = data['data']
      >>> template
      'widget_grid.html'
      >>> rptctx.parent is auth_ctx
      True

      In Trac=0.13 (0.12 ?) My Tickets report adds another group
      So perform common check in here ...

      >>> reported_tickets = None
      >>> for x in data['row_groups']:
      ...   if x[0] == 'Reported':
      ...     reported_tickets = x
      ...     break
      ...
      >>> if reported_tickets:
      ...   data['row_groups'].remove(reported_tickets)
      ...
      >>> pprint(data)
      {'action': 'view',
       'args': {'USER': 'murphy'},
       'context': <Context <Resource u'report:7'>>,
       'description': u'\nThis report demonstrates the use of the automatically set \nUSER dynamic variable, replaced with the username of the\nlogged in user when executed.\n',
       'email_map': {},
       'header_groups': [[{'asc': False,
                           'col': u'__color__',
                           'hidden': True,
                           'title': u'Color'},
                          {'asc': False,
                           'col': u'__group__',
                           'hidden': True,
                           'title': u'Group'},
                          {'asc': False,
                           'col': u'ticket',
                           'hidden': False,
                           'title': u'Ticket'},
                          {'asc': False,
                           'col': u'summary',
                           'hidden': False,
                           'title': u'Summary'},
                          {'asc': False,
                           'col': u'component',
                           'hidden': False,
                           'title': u'Component'},
                          {'asc': False,
                           'col': u'version',
                           'hidden': False,
                           'title': u'Version'},
                          {'asc': False,
                           'col': u'milestone',
                           'hidden': False,
                           'title': u'Milestone'},
                          {'asc': False,
                           'col': u'type',
                           'hidden': False,
                           'title': u'Type'},
                          {'asc': False,
                           'col': u'priority',
                           'hidden': False,
                           'title': u'Priority'},
                          {'asc': False,
                           'col': u'created',
                           'hidden': False,
                           'title': u'Created'},
                          {'asc': False,
                           'col': u'_changetime',
                           'hidden': True,
                           'title': u'Changetime'},
                          {'asc': False,
                           'col': u'_description',
                           'hidden': True,
                           'title': u'Description'},
                          {'asc': False,
                           'col': u'_reporter',
                           'hidden': True,
                           'title': u'Reporter'}]],
       'message': None,
       'numrows': 3,
       'paginator': <trac.util.presentation.Paginator object at ...>,
       'report': {'id': 7, 'resource': <Resource u'report:7'>},
       'row_groups': [(u'Accepted',
                       [{u'__color__': u'3',
                         '__idx__': 0,
                         'cell_groups': [[{'header': {'asc': False,
                                                      'col': u'__color__',
                                                      'hidden': True,
                                                      'title': u'Color'},
                                           'index': 0,
                                           'value': u'3'},
                                          {'header': {'asc': False,
                                                      'col': u'__group__',
                                                      'hidden': True,
                                                      'title': u'Group'},
                                           'index': 1,
                                           'value': u'Accepted'},
                                          {'header': {'asc': False,
                                                      'col': u'ticket',
                                                      'hidden': False,
                                                      'title': u'Ticket'},
                                           'index': 2,
                                           'value': u'1'},
                                          {'header': {'asc': False,
                                                      'col': u'summary',
                                                      'hidden': False,
                                                      'title': u'Summary'},
                                           'index': 3,
                                           'value': u'Ticket 1'},
                                          {'header': {'asc': False,
                                                      'col': u'component',
                                                      'hidden': False,
                                                      'title': u'Component'},
                                           'index': 4,
                                           'value': u'component1'},
                                          {'header': {'asc': False,
                                                      'col': u'version',
                                                      'hidden': False,
                                                      'title': u'Version'},
                                           'index': 5,
                                           'value': u'1.0'},
                                          {'header': {'asc': False,
                                                      'col': u'milestone',
                                                      'hidden': False,
                                                      'title': u'Milestone'},
                                           'index': 6,
                                           'value': u'milestone1'},
                                          {'header': {'asc': False,
                                                      'col': u'type',
                                                      'hidden': False,
                                                      'title': u'Type'},
                                           'index': 7,
                                           'value': u'defect'},
                                          {'header': {'asc': False,
                                                      'col': u'priority',
                                                      'hidden': False,
                                                      'title': u'Priority'},
                                           'index': 8,
                                           'value': u'major'},
                                          {'header': {'asc': False,
                                                      'col': u'created',
                                                      'hidden': False,
                                                      'title': u'Created'},
                                           'index': 9,
                                           'value': u'...'},
                                          {'header': {'asc': False,
                                                      'col': u'_changetime',
                                                      'hidden': True,
                                                      'title': u'Changetime'},
                                           'index': 10,
                                           'value': u'...'},
                                          {'header': {'asc': False,
                                                      'col': u'_description',
                                                      'hidden': True,
                                                      'title': u'Description'},
                                           'index': 11,
                                           'value': u'Description 1'},
                                          {'header': {'asc': False,
                                                      'col': u'_reporter',
                                                      'hidden': True,
                                                      'title': u'Reporter'},
                                           'index': 12,
                                           'value': u'murphy'}]],
                         'id': u'1',
                         'resource': <Resource u'ticket:1'>},
                        {u'__color__': u'3',
                         '__idx__': 1,
                         'cell_groups': [[{'header': {'asc': False,
                                                      'col': u'__color__',
                                                      'hidden': True,
                                                      'title': u'Color'},
                                           'index': 0,
                                           'value': u'3'},
                                          {'header': {'asc': False,
                                                      'col': u'__group__',
                                                      'hidden': True,
                                                      'title': u'Group'},
                                           'index': 1,
                                           'value': u'Accepted'},
                                          {'header': {'asc': False,
                                                      'col': u'ticket',
                                                      'hidden': False,
                                                      'title': u'Ticket'},
                                           'index': 2,
                                           'value': u'2'},
                                          {'header': {'asc': False,
                                                      'col': u'summary',
                                                      'hidden': False,
                                                      'title': u'Summary'},
                                           'index': 3,
                                           'value': u'Ticket 2'},
                                          {'header': {'asc': False,
                                                      'col': u'component',
                                                      'hidden': False,
                                                      'title': u'Component'},
                                           'index': 4,
                                           'value': ''},
                                          {'header': {'asc': False,
                                                      'col': u'version',
                                                      'hidden': False,
                                                      'title': u'Version'},
                                           'index': 5,
                                           'value': ''},
                                          {'header': {'asc': False,
                                                      'col': u'milestone',
                                                      'hidden': False,
                                                      'title': u'Milestone'},
                                           'index': 6,
                                           'value': u'milestone4'},
                                          {'header': {'asc': False,
                                                      'col': u'type',
                                                      'hidden': False,
                                                      'title': u'Type'},
                                           'index': 7,
                                           'value': u'task'},
                                          {'header': {'asc': False,
                                                      'col': u'priority',
                                                      'hidden': False,
                                                      'title': u'Priority'},
                                           'index': 8,
                                           'value': u'major'},
                                          {'header': {'asc': False,
                                                      'col': u'created',
                                                      'hidden': False,
                                                      'title': u'Created'},
                                           'index': 9,
                                           'value': u'...'},
                                          {'header': {'asc': False,
                                                      'col': u'_changetime',
                                                      'hidden': True,
                                                      'title': u'Changetime'},
                                           'index': 10,
                                           'value': u'...'},
                                          {'header': {'asc': False,
                                                      'col': u'_description',
                                                      'hidden': True,
                                                      'title': u'Description'},
                                           'index': 11,
                                           'value': u'Description 2'},
                                          {'header': {'asc': False,
                                                      'col': u'_reporter',
                                                      'hidden': True,
                                                      'title': u'Reporter'},
                                           'index': 12,
                                           'value': u'murphy'}]],
                         'id': u'2',
                         'resource': <Resource u'ticket:2'>}]),
                      (u'Owned',
                       [{u'__color__': u'4',
                         '__idx__': 2,
                         'cell_groups': [[{'header': {'asc': False,
                                                      'col': u'__color__',
                                                      'hidden': True,
                                                      'title': u'Color'},
                                           'index': 0,
                                           'value': u'4'},
                                          {'header': {'asc': False,
                                                      'col': u'__group__',
                                                      'hidden': True,
                                                      'title': u'Group'},
                                           'index': 1,
                                           'value': u'Owned'},
                                          {'header': {'asc': False,
                                                      'col': u'ticket',
                                                      'hidden': False,
                                                      'title': u'Ticket'},
                                           'index': 2,
                                           'value': u'5'},
                                          {'header': {'asc': False,
                                                      'col': u'summary',
                                                      'hidden': False,
                                                      'title': u'Summary'},
                                           'index': 3,
                                           'value': u'Ticket 5'},
                                          {'header': {'asc': False,
                                                      'col': u'component',
                                                      'hidden': False,
                                                      'title': u'Component'},
                                           'index': 4,
                                           'value': ''},
                                          {'header': {'asc': False,
                                                      'col': u'version',
                                                      'hidden': False,
                                                      'title': u'Version'},
                                           'index': 5,
                                           'value': u'2.0'},
                                          {'header': {'asc': False,
                                                      'col': u'milestone',
                                                      'hidden': False,
                                                      'title': u'Milestone'},
                                           'index': 6,
                                           'value': u'milestone3'},
                                          {'header': {'asc': False,
                                                      'col': u'type',
                                                      'hidden': False,
                                                      'title': u'Type'},
                                           'index': 7,
                                           'value': u'task'},
                                          {'header': {'asc': False,
                                                      'col': u'priority',
                                                      'hidden': False,
                                                      'title': u'Priority'},
                                           'index': 8,
                                           'value': u'minor'},
                                          {'header': {'asc': False,
                                                      'col': u'created',
                                                      'hidden': False,
                                                      'title': u'Created'},
                                           'index': 9,
                                           'value': u'...'},
                                          {'header': {'asc': False,
                                                      'col': u'_changetime',
                                                      'hidden': True,
                                                      'title': u'Changetime'},
                                           'index': 10,
                                           'value': u'...'},
                                          {'header': {'asc': False,
                                                      'col': u'_description',
                                                      'hidden': True,
                                                      'title': u'Description'},
                                           'index': 11,
                                           'value': u'Description 5'},
                                          {'header': {'asc': False,
                                                      'col': u'_reporter',
                                                      'hidden': True,
                                                      'title': u'Reporter'},
                                           'index': 12,
                                           'value': u'murphy'}]],
                         'id': u'5',
                         'resource': <Resource u'ticket:5'>}])],
       'sorting_enabled': False,
       'title': u'{7} My Tickets'}

      ... and check for Trac=0.13 in here ;)

      >>> if trac_version < trac_tags[0]:
      ...   __tester__.assertEquals(reported_tickets, None)
      ... else:
      ...   __tester__.assertEquals(
      ...       [x['ticket'] for x in reported_tickets[1]],
      ...       [3, 6]
      ...     )
      ...
      """,
    '|TicketReport: Render a subset of My Tickets report': r"""

      Add tickets

      >>> from tracrpc.ticket import TicketRPC
      >>> tcktrpc = TicketRPC(env)
      >>> for td in ticket_data :
      ...   tcktrpc.create(auth_req, *td)
      ...
      1
      2
      3
      4
      5
      6
      7
      8
      9

      >>> if all(tcktrpc.get(auth_req, tid)[-1].get('status') == 'new' \
      ...            for tid in xrange(1, 10)):
      ...   # RPC considers ticket workflow
      ...   prepare_ticket_workflow(tcktrpc, ticket_data, auth_req)
      ...

      Check everything is ok with tickets

      >>> for tid in xrange(1, 10):
      ...   d = tcktrpc.get(auth_req, tid)[-1]
      ...   print tuple(d.get(attr) or '' for attr in TICKET_ATTRS)
      (u'Ticket 1', u'Description 1', u'major', u'milestone1',
          u'defect', u'murphy', u'accepted', u'component1', u'1.0')
      (u'Ticket 2', u'Description 2', u'major', u'milestone4',
          u'task', u'murphy', u'accepted', '', '')
      (u'Ticket 3', u'Description 3', u'critical', u'milestone3',
          u'enhancement', u'tester', u'new', '', u'2.0')
      (u'Ticket 4', u'Description 4', u'minor', u'milestone3',
          u'task', u'murphy', u'closed', u'component1', u'1.0')
      (u'Ticket 5', u'Description 5', u'minor', u'milestone3',
          u'task', u'murphy', u'new', '', u'2.0')
      (u'Ticket 6', u'Description 6', u'minor', u'milestone1',
          u'task', u'tester', u'assigned', u'component2', u'1.0')
      (u'Ticket 7', u'Description 7', u'critical', '', u'enhancement',
          u'murphy', u'closed', '', '')
      (u'Ticket 8', u'Description 8', u'major', '', u'task',
          u'murphy', u'closed', u'component1', '')
      (u'Ticket 9', u'Description 9', u'minor', '', u'enhancement',
          u'tester', u'closed', '', u'2.0')

      >>> pprint(widget.render_widget('TicketReport', auth_ctx, {
      ...     'args' : {'id' : 7, 'limit' : 2}
      ...   }))
      ...
      ('widget_grid.html',
       {'data': {'action': 'view',
                 'args': {'USER': 'murphy'},
                 'context': <...Context <Resource u'report:7'>>,
                 'description': u'\nThis report demonstrates the use of the automatically set \nUSER dynamic variable, replaced with the username of the\nlogged in user when executed.\n',
                 'email_map': {},
                 'header_groups': [[{'asc': False,
                                     'col': u'__color__',
                                     'hidden': True,
                                     'title': u'Color'},
                                    {'asc': False,
                                     'col': u'__group__',
                                     'hidden': True,
                                     'title': u'Group'},
                                    {'asc': False,
                                     'col': u'ticket',
                                     'hidden': False,
                                     'title': u'Ticket'},
                                    {'asc': False,
                                     'col': u'summary',
                                     'hidden': False,
                                     'title': u'Summary'},
                                    {'asc': False,
                                     'col': u'component',
                                     'hidden': False,
                                     'title': u'Component'},
                                    {'asc': False,
                                     'col': u'version',
                                     'hidden': False,
                                     'title': u'Version'},
                                    {'asc': False,
                                     'col': u'milestone',
                                     'hidden': False,
                                     'title': u'Milestone'},
                                    {'asc': False,
                                     'col': u'type',
                                     'hidden': False,
                                     'title': u'Type'},
                                    {'asc': False,
                                     'col': u'priority',
                                     'hidden': False,
                                     'title': u'Priority'},
                                    {'asc': False,
                                     'col': u'created',
                                     'hidden': False,
                                     'title': u'Created'},
                                    {'asc': False,
                                     'col': u'_changetime',
                                     'hidden': True,
                                     'title': u'Changetime'},
                                    {'asc': False,
                                     'col': u'_description',
                                     'hidden': True,
                                     'title': u'Description'},
                                    {'asc': False,
                                     'col': u'_reporter',
                                     'hidden': True,
                                     'title': u'Reporter'}]],
                 'message': None,
                 'numrows': 3,
                 'paginator': <trac.util.presentation.Paginator object at ...>,
                 'report': {'id': 7, 'resource': <Resource u'report:7'>},
                 'row_groups': [(u'Accepted',
                                 [{u'__color__': u'3',
                                    '__idx__': 0,
                                    'cell_groups': [[{'header': {'asc': False,
                                                                'col': u'__color__',
                                                                'hidden': True,
                                                                'title': u'Color'},
                                                     'index': 0,
                                                     'value': u'3'},
                                                    {'header': {'asc': False,
                                                                'col': u'__group__',
                                                                'hidden': True,
                                                                'title': u'Group'},
                                                     'index': 1,
                                                     'value': u'Accepted'},
                                                    {'header': {'asc': False,
                                                                'col': u'ticket',
                                                                'hidden': False,
                                                                'title': u'Ticket'},
                                                     'index': 2,
                                                     'value': u'1'},
                                                    {'header': {'asc': False,
                                                                'col': u'summary',
                                                                'hidden': False,
                                                                'title': u'Summary'},
                                                     'index': 3,
                                                     'value': u'Ticket 1'},
                                                    {'header': {'asc': False,
                                                                'col': u'component',
                                                                'hidden': False,
                                                                'title': u'Component'},
                                                     'index': 4,
                                                     'value': u'component1'},
                                                    {'header': {'asc': False,
                                                                'col': u'version',
                                                                'hidden': False,
                                                                'title': u'Version'},
                                                     'index': 5,
                                                     'value': u'1.0'},
                                                    {'header': {'asc': False,
                                                                'col': u'milestone',
                                                                'hidden': False,
                                                                'title': u'Milestone'},
                                                     'index': 6,
                                                     'value': u'milestone1'},
                                                    {'header': {'asc': False,
                                                                'col': u'type',
                                                                'hidden': False,
                                                                'title': u'Type'},
                                                     'index': 7,
                                                     'value': u'defect'},
                                                    {'header': {'asc': False,
                                                                'col': u'priority',
                                                                'hidden': False,
                                                                'title': u'Priority'},
                                                     'index': 8,
                                                     'value': u'major'},
                                                    {'header': {'asc': False,
                                                                'col': u'created',
                                                                'hidden': False,
                                                                'title': u'Created'},
                                                     'index': 9,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_changetime',
                                                                'hidden': True,
                                                                'title': u'Changetime'},
                                                     'index': 10,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_description',
                                                                'hidden': True,
                                                                'title': u'Description'},
                                                     'index': 11,
                                                     'value': u'Description 1'},
                                                    {'header': {'asc': False,
                                                                'col': u'_reporter',
                                                                'hidden': True,
                                                                'title': u'Reporter'},
                                                     'index': 12,
                                                     'value': u'murphy'}]],
                                    'id': u'1',
                                    'resource': <Resource u'ticket:1'>},
                                  {u'__color__': u'3',
                                    '__idx__': 1,
                                    'cell_groups': [[{'header': {'asc': False,
                                                                'col': u'__color__',
                                                                'hidden': True,
                                                                'title': u'Color'},
                                                     'index': 0,
                                                     'value': u'3'},
                                                    {'header': {'asc': False,
                                                                'col': u'__group__',
                                                                'hidden': True,
                                                                'title': u'Group'},
                                                     'index': 1,
                                                     'value': u'Accepted'},
                                                    {'header': {'asc': False,
                                                                'col': u'ticket',
                                                                'hidden': False,
                                                                'title': u'Ticket'},
                                                     'index': 2,
                                                     'value': u'2'},
                                                    {'header': {'asc': False,
                                                                'col': u'summary',
                                                                'hidden': False,
                                                                'title': u'Summary'},
                                                     'index': 3,
                                                     'value': u'Ticket 2'},
                                                    {'header': {'asc': False,
                                                                'col': u'component',
                                                                'hidden': False,
                                                                'title': u'Component'},
                                                     'index': 4,
                                                     'value': ''},
                                                    {'header': {'asc': False,
                                                                'col': u'version',
                                                                'hidden': False,
                                                                'title': u'Version'},
                                                     'index': 5,
                                                     'value': ''},
                                                    {'header': {'asc': False,
                                                                'col': u'milestone',
                                                                'hidden': False,
                                                                'title': u'Milestone'},
                                                     'index': 6,
                                                     'value': u'milestone4'},
                                                    {'header': {'asc': False,
                                                                'col': u'type',
                                                                'hidden': False,
                                                                'title': u'Type'},
                                                     'index': 7,
                                                     'value': u'task'},
                                                    {'header': {'asc': False,
                                                                'col': u'priority',
                                                                'hidden': False,
                                                                'title': u'Priority'},
                                                     'index': 8,
                                                     'value': u'major'},
                                                    {'header': {'asc': False,
                                                                'col': u'created',
                                                                'hidden': False,
                                                                'title': u'Created'},
                                                     'index': 9,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_changetime',
                                                                'hidden': True,
                                                                'title': u'Changetime'},
                                                     'index': 10,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_description',
                                                                'hidden': True,
                                                                'title': u'Description'},
                                                     'index': 11,
                                                     'value': u'Description 2'},
                                                    {'header': {'asc': False,
                                                                'col': u'_reporter',
                                                                'hidden': True,
                                                                'title': u'Reporter'},
                                                     'index': 12,
                                                     'value': u'murphy'}]],
                                    'id': u'2',
                                    'resource': <Resource u'ticket:2'>}]),
                                (u'Owned',
                                 [{u'__color__': u'4',
                                    '__idx__': 2,
                                    'cell_groups': [[{'header': {'asc': False,
                                                                'col': u'__color__',
                                                                'hidden': True,
                                                                'title': u'Color'},
                                                     'index': 0,
                                                     'value': u'4'},
                                                    {'header': {'asc': False,
                                                                'col': u'__group__',
                                                                'hidden': True,
                                                                'title': u'Group'},
                                                     'index': 1,
                                                     'value': u'Owned'},
                                                    {'header': {'asc': False,
                                                                'col': u'ticket',
                                                                'hidden': False,
                                                                'title': u'Ticket'},
                                                     'index': 2,
                                                     'value': u'5'},
                                                    {'header': {'asc': False,
                                                                'col': u'summary',
                                                                'hidden': False,
                                                                'title': u'Summary'},
                                                     'index': 3,
                                                     'value': u'Ticket 5'},
                                                    {'header': {'asc': False,
                                                                'col': u'component',
                                                                'hidden': False,
                                                                'title': u'Component'},
                                                     'index': 4,
                                                     'value': ''},
                                                    {'header': {'asc': False,
                                                                'col': u'version',
                                                                'hidden': False,
                                                                'title': u'Version'},
                                                     'index': 5,
                                                     'value': u'2.0'},
                                                    {'header': {'asc': False,
                                                                'col': u'milestone',
                                                                'hidden': False,
                                                                'title': u'Milestone'},
                                                     'index': 6,
                                                     'value': u'milestone3'},
                                                    {'header': {'asc': False,
                                                                'col': u'type',
                                                                'hidden': False,
                                                                'title': u'Type'},
                                                     'index': 7,
                                                     'value': u'task'},
                                                    {'header': {'asc': False,
                                                                'col': u'priority',
                                                                'hidden': False,
                                                                'title': u'Priority'},
                                                     'index': 8,
                                                     'value': u'minor'},
                                                    {'header': {'asc': False,
                                                                'col': u'created',
                                                                'hidden': False,
                                                                'title': u'Created'},
                                                     'index': 9,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_changetime',
                                                                'hidden': True,
                                                                'title': u'Changetime'},
                                                     'index': 10,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_description',
                                                                'hidden': True,
                                                                'title': u'Description'},
                                                     'index': 11,
                                                     'value': u'Description 5'},
                                                    {'header': {'asc': False,
                                                                'col': u'_reporter',
                                                                'hidden': True,
                                                                'title': u'Reporter'},
                                                     'index': 12,
                                                     'value': u'murphy'}]],
                                    'id': u'5',
                                    'resource': <Resource u'ticket:5'>}])],
                 'sorting_enabled': False,
                 'title': u'{7} My Tickets'},
       'title': <Element "a">},
       <...Context <Resource u'report:7'>>)
      """,
    '|TicketReport: Invalid widget name': r"""
      >>> widget.render_widget('OlkswSk', ctx, {
      ...     'args' : {'id' : 1, 'limit' : 8}
      ...   })
      ...
      Traceback (most recent call last):
        ...
      InvalidIdentifier: Widget name MUST match any of TicketReport
      """,
    '|TicketReport: Invalid report ID in arguments': r"""
      >>> widget.render_widget('TicketReport', ctx, {
      ...     'args' : {'id' : 99999}
      ...   })
      ...
      Traceback (most recent call last):
        ...
      InvalidIdentifier: Report 99999 does not exist.
      """,
    '|TicketReport: Missing required arguments': r"""
      >>> widget.render_widget('TicketReport', ctx, {
      ...     'args' : {}
      ...   })
      ...
      Traceback (most recent call last):
        ...
      InvalidWidgetArgument: Invalid argument `id`. Required parameter expected

      >>> widget.render_widget('TicketReport', ctx, {
      ...     'args' : {'limit' : 4}
      ...   })
      ...
      Traceback (most recent call last):
        ...
      InvalidWidgetArgument: Invalid argument `id`. Required parameter expected
      """,
    '|TicketReport: Invalid widget parameter': r"""

      Add tickets

      >>> from tracrpc.ticket import TicketRPC
      >>> tcktrpc = TicketRPC(env)
      >>> for td in ticket_data :
      ...   tcktrpc.create(auth_req, *td)
      ...
      1
      2
      3
      4
      5
      6
      7
      8
      9

      >>> if all(tcktrpc.get(auth_req, tid)[-1].get('status') == 'new' \
      ...            for tid in xrange(1, 10)):
      ...   # RPC considers ticket workflow
      ...   prepare_ticket_workflow(tcktrpc, ticket_data, auth_req)
      ...

      Check everything is ok with tickets

      >>> for tid in xrange(1, 10):
      ...   d = tcktrpc.get(auth_req, tid)[-1]
      ...   print tuple(d.get(attr) or '' for attr in TICKET_ATTRS)
      (u'Ticket 1', u'Description 1', u'major', u'milestone1',
          u'defect', u'murphy', u'accepted', u'component1', u'1.0')
      (u'Ticket 2', u'Description 2', u'major', u'milestone4',
          u'task', u'murphy', u'accepted', '', '')
      (u'Ticket 3', u'Description 3', u'critical', u'milestone3',
          u'enhancement', u'tester', u'new', '', u'2.0')
      (u'Ticket 4', u'Description 4', u'minor', u'milestone3',
          u'task', u'murphy', u'closed', u'component1', u'1.0')
      (u'Ticket 5', u'Description 5', u'minor', u'milestone3',
          u'task', u'murphy', u'new', '', u'2.0')
      (u'Ticket 6', u'Description 6', u'minor', u'milestone1',
          u'task', u'tester', u'assigned', u'component2', u'1.0')
      (u'Ticket 7', u'Description 7', u'critical', '', u'enhancement',
          u'murphy', u'closed', '', '')
      (u'Ticket 8', u'Description 8', u'major', '', u'task',
          u'murphy', u'closed', u'component1', '')
      (u'Ticket 9', u'Description 9', u'minor', '', u'enhancement',
          u'tester', u'closed', '', u'2.0')

      >>> pprint(widget.render_widget('TicketReport', auth_ctx, {
      ...     'args' : {'newjums' : 7, 'id' : 7, 'limit' : 1}
      ...   }))
      ...
      ('widget_grid.html',
       {'data': {'action': 'view',
                 'args': {'USER': 'murphy'},
                 'context': <...Context <Resource u'report:7'>>,
                 'description': u'\nThis report demonstrates the use of the automatically set \nUSER dynamic variable, replaced with the username of the\nlogged in user when executed.\n',
                 'email_map': {},
                 'header_groups': [[{'asc': False,
                                     'col': u'__color__',
                                     'hidden': True,
                                     'title': u'Color'},
                                    {'asc': False,
                                     'col': u'__group__',
                                     'hidden': True,
                                     'title': u'Group'},
                                    {'asc': False,
                                     'col': u'ticket',
                                     'hidden': False,
                                     'title': u'Ticket'},
                                    {'asc': False,
                                     'col': u'summary',
                                     'hidden': False,
                                     'title': u'Summary'},
                                    {'asc': False,
                                     'col': u'component',
                                     'hidden': False,
                                     'title': u'Component'},
                                    {'asc': False,
                                     'col': u'version',
                                     'hidden': False,
                                     'title': u'Version'},
                                    {'asc': False,
                                     'col': u'milestone',
                                     'hidden': False,
                                     'title': u'Milestone'},
                                    {'asc': False,
                                     'col': u'type',
                                     'hidden': False,
                                     'title': u'Type'},
                                    {'asc': False,
                                     'col': u'priority',
                                     'hidden': False,
                                     'title': u'Priority'},
                                    {'asc': False,
                                     'col': u'created',
                                     'hidden': False,
                                     'title': u'Created'},
                                    {'asc': False,
                                     'col': u'_changetime',
                                     'hidden': True,
                                     'title': u'Changetime'},
                                    {'asc': False,
                                     'col': u'_description',
                                     'hidden': True,
                                     'title': u'Description'},
                                    {'asc': False,
                                     'col': u'_reporter',
                                     'hidden': True,
                                     'title': u'Reporter'}]],
                 'message': None,
                 'numrows': 3,
                 'paginator': <trac.util.presentation.Paginator object at ...>,
                 'report': {'id': 7, 'resource': <Resource u'report:7'>},
                 'row_groups': [(u'Accepted',
                                 [{u'__color__': u'3',
                                   '__idx__': 0,
                                   'cell_groups': [[{'header': {'asc': False,
                                                                'col': u'__color__',
                                                                'hidden': True,
                                                                'title': u'Color'},
                                                     'index': 0,
                                                     'value': u'3'},
                                                    {'header': {'asc': False,
                                                                'col': u'__group__',
                                                                'hidden': True,
                                                                'title': u'Group'},
                                                     'index': 1,
                                                     'value': u'Accepted'},
                                                    {'header': {'asc': False,
                                                                'col': u'ticket',
                                                                'hidden': False,
                                                                'title': u'Ticket'},
                                                     'index': 2,
                                                     'value': u'1'},
                                                    {'header': {'asc': False,
                                                                'col': u'summary',
                                                                'hidden': False,
                                                                'title': u'Summary'},
                                                     'index': 3,
                                                     'value': u'Ticket 1'},
                                                    {'header': {'asc': False,
                                                                'col': u'component',
                                                                'hidden': False,
                                                                'title': u'Component'},
                                                     'index': 4,
                                                     'value': u'component1'},
                                                    {'header': {'asc': False,
                                                                'col': u'version',
                                                                'hidden': False,
                                                                'title': u'Version'},
                                                     'index': 5,
                                                     'value': u'1.0'},
                                                    {'header': {'asc': False,
                                                                'col': u'milestone',
                                                                'hidden': False,
                                                                'title': u'Milestone'},
                                                     'index': 6,
                                                     'value': u'milestone1'},
                                                    {'header': {'asc': False,
                                                                'col': u'type',
                                                                'hidden': False,
                                                                'title': u'Type'},
                                                     'index': 7,
                                                     'value': u'defect'},
                                                    {'header': {'asc': False,
                                                                'col': u'priority',
                                                                'hidden': False,
                                                                'title': u'Priority'},
                                                     'index': 8,
                                                     'value': u'major'},
                                                    {'header': {'asc': False,
                                                                'col': u'created',
                                                                'hidden': False,
                                                                'title': u'Created'},
                                                     'index': 9,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_changetime',
                                                                'hidden': True,
                                                                'title': u'Changetime'},
                                                     'index': 10,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_description',
                                                                'hidden': True,
                                                                'title': u'Description'},
                                                     'index': 11,
                                                     'value': u'Description 1'},
                                                    {'header': {'asc': False,
                                                                'col': u'_reporter',
                                                                'hidden': True,
                                                                'title': u'Reporter'},
                                                     'index': 12,
                                                     'value': u'murphy'}]],
                                   'id': u'1',
                                   'resource': <Resource u'ticket:1'>},
                                  {u'__color__': u'3',
                                   '__idx__': 1,
                                   'cell_groups': [[{'header': {'asc': False,
                                                                'col': u'__color__',
                                                                'hidden': True,
                                                                'title': u'Color'},
                                                     'index': 0,
                                                     'value': u'3'},
                                                    {'header': {'asc': False,
                                                                'col': u'__group__',
                                                                'hidden': True,
                                                                'title': u'Group'},
                                                     'index': 1,
                                                     'value': u'Accepted'},
                                                    {'header': {'asc': False,
                                                                'col': u'ticket',
                                                                'hidden': False,
                                                                'title': u'Ticket'},
                                                     'index': 2,
                                                     'value': u'2'},
                                                    {'header': {'asc': False,
                                                                'col': u'summary',
                                                                'hidden': False,
                                                                'title': u'Summary'},
                                                     'index': 3,
                                                     'value': u'Ticket 2'},
                                                    {'header': {'asc': False,
                                                                'col': u'component',
                                                                'hidden': False,
                                                                'title': u'Component'},
                                                     'index': 4,
                                                     'value': ''},
                                                    {'header': {'asc': False,
                                                                'col': u'version',
                                                                'hidden': False,
                                                                'title': u'Version'},
                                                     'index': 5,
                                                     'value': ''},
                                                    {'header': {'asc': False,
                                                                'col': u'milestone',
                                                                'hidden': False,
                                                                'title': u'Milestone'},
                                                     'index': 6,
                                                     'value': u'milestone4'},
                                                    {'header': {'asc': False,
                                                                'col': u'type',
                                                                'hidden': False,
                                                                'title': u'Type'},
                                                     'index': 7,
                                                     'value': u'task'},
                                                    {'header': {'asc': False,
                                                                'col': u'priority',
                                                                'hidden': False,
                                                                'title': u'Priority'},
                                                     'index': 8,
                                                     'value': u'major'},
                                                    {'header': {'asc': False,
                                                                'col': u'created',
                                                                'hidden': False,
                                                                'title': u'Created'},
                                                     'index': 9,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_changetime',
                                                                'hidden': True,
                                                                'title': u'Changetime'},
                                                     'index': 10,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_description',
                                                                'hidden': True,
                                                                'title': u'Description'},
                                                     'index': 11,
                                                     'value': u'Description 2'},
                                                    {'header': {'asc': False,
                                                                'col': u'_reporter',
                                                                'hidden': True,
                                                                'title': u'Reporter'},
                                                     'index': 12,
                                                     'value': u'murphy'}]],
                                   'id': u'2',
                                   'resource': <Resource u'ticket:2'>}]),
                                (u'Owned',
                                 [{u'__color__': u'4',
                                   '__idx__': 2,
                                   'cell_groups': [[{'header': {'asc': False,
                                                                'col': u'__color__',
                                                                'hidden': True,
                                                                'title': u'Color'},
                                                     'index': 0,
                                                     'value': u'4'},
                                                    {'header': {'asc': False,
                                                                'col': u'__group__',
                                                                'hidden': True,
                                                                'title': u'Group'},
                                                     'index': 1,
                                                     'value': u'Owned'},
                                                    {'header': {'asc': False,
                                                                'col': u'ticket',
                                                                'hidden': False,
                                                                'title': u'Ticket'},
                                                     'index': 2,
                                                     'value': u'5'},
                                                    {'header': {'asc': False,
                                                                'col': u'summary',
                                                                'hidden': False,
                                                                'title': u'Summary'},
                                                     'index': 3,
                                                     'value': u'Ticket 5'},
                                                    {'header': {'asc': False,
                                                                'col': u'component',
                                                                'hidden': False,
                                                                'title': u'Component'},
                                                     'index': 4,
                                                     'value': ''},
                                                    {'header': {'asc': False,
                                                                'col': u'version',
                                                                'hidden': False,
                                                                'title': u'Version'},
                                                     'index': 5,
                                                     'value': u'2.0'},
                                                    {'header': {'asc': False,
                                                                'col': u'milestone',
                                                                'hidden': False,
                                                                'title': u'Milestone'},
                                                     'index': 6,
                                                     'value': u'milestone3'},
                                                    {'header': {'asc': False,
                                                                'col': u'type',
                                                                'hidden': False,
                                                                'title': u'Type'},
                                                     'index': 7,
                                                     'value': u'task'},
                                                    {'header': {'asc': False,
                                                                'col': u'priority',
                                                                'hidden': False,
                                                                'title': u'Priority'},
                                                     'index': 8,
                                                     'value': u'minor'},
                                                    {'header': {'asc': False,
                                                                'col': u'created',
                                                                'hidden': False,
                                                                'title': u'Created'},
                                                     'index': 9,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_changetime',
                                                                'hidden': True,
                                                                'title': u'Changetime'},
                                                     'index': 10,
                                                     'value': u'...'},
                                                    {'header': {'asc': False,
                                                                'col': u'_description',
                                                                'hidden': True,
                                                                'title': u'Description'},
                                                     'index': 11,
                                                     'value': u'Description 5'},
                                                    {'header': {'asc': False,
                                                                'col': u'_reporter',
                                                                'hidden': True,
                                                                'title': u'Reporter'},
                                                     'index': 12,
                                                     'value': u'murphy'}]],
                                   'id': u'5',
                                   'resource': <Resource u'ticket:5'>}])],
                 'sorting_enabled': False,
                 'title': u'{7} My Tickets'},
        'title': <Element "a">},
       <...Context <Resource u'report:7'>>)
      """,
    '|TicketReport: Invalid report definition': r"""
      >>> raise NotImplementedError()
      """,
}

########NEW FILE########
__FILENAME__ = test_webui
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

In this file you'll find part of the tests written to ensure that
dashboard web module works as expected.

Only the tests requiring minimal setup effort are included below.
This means that the environment used to run these tests contains the
barely minimal information included in an environment (i.e. only the
data specified by `trac.db_default.get_data`.).

Once the tests are started all built-in components (except
trac.versioncontrol.* ) as well as widget system and extensions
are loaded. Besides the following values are (auto-magically)
made available in the global namespace (i.e. provided that
the test name be written like `|widget_name: Descriptive message`):

  - __tester__  An instance of `unittest.TestCase` representing the
                test case for the statement under test. Useful
                when specific assertions (e.g. `assertEquals`)
                are needed.
  - req         A dummy request object setup for anonymous access.
  - auth_req    A dummy request object setup like if user `murphy` was
                accessing the site.
  - env         the Trac environment used as a stub for testing purposes.
                This object is an instance of
                `bhdashboard.tests.EnvironmentStub`.
  - ticket_data A set of tickets used for testing purposes.
"""

#------------------------------------------------------
#    Test artifacts
#------------------------------------------------------

import sys

from bhdashboard.tests import trac_version, trac_tags


def test_suite():
    from doctest import NORMALIZE_WHITESPACE, ELLIPSIS, REPORT_UDIFF
    from dutest import MultiTestLoader
    from unittest import defaultTestLoader

    from bhdashboard.tests import DocTestTracLoader, ticket_data

    magic_vars = dict(ticket_data=ticket_data)
    if trac_version < (0, 13):  # FIXME: Should it be (0, 12) ?
        kwargs = {'enable': ['trac.[a-uw-z]*', 'tracrpc.*', 'bhdashboard.*']}
    else:
        kwargs = {
            'enable': ['trac.*', 'tracrpc.*', 'bhdashboard.*'],
            'disable': ['trac.versioncontrol.*']
        }

    l = MultiTestLoader(
        [defaultTestLoader,
         DocTestTracLoader(extraglobs=magic_vars,
                           default_data=True,
                           optionflags=ELLIPSIS | REPORT_UDIFF |
                                       NORMALIZE_WHITESPACE,
                           **kwargs)
        ])

    return l.loadTestsFromModule(sys.modules[__name__])

#------------------------------------------------------
#    Helper functions
#------------------------------------------------------

from datetime import datetime, time, date
from itertools import izip
from pprint import pprint

from bhdashboard.tests import clear_perm_cache


def prepare_ticket_workflow(tcktrpc, ticket_data, auth_req):
    r"""Set ticket status considering the actions defined in standard
    ticket workflow. Needed for TracRpc>=1.0.6
    """
    from time import sleep

    TICKET_ACTIONS = {'accepted': 'accept', 'closed': 'resolve',
                      'assigned': 'reassign'}
    sleep(1)
    for idx, (_, __, td) in enumerate(ticket_data):
        action = TICKET_ACTIONS.get(td.get('status'))
        if action is not None:
            aux_attrs = {'action': action}
            aux_attrs.update(td)
            tcktrpc.update(auth_req, idx + 1, "", aux_attrs)
    sleep(1)
    for idx, (_, __, td) in enumerate(ticket_data):
        tcktrpc.update(auth_req, idx + 1, "", td)

from bhdashboard.web_ui import DashboardModule

__test__ = {
    'Initialization: Report widgets' : r"""
      """,
    'Rendering templates' : r"""
      >>> dbm = DashboardModule(env)
      >>> from trac.mimeview.api import Context
      >>> context = Context.from_request(auth_req)

      #FIXME: This won't work. Missing schema

      >>> pprint(dbm.expand_widget_data(context))
      [{'content': <genshi.core.Stream object at ...>,
      'title': <Element "a">}]
      """,
}

########NEW FILE########
__FILENAME__ = timeline
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest

from bhdashboard.widgets.timeline import TicketFieldTimelineFilter
from trac.test import EnvironmentStub, Mock
from trac.ticket import Ticket


class TicketFieldTimelineFilterTests(unittest.TestCase):
    def setUp(self):
        self.env = EnvironmentStub()
        t1 = self._insert_and_load_ticket("foo")
        self.filter = TicketFieldTimelineFilter(self.env)
        self.context = Mock(resource=t1.resource)

    def tearDown(self):
        self.env.reset_db()

    def test_returns_none_for_invalid_ticket_id(self):
        event = ['ticket', None, None, ['88']]

        result = self.filter.filter_event(self.context, None, event, None)
        self.assertIsNone(result)

    def test_long_resource_id(self):
        """Test resource with long id (#547)"""
        resource = self.context.resource
        resource.id = long(resource.id)
        event = ['ticket', None, None, [resource]]

        result = self.filter.filter_event(self.context, None, event, None)
        self.assertEqual(result, event)

    def _insert_and_load_ticket(self, summary, **kw):
        ticket = Ticket(self.env)
        ticket["summary"] = summary
        for k, v in kw.items():
            ticket[k] = v
        return Ticket(self.env, ticket.insert())


def suite():
    return unittest.makeSuite(TicketFieldTimelineFilterTests)


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = translation
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Translation functions and classes.
"""

from trac.util.translation import domain_functions

#------------------------------------------------------
#    Internationalization
#------------------------------------------------------

_, ngettext, tag_, tagn_, gettext, N_, add_domain = \
   domain_functions('bhdashboard', ('_', 'ngettext', 'tag_', 'tagn_',
                                'gettext', 'N_', 'add_domain'))

########NEW FILE########
__FILENAME__ = widgets
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widget helpers functions and classes.
"""
import inspect

from trac.core import Component, implements
from trac.util.text import to_unicode

from bhdashboard.api import DashboardSystem, IWidgetProvider, InvalidIdentifier

#------------------------------------------------------
#    Widget helpers
#------------------------------------------------------

class WidgetBase(Component):
    """Abstract base class for widgets"""

    implements(IWidgetProvider)
    abstract = True

    def get_widgets(self):
        """Yield the name of the widget based on the class name."""
        name = self.__class__.__name__
        if name.endswith('Widget'):
            name = name[:-6]
        yield name

    def get_widget_description(self, name):
        """Return the subclass's docstring."""
        return to_unicode(inspect.getdoc(self.__class__))

    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        raise NotImplementedError

    def render_widget(self, context, name, options):
        """Render widget considering given options."""
        raise NotImplementedError

    # Helper methods
    def bind_params(self, name, options, *params):
        return DashboardSystem(self.env).bind_params(options, 
                self.get_widget_params(name), *params)

def check_widget_name(f):
    """Decorator used to wrap methods of widget providers so as to ensure
    widget names will match those listed by `get_widgets` method.
    """
    def widget_name_checker(self, name, *args, **kwargs):
        names = set(self.get_widgets())
        if name not in names: 
            raise InvalidIdentifier('Widget name MUST match any of ' + 
                        ', '.join(names), 
                    title='Invalid widget identifier')
        return f(self, name, *args, **kwargs)
    return widget_name_checker

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Implementing dashboard user interface.
"""

__metaclass__ = type

import copy
import pkg_resources
import re
from uuid import uuid4

from genshi.builder import tag
from genshi.core import Stream
from trac.core import Component, implements
from trac.config import Option, IntOption
from trac.mimeview.api import Context
from trac.ticket.query import QueryModule
from trac.ticket.report import ReportModule
from trac.util.compat import groupby
from trac.web.api import IRequestHandler, IRequestFilter
from trac.web.chrome import add_ctxtnav, add_stylesheet, Chrome, \
                            INavigationContributor, ITemplateProvider

from bhdashboard.api import DashboardSystem, InvalidIdentifier
from bhdashboard import _json
from bhdashboard.util.translation import _, add_domain
from multiproduct.env import ProductEnvironment


class DashboardModule(Component):
    """Web frontend for dashboard infrastructure.
    """
    implements(IRequestHandler, IRequestFilter, INavigationContributor,
               ITemplateProvider)

    mainnav_label = Option('mainnav', 'tickets.label', 'Tickets',
                           """Dashboard label in mainnav""",
                           doc_domain='bhdashboard')
    default_widget_height = IntOption('widgets', 'default_height', 320,
                                      """Default widget height in pixels""", 
                                      doc_domain='bhdashboard')

    def __init__(self, *args, **kwargs):
        locale_dir = pkg_resources.resource_filename(__name__, 'locale')
        add_domain(self.env.path, locale_dir)
        super(DashboardModule, self).__init__(*args, **kwargs)

    # IRequestFilter methods

    def pre_process_request(self, req, handler):
        """Always returns the request handler unchanged.
        """
        return handler

    def post_process_request(self, req, template, data, content_type):
        """Inject dashboard helpers in data.
        """
        if data is not None:
            data['bhdb'] = DashboardChrome(self.env)
            if isinstance(req.perm.env, ProductEnvironment) \
                    and not 'resourcepath_template' in data \
                    and 'product_list' in data:
                data['resourcepath_template'] = 'bh_path_general.html'
        for item in req.chrome['nav'].get('mainnav', []):
            self.log.debug('%s' % (item,))
            if item['name'] == 'tickets':
                item['label'] = tag.a(_(self.mainnav_label),
                                      href=req.href.dashboard())
                if item['active'] and \
                        not ReportModule(self.env).match_request(req):
                    add_ctxtnav(req, _('Reports'),
                                href=req.href.report())
                break
        return template, data, content_type

    # IRequestHandler methods
    def match_request(self, req):
        """Match dashboard prefix"""
        return bool(re.match(r'^/dashboard(/.)?', req.path_info))

    def process_request(self, req):
        req.perm.require('PRODUCT_VIEW')
        # Initially this will render static widgets. With time it will be
        # more and more dynamic and flexible.
        if self.env[QueryModule] is not None:
            add_ctxtnav(req, _('Custom Query'), req.href.query())
        if self.env[ReportModule] is not None:
            add_ctxtnav(req, _('Reports'), req.href.report())
        context = Context.from_request(req)
        template, layout_data = self.expand_layout_data(context,
            'bootstrap_grid',
            self.DASHBOARD_SCHEMA if isinstance(self.env, ProductEnvironment)
            else self.DASHBOARD_GLOBAL_SCHEMA
        )
        widgets = self.expand_widget_data(context, layout_data)
        return template, {
            'context': Context.from_request(req),
            'layout': layout_data,
            'widgets': widgets,
            'title': _(self.mainnav_label),
            'default': {'height': self.default_widget_height or None}
        }, None

    # INavigationContributor methods
    def get_active_navigation_item(self, req):
        """Highlight dashboard mainnav item.
        """
        return 'tickets'

    def get_navigation_items(self, req):
        """Skip silently
        """
        return None

    # ITemplateProvider methods
    def get_htdocs_dirs(self):
        """List `htdocs` dirs for dashboard and widgets.
        """
        resource_filename = pkg_resources.resource_filename
        return [('dashboard', resource_filename('bhdashboard', 'htdocs')),
                #('widgets', resource_filename('bhdashboard.widgets', 'htdocs'))
                ('layouts', resource_filename('bhdashboard.layouts', 'htdocs'))]

    def get_templates_dirs(self):
        """List `templates` folders for dashboard and widgets.
        """
        resource_filename = pkg_resources.resource_filename
        return [resource_filename('bhdashboard.layouts', 'templates'),
                resource_filename('bhdashboard', 'templates'),
                resource_filename('bhdashboard.widgets', 'templates')]

    # Temp vars
    DASHBOARD_GLOBAL_SCHEMA = DASHBOARD_SCHEMA = {
            'div': [
                    {
                        '_class': 'row',
                        'div': [
                                {
                                    '_class': 'span8',
                                    'widgets': ['my tickets', 'active tickets',
                                                'products', 'versions',
                                                'milestones', 'components']
                                },
                                {
                                    '_class': 'span4',
                                    'widgets': ['activity']
                                }
                            ]
                    }
                ],
            'widgets': {
                    'components': {
                            'args': [
                                'TicketFieldValues',
                                None,
                                {'args': {
                                    'field': 'component',
                                    'title': 'Components',
                                    'verbose': True}}]
                        },
                    'milestones': {
                            'args': [
                                'TicketFieldValues',
                                None,
                                {'args': {
                                    'field': 'milestone',
                                    'title': 'Milestones',
                                    'verbose': True}}]
                        },
                    'versions': {
                            'args': [
                                'TicketFieldValues',
                                None,
                                {'args' : {
                                    'field' : 'version',
                                    'title' : 'Versions',
                                    'verbose' : True}}]
                        },
                    'active tickets': {
                            'args': [
                                'TicketQuery',
                                None,
                                {'args': {
                                    'max' : 10,
                                    'query': 'status=!closed&group=milestone'
                                        '&col=id&col=summary&col=owner'
                                        '&col=status&col=priority&'
                                        'order=priority',
                                    'title': _('Active Tickets')}}],
                            'altlinks': False
                        },
                    'my tickets': {
                            'args': [
                                'TicketQuery',
                                None,
                                {'args': {
                                 'max': 10,
                                 'query': 'status=!closed&group=milestone'
                                          '&col=id&col=summary&col=owner'
                                          '&col=status&col=priority&'
                                          'order=priority&'
                                          'owner=$USER',
                                    'title': _('My Tickets')}
                                }],
                            'altlinks': False
                        },
                    'activity': {
                            'args': ['Timeline', None, {'args': {}}]
                        },
                    'products': {
                            'args': ['Product', None, {'args': {'max': 3,
                                                                'cols': 2}}]
                        },
               }
        }

    # global dashboard queries: add milestone column, group by product
    DASHBOARD_GLOBAL_SCHEMA['widgets']['active tickets']['args'][2]['args']['query'] = (
        'status=!closed&group=product&col=id&col=summary&col=owner&col=status&'
        'col=priority&order=priority&col=milestone'
    )
    DASHBOARD_GLOBAL_SCHEMA['widgets']['my tickets']['args'][2]['args']['query'] = (
        'status=!closed&group=product&col=id&col=summary&col=owner&col=status&'
        'col=priority&order=priority&col=milestone&owner=$USER&'
    )
    for widget in ('milestones', 'versions', 'components'):
        DASHBOARD_GLOBAL_SCHEMA['div'][0]['div'][0]['widgets'].remove(widget)

    # Public API
    def expand_layout_data(self, context, layout_name, schema, embed=False):
        """Determine the template needed to render a specific layout
        and the data needed to place the widgets at expected
        location.
        """
        layout = DashboardSystem(self.env).resolve_layout(layout_name)

        template = layout.expand_layout(layout_name, context, {
            'schema': schema,
            'embed': embed
        })['template']
        return template, schema

    def _render_widget(self, wp, name, ctx, options):
        """Render widget without failing.
        """
        if wp is None:
            data = {'msglabel': _('Warning'),
                    'msgbody': _('Unknown widget %(name)s', name=name)}
            return 'widget_alert.html', {'title': '', 'data': data}, ctx

        try:
            return wp.render_widget(name, ctx, options)
        except Exception, exc:
            log_entry = str(uuid4())
            exccls = exc.__class__
            self.log.exception(
                "- %s - Error rendering widget %s with options %s",
                log_entry, name, options)
            data = {
                'msgtype': 'error',
                'msglabel': 'Error',
                'msgbody': _('Exception raised while rendering widget. '
                             'Contact your administrator for further details.'),
                'msgdetails': [
                    ('Widget name', name),
                    ('Exception type', tag.code(exccls.__name__)),
                    ('Log entry ID', log_entry),
                ],
            }
            return 'widget_alert.html', {
                'title': _('Widget error'),
                'data': data
            }, ctx

    def expand_widget_data(self, context, schema):
        """Expand raw widget data and format it for use in template
        """
        # TODO: Implement dynamic dashboard specification
        widgets_spec = schema.get('widgets', {})
        widgets_index = dict([wnm, wp]
            for wp in DashboardSystem(self.env).widget_providers
            for wnm in wp.get_widgets()
        )
        self.log.debug("Bloodhound: Widget index %s" % (widgets_index,))
        for w in widgets_spec.itervalues():
            w['c'] = widgets_index.get(w['args'][0])
            w['args'][1] = context
        self.log.debug("Bloodhound: Widget specs %s" % (widgets_spec,))
        chrome = Chrome(self.env)
        render = chrome.render_template
        data_strm = ((k, w, self._render_widget(w['c'], *w['args']))
                     for k, w in widgets_spec.iteritems())
        return dict([k, {'title': data['title'],
                         'content': render(wctx.req, template, data['data'],
                                           fragment=True),
                         'ctxtnav': w.get('ctxtnav', True) and
                                    data.get('ctxtnav') or None,
                         'altlinks': w.get('altlinks', True) and
                                     data.get('altlinks') or None,
                         'visible': w['c'] is not None or
                                    not w.get('hide_disabled', False)}
                     ] for k, w, (template, data, wctx) in data_strm)

    def alert_disabled(self):
        return tag.div(tag.span('Error', class_='label label-important'),
                       ' Could not load dashboard. Is ',
                       tag.code('bhdashboard.web_ui.DashboardModule'),
                       ' component disabled ?',
                       class_='alert alert-error')

#------------------------------------------------------
#    Dashboard Helpers to be used in templates
#------------------------------------------------------

XMLNS_DASHBOARD_UI = 'http://issues.apache.org/bloodhound/wiki/Ui/Dashboard'


class DashboardChrome:
    """Helper functions providing access to dashboard infrastructure
    in Genshi templates. Useful to reuse layouts and widgets across
    website.
    """
    def __init__(self, env):
        self.env = env

    def embed_layout(self, context, layout, **kwargs):
        """Render layout and widgets

        :param context: Rendering context
        :param layout: Identifier of target layout
        :param schema: Data describing widget positioning
        :param widgets: Widgets definition
        """
        dbmod = DashboardModule(self.env)
        schema = kwargs.get('schema', {})
        if isinstance(schema, basestring):
            schema = _json.loads(schema)
        widgets = kwargs.get('widgets')
        if widgets is not None:
            # TODO: Use this one once widgets markup parser will be ready
            #widgets = parse_widgets_markup(widgets)
            if isinstance(widgets, basestring):
                widgets = _json.loads(widgets)
        else:
            widgets = {}
        schema['widgets'] = widgets
        template, layout_data = dbmod.expand_layout_data(context, layout,
                                                         schema, True)
        widgets = dbmod.expand_widget_data(context, layout_data)
        return Chrome(self.env).render_template(
            context.req, template,
            dict(context=context, layout=layout_data, widgets=widgets, title='',
                 default={'height': dbmod.default_widget_height or None}),
            fragment=True)

    def expand_widget(self, context, widget):
        """Render single widget

        :param context: Rendering context
        :param widget: Widget definition
        """
        dbmod = DashboardModule(self.env)
        options = widget['args'][2]
        argsdef = options.get('args')
        if isinstance(argsdef, basestring):
            options['args'] = _json.loads(argsdef)
        elif isinstance(argsdef, Stream):
            options['args'] = parse_args_tag(argsdef)
        return dbmod.expand_widget_data(context, {'widgets': {0: widget}})[0]

#------------------------------------------------------
#    Stream processors
#------------------------------------------------------


def parse_args_tag(stream):
    """Parse Genshi Markup for widget arguments
    """
    args = {}
    inside = False
    argnm = ''
    argvalue = ''
    for kind, data, _ in stream:
        if kind == Stream.START:
            qname, attrs = data
            if qname.namespace == XMLNS_DASHBOARD_UI \
                    and qname.localname == 'arg':
                if inside:
                    raise RuntimeError('Nested bh:arg tag')
                else:
                    argnm = attrs.get('name')
                    argvalue = ''
                    inside = True
        elif kind == Stream.TEXT:
            argvalue += data
        elif kind == Stream.END:
            if qname.namespace == XMLNS_DASHBOARD_UI \
                    and qname.localname == 'arg':
                args[argnm] = argvalue
                inside = False
    return args

########NEW FILE########
__FILENAME__ = containers
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widgets acting as containers.
"""

from genshi.builder import tag
from trac.core import implements, TracError

from bhdashboard.api import DashboardSystem, InvalidWidgetArgument, JsonField
from bhdashboard.util import dummy_request, merge_links, minmax, \
                              pretty_wrapper, trac_version, trac_tags
from bhdashboard.util.widgets import WidgetBase, check_widget_name
from bhdashboard.web_ui import DashboardModule

class ContainerWidget(WidgetBase):
    """Embed widgets positioned according to the rules defined by a layout.
    """
    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        return {
                'layout' : {
                        'desc' : """Name of layout used to arrange widgets""",
                        'required' : True,
                    },
                'schema' : {
                        'desc' : """Widgets and position (in JSON)""",
                        'required' : True,
                        'type' : JsonField()
                    },
                'show_captions' : {
                        'desc' : """Show widget titles""",
                        'default' : False,
                    },
                'title' : {
                        'desc' : """User-defined title""",
                    },
            }
    get_widget_params = pretty_wrapper(get_widget_params, check_widget_name)

    def render_widget(self, name, context, options):
        """Count ocurrences of values assigned to given ticket field.
        """
        dbsys = DashboardSystem(self.env)
        params = ('layout', 'schema', 'show_captions', 'title')
        layout, schema, show_captions, title = \
                self.bind_params(name, options, *params)
        lp = dbsys.resolve_layout(layout)
        dbmod = DashboardModule(self.env)
        layout_data = lp.expand_layout(layout, context,
                { 'schema' : schema, 'embed' : True })
        widgets = dbmod.expand_widget_data(context, schema)

        return layout_data['template'], \
                {
                    'title' : title,
                    'data' : dict(
                            context=context,
                            layout=schema,
                            widgets=widgets,
                            title='',
                            default={
                                    'height' : dbmod.default_widget_height or None
                                }
                        ),
                }, \
                context

    render_widget = pretty_wrapper(render_widget, check_widget_name)

########NEW FILE########
__FILENAME__ = product
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widgets displaying product information (multiproduct).
"""

import itertools

from genshi.builder import tag

from trac.resource import Neighborhood
from trac.ticket.model import Milestone, Component, Version
from trac.ticket.query import Query

from bhdashboard.util import pretty_wrapper
from bhdashboard.util.widgets import WidgetBase, check_widget_name
from bhdashboard.util.translation import _

from multiproduct.env import Product, ProductEnvironment


__metaclass__ = type


class ProductWidget(WidgetBase):
    """Display products available to the user.
    """

    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        return {
            'max': {'desc': """Limit the number of products displayed""",
                    'type': int},
            'cols': {'desc': """Number of columns""",
                     'type': int}
        }

    get_widget_params = pretty_wrapper(get_widget_params, check_widget_name)

    COMMON_QUERY = 'order=priority&status=!closed&col=id&col=summary' \
                   '&col=owner&col=type&col=status&col=priority&col=product'

    def _get_product_info(self, product, href, resource, max_):
        penv = ProductEnvironment(self.env, product.prefix)
        results = []

        # some queries return a list/tuple, some a generator,
        # hence count() to get the result length
        def count(iter_):
            try:
                return len(iter_)
            except TypeError:
                return sum(1 for _ in iter_)

        query = resource['type'].select(penv)
        for q in itertools.islice(query, max_):
            q.url = href(resource['name'], q.name) \
                if resource.get('hrefurl') \
                else Query.from_string(penv,
                    '%s=%s&%s&col=%s' % (resource['name'], q.name,
                                         self.COMMON_QUERY, resource['name'])
            ).get_href(href)
            q.ticket_count = penv.db_query("""
                SELECT COUNT(*) FROM ticket WHERE ticket.%s='%s'
                AND ticket.status <> 'closed'
                """ % (resource['name'], q.name))[0][0]

            results.append(q)

        # add a '(No <milestone/component/version>)' entry if there are
        # tickets without an assigned resource in the product
        ticket_count = penv.db_query(
            """SELECT COUNT(*) FROM ticket WHERE %s=''
               AND status <> 'closed'""" % (resource['name'],))[0][0]
        if ticket_count != 0:
            q = resource['type'](penv)
            q.name = '(No %s)' % (resource['name'],)
            q.url = Query.from_string(penv,
               'status=!closed&col=id&col=summary&col=owner'
               '&col=status&col=priority&order=priority&%s='
               % (resource['name'],)
            ).get_href(href)
            q.ticket_count = ticket_count
            results.append(q)

        results.sort(key=lambda x: x.ticket_count, reverse=True)

        # add a link to the resource list if there are
        # more than max resources defined
        if count(query) > max_:
            q = resource['type'](penv)
            q.name = _('... more')
            q.ticket_count = None
            q.url = href(resource['name']) if resource.get('hrefurl') \
                else href.dashboard()
            results.append(q)

        return results

    def render_widget(self, name, context, options):
        """Gather product list and render data in compact view
        """
        data = {}
        req = context.req
        title = ''
        params = ('max', 'cols')
        max_, cols = self.bind_params(name, options, *params)

        if not isinstance(self.env, ProductEnvironment):
            for p in Product.select(self.env):
                if 'PRODUCT_VIEW' in req.perm(Neighborhood('product', p.prefix)):
                    penv = ProductEnvironment(self.env, p.prefix)
                    phref = ProductEnvironment.resolve_href(penv, self.env)
                    for resource in (
                        {'type': Milestone, 'name': 'milestone', 'hrefurl': True},
                        {'type': Component, 'name': 'component'},
                        {'type': Version, 'name': 'version'},
                    ):
                        setattr(p, resource['name'] + 's',
                                self._get_product_info(p, phref, resource, max_))
                    p.owner_link = Query.from_string(self.env,
                        'status!=closed&col=id&col=summary&col=owner'
                        '&col=status&col=priority&order=priority'
                        '&group=product&owner=%s' % (p._data['owner'] or '', )
                    ).get_href(phref)
                    p.href = phref()
                    data.setdefault('product_list', []).append(p)
            title = _('Products')

        data['colseq'] = itertools.cycle(xrange(cols - 1, -1, -1)) if cols \
            else itertools.repeat(1)

        return 'widget_product.html', {
            'title': title,
            'data': data,
            'ctxtnav': [tag.a(_('More'), href=req.href('products'))],
        }, context

    render_widget = pretty_wrapper(render_widget, check_widget_name)

########NEW FILE########
__FILENAME__ = query
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widgets displaying report data.
"""

from cgi import parse_qs
from datetime import datetime, date, time
from itertools import count, imap, islice

from genshi.builder import tag
from trac.core import implements, TracError
from trac.mimeview.api import Context
from trac.resource import Resource, ResourceNotFound
from trac.ticket.query import Query, QueryModule
from trac.web.api import RequestDone

from bhdashboard.util import dummy_request, merge_links, \
                              pretty_wrapper, trac_version, \
                              trac_tags
from bhdashboard.util.widgets import WidgetBase, InvalidIdentifier, \
                                      check_widget_name
from bhdashboard.util.translation import _

from multiproduct.env import ProductEnvironment

class TicketQueryWidget(WidgetBase):
    """Display tickets matching a TracQuery using a grid
    """
    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        return {
                'query' : {
                        'desc' : """Query string""",
                        'required' : True,
                    },
                'max' : {
                        'default' : 0,
                        'desc' : """Limit the number of results displayed""",
                        'type' : int,
                },
                'page' : {
                        'desc' : """Page number""",
                        'type' : int,
                },
                'title' : {
                        'desc' : """Widget title""",
                },
            }
    get_widget_params = pretty_wrapper(get_widget_params, check_widget_name)

    def render_widget(self, name, context, options):
        """Execute custom query and render data using a grid
        """
        data = None
        req = context.req
        try:
            params = ('query', 'max', 'page', 'title')
            qstr, maxrows, page, title = self.bind_params(name, options, *params)

            fakereq = dummy_request(self.env, req.authname)
            fakereq.args = args = parse_qs(qstr)
            fakereq.arg_list = []
            for k,v in args.items():
                # Patch for 0.13
                fakereq.arg_list.extend((k, _v) for _v in v)
                try:
                    if len(v) == 1:
                        args[k] = v[0]
                except TypeError:
                    pass
            more_link_href = req.href('query', args)
            args.update({'page' : page, 'max': maxrows})

            qrymdl = self.env[QueryModule]
            if qrymdl is None :
                raise TracError('Query module not available (disabled?)')

            data = qrymdl.process_request(fakereq, self.env)[1]
        except TracError, exc:
            if data is not None:
                exc.title = data.get('title', 'TracQuery')
            raise
        else:
            qryctx = Context.from_request(fakereq)
            query = data['query']
            idxs = count()
            headers = [dict(title=h['label'], col=h['name'], hidden=False,
                            asc=h['name'] == query.order and not query.desc) \
                                for h in data['headers']]
            data.update(
                dict(header_groups=[headers],
                    numrows=len(data['tickets']),
                    row_groups=[(group_value,
                            [{
                                '__color__' : t['priority_value'],
                                '__idx__' : idxs.next(),
                                'cell_groups' : [[
                                        {
                                            'header' : h,
                                            'index' : hidx,
                                            'value' : t[h['col']]
                                        } \
                                    for hidx, h in enumerate(headers)]],
                                'id' : t['id'],
                                'resource' : Resource('ticket', t['id']),
                                'href': t['href']
                            } for t in tickets]) \
                                for group_value, tickets in data['groups'] ]))
            return 'widget_grid.html', \
                    {
                        'title' : title or _('Custom Query'),
                        'data' : data,
                        'ctxtnav' : [
                                tag.a(_('More'),
                                    href=more_link_href)],
                        'altlinks' : fakereq.chrome.get('links', {}).get('alternate')
                    }, \
                    qryctx

    render_widget = pretty_wrapper(render_widget, check_widget_name)

#--------------------------------------
# Query functions and methods
#--------------------------------------

def exec_query(env, req, qstr='status!=closed'):
    """ Perform a ticket query, returning a list of ticket ID's.
    """
    return Query.from_string(env, qstr).execute(req)

########NEW FILE########
__FILENAME__ = report
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widgets displaying report data.
"""

from datetime import datetime, date, time
from itertools import imap, islice

from genshi.builder import tag
from trac.core import implements, TracError
from trac.mimeview.api import Context
from trac.resource import ResourceNotFound
from trac.ticket.report import ReportModule
from trac.web.api import RequestDone

from bhdashboard.util import dummy_request, merge_links, \
                              pretty_wrapper, trac_version, \
                              trac_tags
from bhdashboard.util.widgets import WidgetBase, InvalidIdentifier, \
                               check_widget_name
from bhdashboard.util.translation import _

class TicketReportWidget(WidgetBase):
    """Display tickets in saved report using a grid
    """
    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        return {
                'id' : {
                        'desc' : """Report number""",
                        'required' : True,
                        'type' : int,
                    },
                'page' : {
                        'default' : 1,
                        'desc' : """Retrieve results in given page.""",
                        'type' : int,
                },
                'user' : {
                        'desc' : """Render the report for a given user.""",
                },
            }
    get_widget_params = pretty_wrapper(get_widget_params, check_widget_name)

    def render_widget(self, name, context, options):
        """Execute stored report and render data using a grid
        """
        data = None
        req = context.req
        try:
            params = ('id', 'page', 'user')
            rptid, page, user = self.bind_params(name, options, *params)
            user = user or req.authname

            fakereq = dummy_request(self.env, req.authname)
            fakereq.args = {'page' : page, 'user' : user}
            del fakereq.redirect     # raise RequestDone as usual

            rptmdl = self.env[ReportModule]
            if rptmdl is None :
                raise TracError('Report module not available (disabled?)')
            if trac_version < trac_tags[0]:
                args = fakereq, self.env.get_db_cnx(), rptid
            else:
                args = fakereq, rptid
            data = rptmdl._render_view(*args)[1]
        except ResourceNotFound, exc:
            raise InvalidIdentifier(unicode(exc))
        except RequestDone:
            raise TracError('Cannot execute report. Redirection needed')
        except TracError, exc:
            if data is not None:
                exc.title = data.get('title', 'TracReports')
            raise
        else:
            title = data.get('title', '%s {%s}' % (_('Report'), rptid))
            rptctx = Context.from_request(fakereq, 'report', rptid)
            return 'widget_grid.html', \
                    {
                        'title' : title,
                        'data' : data,
                        'ctxtnav' : [
                            tag.a(_('More'), href=req.href('report', rptid)),
                            ('REPORT_MODIFY' in req.perm(rptctx.resource)) and \
                                tag.a(_('Edit'), href=req.href('report', rptid, action='edit')) or None,
                            ],
                        'altlinks' : fakereq.chrome.get('links', {}).get('alternate')
                    }, \
                    rptctx

    render_widget = pretty_wrapper(render_widget, check_widget_name)

########NEW FILE########
__FILENAME__ = ticket
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widgets displaying ticket data.
"""

from itertools import imap, islice
from urllib import urlencode

from genshi.builder import tag
from genshi.core import Markup
from trac.core import implements, TracError
from trac.ticket.api import TicketSystem
from trac.ticket.query import Query
from trac.ticket.roadmap import apply_ticket_permissions, get_ticket_stats, \
                            ITicketGroupStatsProvider, RoadmapModule
from trac.util.text import unicode_urlencode
from trac.web.chrome import add_stylesheet

from bhdashboard.api import DateField, EnumField, InvalidWidgetArgument, \
                            ListField
from bhdashboard.widgets.query import exec_query
from bhdashboard.util import dummy_request, merge_links, minmax, \
                            pretty_wrapper, resolve_ep_class, \
                            trac_version, trac_tags
from bhdashboard.util.widgets import WidgetBase, check_widget_name
from bhdashboard.util.translation import _

from multiproduct.env import Product, ProductEnvironment

class TicketFieldValuesWidget(WidgetBase):
    """Display a tag cloud representing frequency of values assigned to
    ticket fields.
    """
    DASH_ITEM_HREF_MAP = {'milestone': ('milestone',),
                         }

    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        return {
                'field' : {
                        'desc' : """Target ticket field. """
                                """Required if no group in `query`.""",
                    },
                'query' : {
                        'desc' : """TracQuery used to filter target tickets.""",
                    },
                'title' : {
                        'desc' : """Widget title""",
                    },
                'verbose' : {
                        'desc' : """Show frequency next to each value""",
                        'default' : False,
                        'type' : bool,
                    },
                'threshold' : {
                        'desc' : """Filter items having smaller frequency""",
                        'type' : int,
                    },
                'max' : {
                        'default' : 0,
                        'desc' : """Limit the number of items displayed""",
                        'type' : int
                    },
                'view' : {
                        'desc' : """Display mode. Should be one of the following

                            - `list` : Unordered value list (default)
                            - `cloud` : Similar to tag cloud
                            """,
                        'default' : 'list',
                        'type' : EnumField('list', 'cloud', 'table', 'compact'),
                    },
            }
    get_widget_params = pretty_wrapper(get_widget_params, check_widget_name)

    def render_widget(self, name, context, options):
        """Count ocurrences of values assigned to given ticket field.
        """
        req = context.req
        params = ('field', 'query', 'verbose', 'threshold', 'max', 'title',
                  'view')
        fieldnm, query, verbose, threshold, maxitems, title, view = \
                self.bind_params(name, options, *params)

        field_maps = {'type': {'admin_url': 'type',
                               'title': _('Types'),
                               },
                      'status': {'admin_url': None,
                                 'title': _('Statuses'),
                                 },
                      'priority': {'admin_url': 'priority',
                                   'title': _('Priorities'),
                                   },
                      'milestone': {'admin_url': 'milestones',
                                    'title': _('Milestones'),
                                    },
                      'component': {'admin_url': 'components',
                                    'title': _('Components'),
                                    },
                      'version': {'admin_url': 'versions',
                                  'title': _('Versions'),
                                  },
                      'severity': {'admin_url': 'severity',
                                   'title': _('Severities'),
                                   },
                      'resolution': {'admin_url': 'resolution',
                                     'title': _('Resolutions'),
                                     },
                      }
        _field = []
        def check_field_name():
            if fieldnm is None:
                raise InvalidWidgetArgument('field', 'Missing ticket field')
            tsys = self.env[TicketSystem]
            if tsys is None:
                raise TracError(_('Error loading ticket system (disabled?)'))
            for field in tsys.get_ticket_fields():
                if field['name'] == fieldnm:
                    _field.append(field)
                    break
            else:
                if fieldnm in field_maps:
                    admin_suffix = field_maps.get(fieldnm)['admin_url']
                    if 'TICKET_ADMIN' in req.perm and admin_suffix is not None:
                        hint = _('You can add one or more '
                                 '<a href="%(url)s">here</a>.',
                                url=req.href.admin('ticket', admin_suffix))
                    else:
                        hint = _('Contact your administrator for further details')
                    return 'widget_alert.html', \
                            {
                                'title' : Markup(field_maps[fieldnm]['title']),
                                'data' : dict(msgtype='info',
                                    msglabel="Note",
                                    msgbody=Markup(_('''No values are
                                        defined for ticket field
                                        <em>%(field)s</em>. %(hint)s''',
                                        field=fieldnm, hint=hint))
                                    )
                            }, context
                else:
                    raise InvalidWidgetArgument('field',
                            'Unknown ticket field %s' % (fieldnm,))
            return None

        if query is None :
            data = check_field_name()
            if data is not None:
                return data
            field = _field[0]
            if field.get('custom'):
                sql = "SELECT COALESCE(value, ''), count(COALESCE(value, ''))" \
                        " FROM ticket_custom " \
                        " WHERE name='%(name)s' GROUP BY COALESCE(value, '')"
            else:
                sql = "SELECT COALESCE(%(name)s, ''), " \
                        "count(COALESCE(%(name)s, '')) FROM ticket " \
                        "GROUP BY COALESCE(%(name)s, '')"
            sql = sql % field
            # TODO : Implement threshold and max

            db_query = req.perm.env.db_query \
                if isinstance(req.perm.env, ProductEnvironment) \
                else req.perm.env.db_direct_query
            with db_query as db:
                cursor = db.cursor()
                cursor.execute(sql)
                items = cursor.fetchall()

            QUERY_COLS = ['id', 'summary', 'owner', 'type', 'status', 'priority']
            item_link= lambda item: req.href.query(col=QUERY_COLS + [fieldnm],
                                                    **{fieldnm:item[0]})
        else:
            query = Query.from_string(self.env, query, group=fieldnm)
            if query.group is None:
                data = check_field_name()
                if data is not None:
                    return data
                raise InvalidWidgetArgument('field',
                        'Invalid ticket field for ticket groups')

            fieldnm = query.group
            sql, v = query.get_sql()
            sql = "SELECT COALESCE(%(name)s, '') , count(COALESCE(%(name)s, ''))"\
                    "FROM (%(sql)s) AS foo GROUP BY COALESCE(%(name)s, '')" % \
                    { 'name' : fieldnm, 'sql' : sql }
            db = self.env.get_db_cnx()
            try :
                cursor = db.cursor()
                cursor.execute(sql, v)
                items = cursor.fetchall()
            finally:
                cursor.close()

            query_href = query.get_href(req.href)
            item_link= lambda item: query_href + \
                    '&' + unicode_urlencode([(fieldnm, item[0])])

        if fieldnm in self.DASH_ITEM_HREF_MAP:
            def dash_item_link(item):
                if item[0]:
                    args = self.DASH_ITEM_HREF_MAP[fieldnm] + (item[0],)
                    return req.href(*args)
                else:
                    return item_link(item)
        else:
            dash_item_link = item_link

        if title is None:
            heading = _(fieldnm.capitalize())
        else:
            heading = None

        return 'widget_cloud.html', \
                {
                    'title' : title,
                    'data' : dict(
                            bounds=minmax(items, lambda x: x[1]),
                            item_link=dash_item_link,
                            heading=heading,
                            items=items,
                            verbose=verbose,
                            view=view,
                        ),
                }, \
                context

    render_widget = pretty_wrapper(render_widget, check_widget_name)

class TicketGroupStatsWidget(WidgetBase):
    """Display progress bar illustrating statistics gathered on a group
    of tickets.
    """
    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        return {
                'query' : {
                        'default' : 'status!=closed',
                        'desc' : """Query string""",
                    },
                'stats_provider' : {
                        'desc' : """Name of the component implementing
        `ITicketGroupStatsProvider`, which is used to collect statistics
        on groups of tickets.""",
                        'default' : 'DefaultTicketGroupStatsProvider'
                    },
                'skin' : {
                        'desc' : """Look and feel of the progress bar""",
                        'type' : EnumField('info', 'success', 'warning',
                                'danger',
                                'info-stripped', 'success-stripped',
                                'warning-stripped', 'danger-stripped')
                    },
                'title' : {
                        'desc' : """Widget title""",
                    },
                'legend' : {
                        'desc' : """Text on top of the progress bar""",
                    },
                'desc' : {
                        'desc' : """Descriptive (wiki) text""",
                    },
                'view' : {
                        'desc' : """Display mode to render progress info""",
                        'type' : EnumField('compact', 'standard')
                    },
            }
    get_widget_params = pretty_wrapper(get_widget_params, check_widget_name)

    def render_widget(self, name, context, options):
        """Prepare ticket stats
        """
        req = context.req
        params = ('query', 'stats_provider', 'skin', 'title', 'legend', 'desc',
                'view')
        qstr, pnm, skin, title, legend, desc, view = \
                self.bind_params(name, options, *params)
        statsp = resolve_ep_class(ITicketGroupStatsProvider, self, pnm,
                                    default=RoadmapModule(self.env).stats_provider)
        if skin is not None :
            skin = (skin or '').split('-', 2)

        tickets = exec_query(self.env, req, qstr)
        tickets = apply_ticket_permissions(self.env, req, tickets)
        stat = get_ticket_stats(statsp, tickets)

        add_stylesheet(req, 'dashboard/css/bootstrap.css')
        add_stylesheet(req, 'dashboard/css/bootstrap-responsive.css')
        add_stylesheet(req, 'dashboard/css/roadmap.css')
        return 'widget_progress.html', \
                {
                    'title' : title,
                    'data' : dict(
                            desc=desc, legend=legend, bar_styles=skin,
                            stats=stat, view=view,
                        ),
                }, \
                context

    render_widget = pretty_wrapper(render_widget, check_widget_name)

########NEW FILE########
__FILENAME__ = timeline
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widgets displaying timeline data.
"""

from datetime import datetime, date, time, timedelta
from itertools import imap, islice
from types import MethodType

from genshi.builder import tag
from trac.core import Component, ExtensionPoint, implements, Interface, \
        TracError
from trac.config import IntOption
from trac.mimeview.api import RenderingContext
from trac.resource import Resource, resource_exists, ResourceNotFound
from trac.timeline.web_ui import TimelineModule
from trac.ticket.api import TicketSystem
from trac.ticket.model import Ticket
from trac.ticket.web_ui import TicketModule
from trac.util.datefmt import utc
from trac.web.chrome import add_stylesheet

from bhdashboard.api import DateField, EnumField, ListField
from bhdashboard.util import dummy_request, merge_links, pretty_wrapper, \
                             trac_version, trac_tags
from bhdashboard.util.widgets import WidgetBase, InvalidIdentifier, \
                              check_widget_name
from bhdashboard.util.translation import _, tag_

__metaclass__ = type


class ITimelineEventsFilter(Interface):
    """Filter timeline events displayed in a rendering context
    """
    def supported_providers():
        """List supported timeline providers. Filtering process will take
        place only for the events contributed by listed providers.
        Return `None` and all events contributed by all timeline providers
        will be processed.
        """
    def filter_event(context, provider, event, filters):
        """Decide whether a timeline event is relevant in a rendering context.

        :param context: rendering context, used to determine events scope
        :param provider: provider contributing event
        :param event: target event
        :param filters: active timeline filters
        :return: the event resulting from the filtering process or
                  `None` if it has to be removed from the event stream or
                  `NotImplemented` if the filter doesn't care about it.
        """


class TimelineWidget(WidgetBase):
    """Display activity feed.
    """
    default_count = IntOption('widget_activity', 'limit', 25,
        """Maximum number of items displayed by default""",
                              doc_domain='bhdashboard')

    event_filters = ExtensionPoint(ITimelineEventsFilter)

    _filters_map = None

    @property
    def filters_map(self):
        """Quick access to timeline events filters to be applied for a
        given timeline provider.
        """
        if self._filters_map is None:
            self._filters_map = {}
            for _filter in self.event_filters:
                providers = _filter.supported_providers()
                if providers is None:
                    providers = [None]
                for p in providers:
                    self._filters_map.setdefault(p, []).append(_filter)
        return self._filters_map

    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        return {
            'from': {
                'desc': """Display events before this date""",
                'type': DateField(),  # TODO: Custom datetime format
            },
            'daysback': {
                'desc': """Event time window""",
                'type': int,
            },
            'precision': {
                'desc': """Time precision""",
                'type': EnumField('second', 'minute', 'hour')
            },
            'doneby': {
                'desc': """Filter events related to user""",
            },
            'filters': {
                'desc': """Event filters""",
                'type': ListField()
            },
            'max': {
                'desc': """Limit the number of events displayed""",
                'type': int
            },
            'realm': {
                'desc': """Resource realm. Used to filter events""",
            },
            'id': {
                'desc': """Resource ID. Used to filter events""",
            },
        }
    get_widget_params = pretty_wrapper(get_widget_params, check_widget_name)

    def render_widget(self, name, context, options):
        """Gather timeline events and render data in compact view
        """
        data = None
        req = context.req
        try:
            timemdl = self.env[TimelineModule]
            admin_page = tag.a(_("administration page."),
                               title=_("Plugin Administration Page"),
                               href=req.href.admin('general/plugin'))
            if timemdl is None:
                return 'widget_alert.html', {
                    'title':  _("Activity"),
                    'data': {
                        'msglabel': _("Warning"),
                        'msgbody':
                            tag_("The TimelineWidget is disabled because the "
                                 "Timeline component is not available. "
                                  "Is the component disabled? "
                                  "You can enable from the %(page)s",
                                  page=admin_page),
                        'dismiss': False,
                    }
                }, context

            params = ('from', 'daysback', 'doneby', 'precision', 'filters',
                      'max', 'realm', 'id')
            start, days, user, precision, filters, count, realm, rid = \
                self.bind_params(name, options, *params)
            if context.resource.realm == 'ticket':
                if days is None:
                    # calculate a long enough time daysback
                    ticket = Ticket(self.env, context.resource.id)
                    ticket_age = datetime.now(utc) - ticket.time_created
                    days = ticket_age.days + 1
                if count is None:
                    # ignore short count for ticket feeds
                    count = 0
            if count is None:
                count = self.default_count

            fakereq = dummy_request(self.env, req.authname)
            fakereq.args = {
                'author': user or '',
                'daysback': days or '',
                'max': count,
                'precision': precision,
                'user': user
            }
            if filters:
                fakereq.args.update(dict((k, True) for k in filters))
            if start is not None:
                fakereq.args['from'] = start.strftime('%x %X')

            wcontext = context.child()
            if (realm, rid) != (None, None):
                # Override rendering context
                resource = Resource(realm, rid)
                if resource_exists(self.env, resource) or \
                        realm == rid == '':
                    wcontext = context.child(resource)
                    wcontext.req = req
                else:
                    self.log.warning("TimelineWidget: Resource %s not found",
                                     resource)
            # FIXME: Filter also if existence check is not conclusive ?
            if resource_exists(self.env, wcontext.resource):
                module = FilteredTimeline(self.env, wcontext)
                self.log.debug('Filtering timeline events for %s',
                               wcontext.resource)
            else:
                module = timemdl
            data = module.process_request(fakereq)[1]
        except TracError, exc:
            if data is not None:
                exc.title = data.get('title', _('Activity'))
            raise
        else:
            merge_links(srcreq=fakereq, dstreq=req,
                        exclude=["stylesheet", "alternate"])
            if 'context' in data:
                # Needed for abbreviated messages in widget events (#340)
                wcontext.set_hints(**(data['context']._hints or {}))
            data['context'] = wcontext
            return 'widget_timeline.html', {
                'title': _('Activity'),
                'data': data,
                'altlinks': fakereq.chrome.get('links', {}).get('alternate')
            }, context

    render_widget = pretty_wrapper(render_widget, check_widget_name)


class FilteredTimeline:
    """This is a class (not a component ;) aimed at overriding some parts of
    TimelineModule without patching it in order to inject code needed to filter
    timeline events according to rendering context. It acts as a wrapper on top
    of TimelineModule.
    """
    def __init__(self, env, context, keep_mismatched=False):
        """Initialization

        :param env: Environment object
        :param context: Rendering context
        """
        self.env = env
        self.context = context
        self.keep_mismatched = keep_mismatched

    # Access to TimelineModule's members

    process_request = TimelineModule.__dict__['process_request']
    _provider_failure = TimelineModule.__dict__['_provider_failure']
    _event_data = TimelineModule.__dict__['_event_data']
    _max_daysback = TimelineModule.max_daysback

    @property
    def max_daysback(self):
        return (-1 if self.context.resource.realm == 'ticket'
                else self._max_daysback)

    @property
    def event_providers(self):
        """Introduce wrappers around timeline event providers in order to
        filter event streams.
        """
        for p in TimelineModule(self.env).event_providers:
            yield TimelineFilterAdapter(p, self.context, self.keep_mismatched)

    def __getattr__(self, attrnm):
        """Forward attribute access request to TimelineModule
        """
        try:
            value = getattr(TimelineModule(self.env), attrnm)
            if isinstance(value, MethodType):
                raise AttributeError()
        except AttributeError:
            raise AttributeError("'%s' object has no attribute '%s'"
                                 % (self.__class__.__name__, attrnm))
        else:
            return value


class TimelineFilterAdapter:
    """Wrapper class used to filter timeline event streams transparently.
    Therefore it is compatible with `ITimelineEventProvider` interface
    and reuses the implementation provided by real provider.
    """
    def __init__(self, provider, context, keep_mismatched=False):
        """Initialize wrapper object by providing real timeline events provider.
        """
        self.provider = provider
        self.context = context
        self.keep_mismatched = keep_mismatched

    # ITimelineEventProvider methods

    def get_timeline_filters(self, req):
        gen = self.provider.get_timeline_filters(req)
        if self.context.resource.realm == 'ticket' and \
                isinstance(self.provider, TicketModule) and \
                'TICKET_VIEW' in req.perm:
            # ensure ticket_details appears once if this is a query on a ticket
            gen = list(gen)
            if not [g for g in gen if g[0] == 'ticket_details']:
                gen.append(('ticket_details', _("Ticket updates"), False))
        return gen

    #def render_timeline_event(self, context, field, event):

    def get_timeline_events(self, req, start, stop, filters):
        """Filter timeline events according to context.
        """
        filters_map = TimelineWidget(self.env).filters_map
        evfilters = filters_map.get(self.provider.__class__.__name__, []) + \
            filters_map.get(None, [])
        self.log.debug('Applying filters %s for %s against %s', evfilters,
                       self.context.resource, self.provider)
        if evfilters:
            for event in self.provider.get_timeline_events(
                    req, start, stop, filters):
                match = False
                for f in evfilters:
                    new_event = f.filter_event(self.context, self.provider,
                                               event, filters)
                    if new_event is None:
                        event = None
                        match = True
                        break
                    elif new_event is NotImplemented:
                        pass
                    else:
                        event = new_event
                        match = True
                if event is not None and (match or self.keep_mismatched):
                    yield event
        else:
            if self.keep_mismatched:
                for event in self.provider.get_timeline_events(
                        req, start, stop, filters):
                    yield event

    def __getattr__(self, attrnm):
        """Forward attribute access request to real provider
        """
        try:
            value = getattr(self.provider, attrnm)
        except AttributeError:
            raise AttributeError("'%s' object has no attribute '%s'"
                                 % (self.__class__.__name__, attrnm))
        else:
            return value


class TicketFieldTimelineFilter(Component):
    """A class filtering ticket events related to a given resource
    associated via ticket fields.
    """
    implements(ITimelineEventsFilter)

    @property
    def fields(self):
        """Available ticket fields
        """
        field_names = getattr(self, '_fields', None)
        if field_names is None:
            self._fields = set(f['name'] for f in
                               TicketSystem(self.env).get_ticket_fields())
        return self._fields

    # ITimelineEventsFilter methods

    def supported_providers(self):
        """This filter will work on ticket events. It also intercepts events
        even when multi-product ticket module is installed.
        """
        yield 'TicketModule'
        yield 'ProductTicketModule'

    def filter_event(self, context, provider, event, filters):
        """Decide whether the target of a ticket event has a particular custom
        field set to the context resource's identifier.
        """
        if context.resource is not None:
            field_name = context.resource.realm
            if field_name in self.fields.union(['ticket']):
                try:
                    ticket_ids = event[3][0]
                except:
                    self.log.exception('Unknown ticket event %s ... [SKIP]',
                                       event)
                    return None

                if not isinstance(ticket_ids, list):
                    ticket_ids = [ticket_ids]
                context._ticket_cache = ticket_cache = \
                    getattr(context, '_ticket_cache', None) or {}
                for t in ticket_ids:
                    if isinstance(t, Resource):
                        if event[0] != 'attachment':
                            t = t.id
                        else:
                            t = t.parent.id
                    try:
                        t = ticket_cache.get(t) or Ticket(self.env, t)
                    except ResourceNotFound:
                        return None
                    if field_name == 'ticket' and t.id == context.resource.id:
                        return event
                    if t[field_name] == context.resource.id:
                        return event
                    ticket_cache[t.id] = t
                else:
                    return None
        return NotImplemented

########NEW FILE########
__FILENAME__ = wiki
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

WikiMacros and WikiProcessors related to dashboard system.
"""

from ast import literal_eval

from genshi.builder import tag

from trac.web.chrome import Chrome
from trac.wiki.api import parse_args
from trac.wiki.macros import WikiMacroBase

from bhdashboard.web_ui import DashboardChrome, DashboardModule

GUIDE_NAME = 'Guide'
RENAME_MAP = {'TracGuide': GUIDE_NAME + '/Index',}

def new_name(name, force=False):
    if name.startswith('Trac'):
        return RENAME_MAP.get(name, GUIDE_NAME + '/' + name[4:])
    else:
        return name

class WidgetMacro(WikiMacroBase):
    """Embed Bloodhound widgets using WikiFormatting.
    """
    #: A gettext domain to translate the macro description
    _domain = None

    #: A macro description
    _description = """Embed Bloodhound widgets using WikiFormatting."""

    def expand_macro(self, formatter, name, content):
        """Render widget contents by re-using wiki markup implementation
        """
        if self.env[DashboardModule] is None:
            return DashboardModule(self.env).alert_disabled()
        largs, kwargs = parse_args(content, strict=True)
        try:
            (widget_name ,) = largs
        except ValueError:
            template = 'widget_alert.html'
            data = {
                    'msgtype' : 'error',
                    'msglabel' : 'Error',
                    'msgbody' : tag('Expected ', tag.code(1),
                            ' positional argument (i.e. widget name), but got ',
                            tag.code(len(largs)), ' instead'),
                    'msgdetails' : [
                            ('Macro name', tag.code('WidgetMacro')),
                            ('Arguments', ', '.join(largs) if largs \
                                    else tag.span('None', class_='label')),
                        ],
                }
        else:
            widget_name = widget_name.strip()
            wopts = {} ; wargs = {}

            def parse_literal(value):
                try:
                    return literal_eval(value)
                except (SyntaxError, ValueError):
                    return value

            for argnm, value in kwargs.iteritems():
                if argnm.startswith('wo_'):
                    wopts[argnm[3:]] = value
                else :
                    wargs[argnm] = parse_literal(value)
            template = 'widget.html'
            data = {
                    'args' : wargs,
                    'bhdb' : DashboardChrome(self.env),
                    'id' : None,
                    'opts' : wopts,
                    'widget' : widget_name
                }
        return Chrome(self.env).render_template(
                formatter.req, template, data, fragment=True)

########NEW FILE########
__FILENAME__ = _json
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Provide a single namespace to access JSON functions.
"""

try :
    from json import *
except ImportError:
    from simplejson import *

########NEW FILE########
__FILENAME__ = api
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import copy
import os
import shutil

from genshi.builder import tag, Element
from genshi.core import escape, Markup, unescape

from pkg_resources import resource_filename
from trac.attachment import Attachment
from trac.config import Option, PathOption
from trac.core import Component, TracError, implements, Interface
from trac.db import Table, Column, DatabaseManager, Index
import trac.db_default
from trac.env import IEnvironmentSetupParticipant, Environment
from trac.perm import IPermissionRequestor, PermissionCache
from trac.resource import IExternalResourceConnector, IResourceChangeListener,\
                          IResourceManager, ResourceNotFound
from trac.ticket.api import ITicketFieldProvider, ITicketManipulator
from trac.util.text import to_unicode, unquote_label, unicode_unquote
from trac.web.chrome import ITemplateProvider, add_warning
from trac.web.main import FakePerm, FakeSession
from trac.wiki.admin import WikiAdmin
from trac.wiki.api import IWikiSyntaxProvider
from trac.wiki.parser import WikiParser

from multiproduct.dbcursor import GLOBAL_PRODUCT
from multiproduct.model import Product, ProductResourceMap, ProductSetting
from multiproduct.util import EmbeddedLinkFormatter, IDENTIFIER, \
                              using_mysql_backend, using_sqlite_backend
from multiproduct.util.translation import _, N_, add_domain

__all__ = ['MultiProductSystem', 'PRODUCT_SYNTAX_DELIMITER']

DB_VERSION = 5
DB_SYSTEM_KEY = 'bloodhound_multi_product_version'
PLUGIN_NAME = 'Bloodhound multi product'

class ISupportMultiProductEnvironment(Interface):
    """Extension point interface for components that are aware of multi
    product environment and its specifics.

    Component implementing this interface is handled in a special way in the
    following scenarios:

    * if implementing `IEnvironmentSetupParticipant` interface, the component
      will only be invoked once per global environment creation/upgrade. It is
      up to the component to install/update it's environment specifics (schema,
      possibly files, etc.) for all products. In contrast, components that don't
      implement `ISupportMultiProductEnvironment` interface will be, during
      install/update, invoked per product environment.
    """
    pass

class MultiProductSystem(Component):
    """Creates the database tables and template directories"""

    implements(IEnvironmentSetupParticipant, IExternalResourceConnector,
               IPermissionRequestor, IResourceChangeListener, IResourceManager,
               ISupportMultiProductEnvironment, ITemplateProvider,
               ITicketFieldProvider, IWikiSyntaxProvider, ITicketManipulator)

    default_product_prefix = Option(
        'multiproduct',
        'default_product_prefix',
        default='@',
        doc="""Prefix used for default product when migrating single-product
        installations to multi-product.""", doc_domain='multiproduct')

    default_product = Option('ticket', 'default_product', '',
        """Default product for newly created tickets.""")

    product_base_url = Option('multiproduct', 'product_base_url', '',
        """A pattern used to generate the base URL of product environments,
        e.g. the use cases listed in bh:wiki:/Proposals/BEP-0003#url-mapping .
        Both absolute as well as relative URLs are supported. The later
        will be resolved with respect to the base URL of the parent global
        environment. The pattern may contain references to $(envname)s,
        $(prefix)s and $(name)s placeholders representing the environment name,
        product prefix and product name respectively . If nothing is set the
        following will be used `products/$(prefix)s`

        Note the usage of `$(...)s` instead of `%(...)s` as the later form
        would be interpreted by the ConfigParser itself. """,
                              doc_domain='multiproduct')

    product_config_parent = PathOption('inherit', 'multiproduct', '',
        """The path to the configuration file containing the settings shared
        by sibling product environments. By default will inherit
        global environment configuration.
        """, doc_domain='multiproduct')

    SCHEMA = [mcls._get_schema()
              for mcls in (Product, ProductResourceMap)]

    # Tables which should be migrated (extended with 'product' column)
    MIGRATE_TABLES = ['component',
                      'milestone',
                      'version',
                      'enum',
                      'permission',
                      'wiki',
                      'report',
                      ]

    PRODUCT_POPULATE_TABLES = list(set(MIGRATE_TABLES) - set(['wiki']))

    def __init__(self, *args, **kwargs):
        import pkg_resources
        locale_dir = pkg_resources.resource_filename(__name__, 'locale')
        add_domain(self.env.path, locale_dir)
        super(MultiProductSystem, self).__init__(*args, **kwargs)

    def get_version(self):
        """Finds the current version of the bloodhound database schema"""
        rows = self.env.db_direct_query("""
            SELECT value FROM system WHERE name = %s
            """, (DB_SYSTEM_KEY,))
        return int(rows[0][0]) if rows else -1

    # IEnvironmentSetupParticipant methods
    def environment_created(self):
        """Insertion of any default data into the database."""
        self.log.debug("creating environment for %s plugin." % PLUGIN_NAME)

    def environment_needs_upgrade(self, db_dummy=None):
        """Detects if the installed db version matches the running system"""
        db_installed_version = self.get_version()

        if db_installed_version > DB_VERSION:
            raise TracError('''Current db version (%d) newer than supported by
            this version of the %s (%d).''' % (db_installed_version,
                                               PLUGIN_NAME,
                                               DB_VERSION))
        needs_upgrade = db_installed_version < DB_VERSION
        if not needs_upgrade:
            self.env.enable_multiproduct_schema(True)
        return needs_upgrade

    def _update_db_version(self, db, version):
        old_version = self.get_version()
        if old_version != -1:
            self.log.info("Updating multiproduct database schema from version %d"
                          " to %d" % (old_version, version))
            db("""UPDATE system SET value=%s
                      WHERE name=%s""", (version, DB_SYSTEM_KEY))
        else:
            self.log.info("Initial multiproduct database schema set to version %d" % version)
            db("""
                INSERT INTO system (name, value) VALUES ('%s','%s')
                """  % (DB_SYSTEM_KEY, version))
        return version


    _system_wiki_list = None
    @property
    def system_wiki_list(self):
        if MultiProductSystem._system_wiki_list is None:
            MultiProductSystem._system_wiki_list = self._get_system_wiki_list()
        return MultiProductSystem._system_wiki_list

    def _get_system_wiki_list(self):
        """Helper function that enumerates all 'system' wikis. The
        list is combined of default wiki pages and pages that are
        bundled with Bloodhound dashboard and search plugins"""
        from bhdashboard import wiki

        paths = [resource_filename('trac.wiki',
                                   'default-pages')] + \
                [resource_filename('bhdashboard',
                                   'default-pages')] + \
                [resource_filename('bhsearch',
                                   'default-pages')]
        pages = []
        original_pages = []
        for path in paths:
            for page in os.listdir(path):
                filename = os.path.join(path, page)
                page = unicode_unquote(page.encode('utf-8'))
                if os.path.isfile(filename):
                    original_pages.append(page)
        for original_name in original_pages:
            if original_name.startswith('Trac'):
                new_name = wiki.new_name(original_name)
                if not new_name:
                    continue
                if new_name in original_pages:
                    continue
                name = new_name
                # original trac wikis should also be included in the list
                pages.append(original_name)
            else:
                name = original_name
            pages.append(name)
        return pages

    def upgrade_environment(self, db_dummy=None):
        """Installs or updates tables to current version"""
        self.log.debug("upgrading existing environment for %s plugin." %
                       PLUGIN_NAME)
        db_installed_version = self.get_version()
        with self.env.db_direct_transaction as db:
            if db_installed_version < 1:
                self._add_column_product_to_ticket(db)
                self._create_multiproduct_tables(db)
                db_installed_version = self._update_db_version(db, 1)

            if db_installed_version < 2:
                self._replace_product_on_ticket_with_product_prefix(db)
                db_installed_version = self._update_db_version(db, 2)

            if db_installed_version < 3:
                SYSTEM_TABLES = ['system']
                TICKET_TABLES = [
                    'ticket_change', 'ticket_custom', 'attachment',
                ]
                table_defs = self._add_product_column_to_tables(
                    self.MIGRATE_TABLES + TICKET_TABLES + SYSTEM_TABLES,
                    db_installed_version)
                table_columns = self._get_table_columns(table_defs)
                create_temp_table = lambda table: self._create_temp_table(
                    db, table, table_columns, table_defs)

                self._insert_default_product(db)
                self._upgrade_tickets(db, TICKET_TABLES, create_temp_table)
                self._upgrade_wikis(db, create_temp_table)
                self._upgrade_system_tables(db, create_temp_table)
                self._soft_link_repositories_to_default_product(db)
                self._upgrade_table_system(SYSTEM_TABLES, create_temp_table, db)
                self._enable_multiproduct_hooks()

                db_installed_version = self._update_db_version(db, 3)

            if db_installed_version < 4:
                self._create_product_tables_for_plugins(db)
                db_installed_version = self._update_db_version(db, 4)

            if db_installed_version < 5:
                table_defs = self._add_product_column_to_tables(
                    ['ticket'], db_installed_version)
                self._modify_ticket_pk(db, table_defs)
                db_installed_version = self._update_db_version(db, 5)

            self.env.enable_multiproduct_schema(True)

    def _add_column_product_to_ticket(self, db):
        self.log.debug("Adding field product to ticket table")
        db("ALTER TABLE ticket ADD COLUMN product TEXT")

    def _create_multiproduct_tables(self, db):
        self.log.debug("Creating initial db tables for %s plugin." %
                       PLUGIN_NAME)
        db_connector, dummy = DatabaseManager(self.env)._get_connector()
        for table in self.SCHEMA:
            for statement in db_connector.to_sql(table):
                db(statement)

    def _replace_product_on_ticket_with_product_prefix(self, db):
        for prod in Product.select(self.env):
            db("""UPDATE ticket SET product=%s
                          WHERE product=%s""", (prod.prefix, prod.name))

    def _create_temp_table(self, db, table, table_columns, table_defs):
        """creates temporary table with the new schema and
        drops original table"""
        table_temp_name = '%s_temp' % table
        if table == 'report':
            cols = ','.join([c for c in table_columns[table] if c != 'id'])
        else:
            cols = ','.join(table_columns[table])
        self.log.info("Migrating table '%s' to a new schema", table)
        db("""CREATE TABLE %s AS SELECT %s FROM %s""" %
              (table_temp_name, cols, table))
        db("""DROP TABLE %s""" % table)
        db_connector, _ = DatabaseManager(self.env)._get_connector()
        table_schema = [t for t in table_defs if t.name == table][0]
        for sql in db_connector.to_sql(table_schema):
            db(sql)
        return table_temp_name, cols

    def _drop_temp_table(self, db, table):
        db("""DROP TABLE %s""" % table)

    def _add_product_column_to_tables(self, tables, current_version):
        """Extend trac default schema by adding product column
        and extending key with product.
        """
        table_defs = [copy.deepcopy(t) for t in trac.db_default.schema
                      if
                      t.name in tables]
        for t in table_defs:
            t.columns.append(Column('product'))
            if isinstance(t.key, list):
                t.key = tuple(t.key) + tuple(['product'])
            elif isinstance(t.key, tuple):
                t.key = t.key + tuple(['product'])
            else:
                raise TracError(
                    "Invalid table '%s' schema key '%s' while upgrading "
                    "plugin '%s' from version %d to %d'" %
                    (t.name, t.key, PLUGIN_NAME, current_version, 3))
        return table_defs

    def _get_table_columns(self, table_defs, all_columns=False):
        table_columns = dict()
        for table in table_defs:
            table_definition = \
                [t for t in table_defs if t.name == table.name][0]
            column_names = \
                [column.name for column in table_definition.columns]
            table_columns[table.name] = \
                [c for c in column_names if all_columns or c != 'product']
        return table_columns

    def _insert_default_product(self, db):
        self.log.info("Creating default product")
        db("""INSERT INTO bloodhound_product (prefix, name, description, owner)
              VALUES ('%s', '%s', '%s', '')
           """ % (self.default_product_prefix, 'Default', 'Default product'))

    def _upgrade_tickets(self, db, TICKET_TABLES, create_temp_table):
        # migrate tickets that don't have product assigned to default product
        # - update ticket table product column
        # - update ticket related tables by:
        #   - upgrading schema
        #   - update product column to match ticket's product
        self.log.info("Migrating tickets w/o product to default product")
        db("""UPDATE ticket SET product='%s'
                      WHERE (product IS NULL OR product='')
           """ % self.default_product_prefix)
        self._migrate_attachments(
            db("""SELECT a.type, a.id, a.filename
                            FROM attachment a
                      INNER JOIN ticket t ON a.id = %(t.id)s
                           WHERE a.type='ticket'
                       """ % {'t.id': db.cast('t.id', 'text')}),
            to_product=self.default_product_prefix
        )
        self.log.info("Migrating ticket tables to a new schema")
        for table in TICKET_TABLES:
            temp_table_name, cols = create_temp_table(table)
            db("""INSERT INTO %s (%s, product)
                          SELECT %s, '' FROM %s""" %
               (table, cols, cols, temp_table_name))
            self._drop_temp_table(db, temp_table_name)
            if table == 'attachment':
                db("""UPDATE attachment
                         SET product=(SELECT ticket.product
                                        FROM ticket
                                       WHERE %(ticket.id)s=attachment.id
                                       LIMIT 1)
                       WHERE attachment.type='ticket'
                         AND EXISTS(SELECT ticket.product
                                      FROM ticket
                                     WHERE %(ticket.id)s=attachment.id)
                   """ % {'ticket.id': db.cast('ticket.id', 'text')})
            else:
                db("""UPDATE %(table)s
                         SET product=(SELECT ticket.product
                                        FROM ticket
                                       WHERE ticket.id=%(table)s.ticket)
                   """ % {'table': table})

    def _upgrade_system_tables(self, db, create_temp_table):
        # migrate system table (except wiki which is handled separately)
        # to a new schema
        # - create tables with the new schema
        # - populate system tables with global configuration for each product
        # - exception is permission table where permissions
        #   are also populated in global scope
        #
        # permission table specifics: 'anonymous' and 'authenticated' users
        # should by default have a PRODUCT_VIEW permission for all products
        self.log.info("Migrating system tables to a new schema")
        for table in self.MIGRATE_TABLES:
            if table == 'wiki':
                continue
            temp_table_name, cols = create_temp_table(table)
            for product in Product.select(self.env):
                self.log.info("Populating table '%s' for product '%s' ('%s')",
                              table, product.name, product.prefix)
                db("""INSERT INTO %s (%s, product) SELECT %s,'%s' FROM %s""" %
                   (table, cols, cols, product.prefix, temp_table_name))
                if table == 'permission':
                    db.executemany(
                        """INSERT INTO permission (username, action, product)
                           VALUES (%s, %s, %s)""",
                        [('anonymous', 'PRODUCT_VIEW', product.prefix),
                         ('authenticated', 'PRODUCT_VIEW', product.prefix)])

            if table == 'permission':
                self.log.info("Populating table '%s' for global scope", table)
                db("""INSERT INTO %s (%s, product) SELECT %s,'%s' FROM %s""" %
                   (table, cols, cols, '', temp_table_name))
            self._drop_temp_table(db, temp_table_name)
        db.executemany(
            """INSERT INTO permission (username, action, product)
                VALUES (%s, %s, %s)""",
            [('anonymous', 'PRODUCT_VIEW', ''),
             ('authenticated', 'PRODUCT_VIEW', '')])


    def _upgrade_wikis(self, db, create_temp_table):
        # migrate wiki table
        # - populate system wikis to all products + global scope
        # - update wiki attachment product to match wiki product
        table = 'wiki'
        temp_table_name, cols = create_temp_table(table)
        self.log.info("Migrating wikis to default product")
        db("""INSERT INTO %(table)s (%(cols)s, product)
                   SELECT %(cols)s, '%(default_product)s' FROM %(temp_table)s
           """ % dict(table=table,
                      temp_table=temp_table_name,
                      cols=cols,
                      default_product=self.default_product_prefix,))
        db("""UPDATE attachment
                 SET product='%s'
               WHERE attachment.type='wiki'
           """ % self.default_product_prefix)
        self._migrate_attachments(
            db("""SELECT type, id, filename
                    FROM attachment
                   WHERE type='wiki'
                     AND product='%s'
               """ % (self.default_product_prefix)),
            to_product=self.default_product_prefix,
        )
        self._drop_temp_table(db, temp_table_name)

    def _migrate_attachments(self, attachments, to_product=None, copy=False):
        for type, id, filename in attachments:
            old_path = Attachment._get_path(self.env.path, type, id, filename)
            new_path = self.env.path
            if to_product:
                new_path = os.path.join(new_path, 'products', to_product)
            new_path = Attachment._get_path(new_path, type, id, filename)
            dirname = os.path.dirname(new_path)
            if not os.path.exists(old_path):
                self.log.warning(
                    "Missing attachment files for %s:%s/%s",
                    type, id, filename)
                continue
            if os.path.exists(new_path):
                # TODO: Do we want to overwrite?
                continue
            try:
                if not os.path.exists(dirname):
                    os.makedirs(dirname)
                if copy:
                    if hasattr(os, 'link'):
                        # TODO: It this safe?
                        os.link(old_path, new_path)
                    else:
                        shutil.copy(old_path, new_path)
                else:
                    os.rename(old_path, new_path)
            except OSError as err:
                self.log.warning(
                    "Could not move attachment %s from %s %s to"
                    "product @ (%s)",
                    filename, type, id, str(err)
                )

    def _soft_link_repositories_to_default_product(self, db):
        # soft link existing repositories to default product
        repositories_linked = []
        for id, name in db("""SELECT id, value FROM repository
                                      WHERE name='name'"""):
            if id in repositories_linked:
                continue
            db("""INSERT INTO repository (id, name, value)
                          VALUES (%s, 'product', '%s')""" %
               (id, self.default_product_prefix))
            repositories_linked.append(id)
            self.log.info("Repository '%s' (%s) soft linked to default product",
                          name, id)

    def _upgrade_table_system(self, SYSTEM_TABLES, create_temp_table, db):
        # Update system tables
        # Upgrade schema
        self.log.info("Migrating system tables to a new schema")
        for table in SYSTEM_TABLES:
            temp_table_name, cols = create_temp_table(table)
            db("""INSERT INTO %s (%s, product)
                          SELECT %s,'' FROM %s""" %
               (table, cols, cols, temp_table_name))
            self._drop_temp_table(db, temp_table_name)

    def _enable_multiproduct_hooks(self):
        # enable multi product hooks in environment configuration
        import multiproduct.hooks
        import inspect

        config_update = False
        hook_path = os.path.realpath(inspect.getsourcefile(multiproduct.hooks))
        if not 'environment_factory' in self.env.config['trac']:
            self.env.config['trac'].set('environment_factory', hook_path)
            config_update = True
        if not 'request_factory' in self.env.config['trac']:
            self.env.config['trac'].set('request_factory', hook_path)
            config_update = True
        if config_update:
            self.log.info(
                "Enabling multi product hooks in environment configuration")
            self.env.config.save()

    def _create_product_tables_for_plugins(self, db):
        self.log.debug("creating additional db tables for %s plugin." %
                       PLUGIN_NAME)
        db_connector, dummy = DatabaseManager(self.env)._get_connector()
        for statement in db_connector.to_sql(ProductSetting._get_schema()):
            db(statement)

    def _modify_ticket_pk(self, db, table_defs):
        self.log.debug("Modifying ticket primary key: id -> uid")
        table_columns = self._get_table_columns(table_defs, True)
        db_connector, _ = DatabaseManager(self.env)._get_connector()

        def rename_id_to_uid(table):
            for c in table.columns:
                if c.name == 'id':
                    c.name = 'uid'
                    break
            table.key = ['uid']

        def add_new_id_column(table):
            id_column = Column('id', type='int', auto_increment=True)
            if using_sqlite_backend(self.env) or using_mysql_backend(self.env):
                # sqlite and mysql don't support multiple auto increment columns
                id_column.auto_increment = False
            table.columns.append(id_column)
            table.indices.append(Index(['product', 'id'], unique=True))


        for t in table_defs:
            rename_id_to_uid(t)
            add_new_id_column(t)

            temp_table_name, cols = self._create_temp_table(
                db, t.name, table_columns, table_defs)
            db("""INSERT INTO ticket (%s, uid)
                       SELECT %s, id FROM ticket_temp""" %
                (cols, cols))
            self._drop_temp_table(db, temp_table_name)
            db.update_sequence(db.cursor(), 'ticket', 'id')
            db.update_sequence(db.cursor(), 'ticket', 'uid')

    # IResourceChangeListener methods
    def match_resource(self, resource):
        return isinstance(resource, Product)

    def resource_created(self, resource, context):
        import trac.db_default
        from multiproduct.env import EnvironmentStub

        # Don't populate product database when running from within test
        # environment stub as test cases really don't expect that ...
        if isinstance(self.env, EnvironmentStub):
            return

        product = resource
        self.log.debug("Adding product info (%s) to tables:" % product.prefix)
        with self.env.db_direct_transaction as db:
            # create the default entries for this Product from defaults
            for table in trac.db_default.get_data(db):
                if not table[0] in self.PRODUCT_POPULATE_TABLES:
                    continue

                self.log.debug("  -> %s" % table[0])
                cols = table[1] + ('product', )
                rows = [p + (product.prefix, ) for p in table[2]]
                db.executemany(
                    "INSERT INTO %s (%s) VALUES (%s)" %
                    (table[0], ','.join(cols), ','.join(['%s' for c in cols])),
                    rows)

        # Import default pages in product wiki
        wikiadmin = WikiAdmin(ProductEnvironment(self.env, product.prefix))
        pages = ('TitleIndex', 'RecentChanges', 'InterTrac', 'InterWiki')
        for page in pages:
            filename = resource_filename('trac.wiki', 'default-pages/' + page)
            wikiadmin.import_page(filename, page)

    def resource_changed(self, resource, old_values, context):
        return

    def resource_deleted(self, resource, context):
        return

    def resource_version_deleted(self, resource, context):
        return

    # ITemplateProvider methods
    def get_templates_dirs(self):
        """provide the plugin templates"""
        return [resource_filename(__name__, 'templates')]

    def get_htdocs_dirs(self):
        """proved the plugin htdocs"""
        return []

    # IPermissionRequestor methods
    def get_permission_actions(self):
        acts = ['PRODUCT_CREATE', 'PRODUCT_DELETE', 'PRODUCT_MODIFY',
                'PRODUCT_VIEW']
        if not isinstance(self.env, ProductEnvironment):
            return acts + [('PRODUCT_ADMIN', acts)] + [('ROADMAP_ADMIN', acts)]
        else:
            # In product context PRODUCT_ADMIN will be provided by product env
            # to ensure it will always be handy
            return acts

    # ITicketFieldProvider methods
    def get_select_fields(self):
        """Product select fields"""
        return [(35, {'name': 'product', 'label': _('Product'),
                      'cls': Product, 'pk': 'prefix', 'optional': False,
                      'value': self.default_product})]

    def get_radio_fields(self):
        """Product radio fields"""
        return []

    # IResourceManager methods
    def get_resource_realms(self):
        """Manage 'product' realm.
        """
        yield 'product'

    def get_resource_description(self, resource, format='default', context=None,
                                 **kwargs):
        """Describe product resource.
        """
        desc = resource.id
        if format != 'compact':
            desc = _('Product %(name)s', name=resource.id)
        if context:
            return self._render_link(context, resource.id, desc)
        else:
            return desc

    def resource_exists(self, resource):
        """Check whether product exists physically.
        """
        products = Product.select(self.env, where={'name' : resource.id})
        return bool(products)

    # IExternalResourceConnector methods
    def get_supported_neighborhoods(self):
        """Neighborhoods for `product` and `global` environments.
        """
        yield 'product'
        yield 'global'

    def load_manager(self, neighborhood):
        """Load global environment or product environment given its prefix
        """
        if neighborhood._realm == 'global':
            # FIXME: ResourceNotFound if neighborhood ID != None ?
            prefix = GLOBAL_PRODUCT
        elif neighborhood._realm == 'product':
            prefix = neighborhood._id
        else:
            raise ResourceNotFound(_(u'Unsupported neighborhood %(realm)s',
                                     realm=neighborhood._realm))
        try:
            return lookup_product_env(self.env, prefix)
        except LookupError:
            raise ResourceNotFound(_(u'Unknown product prefix %(prefix)s',
                                     prefix=prefix))

    def manager_exists(self, neighborhood):
        """Check whether the target environment exists physically.
        """
        if neighborhood._realm == 'global':
            # Global environment
            return isinstance(self.env, (Environment, ProductEnvironment))
        elif neighborhood._realm == 'product':
            prefix = neighborhood._id
            if not prefix:
                # Global environment
                return True
            return Product(lookup_product_env(self.env, GLOBAL_PRODUCT),
                           {'prefix' : prefix})._exists

    # IWikiSyntaxProvider methods

    short_syntax_delimiter = u'->'

    def get_wiki_syntax(self):
        yield (r'(?<!\S)!?(?P<pid>%s)%s(?P<ptarget>%s:(?:%s)|%s|%s(?:%s*%s)?)' %
                    (IDENTIFIER,
                     PRODUCT_SYNTAX_DELIMITER_RE,
                     WikiParser.LINK_SCHEME, WikiParser.QUOTED_STRING,
                     WikiParser.QUOTED_STRING, WikiParser.SHREF_TARGET_FIRST,
                     WikiParser.SHREF_TARGET_MIDDLE, WikiParser.SHREF_TARGET_LAST),
               lambda f, m, fm :
                    self._format_link(f, 'product',
                                      '%s:%s' % (fm.group('pid'),
                                                 unquote_label(fm.group('ptarget'))),
                                      fm.group(0), fm))
        if self.env[ProductTicketModule] is not None:
            yield (r"(?<!\S)!?(?P<jtp>%s)-(?P<jtt>\d+)(?P<jtf>[?#]\S+)?" %
                        (IDENTIFIER,),
                   lambda f, m, fm :
                        self._format_link(f, 'product',
                                          '%s:ticket:%s' %
                                                (fm.group('jtp'),
                                                 fm.group('jtt') +
                                                 (fm.group('jtf') or '')),
                                          m, fm))

    def get_link_resolvers(self):
        yield ('global', self._format_link)
        yield ('product', self._format_link)

    # ITicketManipulator methods
    def validate_ticket(self, req, ticket):
        # check whether the owner exists in db, add a warning if not
        if req.args.get('action') == 'reassign' and \
           ticket['owner'] != self.env.config.get('ticket', 'default_owner'):
            owner = self.env.db_direct_query(
                "SELECT sid FROM session WHERE sid=%s",
                (ticket['owner'], ))
            if not owner:
                # Note: add_warning() is used intead of returning a list of
                # error tuples, since the latter results in trac rendering
                # errors (ticket's change.date is not populated)
                add_warning(req, _('The user "%s" does not exist.') %
                    ticket['owner'])
        return []


    # Internal methods

    def _render_link(self, context, name, label, extra='', prefix=None):
        """Render link to product page.
        """
        product_env = product = None
        env = self.env
        if isinstance(env, ProductEnvironment):
            if (prefix is not None and env.product.prefix == prefix) \
                    or (prefix is None and env.name == name):
                product_env = env
            env = env.parent
        try:
            if product_env is None:
                if prefix is not None:
                    product_env = ProductEnvironment(env, to_unicode(prefix))
                else:
                    product = Product.select(env,
                                             where={'name' : to_unicode(name)})
                    if not product:
                        raise LookupError("Missing product")
                    product_env = ProductEnvironment(env,
                                                     to_unicode(product[0]))
        except LookupError:
            pass

        if product_env is not None:
            product = product_env.product
            href = resolve_product_href(to_env=product_env, at_env=self.env)
            if 'PRODUCT_VIEW' in context.perm(product.resource):
                return tag.a(label, class_='product', href=href() + extra,
                             title=product.name)
        if 'PRODUCT_CREATE' in context.perm('product', name):
            params = [('action', 'new')]
            if prefix:
                params.append( ('prefix', prefix) )
            if name:
                params.append( ('name', name) )
            return tag.a(label, class_='missing product',
                    href=env.href('products', params),
                    rel='nofollow')
        return tag.a(label, class_='missing product')

    def _format_link(self, formatter, ns, target, label, fullmatch):
        link, params, fragment = formatter.split_link(target)
        expr = link.split(':', 1)
        if ns == 'product' and len(expr) == 1:
            # product:prefix form
            return self._render_link(formatter.context, None, label,
                                     params + fragment, expr[0])
        elif ns == 'global' or (ns == 'product' and expr[0] == ''):
            # global scope
            sublink = link if ns == 'global' else expr[1]
            target_env = self.env.parent \
                            if isinstance(self.env, ProductEnvironment) \
                            else self.env
            return self._make_sublink(target_env, sublink, formatter, ns,
                                      target, label, fullmatch,
                                      extra=params + fragment)
        else:
            # product:prefix:realm:id:...
            prefix, sublink = expr
            try:
                target_env = lookup_product_env(self.env, prefix)
            except LookupError:
                return tag.a(label, class_='missing product')
            # TODO: Check for nested product links
            # e.g. product:p1:product:p2:ticket:1
            return self._make_sublink(target_env, sublink, formatter, ns,
                                      target, label, fullmatch,
                                      extra=params + fragment)

    FakePermClass = FakePerm

    def _make_sublink(self, env, sublink, formatter, ns, target, label,
                      fullmatch, extra=''):
        parent_match = {'ns' : ns,
                        'target' : target,
                        'label': Markup(escape(unescape(label)
                                               if isinstance(label, Markup)
                                               else label)),
                        'fullmatch' : fullmatch,
                        }

        # Tweak nested context to work in target product/global scope
        subctx = formatter.context.child()
        subctx.href = resolve_product_href(to_env=env, at_env=self.env)
        try:
            req = formatter.context.req
        except AttributeError:
            pass
        else:
            # Authenticate in local context but use foreign permissions
            subctx.perm = self.FakePermClass() \
                            if isinstance(req.session, FakeSession) \
                            else PermissionCache(env, req.authname)
            subctx.req = req

        subformatter = EmbeddedLinkFormatter(env, subctx, parent_match)
        subformatter.auto_quote = True
        ctxtag = '[%s] ' % (env.product.prefix,) \
                    if isinstance(env, ProductEnvironment) \
                    else '<global> '
        subformatter.enhance_link = lambda link : (
                                link(title=ctxtag + link.attrib.get('title'))
                                if isinstance(link, Element)
                                    and 'title' in link.attrib
                                else link)
        link = subformatter.match(sublink + extra)
        if link:
            return link
        else:
            # Return outermost match unchanged like if it was !-escaped
            for itype, match in fullmatch.groupdict().items():
                if match and not itype in formatter.wikiparser.helper_patterns:
                    return escape(match)


PRODUCT_SYNTAX_DELIMITER = MultiProductSystem.short_syntax_delimiter
PRODUCT_SYNTAX_DELIMITER_RE = ''.join('[%s]' % c
                                      for c in PRODUCT_SYNTAX_DELIMITER)

from multiproduct.env import ProductEnvironment, lookup_product_env, \
        resolve_product_href
from multiproduct.ticket.web_ui import ProductTicketModule

########NEW FILE########
__FILENAME__ = cache
#
# LRU and LFU cache decorators - licensed under the PSF License
# Developed by Raymond Hettinger
# (http://code.activestate.com/recipes/498245-lru-and-lfu-cache-decorators/)
#
# March 13, 2013 updated by Olemis Lang
#    Added keymap arg to build custom keys out of actual args
# March 14, 2013 updated by Olemis Lang
#    Keep cache consistency on user function failure

import collections
import functools
from itertools import ifilterfalse
from heapq import nsmallest
from operator import itemgetter

class Counter(dict):
    'Mapping where default values are zero'
    def __missing__(self, key):
        return 0

def lru_cache(maxsize=100, keymap=None):
    '''Least-recently-used cache decorator.

    Arguments to the cached function must be hashable.
    Cache performance statistics stored in f.hits and f.misses.
    Clear the cache with f.clear().
    http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used

    :param keymap:    build custom keys out of actual arguments.
                      Its signature will be lambda (args, kwds, kwd_mark)
    '''
    maxqueue = maxsize * 10
    def decorating_function(user_function,
                            len=len, iter=iter, tuple=tuple, sorted=sorted, KeyError=KeyError):
        cache = {}                  # mapping of args to results
        queue = collections.deque() # order that keys have been used
        refcount = Counter()        # times each key is in the queue
        sentinel = object()         # marker for looping around the queue
        kwd_mark = object()         # separate positional and keyword args

        # lookup optimizations (ugly but fast)
        queue_append, queue_popleft = queue.append, queue.popleft
        queue_appendleft, queue_pop = queue.appendleft, queue.pop

        @functools.wraps(user_function)
        def wrapper(*args, **kwds):
            # cache key records both positional and keyword args
            if keymap is None:
                key = args
                if kwds:
                    key += (kwd_mark,) + tuple(sorted(kwds.items()))
            else:
                key = keymap(args, kwds, kwd_mark)

            # get cache entry or compute if not found
            try:
                result = cache[key]
                wrapper.hits += 1

                # record recent use of this key
                queue_append(key)
                refcount[key] += 1
            except KeyError:
                # Explicit exception handling for readability
                try:
                    result = user_function(*args, **kwds)
                except:
                    raise
                else:
                    # record recent use of this key
                    queue_append(key)
                    refcount[key] += 1

                cache[key] = result
                wrapper.misses += 1

                # purge least recently used cache entry
                if len(cache) > maxsize:
                    key = queue_popleft()
                    refcount[key] -= 1
                    while refcount[key]:
                        key = queue_popleft()
                        refcount[key] -= 1
                    del cache[key], refcount[key]

            # periodically compact the queue by eliminating duplicate keys
            # while preserving order of most recent access
            if len(queue) > maxqueue:
                refcount.clear()
                queue_appendleft(sentinel)
                for key in ifilterfalse(refcount.__contains__,
                    iter(queue_pop, sentinel)):
                    queue_appendleft(key)
                    refcount[key] = 1


            return result

        def clear():
            cache.clear()
            queue.clear()
            refcount.clear()
            wrapper.hits = wrapper.misses = 0

        wrapper.hits = wrapper.misses = 0
        wrapper.clear = clear
        return wrapper
    return decorating_function


def lfu_cache(maxsize=100, keymap=None):
    '''Least-frequenty-used cache decorator.

    Arguments to the cached function must be hashable.
    Cache performance statistics stored in f.hits and f.misses.
    Clear the cache with f.clear().
    http://en.wikipedia.org/wiki/Least_Frequently_Used

    :param keymap:    build custom keys out of actual arguments.
                      Its signature will be lambda (args, kwds, kwd_mark)
    '''
    def decorating_function(user_function):
        cache = {}                      # mapping of args to results
        use_count = Counter()           # times each key has been accessed
        kwd_mark = object()             # separate positional and keyword args

        @functools.wraps(user_function)
        def wrapper(*args, **kwds):
            if keymap is None:
                key = args
                if kwds:
                    key += (kwd_mark,) + tuple(sorted(kwds.items()))
            else:
                key = keymap(args, kwds, kwd_mark)
            use_count[key] += 1

            # get cache entry or compute if not found
            try:
                result = cache[key]
                wrapper.hits += 1
            except KeyError:
                result = user_function(*args, **kwds)
                cache[key] = result
                wrapper.misses += 1

                # purge least frequently used cache entry
                if len(cache) > maxsize:
                    for key, _ in nsmallest(maxsize // 10,
                        use_count.iteritems(),
                        key=itemgetter(1)):
                        del cache[key], use_count[key]

            return result

        def clear():
            cache.clear()
            use_count.clear()
            wrapper.hits = wrapper.misses = 0

        wrapper.hits = wrapper.misses = 0
        wrapper.clear = clear
        return wrapper
    return decorating_function

#----------------------
# Helper functions
#----------------------

def default_keymap(args, kwds, kwd_mark):
    key = args
    if kwds:
        key += (kwd_mark,) + tuple(sorted(kwds.items()))
    return key

########NEW FILE########
__FILENAME__ = config
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

__all__ = 'Configuration', 'Section'

import os.path

from trac.config import Configuration, ConfigurationError, Option, \
        OrderedExtensionsOption, Section, _use_default
from trac.resource import ResourceNotFound
from trac.util import create_file
from trac.util.text import to_unicode

from multiproduct.model import ProductSetting
from multiproduct.perm import MultiproductPermissionPolicy


class Configuration(Configuration):
    """Product-aware settings repository equivalent to instances of
    `trac.config.Configuration` (and thus `ConfigParser` from the
    Python Standard Library) but retrieving configuration values
    from the database.
    """

    CONFIG_LOCK_FILE = 'config.lock'

    def __init__(self, env, product, parents=None):
        """Initialize configuration object with an instance of
        `trac.env.Environment` and product prefix.

        Optionally it is possible to inherit settings from parent
        Configuration objects. Environment's configuration will not
        be added to parents list.
        """
        self.env = env
        self.product = to_unicode(product)
        self._sections = {}
        self._lastmtime = 0
        self._lock_path = os.path.join(self.env.path, self.CONFIG_LOCK_FILE)
        if not os.path.exists(self._lock_path):
            create_file(self._lock_path)
        self._orig_parents = parents
        self._setup_parents(parents)

    def __getitem__(self, name):
        """Return the configuration section with the specified name.
        """
        if name not in self._sections:
            self._sections[name] = Section(self, name)
        return self._sections[name]

    def get_lock_file_mtime(self):
        """Returns to modification time of the lock file."""
        return os.path.getmtime(self._lock_path)

    def sections(self, compmgr=None, defaults=True):
        """Return a list of section names.

        If `compmgr` is specified, only the section names corresponding to
        options declared in components that are enabled in the given
        `ComponentManager` are returned.
        """
        sections = set(to_unicode(s) \
                for s in ProductSetting.get_sections(self.env, self.product))
        for parent in self.parents:
            sections.update(parent.sections(compmgr, defaults=False))
        if defaults:
            sections.update(self.defaults(compmgr))
        return sorted(sections)

    def has_option(self, section, option, defaults=True):
        """Returns True if option exists in section in either the project
        trac.ini or one of the parents, or is available through the Option
        registry.

        (since Trac 0.11)
        """
        if ProductSetting.exists(self.env, self.product, section, option):
            return True
        for parent in self.parents:
            if parent.has_option(section, option, defaults=False):
                return True
        return defaults and (section, option) in Option.registry

    def save(self):
        """Just touch config lock file.

        Notice: In contrast to Trac's Configuration objects Bloodhound's
        product configuration objects commit changes to the database
        immediately. Thus there's no much to do in this method.
        """
        self.touch()
        self._lastmtime = self.get_lock_file_mtime()

    def parse_if_needed(self, force=False):
        """Invalidate options cache considering global lock timestamp.

        Notice: Opposite to Trac's Configuration objects Bloodhound's
        product configuration objects commit changes to the database
        immediately. Thus there's no much to do in this method.
        """
        changed = False
        modtime = self.get_lock_file_mtime()
        if force or modtime > self._lastmtime:
            self._sections = {}
            self._lastmtime = modtime
            changed = True

        if changed:
            self._setup_parents(self._orig_parents)
        else:
            for parent in self.parents:
                changed |= parent.parse_if_needed(force=force)

        return changed

    def touch(self):
        if os.access(self._lock_path, os.W_OK):
            os.utime(self._lock_path, None)

    def set_defaults(self, compmgr=None):
        """Retrieve all default values and store them explicitly in the
        configuration, so that they can be saved to file.

        Values already set in the configuration are not overridden.
        """
        for section, default_options in self.defaults(compmgr).items():
            for name, value in default_options.items():
                if not ProductSetting.exists(self.env, self.product,
                                             section, name):
                    if any(parent[section].contains(name, defaults=False)
                           for parent in self.parents):
                        value = None
                    self.set(section, name, value)

    # Helper methods

    def _setup_parents(self, parents=None):
        """Inherit configuration from parent `Configuration` instances.
        If there's a value set to 'file' option in 'inherit' section then
        it will be considered as a list of paths to .ini files
        that will be added to parents list as well.
        """
        from trac import config
        self.parents = (parents or [])
        for filename in self.get('inherit', 'file').split(','):
            filename = Section._normalize_path(filename.strip(), self.env)
            self.parents.append(config.Configuration(filename))


class Section(Section):
    """Proxy for a specific configuration section.

    Objects of this class should not be instantiated directly.
    """
    __slots__ = ['config', 'name', 'overridden', '_cache']

    @staticmethod
    def optionxform(optionstr):
        return to_unicode(optionstr.lower())

    def __init__(self, config, name):
        self.config = config
        self.name = to_unicode(name)
        self.overridden = {}
        self._cache = {}

    @property
    def env(self):
        return self.config.env

    @property
    def product(self):
        return self.config.product

    def contains(self, key, defaults=True):
        key = self.optionxform(key)
        if ProductSetting.exists(self.env, self.product, self.name, key):
            return True
        for parent in self.config.parents:
            if parent[self.name].contains(key, defaults=False):
                return True
        return defaults and (self.name, key) in Option.registry

    __contains__ = contains

    def iterate(self, compmgr=None, defaults=True):
        """Iterate over the options in this section.

        If `compmgr` is specified, only return default option values for
        components that are enabled in the given `ComponentManager`.
        """
        options = set()
        name_str = self.name
        for setting in ProductSetting.select(self.env,
                                             where={'product': self.product,
                                                    'section': name_str}):
            option = self.optionxform(setting.option)
            options.add(option)
            yield option
        for parent in self.config.parents:
            for option in parent[self.name].iterate(defaults=False):
                loption = self.optionxform(option)
                if loption not in options:
                    options.add(loption)
                    yield option
        if defaults:
            for section, option in Option.get_registry(compmgr).keys():
                if section == self.name and \
                        self.optionxform(option) not in options:
                    yield option

    __iter__ = iterate

    def __repr__(self):
        return '<%s [%s , %s]>' % (self.__class__.__name__,
                                   self.product, self.name)

    def get(self, key, default=''):
        """Return the value of the specified option.

        Valid default input is a string. Returns a string.
        """
        key = self.optionxform(key)
        cached = self._cache.get(key, _use_default)
        if cached is not _use_default:
            return cached
        name_str = self.name
        key_str = to_unicode(key)
        settings = ProductSetting.select(self.env,
                                         where={'product': self.product,
                                                'section': name_str,
                                                'option': key_str})
        if len(settings) > 0:
            value = settings[0].value
        else:
            for parent in self.config.parents:
                value = parent[self.name].get(key, _use_default)
                if value is not _use_default:
                    break
            else:
                if default is not _use_default:
                    option = Option.registry.get((self.name, key))
                    value = option.default if option else _use_default
                else:
                    value = _use_default
        if value is _use_default:
            return default
        if not value:
            value = u''
        elif isinstance(value, basestring):
            value = to_unicode(value)
        self._cache[key] = value
        return value

    def getpath(self, key, default=''):
        """Return a configuration value as an absolute path.

        Relative paths are resolved relative to `conf` subfolder
        of the target global environment. This approach is consistent
        with TracIni path resolution.

        Valid default input is a string. Returns a normalized path.

        (enabled since Trac 0.11.5)
        """
        path = self.get(key, default)
        if not path:
            return default
        return self._normalize_path(path, self.env)

    def remove(self, key):
        """Delete a key from this section.

        Like for `set()`, the changes won't persist until `save()` gets called.
        """
        key_str = self.optionxform(key)
        option_key = {
            'product': self.product,
            'section': self.name,
            'option': key_str
        }
        try:
            setting = ProductSetting(self.env, keys=option_key)
        except ResourceNotFound:
            self.env.log.warning("No record for product option %s", option_key)
        else:
            self._cache.pop(key, None)
            setting.delete()
            self.env.log.info("Removing product option %s", option_key)

    def set(self, key, value):
        """Change a configuration value.

        These changes will be persistent right away.
        """
        key_str = self.optionxform(key)
        value_str = to_unicode(value)
        self._cache.pop(key_str, None)
        option_key = {
            'product': self.product,
            'section': self.name,
            'option': key_str,
        }
        try:
            setting = ProductSetting(self.env, option_key)
        except ResourceNotFound:
            if value is not None:
                # Insert new record in the database
                setting = ProductSetting(self.env)
                setting._data.update(option_key)
                setting._data['value'] = value_str
                self.env.log.debug('Writing option %s', setting._data)
                setting.insert()
        else:
            if value is None:
                # Delete existing record from the database
                # FIXME : Why bother with setting overriden
                self.overridden[key] = True
                setting.delete()
            else:
                # Update existing record
                setting._data['value'] = value
                setting.update()

    # Helper methods

    @staticmethod
    def _normalize_path(path, env):
        if not os.path.isabs(path):
            path = os.path.join(env.path, 'conf', path)
        return os.path.normcase(os.path.realpath(path))


#--------------------
# Option override classes
#--------------------

class ProductPermissionPolicyOption(OrderedExtensionsOption):
    """Prepend an instance of `multiproduct.perm.MultiproductPermissionPolicy`
    """
    def __get__(self, instance, owner):
        # FIXME: Better handling of recursive imports
        from multiproduct.env import ProductEnvironment

        if instance is None:
            return self
        components = OrderedExtensionsOption.__get__(self, instance, owner)
        env = getattr(instance, 'env', None)
        return [MultiproductPermissionPolicy(env)] + components \
               if isinstance(env, ProductEnvironment) \
               else components

########NEW FILE########
__FILENAME__ = core
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.core import ComponentMeta, ExtensionPoint


class MultiProductExtensionPoint(ExtensionPoint):
    """Marker class for multiproduct extension points in components."""

    def extensions(self, component):
        """Return a multiproduct aware list of components that declare to
        implement the extension point interface.

        When accessed in product environment, only components for that
        environment are returned.

        When accessed in global environment, a separate instance will be
        returned for global and each of the product environments.
        """
        compmgr = component.compmgr
        if not hasattr(compmgr, 'parent') or compmgr.parent is not None:
            return \
                super(MultiProductExtensionPoint, self).extensions(component)

        classes = ComponentMeta._registry.get(self.interface, ())
        components = [component.compmgr[cls] for cls in classes]
        components += [
            env[cls]
            for cls in classes
            for env in component.compmgr.all_product_envs()
        ]
        return [c for c in components if c]

########NEW FILE########
__FILENAME__ = dbcursor
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


import trac.db.util
from trac.util import concurrency

import sqlparse
import sqlparse.tokens as Tokens
import sqlparse.sql as Types

from multiproduct.cache import lru_cache
from multiproduct.util import using_sqlite_backend, using_mysql_backend

__all__ = ['BloodhoundIterableCursor', 'BloodhoundConnectionWrapper', 'ProductEnvContextManager']

SKIP_TABLES = ['auth_cookie',
               'session', 'session_attribute',
               'cache',
               'repository', 'revision', 'node_change',
               'bloodhound_product', 'bloodhound_productresourcemap', 'bloodhound_productconfig',
               'sqlite_master', 'bloodhound_relations'
               ]
TRANSLATE_TABLES = ['system',
                    'ticket', 'ticket_change', 'ticket_custom',
                    'attachment',
                    'enum', 'component', 'milestone', 'version',
                    'permission',
                    'wiki',
                    'report',
                   ]
PRODUCT_COLUMN = 'product'
GLOBAL_PRODUCT = ''

# Singleton used to mark translator as unset
class empty_translator(object):
    pass

translator_not_set = empty_translator()

@lru_cache(maxsize=1000)
def translate_sql(env, sql):
    translator = None
    log = None
    product_prefix = None
    if env is not None:
        if trac.db.api.DatabaseManager(env).debug_sql:
            log = env.log
        product_prefix = env.product.prefix if env.product else GLOBAL_PRODUCT
        translator = BloodhoundProductSQLTranslate(SKIP_TABLES,
                                                   TRANSLATE_TABLES,
                                                   PRODUCT_COLUMN,
                                                   product_prefix,
                                                   env)
    if log:
        log.debug('Original SQl: %s', sql)
    realsql = translator.translate(sql) if (translator is not None) else sql
    if log:
        log.debug('SQL: %s', realsql)

    return realsql

class BloodhoundIterableCursor(trac.db.util.IterableCursor):
    __slots__ = trac.db.util.IterableCursor.__slots__ + ['_translator']
    _tls = concurrency.ThreadLocal(env=None)

    def __init__(self, cursor, log=None):
        super(BloodhoundIterableCursor, self).__init__(cursor, log=log)

    def execute(self, sql, args=None):
        return super(BloodhoundIterableCursor, self).execute(translate_sql(self.env, sql), args=args)

    def executemany(self, sql, args=None):
        return super(BloodhoundIterableCursor, self).executemany(translate_sql(self.env, sql), args=args)

    @property
    def env(self):
        return self._tls.env

    @classmethod
    def set_env(cls, env):
        cls._tls.env = env

    @classmethod
    def get_env(cls):
        return cls._tls.env

    @classmethod
    def cache_reset(cls):
        translate_sql.clear()

# replace trac.db.util.IterableCursor with BloodhoundIterableCursor
trac.db.util.IterableCursor = BloodhoundIterableCursor

class BloodhoundConnectionWrapper(object):

    def __init__(self, connection, env):
        self.connection = connection
        self.env = env

    def __getattr__(self, name):
        return getattr(self.connection, name)

    def execute(self, query, params=None):
        BloodhoundIterableCursor.set_env(self.env)
        return self.connection.execute(query, params=params)

    __call__ = execute

    def executemany(self, query, params=None):
        BloodhoundIterableCursor.set_env(self.env)
        return self.connection.executemany(query, params=params)

    def cursor(self):
        return BloodhoundCursorWrapper(self.connection.cursor(), self.env)

class BloodhoundCursorWrapper(object):

    def __init__(self, cursor, env):
        self.cursor = cursor
        self.env = env

    def __getattr__(self, name):
        return getattr(self.cursor, name)

    def __iter__(self):
        return self.cursor.__iter__()

    def execute(self, sql, args=None):
        BloodhoundIterableCursor.set_env(self.env)
        return self.cursor.execute(sql, args=args)

    def executemany(self, sql, args=None):
        BloodhoundIterableCursor.set_env(self.env)
        return self.cursor.executemany(sql, args=args)

class ProductEnvContextManager(object):
    """Wrap an underlying database context manager so as to keep track
    of (nested) product context.
    """
    def __init__(self, context, env=None):
        """Initialize product database context.

        :param context: Inner database context (e.g. `QueryContextManager`,
                        `TransactionContextManager` )
        :param env:     An instance of either `trac.env.Environment` or
                        `multiproduct.env.ProductEnvironment` used to
                        reduce the scope of database queries. If set
                        to `None` then SQL queries will not be translated,
                        which is equivalent to having direct database access.
        """
        self.db_context = context
        self.env = env

    def __enter__(self):
        """Keep track of previous product context and override it with `env`;
        then enter the inner database context.
        """
        return BloodhoundConnectionWrapper(self.db_context.__enter__(), self.env)

    def __exit__(self, et, ev, tb):
        """Uninstall current product context by restoring the last one;
        then leave the inner database context.
        """
        return self.db_context.__exit__(et, ev, tb)

    def __call__(self, *args, **kwargs):
        """Forward attribute access to nested database context on failure.
        """
        BloodhoundIterableCursor.set_env(self.env)
        return self.db_context(*args, **kwargs)

    def __getattr__(self, attrnm):
        """Forward attribute access to nested database context on failure.
        """
        return getattr(self.db_context, attrnm)

    def execute(self, sql, params=None):
        BloodhoundIterableCursor.set_env(self.env)
        return self.db_context.execute(sql, params=params)

    def executemany(self, sql, params=None):
        BloodhoundIterableCursor.set_env(self.env)
        return self.db_context.executemany(sql, params=params)


class BloodhoundProductSQLTranslate(object):
    _join_statements = ['LEFT JOIN', 'LEFT OUTER JOIN',
                        'RIGHT JOIN', 'RIGHT OUTER JOIN',
                        'JOIN', 'INNER JOIN']
    _from_end_words = ['WHERE', 'GROUP', 'HAVING', 'ORDER', 'UNION', 'LIMIT']

    def __init__(self, skip_tables, translate_tables, product_column, product_prefix, env=None):
        self._skip_tables = skip_tables
        self._translate_tables = translate_tables
        self._product_column = product_column
        self._product_prefix = product_prefix
        self._id_calculated = env is None or using_sqlite_backend(env) \
            or using_mysql_backend(env)

    def _sqlparse_underline_hack(self, token):
        underline_token = lambda token: token.ttype == Tokens.Token.Error and token.value == '_'
        identifier_token = lambda token: isinstance(token, Types.Identifier) or isinstance(token, Types.Token)
        def prefix_token(token, prefix):
            if identifier_token(token):
                if isinstance(token, Types.IdentifierList):
                    token = token.tokens[0]
                token.value = prefix + token.value
                token.normalized = token.value.upper() if token.ttype in Tokens.Keyword \
                                                            else token.value
                if hasattr(token, 'tokens'):
                    if len(token.tokens) != 1:
                        raise Exception("Internal error, invalid token list")
                    token.tokens[0].value, token.tokens[0].normalized = token.value, token.normalized
            return

        if hasattr(token, 'tokens') and token.tokens and len(token.tokens):
            current = self._token_first(token)
            while current:
                leftover = None
                if underline_token(current):
                    prefix = ''
                    while underline_token(current):
                        prefix += current.value
                        prev = current
                        current = self._token_next(token, current)
                        self._token_delete(token, prev)
                        # expression ends with _ ... push the token to parent
                        if not current:
                            return prev
                    prefix_token(current, prefix)
                else:
                    leftover = self._sqlparse_underline_hack(current)
                    if leftover:
                        leftover.parent = token
                        self._token_insert_after(token, current, leftover)
                current = leftover if leftover else self._token_next(token, current)
        return None

    def _select_table_name_alias(self, tokens):
        return filter(lambda t: t.upper() != 'AS', [t.value for t in tokens if t.value.strip()])
    def _column_expression_name_alias(self, tokens):
        return filter(lambda t: t.upper() != 'AS', [t.value for t in tokens if t.value.strip()])

    def _select_alias_sql(self, alias):
        return ' AS %s' % alias

    def _translated_table_view_sql(self, name, alias=None):
        sql = "(SELECT * FROM %s WHERE %s='%s')" % (name, self._product_column, self._product_prefix)
        if alias:
            sql += self._select_alias_sql(alias)
        return sql

    def _prefixed_table_entity_name(self, tablename):
        return '"%s_%s"' % (self._product_prefix, tablename) if self._product_prefix else tablename

    def _prefixed_table_view_sql(self, name, alias):
        return '(SELECT * FROM %s) AS %s' % (self._prefixed_table_entity_name(name),
                                             alias)

    def _token_first(self, parent):
        return parent.token_first()
    def _token_next_match(self, parent, start_token, ttype, token):
        return parent.token_next_match(self._token_idx(parent, start_token), ttype, token)
    def _token_next(self, parent, from_token):
        return parent.token_next(self._token_idx(parent, from_token))
    def _token_prev(self, parent, from_token):
        return parent.token_prev(self._token_idx(parent, from_token))
    def _token_next_by_instance(self, parent, start_token, klass):
        return parent.token_next_by_instance(self._token_idx(parent, start_token), klass)
    def _token_next_by_type(self, parent, start_token, ttype):
        return parent.token_next_by_type(self._token_idx(parent, start_token), ttype)
    def _token_insert_before(self, parent, where, token):
        return parent.insert_before(where, token)
    def _token_insert_after(self, parent, where, token):
        return parent.insert_after(where, token)
    def _token_idx(self, parent, token):
        return parent.token_index(token)
    def _token_delete(self, parent, token):
        idx = self._token_idx(parent, token)
        del parent.tokens[idx]
        return idx
    def _token_insert(self, parent, idx, token):
        parent.tokens.insert(idx, token)

    def _eval_expression_value(self, parent, token):
        if isinstance(token, Types.Parenthesis):
            t = self._token_first(token)
            if t.match(Tokens.Punctuation, '('):
                t = self._token_next(token, t)
                if t.match(Tokens.DML, 'SELECT'):
                    self._select(token, t)

    def _expression_token_unwind_hack(self, parent, token, start_token):
        # hack to workaround sqlparse bug that wrongly presents list of tokens
        # as IdentifierList in certain situations
        if isinstance(token, Types.IdentifierList):
            idx = self._token_delete(parent, token)
            for t in token.tokens:
                self._token_insert(parent, idx, t)
                idx += 1
            token = self._token_next(parent, start_token)
        return token

    def _where(self, parent, where_token):
        if isinstance(where_token, Types.Where):
            token = self._token_first(where_token)
            if not token.match(Tokens.Keyword, 'WHERE'):
                raise Exception("Invalid WHERE statement")
            while token:
                self._eval_expression_value(where_token, token)
                token = self._token_next(where_token, token)
        return

    def _select_expression_tokens(self, parent, first_token, end_words):
        if isinstance(first_token, Types.IdentifierList):
            return first_token, [list(first_token.flatten())]
        tokens = list()
        current_list = list()
        current_token = first_token
        while current_token and not current_token.match(Tokens.Keyword, end_words):
            if current_token.match(Tokens.Punctuation, ','):
                if current_list:
                    tokens.append(current_list)
                    current_list = list()
            elif current_token.is_whitespace():
                pass
            else:
                current_list.append(current_token)
            current_token = self._token_next(parent, current_token)
        if current_list:
            tokens.append(current_list)
        return current_token, tokens

    def _select_join(self, parent, start_token, end_words):
        current_token = self._select_from(parent, start_token, ['ON'], force_alias=True)
        tokens = list()
        if current_token:
            current_token = self._token_next(parent, current_token)
            while current_token and \
                  not current_token.match(Tokens.Keyword, end_words) and \
                  not isinstance(current_token, Types.Where):
                tokens.append(current_token)
                current_token = self._token_next(parent, current_token)
        return current_token

    def _select_from(self, parent, start_token, end_words, table_name_callback=None, force_alias=False):
        def inject_table_view(token, name, alias):
            if name in self._skip_tables:
                pass
            elif name in self._translate_tables:
                if force_alias and not alias:
                    alias = name
                parent.tokens[self._token_idx(parent, token)] = sqlparse.parse(self._translated_table_view_sql(name,
                                                                                                               alias=alias))[0]
                if table_name_callback:
                    table_name_callback(name)
            else:
                if not alias:
                    alias = name
                parent.tokens[self._token_idx(parent, token)] = sqlparse.parse(self._prefixed_table_view_sql(name,
                                                                                                             alias))[0]
                if table_name_callback:
                    table_name_callback(name)

        def inject_table_alias(token, alias):
            parent.tokens[self._token_idx(parent, token)] = sqlparse.parse(self._select_alias_sql(alias))[0]

        def process_table_name_tokens(nametokens):
            if nametokens:
                l = self._select_table_name_alias(nametokens)
                if not l:
                    raise Exception("Invalid FROM table name")
                name, alias = l[0], None
                alias = l[1] if len(l) > 1 else name
                if not name in self._skip_tables:
                    token = nametokens[0]
                    for t in nametokens[1:]:
                        self._token_delete(parent, t)
                    inject_table_view(token, name, alias)
            return list()

        current_token = self._token_next(parent, start_token)
        prev_token = start_token
        table_name_tokens = list()
        join_tokens = list()
        while current_token and \
              not current_token.match(Tokens.Keyword, end_words) and \
              not isinstance(current_token, Types.Where):
            next_token = self._token_next(parent, current_token)
            if current_token.is_whitespace():
                pass
            elif isinstance(current_token, Types.IdentifierList):
                current_token = self._expression_token_unwind_hack(parent, current_token, prev_token)
                continue
            elif isinstance(current_token, Types.Identifier):
                parenthesis = filter(lambda t: isinstance(t, Types.Parenthesis), current_token.tokens)
                if parenthesis:
                    for p in parenthesis:
                        t = self._token_next(p, self._token_first(p))
                        if not t.match(Tokens.DML, 'SELECT'):
                            raise Exception("Invalid subselect statement")
                        self._select(p, t)
                else:
                    tablename = current_token.value.strip()
                    tablealias = current_token.get_name().strip()
                    if tablename == tablealias:
                        table_name_tokens.append(current_token)
                    else:
                        inject_table_view(current_token, tablename, tablealias)
            elif isinstance(current_token, Types.Parenthesis):
                t = self._token_next(current_token, self._token_first(current_token))
                if t.match(Tokens.DML, 'SELECT'):
                    identifier_token = self._token_next(parent, current_token)
                    as_token = None
                    if identifier_token.match(Tokens.Keyword, 'AS'):
                        as_token = identifier_token
                        identifier_token = self._token_next(parent, identifier_token)
                    if not isinstance(identifier_token, Types.Identifier):
                        raise Exception("Invalid subselect statement")
                    next_token = self._token_next(parent, identifier_token)
                    self._select(current_token, t)
                    if as_token:
                        self._token_delete(parent, as_token)
                    inject_table_alias(identifier_token, identifier_token.value)
            elif current_token.ttype == Tokens.Punctuation:
                if table_name_tokens:
                    next_token = self._token_next(parent, current_token)
                    table_name_tokens = process_table_name_tokens(table_name_tokens)
            elif current_token.match(Tokens.Keyword, ['JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER'] + self._join_statements):
                join_tokens.append(current_token.value.strip().upper())
                join = ' '.join(join_tokens)
                if join in self._join_statements:
                    join_tokens = list()
                    table_name_tokens = process_table_name_tokens(table_name_tokens)
                    next_token = self._select_join(parent,
                                                   current_token,
                                                   ['JOIN', 'LEFT', 'RIGHT', 'INNER', 'OUTER']
                                                    + self._join_statements
                                                    + self._from_end_words)
            elif current_token.ttype == Tokens.Keyword or \
                 current_token.ttype == Tokens.Token.Literal.Number.Integer:
                table_name_tokens.append(current_token)
            else:
                raise Exception("Failed to parse FROM table name")
            prev_token = current_token
            current_token = next_token
        if prev_token:
            process_table_name_tokens(table_name_tokens)
        return current_token

    def _select(self, parent, start_token, insert_table=None):
        token = self._token_next(parent, start_token)
        fields_token = self._token_next(parent, token) if token.match(Tokens.Keyword, ['ALL', 'DISTINCT']) else token
        current_token, field_lists = self._select_expression_tokens(parent, fields_token, ['FROM'] + self._from_end_words)
        def handle_insert_table(table_name):
            if insert_table and insert_table in self._translate_tables:
                if not field_lists or not field_lists[-1]:
                    raise Exception("Invalid SELECT field list")
                last_token = list(field_lists[-1][-1].flatten())[-1]
                for keyword in ["'", self._product_prefix, "'", ' ', ',']:
                    self._token_insert_after(last_token.parent, last_token, Types.Token(Tokens.Keyword, keyword))
            return
        table_name_callback = handle_insert_table if insert_table else None
        from_token = self._token_next_match(parent, start_token, Tokens.Keyword, 'FROM')
        if not from_token:
            # FROM not always required, example would be SELECT CURRVAL('"ticket_id_seq"')
            return current_token
        current_token = self._select_from(parent,
                                          from_token, self._from_end_words,
                                          table_name_callback=table_name_callback)
        if not current_token:
            return None
        while current_token:
            if isinstance(current_token, Types.Where) or \
               current_token.match(Tokens.Keyword, ['GROUP', 'HAVING', 'ORDER', 'LIMIT']):
                if isinstance(current_token, Types.Where):
                    self._where(parent, current_token)
                start_token = self._token_next(parent, current_token)
                next_token = self._token_next_match(parent,
                                                    start_token,
                                                    Tokens.Keyword,
                                                    self._from_end_words) if start_token else None
            elif current_token.match(Tokens.Keyword, ['UNION']):
                token = self._token_next(parent, current_token)
                if not token.match(Tokens.DML, 'SELECT'):
                    raise Exception("Invalid SELECT UNION statement")
                token = self._select(parent, current_token, insert_table=insert_table)
                next_token = self._token_next(parent, token) if token else None
            else:
                raise Exception("Unsupported SQL statement")
            current_token = next_token
        return current_token

    def _replace_table_entity_name(self, parent, token, table_name, entity_name=None):
        if not entity_name:
            entity_name = table_name
        next_token = self._token_next(parent, token)
        if not table_name in self._skip_tables + self._translate_tables:
            token_to_replace = parent.tokens[self._token_idx(parent, token)]
            if isinstance(token_to_replace, Types.Function):
                t = self._token_first(token_to_replace)
                if isinstance(t, Types.Identifier):
                    token_to_replace.tokens[self._token_idx(token_to_replace, t)] = Types.Token(Tokens.Keyword,
                                                                                                self._prefixed_table_entity_name(entity_name))
            elif isinstance(token_to_replace, Types.Identifier) or isinstance(token_to_replace, Types.Token):
                parent.tokens[self._token_idx(parent, token_to_replace)] = Types.Token(Tokens.Keyword,
                                                                                       self._prefixed_table_entity_name(entity_name))
            else:
                raise Exception("Internal error, invalid table entity token type")
        return next_token

    def _insert(self, parent, start_token):
        token = self._token_next(parent, start_token)
        if not token.match(Tokens.Keyword, 'INTO'):
            raise Exception("Invalid INSERT statement")
        def insert_extra_columns(tablename, columns_token):
            columns_present = []
            if tablename in self._translate_tables and \
               isinstance(columns_token, Types.Parenthesis):
                ptoken = self._token_first(columns_token)
                if not ptoken.match(Tokens.Punctuation, '('):
                    raise Exception("Invalid INSERT statement, expected parenthesis around columns")
                ptoken = self._token_next(columns_token, ptoken)
                last_token = ptoken
                while ptoken:
                    if isinstance(ptoken, Types.IdentifierList):
                        if not 'product' in columns_present \
                           and any(i.get_name() == 'product'
                                for i in ptoken.get_identifiers()
                                if isinstance(i, Types.Identifier)):
                            columns_present.append('product')
                        elif not 'id' in columns_present \
                             and tablename == 'ticket' \
                             and isinstance(ptoken, Types.IdentifierList) \
                             and any((t.ttype is None or t.is_keyword)
                                    and t.value == 'id'
                                    for t in ptoken.get_identifiers()):
                            columns_present.append('id')
                    last_token = ptoken
                    ptoken = self._token_next(columns_token, ptoken)
                if not last_token or \
                   not last_token.match(Tokens.Punctuation, ')'):
                    raise Exception("Invalid INSERT statement, unable to find column parenthesis end")

                columns_to_insert = []
                if not 'product' in columns_present:
                    columns_to_insert += [',', ' ', self._product_column]
                if self._id_calculated \
                   and tablename == 'ticket'\
                   and not 'id' in columns_present:
                    columns_to_insert += [',', ' ', 'id']
                for keyword in columns_to_insert:
                    self._token_insert_before(columns_token, last_token, Types.Token(Tokens.Keyword, keyword))
            return columns_present

        def insert_extra_column_values(tablename, ptoken, before_token,
                columns_present):
            if tablename in self._translate_tables:
                values_to_insert = []
                if not 'product' in columns_present:
                    values_to_insert += [',', "'", self._product_prefix, "'"]
                if self._id_calculated \
                   and tablename == 'ticket' \
                   and not 'id' in columns_present:
                    values_to_insert += [
                        ',', """COALESCE((SELECT MAX(id) FROM
                                           (SELECT * FROM ticket WHERE product='%s')
                                           AS subquery), 0)+1""" %
                             (self._product_prefix,)
                    ]
                for keyword in values_to_insert:
                    self._token_insert_before(ptoken, before_token, Types.Token(Tokens.Keyword, keyword))
            return

        tablename = None
        table_name_token = self._token_next(parent, token)
        columns_present = []
        if isinstance(table_name_token, Types.Function):
            token = self._token_first(table_name_token)
            if isinstance(token, Types.Identifier):
                tablename = token.get_name()
                columns_token = self._replace_table_entity_name(table_name_token, token, tablename)
                if columns_token.match(Tokens.Keyword, 'VALUES'):
                    token = columns_token
                else:
                    columns_present = insert_extra_columns(tablename, columns_token)
                    token = self._token_next(parent, table_name_token)
        else:
            tablename = table_name_token.value
            columns_token = self._replace_table_entity_name(parent, table_name_token, tablename)
            if columns_token.match(Tokens.Keyword, 'VALUES'):
                token = columns_token
            else:
                columns_present = insert_extra_columns(tablename, columns_token)
                token = self._token_next(parent, columns_token)

        if token.match(Tokens.Keyword, 'VALUES'):
            separators = [',', '(', ')']
            token = self._token_next(parent, token)
            while token:
                if isinstance(token, Types.Parenthesis):
                    ptoken = self._token_first(token)
                    if not ptoken.match(Tokens.Punctuation, '('):
                        raise Exception("Invalid INSERT statement")
                    last_token = ptoken
                    while ptoken:
                        if not ptoken.match(Tokens.Punctuation, separators) and \
                           not ptoken.match(Tokens.Keyword, separators) and \
                           not ptoken.is_whitespace():
                            ptoken = self._expression_token_unwind_hack(token, ptoken, self._token_prev(token, ptoken))
                            self._eval_expression_value(token, ptoken)
                        last_token = ptoken
                        ptoken = self._token_next(token, ptoken)
                    if not last_token or \
                       not last_token.match(Tokens.Punctuation, ')'):
                        raise Exception("Invalid INSERT statement, unable to find column value parenthesis end")
                    insert_extra_column_values(tablename, token, last_token, columns_present)
                elif not token.match(Tokens.Punctuation, separators) and\
                     not token.match(Tokens.Keyword, separators) and\
                     not token.is_whitespace():
                    raise Exception("Invalid INSERT statement, unable to parse VALUES section")
                token = self._token_next(parent, token)
        elif token.match(Tokens.DML, 'SELECT'):
            self._select(parent, token, insert_table=tablename)
        else:
            raise Exception("Invalid INSERT statement")
        return

    def _update_delete_where_limit(self, table_name, parent, start_token):
        if not start_token:
            return
        where_token = start_token if isinstance(start_token, Types.Where) \
                                  else self._token_next_by_instance(parent, start_token, Types.Where)
        if where_token:
            self._where(parent, where_token)
        if not table_name in self._translate_tables:
            return
        if where_token:
            keywords = [self._product_column, '=', "'", self._product_prefix, "'", ' ', 'AND', ' ']
            keywords.reverse()
            token = self._token_first(where_token)
            if not token.match(Tokens.Keyword, 'WHERE'):
                token = self._token_next_match(where_token, token, Tokens.Keyword, 'WHERE')
            if not token:
                raise Exception("Invalid UPDATE statement, failed to parse WHERE")
            for keyword in keywords:
                self._token_insert_after(where_token, token, Types.Token(Tokens.Keyword, keyword))
        else:
            keywords = ['WHERE', ' ', self._product_column, '=', "'", self._product_prefix, "'"]
            limit_token = self._token_next_match(parent, start_token, Tokens.Keyword, 'LIMIT')
            if limit_token:
                for keyword in keywords:
                    self._token_insert_before(parent, limit_token, Types.Token(Tokens.Keyword, keyword))
                self._token_insert_before(parent, limit_token, Types.Token(Tokens.Keyword, ' '))
            else:
                last_token = token = start_token
                while token:
                    last_token = token
                    token = self._token_next(parent, token)
                keywords.reverse()
                for keyword in keywords:
                    self._token_insert_after(parent, last_token, Types.Token(Tokens.Keyword, keyword))
        return

    def _get_entity_name_from_token(self, parent, token):
        tablename = None
        if isinstance(token, Types.Identifier):
            tablename = token.get_name()
        elif isinstance(token, Types.Function):
            token = self._token_first(token)
            if isinstance(token, Types.Identifier):
                tablename = token.get_name()
        elif isinstance(token, Types.Token):
            tablename = token.value
        return tablename

    def _update(self, parent, start_token):
        table_name_token = self._token_next(parent, start_token)
        tablename = self._get_entity_name_from_token(parent, table_name_token)
        if not tablename:
            raise Exception("Invalid UPDATE statement, expected table name")
        token = self._replace_table_entity_name(parent, table_name_token, tablename)
        set_token = self._token_next_match(parent, token, Tokens.Keyword, 'SET')
        if set_token:
            token = set_token
            while token and \
                  not isinstance(token, Types.Where) and \
                  not token.match(Tokens.Keyword, 'LIMIT'):
                if not token.match(Tokens.Keyword, 'SET') and \
                   not token.match(Tokens.Punctuation, ','):
                    raise Exception("Invalid UPDATE statement, failed to match separator")
                column_token = self._token_next(parent, token)
                if isinstance(column_token, Types.Comparison):
                    token = self._token_next(parent, column_token)
                    continue
                equals_token = self._token_next(parent, column_token)
                if not equals_token.match(Tokens.Token.Operator.Comparison, '='):
                    raise Exception("Invalid UPDATE statement, SET equals token mismatch")
                expression_token = self._token_next(parent, equals_token)
                expression_token = self._expression_token_unwind_hack(parent, expression_token, equals_token)
                self._eval_expression_value(parent, expression_token)
                token = self._token_next(parent, expression_token)
            start_token = token
        self._update_delete_where_limit(tablename, parent, start_token)
        return

    def _delete(self, parent, start_token):
        token = self._token_next(parent, start_token)
        if not token.match(Tokens.Keyword, 'FROM'):
            raise Exception("Invalid DELETE statement")
        table_name_token = self._token_next(parent, token)
        tablename = self._get_entity_name_from_token(parent, table_name_token)
        if not tablename:
            raise Exception("Invalid DELETE statement, expected table name")
        start_token = self._replace_table_entity_name(parent, table_name_token, tablename)
        self._update_delete_where_limit(tablename, parent, start_token)
        return

    def _create(self, parent, start_token):
        token = self._token_next(parent, start_token)
        if token.match(Tokens.Keyword, 'TEMPORARY'):
            token = self._token_next(parent, token)
        if token.match(Tokens.Keyword, 'TABLE'):
            token = self._token_next(parent, token)
            while token.match(Tokens.Keyword, ['IF', 'NOT', 'EXIST']) or \
                  token.is_whitespace():
                token = self._token_next(parent, token)
            table_name = self._get_entity_name_from_token(parent, token)
            if not table_name:
                raise Exception("Invalid CREATE TABLE statement, expected table name")

            as_token = self._token_next_match(parent, token,
                                              Tokens.Keyword, 'AS')
            self._replace_table_entity_name(parent, token, table_name)

            if as_token:
                select_token = self._token_next_match(parent, as_token,
                                                      Tokens.DML, 'SELECT')
                if select_token:
                    return self._select(parent, select_token)
        elif token.match(Tokens.Keyword, ['UNIQUE', 'INDEX']):
            if token.match(Tokens.Keyword, 'UNIQUE'):
                token = self._token_next(parent, token)
            if token.match(Tokens.Keyword, 'INDEX'):
                index_token = self._token_next(parent, token)
                index_name = self._get_entity_name_from_token(parent, index_token)
                if not index_name:
                    raise Exception("Invalid CREATE INDEX statement, expected index name")
                on_token = self._token_next_match(parent, index_token, Tokens.Keyword, 'ON')
                if not on_token:
                    raise Exception("Invalid CREATE INDEX statement, expected ON specifier")
                table_name_token = self._token_next(parent, on_token)
                table_name = self._get_entity_name_from_token(parent, table_name_token)
                if not table_name:
                    raise Exception("Invalid CREATE INDEX statement, expected table name")
                self._replace_table_entity_name(parent, table_name_token, table_name)
                self._replace_table_entity_name(parent, index_token, table_name, entity_name=index_name)
        return

    def _alter(self, parent, start_token):
        token = self._token_next(parent, start_token)
        if token.match(Tokens.Keyword, 'TABLE'):
            token = self._token_next(parent, token)
            table_name = self._get_entity_name_from_token(parent, token)
            if not table_name:
                raise Exception("Invalid CREATE TABLE statement, expected table name")
            token = self._replace_table_entity_name(parent, token, table_name)
            if token.match(Tokens.Keyword.DDL, ['ADD', 'DROP']) or\
               token.match(Tokens.Keyword, ['ADD', 'DROP']):
                token = self._token_next(parent, token)
                if token.match(Tokens.Keyword, 'CONSTRAINT'):
                    token = self._token_next(parent, token)
                    constraint_name = self._get_entity_name_from_token(parent, token)
                    if not constraint_name:
                        raise Exception("Invalid ALTER TABLE statement, expected constraint name")
                    self._replace_table_entity_name(parent, token, table_name, constraint_name)
        return

    def _drop(self, parent, start_token):
        token = self._token_next(parent, start_token)
        if token.match(Tokens.Keyword, 'TABLE'):
            token = self._token_next(parent, token)
            while token.match(Tokens.Keyword, ['IF', 'EXIST']) or\
                  token.is_whitespace():
                token = self._token_next(parent, token)
            table_name = self._get_entity_name_from_token(parent, token)
            if not table_name:
                raise Exception("Invalid DROP TABLE statement, expected table name")
            self._replace_table_entity_name(parent, token, table_name)
        return

    def translate(self, sql):
        dml_handlers = {'SELECT': self._select,
                        'INSERT': self._insert,
                        'UPDATE': self._update,
                        'DELETE': self._delete,
                        }
        ddl_handlers = {'CREATE': self._create,
                        'ALTER': self._alter,
                        'DROP': self._drop,
                        }
        try:
            formatted_sql = lambda sql: sql.to_unicode()
            sql_statement = sqlparse.parse(sql)[0]
            if '_' in sql:
                self._sqlparse_underline_hack(sql_statement)
            t = sql_statement.token_first()
            if t.match(Tokens.DML, dml_handlers.keys()):
                dml_handlers[t.normalized](sql_statement, t)
                sql = formatted_sql(sql_statement)
            elif t.match(Tokens.DDL, ddl_handlers.keys()):
                ddl_handlers[t.normalized](sql_statement, t)
                sql = formatted_sql(sql_statement)
            else:
                pass
        except Exception, ex:
            raise Exception("Failed to translate SQL '%s', exception '%s'" % (sql, ex.message))
        return sql

########NEW FILE########
__FILENAME__ = env
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import os.path
from urlparse import urlsplit

from trac.config import BoolOption, ConfigSection, Option
from trac.core import Component, ComponentManager, ExtensionPoint, implements, \
                      ComponentMeta
from trac.db.api import TransactionContextManager, QueryContextManager, \
                        DatabaseManager
from trac.perm import IPermissionRequestor, PermissionSystem
from trac.util import get_pkginfo, lazy
from trac.util.compat import sha1
from trac.util.text import to_unicode, unicode_quote
from trac.versioncontrol import RepositoryManager
from trac.web.href import Href

from multiproduct.api import MultiProductSystem, ISupportMultiProductEnvironment
from multiproduct.cache import lru_cache, default_keymap
from multiproduct.config import Configuration
from multiproduct.dbcursor import BloodhoundConnectionWrapper, BloodhoundIterableCursor, \
                                  ProductEnvContextManager
from multiproduct.model import Product

import trac.env


class ComponentEnvironmentContext(object):
    def __init__(self, env, component):
        self._env = env
        self._component = component

    def __enter__(self):
        self._old_env = self._component.env
        self._env.component_activated(self._component)
        return self

    def __exit__(self, type, value, traceback):
        self._old_env.component_activated(self._component)


class Environment(trac.env.Environment):
    """Bloodhound environment manager

    This class is intended as monkey-patch replacement for
    trac.env.Environment. Required database access methods/properties
    are replaced to provide global view of the database in contrast
    to ProductEnvironment that features per-product view of the database
    (in the context of selected product).

        :param path:   the absolute path to the Trac environment
        :param create: if `True`, the environment is created and
                       populated with default data; otherwise, the
                       environment is expected to already exist.
        :param options: A list of `(section, name, value)` tuples that
                        define configuration options
    """

    multi_product_support_components = ExtensionPoint(ISupportMultiProductEnvironment)

    @property
    def global_setup_participants(self):
        """If multi product schema is enabled, return only setup participants
        that implement ISupportMultiProduct. Otherwise, all setup participants
        are considered global.
        """
        if self._multiproduct_schema_enabled:
            all_participants = self.setup_participants
            multiproduct_aware = set(self.multi_product_support_components)
            priority = lambda x: 0 if isinstance(x, MultiProductSystem) else 10

            return sorted(
                (c for c in all_participants if c in multiproduct_aware),
                key=priority
            )
        else:
            return self.setup_participants

    @property
    def product_setup_participants(self):
        """If multi product schema is enabled, return setup participants that
        need to be instantiated for each product env. Otherwise, return an
        empty list.
        """
        if self._multiproduct_schema_enabled:
            all_participants = self.setup_participants
            multiproduct_aware = set(self.multi_product_support_components)
            return [
                c for c in all_participants if c not in multiproduct_aware
            ]
        else:
            return []

    def __init__(self, path, create=False, options=[]):
        # global environment w/o parent, set these two before super.__init__
        # as database access can take place within trac.env.Environment
        self.parent = None
        self.product = None

        # `trac.env.Environment.__init__` is not invoked as creation is handled differently
        # from base implementation - different setup participants are invoked when creating
        # global environment.
        ComponentManager.__init__(self)

        self.path = path
        self.systeminfo = []
        self._href = self._abs_href = None

        self._multiproduct_schema_enabled = False

        if create:
            self.create(options)
        else:
            self.verify()
            self.setup_config()

        # invoke `IEnvironmentSetupParticipant.environment_created` for all
        # global setup participants
        if create:
            for participant in self.global_setup_participants:
                with ComponentEnvironmentContext(self, participant):
                    participant.environment_created()

    @property
    def db_query(self):
        return ProductEnvContextManager(super(Environment, self).db_query, self) \
            if self._multiproduct_schema_enabled else self.db_direct_query

    @property
    def db_transaction(self):
        return ProductEnvContextManager(super(Environment, self).db_transaction, self) \
            if self._multiproduct_schema_enabled else self.db_direct_transaction

    @property
    def db_direct_query(self):
        return ProductEnvContextManager(super(Environment, self).db_query)

    @property
    def db_direct_transaction(self):
        return ProductEnvContextManager(super(Environment, self).db_transaction)

    def all_product_envs(self):
        return [ProductEnvironment(self, product) for product in Product.select(self)]

    def needs_upgrade(self):
        """Return whether the environment needs to be upgraded."""
        def needs_upgrade_in_env(participant, env):
            with ComponentEnvironmentContext(env, participant):
                with env.db_query as db:
                    if participant.environment_needs_upgrade(db):
                        self.log.warn("component %s.%s requires environment upgrade in environment %s...",
                                      participant.__module__, participant.__class__.__name__,
                                      env)
                        return True
        if any(needs_upgrade_in_env(participant, self)
               for participant in self.global_setup_participants):
            return True

        # until schema is multi product aware, product environments can't (and shouldn't) be
        # instantiated
        if self._multiproduct_schema_enabled:
            if any(needs_upgrade_in_env(participant, env)
                   for env in [self] + self.all_product_envs()
                   for participant in self.product_setup_participants):
                return True
        return False

    def upgrade(self, backup=False, backup_dest=None):
        """Upgrade database.

        :param backup: whether or not to backup before upgrading
        :param backup_dest: name of the backup file
        :return: whether the upgrade was performed
        """
        def upgrader_for_env(participant, env):
            with ComponentEnvironmentContext(env, participant):
                with env.db_query as db:
                    if participant.environment_needs_upgrade(db):
                        self.log.info(
                            "%s.%s needs upgrade in environment %s...",
                            participant.__module__,
                            participant.__class__.__name__,
                            env)
                        return env, participant

        def upgraders_for_product_envs():
            upgraders = (upgrader_for_env(participant, env)
                         for participant in self.product_setup_participants
                         for env in [self] + self.all_product_envs())
            return [u for u in upgraders if u]

        # first enumerate components that are multi product aware and
        # require upgrade in global environment
        global_upgraders = [upgrader_for_env(participant, self)
                            for participant in self.global_setup_participants]
        global_upgraders = [u for u in global_upgraders if u]
        product_upgraders = None
        if not global_upgraders and self._multiproduct_schema_enabled:
            # if no upgrades required in global environment, enumerate
            # required upgrades for product environments
            product_upgraders = upgraders_for_product_envs()

        if not global_upgraders + (product_upgraders or []):
            return False

        if backup:
            try:
                self.backup(backup_dest)
            except Exception, e:
                raise trac.env.BackupError(e)

        def execute_upgrades(upgraders_list):
            for env, participant in upgraders_list:
                self.log.info("%s.%s upgrading in environment %s...",
                              participant.__module__,
                              participant.__class__.__name__,
                              env)
                with ComponentEnvironmentContext(env, participant):
                    with env.db_transaction as db:
                        participant.upgrade_environment(db)
                # Database schema may have changed, so close all connections
                DatabaseManager(env).shutdown()

        # execute global upgrades first, product environment upgrades next
        execute_upgrades(global_upgraders)
        if product_upgraders is None and self._multiproduct_schema_enabled:
            product_upgraders = upgraders_for_product_envs()
        if product_upgraders:
            execute_upgrades(product_upgraders)
        return True

    def get_version(self, db=None, initial=False):
        """Return the current version of the database.  If the
        optional argument `initial` is set to `True`, the version of
        the database used at the time of creation will be returned.
        """
        rows = self.db_direct_query("""
                SELECT value FROM system WHERE name='%sdatabase_version'
                """ % ('initial_' if initial else ''))
        return (rows and int(rows[0][0])) or 0

    def enable_multiproduct_schema(self, enable=True):
        self._multiproduct_schema_enabled = enable
        BloodhoundIterableCursor.cache_reset()

# replace trac.env.Environment with Environment
trac.env.Environment = Environment


# this must follow the monkey patch (trac.env.Environment) above, otherwise
# trac.test.EnvironmentStub will not be correct as the class will derive from
# not replaced trac.env.Environment
import trac.test

class EnvironmentStub(trac.test.EnvironmentStub):
    """Bloodhound test environment stub

    This class replaces trac.test.EnvironmentStub and extends it with parent
    and product properties (same case as with the Environment).
    """
    def __init__(self, default_data=False, enable=None, disable=None,
                 path=None, destroying=False):
        self.parent = None
        self.product = None

        self._multiproduct_schema_enabled = False

        super(EnvironmentStub, self).__init__(default_data=False,
                                              enable=enable, disable=disable,
                                              path=path, destroying=destroying)
        if default_data:
            self.reset_db(default_data)

    @staticmethod
    def enable_component_in_config(env, cls):
        """Keep track of enabled state in configuration as well
        during test runs. This is closer to reality than
        inherited `enable_component` method.
        """
        env.config['components'].set(env._component_name(cls), 'enabled')
        env.enabled.clear()
        env.components.pop(cls, None)
        try:
            del env._rules
        except AttributeError:
            pass
        # FIXME: Shall we ?
        #env.config.save()

    @staticmethod
    def disable_component_in_config(env, component):
        """Keep track of disabled state in configuration as well
        during test runs. This is closer to reality than
        inherited `disable_component` method.
        """
        if isinstance(component, type):
            cls = component
        else:
            cls = component.__class__
        env.config['components'].set(env._component_name(cls), 'disabled')
        env.enabled.clear()
        env.components.pop(cls, None)
        try:
            del env._rules
        except AttributeError:
            pass
        env.config.save()

    def reset_db(self, default_data=None):
        multiproduct_schema = self._multiproduct_schema_enabled
        self._multiproduct_schema_enabled = False
        try:
            super(EnvironmentStub, self).reset_db(default_data=default_data)
        finally:
            self._multiproduct_schema_enabled = multiproduct_schema

# replace trac.test.EnvironmentStub
trac.test.EnvironmentStub = EnvironmentStub


class ProductEnvironment(Component, ComponentManager):
    """Bloodhound product-aware environment manager.

    Bloodhound encapsulates access to product resources stored inside a
    Trac environment via product environments. They are compatible lightweight
    irepresentations of top level environment.

    Product environments contain among other things:

    * configuration key-value pairs stored in the database,
    * product-aware clones of the wiki and ticket attachments files,

    Product environments do not have:

    * product-specific templates and plugins,
    * a separate database
    * active participation in database upgrades and other setup tasks

    See https://issues.apache.org/bloodhound/wiki/Proposals/BEP-0003
    """

    class __metaclass__(ComponentMeta):

        def select_global_env(f):
            """Replaces env with env.parent where appropriate"""
            # Keep the signature of __call__ method
            def __call__(self, env, *args, **kwargs):
                g_env = env.parent if isinstance(env,
                                                 ProductEnvironment) else env
                return f(self, g_env, *args, **kwargs)
            return __call__

        def product_env_keymap(args, kwds, kwd_mark):
            # Remove meta-reference to self (i.e. product env class)
            args = args[1:]
            try:
                product = kwds['product']
            except KeyError:
                # Product provided as positional argument
                if isinstance(args[1], Product):
                    args = (args[0], args[1].prefix) + args[2:]
            else:
                # Product supplied as keyword argument
                if isinstance(product, Product):
                    kwds['product'] = product.prefix
            return default_keymap(args, kwds, kwd_mark)

        @select_global_env
        @lru_cache(maxsize=100, keymap=product_env_keymap)
        def __call__(self, *args, **kwargs):
            """Return an existing instance if there is a hit
            in the global LRU cache, otherwise create a new instance.
            """
            return ComponentMeta.__call__(self, *args, **kwargs)

        del product_env_keymap, select_global_env

    implements(trac.env.ISystemInfoProvider, IPermissionRequestor)

    setup_participants = ExtensionPoint(trac.env.IEnvironmentSetupParticipant)
    multi_product_support_components = ExtensionPoint(ISupportMultiProductEnvironment)

    @property
    def product_setup_participants(self):
        return [
            component for component in self.setup_participants
            if component not in self.multi_product_support_components
        ]

    components_section = ConfigSection('components',
        """This section is used to enable or disable components
        provided by plugins, as well as by Trac itself.

        See also: TracIni , TracPlugins
        """)

    @property
    def shared_plugins_dir():
        """Product environments may not add plugins.
        """
        return ''

    _base_url = Option('trac', 'base_url', '',
        """Reference URL for the Trac deployment.

        This is the base URL that will be used when producing
        documents that will be used outside of the web browsing
        context, like for example when inserting URLs pointing to Trac
        resources in notification e-mails.""", doc_domain='multiproduct')

    @property
    def base_url(self):
        base_url = self._base_url
        if base_url == self.parent.base_url:
            return ''
        return base_url

    _base_url_for_redirect = BoolOption('trac', 'use_base_url_for_redirect',
            False,
        """Optionally use `[trac] base_url` for redirects.

        In some configurations, usually involving running Trac behind
        a HTTP proxy, Trac can't automatically reconstruct the URL
        that is used to access it. You may need to use this option to
        force Trac to use the `base_url` setting also for
        redirects. This introduces the obvious limitation that this
        environment will only be usable when accessible from that URL,
        as redirects are frequently used. ''(since 0.10.5)''""",
                                        doc_domain='multiproduct')

    @property
    def project_name(self):
        """Name of the product.
        """
        return self.product.name

    @property
    def project_description(self):
        """Short description of the product.
        """
        return self.product.description

    @property
    def project_url(self):
        """URL of the main project web site, usually the website in
        which the `base_url` resides. This is used in notification
        e-mails.
        """
        # FIXME: Should products have different values i.e. config option ?
        return self.parent.project_url

    project_admin = Option('project', 'admin', '',
        """E-Mail address of the product's leader / administrator.""",
                           doc_domain='multiproduct')

    @property
    def project_footer(self):
        """Page footer text (right-aligned).
        """
        # FIXME: Should products have different values i.e. config option ?
        return self.parent.project_footer

    project_icon = Option('project', 'icon', 'common/trac.ico',
        """URL of the icon of the product.""", doc_domain='multiproduct')

    log_type = Option('logging', 'log_type', 'inherit',
        """Logging facility to use.

        Should be one of (`inherit`, `none`, `file`, `stderr`,
        `syslog`, `winlog`).""", doc_domain='multiproduct')

    log_file = Option('logging', 'log_file', 'trac.log',
        """If `log_type` is `file`, this should be a path to the
        log-file.  Relative paths are resolved relative to the `log`
        directory of the environment.""", doc_domain='multiproduct')

    log_level = Option('logging', 'log_level', 'DEBUG',
        """Level of verbosity in log.

        Should be one of (`CRITICAL`, `ERROR`, `WARN`, `INFO`, `DEBUG`).""",
                       doc_domain='multiproduct')

    log_format = Option('logging', 'log_format', None,
        """Custom logging format.

        If nothing is set, the following will be used:

        Trac[$(module)s] $(levelname)s: $(message)s

        In addition to regular key names supported by the Python
        logger library (see
        http://docs.python.org/library/logging.html), one could use:

        - $(path)s     the path for the current environment
        - $(basename)s the last path component of the current environment
        - $(project)s  the project name

        Note the usage of `$(...)s` instead of `%(...)s` as the latter form
        would be interpreted by the ConfigParser itself.

        Example:
        `($(thread)d) Trac[$(basename)s:$(module)s] $(levelname)s: $(message)s`

        ''(since 0.10.5)''""", doc_domain='multiproduct')

    def __init__(self, env, product, create=False):
        """Initialize the product environment.

        :param env:     the global Trac environment
        :param product: product prefix or an instance of
                        multiproduct.model.Product
        """
        if not isinstance(env, trac.env.Environment):
            cls = self.__class__
            raise TypeError("Initializer must be called with " \
                "trac.env.Environment instance as first argument " \
                "(got %s instance instead)" %
                         (cls.__module__ + '.' + cls.__name__, ))

        ComponentManager.__init__(self)

        if isinstance(product, Product):
            if product._env is not env:
                raise ValueError("Product's environment mismatch")
        elif isinstance(product, basestring):
            products = Product.select(env, where={'prefix': product})
            if len(products) == 1 :
                product = products[0]
            else:
                env.log.debug("Products for '%s' : %s",
                              product, products)
                raise LookupError("Missing product %s" % (product,))

        self.parent = env
        self.product = product
        self.systeminfo = []

        self.setup_config()

        # when creating product environment, invoke `IEnvironmentSetupParticipant.environment_created`
        # for all setup participants that don't support multi product environments
        if create:
            for participant in self.product_setup_participants:
                with ComponentEnvironmentContext(self, participant):
                    participant.environment_created()

    def __getitem__(self, cls):
        if issubclass(cls, trac.env.Environment):
            return self.parent
        elif cls is self.__class__:
            return self
        else:
            return ComponentManager.__getitem__(self, cls)

    def __getattr__(self, attrnm):
        """Forward attribute access request to parent environment.

        Initially this will affect the following members of
        `trac.env.Environment` class:

        system_info_providers, secure_cookies, project_admin_trac_url,
        get_system_info, get_version, get_templates_dir, get_templates_dir,
        get_log_dir, backup
        """
        try:
            if attrnm in ('parent', '_rules'):
                raise AttributeError
            return getattr(self.parent, attrnm)
        except AttributeError:
            raise AttributeError("'%s' object has no attribute '%s'" %
                    (self.__class__.__name__, attrnm))

    def __repr__(self):
        return "<%s %s at %s>" % (self.__class__.__name__,
                                 repr(self.product.prefix),
                                 hex(id(self)))

    @lazy
    def path(self):
        """The subfolder `./products/<product prefix>` relative to the
        top-level directory of the global environment will be the root of
        product file system area.
        """
        folder = os.path.join(self.parent.path, 'products', self.product.prefix)
        if not os.path.exists(folder):
            os.makedirs(folder)
        return folder

    # IPermissionRequestor methods
    def get_permission_actions(self):
        """Implement the product-specific `PRODUCT_ADMIN` meta permission.
        """
        actions = set()
        permsys = PermissionSystem(self)
        for requestor in permsys.requestors:
            if requestor is not self and requestor is not permsys:
                for action in requestor.get_permission_actions() or []:
                    if isinstance(action, tuple):
                        actions.add(action[0])
                    else:
                        actions.add(action)
        # PermissionSystem's method was not invoked
        actions.add('EMAIL_VIEW')
        # FIXME: should not be needed, JIC better double check
        actions.discard('TRAC_ADMIN')
        return [('PRODUCT_ADMIN', list(actions))]

    # ISystemInfoProvider methods

    # Same as parent environment's . Avoid duplicated code
    component_activated = trac.env.Environment.component_activated.im_func
    _component_name = trac.env.Environment._component_name.im_func
    _component_rules = trac.env.Environment._component_rules
    enable_component = trac.env.Environment.enable_component.im_func
    get_known_users = trac.env.Environment.get_known_users.im_func
    get_repository = trac.env.Environment.get_repository.im_func

    is_component_enabled_local = trac.env.Environment.is_component_enabled.im_func

    def is_enabled(self, cls):
        """Return whether the given component class is enabled."""
        modtime = max(self.config.get_lock_file_mtime(),
                      self.config._lastmtime)
        if modtime > self._config_mtime:
            self.enabled.clear()
            try:
                del self._rules
            except AttributeError:
                pass
            # FIXME : Improve cache hits by tracking global env last mtime
            self.parent.enabled.clear()
            try:
                del self.parent._rules
            except AttributeError:
                pass
        self._config_mtime = modtime
        return super(ProductEnvironment, self).is_enabled(cls)

    def is_component_enabled(self, cls):
        """Implemented to only allow activation of components already
        activated in the global environment that are in turn not disabled in
        the configuration.

        This is called by the `ComponentManager` base class when a
        component is about to be activated. If this method returns
        `False`, the component does not get activated. If it returns
        `None`, the component only gets activated if it is located in
        the `plugins` directory of the environment.
        """
        if cls is self.__class__:
            # Prevent lookups in parent env ... will always fail
            return True
        # FIXME : Maybe checking for ComponentManager is too drastic
        elif issubclass(cls, ComponentManager):
            # Avoid clashes with overridden Environment's options
            return False
        elif self.parent[cls] is None:
            return False
        return self.is_component_enabled_local(cls)

    def get_db_cnx(self):
        """Return a database connection from the connection pool

        :deprecated: Use :meth:`db_transaction` or :meth:`db_query` instead

        `db_transaction` for obtaining the `db` database connection
        which can be used for performing any query
        (SELECT/INSERT/UPDATE/DELETE)::

           with env.db_transaction as db:
               ...


        `db_query` for obtaining a `db` database connection which can
        be used for performing SELECT queries only::

           with env.db_query as db:
               ...
        """
        return BloodhoundConnectionWrapper(self.parent.get_db_cnx(), self)

    @property
    def db_exc(self):
        """Return an object (typically a module) containing all the
        backend-specific exception types as attributes, named
        according to the Python Database API
        (http://www.python.org/dev/peps/pep-0249/).

        To catch a database exception, use the following pattern::

            try:
                with env.db_transaction as db:
                    ...
            except env.db_exc.IntegrityError, e:
                ...
        """
        # exception types same as in global environment
        return self.parent.db_exc

    def with_transaction(self, db=None):
        """Decorator for transaction functions :deprecated:
        """
        raise NotImplementedError('Deprecated method')

    def get_read_db(self):
        """Return a database connection for read purposes :deprecated:

        See `trac.db.api.get_read_db` for detailed documentation.
        """
        return BloodhoundConnectionWrapper(self.parent.get_read_db(), self)

    @property
    def db_query(self):
        """Return a context manager which can be used to obtain a
        read-only database connection.

        Example::

            with env.db_query as db:
                cursor = db.cursor()
                cursor.execute("SELECT ...")
                for row in cursor.fetchall():
                    ...

        Note that a connection retrieved this way can be "called"
        directly in order to execute a query::

            with env.db_query as db:
                for row in db("SELECT ..."):
                    ...

        If you don't need to manipulate the connection itself, this
        can even be simplified to::

            for row in env.db_query("SELECT ..."):
                ...

        :warning: after a `with env.db_query as db` block, though the
          `db` variable is still available, you shouldn't use it as it
          might have been closed when exiting the context, if this
          context was the outermost context (`db_query` or
          `db_transaction`).
        """
        return ProductEnvContextManager(QueryContextManager(self.parent), self)

    @property
    def db_transaction(self):
        """Return a context manager which can be used to obtain a
        writable database connection.

        Example::

            with env.db_transaction as db:
                cursor = db.cursor()
                cursor.execute("UPDATE ...")

        Upon successful exit of the context, the context manager will
        commit the transaction. In case of nested contexts, only the
        outermost context performs a commit. However, should an
        exception happen, any context manager will perform a rollback.

        Like for its read-only counterpart, you can directly execute a
        DML query on the `db`::

            with env.db_transaction as db:
                db("UPDATE ...")

        If you don't need to manipulate the connection itself, this
        can also be simplified to::

            env.db_transaction("UPDATE ...")

        :warning: after a `with env.db_transaction` as db` block,
          though the `db` variable is still available, you shouldn't
          use it as it might have been closed when exiting the
          context, if this context was the outermost context
          (`db_query` or `db_transaction`).
        """
        return ProductEnvContextManager(TransactionContextManager(self.parent), self)

    def shutdown(self, tid=None):
        """Close the environment."""
        RepositoryManager(self).shutdown(tid)
        # FIXME: Shared DB so IMO this should not happen ... at least not here
        #DatabaseManager(self).shutdown(tid)
        if tid is None:
            self.log.removeHandler(self._log_handler)
            self._log_handler.flush()
            self._log_handler.close()
            del self._log_handler

    def create(self, options=[]):
        """Placeholder for compatibility when trying to create the basic
        directory structure of the environment, etc ...

        This method does nothing at all.
        """
        # TODO: Handle options args

    def setup_config(self):
        """Load the configuration object.
        """
        import trac.config

        parent_path = MultiProductSystem(self.parent).product_config_parent
        if parent_path and os.path.isfile(parent_path):
            parents = [trac.config.Configuration(parent_path)]
        else:
            parents = [self.parent.config]
        self.config = Configuration(self.parent, self.product.prefix, parents)
        self._config_mtime = 0
        self.setup_log()

    def setup_log(self):
        """Initialize the logging sub-system."""
        from trac.log import logger_handler_factory
        logtype = self.log_type
        logfile = self.log_file
        format = self.log_format

        self.parent.log.debug("Log type '%s' for product '%s'",
                logtype, self.product.prefix)

        # Force logger inheritance on identical configuration
        if (logtype, logfile, format) == (self.parent.log_type,
                self.parent.log_file, self.parent.log_format):
            logtype = 'inherit'

        if logtype == 'inherit':
            self.log = self.parent.log
            self._log_handler = self.parent._log_handler
            self.parent.log.info("Inheriting parent logger for product '%s'",
                    self.product.prefix)
        else:
            if logtype == 'file' and not os.path.isabs(logfile):
                logfile = os.path.join(self.get_log_dir(), logfile)
            logid = 'Trac.%s.%s' % \
                    (sha1(self.parent.path).hexdigest(), self.product.prefix)
            if format:
                format = format.replace('$(', '%(') \
                         .replace('%(path)s', self.path) \
                         .replace('%(basename)s', os.path.basename(self.path)) \
                         .replace('%(project)s', self.project_name)
            self.log, self._log_handler = logger_handler_factory(
                logtype, logfile, self.log_level, logid, format=format)

        from trac import core, __version__ as VERSION
        self.log.info('-' * 32 +
                        ' product %s environment startup [Trac %s] ' +
                        '-' * 32,
                      self.product.prefix,
                      get_pkginfo(core).get('version', VERSION))

    def needs_upgrade(self):
        """Return whether the environment needs to be upgraded."""
        # Upgrades are handled by global environment
        return False

    def upgrade(self, backup=False, backup_dest=None):
        """Upgrade database.

        :param backup: whether or not to backup before upgrading
        :param backup_dest: name of the backup file
        :return: whether the upgrade was performed
        """
        # Upgrades handled by global environment
        return True

    @lazy
    def href(self):
        """The application root path"""
        return Href(urlsplit(self.abs_href.base).path)

    @lazy
    def abs_href(self):
        """The application URL"""
        if not self.base_url:
            urlpattern = MultiProductSystem(self.parent).product_base_url
            if not urlpattern:
                self.log.warn("product_base_url option not set in "
                              "configuration, generated links may be "
                              "incorrect")
                urlpattern = 'products/$(prefix)s'
            envname = os.path.basename(self.parent.path)
            prefix = unicode_quote(self.product.prefix, safe="")
            name = unicode_quote(self.product.name, safe="")
            url = urlpattern.replace('$(', '%(') \
                            .replace('%(envname)s', envname) \
                            .replace('%(prefix)s', prefix) \
                            .replace('%(name)s', name)
            if urlsplit(url).netloc:
                #  Absolute URLs
                _abs_href = Href(url)
            else:
                # Relative URLs
                parent_href = Href(self.parent.abs_href(),
                                   path_safe="/!~*'()%",
                                   query_safe="!~*'()%")
                _abs_href = Href(parent_href(url))
        else:
            _abs_href = Href(self.base_url)
        return _abs_href

    # Multi-product API extensions

    @classmethod
    def lookup_global_env(cls, env):
        return env.parent if isinstance(env, ProductEnvironment) else env

    @classmethod
    def lookup_env(cls, env, prefix=None, name=None):
        """Instantiate environment according to product prefix or name

        @throws LookupError if no product matches neither prefix nor name
        """
        if isinstance(env, ProductEnvironment):
            global_env = env.parent
        else:
            global_env = env

        # FIXME: Update if multiproduct.dbcursor.GLOBAL_PRODUCT != ''
        if not prefix and not name:
            return global_env
        elif isinstance(env, ProductEnvironment) and \
                env.product.prefix == prefix:
            return env
        if prefix:
            try:
                return ProductEnvironment(global_env, prefix)
            except LookupError:
                if not name:
                    raise
        if name:
            # Lookup product by name
            products = Product.select(global_env, where={'name' : name})
            if products:
                return ProductEnvironment(global_env, products[0])
            else:
                raise LookupError("Missing product '%s'" % (name,))
        else:
            raise LookupError("Mising product '%s'" % (prefix or name,))

    @classmethod
    def resolve_href(cls, to_env, at_env):
        """Choose absolute or relative href when generating links to
        a product (or global) environment.

        @param at_env:        href expansion is taking place in the
                              scope of this environment
        @param to_env:        generated URLs point to resources in
                              this environment
        """
        at_href = at_env.abs_href()
        target_href = to_env.abs_href()
        if urlsplit(at_href)[1] == urlsplit(target_href)[1]:
            return to_env.href
        else:
            return to_env.abs_href


lookup_product_env = ProductEnvironment.lookup_env
resolve_product_href = ProductEnvironment.resolve_href

# Override product-specific options
from multiproduct.config import ProductPermissionPolicyOption
PermissionSystem.policies.__class__ = ProductPermissionPolicyOption

########NEW FILE########
__FILENAME__ = hooks
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

# these imports monkey patch classes required to enable
# multi product support

import re

from trac.hooks import EnvironmentFactoryBase, RequestFactoryBase
from trac.web.href import Href
from trac.web.main import RequestWithSession

import multiproduct.env
import multiproduct.dbcursor
import multiproduct.ticket.batch
import multiproduct.ticket.query
import multiproduct.versioncontrol

PRODUCT_RE = re.compile(r'^/products(?:/(?P<pid>[^/]*)(?P<pathinfo>.*))?')


class MultiProductEnvironmentFactory(EnvironmentFactoryBase):
    def open_environment(self, environ, env_path, global_env, use_cache=False):
        environ.setdefault('SCRIPT_NAME', '')  # bh:ticket:594

        env = pid = product_path = None
        path_info = environ.get('PATH_INFO')
        if not path_info:
            return env
        m = PRODUCT_RE.match(path_info)
        if m:
            pid = m.group('pid')
            product_path = m.group('pathinfo') or ''

        def create_product_env(product_prefix, script_name, path_info):
            if not global_env._abs_href:
                # make sure global environment absolute href is set before
                # instantiating product environment. This would normally
                # happen from within trac.web.main.dispatch_request
                req = RequestWithSession(environ, None)
                global_env._abs_href = req.abs_href
            try:
                env = multiproduct.env.ProductEnvironment(global_env,
                                                          product_prefix)
            except LookupError:
                # bh:ticket:561 - Display product list and warning message
                env = global_env
            else:
                # shift WSGI environment to the left
                environ['SCRIPT_NAME'] = script_name
                environ['PATH_INFO'] = path_info
            return env

        if pid and not (product_path in ('', '/') and
                        environ.get('QUERY_STRING')):
            env = create_product_env(pid,
                                     environ['SCRIPT_NAME'] + '/products/' +
                                     pid, product_path)
            env.config.parse_if_needed()

        return env


class ProductizedHref(Href):
    PATHS_NO_TRANSFORM = ['chrome', 'login', 'logout', 'prefs', 'products',
                          'register',  'reset_password', 'verify_email']
    STATIC_PREFIXES = ['css/', 'img/', 'js/']

    def __init__(self, global_href, base):
        self.super = super(ProductizedHref, self)
        self.super.__init__(base)
        self._global_href = global_href

    def __call__(self, *args, **kwargs):
        if args and isinstance(args[0], basestring):
            if args[0] in self.PATHS_NO_TRANSFORM or \
                    (len(args) == 1 and args[0] == 'admin') or \
                    filter(lambda x: args[0].startswith(x),
                           self.STATIC_PREFIXES):
                return self._global_href(*args, **kwargs)
        return self.super.__call__(*args, **kwargs)


class ProductRequestWithSession(RequestWithSession):
    def __init__(self, env, environ, start_response):
        super(ProductRequestWithSession, self).__init__(environ, start_response)
        self.base_url = env.base_url
        if isinstance(env, multiproduct.env.ProductEnvironment):
            self.href = ProductizedHref(env.parent.href, env.href.base)
            self.abs_href = ProductizedHref(env.parent.abs_href,
                                            env.abs_href.base)


class ProductRequestFactory(RequestFactoryBase):
    def create_request(self, env, environ, start_response):
        return ProductRequestWithSession(env, environ, start_response) \
               if env else RequestWithSession(environ, start_response)

########NEW FILE########
__FILENAME__ = model
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from datetime import datetime
from itertools import izip

from trac.core import TracError
from trac.resource import Resource
from trac.ticket.model import Ticket
from trac.ticket.query import Query
from trac.util.datefmt import utc

from bhdashboard.model import ModelBase

# -------------------------------------------
# Product API
# -------------------------------------------


class Product(ModelBase):
    """The Product table"""
    _meta = {'table_name': 'bloodhound_product',
             'object_name': 'Product',
             'key_fields': ['prefix'],
             'non_key_fields': ['name', 'description', 'owner'],
             'no_change_fields': ['prefix'],
             'unique_fields': ['name'],
             }

    @property
    def resource(self):
        """Allow Product to be treated as a Resource"""
        return Resource('product', self.prefix)

    def delete(self, resources_to=None):
        """ override the delete method so that we can move references to this
        object to a new product """
        if resources_to is not None:
            new_product = Product(self._env, resources_to)
            if not new_product._exists:
                sdata = {'new_table': resources_to}
                sdata.update(self._meta)
                raise TracError('%(object_name)s %(new_table)s does not exist' %
                                sdata)
        original_prefix = self._data['prefix']
        super(Product, self).delete()
        #find and update all resources that should move
        where = {'product_id': original_prefix}
        for prm in ProductResourceMap.select(self._env, where=where):
            prm._data['product_id'] = resources_to
            prm.update()

    def _update_relations(self, db=None, author=None):
        """Extra actions due to update"""
        # tickets need to be updated
        old_name = self._old_data['name']
        new_name = self._data['name']
        now = datetime.now(utc)
        comment = 'Product %s renamed to %s' % (old_name, new_name)
        if old_name != new_name:
            env = self._env.parent or self._env
            if self._data['prefix']:
                from multiproduct.env import ProductEnvironment
                env = ProductEnvironment(env, self._data['prefix'])
            for t in Product.get_tickets(self._env, self._data['prefix']):
                ticket = Ticket(env, t['id'], db)
                ticket.save_changes(author, comment, now)

    @classmethod
    def get_tickets(cls, env, product=''):
        """Retrieve all tickets associated with the product."""
        from multiproduct.ticket.query import ProductQuery
        from multiproduct.env import ProductEnvironment
        if not product and isinstance(env, ProductEnvironment):
            product = env.product.prefix
        q = ProductQuery.from_string(env, 'product=%s' % product)
        return q.execute()


class ProductResourceMap(ModelBase):
    """Table representing the mapping of resources to their product"""
    _meta = {'table_name': 'bloodhound_productresourcemap',
             'object_name': 'ProductResourceMapping',
             'key_fields': ['id'],
             'non_key_fields': ['product_id', 'resource_type', 'resource_id'],
             'no_change_fields': ['id'],
             'unique_fields': [],
             'auto_inc_fields': ['id'],
             }

    def reparent_resource(self, product=None):
        """a specific function to update a record when it is to move product"""
        if product is not None:
            new_product = Product(self._env, product)
            if not new_product._exists:
                sdata = {'new_table': product}
                sdata.update(self.meta)
                raise TracError('%(object_name)s %(new_table)s does not exist'
                                % sdata)
        self._data['product_id'] = product
        self.update()


# -------------------------------------------
# Configuration
# -------------------------------------------

class ProductSetting(ModelBase):
    """The Product configuration table
    """
    _meta = {'table_name': 'bloodhound_productconfig',
             'object_name': 'ProductSetting',
             'key_fields': ['product', 'section', 'option'],
             'non_key_fields': ['value', ],
             'no_change_fields': ['product', 'section', 'option'],
             'unique_fields': [],
             }

    @classmethod
    def exists(cls, env, product, section=None, option=None, db=None):
        """Determine whether there are configuration values for
        product, section, option .
        """
        if product is None:
            raise ValueError("Product prefix required")
        l = locals()
        option_subkey = ([c, l[c]] for c in ('product', 'section', 'option'))
        option_subkey = dict(c for c in option_subkey if c[1] is not None)
        return len(cls.select(env, db, where=option_subkey, limit=1)) > 0

    @classmethod
    def get_sections(cls, env, product):
        """Retrieve configuration sections defined for a product
        """
        # FIXME: Maybe something more ORM-ish should be added in ModelBase
        return [row[0] for row in env.db_query("""SELECT DISTINCT section
                FROM bloodhound_productconfig WHERE product = %s""",
                (product,))]

########NEW FILE########
__FILENAME__ = perm
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Permission components for Bloodhound product environments"""

from functools import wraps

from trac.core import Component, implements
from trac.perm import IPermissionPolicy, PermissionSystem, PermissionError

__all__ = 'ProductPermissionPolicy',

#--------------------------
# Permission components
#--------------------------

class MultiproductPermissionPolicy(Component):
    """Apply product policy in product environments to deal with TRAC_ADMIN,
    PRODUCT_ADMIN and alike.
    """
    implements(IPermissionPolicy)

    # IPermissionPolicy methods
    def check_permission(self, action, username, resource, perm):
        # FIXME: Better handling of recursive imports
        from multiproduct.env import ProductEnvironment

        if isinstance(self.env, ProductEnvironment):
            permsys = PermissionSystem(self.env.parent)
            if permsys.check_permission('TRAC_ADMIN', username):
                return action in PermissionSystem(self.env).get_actions() \
                        or None     # FIXME: maybe False is better
            elif username == self.env.product.owner:
                # Product owner granted with PRODUCT_ADMIN permission ootb
                permsys = PermissionSystem(self.env)
                # FIXME: would `action != 'TRAC_ADMIN'` be enough ?
                return True if action in permsys.get_actions() and \
                                action != 'TRAC_ADMIN' \
                            else None


#--------------------------
# Impersonation helpers
#--------------------------

class SudoPermissionContext(object):
    """Allows a permitted user (by default `PRODUCT_ADMIN`) to execute
    a command as if temporarily granted with `TRAC_ADMIN` or other specific
    permission. There is also support to revoke some actions unconditionally.

    These objects will act as context managers wrapping the permissions cache
    of the target request object. Entering the same context more than once
    is not supported and will result in unexpected behavior.
    """
    def __init__(self, req, require=None, grant=None, revoke=None):
        grant = frozenset(grant if grant is not None else ('TRAC_ADMIN',))
        revoke = frozenset(revoke or [])
        if grant & revoke:
            raise ValueError('Impossible to grant and revoke (%s)' %
                             ', '.join(sorted(grant & revoke)))

        self.grant = grant
        self.revoke = revoke
        if req:
            self._expand_perms(req.perm.env)
        else:
            self._expanded = False
        self._perm = None
        self.req = req
        self.require_actions = frozenset(('PRODUCT_ADMIN',) if require is None
                                         else ([require]
                                               if isinstance(require, basestring)
                                               else require))

    @property
    def perm(self):
        return self._perm

    @perm.setter
    def perm(self, perm):
        if perm and not self._expanded:
            self._expand_perms(perm.env)
        self._perm = perm

    def __getattr__(self, attrnm):
        # Actually PermissionCache.__slots__ but this will be faster
        if attrnm in ('env', 'username', '_resource', '_cache'):
            try:
                return getattr(self.perm, attrnm)
            except AttributeError:
                pass
        raise AttributeError("'%s' object has no attribute '%s'" %
                             (self.__class__.__name__, attrnm))

    def __enter__(self):
        if self.req is None:
            # e.g. instances returned by __call__
            raise ValueError('Context manager not bound to request object')
        req = self.req
        for action in self.require_actions:
            req.perm.require(action)
        self.perm = req.perm
        req.perm = self
        return self

    def __exit__(self, exc_type, exc_value, tb):
        self.req.perm = self.perm
        self.perm = None

    # Internal methods

    @property
    def is_active(self):
        """Determine whether this context is active
        """
        return self.req and self.perm

    def _expand_perms(self, env):
        permsys = PermissionSystem(env)
        grant = frozenset(permsys.expand_actions(self.grant))
        revoke = frozenset(permsys.expand_actions(self.revoke))
        # Double check ambiguous action lists
        if grant & revoke:
            raise ValueError('Impossible to grant and revoke (%s)' %
                             ', '.join(sorted(grant & revoke)))
        self.grant = grant
        self.revoke = revoke
        self._expanded = True

    def __assert_require(f):
        @wraps(f)
        def __require(self, *args, **kwargs):
            # FIXME : No check ? Transform into assert statement ?
            if not self.perm:
                raise RuntimeError('Permission check out of context')
            if not self.is_active:
                for action in self.require_actions:
                    self.perm.require(action)
            return f(self, *args, **kwargs)

        return __require

    # PermissionCache methods
    @__assert_require
    def __call__(self, realm_or_resource, id=False, version=False):
        newperm = self.perm(realm_or_resource, id, version)
        if newperm is self.perm:
            return self
        else:
            newctx = SudoPermissionContext(None, self.require_actions, self.grant,
                                           self.revoke)
            newctx.perm = newperm
            return newctx

    @__assert_require
    def has_permission(self, action, realm_or_resource=None, id=False,
                       version=False):
        return action in self.grant or \
               (action not in self.revoke and
                self.perm.has_permission(action, realm_or_resource, id,
                                         version))

    __contains__ = has_permission

    @__assert_require
    def require(self, action, realm_or_resource=None, id=False, version=False):
        if action in self.grant:
            return
        if action in self.revoke:
            resource = self._normalize_resource(realm_or_resource, id, version)
            raise PermissionError(action, resource, self.perm.env)
        self.perm.require(action, realm_or_resource, id, version)

    assert_permission = require

    @__assert_require
    def permissions(self):
        """Deprecated (but still used by the HDF compatibility layer)
        """
        self.perm.env.log.warning("perm.permissions() is deprecated and "
                             "is only present for HDF compatibility")
        permsys = PermissionSystem(self.perm.env)
        actions = permsys.get_user_permissions(self.perm.username)
        return [action for action in actions if action in self]

    del __assert_require


sudo = SudoPermissionContext

########NEW FILE########
__FILENAME__ = product_admin
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.admin.api import IAdminCommandProvider, AdminCommandError,\
    AdminCommandManager
from trac.admin.console import TracAdmin, TRAC_VERSION
from trac.admin.web_ui import AdminModule
from trac.core import *
from trac.config import *
from trac.perm import PermissionSystem
from trac.resource import ResourceNotFound
from trac.ticket.admin import TicketAdminPanel, _save_config
from trac.util import getuser, lazy
from trac.util.text import print_table, to_unicode, printerr, printout
from trac.web.api import HTTPNotFound, IRequestFilter, IRequestHandler
from trac.web.chrome import Chrome, add_notice, add_warning

from multiproduct.env import ProductEnvironment
from multiproduct.model import Product
from multiproduct.perm import sudo
from multiproduct.util import ReplacementComponent
from multiproduct.util.translation import _, N_, gettext, ngettext

import multiproduct.versioncontrol
import trac.versioncontrol.admin
from trac.versioncontrol import DbRepositoryProvider, RepositoryManager

#--------------------------
# Product admin panel
#--------------------------

class ProductAdminPanel(TicketAdminPanel):
    """The Product Admin Panel"""
    _type = 'products'
    _label = ('Product','Products')

    def get_admin_commands(self):
        if not isinstance(self.env, ProductEnvironment):
            yield ('product add', '<prefix> <owner> <name>',
                   'Add a new product',
                   None, self._do_product_add)
            yield ('product chown', '<prefix> <owner>',
                   'Change product ownership',
                   self._complete_product, self._do_product_chown)
            yield ('product list', '',
                   'Show available products',
                   None, self._do_product_list)
            yield ('product remove', '<prefix>',
                   'Remove/uninstall a product',
                   self._complete_product, self._do_product_remove)
            yield ('product rename', '<prefix> <newname>',
                   'Rename a product',
                   self._complete_product, self._do_product_rename)

    def get_admin_panels(self, req):
        if isinstance(req.perm.env, ProductEnvironment):
            return None
        return super(ProductAdminPanel, self).get_admin_panels(req)

    def _render_admin_panel(self, req, cat, page, product):
        req.perm.require('PRODUCT_VIEW')

        name = req.args.get('name')
        description = req.args.get('description','')
        prefix = req.args.get('prefix') if product is None else product
        owner = req.args.get('owner')
        keys = {'prefix':prefix}
        field_data = {'name':name,
                      'description':description,
                      'owner':owner,
                      }
        data = {}

        # Detail view?
        if product:
            prod = Product(self.env, keys)
            if req.method == 'POST':
                if req.args.get('save'):
                    req.perm.require('PRODUCT_MODIFY')
                    prod.update_field_dict(field_data)
                    prod.update(req.authname)
                    add_notice(req, _('Your changes have been saved.'))
                    req.redirect(req.href.admin(cat, page))
                elif req.args.get('cancel'):
                    req.redirect(req.href.admin(cat, page))

            Chrome(self.env).add_wiki_toolbars(req)
            data = {'view': 'detail', 'product': prod}
        else:
            default = self.config.get('ticket', 'default_product')
            if req.method == 'POST':
                # Add Product
                if req.args.get('add'):
                    req.perm.require('PRODUCT_CREATE')
                    if not (prefix and name and owner):
                        if not prefix:
                            add_warning(req, _("You must provide a prefix "
                                               "for the product."))
                        if not name:
                            add_warning(req, _("You must provide a name "
                                               "for the product."))
                        if not owner:
                            add_warning(req, _("You must provide an owner "
                                               "for the product."))
                        data['prefix'] = prefix
                        data['name'] = name
                        data['owner'] = owner
                    else:
                        try:
                            prod = Product(self.env, keys)
                        except ResourceNotFound:
                            prod = Product(self.env)
                            prod.update_field_dict(keys)
                            prod.update_field_dict(field_data)
                            prod.insert()
                            add_notice(req, _('The product "%(id)s" has been '
                                              'added.', id=prefix))
                            req.redirect(req.href.admin(cat, page))
                        else:
                            if prod.prefix is None:
                                raise TracError(_('Invalid product id.'))
                            raise TracError(_("Product %(id)s already exists.",
                                              id=prefix))

                # Remove product
                elif req.args.get('remove'):
                    raise TracError(_('Product removal is not allowed!'))

                # Set default product
                elif req.args.get('apply'):
                    prefix = req.args.get('default')
                    if prefix and prefix != default:
                        self.log.info("Setting default product to %s",
                                      prefix)
                        self.config.set('ticket', 'default_product',
                                        prefix)
                        _save_config(self.config, req, self.log)
                        req.redirect(req.href.admin(cat, page))

                # Clear default product
                elif req.args.get('clear'):
                    self.log.info("Clearing default product")
                    self.config.set('ticket', 'default_product', '')
                    _save_config(self.config, req, self.log)
                    req.redirect(req.href.admin(cat, page))

            data['view'] = 'list'
            data['products'] = Product.select(self.env)
            data['default'] = default
        if self.config.getbool('ticket', 'restrict_owner'):
            perm = PermissionSystem(self.env)
            def valid_owner(username):
                return perm.get_user_permissions(username).get('TICKET_MODIFY')
            data['owners'] = [username for username, name, email
                              in self.env.get_known_users()
                              if valid_owner(username)]
            data['owners'].insert(0, '')
            data['owners'].sort()
        else:
            data['owners'] = None
        return 'admin_products.html', data

    def load_product(self, prefix):
        products = Product.select(self.env, where={'prefix' : prefix})
        if not products:
            raise AdminCommandError('Unknown product %s' % (prefix,))
        return products[0]

    def _complete_product(self, args):
        if len(args) == 1:
            return get_products(self.env)

    def _do_product_add(self, prefix, owner, name):
        product = Product(self.env)
        product._data.update({'prefix':prefix, 'name':name, 'owner':owner})
        try:
            product.insert()
        except TracError, exc:
            raise AdminCommandError(to_unicode(exc))

    def _do_product_chown(self, prefix, owner):
        product = self.load_product(prefix)
        product._data['owner'] = owner
        product.update(getuser())

    def _do_product_list(self):
        if not isinstance(self.env, ProductEnvironment):
            print_table([(p.prefix, p.owner, p.name)
                         for p in Product.select(self.env)],
                        [_('Prefix'), _('Owner'), _('Name')])

    def _do_product_remove(self, prefix):
        raise AdminCommandError(_("Command 'product remove' not supported yet"))

    def _do_product_rename(self, prefix, newname):
        product = self.load_product(prefix)
        product._data['name'] = newname
        product.update(getuser())


#--------------------------
# Advanced administration in product context
#--------------------------

class IProductAdminAclContributor(Interface):
    """Interface implemented by components contributing with entries to the
    access control white list in order to enable admin panels in product
    context.

    **Notice** that deny entries configured by users in the blacklist
    (i.e. using TracIni `admin_blacklist` option in `multiproduct` section)
    will override these entries.
    """
    def enable_product_admin_panels():
        """Return a sequence of `(cat_id, panel_id)` tuples that will be
        enabled in product context unless specified otherwise in configuration.
        If `panel_id` is set to `'*'` then all panels in section `cat_id`
        will have green light.
        """


class ProductAdminModule(Component):
    """Leverage administration panels in product context based on the
    combination of white list and black list.
    """
    implements(IAdminCommandProvider, IRequestFilter, IRequestHandler)

    acl_contributors = ExtensionPoint(IProductAdminAclContributor)

    raw_blacklist = ListOption('multiproduct', 'admin_blacklist',
        doc="""Do not show any product admin panels in this list even if
        allowed by white list. Value must be a comma-separated list of
        `cat:id` strings respectively identifying the section and identifier
        of target admin panel. Empty values of `cat` and `id` will be ignored
        and warnings emitted if TracLogging is enabled. If `id` is set
        to `*` then all panels in `cat` section will be added to blacklist
        while in product context.""")

    @lazy
    def acl(self):
        """Access control table based on blacklist and white list.
        """
        # FIXME : Use an immutable (mapping?) type
        acl = {}
        if isinstance(self.env, ProductEnvironment):
            for acl_c in self.acl_contributors:
                for cat_id, panel_id in acl_c.enable_product_admin_panels():
                    if cat_id and panel_id:
                        if panel_id == '*':
                            acl[cat_id] = True
                        else:
                            acl[(cat_id, panel_id)] = True
                    else:
                        self.log.warning('Invalid panel %s in white list',
                                         panel_id)

            # Blacklist entries will override those in white list
            warnings = []
            for panelref in self.raw_blacklist:
                try:
                    cat_id, panel_id = panelref.split(':')
                except ValueError:
                    cat_id = panel_id = ''
                if cat_id and panel_id:
                    if panel_id == '*':
                        acl[cat_id] = False
                    else:
                        acl[(cat_id, panel_id)] = False
                else:
                    warnings.append(panelref)
            if warnings:
                self.log.warning("Invalid panel descriptors '%s' in blacklist",
                                 ','.join(warnings))
        return acl

    # IAdminCommandProvider methods
    def get_admin_commands(self):
        if not isinstance(self.env, ProductEnvironment):
            yield ('product admin', '<PREFIX> <admin command>',
                   'Execute admin (sub-)command upon product resources',
                   self._complete_product_admin, self._do_product_admin)

    def product_admincmd_mgr(self, prefix):
        try:
            product_env = ProductEnvironment.lookup_env(self.env, prefix)
        except LookupError:
            raise AdminCommandError('Unknown product %s' % (prefix,))
        else:
            return AdminCommandManager(product_env)

    def _complete_product_admin(self, args):
        if len(args) == 1:
            return get_products(self.env)
        else:
            mgr = self.product_admincmd_mgr(args[0])
            return mgr.complete_command(args[1:])

    GLOBAL_COMMANDS = ('deploy', 'hotcopy', 'initenv', 'upgrade')

    def _do_product_admin(self, prefix, *args):
        mgr = self.product_admincmd_mgr(prefix)
        if args and args[0] in self.GLOBAL_COMMANDS:
            raise AdminCommandError('%s command not supported for products' %
                                    (args[0],))
        if args and args[0] == 'help':
            help_args = args[1:]
            if help_args:
                doc = mgr.get_command_help(list(help_args))
                if doc:
                    TracAdmin.print_doc(doc)
                else:
                    printerr(_("No documentation found for '%(cmd)s'."
                               " Use 'help' to see the list of commands.",
                               cmd=' '.join(help_args)))
                    cmds = mgr.get_similar_commands(help_args[0])
                    if cmds:
                        printout('')
                        printout(ngettext("Did you mean this?",
                                          "Did you mean one of these?",
                                          len(cmds)))
                        for cmd in cmds:
                            printout('    ' + cmd)
            else:
                printout(_("trac-admin - The Trac Administration Console "
                           "%(version)s", version=TRAC_VERSION))
                env = mgr.env
                TracAdmin.print_doc(TracAdmin.all_docs(env), short=True)
        else:
            try:
                mgr.execute_command(*args)
            except AdminCommandError, e:
                printerr(_("Error: %(msg)s", msg=to_unicode(e)))
                if e.show_usage:
                    print
                    self._do_product_admin(prefix, 'help', *args[:2])
            except:
                raise

    # IRequestFilter methods
    def pre_process_request(self, req, handler):
        """Intercept admin requests in product context if `TRAC_ADMIN`
        expectations are not met.
        """
        if isinstance(self.env, ProductEnvironment) and \
                handler is AdminModule(self.env) and \
                not req.perm.has_permission('TRAC_ADMIN') and \
                req.perm.has_permission('PRODUCT_ADMIN'):
            # Intercept admin request
            return self
        return handler

    def post_process_request(self, req, template, data, content_type):
        return template, data, content_type

    # IRequestHandler methods
    def match_request(self, req):
        """Never match a request"""

    def process_request(self, req):
        """Anticipate permission error to hijack admin panel dispatching
        process in product context if `TRAC_ADMIN` expectations are not met.
        """
        # TODO: Verify `isinstance(self.env, ProductEnvironment)` once again ?
        cat_id = req.args.get('cat_id')
        panel_id = req.args.get('panel_id')
        if self._check_panel(cat_id, panel_id):
            with sudo(req):
                return self.global_process_request(req)
        else:
            raise HTTPNotFound(_('Unknown administration panel'))

    global_process_request = AdminModule.process_request.im_func

    # Internal methods
    def _get_panels(self, req):
        if isinstance(self.env, ProductEnvironment):
            panels, providers = AdminModule(self.env)._get_panels(req)
            # Filter based on ACLs
            panels = [p for p in panels if self._check_panel(p[0], p[2])]
#            providers = dict([k, p] for k, p in providers.iteritems()
#                                    if self._check_panel(*k))
            return panels, providers
        else:
            return [], []

    def _check_panel(self, cat_id, panel_id):
        cat_allow = self.acl.get(cat_id)
        panel_allow = self.acl.get((cat_id, panel_id))
        return cat_allow is not False and panel_allow is not False \
               and (cat_allow, panel_allow) != (None, None) \
               and (cat_id, panel_id) != ('general', 'plugin') # double-check !


def get_products(env):
    return [p.prefix for p in Product.select(env)]


class DefaultProductAdminWhitelist(Component):
    implements(IProductAdminAclContributor)

    # IProductAdminAclContributor methods
    def enable_product_admin_panels(self):
        yield 'general', 'basics'
        yield 'general', 'perm'
        yield 'accounts', 'notification'
        # FIXME: Include users admin panel ?
        #yield 'accounts', 'users'
        yield 'ticket', '*'
        yield 'versioncontrol', 'repository'


class ProductRepositoryAdminPanel(ReplacementComponent, trac.versioncontrol.admin.RepositoryAdminPanel):
    """Web admin panel for repository administration, product-aware."""

    implements(trac.admin.IAdminPanelProvider)

    # IAdminPanelProvider methods

    def get_admin_panels(self, req):
        if 'VERSIONCONTROL_ADMIN' in req.perm:
            yield ('versioncontrol', _('Version Control'), 'repository',
                   _('Repository Links') if isinstance(self.env, ProductEnvironment)
                    else _('Repositories'))

    def render_admin_panel(self, req, category, page, path_info):
        if not isinstance(self.env, ProductEnvironment):
            return super(ProductRepositoryAdminPanel, self).render_admin_panel(
                req, category, page, path_info)

        req.perm.require('VERSIONCONTROL_ADMIN')
        db_provider = self.env[DbRepositoryProvider]

        if req.method == 'POST' and db_provider:
            if req.args.get('remove'):
                repolist = req.args.get('sel')
                if repolist:
                    if isinstance(repolist, basestring):
                        repolist = [repolist, ]
                    for reponame in repolist:
                        db_provider.unlink_product(reponame)
            elif req.args.get('addlink') is not None and db_provider:
                reponame = req.args.get('repository')
                db_provider.link_product(reponame)
            req.redirect(req.href.admin(category, page))

        # Retrieve info for all product repositories
        rm_product = RepositoryManager(self.env)
        rm_product.reload_repositories()
        all_product_repos = rm_product.get_all_repositories()
        repositories = dict((reponame, self._extend_info(
                                reponame, info.copy(), True))
                            for (reponame, info) in
                                all_product_repos.iteritems())
        types = sorted([''] + rm_product.get_supported_types())

        # construct a list of all repositores not linked to this product
        rm = RepositoryManager(self.env.parent)
        all_repos = rm.get_all_repositories()
        unlinked_repositories = dict([(k, all_repos[k]) for k in
            sorted(set(all_repos) - set(all_product_repos))])

        data = {'types': types, 'default_type': rm_product.repository_type,
                'repositories': repositories,
                'unlinked_repositories': unlinked_repositories}
        return 'repository_links.html', data

trac.versioncontrol.admin.RepositoryAdminPanel = ProductRepositoryAdminPanel

########NEW FILE########
__FILENAME__ = batch
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.ticket.batch import BatchModifyModule
from trac.web.chrome import add_script_data
from multiproduct.env import ProductEnvironment
from multiproduct.util.translation import _


class ProductBatchModifyModule(BatchModifyModule):

    def add_template_data(self, req, data, tickets):
        if isinstance(self.env, ProductEnvironment):
            super(ProductBatchModifyModule, self).add_template_data(req, data,
                                                                    tickets)
            return

        data['batch_modify'] = True
        data['query_href'] = req.session['query_href'] or req.href.query()

        tickets_by_product = {}
        for t in tickets:
            tickets_by_product.setdefault(t['product'], []).append(t)

        data['action_controls'] = []
        global_env = ProductEnvironment.lookup_global_env(self.env)
        cache = {}
        for k, v in tickets_by_product.iteritems():
            batch_module = cache.get(k or '')
            if batch_module is None:
                env = ProductEnvironment(global_env, k) if k else global_env
                cache[k] = batch_module = ProductBatchModifyModule(env)
            data['action_controls'] += batch_module._get_action_controls(req,
                                                                         v)
        batch_list_modes = [
            {'name': _("add"), 'value': "+"},
            {'name': _("remove"), 'value': "-"},
            {'name': _("add / remove"), 'value': "+-"},
            {'name': _("set to"), 'value': "="},
        ]
        add_script_data(req, batch_list_modes=batch_list_modes,
                        batch_list_properties=self._get_list_fields())

import trac.ticket.batch
trac.ticket.batch.BatchModifyModule = ProductBatchModifyModule
trac.ticket.BatchModifyModule = ProductBatchModifyModule

########NEW FILE########
__FILENAME__ = query
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from __future__ import with_statement

import re

from itertools import groupby
from math import ceil
from datetime import datetime, timedelta

from genshi.builder import tag

from trac.core import TracError
from trac.db import get_column_names
from trac.mimeview.api import Mimeview
from trac.ticket.api import TicketSystem
from trac.ticket.query import Query, QueryModule, TicketQueryMacro, QueryValueError
from trac.util.datefmt import from_utimestamp, utc, to_timestamp
from trac.util.text import shorten_line
from trac.web import parse_arg_list, arg_list_to_args
from trac.web.chrome import Chrome, add_stylesheet, add_link, web_context, \
    add_script_data, add_script, add_ctxtnav, add_warning
from trac.resource import Resource

from multiproduct.dbcursor import GLOBAL_PRODUCT
from multiproduct.env import lookup_product_env, resolve_product_href, \
                             ProductEnvironment
from multiproduct.util.translation import _, tag_


class ProductQuery(Query):
    """Product Overrides for TracQuery.

    This class allows for writing TracQuery expressions matching resources
    beyond product boundaries.
    """

    def _count(self, sql, args):
        if isinstance(self.env, ProductEnvironment):
            return super(ProductQuery, self)._count(sql, args)

        cnt = self.env.db_direct_query("SELECT COUNT(*) FROM (%s) AS x"
                                       % sql, args)[0][0]
        # "AS x" is needed for MySQL ("Subqueries in the FROM Clause")
        self.env.log.debug("Count results in Query: %d", cnt)
        return cnt

    def get_columns(self):
        super(ProductQuery, self).get_columns()
        if not 'product' in self.cols and self.group != 'product':
            # make sure 'product' is always present
            # (needed for product context, href, permission checks ...)
            # but don't implicitly include it if items are grouped by product
            self.cols.insert(0, 'product')
        return self.cols

    def _get_ticket_href(self, prefix, tid):
        try:
            env = lookup_product_env(self.env, prefix)
        except LookupError:
            return '#invalid-product-' + prefix
        else:
            href = resolve_product_href(env, self.env)
            return href.ticket(tid)

    def get_href(self, href, id=None, order=None, desc=None, format=None,
                 max=None, page=None):
        from multiproduct.hooks import ProductizedHref
        return super(ProductQuery, self).get_href(
            ProductizedHref(href, self.env.href.base), id, order, desc,
            format, max, page)

    def execute(self, req=None, db=None, cached_ids=None, authname=None,
                tzinfo=None, href=None, locale=None):
        """Retrieve the list of matching tickets.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        with self.env.db_direct_query as db:
            cursor = db.cursor()

            self.num_items = 0
            sql, args = self.get_sql(req, cached_ids, authname, tzinfo, locale)
            if sql.startswith('SELECT ') and not sql.startswith('SELECT DISTINCT '):
                sql = 'SELECT DISTINCT * FROM (' + sql + ') AS subquery'
            if isinstance(self.env, ProductEnvironment):
                sql = sql + """ WHERE product='%s'""" % (self.env.product.prefix, )
            self.num_items = self._count(sql, args)

            if self.num_items <= self.max:
                self.has_more_pages = False

            if self.has_more_pages:
                max = self.max
                if self.group:
                    max += 1
                sql = sql + " LIMIT %d OFFSET %d" % (max, self.offset)
                if self.page > int(ceil(float(self.num_items) / self.max)) and \
                        self.num_items != 0:
                    raise TracError(_("Page %(page)s is beyond the number of "
                                      "pages in the query", page=self.page))

            # self.env.log.debug("SQL: " + sql % tuple([repr(a) for a in args]))
            cursor.execute(sql, args)
            columns = get_column_names(cursor)
            fields = []
            for column in columns:
                fields += [f for f in self.fields if f['name'] == column] or \
                          [None]
            results = []

            product_idx = columns.index('product')
            column_indices = range(len(columns))
            for row in cursor:
                result = {}
                for i in column_indices:
                    name, field, val = columns[i], fields[i], row[i]
                    if name == 'reporter':
                        val = val or 'anonymous'
                    elif name == 'id':
                        val = int(val)
                        result['href'] = self._get_ticket_href(
                            row[product_idx], val)
                    elif name in self.time_fields:
                        val = from_utimestamp(val)
                    elif field and field['type'] == 'checkbox':
                        try:
                            val = bool(int(val))
                        except (TypeError, ValueError):
                            val = False
                    elif val is None:
                        val = ''
                    result[name] = val
                results.append(result)
            cursor.close()
            return results

import trac.ticket.query
trac.ticket.query.Query = ProductQuery
trac.ticket.Query = ProductQuery


class ProductQueryModule(QueryModule):
    def process_request(self, req, env=None):
        tmpenv = self.env
        if isinstance(self.env, ProductEnvironment) and env is not None:
            self.env = env
        result = super(ProductQueryModule, self).process_request(req)
        self.env = tmpenv
        return result

trac.ticket.query.QueryModule = ProductQueryModule
trac.ticket.QueryModule = ProductQueryModule


class ProductTicketQueryMacro(TicketQueryMacro):
    """TracQuery macro retrieving results across product boundaries.
    """
    @staticmethod
    def parse_args(content):
        """Parse macro arguments and translate them to a query string."""
        clauses = [{}]
        argv = []
        kwargs = {}
        for arg in TicketQueryMacro._comma_splitter.split(content):
            arg = arg.replace(r'\,', ',')
            m = re.match(r'\s*[^=]+=', arg)
            if m:
                kw = arg[:m.end() - 1].strip()
                value = arg[m.end():]
                if kw in ('order', 'max', 'format', 'col', 'product'):
                    kwargs[kw] = value
                else:
                    clauses[-1][kw] = value
            elif arg.strip() == 'or':
                clauses.append({})
            else:
                argv.append(arg)
        clauses = filter(None, clauses)

        if len(argv) > 0 and not 'format' in kwargs: # 0.10 compatibility hack
            kwargs['format'] = argv[0]
        if 'order' not in kwargs:
            kwargs['order'] = 'id'
        if 'max' not in kwargs:
            kwargs['max'] = '0' # unlimited by default

        format = kwargs.pop('format', 'list').strip().lower()
        if format in ('list', 'compact'): # we need 'status' and 'summary'
            if 'col' in kwargs:
                kwargs['col'] = 'status|summary|' + kwargs['col']
            else:
                kwargs['col'] = 'status|summary'

        query_string = '&or&'.join('&'.join('%s=%s' % item
                                            for item in clause.iteritems())
                                   for clause in clauses)
        return query_string, kwargs, format

    def expand_macro(self, formatter, name, content):
        req = formatter.req
        query_string, kwargs, format = self.parse_args(content)
        if query_string:
            query_string += '&'
        query_string += '&'.join('%s=%s' % item
                                 for item in kwargs.iteritems())

        env = ProductEnvironment.lookup_global_env(self.env)
        query = ProductQuery.from_string(env, query_string)

        if format == 'count':
            cnt = query.count(req)
            return tag.span(cnt, title='%d tickets for which %s' %
                            (cnt, query_string), class_='query_count')

        tickets = query.execute(req)

        if format == 'table':
            data = query.template_data(formatter.context, tickets,
                                       req=formatter.context.req)

            add_stylesheet(req, 'common/css/report.css')

            return Chrome(env).render_template(
                req, 'query_results.html', data, None, fragment=True)

        if format == 'progress':
            from trac.ticket.roadmap import (RoadmapModule,
                                             apply_ticket_permissions,
                                             get_ticket_stats,
                                             grouped_stats_data)

            add_stylesheet(req, 'common/css/roadmap.css')

            def query_href(extra_args, group_value=None):
                q = ProductQuery.from_string(env, query_string)
                if q.group:
                    extra_args[q.group] = group_value
                    q.group = None
                for constraint in q.constraints:
                    constraint.update(extra_args)
                if not q.constraints:
                    q.constraints.append(extra_args)
                return q.get_href(formatter.context)
            chrome = Chrome(env)
            tickets = apply_ticket_permissions(env, req, tickets)
            stats_provider = RoadmapModule(env).stats_provider
            by = query.group
            if not by:
                stat = get_ticket_stats(stats_provider, tickets)
                data = {
                    'stats': stat,
                    'stats_href': query_href(stat.qry_args),
                    'interval_hrefs': [query_href(interval['qry_args'])
                                       for interval in stat.intervals],
                    'legend': True,
                }
                return tag.div(
                    chrome.render_template(req, 'progress_bar.html', data,
                                           None, fragment=True),
                    class_='trac-progress')

            def per_group_stats_data(gstat, group_name):
                return {
                    'stats': gstat,
                    'stats_href': query_href(gstat.qry_args,  group_name),
                    'interval_hrefs': [query_href(interval['qry_args'],
                                                  group_name)
                                       for interval in gstat.intervals],
                    'percent': '%d / %d' % (gstat.done_count,
                                            gstat.count),
                    'legend': False,
                }

            groups = grouped_stats_data(env, stats_provider, tickets, by,
                                        per_group_stats_data)
            data = {
                'groups': groups, 'grouped_by': by,
                'summary': _("Ticket completion status for each %(group)s",
                             group=by),
            }
            return tag.div(
                chrome.render_template(req, 'progress_bar_grouped.html', data,
                                       None, fragment=True),
                class_='trac-groupprogress')

        # Formats above had their own permission checks, here we need to
        # do it explicitly:

        tickets = [t for t in tickets
                   if 'TICKET_VIEW' in req.perm('ticket', t['id'])]

        if not tickets:
            return tag.span(_("No results"), class_='query_no_results')

        # Cache resolved href targets
        hrefcache = {}

        def ticket_anchor(ticket):
            try:
                pvalue = ticket.get('product') or GLOBAL_PRODUCT
                envhref = hrefcache[pvalue]
            except KeyError:
                try:
                    env = lookup_product_env(self.env, prefix=pvalue,
                                             name=pvalue)
                except LookupError:
                    return tag.a('#%s' % ticket['id'],
                                 class_='missing product')
                hrefcache[pvalue] = envhref = \
                    resolve_product_href(to_env=env, at_env=self.env)
            return tag.a('#%s' % ticket['id'],
                         class_=ticket['status'],
                         href=envhref.ticket(int(ticket['id'])),
                         title=shorten_line(ticket['summary']))

        def ticket_groups():
            groups = []
            for v, g in groupby(tickets, lambda t: t[query.group]):
                q = ProductQuery.from_string(env, query_string)
                # produce the hint for the group
                q.group = q.groupdesc = None
                order = q.order
                q.order = None
                title = _("%(groupvalue)s %(groupname)s tickets matching "
                          "%(query)s", groupvalue=v, groupname=query.group,
                          query=q.to_string())
                # produce the href for the query corresponding to the group
                for constraint in q.constraints:
                    constraint[str(query.group)] = v
                q.order = order
                href = q.get_href(formatter.context)
                groups.append((v, [t for t in g], href, title))
            return groups

        if format == 'compact':
            if query.group:
                groups = [(v, ' ',
                           tag.a('#%s' % u',\u200b'.join(str(t['id'])
                                                         for t in g),
                                 href=href, class_='query', title=title))
                          for v, g, href, title in ticket_groups()]
                return tag(groups[0], [(', ', g) for g in groups[1:]])
            else:
                alist = [ticket_anchor(ticket) for ticket in tickets]
                return tag.span(alist[0], *[(', ', a) for a in alist[1:]])
        else:
            if query.group:
                return tag.div(
                    [(tag.p(tag_('%(groupvalue)s %(groupname)s tickets:',
                                 groupvalue=tag.a(v, href=href, class_='query',
                                                  title=title),
                                 groupname=query.group)),
                      tag.dl([(tag.dt(ticket_anchor(t)),
                               tag.dd(t['summary'])) for t in g],
                             class_='wiki compact'))
                     for v, g, href, title in ticket_groups()])
            else:
                return tag.div(tag.dl([(tag.dt(ticket_anchor(ticket)),
                                        tag.dd(ticket['summary']))
                                       for ticket in tickets],
                                      class_='wiki compact'))

    def is_inline(self, content):
        query_string, kwargs, format = self.parse_args(content)
        return format in ('count', 'compact')

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import re

from genshi.builder import tag

from trac.core import TracError
from trac.ticket.model import Ticket
from trac.ticket.web_ui import TicketModule
from trac.ticket.report import ReportModule
from trac.attachment import AttachmentModule
from trac.ticket.api import TicketSystem
from trac.resource import Resource, get_resource_shortname, ResourceNotFound
from trac.search import search_to_sql, shorten_result
from trac.util.datefmt import from_utimestamp

from multiproduct.api import MultiProductSystem, PRODUCT_SYNTAX_DELIMITER_RE
from multiproduct.env import ProductEnvironment
from multiproduct.model import Product
from multiproduct.util import IDENTIFIER
from multiproduct.util.translation import _, tag_
from multiproduct.web_ui import ProductModule


class ProductTicketModule(TicketModule):
    """Product Overrides for the TicketModule"""

    # IRequestHandler methods
    #def match_request(self, req):
    # override not yet required

    def process_request(self, req):
        """Override for TicketModule process_request"""
        ticketid = req.args.get('id')
        productid = req.args.get('productid', '')

        if not ticketid:
            # if /newticket is executed in global scope (from QCT), redirect
            # the request to /products/<first_product_in_DB>/newticket
            if not productid and \
                    not isinstance(self.env, ProductEnvironment):
                default_product = self.env.config.get('ticket',
                                                      'default_product')
                products = Product.select(self.env, {'fields': ['prefix']})
                prefixes = [prod.prefix for prod in products]
                if not default_product or default_product not in prefixes:
                    default_product = products[0].prefix
                req.redirect(req.href.products(default_product, 'newticket'))

            return self._process_newticket_request(req)

        if req.path_info in ('/newticket', '/products'):
            raise TracError(_("id can't be set for a new ticket request."))

        if isinstance(self.env, ProductEnvironment):
            ticket = Ticket(self.env, ticketid)
            if productid and ticket['product'] != productid:
                msg = "Ticket %(id)s in product '%(prod)s' does not exist."
                raise ResourceNotFound(_(msg, id=ticketid, prod=productid),
                                       _("Invalid ticket number"))
            return self._process_ticket_request(req)

        # executed in global scope -> assume ticketid=UID, redirect to product
        with self.env.db_direct_query as db:
            rows = db("""SELECT id,product FROM ticket WHERE uid=%s""",
                      (ticketid,))
            if not rows:
                msg = "Ticket with uid %(uid)s does not exist."
                raise ResourceNotFound(_(msg, uid=ticketid),
                                       _("Invalid ticket number"))
            tid, prefix = rows[0]
            req.redirect(req.href.products(prefix, 'ticket', tid))

    # INavigationContributor methods

    #def get_active_navigation_item(self, req):
    # override not yet required

    def get_navigation_items(self, req):
        """Overriding TicketModules New Ticket nav item"""
        return

    # ISearchSource methods
    #def get_search_filters(self, req):
    # override not yet required

    def get_search_results(self, req, terms, filters):
        """Overriding search results for Tickets"""
        if not 'ticket' in filters:
            return
        ticket_realm = Resource('ticket')
        with self.env.db_query as db:
            sql, args = search_to_sql(db, ['summary', 'keywords',
                                           'description', 'reporter', 'cc',
                                           db.cast('id', 'text')], terms)
            sql2, args2 = search_to_sql(db, ['newvalue'], terms)
            sql3, args3 = search_to_sql(db, ['value'], terms)
            ticketsystem = TicketSystem(self.env)
            if req.args.get('product'):
                productsql = "product='%s' AND" % req.args.get('product')
            else:
                productsql = ""

            for summary, desc, author, type, tid, ts, status, resolution in \
                    db("""SELECT summary, description, reporter, type, id,
                                 time, status, resolution
                          FROM ticket
                          WHERE (%s id IN (
                              SELECT id FROM ticket WHERE %s
                            UNION
                              SELECT ticket FROM ticket_change
                              WHERE field='comment' AND %s
                            UNION
                              SELECT ticket FROM ticket_custom WHERE %s
                          ))
                          """ % (productsql, sql, sql2, sql3),
                          args + args2 + args3):
                t = ticket_realm(id=tid)
                if 'TICKET_VIEW' in req.perm(t):
                    yield (req.href.ticket(tid),
                           tag_("%(title)s: %(message)s",
                                title=tag.span(
                                    get_resource_shortname(self.env, t),
                                    class_=status),
                                message=ticketsystem.format_summary(
                                    summary, status, resolution, type)),
                           from_utimestamp(ts), author,
                           shorten_result(desc, terms))

        # Attachments
        for result in AttachmentModule(self.env) \
                      .get_search_results(req, ticket_realm, terms):
            yield result


class ProductReportModule(ReportModule):
    """Multiproduct replacement for ReportModule"""

    # INavigationContributor methods
    #def get_active_navigation_item(self, req):
    # not yet required

    def get_navigation_items(self, req):
        if 'REPORT_VIEW' in req.perm:
            href = ProductModule.get_product_path(self.env, req, 'report')
            yield ('mainnav', 'tickets', tag.a(_('View Tickets'), href=href))

    # IWikiSyntaxProvider methods
    #def get_link_resolvers(self):
    # not yet required

    def get_wiki_syntax(self):
        # FIXME: yield from
        for s in super(ProductReportModule, self).get_wiki_syntax():
            yield s
        # Previously unmatched prefix
        yield (r"!?\{(?P<prp>%s(?:\s+|(?:%s)))[0-9]+\}"
               % (IDENTIFIER, PRODUCT_SYNTAX_DELIMITER_RE),
               lambda x, y, z: self._format_link(x, 'report', y[1:-1], y, z))
        # Absolute product report syntax
        yield (r"!?\{(?P<prns>global:|product:%s(?:\s+|:))"
               r"(?P<prid>[0-9]+)\}" % (IDENTIFIER,),
               lambda x, y, z: (self._format_mplink(x, 'report', y[1:-1], y, z)))

    def _format_link(self, formatter, ns, target, label, fullmatch=None):
        intertrac = \
            formatter.shorthand_intertrac_helper(ns, target, label, fullmatch)
        if intertrac:
            return intertrac

        # second chance to match InterTrac prefix as product prefix
        it_report = fullmatch.group('it_' + ns) or fullmatch.group('prp')
        if it_report:
            return self._format_mplink(formatter, ns, target, label, fullmatch)

        report, args, fragment = formatter.split_link(target)
        return tag.a(label, href=formatter.href.report(report) + args,
                     class_='report')

    def _format_mplink(self, formatter, ns, target, label, fullmatch=None):
        mpsys = self.env[MultiProductSystem]
        if mpsys is not None:
            substeps = []
            prns = fullmatch.group('prns')
            if not prns:
                # Forwarded from _format_link, inherit current context
                product_id = fullmatch.group('it_' + ns) or \
                             fullmatch.group('prp')
                if product_id:
                    product_ns = 'product'
                    substeps = [product_id.strip()]
                elif isinstance(self.env, ProductEnvironment):
                    product_ns = 'product'
                    substeps = [self.env.product.prefix]
                else:
                    product_ns = 'global'
            elif prns == 'global:':
                product_ns = 'global'
            elif prns.startswith('product:'):
                product_ns, product_id = prns.strip().split(':')[:2]
                substeps = [product_id]
            report_id = fullmatch.group('prid') or \
                        re.match(r'^.*?(\d+)$', target).group(1)
            substeps += [ns, report_id]

            return mpsys._format_link(formatter, product_ns,
                                      u':'.join(substeps),
                                      label, fullmatch)
        else:
            return tag.a(label, class_='missing product')

########NEW FILE########
__FILENAME__ = translation
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Translation functions and classes.
"""

from trac.util.translation import domain_functions

#------------------------------------------------------
#    Internationalization
#------------------------------------------------------

_, ngettext, tag_, tagn_, gettext, N_, add_domain = \
   domain_functions('multiproduct', ('_', 'ngettext', 'tag_', 'tagn_',
                                'gettext', 'N_', 'add_domain'))

########NEW FILE########
__FILENAME__ = versioncontrol
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import os.path

from trac.util.concurrency import threading
from trac.core import implements
import trac.versioncontrol.api
from trac.versioncontrol import RepositoryManager
import trac.admin
import trac.web.api
import trac.resource
from multiproduct.util import ReplacementComponent
from multiproduct.env import ProductEnvironment

class DbRepositoryProvider(ReplacementComponent, trac.versioncontrol.api.DbRepositoryProvider):
    """Inplace replacement for trac.versioncontrol.api.DbRepositoryProvider. Filters
    repositories based on soft-links to products. Soft links are stored in 'product'
    repository attribute, separated by comma."""

    repository_attrs = trac.versioncontrol.api.DbRepositoryProvider.repository_attrs + tuple(['product'])

    implements(trac.versioncontrol.api.IRepositoryProvider,
               trac.admin.IAdminCommandProvider)

    # IRepositoryProvider methods
    def get_repositories(self):
        """Retrieve list of repositories specified in the repository
        table for current product environment
        """
        if isinstance(self.env, ProductEnvironment):
            repos = {}
            for id, name, value in self.env.db_direct_query(
                "SELECT id, name, value FROM repository WHERE name IN (%s)"
                % ",".join("'%s'" % each for each in self.repository_attrs)):
                if value is not None:
                    repos.setdefault(id, {})[name] = value
            reponames = {}
            for id, info in repos.iteritems():
                if not 'product' in info or \
                   not self.env.product.prefix in info['product'].split(','):
                    # skip repository if not soft linked from the current
                    # product environment
                    continue
                if 'product' in info:
                    del info['product']
                if 'name' in info and ('dir' in info or 'alias' in info):
                    info['id'] = id
                    reponames[info['name']] = info
            return reponames.iteritems()
        else:
            return super(DbRepositoryProvider, self).get_repositories()

    def _get_repository_links(self, repoid):
        with self.env.db_direct_query as db:
            rows = db("""SELECT value FROM repository WHERE id=%s
                         AND name='product'""" % (repoid,))
            if rows:
                return rows[0][0].split(',')
        return None

    def link_product(self, reponame):
        if not isinstance(self.env, ProductEnvironment):
            return
        rm = RepositoryManager(self.env.parent)
        repoid = rm.get_repository_id(reponame)
        links = self._get_repository_links(repoid)
        with self.env.db_direct_transaction as db:
            if links:
                links.append(self.env.product.prefix)
                db("""UPDATE repository SET value=%s WHERE id=%s
                      AND name='product'""", (','.join(links), repoid))
            else:
                db("""INSERT INTO repository (id, name, value)
                        VALUES(%s, 'product', '%s')""" %
                        (repoid, self.env.product.prefix))

    def unlink_product(self, reponame):
        if not isinstance(self.env, ProductEnvironment):
            return
        rm = RepositoryManager(self.env.parent)
        repoid = rm.get_repository_id(reponame)
        links = self._get_repository_links(repoid)
        links.remove(self.env.product.prefix)
        with self.env.db_direct_transaction as db:
            if len(links) > 0:
                db("""UPDATE repository SET value=%s WHERE id=%s
                      AND name='product'""", (','.join(links), repoid))
            else:
                db("""DELETE FROM repository WHERE id=%s AND name='product'
                        AND value='%s'""" % (repoid, self.env.product.prefix))

trac.versioncontrol.api.DbRepositoryProvider = DbRepositoryProvider
trac.versioncontrol.DbRepositoryProvider = DbRepositoryProvider

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: UTF-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import re

from trac.core import Component, TracError, implements
from trac.resource import Neighborhood, Resource, ResourceNotFound
from trac.web.api import HTTPNotFound, IRequestHandler, IRequestFilter
from trac.web.chrome import (
    Chrome, INavigationContributor, add_link, add_notice, add_warning,
    prevnext_nav, web_context
)

from multiproduct.env import resolve_product_href, lookup_product_env
from multiproduct.hooks import PRODUCT_RE
from multiproduct.model import Product
from multiproduct.env import ProductEnvironment
from multiproduct.util.translation import _

# requests to the following URLs will be skipped in the global scope
# (no more redirection to default product)
IGNORED_REQUESTS_RE = \
    re.compile(r'^/(?P<section>milestone|roadmap|search|'
               r'(raw-|zip-)?attachment/(ticket|milestone))(?P<pathinfo>.*)')

class ProductModule(Component):
    """Base Product behaviour"""

    implements(IRequestFilter, IRequestHandler)

    # IRequestFilter methods
    def pre_process_request(self, req, handler):
        if not isinstance(self.env, ProductEnvironment) and \
           IGNORED_REQUESTS_RE.match(req.path_info):
            return None
        return handler

    def post_process_request(req, template, data, content_type):
        return template, data, content_type

    # IRequestHandler methods
    def match_request(self, req):
        m = PRODUCT_RE.match(req.path_info)
        if m:
            req.args['productid'] = m.group('pid')
            req.args['pathinfo'] = m.group('pathinfo')
        return not m is None

    def process_request(self, req):
        """process request handler"""

        req.perm.require('PRODUCT_VIEW')
        pid = req.args.get('productid', None)
        if pid:
            req.perm('product', pid).require('PRODUCT_VIEW')

        try:
            product = Product(self.env, {'prefix': pid})
        except ResourceNotFound:
            product = Product(self.env)

        path_info = req.args.get('pathinfo')
        if path_info and path_info != '/':
            if not product._exists:
                # bh:ticket:561 - Display product list and warning message
                if pid:
                    add_warning(req, _("Product %(pid)s not found", pid=pid))
                return self._render_list(req)
            else:
                raise HTTPNotFound(
                    _('Unable to render product page. Wrong setup?'))

        if pid:
            add_link(req, 'up', req.href.products(), _('Products'))

        action = req.args.get('action', 'view')
        if req.method == 'POST':
            if 'cancel' in req.args:
                req.redirect(req.href.products(product.prefix))
            elif action == 'edit':
                return self._do_save(req, product)
            elif action == 'delete':
                raise TracError(_('Product removal is not allowed!'))
        elif action in ('new', 'edit'):
            return self._render_editor(req, product)
        elif action == 'delete':
            raise TracError(_('Product removal is not allowed!'))

        if not product._exists:
            if pid:
                # bh:ticket:561 - Display product list and warning message
                add_warning(req, _("Product %(pid)s not found", pid=pid))
            return self._render_list(req)

        data = {'product': product,
                'context': web_context(req, product.resource)}
        return 'product_view.html', data, None

    def _render_list(self, req):
        """products list"""
        products = [p for p in Product.select(self.env)
                    if 'PRODUCT_VIEW' in req.perm(Neighborhood('product',
                                                               p.prefix))]
        map(lambda p: setattr(p, 'href', resolve_product_href(
            lookup_product_env(self.env, p.prefix), self.env)), products)
        data = {'products': products,
                'context': web_context(req, Resource('product', None))}
        return 'product_list.html', data, None

    def _render_editor(self, req, product):
        """common processing for creating rendering the edit page"""
        if product._exists:
            req.perm(product.resource).require('PRODUCT_MODIFY')
        else:
            req.perm(product.resource).require('PRODUCT_CREATE')

        chrome = Chrome(self.env)
        chrome.add_jquery_ui(req)
        chrome.add_wiki_toolbars(req)
        data = {'product': product,
                'context': web_context(req, product.resource)}
        return 'product_edit.html', data, None

    def _do_save(self, req, product):
        """common processing for product save events"""
        req.perm.require('PRODUCT_VIEW')

        name = req.args.get('name')
        prefix = req.args.get('prefix')
        description = req.args.get('description', '')

        owner = req.args.get('owner') or req.authname
        keys = {'prefix': prefix}
        field_data = {'name': name,
                      'description': description,
                      'owner': owner,
                      }

        warnings = []
        def warn(msg):
            add_warning(req, msg)
            warnings.append(msg)

        if product._exists:
            if name != product.name and Product.select(self.env,
                                                       where={'name': name}):
                warn(_('A product with name "%(name)s" already exists, please '
                       'choose a different name.', name=name))
            elif not name:
                warn(_('You must provide a name for the product.'))
            else:
                req.perm.require('PRODUCT_MODIFY')
                product.update_field_dict(field_data)
                product.update(req.authname)
                add_notice(req, _('Your changes have been saved.'))
        else:
            req.perm.require('PRODUCT_CREATE')

            if not prefix:
                warn(_('You must provide a prefix for the product.'))
            elif Product.select(self.env, where={'prefix': prefix}):
                warn(_('Product "%(id)s" already exists, please choose another '
                       'prefix.', id=prefix))
            if not name:
                warn(_('You must provide a name for the product.'))
            elif Product.select(self.env, where={'name': name}):
                warn(_('A product with name "%(name)s" already exists, please '
                       'choose a different name.', name=name))

            if not warnings:
                prod = Product(self.env)
                prod.update_field_dict(keys)
                prod.update_field_dict(field_data)
                prod.insert()
                add_notice(req, _('The product "%(id)s" has been added.',
                                  id=prefix))

        if warnings:
            product.update_field_dict(keys)
            product.update_field_dict(field_data)
            return self._render_editor(req, product)
        req.redirect(req.href.products(prefix))

    # helper methods for INavigationContributor implementations
    @classmethod
    def get_product_path(cls, env, req, itempath):
        """Provide a navigation item path"""
        product = req.args.get('productid', '')
        if product and env.is_component_enabled(ProductModule):
            return req.href('products', product, itempath)
        return req.href(itempath)

    @classmethod
    def get_product_list(cls, env, req, href_fcn=None):
        """Returns a list of products as (prefix, name, url) tuples
        """
        if href_fcn is None:
            href_fcn = req.href.products
        product_list = []
        for product in Product.select(env):
            if 'PRODUCT_VIEW' in req.perm(Neighborhood('product',
                                                       product.prefix).
                                          child(product.resource)):
                product_list.append((product.prefix, product.name,
                                     href_fcn(product.prefix)))
        return product_list

########NEW FILE########
__FILENAME__ = console
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's admin console in product environments"""

import os.path
import sys
import unittest

from trac.admin.tests.console import TracadminTestCase, load_expected_results

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase


class ProductTracAdminTestCase(TracadminTestCase, MultiproductTestCase):

    expected_results = load_expected_results(
            os.path.join(os.path.split(__file__)[0], 'console-tests.txt'),
            '===== (test_[^ ]+) =====')

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(
                    enable=('trac.*', 'multiproduct.*'),
                    disable=('trac.tests.*',),
            )
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(self.global_env,
                                                 self.default_product)
            self._load_default_data(env)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None

    def test_product_help_ok(self):
        self._admin.env_set('', self.global_env)
        from trac import __version__
        test_name = sys._getframe().f_code.co_name
        expected_results = self.expected_results[test_name] \
                           % {'version': __version__}
        rv, output = self._execute('product admin %s help'
                                   % self.default_product)
        self.assertEqual(0, rv)
        self.assertEqual(expected_results, output)

    def test_product_help_version(self):
        rv, output = self._execute('help version')
        self.assertEqual(0, rv)
        expected = self.expected_results[self._testMethodName]
        self.assertEqual(expected, output)

    def test_product_help_version_add(self):
        rv, output = self._execute('help version add')
        self.assertEqual(0, rv)
        expected = self.expected_results[self._testMethodName]
        self.assertEqual(expected, output)

    def test_product_fail_version_add(self):
        rv, output = self._execute('version add v x y')
        self.assertEqual(2, rv)
        expected = self.expected_results[self._testMethodName]
        self.assertEqual(expected, output)


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductTracAdminTestCase),
    ])


if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = product_admin
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's product admin"""

import sys
import unittest
from wsgiref.util import setup_testing_defaults

from trac.admin.api import IAdminPanelProvider
from trac.admin.web_ui import AdminModule, PluginAdminPanel
from trac.core import Component, implements
from trac.perm import DefaultPermissionPolicy, DefaultPermissionStore, \
                      PermissionCache, PermissionSystem
from trac.tests.perm import TestPermissionRequestor
from trac.web.api import HTTP_STATUS, HTTPForbidden, HTTPNotFound, \
                         IRequestFilter, RequestDone, Request
from trac.web.main import RequestDispatcher

from multiproduct import api, product_admin
from multiproduct.env import ProductEnvironment
from multiproduct.product_admin import IProductAdminAclContributor, \
                                       ProductAdminModule
from tests.env import MultiproductTestCase

class TestAdminHandledException(Exception):
    product = None
    category = None
    page = None
    path_info = None
    admin_panels = None

class TestAdminPanel(Component):
    implements(IAdminPanelProvider, IRequestFilter)

    # IAdminPanelProvider methods
    def get_admin_panels(self, req):
        if 'TRAC_ADMIN' in req.perm:
            yield 'testcat1', 'Test category 1', 'panel1', 'Test panel 1'
            yield 'testcat1', 'Test category 1', 'panel2', 'Test panel 2'
            yield 'testcat1', 'Test category 1', 'panel3', 'Test panel 3'

            yield 'testcat2', 'Test category 2', 'panel1', 'Test panel 1'
            yield 'testcat2', 'Test category 2', 'panel_2', 'Test panel 2'
            yield 'testcat2', 'Test category 2', 'panel-3', 'Test panel 3'

            yield 'testcat3', 'Test category 3', 'panel1', 'Test panel 1'
            yield 'testcat3', 'Test category 3', 'panel2', 'Test panel 2'

    def render_admin_panel(self, req, category, page, path_info):
        req.perm.require('TRAC_ADMIN')
        return 'test.html', {'path_info' : path_info}

    def pre_process_request(self, req, handler):
        return handler

    def post_process_request(self, req, template, data, content_type):
        if sys.exc_info() == (None, None, None):
            exc = TestAdminHandledException()
            exc.product = self.env.product.prefix \
                     if isinstance(self.env, ProductEnvironment) \
                     else ''
            exc.category = data.get('active_cat')
            exc.page = data.get('active_panel')
            exc.path_info = data.get('path_info')
            exc.admin_panels = data.get('panels')
            raise exc
        else:
            return template, data, content_type


class PanelsWhitelist(Component):
    implements(product_admin.IProductAdminAclContributor)

    # IProductAdminAclContributor methods
    def enable_product_admin_panels(self):
        yield 'testcat1', 'panel1'
        yield 'testcat1', 'panel3'
        yield 'testcat2', 'panel3'
        yield 'general', 'plugin'


class SectionWhitelist(Component):
    implements(product_admin.IProductAdminAclContributor)

    # IProductAdminAclContributor methods
    def enable_product_admin_panels(self):
        yield 'testcat3', '*'

class BaseProductAdminPanelTestCase(MultiproductTestCase):
    def setUp(self):
        self._mp_setup(enable=[AdminModule, DefaultPermissionPolicy,
                               DefaultPermissionStore, PermissionSystem,
                               PluginAdminPanel, RequestDispatcher,
                               api.MultiProductSystem,
                               product_admin.ProductAdminModule,
                               PanelsWhitelist, SectionWhitelist,
                               TestAdminPanel, TestPermissionRequestor])
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)

        ProductAdminModule = product_admin.ProductAdminModule
        self.global_product_admin = ProductAdminModule(self.global_env)
        self.product_admin = ProductAdminModule(self.env)

    def tearDown(self):
        self.global_env.reset_db()
        self.env = self.global_env = None
        self.product_admin = self.global_product_admin = None


class ProductAdminSetupTestCase(BaseProductAdminPanelTestCase):
    ALL_PANELS = [('testcat1', 'panel1'), ('testcat1', 'panel2'),
                  ('testcat1', 'panel3'), ('testcat2', 'panel_1'),
                  ('testcat2', 'panel-2'), ('testcat2', 'panel3'),
                  ('testcat3', 'panel1'), ('testcat3', 'panel2'),
                  ('general', 'plugin'), ]

    def test_init_whitelist(self):
        self.assertEqual({}, self.global_product_admin.acl)
        self.assertEqual({'testcat3' : True,
                          ('testcat1', 'panel1') : True,
                          ('testcat1', 'panel3'): True,
                          ('testcat2', 'panel3'): True,
                          ('general', 'plugin') : True,},
                         self.product_admin.acl)
        self.assertTrue(all(not self.global_product_admin._check_panel(c, p)
                            for c, p in self.ALL_PANELS))
        self.assertTrue(self.product_admin._check_panel('testcat1', 'panel1'))
        self.assertFalse(self.product_admin._check_panel('testcat1', 'panel2'))
        self.assertTrue(self.product_admin._check_panel('testcat1', 'panel3'))
        self.assertFalse(self.product_admin._check_panel('testcat2', 'panel_1'))
        self.assertFalse(self.product_admin._check_panel('testcat2', 'panel-2'))
        self.assertTrue(self.product_admin._check_panel('testcat2', 'panel3'))
        self.assertTrue(self.product_admin._check_panel('testcat3', 'panel1'))
        self.assertTrue(self.product_admin._check_panel('testcat3', 'panel2'))
        self.assertFalse(self.product_admin._check_panel('general', 'plugin'))
        self.assertFalse(self.product_admin._check_panel('other', 'panel'))

    def test_init_blacklist(self):
        self.global_env.config.set('multiproduct', 'admin_blacklist',
                                   'testcat1:panel1,testcat3:panel2')
        self.env.config.set('multiproduct', 'admin_blacklist',
                            'testcat1:panel3,testcat3:panel1,testcat2:*')

        self.assertEqual(['testcat1:panel1','testcat3:panel2'],
                          self.global_product_admin.raw_blacklist)
        self.assertEqual(['testcat1:panel3','testcat3:panel1','testcat2:*'],
                         self.product_admin.raw_blacklist)

        self.assertEqual({}, self.global_product_admin.acl)
        self.assertEqual({'testcat3' : True,
                          'testcat2' : False,
                          ('testcat1', 'panel1') : True,
                          ('testcat1', 'panel3'): False,
                          ('testcat2', 'panel3'): True,
                          ('testcat3', 'panel1'): False,
                          ('general', 'plugin'): True,},
                         self.product_admin.acl)

        self.assertTrue(all(not self.global_product_admin._check_panel(c, p)
                            for c, p in self.ALL_PANELS))
        self.assertTrue(self.product_admin._check_panel('testcat1', 'panel1'))
        self.assertFalse(self.product_admin._check_panel('testcat1', 'panel2'))
        self.assertFalse(self.product_admin._check_panel('testcat1', 'panel3'))
        self.assertFalse(self.product_admin._check_panel('testcat2', 'panel_1'))
        self.assertFalse(self.product_admin._check_panel('testcat2', 'panel-2'))
        self.assertFalse(self.product_admin._check_panel('testcat2', 'panel3'))
        self.assertFalse(self.product_admin._check_panel('testcat3', 'panel1'))
        self.assertTrue(self.product_admin._check_panel('testcat3', 'panel2'))
        self.assertFalse(self.product_admin._check_panel('general', 'plugin'))
        self.assertFalse(self.product_admin._check_panel('other', 'panel'))


class ProductAdminDispatchTestCase(BaseProductAdminPanelTestCase):
    maxDiff = None

    def setUp(self):
        BaseProductAdminPanelTestCase.setUp(self)
        self.global_env.config.set('multiproduct', 'admin_blacklist',
                                   'testcat1:panel1,testcat3:panel2')
        self.env.config.set('multiproduct', 'admin_blacklist',
                            'testcat1:panel3,testcat3:panel1,testcat2:*')
        global_permsys = PermissionSystem(self.global_env)
        permsys = PermissionSystem(self.env)

        global_permsys.grant_permission('adminuser', 'TRAC_ADMIN')
        global_permsys.grant_permission('prodadmin', 'PRODUCT_ADMIN')
        global_permsys.grant_permission('testuser', 'TEST_ADMIN')
        permsys.grant_permission('prodadmin', 'PRODUCT_ADMIN')
        permsys.grant_permission('testuser', 'TEST_ADMIN')

        self.req = self._get_request_obj()

    def tearDown(self):
        BaseProductAdminPanelTestCase.tearDown(self)
        self.req = None

    def _get_request_obj(self):
        environ = {}
        setup_testing_defaults(environ)

        def start_response(status, headers):
            return lambda body: None

        req = Request(environ, start_response)
        return req

    def _dispatch(self, req, env):
        req.perm = PermissionCache(env, req.authname)
        return RequestDispatcher(env).dispatch(req)

    GLOBAL_PANELS = [
            {'category': {'id': 'general', 'label': 'General'},
             'panel': {'id': 'plugin', 'label': 'Plugins'}},
            {'category': {'id': 'testcat1', 'label': 'Test category 1'},
             'panel': {'id': 'panel1', 'label': 'Test panel 1'}},
            {'category': {'id': 'testcat1', 'label': 'Test category 1'},
             'panel': {'id': 'panel2', 'label': 'Test panel 2'}},
            {'category': {'id': 'testcat1', 'label': 'Test category 1'},
             'panel': {'id': 'panel3', 'label': 'Test panel 3'}},
            {'category': {'id': 'testcat2', 'label': 'Test category 2'},
             'panel': {'id': 'panel-3', 'label': 'Test panel 3'}},
            {'category': {'id': 'testcat2', 'label': 'Test category 2'},
             'panel': {'id': 'panel1', 'label': 'Test panel 1'}},
            {'category': {'id': 'testcat2', 'label': 'Test category 2'},
             'panel': {'id': 'panel_2', 'label': 'Test panel 2'}},
            {'category': {'id': 'testcat3', 'label': 'Test category 3'},
             'panel': {'id': 'panel1', 'label': 'Test panel 1'}},
            {'category': {'id': 'testcat3', 'label': 'Test category 3'},
             'panel': {'id': 'panel2', 'label': 'Test panel 2'}}]
    PRODUCT_PANELS_ALL = [
            {'category': {'id': 'testcat1', 'label': 'Test category 1'},
             'panel': {'id': 'panel1', 'label': 'Test panel 1'}},
            {'category': {'id': 'testcat1', 'label': 'Test category 1'},
             'panel': {'id': 'panel2', 'label': 'Test panel 2'}},
            {'category': {'id': 'testcat1', 'label': 'Test category 1'},
             'panel': {'id': 'panel3', 'label': 'Test panel 3'}},
            {'category': {'id': 'testcat2', 'label': 'Test category 2'},
             'panel': {'id': 'panel-3', 'label': 'Test panel 3'}},
            {'category': {'id': 'testcat2', 'label': 'Test category 2'},
             'panel': {'id': 'panel1', 'label': 'Test panel 1'}},
            {'category': {'id': 'testcat2', 'label': 'Test category 2'},
             'panel': {'id': 'panel_2', 'label': 'Test panel 2'}},
            {'category': {'id': 'testcat3', 'label': 'Test category 3'},
             'panel': {'id': 'panel1', 'label': 'Test panel 1'}},
            {'category': {'id': 'testcat3', 'label': 'Test category 3'},
             'panel': {'id': 'panel2', 'label': 'Test panel 2'}}]
    PRODUCT_PANELS_ALLOWED = [
            {'category': {'id': 'testcat1', 'label': 'Test category 1'},
             'panel': {'id': 'panel1', 'label': 'Test panel 1'}},
            {'category': {'id': 'testcat3', 'label': 'Test category 3'},
             'panel': {'id': 'panel2', 'label': 'Test panel 2'}}]

    # TRAC_ADMIN
    def test_tracadmin_global_panel(self):
        """Test admin panel with TRAC_ADMIN in global env
        """
        req = self.req
        req.authname = 'adminuser'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel1/some/path'
        with self.assertRaises(TestAdminHandledException) as test_cm:
            self._dispatch(req, self.global_env)

        exc = test_cm.exception
        self.assertEqual('', exc.product)
        self.assertEqual('testcat1', exc.category)
        self.assertEqual('panel1', exc.page)
        self.assertEqual('some/path', exc.path_info)
        self.assertEqual(self.GLOBAL_PANELS, exc.admin_panels)

    def test_tracadmin_global_plugins(self):
        """Plugin admin panel with TRAC_ADMIN in global env
        """
        req = self.req
        req.authname = 'adminuser'
        req.environ['PATH_INFO'] = '/admin/general/plugin'
        # Plugin admin panel looked up but disabled
        with self.assertRaises(TestAdminHandledException) as test_cm:
            self._dispatch(req, self.global_env)

        exc = test_cm.exception
        self.assertEqual(self.GLOBAL_PANELS, exc.admin_panels)

    def test_tracadmin_product_panel_blacklist(self):
        """Test blacklisted admin panel with TRAC_ADMIN in product env
        """
        req = self.req
        req.authname = 'adminuser'
        req.environ['PATH_INFO'] = '/admin/testcat3/panel1/some/path'
        with self.assertRaises(TestAdminHandledException) as test_cm:
            self._dispatch(req, self.env)

        exc = test_cm.exception
        self.assertEqual(self.default_product, exc.product)
        self.assertEqual('testcat3', exc.category)
        self.assertEqual('panel1', exc.page)
        self.assertEqual('some/path', exc.path_info)
        self.assertEqual(self.PRODUCT_PANELS_ALL, exc.admin_panels)

    def test_tracadmin_product_panel_whitelist(self):
        """Test whitelisted admin panel with TRAC_ADMIN in product env
        """
        req = self.req
        req.authname = 'adminuser'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel1/some/path'
        with self.assertRaises(TestAdminHandledException) as test_cm:
            self._dispatch(req, self.env)

        exc = test_cm.exception
        self.assertEqual(self.default_product, exc.product)
        self.assertEqual('testcat1', exc.category)
        self.assertEqual('panel1', exc.page)
        self.assertEqual('some/path', exc.path_info)
        self.assertEqual(self.PRODUCT_PANELS_ALL, exc.admin_panels)

    def test_tracadmin_product_plugins(self):
        """Plugin admin panel with TRAC_ADMIN in global env
        """
        req = self.req
        req.authname = 'adminuser'
        req.environ['PATH_INFO'] = '/admin/general/plugin'
        # Plugin admin panel not available in product context
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.env)

    # PRODUCT_ADMIN
    def test_productadmin_global_panel_whitelist(self):
        """Test whitelisted admin panel with PRODUCT_ADMIN in product env
        """
        req = self.req
        req.authname = 'prodadmin'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel1/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.global_env)

    def test_productadmin_global_panel_blacklist(self):
        """Test blacklisted admin panel with PRODUCT_ADMIN in product env
        """
        req = self.req
        req.authname = 'prodadmin'
        req.environ['PATH_INFO'] = '/admin/testcat3/panel1/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.global_env)

    def test_productadmin_global_panel_norules(self):
        """Test unspecified admin panel with PRODUCT_ADMIN in product env
        """
        req = self.req
        req.authname = 'prodadmin'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel2/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.global_env)

    def test_productadmin_global_plugins(self):
        """Plugin admin panel with PRODUCT_ADMIN in global env
        """
        req = self.req
        req.authname = 'prodadmin'
        req.environ['PATH_INFO'] = '/admin/general/plugin'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.global_env)

    def test_productadmin_product_panel_whitelist(self):
        """Test whitelisted admin panel with PRODUCT_ADMIN in product env
        """
        req = self.req
        req.authname = 'prodadmin'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel1/some/path'
        with self.assertRaises(TestAdminHandledException) as test_cm:
            self._dispatch(req, self.env)

        exc = test_cm.exception
        self.assertEqual(self.default_product, exc.product)
        self.assertEqual('testcat1', exc.category)
        self.assertEqual('panel1', exc.page)
        self.assertEqual('some/path', exc.path_info)
        self.assertEqual(self.PRODUCT_PANELS_ALLOWED, exc.admin_panels)

    def test_productadmin_product_panel_blacklist(self):
        """Test blacklisted admin panel with PRODUCT_ADMIN in product env
        """
        req = self.req
        req.authname = 'prodadmin'
        req.environ['PATH_INFO'] = '/admin/testcat3/panel1/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.env)

    def test_productadmin_product_panel_norules(self):
        """Test unspecified admin panel with PRODUCT_ADMIN in product env
        """
        req = self.req
        req.authname = 'prodadmin'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel2/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.env)

    def test_productadmin_product_plugins(self):
        """Plugin admin panel with PRODUCT_ADMIN in product env
        """
        req = self.req
        req.authname = 'prodadmin'
        req.environ['PATH_INFO'] = '/admin/general/plugin'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.env)

    # Without meta-permissions
    def test_user_global_panel_whitelist(self):
        """Test whitelisted admin panel without meta-perm in product env
        """
        req = self.req
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel1/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.global_env)

    def test_user_global_panel_blacklist(self):
        """Test blacklisted admin panel without meta-perm in product env
        """
        req = self.req
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/admin/testcat3/panel1/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.global_env)

    def test_user_global_panel_norules(self):
        """Test unspecified admin panel without meta-perm in product env
        """
        req = self.req
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel2/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.global_env)

    def test_user_global_plugins(self):
        """Plugin admin panel without meta-perm in global env
        """
        req = self.req
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/admin/general/plugin'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.global_env)

    def test_user_product_panel_whitelist(self):
        """Test whitelisted admin panel without meta-perm in product env
        """
        req = self.req
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel1/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.env)

    def test_user_product_panel_blacklist(self):
        """Test blacklisted admin panel without meta-perm in product env
        """
        req = self.req
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/admin/testcat3/panel1/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.env)

    def test_user_product_panel_norules(self):
        """Test unspecified admin panel without meta-perm in product env
        """
        req = self.req
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/admin/testcat1/panel2/some/path'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.env)

    def test_user_product_plugins(self):
        """Plugin admin panel without meta-perm in product env
        """
        req = self.req
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/admin/general/plugin'
        with self.assertRaises(HTTPNotFound):
            self._dispatch(req, self.env)



def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductAdminSetupTestCase,'test'),
            unittest.makeSuite(ProductAdminDispatchTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = attachment
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's attachments in product environments"""

import shutil
import os.path
import unittest

from trac.attachment import Attachment
from trac.test import EnvironmentStub
from trac.tests.attachment import AttachmentTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductAttachmentTestCase(AttachmentTestCase, MultiproductTestCase):

    def setUp(self):
        try:
            AttachmentTestCase.setUp(self)
        except:
            self.global_env = self.env
            self.tearDown()
            raise
        else:
            self.global_env = global_env = self.env
            self._upgrade_mp(global_env)
            self._setup_test_log(global_env)
            self._load_product_from_data(global_env, self.default_product)
            self.env = ProductEnvironment(global_env, self.default_product)

            # Root folder for default product environment
            self.attachments_dir = os.path.join(self.global_env.path,
                    'products', self.default_product, 'files', 'attachments')

    def tearDown(self):
        if os.path.exists(self.global_env.path):
            shutil.rmtree(self.global_env.path)
        self.env.reset_db()

    def test_product_path_isolation(self):
        product_attachment = Attachment(self.env, 'ticket', '42')
        global_attachment = Attachment(self.global_env, 'ticket', '42')
        global_attachment.filename = product_attachment.filename = 'foo.txt'

        self.assertNotEqual(product_attachment.path, global_attachment.path)

def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductAttachmentTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = config
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's product configuration objects"""

import os.path
import shutil
import time
import unittest
from ConfigParser import ConfigParser
from StringIO import StringIO
from itertools import groupby

from trac.config import Option
from trac.tests.config import ConfigurationTestCase
from trac.util.text import to_unicode

from multiproduct.api import MultiProductSystem
from multiproduct.config import Configuration
from multiproduct.model import Product, ProductSetting
from tests.env import MultiproductTestCase

class MultiproductConfigTestCase(MultiproductTestCase):
    r"""Test setup for configuration test cases.
    """
    def setUp(self):
        r"""Replace Trac environment with product environment
        """
        self.env = self._setup_test_env()

        # Dummy config file, a sibling of trac.ini
        tmpdir = os.path.realpath(self.env.path)
        self.filename = os.path.join(tmpdir, 'conf', 'product.ini')
        # Ensure conf sub-folder is created
        os.path.dirname(self.filename)

        self._upgrade_mp(self.env)
        self._setup_test_log(self.env)
        self._load_product_from_data(self.env, self.default_product)
        self._orig_registry = Option.registry
        Option.registry = {}

    def tearDown(self):
        Option.registry = self._orig_registry
        shutil.rmtree(self.env.path)
        self.env = None

    def _read(self, parents=None, product=None):
        r"""Override superclass method by returning product-aware configuration
        object retrieving settings from the database. Such objects will replace
        instances of `trac.config.Configuration` used in inherited test cases.
        """
        if product is None:
            product = self.default_product
        return Configuration(self.env, product, parents)

    def _write(self, lines, product=None):
        r"""Override superclass method by writing configuration values
        to the database rather than ini file in the filesystem.
        """
        if product is None:
            product = self.default_product
        product = to_unicode(product)
        fp = StringIO(('\n'.join(lines + [''])).encode('utf-8'))
        parser = ConfigParser()
        parser.readfp(fp, 'bh-product-test')
        with self.env.db_transaction as db:
            # Delete existing setting for target product , if any
            for setting in ProductSetting.select(self.env, db,
                    {'product' : product}):
                setting.delete()
            # Insert new options
            for section in parser.sections():
                option_key = dict(
                        section=to_unicode(section),
                        product=to_unicode(product)
                    )
                for option, value in parser.items(section):
                    option_key.update(dict(option=to_unicode(option)))
                    setting = ProductSetting(self.env)
                    setting._data.update(option_key)
                    setting._data['value'] = to_unicode(value)
                    setting.insert()

    def _test_with_inherit(self, testcb):
        """Almost exact copy of `trac.tests.config.ConfigurationTestCase`.
        Differences explained in inline comments.
        """
        # Parent configuration file created in environment's conf sub-folder
        # PS: This modification would not be necessary if the corresponding
        #     statement in overriden method would be written the same way
        #     but the fact that both files have the same parent folder
        #     is not made obvious in there
        sitename = os.path.join(os.path.dirname(self.filename), 'trac-site.ini')

        try:
            with open(sitename, 'w') as sitefile:
                sitefile.write('[a]\noption = x\n')

            self._write(['[inherit]', 'file = trac-site.ini'])
            testcb()
        finally:
            os.remove(sitename)

    def _dump_settings(self, config):
        product = config.product
        fields = ('section', 'option', 'value')
        rows = [tuple(getattr(s, f, None) for f in fields) for s in
                ProductSetting.select(config.env, where={'product' : product})]

        dump = []
        for section, group in groupby(sorted(rows), lambda row: row[0]):
            dump.append('[%s]\n' % (section,))
            for row in group:
                dump.append('%s = %s\n' % (row[1], row[2]))
        return dump


class ProductConfigTestCase(MultiproductConfigTestCase, ConfigurationTestCase):
    r"""Test cases for Trac configuration objects rewritten for product
    scope.
    """
    # Test cases rewritten to avoid reading config file.
    # It does make sense for product config as it's stored in the database

    def test_set_and_save(self):
        config = self._read()
        config.set('b', u'ption0', 'y')
        config.set(u'a', 'ption0', 'x')
        config.set('a', 'option2', "Voil l't")  # UTF-8
        config.set(u'a', 'option1', u"Voil l't") # unicode
        # Note: the following would depend on the locale.getpreferredencoding()
        # config.set('a', 'option3', "Voil\xe0 l'\xe9t\xe9") # latin-1
        self.assertEquals('x', config.get(u'a', u'ption0'))
        self.assertEquals(u"Voil l't", config.get(u'a', 'option1'))
        self.assertEquals(u"Voil l't", config.get(u'a', 'option2'))
        config.save()

        dump = self._dump_settings(config)
        self.assertEquals([
                           u'[a]\n',
                           u"option1 = Voil l't\n",
                           u"option2 = Voil l't\n",
                           u'ption0 = x\n',
                           # u"option3 = Voil l't\n",
                           u'[b]\n',
                           u'ption0 = y\n',
                           ],
                          dump)
        config2 = self._read()
        self.assertEquals('x', config2.get(u'a', u'ption0'))
        self.assertEquals(u"Voil l't", config2.get(u'a', 'option1'))
        self.assertEquals(u"Voil l't", config2.get(u'a', 'option2'))
        # self.assertEquals(u"Voil l't", config2.get('a', 'option3'))

    def test_set_and_save_inherit(self):
        def testcb():
            config = self._read()
            config.set('a', 'option2', "Voil l't")  # UTF-8
            config.set('a', 'option1', u"Voil l't") # unicode
            self.assertEquals('x', config.get('a', 'option'))
            self.assertEquals(u"Voil l't", config.get('a', 'option1'))
            self.assertEquals(u"Voil l't", config.get('a', 'option2'))
            config.save()

            dump = self._dump_settings(config)
            self.assertEquals([
                               u'[a]\n',
                               u"option1 = Voil l't\n",
                               u"option2 = Voil l't\n",
                               u'[inherit]\n',
                               u"file = trac-site.ini\n",
                               ],
                              dump)
            config2 = self._read()
            self.assertEquals('x', config2.get('a', 'option'))
            self.assertEquals(u"Voil l't", config2.get('a', 'option1'))
            self.assertEquals(u"Voil l't", config2.get('a', 'option2'))
        self._test_with_inherit(testcb)

    def test_overwrite(self):
        config = self._read()
        config.set('a', 'option', 'value1')
        self.assertEquals('value1', config.get('a', 'option'))
        config.set('a', 'option', 'value2')
        self.assertEquals('value2', config.get('a', 'option'))


class ProductConfigSyncTestCase(MultiproductConfigTestCase):
    """Test cases for concurrent access of product configuration objects.
    """
    def test_sync(self):
        """Config cache consistency on concurrent edits
        """
        config1 = self._read()
        config2 = self._read()

        # Initial values will be empty
        # This will initialize both instances' cache
        self.assertEqual('', config1.get('s', 'o'))
        self.assertEqual('', config2.get('s', 'o'))

        # First time assignment, no actual cache
        config1.set('s', 'o', 'value0')
        self.assertEqual('value0', config1.get('s', 'o'))
        self.assertEqual('value0', config2.get('s', 'o'))

        # Subsequent hits retrieved from cache
        config1.set('s', 'o', 'value1')
        self.assertEqual('value0', config2.get('s', 'o'))
        # ... unless cache invalidated e.g. by calling save()
        config1.save()
        self.assertTrue(config2.parse_if_needed())
        self.assertEqual('value1', config1.get('s', 'o'))
        self.assertEqual('value1', config2.get('s', 'o'))

        # TODO: Replace with trac.util.compat:wait_for_file_mtime_change when
        # changes from Trac 1.0-stable (> r12258) or Trac 1.0.2 are integrated
        # Two edits may look simultaneous depending on FS accuracy,
        # so wait 1 second to ensure next timestamp below will be different
        # otherwise the test is fragile and results non-deterministic.
        # This holds for Trac config objects too.
        time.sleep(1)

        # After update no subsequent modifications reported
        config2.set('s', 'o', 'value2')
        self.assertFalse(config1.parse_if_needed())
        self.assertEqual('value1', config1.get('s', 'o'))
        # ... unless cache invalidated e.g. by calling touch()
        config2.touch()
        self.assertTrue(config1.parse_if_needed())
        self.assertEqual('value2', config1.get('s', 'o'))
        self.assertEqual('value2', config2.get('s', 'o'))
        self.assertTrue(config2.parse_if_needed())


def test_suite():
    suite = unittest.TestSuite()

    suite.addTest(unittest.makeSuite(ProductConfigTestCase,'test'))
    suite.addTest(unittest.makeSuite(ProductConfigSyncTestCase,'test'))

    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = core
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from tests import unittest

from trac.core import Interface, implements, Component

from multiproduct.core import MultiProductExtensionPoint


class MultiProductExtensionPointTestCase(unittest.TestCase):
    def setUp(self):
        from trac.core import ComponentManager, ComponentMeta
        self.compmgr = ComponentManager()

        # Make sure we have no external components hanging around in the
        # component registry
        self.old_registry = ComponentMeta._registry
        ComponentMeta._registry = {}

    def tearDown(self):
        # Restore the original component registry
        from trac.core import ComponentMeta
        ComponentMeta._registry = self.old_registry

    def test_with_trac_component_manager(self):
        """No parent attribute, no _all_product_envs method"""
        class ComponentA(Component):
            implements(ITest)

        class ComponentB(Component):
            mp_extension_point = MultiProductExtensionPoint(ITest)

        components = ComponentB(self.compmgr).mp_extension_point
        self.assertEqual(len(components), 1)
        for c in components:
            self.assertIsInstance(c, ComponentA)

    def test_with_global_product_component_manager(self):
        self.compmgr.parent = None
        self.compmgr.all_product_envs = lambda: [self.compmgr, self.compmgr]

        class ComponentA(Component):
            implements(ITest)

        class ComponentB(Component):
            mp_extension_point = MultiProductExtensionPoint(ITest)

        components = ComponentB(self.compmgr).mp_extension_point
        self.assertEqual(len(components), 3)
        for c in components:
            self.assertIsInstance(c, ComponentA)

    def test_with_product_component_manager(self):
        self.compmgr.parent = self
        self.compmgr.all_product_envs = lambda: [self.compmgr, self.compmgr]

        class ComponentA(Component):
            implements(ITest)

        class ComponentB(Component):
            mp_extension_point = MultiProductExtensionPoint(ITest)

        components = ComponentB(self.compmgr).mp_extension_point
        self.assertEqual(len(components), 1)
        for c in components:
            self.assertIsInstance(c, ComponentA)


class ITest(Interface):
    def test():
        """Dummy function."""


def test_suite():
    return unittest.TestSuite([
        unittest.makeSuite(MultiProductExtensionPointTestCase, 'test'),
    ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest

from trac.db.tests.api import ParseConnectionStringTestCase, StringsTestCase, ConnectionTestCase, WithTransactionTest

from tests.db.util import ProductEnvMixin

class ProductParseConnectionStringTestCase(ParseConnectionStringTestCase, ProductEnvMixin):
    pass

class ProductStringsTestCase(StringsTestCase, ProductEnvMixin):
    pass

class ProductConnectionTestCase(ConnectionTestCase, ProductEnvMixin):
    pass

class ProductWithTransactionTestCase(WithTransactionTest, ProductEnvMixin):
    pass

def suite():
    suite = unittest.TestSuite([
        unittest.makeSuite(ParseConnectionStringTestCase, 'test'),
        unittest.makeSuite(StringsTestCase, 'test'),
        unittest.makeSuite(ConnectionTestCase, 'test'),
        unittest.makeSuite(WithTransactionTest, 'test'),
        unittest.makeSuite(ProductParseConnectionStringTestCase, 'test'),
        unittest.makeSuite(ProductStringsTestCase, 'test'),
        unittest.makeSuite(ProductConnectionTestCase, 'test'),
        unittest.makeSuite(ProductWithTransactionTestCase, 'test'),
    ])
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = cursor
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for multiproduct/dbcursor.py"""

import unittest
from multiproduct.dbcursor import BloodhoundProductSQLTranslate, SKIP_TABLES, TRANSLATE_TABLES, PRODUCT_COLUMN

# Test case data, each section consists of list of tuples of original and correctly translated SQL statements
data = {
    # non-translated SELECTs
    'system_select_nontranslated' : [
        (
"""SELECT id,
               name,
               value
        FROM repository
        WHERE name IN ('alias',
                       'description',
                       'dir',
                       'hidden',
                       'name',
                       'type',
                       'url')""",
"""SELECT id,
               name,
               value
        FROM repository
        WHERE name IN ('alias',
                       'description',
                       'dir',
                       'hidden',
                       'name',
                       'type',
                       'url')"""
        ),
    ],

    # translated SELECTs
    'system_select_translated' : [
        (
"""SELECT TYPE, id,
                     filename,
                     time,
                     description,
                     author
        FROM attachment
        WHERE time > %s
          AND time < %s
          AND TYPE = %s""",
"""SELECT TYPE, id,
                     filename,
                     time,
                     description,
                     author
        FROM (SELECT * FROM attachment WHERE product='PRODUCT') AS attachment
        WHERE time > %s
          AND time < %s
          AND TYPE = %s"""
        ),
        (
"""SELECT name,
               due,
               completed,
               description
        FROM milestone
        WHERE name=%s""",
"""SELECT name,
               due,
               completed,
               description
        FROM (SELECT * FROM milestone WHERE product='PRODUCT') AS milestone
        WHERE name=%s"""
        ),
        (
"""SELECT COALESCE(component, ''),
               count(COALESCE(component, ''))
        FROM ticket
        GROUP BY COALESCE(component, '')""",
"""SELECT COALESCE(component, ''),
               count(COALESCE(component, ''))
        FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket
        GROUP BY COALESCE(component, '')"""
        ),
        (
"""SELECT id, time, reporter, TYPE, summary,
                                         description
        FROM ticket
        WHERE time>=%s
          AND time<=%s""",
"""SELECT id, time, reporter, TYPE, summary,
                                         description
        FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket
        WHERE time>=%s
          AND time<=%s"""
        ),
        (
"""SELECT t.id,
               tc.time,
               tc.author,
               t.type,
               t.summary,
               tc.field,
               tc.oldvalue,
               tc.newvalue
        FROM ticket_change tc
        INNER JOIN ticket t ON t.id = tc.ticket
        AND tc.time>=1351375199999999
        AND tc.time<=1354057199999999
        ORDER BY tc.time""",
"""SELECT t.id,
               tc.time,
               tc.author,
               t.type,
               t.summary,
               tc.field,
               tc.oldvalue,
               tc.newvalue
        FROM (SELECT * FROM ticket_change WHERE product='PRODUCT') AS tc
        INNER JOIN (SELECT * FROM ticket WHERE product='PRODUCT') AS t ON t.id = tc.ticket
        AND tc.time>=1351375199999999
        AND tc.time<=1354057199999999
        ORDER BY tc.time"""
        ),
        (
"""SELECT COUNT(*)
        FROM
          (SELECT t.id AS id,
                  t.summary AS summary,
                  t.owner AS OWNER,
                  t.status AS status,
                  t.priority AS priority,
                  t.milestone AS milestone,
                  t.time AS time,
                  t.changetime AS changetime,
                  priority.value AS priority_value
           FROM ticket AS t
           LEFT OUTER JOIN enum AS priority ON (priority.type='priority'
                                                AND priority.name=priority)
           LEFT OUTER JOIN milestone ON (milestone.name=milestone)
           WHERE ((COALESCE(t.status,'')!=%s)
                  AND (COALESCE(t.OWNER,'')=%s))
           ORDER BY COALESCE(t.milestone,'')='',
                    COALESCE(milestone.completed,0)=0,
                    milestone.completed,
                    COALESCE(milestone.due,0)=0,
                    milestone.due,
                    t.milestone,
                    COALESCE(priority.value,'')='' DESC,CAST(priority.value AS integer) DESC,t.id) AS x""",
"""SELECT COUNT(*)
        FROM
          (SELECT t.id AS id,
                  t.summary AS summary,
                  t.owner AS OWNER,
                  t.status AS status,
                  t.priority AS priority,
                  t.milestone AS milestone,
                  t.time AS time,
                  t.changetime AS changetime,
                  priority.value AS priority_value
           FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS t
           LEFT OUTER JOIN (SELECT * FROM enum WHERE product='PRODUCT') AS priority ON (priority.type='priority'
                                                AND priority.name=priority)
           LEFT OUTER JOIN (SELECT * FROM milestone WHERE product='PRODUCT') AS milestone ON (milestone.name=milestone)
           WHERE ((COALESCE(t.status,'')!=%s)
                  AND (COALESCE(t.OWNER,'')=%s))
           ORDER BY COALESCE(t.milestone,'')='',
                    COALESCE(milestone.completed,0)=0,
                    milestone.completed,
                    COALESCE(milestone.due,0)=0,
                    milestone.due,
                    t.milestone,
                    COALESCE(priority.value,'')='' DESC,CAST(priority.value AS integer) DESC,t.id) AS x"""
        ),
        (
"""SELECT t.id AS id,
               t.summary AS summary,
               t.owner AS OWNER,
               t.status AS status,
               t.priority AS priority,
               t.milestone AS milestone,
               t.time AS time,
               t.changetime AS changetime,
               priority.value AS priority_value
        FROM ticket AS t
        LEFT OUTER JOIN enum AS priority ON (priority.type='priority'
                                             AND priority.name=priority)
        LEFT OUTER JOIN milestone ON (milestone.name=milestone)
        WHERE ((COALESCE(t.status,'')!=%s)
               AND (COALESCE(t.OWNER,'')=%s))
        ORDER BY COALESCE(t.milestone,'')='',
                 COALESCE(milestone.completed,0)=0,
                 milestone.completed,
                 COALESCE(milestone.due,0)=0,
                 milestone.due,
                 t.milestone,
                 COALESCE(priority.value,'')='' DESC,
                 CAST(priority.value AS integer) DESC,t.id""",
"""SELECT t.id AS id,
               t.summary AS summary,
               t.owner AS OWNER,
               t.status AS status,
               t.priority AS priority,
               t.milestone AS milestone,
               t.time AS time,
               t.changetime AS changetime,
               priority.value AS priority_value
        FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS t
        LEFT OUTER JOIN (SELECT * FROM enum WHERE product='PRODUCT') AS priority ON (priority.type='priority'
                                             AND priority.name=priority)
        LEFT OUTER JOIN (SELECT * FROM milestone WHERE product='PRODUCT') AS milestone ON (milestone.name=milestone)
        WHERE ((COALESCE(t.status,'')!=%s)
               AND (COALESCE(t.OWNER,'')=%s))
        ORDER BY COALESCE(t.milestone,'')='',
                 COALESCE(milestone.completed,0)=0,
                 milestone.completed,
                 COALESCE(milestone.due,0)=0,
                 milestone.due,
                 t.milestone,
                 COALESCE(priority.value,'')='' DESC,
                 CAST(priority.value AS integer) DESC,t.id"""
        ),
       (
"""SELECT COUNT(*)
        FROM
          (SELECT p.value AS __color__, id AS ticket, summary, component, VERSION, milestone, t.type AS TYPE, OWNER, status,
                                                                                                                     time AS created,
                                                                                                                     changetime AS _changetime,
                                                                                                                                    description AS _description,
                                                                                                                                                    reporter AS _reporter
           FROM ticket t
           LEFT JOIN enum p ON p.name = t.priority
           AND p.TYPE = 'priority'
           WHERE status <> 'closed'
           ORDER BY CAST(p.value AS integer),
                    milestone,
                    t.TYPE, time ) AS tab""",
"""SELECT COUNT(*)
        FROM
          (SELECT p.value AS __color__, id AS ticket, summary, component, VERSION, milestone, t.type AS TYPE, OWNER, status,
                                                                                                                     time AS created,
                                                                                                                     changetime AS _changetime,
                                                                                                                                    description AS _description,
                                                                                                                                                    reporter AS _reporter
           FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS t
           LEFT JOIN (SELECT * FROM enum WHERE product='PRODUCT') AS p  ON p.name = t.priority
           AND p.TYPE = 'priority'
           WHERE status <> 'closed'
           ORDER BY CAST(p.value AS integer),
                    milestone,
                    t.TYPE, time ) AS tab"""
       ),
        (
"""SELECT COUNT(*)
        FROM
          (SELECT t.id AS id,
                  t.summary AS summary,
                  t.status AS status,
                  t.type AS TYPE,
                  t.priority AS priority,
                  t.product AS product,
                  t.milestone AS milestone,
                  t.time AS time,
                  t.changetime AS changetime,
                  t.owner AS OWNER,
                  priority.value AS priority_value
           FROM ticket AS t
           LEFT OUTER JOIN enum AS priority ON (priority.TYPE='priority'
                                                AND priority.name=priority)
           WHERE ((COALESCE(t.status,'')!=%s)
                  AND (COALESCE(t.OWNER,'')=%s))
           ORDER BY COALESCE(priority.value,'')='',
                                                CAST(priority.value AS integer),
                                                t.id) AS x""",
"""SELECT COUNT(*)
        FROM
          (SELECT t.id AS id,
                  t.summary AS summary,
                  t.status AS status,
                  t.type AS TYPE,
                  t.priority AS priority,
                  t.product AS product,
                  t.milestone AS milestone,
                  t.time AS time,
                  t.changetime AS changetime,
                  t.owner AS OWNER,
                  priority.value AS priority_value
           FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS t
           LEFT OUTER JOIN (SELECT * FROM enum WHERE product='PRODUCT') AS priority ON (priority.TYPE='priority'
                                                AND priority.name=priority)
           WHERE ((COALESCE(t.status,'')!=%s)
                  AND (COALESCE(t.OWNER,'')=%s))
           ORDER BY COALESCE(priority.value,'')='',
                                                CAST(priority.value AS integer),
                                                t.id) AS x"""
        ),
        (
"""SELECT t.id AS id,
               t.summary AS summary,
               t.status AS status,
               t.type AS TYPE,
               t.priority AS priority,
               t.product AS product,
               t.milestone AS milestone,
               t.time AS time,
               t.changetime AS changetime,
               t.owner AS OWNER,
               priority.value AS priority_value
        FROM ticket AS t
        LEFT OUTER JOIN enum AS priority ON (priority.TYPE='priority'
                                             AND priority.name=priority)
        WHERE ((COALESCE(t.status,'')!=%s)
               AND (COALESCE(t.OWNER,'')=%s))
        ORDER BY COALESCE(priority.value,'')='',
                                             CAST(priority.value AS integer),
                                             t.id""",
"""SELECT t.id AS id,
               t.summary AS summary,
               t.status AS status,
               t.type AS TYPE,
               t.priority AS priority,
               t.product AS product,
               t.milestone AS milestone,
               t.time AS time,
               t.changetime AS changetime,
               t.owner AS OWNER,
               priority.value AS priority_value
        FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS t
        LEFT OUTER JOIN (SELECT * FROM enum WHERE product='PRODUCT') AS priority ON (priority.TYPE='priority'
                                             AND priority.name=priority)
        WHERE ((COALESCE(t.status,'')!=%s)
               AND (COALESCE(t.OWNER,'')=%s))
        ORDER BY COALESCE(priority.value,'')='',
                                             CAST(priority.value AS integer),
                                             t.id"""
        ),
        (
"""SELECT *
        FROM
          (SELECT p.value AS __color__, id AS ticket, summary, component, VERSION, milestone, t.type AS TYPE, OWNER, status,
                                                                                                                     time AS created,
                                                                                                                     changetime AS _changetime,
                                                                                                                                    description AS _description,
                                                                                                                                                    reporter AS _reporter
           FROM ticket t
           LEFT JOIN enum p ON p.name = t.priority
           AND p.TYPE = 'priority'
           WHERE status <> 'closed'
           ORDER BY CAST(p.value AS integer),
                    milestone,
                    t.TYPE, time ) AS tab LIMIT 1""",
"""SELECT *
        FROM
          (SELECT p.value AS __color__, id AS ticket, summary, component, VERSION, milestone, t.type AS TYPE, OWNER, status,
                                                                                                                     time AS created,
                                                                                                                     changetime AS _changetime,
                                                                                                                                    description AS _description,
                                                                                                                                                    reporter AS _reporter
           FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS t
           LEFT JOIN (SELECT * FROM enum WHERE product='PRODUCT') AS p  ON p.name = t.priority
           AND p.TYPE = 'priority'
           WHERE status <> 'closed'
           ORDER BY CAST(p.value AS integer),
                    milestone,
                    t.TYPE, time ) AS tab LIMIT 1"""
        ),
        (
"""SELECT p.value AS __color__, id AS ticket, summary, component, VERSION, milestone, t.type AS TYPE, OWNER, status,
                                                                                                                  time AS created,
                                                                                                                  changetime AS _changetime,
                                                                                                                  description AS _description,
                                                                                                                  reporter AS _reporter
        FROM ticket t
        LEFT JOIN enum p ON p.name = t.priority
        AND p.TYPE = 'priority'
        WHERE status <> 'closed'
        ORDER BY CAST(p.value AS integer),
                 milestone,
                 t.TYPE, time""",
"""SELECT p.value AS __color__, id AS ticket, summary, component, VERSION, milestone, t.type AS TYPE, OWNER, status,
                                                                                                                  time AS created,
                                                                                                                  changetime AS _changetime,
                                                                                                                  description AS _description,
                                                                                                                  reporter AS _reporter
        FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS t
        LEFT JOIN (SELECT * FROM enum WHERE product='PRODUCT') AS p ON p.name = t.priority
        AND p.TYPE = 'priority'
        WHERE status <> 'closed'
        ORDER BY CAST(p.value AS integer),
                 milestone,
                 t.TYPE, time"""
        ),
        (
"""SELECT COALESCE(version, '') ,
               count(COALESCE(version, ''))
        FROM
          (SELECT t.id AS id,
                  t.summary AS summary,
                  t.owner AS owner,
                  t.type AS type,
                  t.status AS status,
                  t.priority AS priority,
                  t.milestone AS milestone,
                  t.version AS version,
                  t.time AS time,
                  t.changetime AS changetime,
                  t.product AS product,
                  priority.value AS priority_value
           FROM
             (SELECT *
              FROM ticket
              WHERE product="default") AS t
           LEFT OUTER JOIN
             (SELECT *
              FROM enum
              WHERE product="default") AS priority ON (priority.type='priority'
                                                       AND priority.name=priority)
           LEFT OUTER JOIN
             (SELECT *
              FROM version
              WHERE product="default") AS version ON (version.name=version)
           WHERE ((COALESCE(t.product,'')='default'))
           ORDER BY COALESCE(t.version,'')='',
                    COALESCE(version.time,0)=0,version.time,
                    t.version,COALESCE(priority.value,'')='',
                    CAST(priority.value AS integer),
                    t.id) AS foo
        GROUP BY COALESCE(version, '')""",
"""SELECT COALESCE(version, '') ,
               count(COALESCE(version, ''))
        FROM
          (SELECT t.id AS id,
                  t.summary AS summary,
                  t.owner AS owner,
                  t.type AS type,
                  t.status AS status,
                  t.priority AS priority,
                  t.milestone AS milestone,
                  t.version AS version,
                  t.time AS time,
                  t.changetime AS changetime,
                  t.product AS product,
                  priority.value AS priority_value
           FROM
             (SELECT *
              FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket
              WHERE product="default") AS t
           LEFT OUTER JOIN
             (SELECT *
              FROM (SELECT * FROM enum WHERE product='PRODUCT') AS enum
              WHERE product="default") AS priority ON (priority.type='priority'
                                                       AND priority.name=priority)
           LEFT OUTER JOIN
             (SELECT *
              FROM (SELECT * FROM version WHERE product='PRODUCT') AS version
              WHERE product="default") AS version ON (version.name=version)
           WHERE ((COALESCE(t.product,'')='default'))
           ORDER BY COALESCE(t.version,'')='',
                    COALESCE(version.time,0)=0,version.time,
                    t.version,COALESCE(priority.value,'')='',
                    CAST(priority.value AS integer),
                    t.id) AS foo
        GROUP BY COALESCE(version, '')"""
        ),
        (
"""SELECT w1.name, w1.time, w1.author, w1.text
        FROM wiki w1,(SELECT name, max(version) AS ver
        FROM wiki GROUP BY name) w2
        WHERE w1.version = w2.ver AND w1.name = w2.name
        AND (w1.name LIKE %s ESCAPE '/' OR w1.author LIKE %s ESCAPE '/' OR w1.text LIKE %s ESCAPE '/')""",
"""SELECT w1.name, w1.time, w1.author, w1.text
        FROM (SELECT * FROM wiki WHERE product='PRODUCT') AS w1,(SELECT name, max(version) AS ver
        FROM (SELECT * FROM wiki WHERE product='PRODUCT') AS wiki GROUP BY name)  AS w2
        WHERE w1.version = w2.ver AND w1.name = w2.name
        AND (w1.name LIKE %s ESCAPE '/' OR w1.author LIKE %s ESCAPE '/' OR w1.text LIKE %s ESCAPE '/')"""
        ),
        (
"""INSERT INTO ticket(id, type, time, changetime, component, severity, priority,
                           owner, reporter, cc, version, milestone, status, resolution,
                           summary, description, keywords)
          SELECT id, 'defect', time, changetime, component, severity, priority, owner,
                 reporter, cc, version, milestone, status, resolution, summary,
                 description, keywords FROM ticket_old
          WHERE COALESCE(severity,'') <> 'enhancement'""",
"""INSERT INTO ticket(id, type, time, changetime, component, severity, priority,
                           owner, reporter, cc, version, milestone, status, resolution,
                           summary, description, keywords, product)
          SELECT id, 'defect', time, changetime, component, severity, priority, owner,
                 reporter, cc, version, milestone, status, resolution, summary,
                 description, keywords, 'PRODUCT' FROM (SELECT * FROM "PRODUCT_ticket_old") AS ticket_old
          WHERE COALESCE(severity,'') <> 'enhancement'"""
        ),
        (
"""INSERT INTO ticket(id, type, time, changetime, component, severity, priority,
                               owner, reporter, cc, version, milestone, status, resolution,
                               summary, description, keywords)
              SELECT id, 'enhancement', time, changetime, component, 'normal', priority,
                     owner, reporter, cc, version, milestone, status, resolution, summary,
                     description, keywords FROM ticket_old
              WHERE severity = 'enhancement'""",
"""INSERT INTO ticket(id, type, time, changetime, component, severity, priority,
                               owner, reporter, cc, version, milestone, status, resolution,
                               summary, description, keywords, product)
              SELECT id, 'enhancement', time, changetime, component, 'normal', priority,
                     owner, reporter, cc, version, milestone, status, resolution, summary,
                     description, keywords, 'PRODUCT' FROM (SELECT * FROM "PRODUCT_ticket_old") AS ticket_old
              WHERE severity = 'enhancement'"""
        ),
        (
"""SELECT COUNT(*) FROM (
        SELECT  __color__, __group,
               (CASE
                 WHEN __group = 1 THEN 'Accepted'
                 WHEN __group = 2 THEN 'Owned'
                 WHEN __group = 3 THEN 'Reported'
                 ELSE 'Commented' END) AS __group__,
               ticket, summary, component, version, milestone,
               type, priority, created, _changetime, _description,
               _reporter
        FROM (
         SELECT DISTINCT CAST(p.value AS integer) AS __color__,
              (CASE
                 WHEN owner = %s AND status = 'accepted' THEN 1
                 WHEN owner = %s THEN 2
                 WHEN reporter = %s THEN 3
                 ELSE 4 END) AS __group,
               t.id AS ticket, summary, component, version, milestone,
               t.type AS type, priority, t.time AS created,
               t.changetime AS _changetime, description AS _description,
               reporter AS _reporter
          FROM ticket t
          LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
          LEFT JOIN ticket_change tc ON tc.ticket = t.id AND tc.author = %s
                                        AND tc.field = 'comment'
          WHERE t.status <> 'closed'
                AND (owner = %s OR reporter = %s OR author = %s)
        ) AS sub
        ORDER BY __group, __color__, milestone, type, created

        ) AS tab""",
"""SELECT COUNT(*) FROM (
        SELECT  __color__, __group,
               (CASE
                 WHEN __group = 1 THEN 'Accepted'
                 WHEN __group = 2 THEN 'Owned'
                 WHEN __group = 3 THEN 'Reported'
                 ELSE 'Commented' END) AS __group__,
               ticket, summary, component, version, milestone,
               type, priority, created, _changetime, _description,
               _reporter
        FROM (
         SELECT DISTINCT CAST(p.value AS integer) AS __color__,
              (CASE
                 WHEN owner = %s AND status = 'accepted' THEN 1
                 WHEN owner = %s THEN 2
                 WHEN reporter = %s THEN 3
                 ELSE 4 END) AS __group,
               t.id AS ticket, summary, component, version, milestone,
               t.type AS type, priority, t.time AS created,
               t.changetime AS _changetime, description AS _description,
               reporter AS _reporter
          FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS t
          LEFT JOIN (SELECT * FROM enum WHERE product='PRODUCT') AS p  ON p.name = t.priority AND p.type = 'priority'
          LEFT JOIN (SELECT * FROM ticket_change WHERE product='PRODUCT') AS tc  ON tc.ticket = t.id AND tc.author = %s
                                        AND tc.field = 'comment'
          WHERE t.status <> 'closed'
                AND (owner = %s OR reporter = %s OR author = %s)
        ) AS sub
        ORDER BY __group, __color__, milestone, type, created

        ) AS tab"""
        ),
    ],

    # custom table SELECTs
    'custom_select' : [
        (
"""SELECT bklg_id, count(*) as total
    FROM backlog_ticket
    WHERE tkt_order IS NULL OR tkt_order > -1
    GROUP BY bklg_id
""",
"""SELECT bklg_id, count(*) as total
    FROM (SELECT * FROM "PRODUCT_backlog_ticket") AS backlog_ticket
    WHERE tkt_order IS NULL OR tkt_order > -1
    GROUP BY bklg_id
"""
        ),
        (
"""SELECT bt.bklg_id, t.status, count(*) as total
    FROM backlog_ticket bt, ticket t
    WHERE t.id = bt.tkt_id
    AND (bt.tkt_order IS NULL OR bt.tkt_order > -1)
    GROUP BY bklg_id, status""",
"""SELECT bt.bklg_id, t.status, count(*) as total
    FROM (SELECT * FROM "PRODUCT_backlog_ticket") AS bt, (SELECT * FROM ticket WHERE product='PRODUCT') AS t
    WHERE t.id = bt.tkt_id
    AND (bt.tkt_order IS NULL OR bt.tkt_order > -1)
    GROUP BY bklg_id, status"""
        ),
    ],

    # non-translated INSERTs
    'system_insert_nontranslated' : [
        (
"""INSERT INTO session VALUES (%s,%s,0)""",
"""INSERT INTO session VALUES (%s,%s,0)"""
        ),
    ],

    # translated INSERTs
    'system_insert_translated' : [
        (
"""INSERT INTO ticket_custom (ticket, name, value)
          SELECT id, 'totalhours', '0' FROM ticket WHERE id NOT IN (
            SELECT ticket from ticket_custom WHERE name='totalhours'
          )""",
"""INSERT INTO ticket_custom (ticket, name, value, product)
              SELECT id, 'totalhours', '0', 'PRODUCT' FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket WHERE id NOT IN (
                SELECT ticket from (SELECT * FROM ticket_custom WHERE product='PRODUCT') AS ticket_custom WHERE name='totalhours'
              )"""
        ),
        (
"""INSERT INTO ticket_custom (ticket, name, value)
                    SELECT id, 'totalhours', '0' FROM ticket WHERE id NOT IN (
                    SELECT ticket from ticket_custom WHERE name='totalhours')""",
"""INSERT INTO ticket_custom (ticket, name, value, product)
                        SELECT id, 'totalhours', '0', 'PRODUCT' FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket WHERE id NOT IN (
                        SELECT ticket from (SELECT * FROM ticket_custom WHERE product='PRODUCT') AS ticket_custom WHERE name='totalhours')"""
        ),
        (
"""INSERT INTO session (sid, last_visit, authenticated)
                SELECT distinct s.sid,COALESCE(%s,0),s.authenticated
                FROM session_old AS s LEFT JOIN session_old AS s2
                ON (s.sid=s2.sid AND s2.var_name='last_visit')
                WHERE s.sid IS NOT NULL""",
"""INSERT INTO session (sid, last_visit, authenticated)
                SELECT distinct s.sid,COALESCE(%s,0),s.authenticated
                FROM (SELECT * FROM "PRODUCT_session_old") AS s LEFT JOIN (SELECT * FROM "PRODUCT_session_old") AS s2
                ON (s.sid=s2.sid AND s2.var_name='last_visit')
                WHERE s.sid IS NOT NULL"""
        ),
        (
"""INSERT INTO session_attribute (sid, authenticated, name, value)
        SELECT s.sid, s.authenticated, s.var_name, s.var_value
        FROM session_old s
        WHERE s.var_name <> 'last_visit' AND s.sid IS NOT NULL""",
"""INSERT INTO session_attribute (sid, authenticated, name, value)
        SELECT s.sid, s.authenticated, s.var_name, s.var_value
        FROM (SELECT * FROM "PRODUCT_session_old") AS s
        WHERE s.var_name <> 'last_visit' AND s.sid IS NOT NULL"""
        ),
        (
"""INSERT INTO wiki(version, name, time, author, ipnr, text)
                              SELECT 1 + COALESCE(max(version), 0), %s, %s, 'trac',
                                     '127.0.0.1', %s FROM wiki WHERE name=%s""",
"""INSERT INTO wiki(version, name, time, author, ipnr, text, product)
                              SELECT 1 + COALESCE(max(version), 0), %s, %s, 'trac',
                                     '127.0.0.1', %s, 'PRODUCT' FROM (SELECT * FROM wiki WHERE product='PRODUCT') AS wiki WHERE name=%s"""
        ),
        (
"""INSERT INTO permission VALUES ('dev','WIKI_VIEW')""",
"""INSERT INTO permission VALUES ('dev','WIKI_VIEW','PRODUCT')"""
        ),
        (
"""INSERT INTO permission (username, action) VALUES ('dev','WIKI_VIEW')""",
"""INSERT INTO permission (username, action, product) VALUES ('dev','WIKI_VIEW','PRODUCT')"""
        ),
    ],

    'custom_insert' : [
        (
"""INSERT INTO node_change (rev,path,kind,change,base_path,base_rev)
            SELECT rev,path,kind,change,base_path,base_rev FROM node_change_old""",
"""INSERT INTO node_change (rev,path,kind,change,base_path,base_rev)
            SELECT rev,path,kind,change,base_path,base_rev FROM (SELECT * FROM "PRODUCT_node_change_old") AS node_change_old"""
        ),
    ],

    # translated UPDATEs
    'system_update_translated' : [
        (
"""UPDATE ticket SET changetime=%s WHERE id=%s""",
"""UPDATE ticket SET changetime=%s WHERE product='PRODUCT' AND id=%s"""
        ),
        (
"""UPDATE ticket SET changetime=(
                          SELECT time FROM ticket_change WHERE ticket=%s
                          UNION
                          SELECT time FROM (
                              SELECT time FROM ticket WHERE id=%s LIMIT 1) AS t
                          ORDER BY time DESC LIMIT 1)
                          WHERE id=%s""",
"""UPDATE ticket SET changetime=(
                          SELECT time FROM (SELECT * FROM ticket_change WHERE product='PRODUCT') AS ticket_change WHERE ticket=%s
                          UNION
                          SELECT time FROM (
                              SELECT time FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket WHERE id=%s LIMIT 1) AS t
                          ORDER BY time DESC LIMIT 1)
                          WHERE product='PRODUCT' AND id=%s"""
        ),
        (
"""UPDATE component SET name=%s,owner=%s, description=%s
                          WHERE name=%s""",
"""UPDATE component SET name=%s,owner=%s, description=%s
                          WHERE product='PRODUCT' AND name=%s"""
        ),
        (
"""UPDATE milestone
                          SET name=%s, due=%s, completed=%s, description=%s
                          WHERE name=%s""",
"""UPDATE milestone
                          SET name=%s, due=%s, completed=%s, description=%s
                          WHERE product='PRODUCT' AND name=%s"""
        ),
        (
"""UPDATE wiki
        SET text=%s
            WHERE name=%s""",
"""UPDATE wiki
        SET text=%s
            WHERE product='PRODUCT' AND name=%s"""
        ),
        (
"""UPDATE ticket SET product=%s
                                  WHERE product=%s""",
"""UPDATE ticket SET product=%s
                                  WHERE product='PRODUCT' AND product=%s"""
        ),
        (
"""UPDATE ticket set changetime=%s where id=%s""",
"""UPDATE ticket set changetime=%s where product='PRODUCT' AND id=%s"""
        ),
        (
"""UPDATE
                                milestone
                           SET
                                id_project='%s' WHERE milestone='%s'""",
"""UPDATE
                                milestone
                           SET
                                id_project='%s' WHERE product='PRODUCT' AND milestone='%s'"""
        ),
        (
"""UPDATE ticket_change  SET  newvalue=%s
                               WHERE ticket=%s and author=%s and time=%s and field=%s""",
"""UPDATE ticket_change  SET  newvalue=%s
                               WHERE product='PRODUCT' AND ticket=%s and author=%s and time=%s and field=%s"""
        ),
        (
"""UPDATE ticket_change  SET oldvalue=%s, newvalue=%s
                               WHERE ticket=%s and author=%s and time=%s and field=%s""",
"""UPDATE ticket_change  SET oldvalue=%s, newvalue=%s
                               WHERE product='PRODUCT' AND ticket=%s and author=%s and time=%s and field=%s"""
        ),
        (
"""UPDATE
                                ticket_custom
                              SET
                                value = '%s'
                              WHERE
                                name = 'project' AND value = '%s'""",
"""UPDATE
                                ticket_custom
                              SET
                                value = '%s'
                              WHERE
                                product='PRODUCT' AND name = 'project' AND value = '%s'"""
        ),
    ],

    # non-translated UPDATEs
    'system_update_nontranslated' : [
        (
"""UPDATE  session_attribute
                            SET value='1'
                        WHERE   sid=%s
                            AND name='password_refreshed'""",
"""UPDATE  session_attribute
                            SET value='1'
                        WHERE   sid=%s
                            AND name='password_refreshed'"""
        ),
        (
"""UPDATE  session_attribute
                    SET value=%s""",
"""UPDATE  session_attribute
                    SET value=%s"""
        ),
        (
"""UPDATE  auth_cookie
                            SET time=%s
                        WHERE   cookie=%s""",
"""UPDATE  auth_cookie
                            SET time=%s
                        WHERE   cookie=%s"""
        ),
    ],

    # custom (plugin) table UPDATEs
    'custom_update' : [
        (
"""UPDATE subscription
                       SET format=%s
                     WHERE distributor=%s
                       AND sid=%s
                       AND authenticated=%s""",
"""UPDATE "PRODUCT_subscription"
                       SET format=%s
                     WHERE distributor=%s
                       AND sid=%s
                       AND authenticated=%s"""
        ),
        (
"""UPDATE subscription
                       SET changetime=CURRENT_TIMESTAMP,
                           priority=%s
                     WHERE id=%s""",
"""UPDATE "PRODUCT_subscription"
                       SET changetime=CURRENT_TIMESTAMP,
                           priority=%s
                     WHERE id=%s"""
        ),
        (
"""UPDATE backlog_ticket SET tkt_order = NULL WHERE tkt_id = %s""",
"""UPDATE "PRODUCT_backlog_ticket" SET tkt_order = NULL WHERE tkt_id = %s"""
        ),
        (
"""UPDATE backlog_ticket SET tkt_order = -1
                      WHERE bklg_id = %s
                      AND tkt_id IN
                      (SELECT id FROM ticket
                       WHERE status = 'closed')""",
"""UPDATE "PRODUCT_backlog_ticket" SET tkt_order = -1
                      WHERE bklg_id = %s
                      AND tkt_id IN
                      (SELECT id FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket
                       WHERE status = 'closed')"""
        ),
        (
"""UPDATE backlog_ticket SET tkt_order = -1
                         WHERE bklg_id = %s
                         AND tkt_id IN (SELECT id FROM ticket
                          WHERE status = 'closed')""",
"""UPDATE "PRODUCT_backlog_ticket" SET tkt_order = -1
                         WHERE bklg_id = %s
                         AND tkt_id IN (SELECT id FROM (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket
                          WHERE status = 'closed')"""
        ),
        (
"""UPDATE estimate SET rate=%s, variability=%s, communication=%s, tickets=%s, comment=%s
        WHERE id=%s""",
"""UPDATE "PRODUCT_estimate" SET rate=%s, variability=%s, communication=%s, tickets=%s, comment=%s
        WHERE id=%s"""
        ),
        (
"""UPDATE estimate_line_item SET estimate_id=%s ,
          description=%s, low=%s, high=%s
        WHERE id=%s""",
"""UPDATE "PRODUCT_estimate_line_item" SET estimate_id=%s ,
          description=%s, low=%s, high=%s
        WHERE id=%s"""
        ),
        (
"""UPDATE estimate SET rate=%s, variability=%s, communication=%s, tickets=%s, comment=%s,
           diffcomment=%s, saveepoch=%s
        WHERE id=%s""",
"""UPDATE "PRODUCT_estimate" SET rate=%s, variability=%s, communication=%s, tickets=%s, comment=%s,
           diffcomment=%s, saveepoch=%s
        WHERE id=%s"""
        ),
        (
"""UPDATE estimate_line_item SET estimate_id=%s ,
          description=%s, low=%s, high=%s
        WHERE id=%s""",
"""UPDATE "PRODUCT_estimate_line_item" SET estimate_id=%s ,
          description=%s, low=%s, high=%s
        WHERE id=%s"""
        ),
        (
"""UPDATE estimate SET rate=%s, variability=%s, communication=%s, tickets=%s, comment=%s,
           diffcomment=%s, saveepoch=%s
        WHERE id=%s""",
"""UPDATE "PRODUCT_estimate" SET rate=%s, variability=%s, communication=%s, tickets=%s, comment=%s,
           diffcomment=%s, saveepoch=%s
        WHERE id=%s"""
        ),
    ],

    # custom CREATE TABLE
    'custom_create_table' : [
        (
"""CREATE TABLE estimate(
            id integer PRIMARY KEY,
        rate DECIMAL,
        variability DECIMAL,
        communication DECIMAL,
        tickets VARCHAR(512),
        comment VARCHAR(8000)
    )""",
"""CREATE TABLE "PRODUCT_estimate"(
            id integer PRIMARY KEY,
        rate DECIMAL,
        variability DECIMAL,
        communication DECIMAL,
        tickets VARCHAR(512),
        comment VARCHAR(8000)
    )"""
        ),
        (
"""CREATE TABLE estimate_line_item(
        id integer PRIMARY KEY,
                           estimate_id integer,
                                       description VARCHAR(2048),
                                                   low DECIMAL,
                                                       high DECIMAL
    )""",
"""CREATE TABLE "PRODUCT_estimate_line_item"(
        id integer PRIMARY KEY,
                           estimate_id integer,
                                       description VARCHAR(2048),
                                                   low DECIMAL,
                                                       high DECIMAL
    )"""
        ),
        (
"""CREATE TABLE backlog_ticket (bklg_id INTEGER NOT NULL,"
                                                          " tkt_id INTEGER NOT NULL,"
                                                          " tkt_order REAL,"
                                                          " PRIMARY KEY(bklg_id, tkt_id))""",
"""CREATE TABLE "PRODUCT_backlog_ticket" (bklg_id INTEGER NOT NULL,"
                                                          " tkt_id INTEGER NOT NULL,"
                                                          " tkt_order REAL,"
                                                          " PRIMARY KEY(bklg_id, tkt_id))"""
        ),
        (
"""CREATE TEMPORARY TABLE backlog_ticket (bklg_id INTEGER NOT NULL,"
                                         " tkt_id INTEGER NOT NULL,"
                                         " tkt_order REAL,"
                                         " PRIMARY KEY(bklg_id, tkt_id))""",
"""CREATE TEMPORARY TABLE "PRODUCT_backlog_ticket" (bklg_id INTEGER NOT NULL,"
                                         " tkt_id INTEGER NOT NULL,"
                                         " tkt_order REAL,"
                                         " PRIMARY KEY(bklg_id, tkt_id))"""
        ),
        (
"""CREATE TEMPORARY TABLE table_old AS SELECT * FROM table""",
"""CREATE TEMPORARY TABLE "PRODUCT_table_old" AS SELECT * FROM"""
""" (SELECT * FROM "PRODUCT_table") AS table""",
        ),
    ],

    # custom ALTER TABLE
    'custom_alter_table' : [
        (
"""ALTER TABLE estimate ADD COLUMN diffcomment text""",
"""ALTER TABLE "PRODUCT_estimate" ADD COLUMN diffcomment text"""
        ),
        (
"""ALTER TABLE estimate ADD COLUMN saveepoch int""",
"""ALTER TABLE "PRODUCT_estimate" ADD COLUMN saveepoch int"""
        ),
    ],

    #lowercase select (#548)
    'lowercase_tokens': [
        (
"""select * from ticket""",
"""select * from (SELECT * FROM ticket WHERE product='PRODUCT') AS ticket"""
        ),
        (
"""create temporary table table_old as select * from table""",
"""create temporary table "PRODUCT_table_old" as select * from (SELECT * FROM "PRODUCT_table") AS table""",
        )
    ],
    # insert with specified product (#601)
    'insert_with_product': [
        (
"""INSERT INTO ticket (summary, product) VALUES ('S', 'swlcu')""",
"""INSERT INTO ticket (summary, product, id) VALUES ('S', 'swlcu',COALESCE((SELECT MAX(id) FROM\n(SELECT * FROM ticket WHERE product='PRODUCT')\nAS subquery), 0)+1)"""
        ),
    ],

}

class DbCursorTestCase(unittest.TestCase):
    """Unit tests covering the BloodhoundProductSQLTranslate"""
    def setUp(self):
        self.translator = BloodhoundProductSQLTranslate(SKIP_TABLES, TRANSLATE_TABLES, PRODUCT_COLUMN, 'PRODUCT')
        for section in data.keys():
            if not getattr(self, 'test_%s' % section, None):
                raise Exception("Section '%s' not covered in test case" % section)

    def tearDown(self):
        pass

    def _run_test(self, section):
        for (sql, translated_sql_check) in data[section]:
            translated_sql = self.translator.translate(sql)
            stripped_sql_check = '\n'.join([l.strip() for l in translated_sql_check.splitlines()])
            stripped_translated_sql = '\n'.join([l.strip() for l in translated_sql.splitlines()])
            self.assertEquals(stripped_sql_check, stripped_translated_sql)

    def test_system_select_nontranslated(self):
        self._run_test('system_select_nontranslated')

    def test_system_select_translated(self):
        self._run_test('system_select_translated')

    def test_custom_select(self):
        self._run_test('custom_select')

    def test_system_insert_nontranslated(self):
        self._run_test('system_insert_nontranslated')

    def test_system_insert_translated(self):
        self._run_test('system_insert_translated')

    def test_custom_insert(self):
        self._run_test('custom_insert')

    def test_system_update_translated(self):
        self._run_test('system_update_translated')

    def test_system_update_nontranslated(self):
        self._run_test('system_update_nontranslated')

    def test_custom_update(self):
        self._run_test('custom_update')

    def test_custom_create_table(self):
        self._run_test('custom_create_table')

    def test_custom_alter_table(self):
        self._run_test('custom_alter_table')

    def test_lowercase_tokens(self):
        self._run_test('lowercase_tokens')

    def test_insert_with_product(self):
        self._run_test('insert_with_product')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = mysql
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest

from trac.db.tests.mysql_test import MySQLTableAlterationSQLTest

from tests.db.util import ProductEnvMixin

class ProductMySQLTableAlterationSQLTest(MySQLTableAlterationSQLTest, ProductEnvMixin):
    pass

def suite():
    suite = unittest.TestSuite([
        unittest.makeSuite(MySQLTableAlterationSQLTest, 'test'),
        unittest.makeSuite(ProductMySQLTableAlterationSQLTest, 'test'),
    ])
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = postgres
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest

from trac.db.tests.postgres_test import PostgresTableCreationSQLTest, PostgresTableAlterationSQLTest

from tests.db.util import ProductEnvMixin

class ProductPostgresTableCreationSQLTest(PostgresTableCreationSQLTest, ProductEnvMixin):
    pass

class ProductPostgresTableAlterationSQLTest(PostgresTableAlterationSQLTest, ProductEnvMixin):
    pass

def suite():
    suite = unittest.TestSuite([
      unittest.makeSuite(PostgresTableCreationSQLTest, 'test'),
      unittest.makeSuite(PostgresTableAlterationSQLTest, 'test'),
      unittest.makeSuite(ProductPostgresTableCreationSQLTest, 'test'),
      unittest.makeSuite(ProductPostgresTableAlterationSQLTest, 'test'),
    ])
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductEnvMixin(MultiproductTestCase):
    def setUp(self):
        self._mp_setup()
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)

########NEW FILE########
__FILENAME__ = env
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's product environments"""

import os.path
import shutil
import sys
import tempfile
from inspect import stack
from tests import unittest
from types import MethodType

from trac.admin.api import AdminCommandManager, IAdminCommandProvider
from trac.config import Option
from trac.core import Component, ComponentMeta, implements
from trac.env import Environment
from trac.test import EnvironmentStub, MockPerm
from trac.tests.env import EnvironmentTestCase
from trac.ticket.report import ReportModule
from trac.ticket.web_ui import TicketModule
from trac.util.text import to_unicode
from trac.web.href import Href

from multiproduct.api import DB_VERSION, MultiProductSystem
from multiproduct.env import ProductEnvironment
from multiproduct.model import Product

_AssertRaisesContext = unittest.case._AssertRaisesContext


class ProductEnvironmentStub(ProductEnvironment):
    r"""A product environment slightly tweaked for testing purposes
    """
    def get_known_users(self, cnx=None):
        return self.known_users


# FIXME: Subclass TestCase explictly ?
class MultiproductTestCase(unittest.TestCase):
    r"""Mixin providing access to multi-product testing extensions.

    This class serves to the purpose of upgrading existing Trac test cases
    with multi-product super-powers while still providing the foundations
    to create product-specific subclasses.
    """

    # unittest2 extensions

    exceptFailureMessage = None

    class _AssertRaisesLoggingContext(_AssertRaisesContext):
        """Add logging capabilities to assertRaises
        """
        def __init__(self, expected, test_case, expected_regexp=None):
            _AssertRaisesContext.__init__(self, expected, test_case,
                                          expected_regexp)
            self.test_case = test_case

        @staticmethod
        def _tb_locals(tb):
            if tb is None:
                # Inspect interpreter stack two levels up
                ns = stack()[2][0].f_locals.copy()
            else:
                # Traceback already in context
                ns = tb.tb_frame.f_locals.copy()
            ns.pop('__builtins__', None)
            return ns

        def __exit__(self, exc_type, exc_value, tb):
            try:
                return _AssertRaisesContext.__exit__(self, exc_type,
                                                     exc_value, tb)
            except self.failureException, exc:
                msg = self.test_case.exceptFailureMessage
                if msg is not None:
                    standardMsg = str(exc)
                    msg = msg % self._tb_locals(tb)
                    msg = self.test_case._formatMessage(msg, standardMsg)
                    raise self.failureException(msg)
                else:
                    raise
            finally:
                # Clear message placeholder
                self.test_case.exceptFailureMessage = None

    def assertRaises(self, excClass, callableObj=None, *args, **kwargs):
        """Adds logging capabilities on top of unittest2 implementation.
        """
        if callableObj is None:
            return self._AssertRaisesLoggingContext(excClass, self)
        else:
            return unittest.TestCase.assertRaises(self, excClass, callableObj,
                                                  *args, **kwargs)

    # Product data

    default_product = 'tp1'
    MAX_TEST_PRODUCT = 3

    PRODUCT_DATA = {
        'tp1': {
            'prefix': 'tp1',
            'name': 'test product 1',
            'description': 'desc for tp1',
        },
        'tp2': {
            'prefix': 'tp2',
            'name': 'test product 2',
            'description': 'desc for tp2',
        },
        u'x': {
            'prefix': u'x',
            'name': 'Non-ASCII chars',
            'description': 'Unicode chars in name',
        },
        u'berflssigkeit': {
            'prefix': u'berflssigkeit',
            'name': 'Non-ASCII chars (long)',
            'description': 'Long name with unicode chars',
        },
        'Foo Bar': {
            'prefix': 'Foo Bar',
            'name': 'Whitespaces',
            'description': 'Whitespace chars in name',
        },
        'Foo Bar#baz': {
            'prefix': 'Foo Bar#baz',
            'name': 'Non-alphanumeric',
            'description': 'Special chars in name',
        },
        'pl/de': {
            'prefix': 'pl/de',
            'name': 'Path separator',
            'description': 'URL path separator in name',
        },
    }

    # Test setup

    def _setup_test_env(self, create_folder=True, path=None, **kwargs):
        r"""Prepare a new test environment .

        Optionally set its path to a meaningful location (temp folder
        if `path` is `None`).
        """
        MultiProductSystem.FakePermClass = MockPerm
        kwargs.setdefault('enable', ['trac.*', 'multiproduct.*'])
        self.env = env = EnvironmentStub(**kwargs)
        if create_folder:
            if path is None:
                env.path = tempfile.mkdtemp(prefix='bh-tempenv-')
            else:
                env.path = path
                if not os.path.exists(env.path):
                    os.mkdir(env.path)
            conf_dir = os.path.join(env.path, 'conf')
            if not os.path.exists(conf_dir):
                os.mkdir(conf_dir)
        return env

    def _setup_test_log(self, env):
        r"""Ensure test product with prefix is loaded
        """
        if not hasattr(env, 'path') or not env.path:
            env.path = tempfile.mkdtemp(prefix='bh-product-tempenv-')
        log_dir = os.path.join(env.path, 'log')
        if not os.path.exists(log_dir):
            os.mkdir(log_dir)
        log_file = os.path.join(log_dir, 'trac-testing.log')
        config = env.config
        config.set('logging', 'log_file', log_file)
        config.set('logging', 'log_type', 'file')
        config.set('logging', 'log_level', 'DEBUG')

        # Log SQL queries
        config.set('trac', 'debug_sql', True)

        config.save()
        env.setup_log()
        env.log.info('%s test case: %s %s', '-' * 10, self.id(), '-' * 10)

        # Clean-up logger instance and associated handler
        # Otherwise large test suites will only result in ERROR eventually
        # (at least in Unix systems) with messages
        #
        # TracError: Error reading '/path/to/file', make sure it is readable.
        # error: /path/to/: Too many open files
        self.addCleanup(self._teardown_test_log, env)

    def _teardown_test_log(self, env):
        if env.log and hasattr(env, '_log_handler'):
            env.log.removeHandler(env._log_handler)
            env._log_handler.flush()
            env._log_handler.close()
            del env._log_handler

    @classmethod
    def _load_product_from_data(cls, env, prefix):
        r"""Ensure test product with prefix is loaded
        """
        # TODO: Use fixtures implemented in #314
        product_data = cls.PRODUCT_DATA[prefix]
        prefix = to_unicode(prefix)
        product = Product(env)
        product._data.update(product_data)
        product.insert()

    @classmethod
    def _upgrade_mp(cls, env):
        r"""Apply multi product upgrades
        """
        # Do not break wiki parser ( see #373 )
        EnvironmentStub.disable_component_in_config(env, TicketModule)
        EnvironmentStub.disable_component_in_config(env, ReportModule)

        mpsystem = MultiProductSystem(env)
        with env.db_transaction as db:
            try:
                mpsystem.upgrade_environment(db)
            except env.db_exc.OperationalError:
                # Database is upgraded, but database version was deleted.
                # Complete the upgrade by inserting default product.
                mpsystem._insert_default_product(db)
            finally:
                # Ensure that multiproduct DB version is set to latest value
                mpsystem._update_db_version(db, DB_VERSION)
        # assume that the database schema has been upgraded, enable
        # multi-product schema support in environment
        env.enable_multiproduct_schema(True)

    @classmethod
    def _load_default_data(cls, env):
        r"""Initialize environment with default data by respecting
        values set in system table.
        """
        from trac import db_default

        env.log.debug('Loading default data')
        with env.db_transaction as db:
            for table, cols, vals in db_default.get_data(db):
                if table != 'system':
                    db.executemany('INSERT INTO %s (%s) VALUES (%s)'
                                   % (table, ','.join(cols),
                                      ','.join(['%s' for c in cols])), vals)
        env.log.debug('Loaded default data')

    def _mp_setup(self, **kwargs):
        """Shortcut for quick product-aware environment setup.
        """
        self.env = self._setup_test_env(**kwargs)
        self._upgrade_mp(self.env)
        self._setup_test_log(self.env)
        self._load_product_from_data(self.env, self.default_product)


class ProductEnvTestCase(EnvironmentTestCase, MultiproductTestCase):
    r"""Test cases for Trac environments rewritten for product environments
    """

    # Test setup

    def setUp(self):
        r"""Replace Trac environment with product environment
        """
        EnvironmentTestCase.setUp(self)
        try:
            self.global_env = self.env
            self._setup_test_log(self.global_env)
            self._upgrade_mp(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            try:
                self.env = ProductEnvironment(self.global_env,
                                              self.default_product)
            except:
                # All tests should fail if anything goes wrong
                self.global_env.log.exception(
                    'Error creating product environment')
                self.env = None
        except:
            shutil.rmtree(self.env.path)
            raise

    def tearDown(self):
        # Discard product environment
        self.env = self.global_env

        EnvironmentTestCase.tearDown(self)


class ProductEnvApiTestCase(MultiproductTestCase):
    """Assertions for Apache(TM) Bloodhound product-specific extensions in
    [https://issues.apache.org/bloodhound/wiki/Proposals/BEP-0003 BEP 3]
    """
    def setUp(self):
        self._mp_setup()
        self.product_env = ProductEnvironment(self.env, self.default_product)

    def tearDown(self):
        # Release reference to transient environment mock object
        if self.env is not None:
            try:
                self.env.reset_db()
            except self.env.db_exc.OperationalError:
                # "Database not found ...",
                # "OperationalError: no such table: system" or the like
                pass
        self.env = None
        self.product_env = None

    def test_attr_forward_parent(self):
        """Testing env.__getattr__"""
        class EnvironmentAttrSandbox(EnvironmentStub):
            """Limit the impact of class edits so as to avoid race conditions
            """

        self.longMessage = True

        class AttrSuccess(Exception):
            """Exception raised when target method / property is actually
            invoked.
            """

        def property_mock(attrnm, expected_self):
            def assertAttrFwd(instance):
                self.assertIs(instance, expected_self,
                              "Mismatch in property '%s'" % (attrnm,))
                raise AttrSuccess
            return property(assertAttrFwd)

        self.env.__class__ = EnvironmentAttrSandbox
        try:
            for attrnm in 'system_info_providers secure_cookies ' \
                    'project_admin_trac_url get_system_info get_version ' \
                    'get_templates_dir get_templates_dir get_log_dir ' \
                    'backup'.split():
                original = getattr(Environment, attrnm)
                if isinstance(original, MethodType):
                    translation = getattr(self.product_env, attrnm)
                    self.assertIs(translation.im_self, self.env,
                                  "'%s' not bound to global env in product env"
                                  % (attrnm,))
                    self.assertIs(translation.im_func, original.im_func,
                                  "'%s' function differs in product env"
                                  % (attrnm,))
                elif isinstance(original, (property, Option)):
                    # Intercept property access e.g. properties, Option, ...
                    setattr(self.env.__class__, attrnm,
                            property_mock(attrnm, self.env))

                    self.exceptFailureMessage = 'Property %(attrnm)s'
                    with self.assertRaises(AttrSuccess) as cm_test_attr:
                        getattr(self.product_env, attrnm)
                else:
                    self.fail("Environment member %s has unexpected type"
                              % (repr(original),))

        finally:
            self.env.__class__ = EnvironmentStub

        for attrnm in 'component_activated _component_rules ' \
                'enable_component get_known_users get_repository ' \
                '_component_name'.split():
            original = getattr(Environment, attrnm)
            if isinstance(original, MethodType):
                translation = getattr(self.product_env, attrnm)
                self.assertIs(translation.im_self, self.product_env,
                              "'%s' not bound to product env" % (attrnm,))
                self.assertIs(translation.im_func, original.im_func,
                              "'%s' function differs in product env"
                              % (attrnm,))
            elif isinstance(original, property):
                translation = getattr(ProductEnvironment, attrnm)
                self.assertIs(original, translation,
                              "'%s' property differs in product env"
                              % (attrnm,))

    def test_typecheck(self):
        """Testing env.__init__"""
        self._load_product_from_data(self.env, 'tp2')
        env2 = ProductEnvironment(self.product_env, 'tp2')
        self.assertIs(env2, ProductEnvironment(self.env, 'tp2'))

    def test_component_enable(self):
        """Testing env.is_component_enabled"""
        class C(Component):
            pass
        # Let's pretend this was declared elsewhere
        C.__module__ = 'dummy_module'
        sys.modules['dummy_module'] = sys.modules[__name__]

        global_env = self.env
        product_env = self.product_env

        def _test_component_enabled(cls):
            cname = global_env._component_name(cls)
            disable_component_in_config = global_env.disable_component_in_config
            enable_component_in_config = global_env.enable_component_in_config

            # cls initially disabled in both envs
            disable_component_in_config(global_env, cls)
            disable_component_in_config(product_env, cls)

            expected_rules = {
                'multiproduct': True,
                'trac': True,
                'trac.ticket.report.reportmodule': False,
                'trac.ticket.web_ui.ticketmodule': False,
                'trac.db': True,
                cname: False,
            }
            self.assertEquals(expected_rules, global_env._component_rules)
            self.assertEquals(expected_rules, product_env._component_rules)

            self.assertFalse(global_env.is_component_enabled(cls))
            self.assertFalse(product_env.is_component_enabled_local(cls))
            self.assertIs(global_env[cls], None)
            self.assertIs(product_env[cls], None)

            # cls enabled in product env but not in global env
            disable_component_in_config(global_env, cls)
            enable_component_in_config(product_env, cls)

            expected_rules[cname] = False
            self.assertEquals(expected_rules, global_env._component_rules)
            expected_rules[cname] = True
            self.assertEquals(expected_rules, product_env._component_rules)

            self.assertFalse(global_env.is_component_enabled(cls))
            self.assertTrue(product_env.is_component_enabled_local(cls))
            self.assertIs(global_env[cls], None)
            self.assertIs(product_env[cls], None)

            # cls enabled in both envs
            enable_component_in_config(global_env, cls)
            enable_component_in_config(product_env, cls)

            expected_rules[cname] = True
            self.assertEquals(expected_rules, global_env._component_rules)
            expected_rules[cname] = True
            self.assertEquals(expected_rules, product_env._component_rules)

            self.assertTrue(global_env.is_component_enabled(cls))
            self.assertTrue(product_env.is_component_enabled_local(cls))
            self.assertIsNot(global_env[cls], None)
            self.assertIsNot(product_env[cls], None)

            # cls enabled in global env but not in product env
            enable_component_in_config(global_env, cls)
            disable_component_in_config(product_env, cls)

            expected_rules[cname] = True
            self.assertEquals(expected_rules, global_env._component_rules)
            expected_rules[cname] = False
            self.assertEquals(expected_rules, product_env._component_rules)

            self.assertTrue(global_env.is_component_enabled(cls))
            self.assertFalse(product_env.is_component_enabled_local(cls))
            self.assertIsNot(global_env[cls], None)
            self.assertIs(product_env[cls], None)

        # Test the rules against custom , external component
        _test_component_enabled(C)

        for env in (global_env, product_env):
            env.config.remove('components', env._component_name(C))

         # Test the rules against Trac component class
        _test_component_enabled(TicketModule)

        # ComponentMeta._components is shared between multiple tests.
        # Unregister class C as its fake module might break something else.
        ComponentMeta._components.remove(C)

    def test_href_is_lazy(self):
        href = self.product_env.href
        self.assertIs(href, self.product_env.href)

    def test_abs_href_is_lazy(self):
        abs_href = self.product_env.abs_href
        self.assertIs(abs_href, self.product_env.abs_href)

    def test_path_is_lazy(self):
        path = self.product_env.path
        self.assertIs(path, self.product_env.path)

    def test_path(self):
        """Testing env.path"""
        self.assertEqual(self.product_env.path,
                         os.path.join(self.env.path, 'products',
                                      self.default_product))

    def test_env_config_inheritance(self):
        """Testing env.config"""
        global_config = self.env.config
        product_config = self.product_env.config

        # By default inherit global settings ...
        global_config['section'].set('key', 'value1')
        self.assertEquals('value1', global_config['section'].get('key'))
        self.assertEquals('value1', product_config['section'].get('key'))

        # ... but allow for overrides in product scope
        product_config['section'].set('key', 'value2')
        self.assertEquals('value1', global_config['section'].get('key'))
        self.assertEquals('value2', product_config['section'].get('key'))

    def test_parametric_singleton(self):
        self.assertIs(self.product_env,
                      ProductEnvironment(self.env, self.default_product))

        for prefix in self.PRODUCT_DATA:
            if prefix != self.default_product:
                self._load_product_from_data(self.env, prefix)

        envgen1 = dict([prefix, ProductEnvironment(self.env, prefix)]
                       for prefix in self.PRODUCT_DATA)
        envgen2 = dict([prefix, ProductEnvironment(self.env, prefix)]
                       for prefix in self.PRODUCT_DATA)

        for prefix, env1 in envgen1.iteritems():
            self.assertIs(env1, envgen2[prefix],
                          "Identity check (by prefix) '%s'" % (prefix,))

        for prefix, env1 in envgen1.iteritems():
            self.assertIs(env1, envgen2[prefix],
                          "Identity check (by prefix) '%s'" % (prefix,))

        def load_product(prefix):
            products = Product.select(self.env, where={'prefix' : prefix})
            if not products:
                raise LookupError('Missing product %s' % (prefix,))
            else:
                return products[0]

        envgen3 = dict([prefix, ProductEnvironment(self.env,
                                                   load_product(prefix))]
                       for prefix in self.PRODUCT_DATA)

        for prefix, env1 in envgen1.iteritems():
            self.assertIs(env1, envgen3[prefix],
                          "Identity check (by product model) '%s'" % (prefix,))


class ProductEnvHrefTestCase(MultiproductTestCase):
    """Assertions for resolution of product environment's base URL
    [https://issues.apache.org/bloodhound/wiki/Proposals/BEP-0003 BEP 3]
    """

    def product_base_url(url_template):
        def decorator(f):
            f.product_base_url = url_template
            return f

        return decorator

    def setUp(self):
        self._mp_setup()
        self.env.abs_href = Href('http://globalenv.com/trac.cgi')
        url_pattern = getattr(getattr(self, self._testMethodName).im_func,
                              'product_base_url', '')
        self.env.config.set('multiproduct', 'product_base_url', url_pattern)
        self.env.config.set('trac', 'base_url', 'http://globalenv.com/trac.cgi')
        self.product_env = ProductEnvironment(self.env, self.default_product)

    def tearDown(self):
        shutil.rmtree(os.path.dirname(self.env.path), ignore_errors=True)
        # Release reference to transient environment mock object
        if self.env is not None:
            try:
                self.env.reset_db()
            except self.env.db_exc.OperationalError:
                # "Database not found ...",
                # "OperationalError: no such table: system" or the like
                pass
        self.env = None
        self.product_env = None

    @product_base_url('http://$(prefix)s.domain.tld/')
    def test_href_subdomain(self):
        """Test product sub domain base URL
        """
        self.assertEqual('/', self.product_env.href())
        self.assertEqual('http://tp1.domain.tld', self.product_env.abs_href())

    @product_base_url('/path/to/bloodhound/$(prefix)s')
    def test_href_sibling_paths(self):
        """Test product base URL at sibling paths
        """
        self.assertEqual('/trac.cgi/path/to/bloodhound/tp1',
                         self.product_env.href())
        self.assertEqual('http://globalenv.com/trac.cgi/path/to/bloodhound/tp1',
                         self.product_env.abs_href())

    @product_base_url('/$(envname)s/$(prefix)s')
    def test_href_inherit_sibling_paths(self):
        """Test product base URL at sibling paths inheriting configuration.
        """
        self.assertEqual('/trac.cgi/%s/tp1'
                         % os.path.split(self.env.path)[-1],
                         self.product_env.href())
        self.assertEqual('http://globalenv.com/trac.cgi/%s/tp1'
                         % os.path.split(self.env.path)[-1],
                         self.product_env.abs_href())

    @product_base_url('')
    def test_href_default(self):
        """Test product base URL is to a default
        """
        self.assertEqual('/trac.cgi/products/tp1', self.product_env.href())
        self.assertEqual('http://globalenv.com/trac.cgi/products/tp1',
                         self.product_env.abs_href())

    @product_base_url('/products/$(prefix)s')
    def test_href_embed(self):
        """Test default product base URL /products/prefix
        """
        self.assertEqual('/trac.cgi/products/tp1', self.product_env.href())
        self.assertEqual('http://globalenv.com/trac.cgi/products/tp1',
                         self.product_env.abs_href())

    @product_base_url('http://$(envname)s.tld/bh/$(prefix)s')
    def test_href_complex(self):
        """Test complex product base URL
        """
        self.assertEqual('/bh/tp1', self.product_env.href())
        self.assertEqual('http://%s.tld/bh/tp1'
                         % os.path.split(self.env.path)[-1],
                         self.product_env.abs_href())

    @product_base_url('http://$(prefix)s.$(envname)s.tld/')
    def test_product_href_uses_multiproduct_product_base_url(self):
        """Test that [multiproduct] product_base_url is used to compute
        abs_href for the product environment when [trac] base_url for
        the product environment is an empty string (the default).
        """
        # Global URLs
        self.assertEqual('http://globalenv.com/trac.cgi', self.env.base_url)
        self.assertEqual('/trac.cgi', self.env.href())
        self.assertEqual('http://globalenv.com/trac.cgi', self.env.abs_href())

        # Product URLs
        self.assertEqual('', self.product_env.base_url)
        self.assertEqual('/', self.product_env.href())
        self.assertEqual('http://tp1.%s.tld'
                         % os.path.split(self.env.path)[-1],
                         self.product_env.abs_href())

    @product_base_url('http://$(prefix)s.$(envname)s.tld/')
    def test_product_href_uses_products_base_url(self):
        """Test that [trac] base_url for the product environment is used to
        compute abs_href for the product environment when [trac] base_url
        for the product environment is different than [trac] base_url for
        the global environment.
        """
        self.product_env.config.set('trac', 'base_url', 'http://productenv.com')
        self.product_env.config.save()

        self.assertEqual('http://productenv.com', self.product_env.base_url)
        self.assertEqual('/', self.product_env.href())
        self.assertEqual('http://productenv.com', self.product_env.abs_href())

    @product_base_url('http://$(prefix)s.$(envname)s.tld/')
    def test_product_href_global_and_product_base_urls_same(self):
        """Test that [multiproduct] product_base_url is used to compute
        abs_href for the product environment when [trac] base_url is the same
        for the product and global environment.
        """
        self.product_env.config.set('trac', 'base_url',
                                    self.env.config.get('trac', 'base_url'))
        self.product_env.config.save()

        self.assertEqual('', self.product_env.base_url)
        self.assertEqual('/', self.product_env.href())
        self.assertEqual('http://tp1.%s.tld'
                         % os.path.split(self.env.path)[-1],
                         self.product_env.abs_href())

    product_base_url = staticmethod(product_base_url)


class ProductEnvConfigTestCase(MultiproductTestCase):
    """Test cases for product environment's configuration
    """

    class DummyAdminCommand(Component):
        """Dummy class used for testing purposes
        """
        implements(IAdminCommandProvider)

        class DummyException(Exception):
            pass

        def do_fail(self, *args):
            raise DummyException(args)

        def get_admin_commands(self):
            yield "fail", "[ARG]...", "Always fail", None, self.do_fail


    def setUp(self):
        self._mp_setup(create_folder=True)
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)

        # Random component class
        self.component_class = self.DummyAdminCommand

    def tearDown(self):
        if self.global_env is not None:
            try:
                self.global_env.reset_db()
            except self.global_env.db_exc.OperationalError:
                # "Database not found ...",
                # "OperationalError: no such table: system" or the like
                pass

        shutil.rmtree(self.env.path)
        self.env = self.global_env = None

    def test_regression_bh_539(self):
        tracadmin = AdminCommandManager(self.env)

        self.assertTrue(self.env[self.component_class] is None,
                        "Expected component disabled")
        self.assertFalse(any(isinstance(c, self.component_class)
                             for c in tracadmin.providers),
                         "Component erroneously listed in admin cmd providers")
        self.assertEqual([], tracadmin.get_command_help(args=['fail']))

        # Enable component in both global and product context
        cmd_args = ['config', 'set', 'components', __name__ + '.*', 'enabled']
        AdminCommandManager(self.global_env).execute_command(*cmd_args)
        tracadmin.execute_command(*cmd_args)

        self.assertTrue(self.env[self.component_class] is not None,
                        "Expected component enabled")
        self.assertTrue(any(isinstance(c, self.component_class)
                            for c in tracadmin.providers),
                        "Component not listed in admin cmd providers")
        self.assertEqual(1, len(tracadmin.get_command_help(args=['fail'])))

    def test_regression_bh_539_concurrent(self):
        try:
            # It is necessary to load another environment object to work around
            # ProductEnvironment class' parametric singleton constraint
            old_env = self.env
            # In-memory DB has to be shared
            self.global_env.__class__.global_databasemanager = \
                self.env.global_databasemanager
            new_global_env = self._setup_test_env(create_folder=True,
                                                  path=self.global_env.path)
            self.env = old_env
            self._setup_test_log(new_global_env)

            # FIXME: EnvironmentStub config is not bound to a real file
            # ... so let's reuse one config for both envs to simulate that they
            # are in sync, a condition verified in another test case
            new_global_env.config = self.global_env.config

            new_env = ProductEnvironment(new_global_env, self.default_product)

            self.assertTrue(new_global_env is not self.global_env)
            self.assertTrue(new_env is not self.env)
            self.assertEqual(self.env.path, new_env.path)
            self.assertEqual(self.env.config._lock_path,
                             new_env.config._lock_path)

            tracadmin = AdminCommandManager(self.env)
            new_tracadmin = AdminCommandManager(new_env)

            # Assertions for self.env
            self.assertTrue(self.env[self.component_class] is None,
                            "Expected component disabled")
            self.assertFalse(any(isinstance(c, self.component_class)
                                 for c in tracadmin.providers),
                             "Component erroneously listed in admin cmd "
                             "providers")
            self.assertEqual([], tracadmin.get_command_help(args=['fail']))

            # Repeat assertions for new_env
            self.assertTrue(new_env[self.component_class] is None,
                            "Expected component disabled")
            self.assertFalse(any(isinstance(c, self.component_class)
                                 for c in new_tracadmin.providers),
                             "Component erroneously listed in admin cmd "
                             "providers")
            self.assertEqual([], new_tracadmin.get_command_help(args=['fail']))

            # Enable component in both self.global_env and self.env contexts
            cmd_args = ['config', 'set', 'components',
                       __name__ + '.*', 'enabled']
            AdminCommandManager(self.global_env).execute_command(*cmd_args)
            tracadmin.execute_command(*cmd_args)

            # Assert that changes are auto-magically reflected in new_env
            self.assertTrue(new_env[self.component_class] is not None,
                            "Expected component enabled")
            self.assertTrue(any(isinstance(c, self.component_class)
                                for c in new_tracadmin.providers),
                            "Component not listed in admin cmd providers")
            self.assertEqual(
                1, len(new_tracadmin.get_command_help(args=['fail'])))
        finally:
            self.global_env.__class__.global_databasemanager = None
            new_global_env = new_env = None


def test_suite():
    return unittest.TestSuite([
        unittest.makeSuite(ProductEnvTestCase, 'test'),
        unittest.makeSuite(ProductEnvApiTestCase, 'test'),
        unittest.makeSuite(ProductEnvHrefTestCase, 'test'),
        unittest.makeSuite(ProductEnvConfigTestCase, 'test'),
    ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest
import uuid

from trac.perm import PermissionSystem
from trac.tests.functional import FunctionalTwillTestCaseSetup, internal_error
from trac.tests.functional.tester import tc

from multiproduct.env import ProductEnvironment
from tests.functional import MultiproductFunctionalTestCase

#----------------
# Functional test cases for admin web UI & CLI
#----------------


class TestAdminProductDefault(MultiproductFunctionalTestCase,
                              FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin set default product"""
        prefix, name, owner = self._tester.admin_create_product(owner='admin')
        products_url = self._tester.url + '/admin/ticket/products'
        tc.go(products_url)
        tc.formvalue('product_table', 'default', prefix)
        tc.submit('apply')
        tc.find('type="radio" name="default" value="%s" checked="checked"'
                % prefix)
        tc.go(self._tester.url + '/newticket')
        tc.find('<option selected="selected" value="%s">%s</option>'
                % (prefix, name))

        # Test the "Clear default" button
        tc.go(products_url)
        tc.submit('clear', 'product_table')
        tc.notfind('type="radio" name="default" value=".+" checked="checked"')


class TestAdminProductRename(MultiproductFunctionalTestCase,
                             FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Rename product from the admin page."""
        prefix, name, owner = self._tester.admin_create_product(owner='admin')
        with self.in_product(prefix) as (testenv, tester):
            t1 = tester.create_ticket()
            t2 = tester.create_ticket()
        new_name = '%s%s' % (name, str(uuid.uuid4()).split('-')[0])

        admin_product_url = self._tester.url + '/admin/ticket/products'
        tc.go(admin_product_url + '/' + prefix)
        tc.formvalue('modprod', 'name', new_name)
        tc.submit('save')
        tc.find("Your changes have been saved")
        tc.find(r'<a href="/admin/ticket/products/%s">%s</a>'
                % (prefix, new_name))

        with self.in_product(prefix) as (testenv, tester):
            tester.go_to_ticket(t1)
            comment = "Product %s renamed to %s" % (name, new_name)
            tc.find(comment)
            tester.go_to_ticket(t2)
            tc.find(comment)


class TestConsoleProductRename(MultiproductFunctionalTestCase,
                               FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Rename product from the console."""
        prefix, name, owner = self._tester.admin_create_product(owner='admin')
        with self.in_product(prefix) as (testenv, tester):
            t1 = tester.create_ticket()
            t2 = tester.create_ticket()
        new_name = '%s%s' % (name, str(uuid.uuid4()).split('-')[0])

        self._testenv._tracadmin('product', 'rename', prefix, new_name)

        with self.in_product(prefix) as (testenv, tester):
            tester.go_to_ticket(t1)
            comment = "Product %s renamed to %s" % (name, new_name)
            tc.find(comment)
            tester.go_to_ticket(t2)
            tc.find(comment)


class RegressionTestBhTicket667(MultiproductFunctionalTestCase,
                                FunctionalTwillTestCaseSetup):

    def runTest(self):
        """User is redirected to the login page when the page they are
        navigating to is forbidden.
        """
        env = self._testenv.get_trac_environment()
        actions = PermissionSystem(env).get_user_permissions('anonymous')

        # Revoke all permissions for 'anonymous'
        self._testenv._tracadmin('permission', 'remove', 'anonymous', *actions)
        self._testenv.restart()  # TODO: can be removed when #539 is resolved
        try:
            with self._tester.as_user(None):
                tc.go(self._tester.url)
                tc.notfind(internal_error)
                tc.url(self._tester.url + '/login\?referer=%2F$')
        finally:
            self._testenv._tracadmin('permission', 'add', 'anonymous',
                                     *actions)


def functionalSuite(suite=None):
    if not suite:
        import tests.functional
        suite = tests.functional.functionalSuite()

    suite.addTest(TestAdminProductDefault())
    suite.addTest(TestAdminProductRename())
    suite.addTest(TestConsoleProductRename())
    suite.addTest(RegressionTestBhTicket667())
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = prefs
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.tests import functional
from trac.tests.functional.tester import tc

#----------------
# Functional test cases for preferences (rewritten)
#----------------

# TODO: These classes are almost a copycat of Trac's. Beware of license header

class TestPreferences(functional.FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Set preferences for admin user"""
        prefs_url = self._tester.url + "/prefs"
        # [BLOODHOUND] Preferences link removed
        tc.follow('/prefs')
        tc.url(prefs_url)
        tc.notfind('Your preferences have been saved.')
        tc.formvalue('userprefs', 'name', ' System Administrator ')
        tc.formvalue('userprefs', 'email', ' admin@example.com ')
        tc.submit()
        tc.find('Your preferences have been saved.')
        tc.follow('Date & Time')
        tc.url(prefs_url + '/datetime')
        tc.formvalue('userprefs', 'tz', 'GMT -10:00')
        tc.submit()
        tc.find('Your preferences have been saved.')
        tc.follow('General')
        tc.url(prefs_url)
        tc.notfind('Your preferences have been saved.')
        tc.find('value="System Administrator"')
        tc.find(r'value="admin@example\.com"')
        tc.follow('Date & Time')
        tc.url(prefs_url + '/datetime')
        tc.find('GMT -10:00')


class RegressionTestRev5785(functional.FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of the fix in r5785"""
        prefs_url = self._tester.url + "/prefs"
        # [BLOODHOUND] Preferences link removed
        tc.follow('/prefs')
        tc.url(prefs_url)
        self._tester.logout()
        self._tester.login('admin')


class RegressionTestTicket5765(functional.FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5765
        Unable to turn off 'Enable access keys' in Preferences
        """
        self._tester.go_to_front()
        # [BLOODHOUND] Preferences link removed
        tc.follow('/prefs')
        tc.follow('Keyboard Shortcuts')
        tc.formvalue('userprefs', 'accesskeys', True)
        tc.submit()
        tc.find('name="accesskeys".*checked="checked"')
        tc.formvalue('userprefs', 'accesskeys', False)
        tc.submit()
        tc.notfind('name="accesskeys".*checked="checked"')

def trac_functionalSuite(suite=None):
    suite.addTest(TestPreferences())
    suite.addTest(RegressionTestRev5785())
    suite.addTest(RegressionTestTicket5765())


#--------------
# Multiproduct test cases
#--------------



def functionalSuite(suite=None):
    if not suite:
        import tests.functional
        suite = tests.functional.functionalSuite()

    trac_functionalSuite(suite)

    return suite


if __name__ == '__main__':
    import unittest
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = product
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from uuid import uuid4

from trac.tests.functional import FunctionalTwillTestCaseSetup
from trac.tests.functional.tester import tc

from tests.functional import MultiproductFunctionalTestCase

#----------------
# Functional test cases for products
#----------------

class TestNewProduct(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Setup new product"""
        prefix, name = self._tester.create_product()
        base_url = self._testenv.get_env_href(prefix=prefix)
        tc.url(base_url())

        tc.follow('Index')
        tc.find('Index by Title')
        tc.find('<a[^>]*>Index by Date')
        pages = ('TitleIndex', 'RecentChanges', 'InterTrac', 'InterWiki')
        for page in pages:
            tc.find('<a[^>]*>%s' % (page,))

        tc.follow('Index by Date')
        tc.find('Index by Date')
        tc.find('<a[^>]*>Index by Title')


class TestProductRenameAuthor(MultiproductFunctionalTestCase,
                              FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Check for correct author in ticket comments on product rename
        https://issues.apache.org/bloodhound/ticket/671
        """
        prefix, name = self._tester.create_product()
        with self.in_product(prefix) as (testenv, tester):
            t1 = tester.create_ticket()
            t2 = tester.create_ticket()
        new_name = '%s%s' % (name, str(uuid4()).split('-')[0])

        tc.go(self._tester.url + '/products')
        tc.follow('.*/products/' + prefix + r'\?action=edit$')
        tc.find('Edit Product')
        tc.find(prefix)
        tc.formvalue('edit', 'name', new_name)
        tc.submit()
        tc.find('Your changes have been saved')

        with self.in_product(prefix) as (testenv, tester):
            tester.go_to_ticket(t1)
            comment = 'Product %s renamed to %s' % (name, new_name)
            tc.find(comment)
            tester.go_to_ticket(t2)
            tc.find(comment)


def functionalSuite(suite=None):
    if not suite:
        import tests.functional
        suite = tests.functional.functionalSuite()

    suite.addTest(TestNewProduct())
    suite.addTest(TestProductRenameAuthor())
    return suite

if __name__ == '__main__':
    import unittest
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = ticket
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Override a few functional tests for tickets.
"""

from urlparse import urlsplit

from twill.errors import TwillException

from trac.ticket.tests.functional import *

from tests import unittest
from tests.functional import regex_owned_by

#----------------
# Functional test cases for tickets (rewritten)
#----------------

# TODO: These classes are almost a copycat of Trac's. Beware of license header

class TestTicketPreview(FunctionalTwillTestCaseSetup):
    """There's no such thing like ticket preview in Bloodhound but, if it would
    then the corresponding Trac test case should be rewritten like this.
    """
    def runTest(self):
        """Preview ticket creation
        """
        # [BLOODHOUND] New Ticket => More fields (in create ticket menu)
        self._tester.go_to_newticket()

        summary = random_sentence(5)
        desc = random_sentence(5)
        tc.formvalue('propertyform', 'field-summary', summary)
        tc.formvalue('propertyform', 'field-description', desc)
        tc.submit('preview')
        tc.url(self._tester.url + '/newticket$')
        tc.find('ticket not yet created')
        tc.find(summary)
        tc.find(desc)


class TestTicketNoSummary(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Creating a ticket without summary should fail
        """
        # [BLOODHOUND] New Ticket => More fields (in create ticket menu)
        self._tester.go_to_newticket()

        desc = random_sentence(5)
        tc.formvalue('propertyform', 'field-description', desc)
        # [BLOODHOUND] no actual button to submit /newticket `propertyform`
        tc.submit()
        tc.find(desc)
        tc.find('Tickets must contain a summary.')
        # [BLOODHOUND] Create New Ticket => New Ticket
        tc.find('New Ticket')
        tc.find('ticket not yet created')


class TestTicketCustomFieldTextNoFormat(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test custom text field with no format explicitly specified.
        Its contents should be rendered as plain text.
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', '')
        env.config.save()

        self._testenv.restart()
        val = "%s %s" % (random_unique_camel(), random_word())
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)

        # [BLOODHOUND] Different markup to render field values
        self._tester.find_ticket_field('newfield', val)


class TestTicketCustomFieldTextAreaNoFormat(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test custom textarea field with no format explicitly specified,
        its contents should be rendered as plain text.
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'textarea')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', '')
        env.config.save()

        self._testenv.restart()
        val = "%s %s" % (random_unique_camel(), random_word())
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)

        # [BLOODHOUND] Different markup to render field values
        self._tester.find_ticket_field('newfield', val)


class TestTicketCustomFieldTextWikiFormat(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test custom text field with `wiki` format.
        Its contents should through the wiki engine, wiki-links and all.
        Feature added in http://trac.edgewall.org/ticket/1791
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'wiki')
        env.config.save()

        self._testenv.restart()
        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        wiki = '<a [^>]*>%s\??</a> %s' % (word1, word2)

        # [BLOODHOUND] Different markup to render field values
        self._tester.find_ticket_field('newfield', wiki)


class TestTicketCustomFieldTextAreaWikiFormat(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test custom textarea field with no format explicitly specified,
        its contents should be rendered as plain text.
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'textarea')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'wiki')
        env.config.save()

        self._testenv.restart()
        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        wiki = '<p>\s*<a [^>]*>%s\??</a> %s<br />\s*</p>' % (word1, word2)

        # [BLOODHOUND] Different markup to render field values
        self._tester.find_ticket_field('newfield', wiki)


class TestTicketCustomFieldTextReferenceFormat(FunctionalTwillTestCaseSetup):
    # Run this test case in default product context to keep body agnostic to
    # context switching
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test custom text field with `reference` format.
        Its contents are treated as a single value
        and are rendered as an auto-query link.
        Feature added in http://trac.edgewall.org/ticket/10643
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'reference')
        env.config.save()

        self._testenv.restart()
        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        query = 'status=!closed&amp;newfield=%s\+%s' % (word1, word2)

        path_prefix = urlsplit(self._tester.url).path
        querylink = '<a href="%s/query\?%s">%s</a>' % (path_prefix, query, val)

        # [BLOODHOUND] Different markup to render field values
        self._tester.find_ticket_field('newfield', querylink)


class TestTicketCustomFieldTextListFormat(FunctionalTwillTestCaseSetup):
    # Run this test case in default product context to keep body agnostic to
    # context switching
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test custom text field with `list` format.
        Its contents are treated as a space-separated list of values
        and are rendered as separate auto-query links per word.
        Feature added in http://trac.edgewall.org/ticket/10643
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'list')
        env.config.save()

        self._testenv.restart()
        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        query1 = 'status=!closed&amp;newfield=~%s' % word1
        query2 = 'status=!closed&amp;newfield=~%s' % word2

        path_prefix = urlsplit(self._tester.url).path
        querylink1 = '<a href="%s/query\?%s">%s</a>' % (path_prefix,
                                                        query1, word1)
        querylink2 = '<a href="%s/query\?%s">%s</a>' % (path_prefix,
                                                        query2, word2)
        querylinks = '%s %s' % (querylink1, querylink2)

        # [BLOODHOUND] Different markup to render field values
        self._tester.find_ticket_field('newfield', querylinks)


class RegressionTestTicket10828(FunctionalTwillTestCaseSetup):
    # Run this test case in default product context to keep body agnostic to
    # context switching
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/10828
        Rendered property changes should be described as lists of added and
        removed items, even in the presence of comma and semicolon separators.
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'A Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'list')
        env.config.save()

        self._testenv.restart()
        ticketid = self._tester.create_ticket(summary=random_sentence(3))
        self._tester.go_to_ticket(ticketid)

        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        tc.formvalue('propertyform', 'field-newfield', val)
        tc.submit('submit')
        tc.find('<em>%s</em> <em>%s</em> added' % (word1, word2))

        word3 = random_unique_camel()
        word4 = random_unique_camel()
        val = "%s,  %s; %s" % (word2, word3, word4)
        tc.formvalue('propertyform', 'field-newfield', val)
        tc.submit('submit')
        tc.find('<em>%s</em> <em>%s</em> added; <em>%s</em> removed'
                % (word3, word4, word1))

        tc.formvalue('propertyform', 'field-newfield', '')
        tc.submit('submit')
        tc.find('<em>%s</em> <em>%s</em> <em>%s</em> removed'
                % (word2, word3, word4))

        val = "%s %s,%s" % (word1, word2, word3)
        tc.formvalue('propertyform', 'field-newfield', val)
        tc.submit('submit')
        tc.find('<em>%s</em> <em>%s</em> <em>%s</em> added'
                % (word1, word2, word3))
        query1 = 'status=!closed&amp;newfield=~%s' % word1
        query2 = 'status=!closed&amp;newfield=~%s' % word2
        query3 = 'status=!closed&amp;newfield=~%s' % word3


        path_prefix = urlsplit(self._tester.url).path
        querylink1 = '<a href="%s/query\?%s">%s</a>' % (path_prefix,
                                                        query1, word1)
        querylink2 = '<a href="%s/query\?%s">%s</a>' % (path_prefix,
                                                        query2, word2)
        querylink3 = '<a href="%s/query\?%s">%s</a>' % (path_prefix,
                                                        query3, word3)
        querylinks = '%s %s, %s' % (querylink1, querylink2, querylink3)

        # [BLOODHOUND] Different markup to render field values
        self._tester.find_ticket_field('newfield', querylinks)


class RegressionTestTicket5394a(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5394 a
        Order user list alphabetically in (re)assign action
        """
        # set restrict_owner config
        env = self._testenv.get_trac_environment()
        env.config.set('ticket', 'restrict_owner', 'yes')
        env.config.save()
        self._testenv.restart()

        self._tester.go_to_front()
        self._tester.logout()

        test_users = ['alice', 'bob', 'jane', 'john', 'charlie', 'alan',
                      'zorro']
        # Apprently it takes a sec for the new user to be recognized by the
        # environment.  So we add all the users, then log in as the users
        # in a second loop.  This should be faster than adding a sleep(1)
        # between the .adduser and .login steps.
        for user in test_users:
            self._testenv.adduser(user)
        for user in test_users:
            self._tester.login(user)
            self._tester.logout()

        self._tester.login('admin')

        ticketid = self._tester.create_ticket("regression test 5394a")
        self._tester.go_to_ticket(ticketid)

        # [BLOODHOUND] Workflow <select /> does not end with id attribute
        options = 'id="action_reassign_reassign_owner"[^>]*>' + \
            ''.join(['<option[^>]*>%s</option>' % user for user in
                     sorted(test_users + ['admin', 'user'])])
        tc.find(options, 's')
        # We don't have a good way to fully delete a user from the Trac db.
        # Once we do, we may want to cleanup our list of users here.


class RegressionTestTicket5394b(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5394 b
        Order user list alphabetically on new ticket page
        """
        #FIXME : Test is missing a lot of context. See RegressionTestTicket5394a

        # Must run after RegressionTestTicket5394a
        self._tester.go_to_front()

        # [BLOODHOUND] New Ticket => More fields (in create ticket menu)
        self._tester.go_to_newticket()
        # [BLOODHOUND] Create New Ticket => New Ticket
        tc.find('New Ticket')

        test_users = ['alice', 'bob', 'jane', 'john', 'charlie', 'alan',
                      'zorro']
        options = 'id="field-owner"[^>]*>[[:space:]]*<option/>.*' + \
            '.*'.join(['<option[^>]*>%s</option>' % user for user in
                     sorted(test_users + ['admin', 'user'])])
        options = '.*'.join(sorted(test_users + ['admin', 'user']))
        tc.find(options, 's')

# FIXME: Verbatim copy of its peer just to override regex_owned_by
class RegressionTestTicket5497a(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 a
        Open ticket, component changed, owner not changed"""
        ticketid = self._tester.create_ticket("regression test 5497a")
        self._tester.go_to_ticket(ticketid)
        tc.formvalue('propertyform', 'field-component', 'regression5497')
        tc.submit('submit')
        tc.find(regex_owned_by('user'))


# FIXME: Verbatim copy of its peer just to override regex_owned_by
class RegressionTestTicket5497b(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 b
        Open ticket, component changed, owner changed"""
        ticketid = self._tester.create_ticket("regression test 5497b")
        self._tester.go_to_ticket(ticketid)
        tc.formvalue('propertyform', 'field-component', 'regression5497')
        tc.formvalue('propertyform', 'action', 'reassign')
        tc.formvalue('propertyform', 'action_reassign_reassign_owner', 'admin')
        tc.submit('submit')
        tc.notfind(regex_owned_by('user'))
        tc.find(regex_owned_by('admin'))


# FIXME: Verbatim copy of its peer just to override regex_owned_by
class RegressionTestTicket5497c(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 c
        New ticket, component changed, owner not changed"""
        ticketid = self._tester.create_ticket("regression test 5497c",
            {'component':'regression5497'})
        self._tester.go_to_ticket(ticketid)
        tc.find(regex_owned_by('user'))


# FIXME: Verbatim copy of its peer just to override regex_owned_by
class RegressionTestTicket5497d(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 d
        New ticket, component changed, owner changed"""
        ticketid = self._tester.create_ticket("regression test 5497d",
            {'component':'regression5497', 'owner':'admin'})
        self._tester.go_to_ticket(ticketid)
        tc.find(regex_owned_by('admin'))

class RegressionTestRev5994(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of the column label fix in r5994"""
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'custfield', 'text')
        env.config.set('ticket-custom', 'custfield.label', 'Custom Field')
        env.config.save()
        try:
            self._testenv.restart()
            self._tester.go_to_query()
            self._tester.find_query_column_selector('custfield', 'Custom Field')
        finally:
            pass
            #env.config.set('ticket', 'restrict_owner', 'no')
            #env.config.save()
            #self._testenv.restart()


class RegressionTestTicket6048(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6048"""
        # Setup the DeleteTicket plugin
        plugin = open(os.path.join(self._testenv.command_cwd, 'sample-plugins',
                                   'workflow', 'DeleteTicket.py')).read()
        open(os.path.join(self._testenv.tracdir, 'plugins', 'DeleteTicket.py'),
             'w').write(plugin)
        env = self._testenv.get_trac_environment()

        # [BLOODHOUND] Ensure plugin will be enabled in target scope
        env.config.set('components', 'DeleteTicket.*', 'enabled')

        prevconfig = env.config.get('ticket', 'workflow')
        env.config.set('ticket', 'workflow',
                       prevconfig + ',DeleteTicketActionController')
        env.config.save()
        env = self._testenv.get_trac_environment() # reload environment

        # Create a ticket and delete it
        ticket_id = self._tester.create_ticket(
            summary='RegressionTestTicket6048')
        # (Create a second ticket so that the ticket id does not get reused
        # and confuse the tester object.)
        self._tester.create_ticket(summary='RegressionTestTicket6048b')
        self._tester.go_to_ticket(ticket_id)
        tc.find('delete ticket')
        tc.formvalue('propertyform', 'action', 'delete')
        tc.submit('submit')

        self._tester.go_to_ticket(ticket_id)
        tc.find('Error: Invalid ticket number')
        tc.find('Ticket %s does not exist.' % ticket_id)

        # Remove the DeleteTicket plugin
        env.config.set('ticket', 'workflow', prevconfig)
        env.config.save()
        env = self._testenv.get_trac_environment() # reload environment
        for ext in ('py', 'pyc', 'pyo'):
            filename = os.path.join(self._testenv.tracdir, 'plugins',
                                    'DeleteTicket.%s' % ext)
            if os.path.exists(filename):
                os.unlink(filename)


class RegressionTestTicket7821group(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/7821 group"""
        env = self._testenv.get_trac_environment()
        saved_default_query = env.config.get('query', 'default_query')
        default_query = 'status!=closed&order=status&group=status&max=42' \
                        '&desc=1&groupdesc=1&col=summary|status|cc' \
                        '&cc~=$USER'
        env.config.set('query', 'default_query', default_query)
        env.config.save()
        try:
            self._testenv.restart()
            self._tester.create_ticket('RegressionTestTicket7821 group')
            self._tester.go_to_query()
            # $USER
            tc.find('<input type="text" name="0_cc" value="admin"'
                    ' size="[0-9]+" />')
            # col
            tc.find('<input type="checkbox" name="col" value="summary"'
                    ' checked="checked" />')
            tc.find('<input type="checkbox" name="col" value="owner" />')
            tc.find('<input type="checkbox" name="col" value="status"'
                    ' checked="checked" />')
            tc.find('<input type="checkbox" name="col" value="cc"'
                    ' checked="checked" />')
            # group
            tc.find('<option selected="selected" value="status">Status'
                    '</option>')
            # groupdesc
            tc.find('<input type="checkbox" name="groupdesc" id="groupdesc"'
                    ' checked="checked" />')
            # max
            # [BLOODHOUND] class="input-mini" added (Twitter Bootstrap)
            tc.find('<input type="text" name="max" id="max" size="[0-9]*?"'
                    ' value="42" [^/]*/>')
            # col in results
            tc.find('<a title="Sort by Ticket [(]ascending[)]" ')
            tc.find('<a title="Sort by Summary [(]ascending[)]" ')
            tc.find('<a title="Sort by Status [(]ascending[)]" ')
            tc.find('<a title="Sort by Cc [(]ascending[)]" ')
            tc.notfind('<a title="Sort by Owner "')
        finally:
            env.config.set('query', 'default_query', saved_default_query)
            env.config.save()
            self._testenv.restart()


class RegressionTestTicket8247(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/8247
        Author field of ticket comment corresponding to the milestone removal
        was always 'anonymous'.
        """
        name = "MilestoneRemove"
        self._tester.create_milestone(name)
        id = self._tester.create_ticket(info={'milestone': name})
        ticket_url = self._tester.url + "/ticket/%d" % id
        tc.go(ticket_url)
        tc.find(name)
        tc.go(self._tester.url + "/admin/ticket/milestones")
        tc.formvalue('milestone_table', 'sel', name)
        tc.submit('remove')
        tc.go(ticket_url)

        # [BLOODHOUND] Ticket comment header changed
        tc.find('<strong class="trac-field-milestone">Milestone</strong>'
                '[ \n\t]*<span>[ \n\t]*<em>%s</em> deleted' % name)
        tc.find('by admin<span>, <a.* ago</a></span>')

        tc.notfind('anonymous')


class TestTimelineTicketDetails(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test ticket details on timeline"""
        env = self._testenv.get_trac_environment()
        env.config.set('timeline', 'ticket_show_details', 'yes')
        env.config.save()
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.go_to_ticket(ticketid)
        self._tester.add_comment(ticketid)
        self._tester.go_to_timeline()
        tc.formvalue('prefs', 'ticket_details', True)
        tc.submit()
        htmltags = '(<[^>]*>)*'

        # [BLOODHOUND] Ticket events are different i.e. 'by user' outside <a />
        tc.find(htmltags + 'Ticket ' + htmltags + '#' + str(ticketid) +
                htmltags + ' \\(' + summary + '\\) updated\\s*' +
                htmltags + '\\s+by\\s+' + htmltags + 'admin', 's')


class TestTicketHistoryDiff(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test ticket history (diff)"""
        name = 'TestTicketHistoryDiff'
        ticketid = self._tester.create_ticket(name)
        self._tester.go_to_ticket(ticketid)
        tc.formvalue('propertyform', 'description', random_sentence(6))
        tc.submit('submit')

        # [BLOODHOUND] Description 'modified' in comments feed inside <span />
        tc.find('Description<[^>]*>\\s*<[^>]*>\\s*modified \\(<[^>]*>diff', 's')
        tc.follow('diff')
        tc.find('Changes\\s*between\\s*<[^>]*>Initial Version<[^>]*>\\s*and' \
                '\\s*<[^>]*>Version 1<[^>]*>\\s*of\\s*<[^>]*>Ticket #' , 's')


class RegressionTestTicket5602(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5602"""
        # Create a set of tickets, and assign them all to a milestone
        milestone = self._tester.create_milestone()
        ids = [self._tester.create_ticket() for x in range(5)]
        [self._tester.ticket_set_milestone(x, milestone) for x in ids]
        # Need a ticket in each state: new, assigned, accepted, closed,
        # reopened
        # leave ids[0] as new
        # make ids[1] be assigned
        self._tester.go_to_ticket(ids[1])
        tc.formvalue('propertyform', 'action', 'reassign')
        tc.formvalue('propertyform', 'action_reassign_reassign_owner', 'admin')
        tc.submit('submit')
        # make ids[2] be accepted
        self._tester.go_to_ticket(ids[2])
        tc.formvalue('propertyform', 'action', 'accept')
        tc.submit('submit')
        # make ids[3] be closed
        self._tester.go_to_ticket(ids[3])
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.formvalue('propertyform', 'action_resolve_resolve_resolution', 'fixed')
        tc.submit('submit')
        # make ids[4] be reopened
        self._tester.go_to_ticket(ids[4])
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.formvalue('propertyform', 'action_resolve_resolve_resolution', 'fixed')
        tc.submit('submit')
        # FIXME: we have to wait a second to avoid "IntegrityError: columns
        # ticket, time, field are not unique"
        time.sleep(1)
        tc.formvalue('propertyform', 'action', 'reopen')
        tc.submit('submit')
        tc.show()
        tc.notfind("Python Traceback")

        # Go to the milestone and follow the links to the closed and active
        # tickets.
        tc.go(self._tester.url + "/roadmap")
        tc.follow(milestone)

        # [BLOODHOUND] closed: labels in milestone progress bar removed
        tc.follow(r"/query\?.*status=closed&.*milestone=%s$" % (milestone,))
        tc.find("Resolution:[ \t\n]+fixed")

        tc.back()
        # [BLOODHOUND] active: labels in milestone progress bar removed
        tc.follow(r"/query\?.*status=new&.*milestone=%s$" % (milestone,))
        tc.find("Status:[ \t\n]+new")
        tc.find("Status:[ \t\n]+assigned")
        tc.find("Status:[ \t\n]+accepted")
        tc.notfind("Status:[ \t\n]+closed")
        tc.find("Status:[ \t\n]+reopened")


class RegressionTestTicket9084(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/9084"""
        ticketid = self._tester.create_ticket()
        self._tester.add_comment(ticketid)
        self._tester.go_to_ticket(ticketid)
        tc.submit('2', formname='reply-to-comment-1') # '1' hidden, '2' submit
        tc.formvalue('propertyform', 'comment', random_sentence(3))

        # [BLOODHPUND] In ticket comments reply form 'Submit changes'=>'Submit'
        tc.submit('Submit')
        tc.notfind('AssertionError')


class RegressionTestTicket6879a(FunctionalTwillTestCaseSetup,
                                unittest.TestCase):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6879 a

        Make sure that previewing a close does not make the available actions
        be those for the close status.
        """
        # create a ticket, then preview resolving the ticket twice
        ticket_id = self._tester.create_ticket("RegressionTestTicket6879 a")
        self._tester.go_to_ticket(ticket_id)
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.formvalue('propertyform', 'action_resolve_resolve_resolution', 'fixed')

        # [BLOODHOUND] No preview button for ticket (comments) in BH theme
        try:
            tc.submit('preview')
        except TwillException:
            self.skipTest('Active theme without ticket preview')

        tc.formvalue('propertyform', 'action', 'resolve')
        tc.submit('preview')


class RegressionTestTicket6879b(FunctionalTwillTestCaseSetup,
                                unittest.TestCase):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6879 b

        Make sure that previewing a close does not make the available actions
        be those for the close status.
        """
        # create a ticket, then preview resolving the ticket twice
        ticket_id = self._tester.create_ticket("RegressionTestTicket6879 b")
        self._tester.go_to_ticket(ticket_id)
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.formvalue('propertyform', 'action_resolve_resolve_resolution', 'fixed')

        # [BLOODHOUND] No preview button for ticket (comments) in BH theme
        try:
            tc.submit('preview')
        except TwillException:
            self.skipTest('Active theme without ticket comment preview')

        tc.formvalue('propertyform', 'action', 'resolve')
        tc.submit('submit')


class TestAdminPriorityRenumber(FunctionalTwillTestCaseSetup):
    BH_IN_DEFAULT_PRODUCT = True

    def runTest(self):
        """Admin renumber priorities"""

        # [BLOODHOUND] class="input-mini" appended to priorities <select />
        valuesRE = re.compile('<select name="value_([0-9]+)".*>', re.M)

        html = b.get_html()
        max_priority = max([int(x) for x in valuesRE.findall(html)])

        name = "RenumberPriority"
        self._tester.create_priority(name + '1')
        self._tester.create_priority(name + '2')
        priority_url = self._tester.url + '/admin/ticket/priority'
        tc.go(priority_url)
        tc.url(priority_url + '$')
        tc.find(name + '1')
        tc.find(name + '2')
        tc.formvalue('enumtable', 'value_%s' % (max_priority + 1), str(max_priority + 2))
        tc.formvalue('enumtable', 'value_%s' % (max_priority + 2), str(max_priority + 1))
        tc.submit('apply')
        tc.url(priority_url + '$')
        # Verify that their order has changed.
        tc.find(name + '2.*' + name + '1', 's')


# Ensure that overridden code will be loaded
def trac_functionalSuite(suite=None):
    suite.addTest(TestTickets())

    # [BLOODHOUND] there's no such thing like ticket preview
    #suite.addTest(TestTicketPreview())

    suite.addTest(TestTicketNoSummary())
    suite.addTest(TestTicketAltFormats())
    suite.addTest(TestTicketCSVFormat())
    suite.addTest(TestTicketTabFormat())
    suite.addTest(TestTicketRSSFormat())

    # [BLOODHOUND] TODO: Move to BloodhoundSearch plugin
    # suite.addTest(TestTicketSearch())
    # suite.addTest(TestNonTicketSearch())

    suite.addTest(TestTicketHistory())
    suite.addTest(TestTicketHistoryDiff())
    suite.addTest(TestTicketQueryLinks())
    suite.addTest(TestTicketQueryOrClause())
    suite.addTest(TestTicketCustomFieldTextNoFormat())
    suite.addTest(TestTicketCustomFieldTextWikiFormat())
    suite.addTest(TestTicketCustomFieldTextAreaNoFormat())
    suite.addTest(TestTicketCustomFieldTextAreaWikiFormat())
    suite.addTest(TestTicketCustomFieldTextReferenceFormat())
    suite.addTest(TestTicketCustomFieldTextListFormat())
    suite.addTest(RegressionTestTicket10828())
    suite.addTest(TestTimelineTicketDetails())
    suite.addTest(TestAdminComponent())
    suite.addTest(TestAdminComponentDuplicates())
    suite.addTest(TestAdminComponentRemoval())
    suite.addTest(TestAdminComponentNonRemoval())
    suite.addTest(TestAdminComponentDefault())
    suite.addTest(TestAdminComponentDetail())
    suite.addTest(TestAdminMilestone())
    suite.addTest(TestAdminMilestoneSpace())
    suite.addTest(TestAdminMilestoneDuplicates())
    suite.addTest(TestAdminMilestoneDetail())
    suite.addTest(TestAdminMilestoneDue())
    suite.addTest(TestAdminMilestoneDetailDue())
    suite.addTest(TestAdminMilestoneCompleted())
    suite.addTest(TestAdminMilestoneCompletedFuture())
    suite.addTest(TestAdminMilestoneRemove())
    suite.addTest(TestAdminMilestoneRemoveMulti())
    suite.addTest(TestAdminMilestoneNonRemoval())
    suite.addTest(TestAdminMilestoneDefault())
    suite.addTest(TestAdminPriority())
    suite.addTest(TestAdminPriorityModify())
    suite.addTest(TestAdminPriorityRemove())
    suite.addTest(TestAdminPriorityRemoveMulti())
    suite.addTest(TestAdminPriorityNonRemoval())
    suite.addTest(TestAdminPriorityDefault())
    suite.addTest(TestAdminPriorityDetail())
    suite.addTest(TestAdminPriorityRenumber())
    suite.addTest(TestAdminPriorityRenumberDup())
    suite.addTest(TestAdminResolution())
    suite.addTest(TestAdminResolutionDuplicates())
    suite.addTest(TestAdminSeverity())
    suite.addTest(TestAdminSeverityDuplicates())
    suite.addTest(TestAdminType())
    suite.addTest(TestAdminTypeDuplicates())
    suite.addTest(TestAdminVersion())
    suite.addTest(TestAdminVersionDuplicates())
    suite.addTest(TestAdminVersionDetail())
    suite.addTest(TestAdminVersionDetailTime())
    suite.addTest(TestAdminVersionDetailCancel())
    suite.addTest(TestAdminVersionRemove())
    suite.addTest(TestAdminVersionRemoveMulti())
    suite.addTest(TestAdminVersionNonRemoval())
    suite.addTest(TestAdminVersionDefault())
    suite.addTest(TestNewReport())
    suite.addTest(TestReportRealmDecoration())
    suite.addTest(RegressionTestRev5665())
    suite.addTest(RegressionTestRev5994())

    suite.addTest(RegressionTestTicket4447())
    suite.addTest(RegressionTestTicket4630a())
    suite.addTest(RegressionTestTicket4630b())
    suite.addTest(RegressionTestTicket5022())
    suite.addTest(RegressionTestTicket5394a())
    suite.addTest(RegressionTestTicket5394b())
    suite.addTest(RegressionTestTicket5497prep())
    suite.addTest(RegressionTestTicket5497a())
    suite.addTest(RegressionTestTicket5497b())
    suite.addTest(RegressionTestTicket5497c())
    suite.addTest(RegressionTestTicket5497d())
    suite.addTest(RegressionTestTicket5602())
    suite.addTest(RegressionTestTicket5687())
    suite.addTest(RegressionTestTicket5930())
    suite.addTest(RegressionTestTicket6048())
    suite.addTest(RegressionTestTicket6747())
    suite.addTest(RegressionTestTicket6879a())
    suite.addTest(RegressionTestTicket6879b())
    suite.addTest(RegressionTestTicket6912a())
    suite.addTest(RegressionTestTicket6912b())
    suite.addTest(RegressionTestTicket7821group())
    suite.addTest(RegressionTestTicket7821var())
    suite.addTest(RegressionTestTicket8247())
    suite.addTest(RegressionTestTicket8861())
    suite.addTest(RegressionTestTicket9084())
    suite.addTest(RegressionTestTicket9981())

    return suite


#--------------
# Multiproduct test cases
#--------------



def functionalSuite(suite=None):
    if not suite:
        from tests import functional
        suite = functional.functionalSuite()

    trac_functionalSuite(suite)

    return suite


if __name__ == '__main__':
    import unittest
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = hooks
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from tests import unittest

from trac.web.href import Href

from multiproduct.hooks import ProductizedHref


class ProductizedHrefTestCase(unittest.TestCase):

    def setUp(self):
        self.ghref = Href('/gbase')
        self.phref = ProductizedHref(self.ghref, '/gbase/product')

    def test_paths_no_transform(self):
        self.assertEqual('/gbase/admin', self.phref.admin())
        self.assertEqual('/gbase/logout', self.phref.logout())
        self.assertEqual('/gbase/prefs', self.phref('prefs'))
        self.assertEqual('/gbase/verify_email?a=1&b=cde',
                         self.phref('verify_email', a=1, b='cde'))

    def test_static_path_no_transform(self):
        self.assertEqual('/gbase/js', self.phref('js/'))
        self.assertEqual('/gbase/css', self.phref('css/'))
        self.assertEqual('/gbase/img', self.phref('img/'))

    def test_params_as_args(self):
        self.assertEqual('/gbase/product/ticket/540',
                         self.phref('ticket', 540))
        self.assertEqual('/gbase/product/ticket/540',
                         self.phref.ticket(540))

    def test_params_as_kwargs(self):
        self.assertIn(self.phref('ticket', param='value',
                                 other='other value'),
                      ['/gbase/product/ticket?param=value&other=other+value',
                       '/gbase/product/ticket?other=other+value&param=value'])

    def test_params_as_dictionary(self):
        self.assertIn(self.phref.ticket({'param': 'value',
                                         'other': 'other value'}),
                      ['/gbase/product/ticket/?param=value&other=other+value',
                       '/gbase/product/ticket?other=other+value&param=value'])


def test_suite():
    return unittest.TestSuite([
        unittest.makeSuite(ProductizedHrefTestCase, 'test')
    ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's ticket reports in product environments"""

import unittest

from trac.mimeview.tests.api import MimeviewTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductMimeviewTestCase(MimeviewTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(
                    enable=['%s.%s' % (MimeviewTestCase.__module__, c)
                            for c in ['Converter0', 'Converter1', 'Converter2']]
                )
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None


def test_suite():
    return unittest.TestSuite([
            # TODO : Put MIME API doctests in product context
            # doctest.DocTestSuite(trac.mimeview.api)
            unittest.makeSuite(ProductMimeviewTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = patch
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's patch renderer in product environments"""

import unittest

from trac.mimeview.api import Mimeview
from trac.mimeview.patch import PatchRenderer
from trac.mimeview.tests.patch import PatchRendererTestCase
from trac.web.chrome import Chrome

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductPatchRendererTestCase(PatchRendererTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(
                    enable=[Chrome, PatchRenderer]
                )
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def setUp(self):
        PatchRendererTestCase.setUp(self)
        self.patch = Mimeview(self.env).renderers[0]

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductPatchRendererTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = pygments
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's Pygments renderer in product environments"""

from tests import unittest

from tests.env import MultiproductTestCase
from trac.mimeview.api import Mimeview
from trac.mimeview.pygments import PygmentsRenderer
from trac.mimeview.tests import pygments as test_pygments
from trac.web.chrome import Chrome

from multiproduct.env import ProductEnvironment

have_pygments = False

if test_pygments.have_pygments:
    super_class = test_pygments.PygmentsRendererTestCase
else:
    class super_class(object):
        test_empty_content = test_extra_mimetypes = test_newline_content = \
        test_python_hello = test_python_hello_mimeview = \
                lambda self : None


class ProductPygmentsRendererTestCase(super_class, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(
                    enable=[Chrome, PygmentsRenderer]
                )
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def setUp(self):
        test_pygments.PygmentsRendererTestCase.setUp(self)
        self.pygments = Mimeview(self.env).renderers[0]

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None

ProductPygmentsRendererTestCase = unittest.skipUnless(
        test_pygments.have_pygments,
        'mimeview/tests/pygments (no pygments installed)'
    )(ProductPygmentsRendererTestCase)

def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductPygmentsRendererTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = model
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for multiproduct/model.py"""
import shutil
import tempfile
from tests import unittest

from trac.core import TracError
from trac.test import EnvironmentStub
from trac.tests.resource import TestResourceChangeListener
from trac.ticket.model import Ticket

from bhdashboard.model import ModelBase
from multiproduct.api import MultiProductSystem
from multiproduct.env import ProductEnvironment
from multiproduct.model import Product


class ProductTestCase(unittest.TestCase):
    """Unit tests covering the Product model"""
    INITIAL_PREFIX = 'tp'
    INITIAL_NAME = 'test project'
    INITIAL_DESCRIPTION = 'a test project'

    def setUp(self):
        self.env = EnvironmentStub(enable=['trac.*', 'multiproduct.*'])
        self.env.path = tempfile.mkdtemp(prefix='bh-product-tempenv-')

        self.mpsystem = MultiProductSystem(self.env)
        try:
            self.mpsystem.upgrade_environment(self.env.db_transaction)
        except self.env.db_exc.OperationalError:
            # table remains but database version is deleted
            pass

        self.listener = self._enable_resource_change_listener()
        self.default_data = {'prefix':self.INITIAL_PREFIX,
                             'name':self.INITIAL_NAME,
                             'description':self.INITIAL_DESCRIPTION}

        self.global_env = self.env
        self.product = Product(self.env)
        self.product._data.update(self.default_data)
        self.product.insert()

    def tearDown(self):
        shutil.rmtree(self.env.path)
        self.env.reset_db()

    def _enable_resource_change_listener(self):
        listener = TestResourceChangeListener(self.env)
        listener.resource_type = Product
        listener.callback = self.listener_callback
        return listener

    def listener_callback(self, action, resource, context, old_values = None):
        # pylint: disable=unused-argument
        # pylint: disable=attribute-defined-outside-init
        self.prefix = resource.prefix
        self.name = resource.name
        self.description = resource.description

    def test_set_table_field(self):
        """tests that table.field style update works"""
        test = {'prefix': 'td',
                'name': 'test field access',
                'description': 'product to test field setting'}

        product = Product(self.env)

        # attempt to set the fields from the data
        product.prefix = test['prefix']
        product.name = test['name']
        product.description = test['description']

        self.assertEqual(product._data['prefix'], test['prefix'])
        self.assertEqual(product._data['name'], test['name'])
        self.assertEqual(product._data['description'], test['description'])

    def test_select(self):
        """tests that select can search Products by fields"""

        p2_data = {'prefix':'tp2',
                   'name':'test project 2',
                   'description':'a different test project'}
        p3_data = {'prefix':'tp3',
                   'name':'test project 3',
                   'description':'test project'}

        product2 = Product(self.env)
        product2._data.update(p2_data)
        product3 = Product(self.env)
        product3._data.update(p3_data)

        product2.insert()
        product3.insert()

        products = list(Product.select(self.env, where={'prefix':'tp'}))
        self.assertEqual(1, len(products))
        products = list(Product.select(self.env,
            where={'name':'test project'}))
        self.assertEqual(1, len(products))
        products = list(Product.select(self.env,
            where={'prefix':'tp3', 'name':'test project 3'}))
        self.assertEqual(1, len(products))

    def test_update(self):
        """tests that we can use update to push data to the database"""
        product = list(Product.select(self.env, where={'prefix':'tp'}))[0]
        self.assertEqual('test project', product._data['name'])

        new_data = {'prefix':'tp',
                    'name':'updated',
                    'description':'nothing'}
        product._data.update(new_data)
        product.update()

        comp_product = list(Product.select(self.env, where={'prefix':'tp'}))[0]
        self.assertEqual('updated', comp_product._data['name'])

    def test_update_key_change(self):
        """tests that we raise an error for attempting to update key fields"""
        bad_data = {'prefix':'tp0',
                    'name':'update',
                    'description':'nothing'}
        product = list(Product.select(self.env, where={'prefix':'tp'}))[0]
        product._data.update(bad_data)
        self.assertRaises(TracError, product.update)

    def test_insert(self):
        """test saving new Product"""
        data = {'prefix':'new', 'name':'new', 'description':'new'}
        product = Product(self.env)
        product._data.update(data)
        product.insert()

        check_products = list(Product.select(self.env, where={'prefix':'new'}))

        self.assertEqual(product._data['prefix'],
                         check_products[0]._data['prefix'])
        self.assertEqual(1, len(check_products))

    def test_insert_duplicate_key(self):
        """test attempted saving of Product with existing key fails"""
        dupe_key_data = {'prefix':'tp',
                         'name':'dupe',
                         'description':'dupe primary key'}
        product2 = Product(self.env)
        product2._data.update(dupe_key_data)
        self.assertRaises(TracError, product2.insert)

    def test_delete(self):
        """test that we are able to delete Products"""
        product = list(Product.select(self.env, where={'prefix':'tp'}))[0]
        product.delete()

        post = list(Product.select(self.env, where={'prefix':'tp'}))
        self.assertEqual(0, len(post))

    def test_delete_twice(self):
        """test that we error when deleting twice on the same key"""
        product = list(Product.select(self.env, where={'prefix':'tp'}))[0]
        product.delete()

        self.assertRaises(TracError, product.delete)

    def test_field_data_get(self):
        """tests that we can use table.field syntax to get to the field data"""
        prefix = self.default_data['prefix']
        name = self.default_data['name']
        description = self.default_data['description']
        product = list(Product.select(self.env, where={'prefix':prefix}))[0]
        self.assertEqual(prefix, product.prefix)
        self.assertEqual(name, product.name)
        self.assertEqual(description, product.description)

    def test_field_set(self):
        """tests that we can use table.field = something to set field data"""
        prefix = self.default_data['prefix']
        product = list(Product.select(self.env, where={'prefix':prefix}))[0]

        new_description = 'test change of description'
        product.description = new_description
        self.assertEqual(new_description, product.description)

    def test_missing_unique_fields(self):
        """ensure that that insert method works when _meta does not specify
        unique fields when inserting more than one ProductResourceMap instances
        """
        class TestModel(ModelBase):
            """A test model with no unique_fields"""
            _meta = {'table_name': 'bloodhound_testmodel',
                     'object_name': 'TestModelObject',
                     'key_fields': ['id',],
                     'non_key_fields': ['value'],
                     'unique_fields': [],}

        from trac.db import DatabaseManager
        schema = [TestModel._get_schema(), ]
        with self.env.db_transaction as db:
            db_connector, dummy = DatabaseManager(self.env)._get_connector()
            for table in schema:
                for statement in db_connector.to_sql(table):
                    db(statement)

        structure =  dict([(table.name, [col.name for col in table.columns])
                           for table in schema])
        tm1 = TestModel(self.env)
        tm1._data.update({'id':1, 'value':'value1'})
        tm1.insert()
        tm2 = TestModel(self.env)
        tm2._data.update({'id':2, 'value':'value2'})
        tm2.insert()

    def test_change_listener_created(self):
        self.assertEqual('created', self.listener.action)
        self.assertIsInstance(self.listener.resource, Product)
        self.assertEqual(self.INITIAL_PREFIX, self.prefix)
        self.assertEqual(self.INITIAL_NAME, self.name)
        self.assertEqual(self.INITIAL_DESCRIPTION, self.description)

    def test_change_listener_changed(self):
        CHANGED_NAME = "changed name"
        self.product.name = CHANGED_NAME
        self.product.update()
        self.assertEqual('changed', self.listener.action)
        self.assertIsInstance(self.listener.resource, Product)
        self.assertEqual(CHANGED_NAME, self.name)
        self.assertEqual({"name":self.INITIAL_NAME}, self.listener.old_values)

    def test_change_listener_deleted(self):
        self.product.delete()
        self.assertEqual('deleted', self.listener.action)
        self.assertIsInstance(self.listener.resource, Product)
        self.assertEqual(self.INITIAL_PREFIX, self.prefix)

    def test_get_tickets(self):
        for pdata in (
            {'prefix': 'p2', 'name':'product, too', 'description': ''},
            {'prefix': 'p3', 'name':'strike three', 'description': ''},
        ):
            num_tickets = 5
            product = Product(self.global_env)
            product._data.update(pdata)
            product.insert()
            self.env = ProductEnvironment(self.global_env, product)
            for i in range(num_tickets):
                ticket = Ticket(self.env)
                ticket['summary'] = 'hello ticket #%s-%d' % (product.prefix, i)
                ticket['reporter'] = 'admin'
                tid = ticket.insert()

            # retrieve tickets using both global and product scope
            tickets_from_global = [(t['product'], t['id']) for t in
                Product.get_tickets(self.global_env, product.prefix)]
            self.assertEqual(len(tickets_from_global), num_tickets)
            tickets_from_product = [(t['product'], t['id']) for t in
                Product.get_tickets(self.env)]
            self.assertEqual(len(tickets_from_product), num_tickets)
            # both lists should contain same elements
            intersection = set(tickets_from_global) & set(tickets_from_product)
            self.assertEqual(len(intersection), num_tickets)

def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(ProductTestCase, 'test'))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = perm
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's product permissions subsystem"""

import unittest

from trac.admin.api import AdminCommandError
from trac import perm
from trac.resource import Neighborhood
from trac.test import Mock
from trac.tests.perm import DefaultPermissionStoreTestCase,\
        PermissionSystemTestCase, PermissionCacheTestCase,\
        PermissionPolicyTestCase, TestPermissionPolicy, TestPermissionRequestor

from multiproduct.api import MultiProductSystem
from multiproduct.env import ProductEnvironment
from multiproduct.model import Product
from multiproduct.perm import MultiproductPermissionPolicy, sudo
from tests.env import MultiproductTestCase

# DefaultPermission policy has its own cache that causes
# test_product_trac_admin_actions to fail sometimes.
perm.DefaultPermissionPolicy.CACHE_EXPIRY = 0


class ProductDefaultPermissionStoreTestCase(DefaultPermissionStoreTestCase,
        MultiproductTestCase):

    def setUp(self):
        self.global_env = self._setup_test_env()
        self._upgrade_mp(self.global_env)
        self._setup_test_log(self.global_env)
        self._load_product_from_data(self.env, self.default_product)
        self.env = ProductEnvironment(self.env, self.default_product)

        self.store = perm.DefaultPermissionStore(self.env)

    def test_env_isolation(self):
        global_env = self.global_env
        env = self.env

        self._load_product_from_data(self.global_env, 'tp2')
        env1 = ProductEnvironment(self.global_env, 'tp2')

        global_store = perm.DefaultPermissionStore(global_env)
        store = perm.DefaultPermissionStore(env)
        store1 = perm.DefaultPermissionStore(env1)

        global_env.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('dev', 'WIKI_MODIFY'),
             ('dev', 'REPORT_ADMIN'),
             ('john', 'dev')])
        env.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('dev', 'WIKI_VIEW'),
             ('dev', 'REPORT_VIEW'),
             ('john', 'dev')])
        env1.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('dev', 'TICKET_CREATE'),
             ('dev', 'MILESTONE_VIEW'),
             ('john', 'dev')])

        self.assertEquals(['REPORT_ADMIN', 'WIKI_MODIFY'],
                          sorted(global_store.get_user_permissions('john')))
        self.assertEquals(['REPORT_VIEW', 'WIKI_VIEW'],
                          sorted(store.get_user_permissions('john')))
        self.assertEquals(['MILESTONE_VIEW', 'TICKET_CREATE'],
                          sorted(store1.get_user_permissions('john')))

class ProductPermissionSystemTestCase(PermissionSystemTestCase,
                                      MultiproductTestCase):
    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(enable=[
                    perm.PermissionSystem,
                    perm.DefaultPermissionStore,
                    TestPermissionRequestor])
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def test_all_permissions(self):
        # PRODUCT_ADMIN meta-permission in product context
        self.assertEqual({'EMAIL_VIEW': True, 'TRAC_ADMIN': True,
                          'TEST_CREATE': True, 'TEST_DELETE': True,
                          'TEST_MODIFY': True,  'TEST_ADMIN': True,
                          'PRODUCT_ADMIN' : True},
                         self.perm.get_user_permissions())

    def test_expand_actions_iter_7467(self):
        # Check that expand_actions works with iterators (#7467)
        # PRODUCT_ADMIN meta-permission in product context
        perms = set(['EMAIL_VIEW', 'TRAC_ADMIN', 'TEST_DELETE', 'TEST_MODIFY',
                     'TEST_CREATE', 'TEST_ADMIN', 'PRODUCT_ADMIN'])
        self.assertEqual(perms, self.perm.expand_actions(['TRAC_ADMIN']))
        self.assertEqual(perms, self.perm.expand_actions(iter(['TRAC_ADMIN'])))


class ProductPermissionCacheTestCase(PermissionCacheTestCase,
                                      MultiproductTestCase):
    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(enable=[
                    perm.DefaultPermissionStore,
                    perm.DefaultPermissionPolicy,
                    TestPermissionRequestor])
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass


class ProductNeighborhoodPermissionCacheTestCase(ProductPermissionCacheTestCase,
                                      MultiproductTestCase):
    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(enable=[
                    perm.DefaultPermissionStore,
                    perm.DefaultPermissionPolicy,
                    MultiProductSystem,
                    TestPermissionRequestor])
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def setUp(self):
        ProductPermissionCacheTestCase.setUp(self)
        nbh = Neighborhood('product', self.default_product)
        resource = nbh.child(None, None)
        self.perm = perm.PermissionCache(self.global_env, 'testuser', resource)


class SudoTestCase(ProductPermissionCacheTestCase):
    loader = unittest.defaultTestLoader
    tcnames = loader.getTestCaseNames(ProductPermissionCacheTestCase)
    _gen_tests = {}

    def test_sudo_wrong_context(self):
        sudoperm = sudo(None, 'EMAIL_VIEW', ['TEST_ADMIN'])

        with self.assertRaises(RuntimeError) as test_cm:
            sudoperm.has_permission('TEST_MODIFY')
        self.assertEqual('Permission check out of context',
                         str(test_cm.exception))

        with self.assertRaises(ValueError) as test_cm:
            with sudoperm:
                pass
        self.assertEquals('Context manager not bound to request object',
                          str(test_cm.exception))

    def test_sudo_fail_require(self):
        sudoperm = sudo(None, 'EMAIL_VIEW', ['TEST_ADMIN'])

        sudoperm.perm = self.perm
        with self.assertRaises(perm.PermissionError) as test_cm:
            sudoperm.require('TRAC_ADMIN')
        self.assertEqual('EMAIL_VIEW', test_cm.exception.action)

    def test_sudo_grant_meta_perm(self):
        self.env.parent.enable_component(perm.PermissionSystem)
        self.env.enable_component(perm.PermissionSystem)
        del self.env.parent.enabled[perm.PermissionSystem]
        del self.env.enabled[perm.PermissionSystem]

        sudoperm = sudo(None, 'TEST_CREATE', ['TRAC_ADMIN'])
        sudoperm.perm = self.perm

        self.assertTrue(sudoperm.has_permission('EMAIL_VIEW'))

    def test_sudo_ambiguous(self):
        with self.assertRaises(ValueError) as test_cm:
            sudo(None, 'TEST_MODIFY', ['TEST_MODIFY', 'TEST_DELETE'],
                 ['TEST_MODIFY', 'TEST_CREATE'])
        self.assertEquals('Impossible to grant and revoke (TEST_MODIFY)',
                          str(test_cm.exception))

        with self.assertRaises(ValueError) as test_cm:
            sudoperm = sudo(None, 'TEST_MODIFY', ['TEST_ADMIN'],
                 ['TEST_MODIFY', 'TEST_CREATE'])
            sudoperm.perm = self.perm
        self.assertEquals('Impossible to grant and revoke '
                          '(TEST_CREATE, TEST_MODIFY)',
                          str(test_cm.exception))

        with self.assertRaises(ValueError) as test_cm:
            req = Mock(perm=self.perm)
            sudo(req, 'TEST_MODIFY', ['TEST_ADMIN'],
                 ['TEST_MODIFY', 'TEST_CREATE'])
        self.assertEquals('Impossible to grant and revoke '
                          '(TEST_CREATE, TEST_MODIFY)',
                          str(test_cm.exception))

    # Sudo permission context equivalent to  permissions cache
    # if there's no action to require, allow or deny.
    def _test_with_sudo_rules(tcnm, prefix, grant):
        target = getattr(ProductPermissionCacheTestCase, tcnm)

        def _sudo_eq_checker(self):
            for action in grant:
                self.perm_system.revoke_permission('testuser', action)
            realperm = self.perm
            self.perm = sudo(None, [], grant, [])
            self.perm.perm = realperm
            target(self)

        _sudo_eq_checker.func_name = prefix + tcnm
        return _sudo_eq_checker

    for tcnm in tcnames:
        f1 = _test_with_sudo_rules(tcnm, '', [])
        f2 = _test_with_sudo_rules(tcnm, 'test_sudo_partial_',
                                   ['TEST_MODIFY'])
        f3 = _test_with_sudo_rules(tcnm, 'test_sudo_full_',
                                   ['TEST_MODIFY', 'TEST_ADMIN'])
        for f in (f1, f2, f3):
            _gen_tests[f.func_name] = f

    del loader, tcnames, tcnm, f1, f2, f3

list(setattr(SudoTestCase, tcnm, f)
     for tcnm, f in SudoTestCase._gen_tests.iteritems())


class ProductPermissionPolicyTestCase(PermissionPolicyTestCase,
                                           MultiproductTestCase):
    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(enable=[
                    perm.DefaultPermissionStore,
                    perm.DefaultPermissionPolicy,
                    perm.PermissionSystem,
                    TestPermissionPolicy,
                    TestPermissionRequestor,
                    MultiproductPermissionPolicy])
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def setUp(self):
        super(ProductPermissionPolicyTestCase, self).setUp()

        self.global_env.config.set('trac', 'permission_policies',
                                   'DefaultPermissionPolicy')
        self.permsys = perm.PermissionSystem(self.env)
        self.global_perm_admin = perm.PermissionAdmin(self.global_env)
        self.product_perm_admin = perm.PermissionAdmin(self.env)

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self.env = None

    def test_prepend_mp_policy(self):
        self.assertEqual([MultiproductPermissionPolicy(self.env), self.policy],
                         self.permsys.policies)

    def test_policy_chaining(self):
        self.env.config.set('trac', 'permission_policies',
                            'TestPermissionPolicy,DefaultPermissionPolicy')
        self.policy.grant('testuser', ['TEST_MODIFY'])
        system = perm.PermissionSystem(self.env)
        system.grant_permission('testuser', 'TEST_ADMIN')

        self.assertEqual(list(system.policies),
                         [MultiproductPermissionPolicy(self.env),
                          self.policy,
                          perm.DefaultPermissionPolicy(self.env)])
        self.assertEqual('TEST_MODIFY' in self.perm, True)
        self.assertEqual('TEST_ADMIN' in self.perm, True)
        self.assertEqual(self.policy.results,
                         {('testuser', 'TEST_MODIFY'): True,
                          ('testuser', 'TEST_ADMIN'): None})

    def test_product_trac_admin_success(self):
        """TRAC_ADMIN in global env also valid in product env
        """
        self.global_perm_admin._do_add('testuser', 'TRAC_ADMIN')
        self.assertTrue(self.perm.has_permission('TRAC_ADMIN'))

    def test_product_trac_admin_actions(self):
        """Allow all actions in product scope for TRAC_ADMIN
        """
        self.global_perm_admin._do_add('testuser', 'TRAC_ADMIN')

        all_actions = self.permsys.get_actions()
        self.assertEquals(['TEST_CREATE', 'EMAIL_VIEW', 'TRAC_ADMIN',
                           'TEST_DELETE', 'TEST_MODIFY', 'PRODUCT_ADMIN',
                           'TEST_ADMIN'], all_actions)
        self.assertEquals({}, self.permsys.get_user_permissions('testuser'))
        for action in all_actions:
            self.assertTrue(self.perm.has_permission(action),
                            'Check for permission action %s' % (action,))
        self.assertFalse(self.perm.has_permission('UNKNOWN_PERM'))

        # Clear permissions cache and retry
        self.perm._cache.clear()
        self.global_perm_admin._do_remove('testuser', 'TRAC_ADMIN')

        all_actions = self.permsys.get_actions()
        self.assertEquals(['TEST_CREATE', 'EMAIL_VIEW', 'TRAC_ADMIN',
                           'TEST_DELETE', 'TEST_MODIFY', 'PRODUCT_ADMIN',
                           'TEST_ADMIN'], all_actions)
        self.assertEquals({}, self.permsys.get_user_permissions('testuser'))
        for action in all_actions:
            self.assertFalse(self.perm.has_permission(action),
                            'Check for permission action %s' % (action,))

    def test_product_trac_admin_fail_local(self):
        """TRAC_ADMIN granted in product env will be ignored
        """
        try:
            # Not needed but added just in case , also for readability
            self.global_perm_admin._do_remove('testuser', 'TRAC_ADMIN')
        except AdminCommandError:
            pass

        # Setting TRAC_ADMIN permission in product scope is in vain
        # since it controls access to critical actions affecting the whole site
        # This will protect the system against malicious actors
        # and / or failures leading to the addition of TRAC_ADMIN permission
        # in product perm store in spite of obtaining unrighteous super powers.
        # On the other hand this also means that PRODUCT_ADMIN(s) are
        # able to set user permissions at will without jeopardizing system
        # integrity and stability.
        self.product_perm_admin._do_add('testuser', 'TRAC_ADMIN')
        self.assertFalse(self.perm.has_permission('TRAC_ADMIN'))

    def test_product_owner_perm(self):
        """Product owner automatically granted with PRODUCT_ADMIN
        """
        self.assertIs(self.env.product.owner, None)
        self.assertFalse(self.perm.has_permission('PRODUCT_ADMIN'))

        self.env.product.owner = 'testuser'
        # FIXME: update really needed ?
        self.env.product.update()
        try:
            # Not needed but added just in case , also for readability
            self.global_perm_admin._do_remove('testuser', 'TRAC_ADMIN')
        except AdminCommandError:
            pass
        self.perm._cache.clear()

        self.assertTrue(self.perm.has_permission('PRODUCT_ADMIN'))
        self.assertFalse(self.perm.has_permission('TRAC_ADMIN'))

    def test_new_product_perm(self):
        """Only product owner and TRAC_ADMIN will access new product
        """
        newproduct = Product(self.global_env)
        newproduct.prefix = 'NEW'
        newproduct.name = 'New product'
        newproduct.owner = 'owneruser'
        newproduct.insert()

        env = ProductEnvironment(self.global_env, newproduct)
        self.global_perm_admin._do_add('adminuser', 'TRAC_ADMIN')
        admin_perm = perm.PermissionCache(env, 'adminuser')
        owner_perm = perm.PermissionCache(env, 'owneruser')
        user_perm = perm.PermissionCache(env, 'testuser')
        global_permsys = perm.PermissionSystem(self.global_env)
        permsys = perm.PermissionSystem(env)

        self.assertEquals({'EMAIL_VIEW': True, 'TEST_ADMIN': True,
                           'TEST_CREATE': True, 'TEST_DELETE': True,
                           'TEST_MODIFY': True, 'TRAC_ADMIN' : True},
                          global_permsys.get_user_permissions('adminuser'))
        self.assertEquals({}, global_permsys.get_user_permissions('owneruser'))
        self.assertEquals({}, global_permsys.get_user_permissions('testuser'))
        self.assertEquals({}, permsys.get_user_permissions('adminuser'))
        self.assertEquals({}, permsys.get_user_permissions('owneruser'))
        self.assertEquals({}, permsys.get_user_permissions('testuser'))

        all_actions = self.permsys.get_actions()
        all_actions.remove('TRAC_ADMIN')
        for action in all_actions:
            self.assertTrue(admin_perm.has_permission(action))
            self.assertTrue(owner_perm.has_permission(action))
            self.assertFalse(user_perm.has_permission(action))

        self.assertTrue(admin_perm.has_permission('TRAC_ADMIN'))
        self.assertFalse(owner_perm.has_permission('TRAC_ADMIN'))
        self.assertFalse(user_perm.has_permission('TRAC_ADMIN'))


def test_suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(ProductDefaultPermissionStoreTestCase,
                                     'test'))
    suite.addTest(unittest.makeSuite(ProductPermissionSystemTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ProductPermissionCacheTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ProductNeighborhoodPermissionCacheTestCase,
                                     'test'))
    suite.addTest(unittest.makeSuite(ProductPermissionPolicyTestCase, 'test'))

    suite.addTest(unittest.makeSuite(SudoTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = resource
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import os.path
import shutil
import tempfile
import unittest
from StringIO import StringIO
from datetime import datetime

import trac.ticket.api
import trac.ticket.report
import trac.ticket.roadmap
import trac.wiki.api
from trac import resource
from trac.attachment import Attachment
from trac.ticket.model import Ticket
from trac.util.datefmt import utc
from trac.wiki.model import WikiPage

from multiproduct.api import MultiProductSystem
from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase


class ProductResourceTestCase(MultiproductTestCase):
    def setUp(self):
        self._mp_setup()
        self.global_env = self.env
        self._load_product_from_data(self.global_env, u'x')

        self.env = ProductEnvironment(self.global_env, self.default_product)
        self.env1 = ProductEnvironment(self.global_env, u'x')

        self._load_default_data(self.global_env)
        self._load_default_data(self.env1)

        # Enable product system component in product context
        self.env.enable_component(MultiProductSystem)

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self.env = None


class ProductAttachmentResourceTestCase(ProductResourceTestCase):
    def setUp(self):
        ProductResourceTestCase.setUp(self)
        self.global_env.path = os.path.join(tempfile.gettempdir(),
                                            'trac-tempenv')
        if os.path.exists(self.global_env.path):
            shutil.rmtree(self.global_env.path)
        os.mkdir(self.global_env.path)

        attachment = Attachment(self.global_env, 'ticket', 1)
        attachment.description = 'Global Bar'
        attachment.insert('foo.txt', StringIO(''), 0)

        attachment = Attachment(self.env1, 'ticket', 1)
        attachment.description = 'Product Bar'
        attachment.insert('foo.txt', StringIO(''), 0)
        self.resource = resource.Resource('ticket',
                                          1).child('attachment', 'foo.txt')

    def tearDown(self):
        shutil.rmtree(self.global_env.path)
        ProductResourceTestCase.tearDown(self)

    def test_global_neighborhood_attachments(self):
        target = resource.Neighborhood('global', None).child(self.resource)

        self.assertEquals("[global:] Attachment 'foo.txt' in [global:] Ticket #1",
                          resource.get_resource_description(self.env, target))
        self.assertEquals("[global:] Attachment 'foo.txt' in [global:] Ticket #1",
                          resource.get_resource_name(self.env, target))
        self.assertEquals("[global:] foo.txt ([global:] Ticket #1)",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals('Global Bar',
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/attachment/ticket/1/foo.txt',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))

    def test_product_neighborhood_attachments(self):
        target = resource.Neighborhood('product', u'x').child(self.resource)

        self.assertEquals(u"[product:x] Attachment 'foo.txt' in [product:x] Ticket #1",
                          resource.get_resource_description(self.env, target))
        self.assertEquals(u"[product:x] Attachment 'foo.txt' in [product:x] Ticket #1",
                          resource.get_resource_name(self.env, target))
        self.assertEquals(u"[product:x] foo.txt ([product:x] Ticket #1)",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals('Product Bar',
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/products/x%C3%BC/attachment/ticket/1/foo.txt',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))


class ProductMilestoneResourceTestCase(ProductResourceTestCase):
    resource = resource.Resource('milestone', 'milestone1')

    def test_global_neighborhood_milestone(self):
        target = resource.Neighborhood('global', None).child(self.resource)

        self.assertEquals("[global:] Milestone milestone1",
                          resource.get_resource_description(self.env, target))
        self.assertEquals("[global:] Milestone milestone1",
                          resource.get_resource_name(self.env, target))
        self.assertEquals("milestone1",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals("[global:] Milestone milestone1",
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/milestone/milestone1',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))

    def test_product_neighborhood_milestone(self):
        target = resource.Neighborhood('product', u'x').child(self.resource)

        self.assertEquals(u"[product:x] Milestone milestone1",
                          resource.get_resource_description(self.env, target))
        self.assertEquals(u"[product:x] Milestone milestone1",
                          resource.get_resource_name(self.env, target))
        self.assertEquals(u"milestone1",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals(u"[product:x] Milestone milestone1",
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/products/x%C3%BC/milestone/milestone1',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))


# FIXME: No resource manager for reports in core ?
class ProductReportResourceTestCase(ProductResourceTestCase):
    resource = resource.Resource('report', 1)

    def test_global_neighborhood_report(self):
        target = resource.Neighborhood('global', None).child(self.resource)

        self.assertEquals("[global:] report:1",
                          resource.get_resource_description(self.env, target))
        self.assertEquals("[global:] report:1",
                          resource.get_resource_name(self.env, target))
        self.assertEquals("[global:] report:1",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals('[global:] report:1 at version None',
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/report/1',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))

    def test_product_neighborhood_report(self):
        target = resource.Neighborhood('product', u'x').child(self.resource)

        self.assertEquals(u"[product:x] report:1",
                          resource.get_resource_description(self.env, target))
        self.assertEquals(u"[product:x] report:1",
                          resource.get_resource_name(self.env, target))
        self.assertEquals(u"[product:x] report:1",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals(u"[product:x] report:1 at version None",
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/products/x%C3%BC/report/1',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))


class ProductTicketResourceTestCase(ProductResourceTestCase):
    def _new_ticket(self, env, ticket_dict):
        ticket = Ticket(env)
        ticket.populate(ticket_dict)
        return ticket.insert()

    def setUp(self):
        ProductResourceTestCase.setUp(self)

    def test_global_neighborhood_ticket(self):
        nbh = resource.Neighborhood('global', None)
        data = dict(summary='Ticket summary', description='Ticket description',
                    type='enhancement', status='new')
        target = nbh.child('ticket', self._new_ticket(self.global_env, data))

        self.assertEquals("[global:] Ticket #1",
                          resource.get_resource_description(self.env, target))
        self.assertEquals("[global:] Ticket #1",
                          resource.get_resource_name(self.env, target))
        self.assertEquals("[global:] #1",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals('enhancement: Ticket summary (new)',
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/ticket/1',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))

    def test_product_neighborhood_ticket(self):
        nbh = resource.Neighborhood('product', u'x')
        data = dict(summary='Ticket summary', description='Ticket description',
                    type='task', status='accepted')
        target = nbh.child('ticket', self._new_ticket(self.env1, data))

        self.assertEquals(u"[product:x] Ticket #1",
                          resource.get_resource_description(self.env, target))
        self.assertEquals(u"[product:x] Ticket #1",
                          resource.get_resource_name(self.env, target))
        self.assertEquals(u"[product:x] #1",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals(u"task: Ticket summary (accepted)",
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/products/x%C3%BC/ticket/1',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))


class ProductWikiResourceTestCase(ProductResourceTestCase):
    resource = resource.Resource('wiki', 'TestPage', version=2)

    def setUp(self):
        ProductResourceTestCase.setUp(self)

        page = WikiPage(self.global_env)
        page.name = 'TestPage'
        page.text = 'Bla bla'
        t = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        page.save('joe', 'Testing global', '::1', t)
        page.text = 'Bla bla bla'
        t = datetime(2002, 2, 2, 2, 2, 2, 0, utc)
        page.save('joe', 'Testing global 2', '::1', t)

        page = WikiPage(self.env1)
        page.name = 'TestPage'
        page.text = 'alb alB'
        t = datetime(2011, 1, 1, 1, 1, 1, 0, utc)
        page.save('mary', 'Testing product', '::1', t)
        page.text = 'Bla bla bla'
        t = datetime(2012, 2, 2, 2, 2, 2, 0, utc)
        page.save('mary', 'Testing product 2', '::1', t)

    def test_global_neighborhood_wiki(self):
        target = resource.Neighborhood('global', None).child(self.resource)

        self.assertEquals("TestPage",
                          resource.get_resource_description(self.env, target))
        self.assertEquals("TestPage",
                          resource.get_resource_name(self.env, target))
        self.assertEquals("TestPage",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals("TestPage",
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/wiki/TestPage?version=2',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))

    def test_product_neighborhood_wiki(self):
        target = resource.Neighborhood('product', u'x').child(self.resource)

        self.assertEquals(u"TestPage",
                          resource.get_resource_description(self.env, target))
        self.assertEquals(u"TestPage",
                          resource.get_resource_name(self.env, target))
        self.assertEquals(u"TestPage",
                          resource.get_resource_shortname(self.env, target))
        self.assertEquals(u"TestPage",
                          resource.get_resource_summary(self.env, target))
        self.assertEquals('http://example.org/trac.cgi/products/x%C3%BC/wiki/TestPage?version=2',
                          resource.get_resource_url(self.env,
                                                    target, self.env.href))


class NeighborhoodTestCase(MultiproductTestCase):
    def setUp(self):
        self._mp_setup()

    def test_get_known_neighborhoods(self):
        rsys = resource.ResourceSystem(self.env)
        self.assertEquals(['global', 'product'],
                          sorted(rsys.get_known_neighborhoods()))


def test_suite():
    return unittest.TestSuite([
        unittest.makeSuite(ProductAttachmentResourceTestCase, 'test'),
        unittest.makeSuite(ProductMilestoneResourceTestCase, 'test'),
        unittest.makeSuite(ProductReportResourceTestCase, 'test'),
        unittest.makeSuite(ProductTicketResourceTestCase, 'test'),
        unittest.makeSuite(ProductWikiResourceTestCase, 'test'),
        unittest.makeSuite(NeighborhoodTestCase, 'test'),
    ])


if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's tickets API in product environments"""

import unittest

from trac.perm import PermissionCache, PermissionSystem
from trac.test import Mock
from trac.ticket.api import TicketSystem
from trac.ticket.tests.api import TicketSystemTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductTicketSystemTestCase(TicketSystemTestCase, MultiproductTestCase):

    def setUp(self):
        self.global_env = self._setup_test_env(create_folder=False)
        self._upgrade_mp(self.global_env)
        self._setup_test_log(self.global_env)
        self._load_product_from_data(self.global_env, self.default_product)
        self.env = ProductEnvironment(self.global_env, self.default_product)

        self.perm = PermissionSystem(self.env)
        self.ticket_system = TicketSystem(self.env)
        self.req = Mock()

    def tearDown(self):
        self.global_env.reset_db()

    def test_custom_field_isolation(self):
        self.env.config.set('ticket-custom', 'test', 'select')
        self.env.config.set('ticket-custom', 'test.label', 'Test')
        self.env.config.set('ticket-custom', 'test.value', '1')
        self.env.config.set('ticket-custom', 'test.options', 'option1|option2')

        self.global_env.config.set('ticket-custom', 'test', 'text')
        self.global_env.config.set('ticket-custom', 'test.label', 'Test')
        self.global_env.config.set('ticket-custom', 'test.value', 'Foo bar')
        self.global_env.config.set('ticket-custom', 'test.format', 'wiki')

        product_fields = TicketSystem(self.env).get_custom_fields()
        global_fields = TicketSystem(self.global_env).get_custom_fields()

        self.assertEqual({'name': 'test', 'type': 'select', 'label': 'Test',
                          'value': '1', 'options': ['option1', 'option2'],
                          'order': 0},
                         product_fields[0])
        self.assertEqual({'name': 'test', 'type': 'text', 'label': 'Test',
                          'value': 'Foo bar', 'order': 0, 'format': 'wiki'},
                         global_fields[0])

    def test_available_actions_isolation(self):
        # Grant TICKET_CREATE in product environment ...
        self.perm.grant_permission('anonymous', 'TICKET_CREATE')
        self.req.perm = PermissionCache(self.env)
        self.assertEqual(['leave', 'reopen'],
                         self._get_actions({'status': 'closed'}))

        # ... but no perms in global environment
        self.req.perm = PermissionCache(self.global_env)
        product_env = self.env
        try:
            self.env = self.global_env
            self.assertEqual(['leave'], self._get_actions({'status': 'closed'}))
        finally:
            self.env = product_env

def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductTicketSystemTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = batch
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's tickets batch updates
in product environments"""

import unittest

from trac.perm import PermissionCache
from trac.test import Mock
from trac.ticket.batch import BatchModifyModule
from trac.ticket.tests.batch import BatchModifyTestCase
from trac.ticket.default_workflow import ConfigurableTicketWorkflow
from trac.util.datefmt import utc

from multiproduct.env import ProductEnvironment
from multiproduct.ticket.web_ui import ProductTicketModule
from tests.env import MultiproductTestCase

class ProductBatchModifyTestCase(BatchModifyTestCase, MultiproductTestCase):

    def setUp(self):
        self.global_env = self._setup_test_env(create_folder=False)
        self._upgrade_mp(self.global_env)
        self._setup_test_log(self.global_env)
        self._load_product_from_data(self.global_env, self.default_product)
        self.env = ProductEnvironment(self.global_env, self.default_product)

        self.global_env.enable_component_in_config(self.env,
                ConfigurableTicketWorkflow)
        self.global_env.enable_component_in_config(self.env,
                ProductTicketModule)

        self._load_default_data(self.env)

        self.req = Mock(href=self.env.href, authname='anonymous', tz=utc)
        self.req.session = {}
        self.req.perm = PermissionCache(self.env)

    def tearDown(self):
        self.global_env.reset_db()


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductBatchModifyTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = conversion
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's MIME conversions for tickets in
product environments"""

import os.path
import unittest

from trac.test import Mock
from trac.mimeview.api import Mimeview
from trac.ticket.tests.conversion import TicketConversionTestCase
from trac.web.href import Href

from multiproduct.ticket.web_ui import ProductTicketModule
from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductTicketConversionTestCase(TicketConversionTestCase, \
        MultiproductTestCase):

    def setUp(self):
        self._mp_setup()
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)

        # Product name inserted in RSS feed
        self.env.product._data['name'] = 'My Project'

        self.env.config.set('trac', 'templates_dir',
                            os.path.join(os.path.dirname(self.env.path),
                                         'templates'))
        self.ticket_module = ProductTicketModule(self.env)
        self.mimeview = Mimeview(self.env)
        self.req = Mock(base_path='/trac.cgi', path_info='',
                        href=Href('/trac.cgi'), chrome={'logo': {}},
                        abs_href=Href('http://example.org/trac.cgi'),
                        environ={}, perm=[], authname='-', args={}, tz=None,
                        locale='', session=None, form_token=None)

    def test_csv_conversion(self):
        ticket = self._create_a_ticket()
        csv = self.mimeview.convert_content(self.req, 'trac.ticket.Ticket',
                                            ticket, 'csv')
        self.assertEqual(('\xef\xbb\xbf'
                          'id,summary,reporter,owner,description,status,'
                          'product,keywords,cc\r'
                          '\n1,Foo,santa,,Bar,,,,\r\n',
                          'text/csv;charset=utf-8', 'csv'), csv)

    def test_tab_conversion(self):
        ticket = self._create_a_ticket()
        csv = self.mimeview.convert_content(self.req, 'trac.ticket.Ticket',
                                            ticket, 'tab')
        self.assertEqual(('\xef\xbb\xbf'
                          'id\tsummary\treporter\towner\tdescription\tstatus\t'
                          'product\tkeywords\tcc\r\n'
                          '1\tFoo\tsanta\t\tBar\t\t\t\t\r\n',
                          'text/tab-separated-values;charset=utf-8', 'tsv'),
                         csv)

    def tearDown(self):
        self.global_env.reset_db()

def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductTicketConversionTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = model
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's tickets model in product environments"""

from datetime import datetime
import shutil
import unittest

from trac.ticket.model import Milestone, Ticket
from trac.ticket.tests.model import TicketTestCase, TicketCommentTestCase, \
        TicketCommentEditTestCase, TicketCommentDeleteTestCase, EnumTestCase, \
        MilestoneTestCase, ComponentTestCase, VersionTestCase
from trac.util.datefmt import to_utimestamp, utc

from multiproduct.model import Product
from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductTicketTestCase(TicketTestCase, MultiproductTestCase):

    def setUp(self):
        self._mp_setup()
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)
        self._load_default_data(self.env)

        self.env.config.set('ticket-custom', 'foo', 'text')
        self.env.config.set('ticket-custom', 'cbon', 'checkbox')
        self.env.config.set('ticket-custom', 'cboff', 'checkbox')

    def tearDown(self):
        self.global_env.reset_db()
        self.env = self.global_env = None

    def _get_ticket_uid(self, tid):
        with self.env.db_query as db:
            rows = db("""SELECT uid FROM ticket WHERE id=%s""", (tid, ))
            return rows[0][0] if rows else -1

    def test_insert_into_multiple_products(self):
        # UIDs are global, autoincremented
        # IDs are product-scoped, incremented in the SQL translator
        self.env = ProductEnvironment(self.global_env, self.default_product)

        tid = self._insert_ticket('hello kitty', reporter='admin')
        ticket = Ticket(self.env, tid)
        self.assertEqual(tid, 1)
        self.assertEqual(self._get_ticket_uid(tid), 1)
        self.assertEqual(ticket.id, tid)
        tid = self._insert_ticket('hello kitteh', reporter='admin')
        ticket = Ticket(self.env, tid)
        self.assertEqual(tid, 2)
        self.assertEqual(self._get_ticket_uid(tid), 2)
        self.assertEqual(ticket.id, tid)

        p2 = Product(self.global_env)
        p2.prefix = 'p2'
        p2.name = 'product, too'
        p2.owner = 'admin'
        p2.insert()
        self.env = ProductEnvironment(self.global_env, p2)

        tid = self._insert_ticket('hello catty', reporter='admin')
        ticket = Ticket(self.env, tid)
        self.assertEqual(tid, 1)
        self.assertEqual(self._get_ticket_uid(tid), 3)
        self.assertEqual(ticket.id, tid)
        tid = self._insert_ticket('hello ocelot', reporter='admin')
        ticket = Ticket(self.env, tid)
        self.assertEqual(tid, 2)
        self.assertEqual(self._get_ticket_uid(tid), 4)
        self.assertEqual(ticket.id, tid)


class ProductTicketCommentTestCase(MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
            self._load_default_data(env)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self._env = self.global_env = None

class ProductTicketCommentEditTestCase(TicketCommentEditTestCase,
        ProductTicketCommentTestCase):
    pass

class ProductTicketCommentDeleteTestCase(TicketCommentDeleteTestCase,
        ProductTicketCommentTestCase):
    pass

class ProductEnumTestCase(EnumTestCase, MultiproductTestCase):
    def setUp(self):
        self._mp_setup()
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)
        self._load_default_data(self.env)

    def tearDown(self):
        self.global_env.reset_db()
        self.env = self.global_env = None

class ProductMilestoneTestCase(MilestoneTestCase, MultiproductTestCase):
    def setUp(self):
        self.global_env = self._setup_test_env(create_folder=True)
        self._upgrade_mp(self.global_env)
        self._setup_test_log(self.global_env)
        self._load_product_from_data(self.global_env, self.default_product)

        self.env = ProductEnvironment(self.global_env, self.default_product)
        self._load_default_data(self.env)

    def tearDown(self):
        shutil.rmtree(self.global_env.path)
        self.global_env.reset_db()
        self.env = self.global_env = None

    def test_update_milestone(self):

        self.env.db_transaction("INSERT INTO milestone (name) VALUES ('Test')")

        milestone = Milestone(self.env, 'Test')
        t1 = datetime(2001, 01, 01, tzinfo=utc)
        t2 = datetime(2002, 02, 02, tzinfo=utc)
        milestone.due = t1
        milestone.completed = t2
        milestone.description = 'Foo bar'
        milestone.update()

        self.assertEqual(
            [('Test', to_utimestamp(t1), to_utimestamp(t2), 'Foo bar',
                    self.default_product)],
            self.env.db_query("SELECT * FROM milestone WHERE name='Test'"))

class ProductComponentTestCase(ComponentTestCase, MultiproductTestCase):
    def setUp(self):
        self._mp_setup()
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)
        self._load_default_data(self.env)

    def tearDown(self):
        self.global_env.reset_db()
        self.env = self.global_env = None

class ProductVersionTestCase(VersionTestCase, MultiproductTestCase):
    def setUp(self):
        self._mp_setup()
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)
        self._load_default_data(self.env)

    def tearDown(self):
        self.global_env.reset_db()
        self.env = self.global_env = None


def test_suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(ProductTicketTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ProductTicketCommentEditTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ProductTicketCommentDeleteTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ProductEnumTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ProductMilestoneTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ProductComponentTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ProductVersionTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = notification
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's tickets notifications
in product environments"""

import unittest

from trac.tests.notification import SMTPThreadedServer
from trac.ticket.tests import notification

from tests.env import ProductEnvironmentStub as ProductEnvironment
from tests.env import MultiproductTestCase

class ProductNotificationTestCase(notification.NotificationTestCase,
        MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
            self._load_default_data(self._env)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        notification.notifysuite.tear_down()
        self.global_env.reset_db()

class ProductNotificationTestSuite(notification.NotificationTestSuite):
    def __init__(self):
        """Start the local SMTP test server"""
        notification.NotificationTestSuite.__init__(self)
        self._tests = []
        self.addTest(unittest.makeSuite(ProductNotificationTestCase, 'test'))


def test_suite():
    if not notification.notifysuite:
        notification.notifysuite = ProductNotificationTestSuite()
    return notification.notifysuite

if __name__ == '__main__':
    unittest.TextTestRunner(verbosity=2).run(test_suite())

########NEW FILE########
__FILENAME__ = query
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's ticket queries in product environments"""

import unittest

from trac.ticket.query import Query
from trac.ticket.tests.query import QueryTestCase, QueryLinksTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductQueryTestCase(QueryTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
            self._load_default_data(env)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None

    def test_all_grouped_by_milestone(self):
        query = Query(self.env, order='id', group='milestone')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
  LEFT OUTER JOIN milestone ON (milestone.name=milestone)
ORDER BY COALESCE(t.milestone,'')='',COALESCE(milestone.completed,0)=0,milestone.completed,COALESCE(milestone.due,0)=0,milestone.due,t.milestone,COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_grouped_by_milestone_desc(self):
        query = Query(self.env, order='id', group='milestone', groupdesc=1)
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
  LEFT OUTER JOIN milestone ON (milestone.name=milestone)
ORDER BY COALESCE(t.milestone,'')='' DESC,COALESCE(milestone.completed,0)=0 DESC,milestone.completed DESC,COALESCE(milestone.due,0)=0 DESC,milestone.due DESC,t.milestone DESC,COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_id(self):
        query = Query(self.env, order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_id_desc(self):
        query = Query(self.env, order='id', desc=1)
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0 DESC,t.id DESC""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_id_from_unicode(self):
        query = Query.from_string(self.env, u'order=id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_id_verbose(self):
        query = Query(self.env, order='id', verbose=1)
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.reporter AS reporter,t.description AS description,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_priority(self):
        query = Query(self.env) # priority is default order
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(priority.value,'')='',%(cast_priority)s,t.id""" % {
          'cast_priority': self.env.get_read_db().cast('priority.value', 'int')})
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_priority_desc(self):
        query = Query(self.env, desc=1) # priority is default order
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(priority.value,'')='' DESC,%(cast_priority)s DESC,t.id""" % {
          'cast_priority': self.env.get_read_db().cast('priority.value', 'int')})
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_custom_field(self):
        self.env.config.set('ticket-custom', 'foo', 'text')
        query = Query.from_string(self.env, 'foo=something', order='id')
        sql, args = query.get_sql()
        foo = self.env.get_read_db().quote('foo')
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value,%s.value AS %s
FROM ticket AS t
  LEFT OUTER JOIN ticket_custom AS %s ON (id=%s.ticket AND %s.name='foo')
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(%s.value,'')=%%s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % ((foo,) * 6))
        self.assertEqual(['something'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_empty_value_contains(self):
        query = Query.from_string(self.env, 'owner~=|', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_empty_value_endswith(self):
        query = Query.from_string(self.env, 'owner$=|', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_empty_value_startswith(self):
        query = Query.from_string(self.env, 'owner^=|', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_milestone(self):
        query = Query.from_string(self.env, 'milestone=milestone1', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,t.milestone AS milestone,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.milestone,'')=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['milestone1'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_milestone_or_version(self):
        query = Query.from_string(self.env, 'milestone=milestone1&or&version=version1', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,t.version AS version,t.milestone AS milestone,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.milestone,'')=%s)) OR ((COALESCE(t.version,'')=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['milestone1', 'version1'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_multiple_owners(self):
        query = Query.from_string(self.env, 'owner=someone|someone_else',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (COALESCE(t.owner,'') IN (%s,%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['someone', 'someone_else'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_multiple_owners_contain(self):
        query = Query.from_string(self.env, 'owner~=someone|someone_else',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqual(['%someone%', '%someone/_else%'], args)
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') %(like)s OR COALESCE(t.owner,'') %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        tickets = query.execute(self.req)

    def test_constrained_by_multiple_owners_not(self):
        query = Query.from_string(self.env, 'owner!=someone|someone_else',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (COALESCE(t.owner,'') NOT IN (%s,%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['someone', 'someone_else'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_owner_beginswith(self):
        query = Query.from_string(self.env, 'owner^=someone', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['someone%'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_owner_containing(self):
        query = Query.from_string(self.env, 'owner~=someone', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['%someone%'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_owner_endswith(self):
        query = Query.from_string(self.env, 'owner$=someone', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['%someone'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_owner_not_containing(self):
        query = Query.from_string(self.env, 'owner!~=someone', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') NOT %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['%someone%'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_status(self):
        query = Query.from_string(self.env, 'status=new|assigned|reopened',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.status AS status,t.owner AS owner,t.type AS type,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (COALESCE(t.status,'') IN (%s,%s,%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['new', 'assigned', 'reopened'], args)
        tickets = query.execute(self.req)

    def test_equal_in_value(self):
        query = Query.from_string(self.env, r'status=this=that&version=version1',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.priority AS priority,t.product AS product,t.milestone AS milestone,t.status AS status,t.time AS time,t.changetime AS changetime,t.version AS version,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.status,'')=%s) AND (COALESCE(t.version,'')=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['this=that', 'version1'], args)
        tickets = query.execute(self.req)

    def test_grouped_by_custom_field(self):
        self.env.config.set('ticket-custom', 'foo', 'text')
        query = Query(self.env, group='foo', order='id')
        sql, args = query.get_sql()
        foo = self.env.get_read_db().quote('foo')
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value,%s.value AS %s
FROM ticket AS t
  LEFT OUTER JOIN ticket_custom AS %s ON (id=%s.ticket AND %s.name='foo')
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(%s.value,'')='',%s.value,COALESCE(t.id,0)=0,t.id""" %
        ((foo,) * 7))
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_grouped_by_priority(self):
        query = Query(self.env, group='priority')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.product AS product,t.milestone AS milestone,t.priority AS priority,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(priority.value,'')='',%(cast_priority)s,t.id""" % {
          'cast_priority': self.env.get_read_db().cast('priority.value', 'int')})
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_special_character_escape(self):
        query = Query.from_string(self.env, r'status=here\&now|maybe\|later|back\slash',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.status AS status,t.owner AS owner,t.type AS type,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (COALESCE(t.status,'') IN (%s,%s,%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['here&now', 'maybe|later', 'back\\slash'], args)
        tickets = query.execute(self.req)

    def test_user_var(self):
        query = Query.from_string(self.env, 'owner=$USER&order=id')
        sql, args = query.get_sql(req=self.req)
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.product AS product,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'')=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['anonymous'], args)
        tickets = query.execute(self.req)


class ProductQueryLinksTestCase(QueryLinksTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
            self._load_default_data(env)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductQueryTestCase,'test'),
            unittest.makeSuite(ProductQueryLinksTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = report
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's ticket reports in product environments"""

import unittest

from trac.ticket.tests.report import ReportTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductReportTestCase(ReportTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None


def test_suite():
    return unittest.TestSuite([
            # TODO : Put report doctests in product context
            # doctest.DocTestSuite(trac.ticket.report,)
            unittest.makeSuite(ProductReportTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = roadmap
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's roadmap in product environments"""

import unittest

from trac.ticket.tests.roadmap import DefaultTicketGroupStatsProviderTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductDefaultTicketGroupStatsProviderTestCase(
        DefaultTicketGroupStatsProviderTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(create_folder=False)
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
            self._load_default_data(env)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self.env = None


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductDefaultTicketGroupStatsProviderTestCase,
                    'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = wikisyntax
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for inherited Apache(TM) Bloodhound ticket wiki syntax
in product environments"""

import os.path
import re
import unittest

from trac.ticket.tests import wikisyntax

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase
from tests.wiki import formatter

def test_suite():
    suite = unittest.TestSuite()
    suite.addTest(formatter.test_suite(wikisyntax.TICKET_TEST_CASES,
                                       wikisyntax.ticket_setup,
                                       wikisyntax.__file__,
                                       wikisyntax.ticket_teardown))
    suite.addTest(formatter.test_suite(wikisyntax.REPORT_TEST_CASES,
                                       wikisyntax.report_setup,
                                       wikisyntax.__file__))
    suite.addTest(formatter.test_suite(wikisyntax.MILESTONE_TEST_CASES,
                                       wikisyntax.milestone_setup,
                                       wikisyntax.__file__,
                                       wikisyntax.milestone_teardown))
    suite.addTest(formatter.test_suite(wikisyntax.QUERY_TEST_CASES,
                                       wikisyntax.ticket_setup,
                                       wikisyntax.__file__,
                                       wikisyntax.ticket_teardown))
    suite.addTest(formatter.test_suite(wikisyntax.QUERY2_TEST_CASES,
                                       wikisyntax.query2_setup,
                                       wikisyntax.__file__,
                                       wikisyntax.query2_teardown))
    suite.addTest(formatter.test_suite(wikisyntax.COMMENT_TEST_CASES,
                                       file=wikisyntax.__file__))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = upgrade
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import os
import shutil
import tempfile
import uuid
from contextlib import contextmanager
from tests import unittest

from trac.attachment import Attachment, AttachmentAdmin
from trac.core import Component, implements
from trac.db import DatabaseManager
from trac.db.schema import Table, Column
from trac.env import IEnvironmentSetupParticipant
from trac.test import Environment
from trac.ticket import Ticket
from trac.wiki import WikiPage

from multiproduct.api import MultiProductSystem
from multiproduct.env import ProductEnvironment
from multiproduct.model import Product

BLOODHOUND_TABLES = (
    'bloodhound_product',
    'bloodhound_productconfig',
    'bloodhound_productresourcemap',
)

TABLES_WITH_PRODUCT_FIELD = (
    'ticket', 'ticket_change', 'ticket_custom', 'attachment', 'component',
    'milestone', 'wiki', 'report',
    'version', 'enum', 'permission', 'system',
)


class EnvironmentUpgradeTestCase(unittest.TestCase):
    def setUp(self, options=()):
        env_path = tempfile.mkdtemp(prefix='bh-product-tempenv-')
        self.env = Environment(env_path, create=True, options=options)
        DummyPlugin.version = 1

    def tearDown(self):
        shutil.rmtree(self.env.path)

    def test_can_upgrade_environment_with_multi_product_disabled(self):
        self.env.upgrade()

        # Multiproduct was not enabled so multiproduct tables should not exist
        for table in BLOODHOUND_TABLES:
            with self.assertFailsWithMissingTable():
                self.env.db_direct_query("SELECT * FROM %s" % table)

        for table in TABLES_WITH_PRODUCT_FIELD:
            with self.assertFailsWithMissingColumn():
                self.env.db_direct_query("SELECT product FROM %s" % table)

    def test_upgrade_creates_multi_product_tables_and_adds_product_column(self):
        self._enable_multiproduct()
        self.env.upgrade()

        with self.env.db_direct_transaction as db:
            for table in BLOODHOUND_TABLES:
                db("SELECT * FROM %s" % table)

            for table in TABLES_WITH_PRODUCT_FIELD:
                db("SELECT product FROM %s" % table)

    def test_upgrade_creates_default_product(self):
        self._enable_multiproduct()
        self.env.upgrade()

        products = Product.select(self.env)
        self.assertEqual(len(products), 1)

    def test_upgrade_moves_tickets_and_related_objects_to_default_prod(self):
        self._add_custom_field('custom_field')
        with self.env.db_direct_transaction as db:
            db("""INSERT INTO ticket (id) VALUES (1)""")
            db("""INSERT INTO attachment (type, id, filename)
                       VALUES ('ticket', '1', '')""")
            db("""INSERT INTO ticket_custom (ticket, name, value)
                       VALUES (1, 'custom_field', '42')""")
            db("""INSERT INTO ticket_change (ticket, time, field)
                       VALUES (1, 42, 'summary')""")

        self._enable_multiproduct()
        self.env.upgrade()

        with self.product('@'):
            ticket = Ticket(self.env, 1)
            attachments = list(Attachment.select(self.env,
                                                 ticket.resource.realm,
                                                 ticket.resource.id))
            self.assertEqual(len(attachments), 1)
            self.assertEqual(ticket['custom_field'], '42')
            changes = ticket.get_changelog()
            self.assertEqual(len(changes), 3)

    def test_upgrade_moves_custom_wikis_to_default_product(self):
        with self.env.db_direct_transaction as db:
            db("""INSERT INTO wiki (name, version) VALUES ('MyPage', 1)""")
            db("""INSERT INTO attachment (type, id, filename)
                         VALUES ('wiki', 'MyPage', '')""")

        self._enable_multiproduct()
        self.env.upgrade()

        with self.env.db_direct_transaction as db:
            self.assertEqual(
                len(db("""SELECT * FROM wiki WHERE product='@'""")), 1)
            self.assertEqual(
                len(db("""SELECT * FROM attachment
                           WHERE product='@'
                             AND type='wiki'""")), 1)

    def test_upgrade_moves_system_wikis_to_products(self):
        with self.env.db_direct_transaction as db:
            db("""INSERT INTO wiki (name, version) VALUES ('WikiStart', 1)""")
            db("""INSERT INTO attachment (type, id, filename)
                         VALUES ('wiki', 'WikiStart', '')""")

        self._enable_multiproduct()
        self.env.upgrade()

        with self.env.db_direct_transaction as db:
            self.assertEqual(
                len(db("""SELECT * FROM wiki WHERE product='@'""")), 1)
            self.assertEqual(
                len(db("""SELECT * FROM attachment
                           WHERE product='@'
                             AND type='wiki'""")), 1)
            self.assertEqual(
                len(db("""SELECT * FROM wiki WHERE product=''""")), 0)
            self.assertEqual(
                len(db("""SELECT * FROM attachment
                           WHERE product=''
                             AND type='wiki'""")), 0)

    def test_upgrade_copies_content_of_system_tables_to_all_products(self):
        mp = MultiProductSystem(self.env)
        with self.env.db_direct_transaction as db:
            mp._add_column_product_to_ticket(db)
            mp._create_multiproduct_tables(db)
            mp._update_db_version(db, 1)
            for i in range(1, 6):
                db("""INSERT INTO bloodhound_product (prefix, name)
                           VALUES ('p%d', 'Product 1')""" % i)
            for table in ('component', 'milestone', 'enum', 'version',
                          'permission', 'report'):
                db("""DELETE FROM %s""" % table)
            db("""INSERT INTO component (name) VALUES ('foobar')""")
            db("""INSERT INTO milestone (name) VALUES ('foobar')""")
            db("""INSERT INTO version (name) VALUES ('foobar')""")
            db("""INSERT INTO enum (type, name) VALUES ('a', 'b')""")
            db("""INSERT INTO permission VALUES ('x', 'TICKET_VIEW')""")
            db("""INSERT INTO report (title) VALUES ('x')""")

        self._enable_multiproduct()
        self.env.upgrade()

        with self.env.db_direct_transaction as db:
            for table in ('component', 'milestone', 'version', 'enum',
                          'report'):
                rows = db("SELECT * FROM %s" % table)
                self.assertEqual(
                    len(rows), 6,
                    "Wrong number of lines in %s (%d instead of %d)\n%s"
                    % (table, len(rows), 6, rows))
            for table in ('permission',):
                # Permissions also hold rows for global product.
                rows = db("SELECT * FROM %s WHERE username='x'" % table)
                self.assertEqual(
                    len(rows), 7,
                    "Wrong number of lines in %s (%d instead of %d)\n%s"
                    % (table, len(rows), 7, rows))

    def test_upgrading_database_moves_attachment_to_correct_product(self):
        ticket = self.insert_ticket('ticket')
        wiki = self.insert_wiki('MyWiki')
        attachment = self._create_file_with_content('Hello World!')
        self.add_attachment(ticket.resource, attachment)
        self.add_attachment(wiki.resource, attachment)

        self._enable_multiproduct()
        self.env.upgrade()

        with self.product('@'):
            attachments = list(
                Attachment.select(self.env, 'ticket', ticket.id))
            attachments.extend(
                Attachment.select(self.env, 'wiki', wiki.name))
        self.assertEqual(len(attachments), 2)
        for attachment in attachments:
            self.assertEqual(attachment.open().read(), 'Hello World!')

    def test_can_upgrade_database_with_ticket_attachment_with_text_ids(self):
        with self.env.db_direct_transaction as db:
            db("""INSERT INTO attachment (id, type, filename)
                       VALUES ('abc', 'ticket', '')""")

        self._enable_multiproduct()
        self.env.upgrade()

    def test_can_upgrade_database_with_orphaned_attachments(self):
        with self.env.db_direct_transaction as db:
            db("""INSERT INTO attachment (id, type, filename)
                       VALUES ('5', 'ticket', '')""")
            db("""INSERT INTO attachment (id, type, filename)
                       VALUES ('MyWiki', 'wiki', '')""")

        self._enable_multiproduct()
        self.env.upgrade()

    def test_can_upgrade_multi_product_from_v1(self):
        mp = MultiProductSystem(self.env)
        with self.env.db_direct_transaction as db:
            mp._add_column_product_to_ticket(db)
            mp._create_multiproduct_tables(db)
            mp._update_db_version(db, 1)

            db("""INSERT INTO bloodhound_product (prefix, name)
                       VALUES ('p1', 'Product 1')""")
            db("""INSERT INTO ticket (id, product)
                       VALUES (1, 'Product 1')""")

        self._enable_multiproduct()
        self.env.upgrade()

        with self.product('p1'):
            Ticket(self.env, 1)

    def test_can_upgrade_multi_product_from_v2(self):
        mp = MultiProductSystem(self.env)
        with self.env.db_direct_transaction as db:
            mp._add_column_product_to_ticket(db)
            mp._create_multiproduct_tables(db)
            mp._replace_product_on_ticket_with_product_prefix(db)
            mp._update_db_version(db, 2)

            db("""INSERT INTO bloodhound_product (prefix, name)
                       VALUES ('p1', 'Product 1')""")
            db("""INSERT INTO ticket (id, product)
                       VALUES (1, 'p1')""")
            db("""INSERT INTO ticket (id)
                       VALUES (2)""")

        self._enable_multiproduct()
        self.env.upgrade()

        with self.product('p1'):
            Ticket(self.env, 1)
        with self.product('@'):
            Ticket(self.env, 2)

    def test_upgrade_plugin(self):
        self._enable_component(DummyPlugin)
        self.env.upgrade()

        with self.env.db_direct_transaction as db:
            db("SELECT v1 FROM dummy_table")
            with self.assertFailsWithMissingColumn():
                db("SELECT v2 FROM dummy_table")

        DummyPlugin.version = 2
        self.env.upgrade()

        with self.env.db_direct_transaction as db:
            db("SELECT v2 FROM dummy_table")

    def test_upgrade_plugin_to_multiproduct(self):
        self._enable_multiproduct()
        self._enable_component(DummyPlugin)
        self.env.upgrade()

        with self.env.db_direct_transaction as db:
            db("SELECT * FROM dummy_table")
            db("""SELECT * FROM "@_dummy_table" """)

    def test_upgrade_existing_plugin_to_multiproduct(self):
        self._enable_component(DummyPlugin)
        self.env.upgrade()
        with self.env.db_direct_transaction as db:
            with self.assertFailsWithMissingTable():
                db("""SELECT * FROM "@_dummy_table" """)

        self._enable_multiproduct()
        self.env.upgrade()
        with self.env.db_direct_transaction as db:
            db("SELECT * FROM dummy_table")
            db("""SELECT * FROM "@_dummy_table" """)

    def test_upgrading_existing_plugin_leaves_data_in_global_env(self):
        DummyPlugin.version = 2
        self._enable_component(DummyPlugin)
        self.env.upgrade()
        with self.env.db_direct_transaction as db:
            for i in range(5):
                db("INSERT INTO dummy_table (v1) VALUES ('%d')" % i)
            self.assertEqual(
                len(db("SELECT * FROM dummy_table")), 5)

        self._enable_multiproduct()
        self.env.upgrade()
        with self.env.db_direct_transaction as db:
            self.assertEqual(
                len(db('SELECT * FROM "dummy_table"')), 5)
            self.assertEqual(
                len(db('SELECT * FROM "@_dummy_table"')), 0)

    def test_creating_new_product_calls_environment_created(self):
        self._enable_component(DummyPlugin)
        self._enable_multiproduct()
        self.env.upgrade()

        prod = Product(self.env)
        prod.update_field_dict(dict(prefix='p1'))
        ProductEnvironment(self.env, prod, create=True)
        with self.env.db_direct_transaction as db:
            db('SELECT * FROM "p1_dummy_table"')

    def test_migrating_to_multiproduct_with_custom_default_prefix(self):
        ticket = self.insert_ticket('ticket')

        self.env.config.set('multiproduct', 'default_product_prefix', 'xxx')
        self._enable_multiproduct()
        self.env.upgrade()

        products = Product.select(self.env)
        self.assertEqual(len(products), 1)
        self.assertEqual(products[0].prefix, 'xxx')

    def test_migration_to_multiproduct_preserves_ticket_ids(self):
        for ticket_id in (1, 3, 5, 7):
            with self.env.db_transaction as db:
                cursor = db.cursor()
                cursor.execute("INSERT INTO ticket (id) VALUES (%i)" % ticket_id)
                db.update_sequence(cursor, 'ticket')

        self._enable_multiproduct()
        self.env.upgrade()

        for ticket_id in (1, 3, 5, 7):
            with self.product('@'):
                ticket = Ticket(self.env, ticket_id)
            self.assertEqual(ticket.id, ticket_id)

    def test_can_insert_tickets_after_upgrade(self):
        t1 = Ticket(self.env)
        t1.summary = "test"
        t1.insert()
        self.assertEqual(t1.id, 1)

        self._enable_multiproduct()
        self.env.upgrade()

        with self.product('@'):
            ticket = Ticket(self.env)
            ticket.summary = 'test'
            ticket.insert()
            self.assertEqual(ticket.id, 2)

    def test_can_insert_tickets_with_same_id_to_different_products(self):
        self._enable_multiproduct()
        self.env.upgrade()

        self.env.db_transaction("INSERT INTO ticket (id, summary)"
                                "            VALUES (1, 'first product')")
        t1 = Ticket(self.env, 1)

        with self.product('@'):
            self.env.db_transaction("INSERT INTO ticket (id, summary)"
                                    "            VALUES (1, 'second product')")
            t2 = Ticket(self.env, 1)

        self.assertEqual(t1.id, t2.id)
        self.assertNotEqual(t1['summary'], t2['summary'])

    def test_batch_ticket_insert_after_upgrade(self):
        self._enable_multiproduct()
        self.env.upgrade()
        with self.env.db_direct_transaction as db:
            db("""CREATE TABLE "@_tmp" (summary text, product text)""")
            for summary in "abcdef":
                db("""INSERT INTO "@_tmp" VALUES ('%s', '@')""" % (summary,))

        with self.product('@'):
            with self.env.db_transaction as db:
                db("""INSERT INTO ticket (summary) SELECT summary FROM tmp""")



    def _enable_multiproduct(self):
        self._update_config('components', 'multiproduct.*', 'enabled')

    def _add_custom_field(self, field_name):
        self._update_config('ticket-custom', field_name, 'text')

    def _enable_component(self, cls):
        self._update_config(
            'components',
            '%s.%s' % (cls.__module__, cls.__name__),
            'enabled'
        )

    def _update_config(self, section, key, value):
        self.env.config.set(section, key, value)
        self.env.config.save()
        self.env = Environment(self.env.path)

    def _create_file_with_content(self, content):
        filename = str(uuid.uuid4())[:6]
        path = os.path.join(self.env.path, filename)
        with open(path, 'wb') as f:
            f.write(content)
        return path

    @contextmanager
    def assertFailsWithMissingTable(self):
        with self.assertRaises(self.env.db_exc.OperationalError) as cm:
            yield
        self.assertIn('no such table', str(cm.exception))

    @contextmanager
    def assertFailsWithMissingColumn(self):
        with self.assertRaises(self.env.db_exc.OperationalError) as cm:
            yield
        self.assertIn('no such column', str(cm.exception))

    def create_ticket(self, summary, **kw):
        ticket = Ticket(self.env)
        ticket["summary"] = summary
        for k, v in kw.items():
            ticket[k] = v
        return ticket

    def insert_ticket(self, summary, **kw):
        """Helper for inserting a ticket into the database"""
        ticket = self.create_ticket(summary, **kw)
        ticket.insert()
        return ticket

    def create_wiki(self, name, text,  **kw):
        page = WikiPage(self.env, name)
        page.text = text
        for k, v in kw.items():
            page[k] = v
        return page

    def insert_wiki(self, name, text = None, **kw):
        text = text or "Dummy text"
        page = self.create_wiki(name, text, **kw)
        page.save("dummy author", "dummy comment", "::1")
        return page

    def add_attachment(self, resource, path):
        resource = '%s:%s' % (resource.realm, resource.id)
        AttachmentAdmin(self.env)._do_add(resource, path)

    @contextmanager
    def product(self, prefix):
        old_env = self.env
        self.env = ProductEnvironment(self.env, prefix)
        yield
        self.env = old_env


class DummyPlugin(Component):
    implements(IEnvironmentSetupParticipant)
    version = 1

    def environment_created(self):
        with self.env.db_transaction as db:
            self.upgrade_environment(db)

    def environment_needs_upgrade(self, db):
        return self.get_version(db) < self.version

    def upgrade_environment(self, db):
        old_version = current_version = self.get_version(db)
        db_connector, dummy = DatabaseManager(self.env)._get_connector()

        while current_version < self.version:
            if current_version > 0:
                db("CREATE TEMPORARY TABLE dummy_table_old AS "
                               "SELECT * FROM dummy_table")
                db("DROP TABLE dummy_table")

            table = self.construct_dummy_table(current_version+1)
            for statement in db_connector.to_sql(table):
                db(statement)

            if current_version > 0:
                cols = ['id'] + ['v%i' % (i+1)
                                 for i in range(current_version+1)]
                db("""INSERT INTO dummy_table (%s)
                                  SELECT %s, '' FROM dummy_table_old
                   """ % (', '.join(cols), ', '.join(cols[:-1])))
                db("DROP TABLE dummy_table_old")

            current_version += 1

        if current_version != old_version:
            self.update_version(db, current_version)

    def construct_dummy_table(self, n_custom_fields=1):
        fields = [Column('id')] + [
            Column('v%d' % (i+1)) for i in range(n_custom_fields)
        ]
        return Table('dummy_table')[fields]

    def get_version(self, db):
        rows = db("SELECT value FROM system WHERE name = %s",
                  (self.__class__.__name__,))
        return int(rows[0][0]) if rows else 0

    def update_version(self, db, version):
        old_version = self.get_version(db)
        if old_version:
            db("UPDATE system SET value=%s WHERE name=%s",
               (version, self.__class__.__name__,))
        else:
            db("INSERT INTO system (name, value) VALUES ('%s','%s')"
               % (self.__class__.__name__, version))
        return version


def test_suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(EnvironmentUpgradeTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = upgrade_postgres
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.
try:
    import psycopg2
    import uuid
    conn = psycopg2.connect(host='localhost', database='test')
    cur = conn.cursor()
    schema = str(uuid.uuid4()).replace('-', '')
    cur.execute('CREATE SCHEMA "%s"' % schema)
    cur.execute('DROP SCHEMA "%s"' % schema)
    conn.close()
    database_available = True
except Exception as err:
    print err
    database_available = False

import upgrade
from contextlib import contextmanager
from tests import unittest


@unittest.skipUnless(database_available, "Postgres database not available.")
class PostgresEnvironmentUpgradeTestCase(upgrade.EnvironmentUpgradeTestCase):
    def setUp(self):
        self.schema = str(uuid.uuid4()).replace('-', '')
        super(PostgresEnvironmentUpgradeTestCase, self).setUp(
            (('trac', 'database',
              'postgres://localhost/test?schema=%s' % self.schema),)
        )

    def tearDown(self):
        super(PostgresEnvironmentUpgradeTestCase, self).tearDown()
        conn = psycopg2.connect(host='localhost', database='test')
        cur = conn.cursor()
        cur.execute('DROP SCHEMA "%s" CASCADE' % self.schema)
        conn.commit()
        conn.close()

    @contextmanager
    def assertFailsWithMissingTable(self):
        with self.assertRaises(psycopg2.ProgrammingError) as cm:
            yield
        self.assertIn("relation", str(cm.exception))
        self.assertIn("does not exist", str(cm.exception))

    @contextmanager
    def assertFailsWithMissingColumn(self):
        with self.assertRaises(psycopg2.ProgrammingError) as cm:
            yield
        self.assertIn("column", str(cm.exception))
        self.assertIn("does not exist", str(cm.exception))

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's repository API in product environments"""

import unittest

from trac.resource import Resource, get_resource_description, get_resource_url
from trac.versioncontrol.api import Repository
from trac.versioncontrol.tests.api import ResourceManagerTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductResourceManagerTestCase(ResourceManagerTestCase,
                                     MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
            self._load_default_data(env)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None

    def test_resource_changeset(self):
        res = Resource('changeset', '42')
        self.assertEqual('Changeset 42', get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/products/tp1/changeset/42',
                         get_resource_url(self.env, res, self.env.href))

        repo = Resource('repository', 'repo')
        res = Resource('changeset', '42', parent=repo)
        self.assertEqual('Changeset 42 in repo',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/products/tp1/changeset/42/repo',
                         get_resource_url(self.env, res, self.env.href))

    def test_resource_source(self):
        res = Resource('source', '/trunk/src')
        self.assertEqual('path /trunk/src',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/products/tp1/browser/trunk/src',
                         get_resource_url(self.env, res, self.env.href))

        repo = Resource('repository', 'repo')
        res = Resource('source', '/trunk/src', parent=repo)
        self.assertEqual('path /trunk/src in repo',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/products/tp1/browser/repo/trunk/src',
                         get_resource_url(self.env, res, self.env.href))

        repo = Resource('repository', 'repo')
        res = Resource('source', '/trunk/src', version=42, parent=repo)
        self.assertEqual('path /trunk/src@42 in repo',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/products/tp1/browser/repo/trunk/src?rev=42',
                         get_resource_url(self.env, res, self.env.href))

    def test_resource_repository(self):
        res = Resource('repository', 'testrepo')
        self.assertEqual('Repository testrepo',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/products/tp1/browser/testrepo',
                         get_resource_url(self.env, res, self.env.href))


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductResourceManagerTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = cache
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's repository cache in
product environments"""

import unittest

from trac.versioncontrol.tests.cache import CacheTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductCacheTestCase(CacheTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductCacheTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = svn_authz
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's SVN authz policy in product environments"""

import os
import unittest

from trac.versioncontrol.svn_authz import AuthzSourcePolicy
from trac.versioncontrol.tests.svn_authz import AuthzSourcePolicyTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductAuthzSourcePolicyTestCase(AuthzSourcePolicyTestCase, \
                                       MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env(enable=[AuthzSourcePolicy])
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None
        os.remove(self.authz)


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductAuthzSourcePolicyTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = chrome
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound web chrome API in product environments"""

import unittest

from trac.web.tests.chrome import ChromeTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductChromeTestCase(ChromeTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def setUp(self):
        # Instantiate environment stub before clearing ComponentMeta._registry
        self.env
        ChromeTestCase.setUp(self)

    def tearDown(self):
        try:
            try:
                global_env = self.global_env
            except AttributeError:
                pass
            else:
                self.global_env.reset_db()
            self.global_env = self._env = None
        finally:
            ChromeTestCase.tearDown(self)


def test_suite():
    return unittest.makeSuite(ProductChromeTestCase,'test')

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = session
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's ticket reports in product environments"""

import unittest

from trac.web.tests.session import SessionTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductSessionTestCase(SessionTestCase, MultiproductTestCase):

    @property
    def env(self):
        env = getattr(self, '_env', None)
        if env is None:
            self.global_env = self._setup_test_env()
            self._upgrade_mp(self.global_env)
            self._setup_test_log(self.global_env)
            self._load_product_from_data(self.global_env, self.default_product)
            self._env = env = ProductEnvironment(
                    self.global_env, self.default_product)
        return env

    @env.setter
    def env(self, value):
        pass

    def tearDown(self):
        self.global_env.reset_db()
        self.global_env = self._env = None


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductSessionTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = wikisyntax
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for inherited Apache(TM) Bloodhound htdocs wiki syntax
in product environments"""

import os.path
import re
import unittest

from trac.web.tests import wikisyntax

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase
from tests.wiki import formatter

def test_suite():
    return formatter.test_suite(wikisyntax.TEST_CASES, file=wikisyntax.__file__)


if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's web modules"""

import sys
import unittest
from wsgiref.util import setup_testing_defaults

from trac.core import Component, implements
from trac.perm import PermissionCache, PermissionSystem
from trac.resource import ResourceNotFound
from trac.web.api import HTTPInternalError, HTTPNotFound, IRequestFilter, \
                         Request, RequestDone
from trac.web.href import Href
from trac.web.main import RequestDispatcher

from multiproduct.api import MultiProductSystem
from multiproduct.env import ProductEnvironment
from multiproduct.hooks import ProductRequestWithSession
from multiproduct.model import Product
from multiproduct.web_ui import ProductModule

from tests.env import MultiproductTestCase

#----------------
# Testing infrastructure for request handlers
#----------------

class TestRequestSpy(Component):

    implements(IRequestFilter)

    def testMatch(self, req, handler):
        raise AssertionError('Test setup error: Missing match assertions')

    def testProcessing(self, req, template, data, content_type):
        raise AssertionError('Test setup error: Missing processing assertions')

    # IRequestFilter methods
    def pre_process_request(self, req, handler):
        self.testMatch(req, handler)
        return handler

    def post_process_request(self, req, template, data, content_type):
        self.testProcessing(req, template, data, content_type)
        return template, data, content_type


class RequestHandlerTestCase(MultiproductTestCase):
    """Helper functions to write test cases for request handlers.

    May be used as a mixin class.
    """
    http_status = None
    http_headers = None
    http_body = None
    record_response = False

    def _get_request_obj(self, env):
        environ = {}
        setup_testing_defaults(environ)
        environ['SCRIPT_NAME'] = env.href()

        def start_response(status, headers):
            if self.record_response:
                self.http_status = status
                self.http_headers = dict(headers)
                self.http_body = []
                return lambda body: self.http_body.append(body)
            else:
                return lambda body: None

        req = ProductRequestWithSession(env, environ, start_response)
        return req

    def _dispatch(self, req, env):
        req.perm = PermissionCache(env, req.authname)
        return RequestDispatcher(env).dispatch(req)

    def assertHttpHeaders(self, expectedHeaders):
        for h, v in expectedHeaders.iteritems():
            self.assertTrue(h in self.http_headers,
                            "Expected HTTP header '%s' not set" % (h,))
            self.assertEquals(v, self.http_headers[h],
                              "Unexpected value for HTTP header '%s'" % (h,))

    def assertRedirect(self, req, url, permanent=False):
        if permanent:
            self.assertEquals('301 Moved Permanently', self.http_status,
                              'Unexpected status code in HTTP redirect')
        elif req.method == 'POST':
            self.assertEquals('303 See Other', self.http_status,
                              'Unexpected status code in HTTP redirect')
        else:
            self.assertEquals('302 Found', self.http_status,
                              'Unexpected status code in HTTP redirect')
        self.assertHttpHeaders({'Location' : url,
                                'Content-Type' : 'text/plain',
                                'Content-Length' : '0',
                                'Pragma' : 'no-cache',
                                'Cache-Control' : 'no-cache',
                                'Expires' : 'Fri, 01 Jan 1999 00:00:00 GMT'})


#----------------
# Testing product module
#----------------

class ProductModuleTestCase(RequestHandlerTestCase):
    def setUp(self):
        self._mp_setup()
        self.global_env = self.env
        self.env = ProductEnvironment(self.global_env, self.default_product)

        self.global_env.enable_component(TestRequestSpy)
        self.env.enable_component(TestRequestSpy)
        TestRequestSpy(self.global_env).testMatch = self._assert_product_match
        PermissionSystem(self.global_env).grant_permission('testuser', 'PRODUCT_CREATE')
        PermissionSystem(self.global_env).grant_permission('testuser', 'PRODUCT_VIEW')
        PermissionSystem(self.global_env).grant_permission('testuser', 'PRODUCT_MODIFY')

    def tearDown(self):
        self.global_env.reset_db()
        self.env = self.global_env = None

    expectedPrefix = None
    expectedPathInfo = None

    def _assert_product_match(self, req, handler):
        self.assertIs(ProductModule(self.global_env), handler)
        self.assertEqual(self.expectedPrefix, req.args['productid'],
                         "Unexpected product prefix")
        self.assertEqual(self.expectedPathInfo, req.args['pathinfo'],
                         "Unexpected sub path")

    def test_product_list(self):
        spy = self.global_env[TestRequestSpy]
        self.assertIsNot(None, spy)

        req = self._get_request_obj(self.global_env)
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/products'

        mps = MultiProductSystem(self.global_env)
        def assert_product_list(req, template, data, content_type):
            self.assertEquals('product_list.html', template)
            self.assertIs(None, content_type)
            self.assertEquals([mps.default_product_prefix,
                               self.default_product],
                              [p.prefix for p in data.get('products')])
            self.assertTrue('context' in data)
            ctx = data['context']
            self.assertEquals('product', ctx.resource.realm)
            self.assertEquals(None, ctx.resource.id)

        spy.testProcessing = assert_product_list
        with self.assertRaises(RequestDone):
            self._dispatch(req, self.global_env)

    def test_product_new(self):
        spy = self.global_env[TestRequestSpy]
        self.assertIsNot(None, spy)

        req = self._get_request_obj(self.global_env)
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/products'
        req.environ['QUERY_STRING'] = 'action=new'

        def assert_product_new(req, template, data, content_type):
            self.assertEquals('product_edit.html', template)
            self.assertIs(None, content_type)
            self.assertFalse('products' in data)
            self.assertTrue('context' in data)
            ctx = data['context']
            self.assertEquals('product', ctx.resource.realm)
            self.assertEquals(None, ctx.resource.id)

        spy.testProcessing = assert_product_new
        with self.assertRaises(RequestDone):
            self._dispatch(req, self.global_env)

    def test_product_view(self):
        spy = self.global_env[TestRequestSpy]
        self.assertIsNot(None, spy)

        def assert_product_view(req, template, data, content_type):
            self.assertEquals('product_view.html', template)
            self.assertIs(None, content_type)
            self.assertFalse('products' in data)

            self.assertTrue('context' in data)
            ctx = data['context']
            self.assertEquals('product', ctx.resource.realm)
            self.assertEquals(real_prefix, ctx.resource.id)

            self.assertTrue('product' in data)
            self.assertEquals(real_prefix, data['product'].prefix)

        spy.testProcessing = assert_product_view

        # Existing product
        req = self._get_request_obj(self.global_env)
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/products/%s' % (self.default_product,)

        real_prefix = self.default_product
        self.expectedPrefix = self.default_product
        self.expectedPathInfo = ''
        with self.assertRaises(RequestDone):
            self._dispatch(req, self.global_env)

    def test_missing_product(self):
        spy = self.global_env[TestRequestSpy]
        self.assertIsNot(None, spy)

        mps = MultiProductSystem(self.global_env)
        def assert_product_list(req, template, data, content_type):
            self.assertEquals('product_list.html', template)
            self.assertIs(None, content_type)
            self.assertEquals([mps.default_product_prefix,
                               self.default_product],
                              [p.prefix for p in data.get('products')])
            self.assertTrue('context' in data)
            ctx = data['context']
            self.assertEquals('product', ctx.resource.realm)
            self.assertEquals(None, ctx.resource.id)

        spy.testProcessing = assert_product_list

        # Missing product
        req = self._get_request_obj(self.global_env)
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/products/missing'

        self.expectedPrefix = 'missing'
        self.expectedPathInfo = ''
        with self.assertRaises(RequestDone):
            self._dispatch(req, self.global_env)
        self.assertEqual(1, len(req.chrome['warnings']))
        self.assertEqual('Product missing not found',
                         req.chrome['warnings'][0].unescape())

    def test_product_edit(self):
        spy = self.global_env[TestRequestSpy]
        self.assertIsNot(None, spy)

        # HTTP GET
        req = self._get_request_obj(self.global_env)
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/products/%s' % (self.default_product,)
        req.environ['QUERY_STRING'] = 'action=edit'

        real_prefix = self.default_product

        def assert_product_edit(req, template, data, content_type):
            self.assertEquals('product_edit.html', template)
            self.assertIs(None, content_type)
            self.assertFalse('products' in data)

            self.assertTrue('context' in data)
            ctx = data['context']
            self.assertEquals('product', ctx.resource.realm)
            self.assertEquals(real_prefix, ctx.resource.id)

            self.assertTrue('product' in data)
            self.assertEquals(real_prefix, data['product'].prefix)

        spy.testProcessing = assert_product_edit

        self.expectedPrefix = self.default_product
        self.expectedPathInfo = ''
        with self.assertRaises(RequestDone):
            self._dispatch(req, self.global_env)

        # HTTP POST
        req = self._get_request_obj(self.global_env)
        req.authname = 'testuser'
        req.environ['REQUEST_METHOD'] = 'POST'
        req.environ['PATH_INFO'] = '/products/%s' % (self.default_product,)
        req.args = dict(action='edit', description='New description',
                        prefix=self.default_product,
                        name=self.env.product.name)

        spy.testProcessing = assert_product_edit

        self.expectedPrefix = self.default_product
        self.expectedPathInfo = ''
        self.record_response = True
        with self.assertRaises(RequestDone):
            self._dispatch(req, self.global_env)

        try:
            product = Product(self.global_env,
                              {'prefix' : self.env.product.prefix})
        except ResourceNotFound:
            self.fail('Default test product deleted ?')
        else:
            self.assertEquals('New description', product.description)

        product_url = Href(req.base_path).products(self.default_product)
        self.assertRedirect(req, product_url)

    def test_product_delete(self):
        spy = self.global_env[TestRequestSpy]
        self.assertIsNot(None, spy)

        req = self._get_request_obj(self.global_env)
        req.authname = 'testuser'
        req.environ['PATH_INFO'] = '/products/%s' % (self.default_product,)
        req.environ['QUERY_STRING'] = 'action=delete'
        self.expectedPrefix = self.default_product
        self.expectedPathInfo = ''
        spy.testProcessing = lambda *args, **kwargs: None

        with self.assertRaises(HTTPInternalError) as test_cm:
            self._dispatch(req, self.global_env)

        self.assertEqual('500 Trac Error (Product removal is not allowed!)',
                         unicode(test_cm.exception))


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductModuleTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = formatter
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's wiki formatters in product environments"""

import os.path
import re
import unittest

from trac.test import Mock, MockPerm, locale_en
from trac.util.datefmt import utc
from trac.web.href import Href
from trac.web.main import FakeSession
from trac.wiki.tests import formatter

from multiproduct.env import ProductEnvironment
from multiproduct.model import Product
from tests.env import MultiproductTestCase


class ProductWikiTestCase(formatter.WikiTestCase, MultiproductTestCase):
    maxDiff = None

    def setUp(self):
        self._prepare_env()

        self._setup_test_log(self.global_env)
        formatter.WikiTestCase.setUp(self)
        if self.context.req:
            self.context.req.session = FakeSession()
        if self.mpctx:
            candidates = set(self.mpctx.get('load_products', []) +
                             [self.mpctx.get('main_product')])
            candidates -= set([self.default_product, None,
                              self.mpctx.get('setup_product')])
            for prefix in candidates:
                self._load_product_from_data(self.env, prefix)

            prefix = self.mpctx.get('main_product', NotImplemented)
            if prefix is None:
                self.env = self.global_env
            elif prefix is not NotImplemented \
                    and (self.env is self.global_env or
                         prefix != self.env.product.prefix):
                self.env = ProductEnvironment(self.global_env, prefix)
            # Enable multi-product components
            self.env.config.set('components', 'multiproduct.*', 'enabled')

    def _prepare_env(self):
        all_test_components = [
                    formatter.HelloWorldMacro, formatter.DivHelloWorldMacro,
                    formatter.TableHelloWorldMacro, formatter.DivCodeMacro,
                    formatter.DivCodeElementMacro, formatter.DivCodeStreamMacro,
                    formatter.NoneMacro, formatter.WikiProcessorSampleMacro,
                    formatter.SampleResolver]
        self.global_env = self._setup_test_env(
            enable=['trac.*', 'multiproduct.*'] + all_test_components
        )

        self._upgrade_mp(self.global_env)
        self._load_product_from_data(self.global_env, self.default_product)
        prefix = self.default_product
        if self.mpctx:
            prefix = self.mpctx.get('setup_product', prefix)
            if prefix and prefix != self.default_product:
                self._load_product_from_data(self.global_env, prefix)
        if prefix:
            self.env = ProductEnvironment(self.global_env,
                                          prefix or self.default_product)
        else:
            self.env = self.global_env

        self.env.path = ''
        config = self.env.config
        # -- intertrac support
        config.set('intertrac', 'trac.title', "Trac's Trac")
        config.set('intertrac', 'trac.url',
                   "http://trac.edgewall.org")
        config.set('intertrac', 't', 'trac')
        config.set('intertrac', 'th.title', "Trac Hacks")
        config.set('intertrac', 'th.url',
                   "http://trac-hacks.org")
        config.set('intertrac', 'th.compat', 'false')
        # -- safe schemes
        config.set('wiki', 'safe_schemes',
                   'file,ftp,http,https,svn,svn+ssh,'
                   'rfc-2396.compatible,rfc-2396+under_score')

        req = Mock(href=Href('/'), abs_href=Href('http://www.example.com/'),
                   authname='anonymous', perm=MockPerm(), tz=utc, args={},
                   locale=locale_en, lc_time=locale_en)

        self.env.href = req.href
        self.env.abs_href = req.abs_href

    def tearDown(self):
        self.global_env.reset_db()
        try:
            if self._teardown:
                self._teardown(self)
        finally:
            self.global_env = self._env = None

    def __init__(self, title, input, correct, file, line, setup=None,
                 teardown=None, context=None, mpctx=None):
        MultiproductTestCase.__init__(self, 'test')
        self.mpctx = mpctx
        formatter.WikiTestCase.__init__(self, title, input, correct, file, line,
                setup, teardown, context)

class ProductOneLinerTestCase(ProductWikiTestCase):
    formatter = formatter.OneLinerTestCase.formatter.im_func

class ProductEscapeNewLinesTestCase(ProductWikiTestCase):
    generate_opts = formatter.EscapeNewLinesTestCase.generate_opts
    formatter = formatter.EscapeNewLinesTestCase.formatter.im_func

class ProductOutlineTestCase(ProductWikiTestCase):
    formatter = formatter.OutlineTestCase.formatter.im_func


def test_suite(data=None, setup=None, file=formatter.__file__,
        teardown=None, context=None, mpctx=None):
    suite = unittest.TestSuite()
    def add_test_cases(data, filename):
        tests = re.compile('^(%s.*)$' % ('=' * 30), re.MULTILINE).split(data)
        next_line = 1
        line = 0
        for title, test in zip(tests[1::2], tests[2::2]):
            title = title.lstrip('=').strip()
            if line != next_line:
                line = next_line
            if not test or test == '\n':
                continue
            next_line += len(test.split('\n')) - 1
            if 'SKIP' in title or 'WONTFIX' in title:
                continue
            blocks = test.split('-' * 30 + '\n')
            if len(blocks) < 5:
                blocks.extend([None,] * (5 - len(blocks)))
            input, page, oneliner, page_escape_nl, outline = blocks[:5]
            if page:
                page = ProductWikiTestCase(
                    title, input, page, filename, line, setup,
                    teardown, context, mpctx)
            if oneliner:
                oneliner = ProductOneLinerTestCase(
                    title, input, oneliner[:-1], filename, line, setup,
                    teardown, context, mpctx)
            if page_escape_nl:
                page_escape_nl = ProductEscapeNewLinesTestCase(
                    title, input, page_escape_nl, filename, line, setup,
                    teardown, context, mpctx)
            if outline:
                outline = ProductOutlineTestCase(
                    title, input, outline, filename, line, setup,
                    teardown, context, mpctx)
            for tc in [page, oneliner, page_escape_nl, outline]:
                if tc:
                    suite.addTest(tc)
    if data:
        add_test_cases(data, file)
    else:
        for f in ('wiki-tests.txt', 'wikicreole-tests.txt'):
            testfile = os.path.join(os.path.split(file)[0], f)
            if os.path.exists(testfile):
                data = open(testfile, 'r').read().decode('utf-8')
                add_test_cases(data, testfile)
            else:
                print 'no ', testfile
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = macros
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for inherited Apache(TM) Bloodhound's wiki macros
in product environments"""

import os.path
import re
import unittest

from trac.wiki.tests import macros

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase
from tests.wiki import formatter

def test_suite():
    suite = unittest.TestSuite()
    suite.addTest(formatter.test_suite(
                                  macros.IMAGE_MACRO_TEST_CASES,
                                  file=macros.__file__))
    suite.addTest(formatter.test_suite(
                                  macros.TITLEINDEX1_MACRO_TEST_CASES,
                                  file=macros.__file__))
    suite.addTest(formatter.test_suite(
                                  macros.TITLEINDEX2_MACRO_TEST_CASES,
                                  file=macros.__file__,
                                  setup=macros.titleindex2_setup,
                                  teardown=macros.titleindex_teardown))
    suite.addTest(formatter.test_suite(
                                  macros.TITLEINDEX3_MACRO_TEST_CASES,
                                  file=macros.__file__,
                                  setup=macros.titleindex3_setup,
                                  teardown=macros.titleindex_teardown))
    suite.addTest(formatter.test_suite(
                                  macros.TITLEINDEX4_MACRO_TEST_CASES,
                                  file=macros.__file__,
                                  setup=macros.titleindex4_setup,
                                  teardown=macros.titleindex_teardown))
    suite.addTest(formatter.test_suite(
                                  macros.TITLEINDEX5_MACRO_TEST_CASES,
                                  file=macros.__file__,
                                  setup=macros.titleindex5_setup,
                                  teardown=macros.titleindex_teardown))
    suite.addTest(formatter.test_suite(
                                  macros.RECENTCHANGES_MACRO_TEST_CASES,
                                  file=macros.__file__,
                                  setup=macros.recentchanges_setup,
                                  teardown=macros.recentchanges_teardown))
    suite.addTest(formatter.test_suite(
                                  macros.TRACINI_MACRO_TEST_CASES,
                                  file=macros.__file__,
                                  setup=macros.tracini_setup,
                                  teardown=macros.tracini_teardown))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = model
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's ticket reports in product environments"""

import os.path
import shutil
import tempfile
import unittest

from trac.wiki.tests.model import WikiPageTestCase

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase

class ProductWikiPageTestCase(WikiPageTestCase, MultiproductTestCase):

    def setUp(self):
        self.global_env = self._setup_test_env(create_folder=True,
                path=os.path.join(tempfile.gettempdir(), 'trac-tempenv') )
        self._upgrade_mp(self.global_env)
        self._setup_test_log(self.global_env)
        self._load_product_from_data(self.global_env, self.default_product)
        self.env = ProductEnvironment(self.global_env, self.default_product)


    def tearDown(self):
        self.global_env.reset_db()
        shutil.rmtree(self.global_env.path)
        self.env = self.global_env = None


def test_suite():
    return unittest.TestSuite([
            unittest.makeSuite(ProductWikiPageTestCase,'test'),
        ])

if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = wikisyntax
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for inherited Apache(TM) Bloodhound's wiki syntax
in product environments"""

import os.path
import re
import unittest

from trac.wiki.tests import wikisyntax

from multiproduct.env import ProductEnvironment
from tests.env import MultiproductTestCase
from tests.wiki import formatter

def test_suite():
    suite = unittest.TestSuite()
    suite.addTest(formatter.test_suite(wikisyntax.TEST_CASES,
                                  wikisyntax.wiki_setup, wikisyntax.__file__,
                                  wikisyntax.wiki_teardown))
    suite.addTest(formatter.test_suite(wikisyntax.RELATIVE_LINKS_TESTS,
                                  wikisyntax.wiki_setup, wikisyntax.__file__,
                                  wikisyntax.wiki_teardown,
                                  context=('wiki', 'Main/Sub')))
    suite.addTest(formatter.test_suite(wikisyntax.SPLIT_PAGE_NAMES_TESTS,
                                  wikisyntax.wiki_setup_split,
                                  wikisyntax.__file__,
                                  wikisyntax.wiki_teardown,
                                  context=('wiki', 'Main/Sub')))
    suite.addTest(formatter.test_suite(wikisyntax.SCOPED_LINKS_TESTS,
                                  wikisyntax.wiki_setup, wikisyntax.__file__,
                                  wikisyntax.wiki_teardown,
                                  context=('wiki',
                                      'FirstLevel/SecondLevel/ThirdLevel')))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = wikisyntax
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for Apache(TM) Bloodhound's core wiki syntax in product environments"""

import os.path
import pkg_resources
import re
import shutil
import tempfile
import unittest

from genshi.core import escape

from trac.attachment import Attachment
from trac.web.href import Href
from trac.tests import wikisyntax
from trac.ticket.model import Ticket
from trac.ticket.tests import wikisyntax as ticket_wikisyntax
from trac.util.text import to_unicode

from multiproduct.api import PRODUCT_SYNTAX_DELIMITER
from multiproduct.env import ProductEnvironment
from multiproduct.ticket.query import ProductTicketQueryMacro
from tests.env import MultiproductTestCase
from tests.wiki import formatter

def attachment_setup(tc):
    import trac.ticket.api
    import trac.wiki.api
    tc.global_env.path = os.path.join(tempfile.gettempdir(), 'trac-tempenv')
    if tc.env is not tc.global_env:
        del tc.env.path
    attachment = Attachment(tc.env, 'wiki', 'WikiStart')
    attachment.insert('file.txt', tempfile.TemporaryFile(), 0)
    attachment = Attachment(tc.env, 'ticket', 123)
    attachment.insert('file.txt', tempfile.TemporaryFile(), 0)
    attachment = Attachment(tc.env, 'wiki', 'SomePage/SubPage')
    attachment.insert('foo.txt', tempfile.TemporaryFile(), 0)

def attachment_teardown(tc):
    tc.global_env.reset_db()
    shutil.rmtree(tc.global_env.path)

def ticket_setup(tc):
    ticket = Ticket(tc.env)
    ticket.values.update({'reporter': 'santa',
                          'summary': 'This is the summary',
                          'status': 'new'})

    # FIXME : UGLY ! Should not be explicit for product environments
    ticket['product'] = (tc.env.product.prefix
                         if isinstance(tc.env, ProductEnvironment)
                         else '')

    ticket.insert()


# Full syntax
PRODUCT_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-link-tests.txt'))
PRODUCT_ATTACHMENT_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-attachment-link-tests.txt'))
PRODUCT_SEARCH_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-search-link-tests.txt'))
PRODUCT_TICKET_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-ticket-link-tests.txt'))
PRODUCT_TICKET_JIRA = to_unicode(pkg_resources.resource_string(
        __name__, 'product-ticket-jira-tests.txt'))
PRODUCT_REPORT_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-report-link-tests.txt'))
PRODUCT_MILESTONE_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-milestone-link-tests.txt'))
PRODUCT_QUERY_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-query-link-tests.txt'))
PRODUCT_QUERY2_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-query2-link-tests.txt'))
PRODUCT_COMMENT_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-comment-link-tests.txt'))

# Compact syntax
PRODUCT_ATTACHMENT_SHORTLINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-attachment-link-tests.short.txt'))
PRODUCT_SEARCH_SHORTLINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-search-link-tests.short.txt'))
PRODUCT_TICKET_SHORTLINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-ticket-link-tests.short.txt'))
PRODUCT_REPORT_SHORTLINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-report-link-tests.short.txt'))
PRODUCT_MILESTONE_SHORTLINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-milestone-link-tests.short.txt'))
PRODUCT_QUERY_SHORTLINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-query-link-tests.short.txt'))
PRODUCT_COMMENT_SHORTLINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-comment-link-tests.short.txt'))

PRODUCT_NOMATCH_LINKS = to_unicode(pkg_resources.resource_string(
        __name__, 'product-nomatch-link-tests.txt'))

PRODUCT_PREFIXES = MultiproductTestCase.PRODUCT_DATA.keys()
PRODUCT_PREFIXES.remove(MultiproductTestCase.default_product)

def clear_base_href_setup(tc):
    tc.global_env.href = Href('/')
    tc.global_env.abs_href = Href('http://www.example.com/')
    if tc.env is not tc.global_env:
        del tc.env.abs_href
        del tc.env.href
    tc.env._href = tc.env._abs_href = None

def load_products_setup(prefixes):
    def _load_products_setup(tc):
        clear_base_href_setup(tc)

        for p in prefixes :
            tc._load_product_from_data(tc.global_env, p)
    return _load_products_setup

def link_mp_setup(_setup):
    def _link_mp_setup(tc):
        clear_base_href_setup(tc)
        _setup(tc)

    return _link_mp_setup


# Product testing contexts explained
#
# Product testing contexts are a hack used to hijack the mechanism
# used by Trac test suite in order to run wiki test cases in product context
#
# title_prefix          : prepend this text to test case summary
# link_prefix           : used to put link references in given product context
# link_title_prefix     : short text to highlight environment context
# path_prefix           : prepended to URLs expanded using `link_prefix`
# main_product          : prefix identifying the product bound to test case
#                         `env` attribute
# setup_product         : optional prefix of the product that will be setup
#                         i.e. the product under test
# load_products         : optional product prefixes list to load at setup time
# *_product_name        : target product name (e.g. setup_product_name )
# *_escaped             : escaped forms used to match output
TEST_PRODUCT_CONTEXTS = [
                         {'tc_title_prefix' : 'product: links',
                          'link_prefix' : 'product:tp1:',
                          'link_prefix_quote' : 'product:"tp1:',
                          'path_prefix' : '/products/tp1',
                          'main_product' : 'tp2',
                          'setup_product' : 'tp1',
                          'link_title_prefix' : '[tp1] ',
                          },
                         {'tc_title_prefix' : 'product: links unicode prefix',
                          'link_prefix' : u'product:x:',
                          'link_prefix_quote' : u'product:"x:',
                          'path_prefix' : '/products/x%C3%BC',
                          'main_product' : 'tp2',
                          'setup_product' : u'x',
                          'link_title_prefix' : u'[x] ',
                          },

                         # Ignored as TracLinks resolver won't match expression
                         #{'tc_title_prefix' : 'product:: refs to global',
                         # 'link_prefix' : 'product::',
                         # 'path_prefix' : '',
                         # 'main_product' : 'tp2',
                         # 'setup_product' : None,
                         # 'link_title_prefix' : '<global> '
                         # },

                         {'tc_title_prefix' : 'global: links',
                          'link_prefix' : 'global:',
                          'link_prefix_quote' : 'global:"',
                          'path_prefix' : '',
                          'main_product' : 'tp2',
                          'setup_product' : '',
                          'link_title_prefix' : '&lt;global&gt; ',
                          },
                        ]

TEST_PRODUCT_CONTEXTS_COMPACT = [
                          {'tc_title_prefix' : 'short product syntax',
                          'link_prefix' : 'tp1' + PRODUCT_SYNTAX_DELIMITER,
                          'link_prefix_quote' : 'tp1%s"' % PRODUCT_SYNTAX_DELIMITER,
                          'path_prefix' : '/products/tp1',
                          'main_product' : 'tp2',
                          'setup_product' : 'tp1',
                          'link_title_prefix' : '[tp1] ',
                          },
                         {'tc_title_prefix' : 'short product syntax unicode prefix',
                          'link_prefix' : u'x' + PRODUCT_SYNTAX_DELIMITER,
                          'link_prefix_quote' : u'x%s"' % PRODUCT_SYNTAX_DELIMITER,
                          'path_prefix' : '/products/x%C3%BC',
                          'main_product' : 'tp2',
                          'setup_product' : u'x',
                          'link_title_prefix' : u'[x] ',
                          },
                        ]

for ctxlst in (TEST_PRODUCT_CONTEXTS, TEST_PRODUCT_CONTEXTS_COMPACT):
    for _ctx in ctxlst:
        _product_extras = {}
        for k,v in _ctx.iteritems():
            _product_extras[k + '_escaped'] = escape(v)
            if k.endswith('_product'):
                if v in MultiproductTestCase.PRODUCT_DATA:
                    _product_extras[k + '_name'] = MultiproductTestCase.PRODUCT_DATA[v]['name']
                else:
                    _product_extras[k + '_name'] = ''
                _product_extras[k + '_name_escaped'] = escape(_product_extras[k + '_name'])
        _ctx.update(_product_extras)

del _ctx, k, v, _product_extras

def test_suite():
    suite = unittest.TestSuite()

    # Legacy test cases
    suite.addTest(formatter.test_suite(wikisyntax.SEARCH_TEST_CASES,
                                  file=wikisyntax.__file__))
    suite.addTest(formatter.test_suite(wikisyntax.ATTACHMENT_TEST_CASES,
                                  file=wikisyntax.__file__,
                                  context=('wiki', 'WikiStart'),
                                  setup=attachment_setup,
                                  teardown=attachment_teardown))
    suite.addTest(formatter.test_suite(wikisyntax.EMAIL_TEST_CASE_DEFAULT,
                                  file=wikisyntax.__file__,
                                  context=wikisyntax.email_default_context()))
    suite.addTest(formatter.test_suite(wikisyntax.EMAIL_TEST_CASE_NEVER_OBFUSCATE,
                                  file=wikisyntax.__file__,
                                  context=wikisyntax.email_default_context(),
                                  setup=wikisyntax.email_never_obfuscate_setup))

    # Product wiki syntax
    suite.addTest(formatter.test_suite(PRODUCT_LINKS,
                                  setup=load_products_setup(PRODUCT_PREFIXES),
                                  file=__file__))
    suite.addTests(formatter.test_suite(PRODUCT_SEARCH_LINKS % ctx,
                                  file=__file__,
                                  setup=clear_base_href_setup,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS)
    suite.addTests(formatter.test_suite(PRODUCT_ATTACHMENT_LINKS % ctx,
                                  file=__file__,
                                  context=('wiki', 'WikiStart'),
                                  setup=link_mp_setup(attachment_setup),
                                  teardown=attachment_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS)
    suite.addTests(formatter.test_suite(PRODUCT_TICKET_LINKS % ctx,
                                  link_mp_setup(ticket_wikisyntax.ticket_setup),
                                  __file__,
                                  # No need to invoke it anymore
                                  # ticket_wikisyntax.ticket_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS)
    suite.addTests(formatter.test_suite(PRODUCT_TICKET_JIRA % ctx,
                                  link_mp_setup(ticket_wikisyntax.ticket_setup),
                                  __file__,
                                  # No need to invoke it anymore
                                  # ticket_wikisyntax.ticket_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS
                   if ctx['path_prefix'])
    suite.addTests(formatter.test_suite(PRODUCT_REPORT_LINKS % ctx,
                                  link_mp_setup(ticket_wikisyntax.report_setup),
                                  __file__,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS)
    suite.addTests(formatter.test_suite(PRODUCT_MILESTONE_LINKS % ctx,
                                  link_mp_setup(ticket_wikisyntax.milestone_setup),
                                  __file__,
                                  ticket_wikisyntax.milestone_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS)
    suite.addTests(formatter.test_suite(PRODUCT_QUERY_LINKS % ctx,
                                  link_mp_setup(ticket_setup),
                                  __file__,
                                  ticket_wikisyntax.ticket_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS)
    suite.addTests(formatter.test_suite(PRODUCT_QUERY2_LINKS % ctx,
                                  link_mp_setup(ticket_wikisyntax.query2_setup),
                                  __file__,
                                  ticket_wikisyntax.query2_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS)
    suite.addTests(formatter.test_suite(PRODUCT_COMMENT_LINKS % ctx,
                                  clear_base_href_setup,
                                  __file__,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS)


    # Compact syntax
    suite.addTests(formatter.test_suite(PRODUCT_SEARCH_SHORTLINKS % ctx,
                                  file=__file__,
                                  setup=clear_base_href_setup,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS_COMPACT)
    suite.addTests(formatter.test_suite(PRODUCT_ATTACHMENT_SHORTLINKS % ctx,
                                  file=__file__,
                                  context=('wiki', 'WikiStart'),
                                  setup=link_mp_setup(attachment_setup),
                                  teardown=attachment_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS_COMPACT)
    suite.addTests(formatter.test_suite(PRODUCT_TICKET_SHORTLINKS % ctx,
                                  link_mp_setup(ticket_wikisyntax.ticket_setup),
                                  __file__,
                                  # No need to invoke it anymore
                                  # ticket_wikisyntax.ticket_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS_COMPACT)

    suite.addTests(formatter.test_suite(PRODUCT_REPORT_SHORTLINKS % ctx,
                                  link_mp_setup(ticket_wikisyntax.report_setup),
                                  __file__,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS_COMPACT)
    suite.addTests(formatter.test_suite(PRODUCT_MILESTONE_SHORTLINKS % ctx,
                                  link_mp_setup(ticket_wikisyntax.milestone_setup),
                                  __file__,
                                  ticket_wikisyntax.milestone_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS_COMPACT)
    suite.addTests(formatter.test_suite(PRODUCT_QUERY_SHORTLINKS % ctx,
                                  link_mp_setup(ticket_setup),
                                  __file__,
                                  ticket_wikisyntax.ticket_teardown,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS_COMPACT)
    suite.addTests(formatter.test_suite(PRODUCT_COMMENT_SHORTLINKS % ctx,
                                  clear_base_href_setup,
                                  __file__,
                                  mpctx=ctx)
                   for ctx in TEST_PRODUCT_CONTEXTS_COMPACT)


    # Unmatched expressions
    suite.addTest(formatter.test_suite(PRODUCT_NOMATCH_LINKS,
                                  file=__file__))

    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='test_suite')

########NEW FILE########
__FILENAME__ = api
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import itertools
import re
from datetime import datetime
from pkg_resources import resource_filename

from trac.config import OrderedExtensionsOption, Option
from trac.core import Component, ExtensionPoint, Interface, TracError, \
                      implements
from trac.db import DatabaseManager
from trac.env import IEnvironmentSetupParticipant
from trac.resource import Neighborhood, Resource, ResourceNotFound, \
                          ResourceSystem, get_resource_shortname
from trac.ticket.api import ITicketChangeListener, ITicketManipulator, \
                            TicketSystem
from trac.ticket.model import Ticket
from trac.util.datefmt import to_utimestamp, utc
from trac.web.chrome import ITemplateProvider

from multiproduct.api import ISupportMultiProductEnvironment
from multiproduct.model import Product
from multiproduct.env import ProductEnvironment

from bhrelations import db_default
from bhrelations.model import Relation
from bhrelations.utils import unique
from bhrelations.utils.translation import _, add_domain


PLUGIN_NAME = 'Bloodhound Relations Plugin'
RELATIONS_CONFIG_NAME = 'bhrelations_links'

default_bhrelations_links = {
    'children.label': 'is a child of',
    'dependency': 'dependson,dependent',
    'dependency.validators': 'NoCycles,SingleProduct',
    'dependson.blocks': 'true',
    'dependson.label': 'depends on',
    'dependent.label': 'is a dependency of',
    'oneway': 'refersto',
    'parent_children': 'parent,children',
    'parent.exclusive': 'true',
    'parent.label': 'is a parent of',
    'parent_children.validators': 'OneToMany,SingleProduct,NoCycles',
    'refersto.label': 'refers to',
    'duplicate': 'duplicateof,duplicatedby',
    'duplicate.validators': 'ReferencesOlder',
    'duplicateof.label': 'is a duplicate of',
    'duplicatedby.label': 'is duplicated by',
}


#TODO: consider making the interface part of future
# I[*|Resource]ChangingListener approach based on output from the
# correlated discussion in Trac community
# (http://trac.edgewall.org/ticket/11148)
class IRelationChangingListener(Interface):
    """
    Extension point interface for components that require notification
    when relations are created or deleted and database transaction is not
    yet committed. The interface can be used when database actions have to be
    made by listener must be performed within the same transaction as
    relations modification.

    Caution:
    Because the database transaction is not yet committed during the event
    notification, a long running listener activity may
    influence overall database performance or raise lock
    or transaction timeout errors. If component have to perform non-transaction
    activity, use IRelationChanged interface instead.

    If a listener raises an exception, all changes that were made within the
    transaction will not be applied.
    """

    def adding_relation(relation):
        """
        Called when a relation was added but transaction was not committed.
        """

    def deleting_relation(relation, when):
        """
        Called when a relation was added but transaction was not committed.
        """


class IRelationValidator(Interface):
    """
    Extension point interface for relation validators.
    """

    def validate(relation):
        """
        Validate the relation. If relation is not valid, raise appropriate
        exception.
        """


class EnvironmentSetup(Component):
    implements(IEnvironmentSetupParticipant, ISupportMultiProductEnvironment,
               ITemplateProvider)

    # IEnvironmentSetupParticipant methods

    def environment_created(self):
        self.upgrade_environment(self.env.db_transaction)

    def environment_needs_upgrade(self, db):
        """Detects if the installed db version matches the running system"""
        db_installed_version = self._get_version(db)

        db_version = db_default.DB_VERSION
        if db_installed_version > db_version:
            raise TracError("""Current db version (%d) newer than supported
                            by this version of the %s (%d)."""
                            % (db_installed_version, PLUGIN_NAME, db_version))
        needs_upgrade = db_installed_version < db_version or \
                        not list(self.config.options(RELATIONS_CONFIG_NAME))
        return needs_upgrade

    def upgrade_environment(self, db):
        self.log.debug("upgrading existing environment for %s plugin." %
                       PLUGIN_NAME)
        db_installed_version = self._get_version(db)
        if db_installed_version < 1:
            self._initialize_db(db)
            self._update_db_version(db, db_default.DB_VERSION)
            #add upgrade logic later if needed

        if not list(self.config.options(RELATIONS_CONFIG_NAME)):
            for option, value in default_bhrelations_links.iteritems():
                self.config.set(RELATIONS_CONFIG_NAME, option, value)
            self.config.save()
            print("Your environment has been upgraded with the default "
                  "[bhrelations_links] configuration.")

    def _get_version(self, db):
        """Finds the current version of the bloodhound database schema"""
        rows = db("""SELECT value FROM system WHERE name = %s
                  """, (db_default.DB_SYSTEM_KEY,))
        return int(rows[0][0]) if rows else -1

    def _update_db_version(self, db, version):
        old_version = self._get_version(db)
        if old_version != -1:
            self.log.info("Updating %s database schema from version %d to %d",
                          PLUGIN_NAME, old_version, version)
            db("""UPDATE system SET value=%s
                  WHERE name=%s""", (version, db_default.DB_SYSTEM_KEY))
        else:
            self.log.info("Initial %s database schema set to version %d",
                          PLUGIN_NAME, version)
            db("""INSERT INTO system (name, value) VALUES ('%s','%s')
                """ % (db_default.DB_SYSTEM_KEY, version))
        return version

    def _initialize_db(self, db):
        # pylint: disable=protected-access
        self.log.debug("creating initial db schema for %s.", PLUGIN_NAME)
        db_connector, dummy = DatabaseManager(self.env)._get_connector()
        for table in db_default.SCHEMA:
            for statement in db_connector.to_sql(table):
                db(statement)

    # ITemplateProviderMethods

    def get_templates_dirs(self):
        """provide the plugin templates"""
        return [resource_filename(__name__, 'templates')]

    def get_htdocs_dirs(self):
        return None


class RelationsSystem(Component):
    PARENT_RELATION_TYPE = 'parent'
    CHILDREN_RELATION_TYPE = 'children'

    changing_listeners = ExtensionPoint(IRelationChangingListener)
    all_validators = ExtensionPoint(IRelationValidator)
    global_validators = OrderedExtensionsOption(
        'bhrelations', 'global_validators',
        IRelationValidator,
        'NoSelfReferenceValidator, ExclusiveValidator, BlockerValidator',
        include_missing=False,
        doc="""Validators used to validate all relations,
        regardless of their type.""",
        doc_domain='bhrelations'
    )

    duplicate_relation_type = Option(
        'bhrelations',
        'duplicate_relation',
        'duplicateof',
        "Relation type to be used with the resolve as duplicate workflow.",
        doc_domain='bhrelations')

    def __init__(self):
        import pkg_resources
        locale_dir = pkg_resources.resource_filename(__name__, 'locale')
        add_domain(self.env.path, locale_dir)
        links, labels, validators, blockers, copy_fields, exclusive = \
            self._parse_config()
        self._links = links
        self._labels = labels
        self._validators = validators
        self._blockers = blockers
        self._copy_fields = copy_fields
        self._exclusive = exclusive

        self.link_ends_map = {}
        for end1, end2 in self.get_ends():
            self.link_ends_map[end1] = end2
            if end2 is not None:
                self.link_ends_map[end2] = end1

    def get_ends(self):
        return self._links

    def add(self,
            source_resource_instance,
            destination_resource_instance,
            relation_type,
            comment=None,
            author=None,
            when=None):
        source = ResourceIdSerializer.get_resource_id_from_instance(
            self.env, source_resource_instance)
        destination = ResourceIdSerializer.get_resource_id_from_instance(
            self.env, destination_resource_instance)
        if relation_type not in self.link_ends_map:
            raise UnknownRelationType(relation_type)
        if when is None:
            when = datetime.now(utc)
        relation = Relation(self.env)
        relation.source = source
        relation.destination = destination
        relation.type = relation_type
        relation.comment = comment
        relation.author = author
        relation.when = when
        self.add_relation(relation)
        return relation

    def get_reverted_relation(self, relation):
        """Return None if relation is one way"""
        other_end = self.link_ends_map[relation.type]
        if other_end:
            return relation.clone_reverted(other_end)

    def add_relation(self, relation):
        self.validate(relation)
        with self.env.db_transaction:
            relation.insert()
            reverted_relation = self.get_reverted_relation(relation)
            if reverted_relation:
                reverted_relation.insert()

            for listener in self.changing_listeners:
                listener.adding_relation(relation)

    def delete(self, relation_id, when=None):
        if when is None:
            when = datetime.now(utc)
        relation = Relation.load_by_relation_id(self.env, relation_id)
        source = relation.source
        destination = relation.destination
        relation_type = relation.type
        with self.env.db_transaction:
            cloned_relation = relation.clone()
            relation.delete()
            other_end = self.link_ends_map[relation_type]
            if other_end:
                reverted_relation = Relation(self.env, keys=dict(
                    source=destination,
                    destination=source,
                    type=other_end,
                ))
                reverted_relation.delete()

            for listener in self.changing_listeners:
                listener.deleting_relation(cloned_relation, when)

            from bhrelations.notification import RelationNotifyEmail
            RelationNotifyEmail(self.env).notify(cloned_relation, deleted=when)

    def delete_resource_relations(self, resource_instance):
        sql = "DELETE FROM " + Relation.get_table_name() + \
              " WHERE source=%s OR destination=%s"
        full_resource_id = ResourceIdSerializer.get_resource_id_from_instance(
            self.env, resource_instance)
        with self.env.db_transaction as db:
            db(sql, (full_resource_id, full_resource_id))

    def _debug_select(self):
        """The method is used for debug purposes"""
        sql = "SELECT id, source, destination, type FROM bloodhound_relations"
        with self.env.db_query as db:
            return [db(sql)]

    def get_relations(self, resource_instance):
        relation_list = []
        for relation in self._select_relations_for_resource_instance(
                resource_instance):
            relation_list.append(dict(
                relation_id=relation.get_relation_id(),
                destination_id=relation.destination,
                destination=ResourceIdSerializer.get_resource_by_id(
                    relation.destination),
                type=relation.type,
                comment=relation.comment,
                when=relation.when,
                author=relation.author,
            ))
        return relation_list

    def _select_relations_for_resource_instance(self, resource):
        resource_full_id = ResourceIdSerializer.get_resource_id_from_instance(
            self.env, resource)
        return self._select_relations(resource_full_id)

    def _select_relations(
            self, source=None, resource_type=None, destination=None):
        #todo: add optional paging for possible umbrella tickets with
        #a lot of child tickets
        where = dict()
        if source:
            where["source"] = source
        if resource_type:
            where["type"] = resource_type
            order_by = ["destination"]
        else:
            order_by = ["type", "destination"]
        if destination:
            where["destination"] = destination
        return Relation.select(
            self.env,
            where=where,
            order_by=order_by
        )

    def _parse_config(self):
        links = []
        labels = {}
        validators = {}
        blockers = {}
        copy_fields = {}
        exclusive = set()

        config = self.config[RELATIONS_CONFIG_NAME]
        for name in [option for option, _ in config.options()
                     if '.' not in option]:
            reltypes = config.getlist(name)
            if not reltypes:
                continue
            if len(reltypes) == 1:
                reltypes += [None]
            links.append(tuple(reltypes))

            custom_validators = self._parse_validators(config, name)
            for rel in filter(None, reltypes):
                labels[rel] = \
                    config.get(rel + '.label') or rel.capitalize()
                blockers[rel] = \
                    config.getbool(rel + '.blocks', default=False)
                if config.getbool(rel + '.exclusive'):
                    exclusive.add(rel)
                validators[rel] = custom_validators

                # <end>.copy_fields may be absent or intentionally set empty.
                # config.getlist() will return [] in either case, so check that
                # the key is present before assigning the value
                cf_key = '%s.copy_fields' % rel
                if cf_key in config:
                    copy_fields[rel] = config.getlist(cf_key)
        return links, labels, validators, blockers, copy_fields, exclusive

    def _parse_validators(self, section, name):
        custom_validators = set(
            '%sValidator' % validator for validator in
            set(section.getlist(name + '.validators', [], ',', True)))
        validators = []
        if custom_validators:
            for impl in self.all_validators:
                if impl.__class__.__name__ in custom_validators:
                    validators.append(impl)
        return validators

    def validate(self, relation):
        """
        Validate the relation using the configured validators. Validation is
        always run on the relation with master type.
        """
        backrel = self.get_reverted_relation(relation)
        if backrel and (backrel.type, relation.type) in self._links:
            relation = backrel

        for validator in self.global_validators:
            validator.validate(relation)

        for validator in self._validators.get(relation.type, ()):
            validator.validate(relation)

    def is_blocker(self, relation_type):
        return self._blockers[relation_type]

    def render_relation_type(self, end):
        return self._labels[end]

    def get_relation_types(self):
        return self._labels

    def find_blockers(self, resource_instance, is_blocker_method):
        # tbd: do we blocker finding to be recursive
        all_blockers = []
        for relation in self._select_relations_for_resource_instance(
                resource_instance):
            if self.is_blocker(relation.type):
                resource = ResourceIdSerializer.get_resource_by_id(
                    relation.destination)
                resource_instance = is_blocker_method(resource)
                if resource_instance is not None:
                    all_blockers.append(resource_instance)
                    # blockers = self._recursive_find_blockers(
                    #     relation, is_blocker_method)
                    # if blockers:
                    #     all_blockers.extend(blockers)
        return all_blockers

    def get_resource_name(self, resource_id):
        resource = ResourceIdSerializer.get_resource_by_id(resource_id)
        return get_resource_shortname(self.env, resource)


class ResourceIdSerializer(object):
    RESOURCE_ID_DELIMITER = u":"

    @classmethod
    def get_resource_by_id(cls, resource_full_id):
        """
        * resource_full_id: fully qualified resource id in format
        "product:ticket:123". In case of global environment it is ":ticket:123"
        """
        nbh_prefix, realm, resource_id = cls.split_full_id(resource_full_id)
        if nbh_prefix:
            neighborhood = Neighborhood('product', nbh_prefix)
            return neighborhood.child(realm, id=resource_id)
        else:
            return Resource(realm, id=resource_id)

    @classmethod
    def split_full_id(cls, resource_full_id):
        return resource_full_id.split(cls.RESOURCE_ID_DELIMITER)

    @classmethod
    def get_resource_id_from_instance(cls, env, resource_instance):
        """
        * resource_instance: can be instance of a ticket, wiki page etc.
        """
        resource = resource_instance.resource
        # nbhprefix = ResourceSystem(env).neighborhood_prefix(
        #     resource.neighborhood)

        #TODO: temporary workaround for the ticket specific behavior
        #change it to generic resource behaviour
        ticket = resource_instance
        if ticket.id is None:
            raise ValueError("Cannot get resource id for ticket "
                             "that does not exist yet.")
        nbh_prefix = ticket["product"]

        resource_full_id = cls.RESOURCE_ID_DELIMITER.join(
            (nbh_prefix, resource.realm, unicode(resource.id))
        )
        return resource_full_id


class TicketRelationsSpecifics(Component):
    implements(ITicketManipulator, ITicketChangeListener)

    def __init__(self):
        self.rls = RelationsSystem(self.env)

    #ITicketChangeListener methods
    def ticket_created(self, ticket):
        pass

    def ticket_changed(self, ticket, comment, author, old_values):
        if self._closed_as_duplicate(ticket) and \
                self.rls.duplicate_relation_type and \
                hasattr(ticket, 'duplicate'):  # workaround for comment:5:ticket:710
            try:
                self.rls.add(ticket, ticket.duplicate,
                             self.rls.duplicate_relation_type,
                             comment, author)
            except TracError:
                pass

    def _closed_as_duplicate(self, ticket):
        return (ticket['status'] == 'closed' and
                ticket['resolution'] == 'duplicate')

    def ticket_deleted(self, ticket):
        self.rls.delete_resource_relations(ticket)

    #ITicketManipulator methods
    def prepare_ticket(self, req, ticket, fields, actions):
        pass

    def validate_ticket(self, req, ticket):
        return itertools.chain(
            self._check_blockers(req, ticket),
            self._check_open_children(req, ticket),
            self._check_duplicate_id(req, ticket),
        )

    def _check_blockers(self, req, ticket):
        action = req.args.get('action')
        operations = self._get_operations_for_action(req, ticket, action)
        if 'set_resolution' in operations:
            blockers = self.rls.find_blockers(ticket, self.is_blocker)
            if blockers:
                blockers_str = ', '.join(
                    get_resource_shortname(self.env, blocker_ticket.resource)
                    for blocker_ticket in unique(blockers))
                msg = ("Cannot resolve this ticket because it is "
                       "blocked by tickets [%s]"
                       % blockers_str)
                yield None, msg

    def _check_open_children(self, req, ticket):
        action = req.args.get('action')
        operations = self._get_operations_for_action(req, ticket, action)
        if 'set_resolution' in operations:
            for relation in [r for r in self.rls.get_relations(ticket)
                             if r['type'] == self.rls.PARENT_RELATION_TYPE]:
                child_ticket = \
                    self._create_ticket_by_full_id(relation['destination'])
                if child_ticket['status'] != 'closed':
                    msg = ("Cannot resolve this ticket because it has open "
                           "child tickets.")
                    yield None, msg

    def _check_duplicate_id(self, req, ticket):
        action = req.args.get('action')
        operations = self._get_operations_for_action(req, ticket, action)
        if 'set_resolution' in operations:
            resolution = req.args.get('action_%s_resolve_resolution' % action)
            if resolution == 'duplicate':
                duplicate_id = req.args.get('duplicate_id')
                if not duplicate_id:
                    yield None, "Duplicate ticket ID must be provided."

                try:
                    duplicate_ticket = self.find_ticket(duplicate_id)
                    req.perm.require('TICKET_MODIFY',
                                     Resource(duplicate_ticket.id))
                    ticket.duplicate = duplicate_ticket
                except NoSuchTicketError:
                    yield None, "Invalid duplicate ticket ID."

    def _get_operations_for_action(self, req, ticket, action):
        operations = []
        for controller in TicketSystem(self.env).action_controllers:
            actions = [a for w, a in
                       controller.get_ticket_actions(req, ticket) or []]
            if action in actions:
                operations += controller.actions[action]['operations']
        return operations

    def find_ticket(self, ticket_spec):
        ticket = None
        m = re.match(r'#?(?:(?P<pid>[^-]+)-)?(?P<tid>\d+)', ticket_spec)
        if m:
            pid = m.group('pid')
            tid = m.group('tid')
            if pid:
                try:
                    env = ProductEnvironment(self.env.parent, pid)
                    ticket = Ticket(env, tid)
                except:
                    pass
            else:
                try:
                    ticket = Ticket(self.env, tid)
                except ResourceNotFound:
                    # ticket not found in current product, try all other products
                    for p in Product.select(self.env):
                        if p.prefix != self.env.product.prefix:
                            # TODO: check for PRODUCT_VIEW permissions
                            penv = ProductEnvironment(self.env.parent,
                                                      p.prefix)
                            try:
                                ticket = Ticket(penv, tid)
                            except ResourceNotFound:
                                pass
                            else:
                                break

        # ticket still not found, use fallback for <prefix>:ticket:<id> syntax
        if ticket is None:
            try:
                resource = ResourceIdSerializer.get_resource_by_id(ticket_spec)
                ticket = self._create_ticket_by_full_id(resource)
            except:
                raise NoSuchTicketError
        return ticket

    def is_blocker(self, resource):
        ticket = self._create_ticket_by_full_id(resource)
        if ticket['status'] != 'closed':
            return ticket
        return None

    def _create_ticket_by_full_id(self, resource):
        env = self._get_env_for_resource(resource)
        if resource.realm == "ticket":
            return Ticket(env, resource.id)
        else:
            raise TracError("Resource type %s is not supported by " +
                            "Bloodhound Relations" % resource.realm)

    def _get_env_for_resource(self, resource):
        if hasattr(resource, "neighborhood"):
            env = ResourceSystem(self.env). \
                    load_component_manager(resource.neighborhood)
        else:
            env = self.env
        return env


class TicketChangeRecordUpdater(Component):
    implements(IRelationChangingListener)

    def adding_relation(self, relation):
        self.update_tickets_change_records(
            relation, False, relation.time)

    def deleting_relation(self, relation, when):
        when_ts = to_utimestamp(when)
        self.update_tickets_change_records(relation, True, when_ts)

    def update_tickets_change_records(self, relation, is_delete, when_ts):
        relation_system = RelationsSystem(self.env)
        with self.env.db_direct_transaction as db:
            self._add_ticket_change_record(
                db,
                relation,
                relation_system,
                is_delete,
                when_ts
            )

            reverted_relation = relation_system.get_reverted_relation(relation)
            if reverted_relation:
                self._add_ticket_change_record(
                    db,
                    reverted_relation,
                    relation_system,
                    is_delete,
                    when_ts
                )

    def _get_ticket_id_and_product(self, resource_full_id):
        nbh_prefix, realm, resource_id = \
            ResourceIdSerializer.split_full_id(resource_full_id)
        ticket_id = None
        if realm == "ticket":
            ticket_id = int(resource_id)
        return ticket_id, nbh_prefix

    def _add_ticket_change_record(
            self, db, relation, relation_system, is_delete, when_ts):
        ticket_id, product = self._get_ticket_id_and_product(relation.source)
        if ticket_id is None:
            return

        related_resource_name = relation_system.get_resource_name(
            relation.destination)
        if is_delete:
            old_value = related_resource_name
            new_value = None
        else:
            old_value = None
            new_value = related_resource_name
        description = 'Relation "%s"' % (
            relation_system.render_relation_type(relation.type),)

        db("""INSERT INTO ticket_change
            (ticket, time, author, field, oldvalue, newvalue, product)
            VALUES (%s, %s, %s, %s, %s, %s, %s)""",
           (ticket_id,
            when_ts,
            relation.author,
            description,
            old_value,
            new_value,
            product))


class UnknownRelationType(ValueError):
    pass


class NoSuchTicketError(ValueError):
    pass

########NEW FILE########
__FILENAME__ = db_default
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from bhrelations.model import Relation

DB_SYSTEM_KEY = 'bhrelations'
DB_VERSION = 2

# pylint: disable=protected-access
SCHEMA = [mcls._get_schema() for mcls in (Relation, )]

migrations = [
]

########NEW FILE########
__FILENAME__ = model
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.resource import Resource
from trac.util.datefmt import to_utimestamp, from_utimestamp

from bhdashboard.model import ModelBase


class Relation(ModelBase):
    """The Relation table"""
    RELATION_ID_DELIMITER = u','

    _meta = {
        'table_name': 'bloodhound_relations',
        'object_name': 'Relation',
        'key_fields': ['source', 'type', 'destination'],
        'non_key_fields': [
            'comment',
            'author',
            {'name': 'time', 'type': 'int64'},
        ],
        'no_change_fields': ['source', 'destination', 'type'],
        'unique_fields': [],
    }

    @property
    def resource(self):
        """Allow Relation to be treated as a Resource"""
        return Resource('relation', self.prefix)

    @property
    def when(self):
        when_ts = self._data.get('time')
        if when_ts is not None:
            return from_utimestamp(when_ts)
        return None

    @when.setter
    def when(self, value):
        when_ts = to_utimestamp(value)
        self._data["time"] = when_ts

    def clone_reverted(self, type):
        data = self._data.copy()
        data['type'] = type
        data['source'] = self.destination
        data['destination'] = self.source
        relation = Relation(self._env)
        # pylint: disable=protected-access
        relation._data = data
        return relation

    def clone(self):
        data = self._data.copy()
        relation = Relation(self._env)
        # pylint: disable=protected-access
        relation._data = data
        return relation

    def get_relation_id(self):
        return self.RELATION_ID_DELIMITER.join((
            self.source,
            self.destination,
            self.type))

    @classmethod
    def _parse_relation_id(cls, relation_id):
        source, destination, relation_type = relation_id.split(
            cls.RELATION_ID_DELIMITER)
        return source, destination, relation_type

    @classmethod
    def load_by_relation_id(cls, env, relation_id):
        source, destination, relation_type = cls._parse_relation_id(
            relation_id)
        return Relation(env, keys=dict(
            source=source,
            destination=destination,
            type=relation_type
        ))

    def __str__(self):
        return '%s %s %s' % (self.source, self.type, self.destination)

########NEW FILE########
__FILENAME__ = notification
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.notification import NotifyEmail
from trac.ticket.notification import TicketNotifyEmail, \
                                     get_ticket_notification_recipients
from trac.util.datefmt import from_utimestamp
from trac.web.chrome import Chrome

from bhrelations.api import ResourceIdSerializer, TicketRelationsSpecifics


class RelationNotifyEmail(TicketNotifyEmail):
    template_name = "relation_notify_email.txt"

    imitate_ticket_notification = False

    def notify(self, relation, deleted=False):
        self.relation = relation
        source = ResourceIdSerializer.get_resource_by_id(relation.source)
        if source.realm == 'ticket':
            self.imitate_ticket_notification = True
            helper = TicketRelationsSpecifics(self.env)
            t = helper._create_ticket_by_full_id(source)
            self.template = Chrome(self.env).load_template(
                TicketNotifyEmail.template_name, method='text')
            if deleted:
                modtime = deleted
            else:
                modtime = from_utimestamp(relation.time)
            TicketNotifyEmail.notify(self, t, newticket=False, modtime=modtime)
        else:
            self._generic_notify(relation, deleted)

    def _generic_notify(self, relation, deleted):
        self.data.update(dict(
            created=not deleted,
            relation=relation,
        ))
        NotifyEmail.notify(self, '', '', '')

    def send(self, torcpts, ccrcpts):
        if self.imitate_ticket_notification:
            TicketNotifyEmail.send(self, torcpts, ccrcpts)
        else:
            NotifyEmail.send(self, torcpts, ccrcpts)

    def get_recipients(self, relid):
        relation = self.relation
        source, destination = map(ResourceIdSerializer.get_resource_by_id,
                                  (relation.source, relation.destination))
        to, cc = [], []
        for resource in (source, destination):
            if resource.realm == 'ticket':
                torecipients, ccrecipients, reporter, owner = \
                    get_ticket_notification_recipients(self.env, self.config,
                    resource.id, [])
                to.extend(torecipients)
                cc.extend(ccrecipients)
        return to, cc

########NEW FILE########
__FILENAME__ = search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.core import Component, implements

from bhsearch.api import IDocIndexPreprocessor
from bhsearch.search_resources.ticket_search import TicketIndexer

from bhrelations.api import RelationsSystem, ResourceIdSerializer,\
    IRelationChangingListener, TicketRelationsSpecifics


class RelationsDocPreprocessor(Component):
    implements(IDocIndexPreprocessor)

    def pre_process(self, doc):
        resource_id = ':'.join([
            doc.get('product', ''), doc.get('type', ''), doc.get('id')])

        try:
            rls = RelationsSystem(self.env)
            relations = []
            for relation in rls._select_relations(resource_id):
                relations.extend(self._format_relations(relation))
            doc['relations'] = ','.join(relations)
        except self.env.db_exc.OperationalError:
            # If bhrelations and bhsearch are installed at the same time and
            # bhsearch is upgraded before bhrelations, table
            # bloodhound_relations will be missing, thus causing the
            # OperationalError. As this means that the relations do not
            # exist yet, just skip indexing them.
            self.log.debug("Not indexing relations for %s", resource_id)

    def _format_relations(self, relation):
        ris = ResourceIdSerializer
        product, realm, res_id = ris.split_full_id(relation.destination)

        if realm == 'ticket':
            yield '%s:#%s' % (relation.type, res_id)
            yield '%s:#%s-%s' % (relation.type, product, res_id)
        elif realm == 'wiki':
            yield '%s:%s' % (relation.type, res_id)


class RelationSearchUpdater(Component):
    implements(IRelationChangingListener)

    def adding_relation(self, relation):
        self._reindex_endpoints(relation)

    def deleting_relation(self, relation, when):
        self._reindex_endpoints(relation)

    def _reindex_endpoints(self, relation):
        trs = TicketRelationsSpecifics(self.env)
        ticket_indexer = TicketIndexer(self.env)
        for resource in map(ResourceIdSerializer.get_resource_by_id,
                            (relation.source, relation.destination)):
            if resource.realm == 'ticket':
                ticket = trs._create_ticket_by_full_id(resource)
                ticket_indexer._index_ticket(ticket)

########NEW FILE########
__FILENAME__ = api
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest
from datetime import datetime

from trac.core import TracError
from trac.ticket.model import Ticket
from trac.util.datefmt import utc

from multiproduct.env import ProductEnvironment

from bhrelations.api import TicketRelationsSpecifics
from bhrelations.tests.mocks import TestRelationChangingListener
from bhrelations.validation import ValidationError
from bhrelations.tests.base import BaseRelationsTestCase, BLOCKED_BY, \
                                   BLOCKS, CHILD, DEPENDENCY_OF, DEPENDS_ON, \
                                   DUPLICATE_OF, MULTIPRODUCT_REL, PARENT, \
                                   REFERS_TO


class ApiTestCase(BaseRelationsTestCase):
    def test_can_add_two_ways_relations(self):
        #arrange
        ticket = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(ticket, DEPENDENCY_OF, ticket2)
        #assert
        relations = self.get_relations(ticket)
        self.assertEqual(DEPENDENCY_OF, relations[0]["type"])
        self.assertEqual(unicode(ticket2.id), relations[0]["destination"].id)

        relations = self.get_relations(ticket2)
        self.assertEqual(DEPENDS_ON, relations[0]["type"])
        self.assertEqual(unicode(ticket.id), relations[0]["destination"].id)

    def test_can_add_single_way_relations(self):
        #arrange
        ticket = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(ticket, REFERS_TO, ticket2)
        #assert
        relations = self.get_relations(ticket)
        self.assertEqual(1, len(relations))
        self.assertEqual(REFERS_TO, relations[0]["type"])
        self.assertEqual(unicode(ticket2.id), relations[0]["destination"].id)

        self.assertEqual(0, len(self.get_relations(ticket2)))

    def test_can_add_multiple_relations(self):
        #arrange
        ticket = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        ticket3 = self._insert_and_load_ticket("A3")
        #act
        self.add_relation(ticket, DEPENDS_ON, ticket2)
        self.add_relation(ticket, DEPENDS_ON, ticket3)
        #assert
        self.assertEqual(2, len(self.get_relations(ticket)))
        self.assertEqual(1, len(self.get_relations(ticket2)))
        self.assertEqual(1, len(self.get_relations(ticket3)))

    def test_will_not_create_more_than_one_identical_relations(self):
        #arrange
        ticket = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(ticket, DEPENDS_ON, ticket2)
        self.assertRaisesRegexp(
            TracError,
            "already exists",
            self.add_relation,
            ticket, DEPENDS_ON, ticket2
        )

    def test_will_not_create_more_than_one_identical_relations_db_level(self):
        sql = """INSERT INTO bloodhound_relations (source, destination, type)
                    VALUES (%s, %s, %s)"""
        with self.env.db_transaction as db:
            db(sql, ["1", "2", DEPENDS_ON])
            self.assertRaises(
                self.env.db_exc.IntegrityError,
                db,
                sql,
                ["1", "2", DEPENDS_ON]
            )

    def test_can_add_one_way_relations(self):
        #arrange
        ticket = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(ticket, REFERS_TO, ticket2)
        #assert
        relations = self.get_relations(ticket)
        self.assertEqual(REFERS_TO, relations[0]["type"])
        self.assertEqual(unicode(ticket2.id),
                         relations[0]["destination"].id)

        self.assertEqual(0, len(self.get_relations(ticket2)))

    def test_can_delete_two_ways_relation(self):
        #arrange
        ticket = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        self.add_relation(ticket, DEPENDS_ON, ticket2)

        relations = self.get_relations(ticket)
        self.assertEqual(1, len(relations))
        self.assertEqual(1, len(self.get_relations(ticket2)))

        #act
        self.delete_relation(relations[0])
        #assert
        self.assertEqual(0, len(self.get_relations(ticket)))
        self.assertEqual(0, len(self.get_relations(ticket2)))

    def test_can_delete_single_way_relation(self):
        #arrange
        ticket = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(ticket, REFERS_TO, ticket2)

        relations = self.get_relations(ticket)
        self.assertEqual(1, len(relations))
        self.assertEqual(0, len(self.get_relations(ticket2)))
        #act
        self.delete_relation(relations[0])
        #assert
        self.assertEqual(0, len(self.get_relations(ticket)))

    def test_can_not_add_cycled_immediate_relations(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(ticket1, DEPENDS_ON, ticket2)

        try:
            self.add_relation(ticket2, DEPENDS_ON, ticket1)
            self.fail("Should throw an exception")
        except ValidationError as ex:
            self.assertSequenceEqual(
                ["tp1:ticket:2", "tp1:ticket:1"], ex.failed_ids)

    def test_can_add_more_depends_ons(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        ticket3 = self._insert_and_load_ticket("A3")
        #act
        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        self.add_relation(ticket1, DEPENDS_ON, ticket3)

        self.assertEqual(2, len(self.get_relations(ticket1)))

    def test_can_not_add_cycled_in_different_direction(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        self.assertRaises(
            ValidationError,
            self.add_relation,
            ticket1, DEPENDENCY_OF, ticket2
        )

    def test_can_not_add_cycled_relations(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        ticket3 = self._insert_and_load_ticket("A3")
        #act
        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        self.add_relation(ticket2, DEPENDS_ON, ticket3)
        self.assertRaises(
            ValidationError,
            self.add_relation,
            ticket3, DEPENDS_ON, ticket1
        )

    def test_can_not_add_more_than_one_parent(self):
        #arrange
        child = self._insert_and_load_ticket("A1")
        parent1 = self._insert_and_load_ticket("A2")
        parent2 = self._insert_and_load_ticket("A3")
        #act
        self.add_relation(parent1, PARENT, child)
        self.assertRaises(
            ValidationError,
            self.add_relation,
            parent2, PARENT, child
        )

        self.assertRaises(
            ValidationError,
            self.add_relation,
            child, CHILD, parent2
        )

    def test_can_add_more_than_one_child(self):
        parent = self._insert_and_load_ticket("A1")
        child1 = self._insert_and_load_ticket("A2")
        child2 = self._insert_and_load_ticket("A3")

        self.add_relation(parent, PARENT, child1)
        self.add_relation(parent, PARENT, child2)
        self.assertEqual(2, len(self.get_relations(parent)))

    def test_ticket_can_be_resolved(self):
        #arrange
        parent = self._insert_and_load_ticket("A1")
        child = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(parent, PARENT, child)

        self.req.args['action'] = 'resolve'
        warnings = \
            TicketRelationsSpecifics(self.env).validate_ticket(self.req, child)
        self.assertEqual(0, len(list(warnings)))

    def test_can_save_and_load_relation_time(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        time = datetime.now(utc)
        self.add_relation(ticket1, DEPENDS_ON, ticket2, when=time)
        relations = self.get_relations(ticket1)
        #assert
        self.assertEqual(time, relations[0]["when"])

    def test_cannot_resolve_ticket_when_blocker_is_unresolved(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        #act
        self.req.args["action"] = 'resolve'
        warnings = TicketRelationsSpecifics(self.env).validate_ticket(
            self.req, ticket1)
        #asset
        self.assertEqual(1, len(list(warnings)))

    def test_can_resolve_ticket_when_blocker_is_resolved(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2", status="closed")
        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        #act
        self.req.args["action"] = 'resolve'
        warnings = TicketRelationsSpecifics(self.env).validate_ticket(
            self.req, ticket1)
        #assert
        self.assertEqual(0, len(list(warnings)))

    def test_that_relations_are_deleted_when_ticket_is_deleted(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")

        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        self.assertEqual(1, len(self.get_relations(ticket2)))
        #act
        ticket1.delete()
        #assert
        self.assertEqual(0, len(self.get_relations(ticket2)))

    def test_that_no_error_when_deleting_ticket_without_relations(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        #act
        ticket1.delete()

    def test_can_add_multi_product_relations(self):

        ticket1 = self._insert_and_load_ticket("A1")
        product2 = "tp2"
        self._load_product_from_data(self.global_env, product2)
        p2_env = ProductEnvironment(self.global_env, product2)
        ticket2 = self._insert_and_load_ticket_with_env(p2_env, "A2")

        self.add_relation(ticket1, MULTIPRODUCT_REL, ticket2)

        self.assertEqual(1, len(self.get_relations(ticket1)))
        self.assertEqual(1, len(self.get_relations(ticket2)))

    def _debug_select(self):
        """
        used for debug purposes
        """
        print " source, destination, type"
        sql = "SELECT source, destination, type FROM bloodhound_relations"
        with self.env.db_query as db:
            # for row in db(sql, ("source", "destination", "type")):
            for row in db(sql):
                print row

    def test_parent_relation_is_incompatible_with_two_way_relations(self):
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        self.add_relation(ticket2, DEPENDS_ON, ticket1)

        self.assertRaises(
            ValidationError,
            self.add_relation,
            ticket1, PARENT, ticket2
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            ticket1, CHILD, ticket2
        )

    def test_parent_relation_is_incompatible_with_one_way_relations(self):
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        self.add_relation(ticket1, REFERS_TO, ticket2)

        self.assertRaises(
            ValidationError,
            self.add_relation,
            ticket1, PARENT, ticket2
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            ticket1, CHILD, ticket2
        )

    def test_parent_must_be_in_same_product(self):
        ticket1 = self._insert_and_load_ticket("A1")
        product2 = "tp2"
        self._load_product_from_data(self.global_env, product2)
        p2_env = ProductEnvironment(self.global_env, product2)
        ticket2 = self._insert_and_load_ticket_with_env(p2_env, "A2")

        self.assertRaises(
            ValidationError,
            self.add_relation,
            ticket1, PARENT, ticket2
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            ticket1, CHILD, ticket2
        )

    def test_cannot_create_other_relations_between_descendants(self):
        t1, t2, t3, t4, t5 = map(self._insert_and_load_ticket, "12345")
        self.add_relation(t1, PARENT, t2)   #    t1 -> t2
        self.add_relation(t2, PARENT, t3)   #         /  \
        self.add_relation(t2, PARENT, t4)   #       t3    t4

        self.assertRaises(
            ValidationError,
            self.add_relation,
            t2, DEPENDS_ON, t1
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            t1, DEPENDS_ON, t2
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            t4, DEPENDS_ON, t1
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            t1, DEPENDS_ON, t3
        )
        try:
            self.add_relation(t1, DEPENDS_ON, t5)
            self.add_relation(t3, DEPENDS_ON, t4)
        except ValidationError:
            self.fail("Could not add valid relation.")

    def test_cannot_add_parent_if_this_would_cause_invalid_relations(self):
        t1, t2, t3, t4, t5 = map(self._insert_and_load_ticket, "12345")
        self.add_relation(t1, PARENT, t2)   #    t1 -> t2
        self.add_relation(t2, PARENT, t3)   #         /  \
        self.add_relation(t2, PARENT, t4)   #       t3    t4    t5
        self.add_relation(t2, DEPENDS_ON, t5)

        self.assertRaises(
            ValidationError,
            self.add_relation,
            t2, PARENT, t5
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            t3, PARENT, t5
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            t5, PARENT, t1,
        )
        try:
            self.add_relation(t1, PARENT, t5)
        except ValidationError:
            self.fail("Could not add valid relation.")

    def test_cannot_close_ticket_with_open_children(self):
        t1 = self._insert_and_load_ticket("1")                    #     t1
        t2 = self._insert_and_load_ticket("2", status='closed')   #   /  |  \
        t3 = self._insert_and_load_ticket("3")                    #  t2 t3  t4
        t4 = self._insert_and_load_ticket("4")
        self.add_relation(t1, PARENT, t2)
        self.add_relation(t1, PARENT, t3)
        self.add_relation(t1, PARENT, t4)

        # A warning is be returned for each open ticket
        self.req.args["action"] = 'resolve'
        warnings = \
            TicketRelationsSpecifics(self.env).validate_ticket(self.req, t1)

        self.assertEqual(2, len(list(warnings)))

    def test_duplicate_can_only_reference_older_ticket(self):
        t1 = self._insert_and_load_ticket("1")
        t2 = self._insert_and_load_ticket("2")

        self.assertRaises(
            ValidationError,
            self.add_relation,
            t1, DUPLICATE_OF, t2
        )
        self.add_relation(t2, DUPLICATE_OF, t1)

    def test_detects_blocker_cycles(self):
        t1, t2, t3, t4, t5 = map(self._insert_and_load_ticket, "12345")
        self.add_relation(t1, BLOCKS, t2)
        self.add_relation(t3, DEPENDS_ON, t2)
        self.add_relation(t4, BLOCKED_BY, t3)
        self.add_relation(t4, DEPENDENCY_OF, t5)

        self.assertRaises(
            ValidationError,
            self.add_relation,
            t2, BLOCKS, t1
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            t3, DEPENDENCY_OF, t1
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            t1, BLOCKED_BY, t2
        )
        self.assertRaises(
            ValidationError,
            self.add_relation,
            t1, DEPENDS_ON, t5
        )

        self.add_relation(t1, DEPENDENCY_OF, t2)
        self.add_relation(t2, BLOCKS, t3)
        self.add_relation(t4, DEPENDS_ON, t3)
        self.add_relation(t5, BLOCKED_BY, t4)

        self.add_relation(t1, REFERS_TO, t2)
        self.add_relation(t2, REFERS_TO, t1)

    def test_can_find_ticket_by_id_from_same_env(self):
        """ Can find ticket given #id"""
        product2 = "tp2"
        self._load_product_from_data(self.global_env, product2)
        p2_env = ProductEnvironment(self.global_env, product2)
        t1 = self._insert_and_load_ticket_with_env(p2_env, "T1")
        trs = TicketRelationsSpecifics(p2_env)

        ticket = trs.find_ticket("#%d" % t1.id)

        self.assertEqual(ticket.id, 1)

    def test_can_find_ticket_by_id_from_different_env(self):
        """ Can find ticket from different env given #id"""
        product2 = "tp2"
        self._load_product_from_data(self.global_env, product2)
        p2_env = ProductEnvironment(self.global_env, product2)
        t1 = self._insert_and_load_ticket_with_env(p2_env, "T1")
        trs = TicketRelationsSpecifics(self.env)

        ticket = trs.find_ticket("#%d" % t1.id)

        self.assertEqual(ticket.id, 1)

    def test_can_find_ticket_by_product_and_id(self):
        """ Can find ticket given #prefix-id"""
        product2 = "tp2"
        self._load_product_from_data(self.global_env, product2)
        p2_env = ProductEnvironment(self.global_env, product2)
        t1 = self._insert_and_load_ticket_with_env(p2_env, "T1")
        trs = TicketRelationsSpecifics(self.env)

        ticket = trs.find_ticket("#%s-%d" % (product2, t1.id))

        self.assertEqual(ticket.id, 1)


class RelationChangingListenerTestCase(BaseRelationsTestCase):
    def test_can_sent_adding_event(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        test_changing_listener = self.env[TestRelationChangingListener]
        #act
        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        #assert
        self.assertEqual("adding_relation", test_changing_listener.action)
        relation = test_changing_listener.relation
        self.assertEqual(DEPENDS_ON, relation.type)

    def test_can_sent_deleting_event(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        test_changing_listener = self.env[TestRelationChangingListener]
        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        #act
        relations = self.get_relations(ticket1)
        self.delete_relation(relations[0])
        #assert
        self.assertEqual("deleting_relation", test_changing_listener.action)
        relation = test_changing_listener.relation
        self.assertEqual(DEPENDS_ON, relation.type)


class TicketChangeRecordUpdaterTestCase(BaseRelationsTestCase):
    def test_can_update_ticket_history_on_relation_add_on(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")
        #act
        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        #assert
        change_log1 = Ticket(self.env, ticket1.id).get_changelog()
        self.assertEquals(1, len(change_log1))

        change_log2 = Ticket(self.env, ticket2.id).get_changelog()
        self.assertEquals(1, len(change_log2))

    def test_can_update_ticket_history_on_relation_deletion(self):
        #arrange
        ticket1 = self._insert_and_load_ticket("A1")
        ticket2 = self._insert_and_load_ticket("A2")

        self.add_relation(ticket1, DEPENDS_ON, ticket2)
        relations = self.get_relations(ticket1)
        #act
        self.delete_relation(relations[0])
        #assert
        change_log1 = Ticket(self.env, ticket1.id).get_changelog()
        self.assertEquals(2, len(change_log1))

        change_log2 = Ticket(self.env, ticket2.id).get_changelog()
        self.assertEquals(2, len(change_log2))

    def _debug_select(self, ticket_id=None):
        """
        used for debug purposes
        """
        # print " source, destination, type"
        sql = "SELECT * FROM ticket_change"
        print "db_direct_transaction result:"
        with self.env.db_direct_transaction as db:
            # for row in db(sql, ("source", "destination", "type")):
            for row in db(sql):
                print row

        sql = "SELECT * FROM ticket_change"
        print "db_transaction result:"
        with self.env.db_transaction as db:
            for row in db(sql):
                print row

        if ticket_id:
            sql = """SELECT time, author, field, oldvalue, newvalue
                     FROM ticket_change WHERE ticket=%s"""
            print "db_transaction select by ticket_id result:"
            with self.env.db_transaction:
                for row in self.env.db_query(sql, (ticket_id, )):
                    print row


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(ApiTestCase))
    test_suite.addTest(unittest.makeSuite(RelationChangingListenerTestCase))
    test_suite.addTest(unittest.makeSuite(TicketChangeRecordUpdaterTestCase))
    return test_suite


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = base
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from tests.env import MultiproductTestCase
from trac.test import EnvironmentStub, Mock, MockPerm
from trac.ticket import Ticket
from trac.util.datefmt import utc

from multiproduct.env import ProductEnvironment

from bhrelations.api import EnvironmentSetup, RelationsSystem, \
                            RELATIONS_CONFIG_NAME

try:
    from babel import Locale
    locale_en = Locale.parse('en_US')
except ImportError:
    locale_en = None


PARENT = "parent"
CHILD = "child"
REFERS_TO = "refersto"
DEPENDS_ON = "dependson"
DEPENDENCY_OF = "dependent"
DUPLICATE_OF = "duplicateof"
DUPLICATED_BY = "duplicatedby"
BLOCKED_BY = "blockedby"
BLOCKS = "blocks"
MULTIPRODUCT_REL = "mprel"
MULTIPRODUCT_BACKREL = "mpbackrel"


class BaseRelationsTestCase(MultiproductTestCase):
    def setUp(self, enabled=()):
        env = EnvironmentStub(
            default_data=True,
            enable=(['trac.*', 'multiproduct.*', 'bhrelations.*'] +
                    list(enabled))
        )
        env.config.set('bhrelations', 'global_validators',
                       'NoSelfReferenceValidator,ExclusiveValidator,'
                       'BlockerValidator')
        env.config.set('bhrelations', 'duplicate_relation',
                       'duplicateof')
        config_name = RELATIONS_CONFIG_NAME
        env.config.set(config_name, 'dependency',
                       ','.join([DEPENDS_ON, DEPENDENCY_OF]))
        env.config.set(config_name, 'dependency.validators',
                       'NoCycles,SingleProduct')
        env.config.set(config_name, 'dependson.blocks', 'true')
        env.config.set(config_name, 'parent_children',
                       ','.join([PARENT, CHILD]))
        env.config.set(config_name, 'parent_children.validators',
                       'OneToMany,SingleProduct,NoCycles')
        env.config.set(config_name, 'children.label', 'Overridden')
        env.config.set(config_name, 'parent.copy_fields',
                       'summary, foo')
        env.config.set(config_name, 'parent.exclusive', 'true')
        env.config.set(config_name, 'multiproduct_relation',
                       ','.join([MULTIPRODUCT_REL, MULTIPRODUCT_BACKREL]))
        env.config.set(config_name, 'oneway', REFERS_TO)
        env.config.set(config_name, 'duplicate',
                       ','.join([DUPLICATE_OF, DUPLICATED_BY]))
        env.config.set(config_name, 'duplicate.validators', 'ReferencesOlder')
        env.config.set(config_name, 'duplicateof.label', 'is a duplicate of')
        env.config.set(config_name, 'duplicatedby.label', 'duplicates')
        env.config.set(config_name, 'blocker', ','.join([BLOCKED_BY, BLOCKS]))
        env.config.set(config_name, 'blockedby.blocks', 'true')

        self.global_env = env
        self._upgrade_mp(self.global_env)
        self._setup_test_log(self.global_env)
        self._load_product_from_data(self.global_env, self.default_product)
        self.env = ProductEnvironment(self.global_env, self.default_product)

        self.req = Mock(href=self.env.href, authname='anonymous', tz=utc,
                        args=dict(action='dummy'),
                        locale=locale_en, lc_time=locale_en,
                        chrome={'warnings': []})
        self.req.perm = MockPerm()
        self.relations_system = RelationsSystem(self.env)
        self._upgrade_env()

    def tearDown(self):
        self.global_env.reset_db()

    def _upgrade_env(self):
        environment_setup = EnvironmentSetup(self.env)
        try:
            environment_setup.upgrade_environment(self.env.db_transaction)
        except self.env.db_exc.OperationalError:
            # table remains but database version is deleted
            pass

    @classmethod
    def _insert_ticket(cls, env, summary, **kw):
        """Helper for inserting a ticket into the database"""
        ticket = Ticket(env)
        ticket["summary"] = summary
        for k, v in kw.items():
            ticket[k] = v
        return ticket.insert()

    def _insert_and_load_ticket(self, summary, **kw):
        return Ticket(self.env, self._insert_ticket(self.env, summary, **kw))

    def _insert_and_load_ticket_with_env(self, env, summary, **kw):
        return Ticket(env, self._insert_ticket(env, summary, **kw))

    def add_relation(self, source, reltype, destination, *args, **kwargs):
        return self.relations_system.add(source, destination, reltype,
                                         *args, **kwargs)

    def get_relations(self, ticket):
        return self.relations_system.get_relations(ticket)

    def delete_relation(self, relation):
        self.relations_system.delete(relation["relation_id"])

########NEW FILE########
__FILENAME__ = mocks
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.core import Component, implements

from bhrelations.api import IRelationChangingListener


class TestRelationChangingListener(Component):
    implements(IRelationChangingListener)

    def adding_relation(self, relation):
        self.action = "adding_relation"
        self.relation = relation

    def deleting_relation(self, relation, when):
        self.action = "deleting_relation"
        self.relation = relation
        self.when = when

########NEW FILE########
__FILENAME__ = notification
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest

from trac.tests.notification import SMTPServerStore, SMTPThreadedServer
from trac.ticket.tests.notification import SMTP_TEST_PORT, smtp_address

from bhrelations.tests.base import DEPENDENCY_OF, BaseRelationsTestCase
from bhrelations.notification import RelationNotifyEmail


class NotificationTestCase(BaseRelationsTestCase):

    @classmethod
    def setUpClass(cls):
        cls.smtpd = CustomSMTPThreadedServer(SMTP_TEST_PORT)
        cls.smtpd.start()

    @classmethod
    def tearDownClass(cls):
        cls.smtpd.stop()

    def setUp(self):
        super(NotificationTestCase, self).setUp()
        self.env.config.set('notification', 'smtp_enabled', 'true')
        self.env.config.set('notification', 'always_notify_owner', 'true')
        self.env.config.set('notification', 'always_notify_reporter', 'true')
        self.env.config.set('notification', 'smtp_always_cc',
                            'joe.user@example.net, joe.bar@example.net')
        self.env.config.set('notification', 'use_public_cc', 'true')
        self.env.config.set('notification', 'smtp_port', str(SMTP_TEST_PORT))
        self.env.config.set('notification', 'smtp_server', 'localhost')
        self.notifier = RelationNotifyEmail(self.env)

    def tearDown(self):
        super(NotificationTestCase, self).tearDown()
        self.smtpd.cleanup()

    def test_recipients_of_both_related_tickets_get_notified(self):
        """To/Cc recipients"""
        ticket = self._insert_and_load_ticket(
            'Foo',
            reporter='"Joe User" < joe.user@example.org >',
            owner='joe.user@example.net',
            cc='joe.user@example.com, joe.bar@example.org, '
               'joe.bar@example.net'
        )
        ticket2 = self._insert_and_load_ticket(
            'Bar',
            reporter='"Bob User" < bob.user@example.org >',
            owner='bob.user@example.net',
            cc='bob.user@example.com, bob.bar@example.org, '
               'bob.bar@example.net')
        relation = self.add_relation(ticket, DEPENDENCY_OF, ticket2)

        self.notifier.notify(relation)

        recipients = self.smtpd.get_recipients()
        # checks there is no duplicate in the recipient list
        rcpts = []
        for r in recipients:
            self.failIf(r in rcpts)
            rcpts.append(r)
        # checks that all cc recipients have been notified
        cc_list = self.env.config.get('notification', 'smtp_always_cc')
        cc_list = "%s, %s, %s" % (cc_list, ticket['cc'], ticket2['cc'])
        for r in cc_list.replace(',', ' ').split():
            self.failIf(r not in recipients)
        # checks that both owners have been notified
        self.failIf(smtp_address(ticket['owner']) not in recipients)
        self.failIf(smtp_address(ticket2['owner']) not in recipients)
        # checks that both reporters have been notified
        self.failIf(smtp_address(ticket['reporter']) not in recipients)
        self.failIf(smtp_address(ticket2['reporter']) not in recipients)

    def test_no_recipient_results_in_no_notification(self):
        self.env.config.set('notification', 'smtp_always_cc', '')
        ticket = self._insert_and_load_ticket('Foo', reporter='anonymous')
        ticket2 = self._insert_and_load_ticket('Bar', reporter='anonymous')

        relation = self.add_relation(ticket, DEPENDENCY_OF, ticket2)
        self.notifier.notify(relation)

        sender = self.smtpd.get_sender()
        recipients = self.smtpd.get_recipients()
        message = self.smtpd.get_message()
        # checks that no message has been sent
        self.failIf(recipients)
        self.failIf(sender)
        self.failIf(message)

    def test_one_email_per_relation(self):
        ticket = self._insert_and_load_ticket('Foo', reporter='anonymous')
        ticket2 = self._insert_and_load_ticket('Bar', reporter='anonymous')

        relation = self.add_relation(ticket, DEPENDENCY_OF, ticket2)
        self.notifier.notify(relation)

        relations = self.env.db_direct_query(
            "SELECT * FROM bloodhound_relations")
        self.assertEqual(len(relations), 2)
        self.assertEqual(self.smtpd.messages_received(), 1)

        self.smtpd.cleanup()

        self.relations_system.delete(relation.get_relation_id())
        relations = self.env.db_direct_query(
            "SELECT * FROM bloodhound_relations")
        self.assertEqual(len(relations), 0)
        self.assertEqual(self.smtpd.messages_received(), 1)


class CustomSMTPServerStore(SMTPServerStore):
    """SMTPServerStore that can count received messages"""
    def __init__(self):
        SMTPServerStore.__init__(self)
        self.messages = 0

    def helo(self, args):
        SMTPServerStore.helo(self, args)
        self.messages += 1


class CustomSMTPThreadedServer(SMTPThreadedServer):
    def __init__(self, port):
        SMTPThreadedServer.__init__(self, port)
        self.store = CustomSMTPServerStore()

    def cleanup(self):
        SMTPThreadedServer.cleanup(self)
        self.store.messages = 0

    def messages_received(self):
        return self.store.messages


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(NotificationTestCase))
    return test_suite


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import shutil
import tempfile
import unittest

from bhsearch.api import BloodhoundSearchApi

# TODO: Figure how to get trac to load components from these modules
import bhsearch.query_parser, bhsearch.search_resources.ticket_search, \
       bhsearch.whoosh_backend
import bhrelations.search
from bhrelations.tests.base import BaseRelationsTestCase, DEPENDENCY_OF


class SearchIntegrationTestCase(BaseRelationsTestCase):

    def setUp(self):
        BaseRelationsTestCase.setUp(self, enabled=['bhsearch.*'])
        self.global_env.path = tempfile.mkdtemp('bhrelations-tempenv')
        self.search_api = BloodhoundSearchApi(self.env)
        self.search_api.upgrade_environment(self.env.db_transaction)

    def tearDown(self):
        shutil.rmtree(self.env.path)
        BaseRelationsTestCase.tearDown(self)

    def test_relations_are_indexed_on_creation(self):
        t1 = self._insert_and_load_ticket("Foo")
        t2 = self._insert_and_load_ticket("Bar")

        self.add_relation(t1, DEPENDENCY_OF, t2)

        result = self.search_api.query('%s:#2' % DEPENDENCY_OF)
        self.assertEqual(result.hits, 1)

    def test_relations_are_indexed_on_deletion(self):
        t1 = self._insert_and_load_ticket("Foo")
        t2 = self._insert_and_load_ticket("Bar")

        self.add_relation(t1, DEPENDENCY_OF, t2)
        relations = self.get_relations(t1)
        self.relations_system.delete(relations[0]["relation_id"])

        result = self.search_api.query('%s:#2' % DEPENDENCY_OF)
        self.assertEqual(result.hits, 0)

    def test_different_types_of_queries(self):
        t1 = self._insert_and_load_ticket("Foo")
        t2 = self._insert_and_load_ticket("Bar")

        self.add_relation(t1, DEPENDENCY_OF, t2)

        self.assertEqual(self.search_api.query('%s:#2'
                                               % DEPENDENCY_OF).hits, 1)
        self.assertEqual(self.search_api.query('%s:#tp1-2'
                                               % DEPENDENCY_OF).hits, 1)


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(SearchIntegrationTestCase))
    return test_suite


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = validation
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest

from bhrelations.tests.base import BaseRelationsTestCase
from bhrelations.validation import Validator


class GraphFunctionsTestCase(BaseRelationsTestCase):
    edges = [
        ('A', 'B', 'p'),  #      A    H
        ('A', 'C', 'p'),  #     /  \ /
        ('C', 'D', 'p'),  #    B    C
        ('C', 'E', 'p'),  #        /  \
        ('E', 'F', 'p'),  #       D    E - F - G
        ('F', 'G', 'p'),  #
        ('H', 'C', 'p'),
    ]

    def setUp(self):
        BaseRelationsTestCase.setUp(self)
        # bhrelations point from destination to source
        for destination, source, type in self.edges:
            self.env.db_direct_transaction(
                """INSERT INTO bloodhound_relations (source, destination, type)
                        VALUES ('%s', '%s', '%s')""" %
                (source, destination, type)
            )
        self.validator = Validator(self.env)

    def test_find_path(self):
        self.assertEqual(self.validator._find_path(u'A', u'E', u'p'),
                         [u'A', u'C', u'E'])
        self.assertEqual(self.validator._find_path(u'A', u'G', u'p'),
                         [u'A', u'C', u'E', u'F', u'G'])
        self.assertEqual(self.validator._find_path(u'H', u'D', u'p'),
                         [u'H', u'C', u'D'])
        self.assertEqual(self.validator._find_path(u'E', u'A', u'p'), None)
        self.assertEqual(self.validator._find_path(u'B', u'D', u'p'), None)

    def test_descendants(self):
        self.assertEqual(self.validator._descendants(u'B', u'p'), set())
        self.assertEqual(self.validator._descendants(u'E', u'p'),
                         set([u'F', u'G']))
        self.assertEqual(self.validator._descendants(u'H', u'p'),
                         set([u'C', u'D', u'E', u'F', u'G']))

    def test_ancestors(self):
        self.assertEqual(self.validator._ancestors(u'B', u'p'), set([u'A']))
        self.assertEqual(self.validator._ancestors(u'E', u'p'),
                         set([u'A', u'C', u'H']))
        self.assertEqual(self.validator._ancestors(u'H', u'p'), set())


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(GraphFunctionsTestCase))
    return test_suite


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import unittest

from trac.ticket import Ticket
from trac.util.datefmt import to_utimestamp
from trac.web import RequestDone

from bhrelations.api import ResourceIdSerializer
from bhrelations.tests.base import DEPENDS_ON, DUPLICATE_OF, \
                                   BaseRelationsTestCase
from bhrelations.web_ui import RelationManagementModule

from multiproduct.ticket.web_ui import TicketModule


class RelationManagementModuleTestCase(BaseRelationsTestCase):

    def setUp(self):
        BaseRelationsTestCase.setUp(self)
        ticket_id = self._insert_ticket(self.env, "Foo")
        self.req.method = 'POST'
        self.req.args['id'] = ticket_id

    def test_can_process_empty_request(self):
        self.req.method = 'GET'
        data = self.process_request()

        self.assertSequenceEqual(data['relations'], [])
        self.assertEqual(len(data['reltypes']), 11)

    def test_handles_missing_ticket_id(self):
        self.req.args['add'] = 'add'

        data = self.process_request()

        self.assertIn("Invalid ticket", data["error"])

    def test_handles_invalid_ticket_id(self):
        self.req.args['add'] = True
        self.req.args['dest_tid'] = 'no such ticket'

        data = self.process_request()

        self.assertIn("Invalid ticket", data["error"])

    def test_handles_missing_relation_type(self):
        t2 = self._insert_ticket(self.env, "Bar")
        self.req.args['add'] = True
        self.req.args['dest_tid'] = str(t2)

        data = self.process_request()

        self.assertIn("Unknown relation type", data["error"])

    def test_handles_invalid_relation_type(self):
        t2 = self._insert_ticket(self.env, "Bar")
        self.req.args['add'] = True
        self.req.args['dest_tid'] = str(t2)
        self.req.args['reltype'] = 'no such relation'

        data = self.process_request()

        self.assertIn("Unknown relation type", data["error"])

    def test_shows_relation_that_was_just_added(self):
        t2 = self._insert_ticket(self.env, "Bar")
        self.req.args['add'] = True
        self.req.args['dest_tid'] = str(t2)
        self.req.args['reltype'] = DEPENDS_ON

        data = self.process_request()

        self.assertEqual(len(data["relations"]), 1)

    def test_failure_to_notify_does_not_result_in_error(self):
        t2 = self._insert_ticket(self.env, "Bar")
        self.req.args['add'] = True
        self.req.args['dest_tid'] = str(t2)
        self.req.args['reltype'] = DEPENDS_ON
        rlm = RelationManagementModule(self.env)
        rlm.notify_relation_changed = self._failing_notification

        rlm.process_request(self.req)
        self.assertEqual(len(self.req.chrome['warnings']), 1)

    def _failing_notification(self, relation):
        raise Exception()

    def process_request(self):
        url, data, x = RelationManagementModule(self.env).process_request(
            self.req)
        return data


class ResolveTicketIntegrationTestCase(BaseRelationsTestCase):

    def setUp(self):
        BaseRelationsTestCase.setUp(self)

        self.mock_request()
        self.configure()

        self.req.redirect = self.redirect
        self.redirect_url = None
        self.redirect_permanent = None

    def test_creates_duplicate_relation_from_duplicate_id(self):
        t1 = self._insert_and_load_ticket("Foo")
        t2 = self._insert_and_load_ticket("Bar")

        self.assertRaises(RequestDone,
                          self.resolve_as_duplicate,
                          t2, self.get_id(t1))
        relations = self.get_relations(t2)
        self.assertEqual(len(relations), 1)
        relation = relations[0]
        self.assertEqual(relation['destination_id'], self.get_id(t1))
        self.assertEqual(relation['type'], DUPLICATE_OF)

    def test_prefills_duplicate_id_if_relation_exists(self):
        t1 = self._insert_and_load_ticket("Foo")
        t2 = self._insert_and_load_ticket("Bar")
        self.add_relation(t2, DUPLICATE_OF, t1)
        self.req.path_info = '/ticket/%d' % t2.id

        data = self.process_request()

        self.assertIn('ticket_duplicate_of', data)
        t1id = ResourceIdSerializer.get_resource_id_from_instance(self.env, t1)
        self.assertEqual(data['ticket_duplicate_of'], t1id)

    def test_can_set_duplicate_resolution_even_if_relation_exists(self):
        t1 = self._insert_and_load_ticket("Foo")
        t2 = self._insert_and_load_ticket("Bar")
        self.add_relation(t2, DUPLICATE_OF, t1)

        self.assertRaises(RequestDone,
                          self.resolve_as_duplicate,
                          t2, self.get_id(t1))
        t2 = Ticket(self.env, t2.id)
        self.assertEqual(t2['status'], 'closed')
        self.assertEqual(t2['resolution'], 'duplicate')

    def test_post_process_request_does_not_break_ticket(self):
        t1 = self._insert_and_load_ticket("Foo")
        self.req.path_info = '/ticket/%d' % t1.id
        self.process_request()

    def test_post_process_request_does_not_break_newticket(self):
        self.req.path_info = '/newticket'
        self.process_request()

    def test_post_process_request_can_handle_none_data(self):
        self.req.path_info = '/source'
        RelationManagementModule(self.env).post_process_request(self.req, '',
                                                                None, '')

    def resolve_as_duplicate(self, ticket, duplicate_id):
        self.req.method = 'POST'
        self.req.path_info = '/ticket/%d' % ticket.id
        self.req.args['id'] = ticket.id
        self.req.args['action'] = 'resolve'
        self.req.args['action_resolve_resolve_resolution'] = 'duplicate'
        self.req.args['duplicate_id'] = duplicate_id
        self.req.args['view_time'] = str(to_utimestamp(ticket['changetime']))
        self.req.args['submit'] = True

        return self.process_request()

    def process_request(self):
        ticket_module = TicketModule(self.env)

        ticket_module.match_request(self.req)
        template, data, content_type = ticket_module.process_request(self.req)
        template, data, content_type = \
            RelationManagementModule(self.env).post_process_request(
                self.req, template, data, content_type)
        return data

    def mock_request(self):
        self.req.method = 'GET'
        self.req.get_header = lambda x: None
        self.req.authname = 'x'
        self.req.session = {}
        self.req.chrome = {'warnings': []}
        self.req.form_token = ''

    def configure(self):
        config = self.env.config
        config['ticket-workflow'].set('resolve', 'new -> closed')
        config['ticket-workflow'].set('resolve.operations', 'set_resolution')
        config['ticket-workflow'].set('resolve.permissions', 'TICKET_MODIFY')
        with self.env.db_transaction as db:
            db("INSERT INTO enum VALUES "
               "('resolution', 'duplicate', 'duplicate')")

    def redirect(self, url, permanent=False):
        self.redirect_url = url
        self.redirect_permanent = permanent
        raise RequestDone

    def get_id(self, ticket):
        return ResourceIdSerializer.get_resource_id_from_instance(self.env,
                                                                  ticket)


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(RelationManagementModuleTestCase))
    return test_suite


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = translation
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Translation functions and classes.
"""

from trac.util.translation import domain_functions

#------------------------------------------------------
#    Internationalization
#------------------------------------------------------

_, ngettext, tag_, tagn_, gettext, N_, add_domain = \
   domain_functions('bhrelations', ('_', 'ngettext', 'tag_', 'tagn_',
                                'gettext', 'N_', 'add_domain'))

########NEW FILE########
__FILENAME__ = validation
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from genshi.builder import tag
from trac.core import Component, implements, TracError
from trac.resource import get_resource_shortname
from trac.util.translation import tag_

from bhrelations.api import IRelationValidator, RelationsSystem, \
    ResourceIdSerializer, TicketRelationsSpecifics


class ValidationError(TracError):
    """Exception raised when a validator fails."""
    def __init__(self, message, title=None, show_traceback=False):
        super(ValidationError, self).__init__(
            message, title, show_traceback)
        self.failed_ids = []


class Validator(Component):
    implements(IRelationValidator)

    def validate(self, relation):
        raise NotImplementedError

    def render_relation_type(self, end):
        return RelationsSystem(self.env)._labels[end]

    def get_resource_name(self, resource_id):
        resource = ResourceIdSerializer.get_resource_by_id(resource_id)
        return get_resource_shortname(self.env, resource)

    def _find_path(self, source, destination, relation_type):
        known_nodes, paths = self._bfs(source, destination, relation_type)
        return paths.get((source, destination), None)

    def _descendants(self, source, relation_type):
        known_nodes, paths = self._bfs(source, None, relation_type)
        return known_nodes - set([source])

    def _ancestors(self, source, relation_type):
        known_nodes, paths = self._bfs(source, None, relation_type,
                                       reverse=True)
        return known_nodes - set([source])

    def _bfs(self, source, destination, relation_type, reverse=False):
        known_nodes = set([source])
        new_nodes = set([source])
        paths = {(source, source): [source]}

        while new_nodes:
            if reverse:
                relation = 'source, destination'
                origin = 'source'
            else:
                relation = 'destination, source'
                origin = 'destination'
            relation_types = \
                ','.join("'%s'" % r for r in relation_type.split(','))
            query = """
                SELECT %(relation)s
                  FROM bloodhound_relations
                 WHERE type IN (%(relation_type)s)
                   AND %(origin)s IN (%(new_nodes)s)
            """ % dict(
                relation=relation,
                relation_type=relation_types,
                new_nodes=', '.join("'%s'" % n for n in new_nodes),
                origin=origin)
            new_nodes = set()
            for s, d in self.env.db_query(query):
                if d not in known_nodes:
                    new_nodes.add(d)
                paths[(source, d)] = paths[(source, s)] + [d]
            known_nodes = set.union(known_nodes, new_nodes)
            if destination in new_nodes:
                break
        return known_nodes, paths


class NoCyclesValidator(Validator):
    def validate(self, relation):
        """If a path exists from relation's destination to its source,
         adding the relation will create a cycle.
         """
        path = self._find_path(relation.source,
                               relation.destination,
                               relation.type)
        if path:
            cycle_str = map(self.get_resource_name, path)
            error = 'Cycle in ''%s'': %s' % (
                self.render_relation_type(relation.type),
                ' -> '.join(cycle_str))
            error = ValidationError(error)
            error.failed_ids = path
            raise error


class ExclusiveValidator(Validator):
    def validate(self, relation):
        """If a path of exclusive type exists between source and destination,
        adding a relation is not allowed.
        """
        rls = RelationsSystem(self.env)
        source, destination = relation.source, relation.destination

        for exclusive_type in rls._exclusive:
            path = (self._find_path(source, destination, exclusive_type)
                    or self._find_path(destination, source, exclusive_type))
            if path:
                raise ValidationError(
                    "Cannot add relation %s, source and destination "
                    "are connected with %s relation." % (
                        self.render_relation_type(relation.type),
                        self.render_relation_type(exclusive_type),
                    )
                )
        if relation.type in rls._exclusive:
            d_ancestors = self._ancestors(destination, exclusive_type)
            d_ancestors.add(destination)
            s_descendants = self._descendants(source, exclusive_type)
            s_descendants.add(source)
            query = """
                SELECT source, destination, type
                  FROM bloodhound_relations
                 WHERE (source in (%(s_ancestors)s)
                        AND destination in (%(d_descendants)s))
                    OR
                       (source in (%(d_descendants)s)
                        AND destination in (%(s_ancestors)s))
            """ % dict(
                s_ancestors=', '.join("'%s'" % n for n in d_ancestors),
                d_descendants=', '.join("'%s'" % n for n in s_descendants))
            conflicting_relations = list(self.env.db_query(query))
            if conflicting_relations:
                raise ValidationError(
                    "Connecting %s and %s with relation %s "
                    "would make the following relations invalid:\n"
                    "%s" % (
                        source,
                        destination,
                        self.render_relation_type(relation.type),
                        '\n'.join(map(str, conflicting_relations))
                    )
                )


class SingleProductValidator(Validator):
    def validate(self, relation):
        product1, product2 = map(self.get_product,
                                 (relation.source, relation.destination))
        if product1 != product2:
            raise ValidationError(
                "Resources for %s relation must belong to the same product." %
                self.render_relation_type(relation.type)
            )

    def get_product(self, resource_id):
        return ResourceIdSerializer.split_full_id(resource_id)[0]


class NoSelfReferenceValidator(Validator):
    def validate(self, relation):
        if relation.source == relation.destination:
            error = ValidationError(
                'Ticket cannot be self-referenced in a relation.')
            error.failed_ids = [relation.source]
            raise error


class OneToManyValidator(Validator):
    """Only tree relationships are allowed. A ticket cannot have multiple
    parents."""
    def validate(self, relation):
        rls = RelationsSystem(self.env)
        existing_relations = \
            rls._select_relations(resource_type=relation.type,
                                  destination=relation.destination)
        if existing_relations:
            raise ValidationError(
                tag_("Another resource is already related to %(destination)s "
                     "with %(relation)s relation.",
                     destination=tag.em(relation.destination),
                     relation=tag.b(self.render_relation_type(relation.type)))
            )


class ReferencesOlderValidator(Validator):
    def validate(self, relation):
        source, destination = map(ResourceIdSerializer.get_resource_by_id,
                                  [relation.source, relation.destination])
        if source.realm == 'ticket' and destination.realm == 'ticket':
            source, destination = map(
                TicketRelationsSpecifics(self.env)._create_ticket_by_full_id,
                [source, destination])
            if destination['time'] > source['time']:
                raise ValidationError(
                    "Relation %s must reference an older resource." %
                    self.render_relation_type(relation.type)
                )


class BlockerValidator(Validator):
    def validate(self, relation):
        """Prevents adding a cyclical blocker relation.
         """
        rls = RelationsSystem(self.env)
        if not rls.is_blocker(relation.type):
            relation = rls.get_reverted_relation(relation)
        if not relation or not rls.is_blocker(relation.type):
            return

        blockers = ','.join(b for b, is_blocker in rls._blockers.items()
                            if is_blocker)

        path = self._find_path(relation.source,
                               relation.destination,
                               blockers)
        if path:
            cycle_str = map(self.get_resource_name, path)
            error = 'Cycle in ''%s'': %s' % (
                self.render_relation_type(relation.type),
                ' -> '.join(cycle_str))
            error = ValidationError(error)
            error.failed_ids = path
            raise error

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Ticket relations for Apache(TM) Bloodhound

Ticket relations user interface.
"""

import re

from trac.core import Component, TracError, implements
from trac.resource import Resource, get_resource_shortname, \
                          get_resource_summary, get_resource_url
from trac.ticket.model import Ticket
from trac.util import exception_to_unicode, to_unicode
from trac.web.api import IRequestFilter, IRequestHandler
from trac.web.chrome import ITemplateProvider, add_warning

from bhrelations.api import NoSuchTicketError, RelationsSystem, \
                            ResourceIdSerializer, TicketRelationsSpecifics, \
                            UnknownRelationType

from bhrelations.model import Relation
from bhrelations.utils.translation import _
from bhrelations.validation import ValidationError


class RelationManagementModule(Component):
    implements(IRequestFilter, IRequestHandler, ITemplateProvider)

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/ticket/([0-9]+)/relations/*$', req.path_info)
        if not match:
            return False

        req.args['id'] = match.group(1)
        return True

    def process_request(self, req):
        tid = req.args.get('id')
        if not tid:
            raise TracError(_('No ticket id provided.'))

        try:
            ticket = Ticket(self.env, tid)
        except ValueError:
            raise TracError(_('Invalid ticket id.'))

        req.perm.require('TICKET_VIEW')
        relsys = RelationsSystem(self.env)

        data = {
            'relation': {},
        }
        if req.method == 'POST':
            # for modifying the relations TICKET_MODIFY is required for
            # both the source and the destination tickets
            req.perm.require('TICKET_MODIFY')

            if 'remove' in req.args:
                rellist = req.args.get('sel')
                if rellist:
                    if isinstance(rellist, basestring):
                        rellist = [rellist, ]
                    self.remove_relations(req, rellist)
            elif 'add' in req.args:
                relation = dict(
                    destination=req.args.get('dest_tid', ''),
                    type=req.args.get('reltype', ''),
                    comment=req.args.get('comment', ''),
                )
                try:
                    trs = TicketRelationsSpecifics(self.env)
                    dest_ticket = trs.find_ticket(relation['destination'])
                except NoSuchTicketError:
                    data['error'] = _('Invalid ticket ID.')
                else:
                    req.perm.require('TICKET_MODIFY', Resource(dest_ticket.id))

                    try:
                        dbrel = relsys.add(ticket, dest_ticket,
                                           relation['type'],
                                           relation['comment'], req.authname)
                    except NoSuchTicketError:
                        data['error'] = _('Invalid ticket ID.')
                    except UnknownRelationType:
                        data['error'] = _('Unknown relation type.')
                    except ValidationError as ex:
                        data['error'] = ex.message
                    else:
                        # Notify
                        try:
                            self.notify_relation_changed(dbrel)
                        except Exception, e:
                            self.log.error("Failure sending notification on"
                                           "creation of relation: %s",
                                           exception_to_unicode(e))
                            add_warning(req, _("The relation has been added, "
                                               "but an error occurred while "
                                               "sending notifications: "
                                               "%(message)s",
                                               message=to_unicode(e)))

                if 'error' in data:
                    data['relation'] = relation
            else:
                raise TracError(_('Invalid operation.'))

        data.update({
            'ticket': ticket,
            'reltypes': sorted(relsys.get_relation_types().iteritems(),
                               key=lambda x: x[0]),
            'relations': self.get_ticket_relations(ticket),
            'get_resource_shortname': get_resource_shortname,
            'get_resource_summary': get_resource_summary,
        })
        return 'relations_manage.html', data, None

    def notify_relation_changed(self, relation):
        from bhrelations.notification import RelationNotifyEmail
        RelationNotifyEmail(self.env).notify(relation)

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        from pkg_resources import resource_filename
        return [resource_filename('bhrelations', 'templates')]

    # IRequestFilter methods

    def pre_process_request(self, req, handler):
        return handler

    def post_process_request(self, req, template, data, content_type):
        if req.path_info.startswith('/ticket/'):
            ticket = data['ticket']
            rls = RelationsSystem(self.env)
            try:
                resid = ResourceIdSerializer \
                            .get_resource_id_from_instance(self.env, ticket)
            except ValueError:
                resid = None

            if rls.duplicate_relation_type and resid is not None:
                duplicate_relations = \
                    rls._select_relations(resid, rls.duplicate_relation_type)
                if duplicate_relations:
                    data['ticket_duplicate_of'] = \
                        duplicate_relations[0].destination
        return template, data, content_type

    # Public methods

    def get_ticket_relations(self, ticket):
        grouped_relations = {}
        relsys = RelationsSystem(self.env)
        reltypes = relsys.get_relation_types()
        trs = TicketRelationsSpecifics(self.env)
        for r in relsys.get_relations(ticket):
            r['desthref'] = get_resource_url(self.env, r['destination'],
                                             self.env.href)
            r['destticket'] = trs._create_ticket_by_full_id(r['destination'])
            grouped_relations.setdefault(reltypes[r['type']], []).append(r)
        return grouped_relations

    def remove_relations(self, req, rellist):
        relsys = RelationsSystem(self.env)
        for relid in rellist:
            relation = Relation.load_by_relation_id(self.env, relid)
            resource = \
                ResourceIdSerializer.get_resource_by_id(relation.destination)
            if 'TICKET_MODIFY' in req.perm(resource):
                relsys.delete(relid)
            else:
                add_warning(req, _('Insufficient permissions to remove '
                                   'relation "%(relation)s"', relation=relid))

########NEW FILE########
__FILENAME__ = relations
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Widgets displaying ticket relations.
"""

from trac.resource import get_resource_shortname, get_resource_summary
from trac.ticket.model import Ticket

from bhdashboard.util import pretty_wrapper
from bhdashboard.util.widgets import WidgetBase, check_widget_name
from bhrelations.web_ui import RelationManagementModule
from bhrelations.utils.translation import _

__metaclass__ = type


class TicketRelationsWidget(WidgetBase):
    """Display ticket relations.
    """
    def get_widget_params(self, name):
        """Return a dictionary containing arguments specification for
        the widget with specified name.
        """
        return {
                'tid': {
                    'desc': """Source ticket id""",
                    'type': int
                },

                'max': {
                    'desc': """Limit the number of relations displayed""",
                    'type': int
                },
        }

    get_widget_params = pretty_wrapper(get_widget_params, check_widget_name)

    def render_widget(self, name, context, options):
        """Gather list of relations and render data in compact view
        """
        title = _('Related tickets')
        params = ('tid', 'max')
        tid, max_ = self.bind_params(name, options, *params)

        ticket = Ticket(self.env, tid)
        data = {
            'ticket': ticket,
            'relations': \
                RelationManagementModule(self.env).get_ticket_relations(ticket),
            'get_resource_shortname': get_resource_shortname,
            'get_resource_summary': get_resource_summary,
        }
        return 'widget_relations.html', {
            'title': title,
            'data': data,
        }, context

    render_widget = pretty_wrapper(render_widget, check_widget_name)

########NEW FILE########
__FILENAME__ = admin
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Administration commands for Bloodhound Search."""
from trac.core import Component, implements
from trac.admin import IAdminCommandProvider
from bhsearch.api import BloodhoundSearchApi

class BloodhoundSearchAdmin(Component):
    """Bloodhound Search administration component."""

    implements(IAdminCommandProvider)

    # IAdminCommandProvider methods
    def get_admin_commands(self):
        yield ('bhsearch rebuild', '',
            'Rebuild Bloodhound Search index',
            None, BloodhoundSearchApi(self.env).rebuild_index)
        yield ('bhsearch optimize', '',
            'Optimize Bloodhound search index',
            None, BloodhoundSearchApi(self.env).optimize)

########NEW FILE########
__FILENAME__ = api
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Core Bloodhound Search components."""
from trac.config import ExtensionOption, OrderedExtensionsOption
from trac.core import (Interface, Component, ExtensionPoint, TracError,
    implements)
from trac.env import IEnvironmentSetupParticipant
from multiproduct.api import ISupportMultiProductEnvironment
from multiproduct.core import MultiProductExtensionPoint
from bhsearch.utils.translation import _, add_domain

ASC = "asc"
DESC = "desc"
SCORE = "score"

class IndexFields(object):
    TYPE = "type"
    ID = "id"
    TIME = 'time'
    AUTHOR = 'author'
    CONTENT = 'content'
    STATUS = 'status'
    PRODUCT = 'product'
    REQUIRED_PERMISSION = 'required_permission'
    NAME = 'name'

class QueryResult(object):
    def __init__(self):
        self.hits = 0
        self.page_count = 0
        self.page_number = 0
        self.offset = 0
        self.docs = []
        self.highlighting = []
        self.facets = None
        self.query_suggestion = None
        self.debug = {}

class SortInstruction(object):
    def __init__(self, field, order):
        self.field = field
        self.order = self._parse_sort_order(order)

    def _parse_sort_order(self, order):
        if not order:
            return ASC
        order = order.strip().lower()
        if order == ASC:
            return ASC
        elif order == DESC:
            return DESC
        else:
            raise TracError(
                "Invalid sort order %s in sort instruction" % order)

    def build_sort_expression(self):
        return "%s %s" % (self.field, self.order)

    def __str__(self):
        return str(self.__dict__)

    def __eq__(self, other):
        if not isinstance(other, SortInstruction):
            return False
        return self.__dict__ == other.__dict__


class ISearchWikiSyntaxFormatter(Interface):
    """Extension point interface for wiki syntax processing.
    """

    def format(self, wiki_text):
        """
        Process wiki syntax and return text representation suitable for search
        """

class ISearchBackend(Interface):
    """Extension point interface for search backend systems.
    """

    def add_doc(doc, operation_context):
        """
        Called when new document instance must be added
        """

    def delete_doc(product, doc_type, doc_id, operation_context):
        """
        Delete document from index
        """

    def optimize():
        """
        Optimize index if needed
        """

    def is_index_outdated():
        """
        Check if index is outdated and needs to be recreated.
        """

    def recreate_index():
        """
        Create a new index, if index exists, it will be deleted
        """

    def open_or_create_index_if_missing():
        """
        Open existing index, if index does not exist, create new one
        """

    def query(
            query,
            sort = None,
            fields = None,
            filter = None,
            facets = None,
            pagenum = 1,
            pagelen = 20,
            highlight=False,
            highlight_fields=None,
            context=None):
        """
        Perform query implementation

        :param query: Parsed query object
        :param sort: list of SortInstruction objects
        :param fields: list of fields to select
        :param boost: list of fields with boost values
        :param filter: filter query object
        :param facets: list of facet fields
        :param pagenum: page number
        :param pagelen: page length
        :param highlight: highlight matched terms in fields
        :param highlight_fields: list of fields to highlight
        :return: ResultsPage
        """

    def start_operation(self):
        """Used to get arguments for batch operation withing single commit"""

class IIndexParticipant(Interface):
    """Extension point interface for components that should be searched.
    """

    def get_entries_for_index():
        """List entities for index creation"""

class ISearchParticipant(Interface):
    """Extension point interface for components that should be searched.
    """
    def format_search_results(contents):
        """Called to see if the module wants to format the search results."""

    def is_allowed(req):
        """Called when we want to build the list of components with search.
        Passes the request object to do permission checking."""

    def get_participant_type():
        """Return type of search participant"""

    def get_required_permission(self):
        """Return permission required to view components in search results"""

    def get_title():
        """Return resource title."""

    def get_default_facets():
        """Return default facets for the specific resource type."""

    def get_default_view():
        """Return True if grid is enabled by default for specific resource."""

    def get_default_view_fields(view):
        """Return list of fields should be returned in grid by default."""


class IQueryParser(Interface):
    """Extension point for Bloodhound Search query parser.
    """

    def parse(query_string, context):
        """Parse query from string"""

    def parse_filters(filters):
        """Parse query filters"""

class IDocIndexPreprocessor(Interface):
    """Extension point for Bloodhound Search document pre-processing before
    adding or update documents into index.
    """

    def pre_process(doc):
        """Process document"""

class IResultPostprocessor(Interface):
    """Extension point for Bloodhound Search result post-processing before
    returning result to caller.
    """

    def post_process(query_result):
        """Process document"""

class IQueryPreprocessor(Interface):
    """Extension point for Bloodhound Search query pre processing.
    """

    def query_pre_process(query_parameters, context):
        """Process query parameters"""


class IMetaKeywordParser(Interface):
    """Extension point for custom meta keywords."""

    def match(text, context):
        """If text matches the keyword, return its transformed value."""


class BloodhoundSearchApi(Component):
    """Implements core indexing functionality, provides methods for
    searching, adding and deleting documents from index.
    """
    implements(IEnvironmentSetupParticipant, ISupportMultiProductEnvironment)

    def __init__(self, *args, **kwargs):
        import pkg_resources
        locale_dir = pkg_resources.resource_filename(__name__, 'locale')
        add_domain(self.env.path, locale_dir)
        super(BloodhoundSearchApi, self).__init__(*args, **kwargs)

    backend = ExtensionOption('bhsearch', 'search_backend',
        ISearchBackend, 'WhooshBackend',
        'Name of the component implementing Bloodhound Search backend \
        interface: ISearchBackend.', doc_domain='bhsearch')

    parser = ExtensionOption('bhsearch', 'query_parser',
        IQueryParser, 'DefaultQueryParser',
        'Name of the component implementing Bloodhound Search query \
        parser.', doc_domain='bhsearch')

    index_pre_processors = OrderedExtensionsOption(
        'bhsearch', 'index_preprocessors', IDocIndexPreprocessor,
        ['SecurityPreprocessor'], include_missing=True,
    )
    result_post_processors = ExtensionPoint(IResultPostprocessor)
    query_processors = ExtensionPoint(IQueryPreprocessor)

    index_participants = MultiProductExtensionPoint(IIndexParticipant)

    def query(
            self,
            query,
            sort = None,
            fields = None,
            filter = None,
            facets = None,
            pagenum = 1,
            pagelen = 20,
            highlight = False,
            highlight_fields = None,
            context = None):
        """Return query result from an underlying search backend.

        Arguments:
        :param query: query string e.g. bla status:closed or a parsed
            representation of the query.
        :param sort: optional sorting
        :param boost: optional list of fields with boost values e.g.
            {id: 1000, subject :100, description:10}.
        :param filter: optional list of terms. Usually can be cached by
            underlying search framework. For example {type: wiki}
        :param facets: optional list of facet terms, can be field or expression
        :param page: paging support
        :param pagelen: paging support
        :param highlight: highlight matched terms in fields
        :param highlight_fields: list of fields to highlight
        :param context: request context

        :return: result QueryResult
        """
        # pylint: disable=too-many-locals
        self.env.log.debug("Receive query request: %s", locals())

        parsed_query = self.parser.parse(query, context)

        parsed_filters = self.parser.parse_filters(filter)
        # TODO: add query parsers and meta keywords post-parsing

        # TODO: apply security filters

        query_parameters = dict(
            query = parsed_query,
            query_string = query,
            sort = sort,
            fields = fields,
            filter = parsed_filters,
            facets = facets,
            pagenum = pagenum,
            pagelen = pagelen,
            highlight = highlight,
            highlight_fields = highlight_fields,
        )
        for query_processor in self.query_processors:
            query_processor.query_pre_process(query_parameters, context)

        query_result = self.backend.query(**query_parameters)

        for post_processor in self.result_post_processors:
            post_processor.post_process(query_result)

        query_result.debug["api_parameters"] = query_parameters
        return query_result

    def start_operation(self):
        return self.backend.start_operation()

    def rebuild_index(self):
        """Rebuild underlying index"""
        self.log.info('Rebuilding the search index.')
        self.backend.recreate_index()
        with self.backend.start_operation() as operation_context:
            doc = None
            try:
                for participant in self.index_participants:
                    self.log.info(
                        "Reindexing resources provided by %s in product %s" %
                        (participant.__class__.__name__,
                         getattr(participant.env.product, 'name', "''"))
                    )
                    docs = participant.get_entries_for_index()
                    for doc in docs:
                        self.log.debug(
                            "Indexing document %s:%s/%s" % (
                                doc.get('product'),
                                doc['type'],
                                doc['id'],
                            )
                        )
                        self.add_doc(doc, operation_context)
                self.log.info("Reindexing complete.")
            except Exception, ex:
                self.log.error(ex)
                if doc:
                    self.log.error("Doc that triggers the error: %s" % doc)
                raise

    def change_doc_id(self, doc, old_id, operation_context=None):
        if operation_context is None:
            with self.backend.start_operation() as operation_context:
                self._change_doc_id(doc, old_id, operation_context)
        else:
            self._change_doc_id(doc, old_id, operation_context)

    def _change_doc_id(self, doc, old_id, operation_context):
        self.backend.delete_doc(
            doc[IndexFields.PRODUCT],
            doc[IndexFields.TYPE],
            old_id,
            operation_context
        )
        self.add_doc(doc, operation_context)


    def optimize(self):
        """Optimize underlying index"""
        self.backend.optimize()

    def add_doc(self, doc, operation_context = None):
        """Add a document to underlying search backend.
        The doc must be dictionary with obligatory "type" field
        """
        for preprocessor in self.index_pre_processors:
            preprocessor.pre_process(doc)
        self.backend.add_doc(doc, operation_context)

    def delete_doc(self, product, doc_type, doc_id):
        """Delete the document from underlying search backend.
        """
        self.backend.delete_doc(product, doc_type, doc_id)

    # IEnvironmentSetupParticipant methods

    def environment_created(self):
        self.upgrade_environment(self.env.db_transaction)

    def environment_needs_upgrade(self, db):
        # pylint: disable=unused-argument
        return self.backend.is_index_outdated()

    def upgrade_environment(self, db):
        # pylint: disable=unused-argument
        self.rebuild_index()

########NEW FILE########
__FILENAME__ = query_parser
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Provides Bloodhound Search query parsing functionality"""

from bhsearch.api import IQueryParser, IMetaKeywordParser, ISearchParticipant
from bhsearch.whoosh_backend import WhooshBackend
from trac.config import ExtensionPoint
from trac.core import Component, implements
from whoosh import query, qparser
from whoosh.qparser import MultifieldParser


class MetaKeywordNode(qparser.GroupNode):
    def __init__(self, group_node=None, **kwargs):
        nodes = group_node.nodes if group_node else []
        super(MetaKeywordNode, self).__init__(nodes, kwargs=kwargs)


class MetaKeywordPlugin(qparser.TaggingPlugin):
    priority = 0
    expr = r"[$](?P<text>[^ \t\r\n]+)(?= |$|\))"
    nodetype = qparser.syntax.WordNode

    def __init__(self, meta_keyword_parsers=(), context=None):
        super(MetaKeywordPlugin, self).__init__()
        self.meta_keyword_parsers = meta_keyword_parsers
        self.context = context

    def match(self, parser, text, pos):
        match = qparser.TaggingPlugin.match(self, parser, text, pos)
        if match is None:
            return

        candidate = match.text
        for meta_keyword_parser in self.meta_keyword_parsers:
            expanded_meta_keyword = meta_keyword_parser.match(candidate,
                                                              self.context)
            if expanded_meta_keyword is not None:
                node = MetaKeywordNode(parser.tag(expanded_meta_keyword))
                return node.set_range(match.startchar, match.endchar)

    def filters(self, parser):
        # must execute before GroupPlugin with priority 0
        return [(self.unroll_meta_keyword_nodes, -100)]

    def unroll_meta_keyword_nodes(self, parser, group):
        newgroup = group.empty_copy()
        for node in group:
            if isinstance(node, MetaKeywordNode):
                newgroup.extend(self.unroll_meta_keyword_nodes(parser, node))
            elif isinstance(node, qparser.GroupNode):
                newgroup.append(self.unroll_meta_keyword_nodes(parser, node))
            else:
                newgroup.append(node)
        return newgroup


class DefaultQueryParser(Component):
    implements(IQueryParser)

    #todo: make field boost configurable e.g. read from config setting.
    #This is prototype implementation ,the fields boost must be tuned later
    field_boosts = dict(
        id = 6,
        name = 6,
        type = 2,
        summary = 5,
        author = 3,
        milestone = 2,
        keywords = 2,
        component = 2,
        status = 2,
        content = 1,
        changes = 1,
        message = 1,
        query_suggestion_basket = 0,
        relations = 1,
    )

    meta_keyword_parsers = ExtensionPoint(IMetaKeywordParser)

    def parse(self, query_string, context=None):
        parser = self._create_parser(context)
        query_string = query_string.strip()
        if query_string == "" or query_string == "*" or query_string == "*:*":
            return query.Every()
        query_string = unicode(query_string)
        parsed_query = parser.parse(query_string)
        parsed_query.original_query_string = query_string
        return parsed_query

    def parse_filters(self, filters):
        """Parse query filters"""
        if not filters:
            return None
        parsed_filters = [self._parse_filter(filter) for filter in filters]
        return query.And(parsed_filters).normalize()

    def _parse_filter(self, filter):
        return self.parse(unicode(filter))

    def _create_parser(self, context):
        parser = MultifieldParser(
            self.field_boosts.keys(),
            WhooshBackend.SCHEMA,
            fieldboosts=self.field_boosts
        )
        parser.add_plugin(
            MetaKeywordPlugin(meta_keyword_parsers=self.meta_keyword_parsers,
                              context=context)
        )
        return parser


class DocTypeMetaKeywordParser(Component):
    implements(IMetaKeywordParser)

    search_participants = ExtensionPoint(ISearchParticipant)

    def match(self, text, context):
        # pylint: disable=unused-argument
        documents = [p.get_participant_type()
                     for p in self.search_participants]
        if text in documents:
            return u'type:%s' % text


class ResolvedMetaKeywordParser(Component):
    implements(IMetaKeywordParser)

    def match(self, text, context):
        # pylint: disable=unused-argument
        if text == u'resolved':
            return u'status:(resolved OR closed)'


class UnResolvedMetaKeywordParser(Component):
    implements(IMetaKeywordParser)

    def match(self, text, context):
        # pylint: disable=unused-argument
        if text == u'unresolved':
            return u'NOT $resolved'


class MeMetaKeywordParser(Component):
    implements(IMetaKeywordParser)

    def match(self, text, context):
        if text == u'me':
            username = unicode(context.req.authname)
            return username


class MyMetaKeywordParser(Component):
    implements(IMetaKeywordParser)

    def match(self, text, context):
        # pylint: disable=unused-argument
        if text == u'my':
            return u'owner:$me'

########NEW FILE########
__FILENAME__ = query_suggestion
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.core import Component, implements
from bhsearch.api import IDocIndexPreprocessor, IndexFields


class SuggestionFields(IndexFields):
    SUMMARY = 'summary'
    BASKET = 'query_suggestion_basket'


class QuerySuggestionPreprocessor(Component):
    implements(IDocIndexPreprocessor)

    suggestion_fields = [
        IndexFields.NAME,
        IndexFields.CONTENT,
        SuggestionFields.SUMMARY,
    ]

    # IDocIndexPreprocessor methods
    def pre_process(self, doc):
        basket = u' '.join(doc.get(field, '')
                           for field in self.suggestion_fields)
        doc[SuggestionFields.BASKET] = basket

########NEW FILE########
__FILENAME__ = base
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Base classes for Bloodhound Search plugin."""
import re

from bhsearch.api import ISearchWikiSyntaxFormatter
from trac.core import Component, implements
from trac.config import BoolOption, ExtensionOption

class BaseIndexer(Component):
    """
    This is base class for Bloodhound Search indexers of specific resource
    """
    silence_on_error = BoolOption('bhsearch', 'silence_on_error', "True",
        """If true, do not throw an exception during indexing a resource""",
                                  doc_domain='bhsearch')

    wiki_formatter = ExtensionOption('bhsearch', 'wiki_syntax_formatter',
        ISearchWikiSyntaxFormatter, 'SimpleSearchWikiSyntaxFormatter',
        'Name of the component implementing wiki syntax to text formatter \
        interface: ISearchWikiSyntaxFormatter.', doc_domain='bhsearch')


class BaseSearchParticipant(Component):
    default_view = None
    default_grid_fields = None
    default_facets = None
    participant_type = None
    required_permission = None

    def get_default_facets(self):
        return self.default_facets

    def get_default_view(self):
        return self.default_view

    def get_default_view_fields(self, view):
        if view == "grid":
            return self.default_grid_fields
        return None

    def is_allowed(self, req=None):
        return (not req or self.required_permission in req.perm)

    def get_participant_type(self):
        return self.participant_type

    def get_required_permission(self):
        return self.required_permission

class SimpleSearchWikiSyntaxFormatter(Component):
    """
    This class provide very naive formatting of wiki syntax to text
    appropriate for indexing and search result presentation.
    A lot of things can be improved here.
    """
    implements(ISearchWikiSyntaxFormatter)

    STRIP_CHARS = re.compile(r'([=#\'\"\*/])')
    REPLACE_CHARS = re.compile(r'([=#\[\]\{\}|])')

    WHITE_SPACE_RE = re.compile(r'([\s]+)')
    def format(self, wiki_content):
        if not wiki_content:
            return wiki_content
        intermediate = self.STRIP_CHARS.sub("", wiki_content)
        intermediate = self.REPLACE_CHARS.sub(" ", intermediate)
        result = self.WHITE_SPACE_RE.sub(" ", intermediate)
        return result.strip()

########NEW FILE########
__FILENAME__ = changeset_search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from bhsearch import BHSEARCH_CONFIG_SECTION
from trac.versioncontrol.api import IRepositoryChangeListener
from bhsearch.api import (IIndexParticipant, BloodhoundSearchApi, IndexFields,
                          ISearchParticipant)
from bhsearch.search_resources.base import BaseIndexer, BaseSearchParticipant
from genshi.builder import tag
from trac.config import ListOption, Option
from trac.core import implements
from trac.versioncontrol.api import RepositoryManager

CHANGESET_TYPE = u"changeset"


class ChangesetFields(IndexFields):
    MESSAGE = "message"
    REPOSITORY = "repository"
    REVISION = "revision"
    CHANGES = "changes"


class ChangesetIndexer(BaseIndexer):
    implements(IRepositoryChangeListener, IIndexParticipant)

    # IRepositoryChangeListener methods
    def changeset_added(self, repos, changeset):
        # pylint: disable=unused-argument
        self._index_changeset(changeset)

    def changeset_modified(self, repos, changeset, old_changeset):
        # pylint: disable=unused-argument
        self._index_changeset(changeset)

    def _index_changeset(self, changeset):
        try:
            doc = self.build_doc(changeset)
            search_api = BloodhoundSearchApi(self.env)
            search_api.add_doc(doc)
        except Exception, e:
            if self.silence_on_error:
                self.log.error("Error occurs during changeset indexing. \
                    The error will not be propagated. Exception: %s", e)
            else:
                raise

    #IIndexParticipant members
    def build_doc(self, trac_doc):
        changeset = trac_doc

        doc = {
            IndexFields.ID: u'%s/%s' % (changeset.rev,
                                        changeset.repos.reponame),
            IndexFields.TYPE: CHANGESET_TYPE,
            ChangesetFields.MESSAGE: changeset.message,
            IndexFields.AUTHOR: changeset.author,
            IndexFields.TIME: changeset.date,
            ChangesetFields.REPOSITORY: changeset.repos.reponame,
            ChangesetFields.REVISION: changeset.repos.short_rev(changeset.rev)
        }
        return doc

    def get_entries_for_index(self):
        repository_manager = RepositoryManager(self.env)
        for repository in repository_manager.get_real_repositories():
            rev = repository.oldest_rev
            stop = repository.youngest_rev
            while True:
                changeset = repository.get_changeset(rev)
                yield self.build_doc(changeset)
                if rev == stop:
                    break
                rev = repository.next_rev(rev)


class ChangesetSearchParticipant(BaseSearchParticipant):
    implements(ISearchParticipant)

    participant_type = CHANGESET_TYPE
    required_permission = 'CHANGESET_VIEW'

    default_facets = [
        IndexFields.PRODUCT,
        ChangesetFields.REPOSITORY,
        ChangesetFields.AUTHOR,
    ]
    default_grid_fields = [
        ChangesetFields.REPOSITORY,
        ChangesetFields.REVISION,
        ChangesetFields.AUTHOR,
        ChangesetFields.MESSAGE
    ]
    prefix = CHANGESET_TYPE

    default_facets = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_facets',
        default=",".join(default_facets),
        doc="""Default facets applied to search view of specific resource""",
        doc_domain='bhsearch')

    default_view = Option(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_view',
        doc = """If true, show grid as default view for specific resource in
            Bloodhound Search results""", doc_domain='bhsearch')

    default_grid_fields = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_grid_fields',
        default=",".join(default_grid_fields),
        doc="""Default fields for grid view for specific resource""",
        doc_domain='bhsearch')

    #ISearchParticipant members
    def get_title(self):
        return "Changeset"

    def format_search_results(self, res):
        message = res['hilited_message'] or res['message']
        return tag(u'Changeset [', res['revision'], u']: ', message)

########NEW FILE########
__FILENAME__ = milestone_search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Milestone specifics for Bloodhound Search plugin."""
from bhsearch import BHSEARCH_CONFIG_SECTION
from bhsearch.api import (IIndexParticipant, BloodhoundSearchApi, IndexFields,
    ISearchParticipant)
from bhsearch.search_resources.base import BaseIndexer, BaseSearchParticipant
from bhsearch.search_resources.ticket_search import TicketIndexer
from bhsearch.utils import get_product
from trac.ticket import Milestone
from trac.config import ListOption, Option
from trac.core import implements
from trac.resource import IResourceChangeListener
from genshi.builder import tag

MILESTONE_TYPE = u"milestone"

class MilestoneFields(IndexFields):
    DUE = "due"
    COMPLETED = "completed"

class MilestoneIndexer(BaseIndexer):
    implements(IResourceChangeListener, IIndexParticipant)

    optional_fields = {
        'description': MilestoneFields.CONTENT,
        'due': MilestoneFields.DUE,
        'completed': MilestoneFields.COMPLETED,
    }

    # IResourceChangeListener methods
    def match_resource(self, resource):
        if isinstance(resource, Milestone):
            return True
        return False

    def resource_created(self, resource, context):
        # pylint: disable=unused-argument
        self._index_milestone(resource)

    def resource_changed(self, resource, old_values, context):
        # pylint: disable=unused-argument
        if "name" in old_values:
            self._rename_milestone(resource, old_values["name"])
        else:
            self._index_milestone(resource)

    def resource_deleted(self, resource, context):
        # pylint: disable=unused-argument
        try:
            search_api = BloodhoundSearchApi(self.env)
            search_api.delete_doc(
                get_product(self.env).prefix, MILESTONE_TYPE, resource.name)
        except Exception, e:
            if self.silence_on_error:
                self.log.error("Error occurs during milestone indexing. \
                    The error will not be propagated. Exception: %s", e)
            else:
                raise

    def _rename_milestone(self, milestone, old_name):
        try:
            doc = self.build_doc(milestone)
            search_api = BloodhoundSearchApi(self.env)
            with search_api.start_operation() as operation_context:
                search_api.change_doc_id(doc, old_name, operation_context)
                TicketIndexer(self.env).reindex_tickets(
                    search_api, operation_context, milestone=milestone.name)
        except Exception, e:
            if self.silence_on_error:
                self.log.error("Error occurs during renaming milestone from \
                 %s to %s. The error will not be propagated. Exception: %s",
                old_name, milestone.name, e)
            else:
                raise

    def _index_milestone(self, milestone):
        try:
            doc = self.build_doc(milestone)
            search_api = BloodhoundSearchApi(self.env)
            search_api.add_doc(doc)
        except Exception, e:
            if self.silence_on_error:
                self.log.error("Error occurs during wiki indexing. \
                    The error will not be propagated. Exception: %s", e)
            else:
                raise

    #IIndexParticipant members
    def build_doc(self, trac_doc):
        milestone = trac_doc
        #TODO: a lot of improvements must be added here.
        if milestone.is_completed:
            status = 'completed'
        else:
            status = 'open'
        doc = {
            IndexFields.ID: milestone.name,
            IndexFields.NAME: milestone.name,
            IndexFields.TYPE: MILESTONE_TYPE,
            IndexFields.STATUS: status,
            IndexFields.PRODUCT: get_product(self.env).prefix,
        }

        for field, index_field in self.optional_fields.iteritems():
            value = getattr(milestone, field, None)
            if value is not None:
                doc[index_field] = value

        return doc

    def get_entries_for_index(self):
        for milestone in Milestone.select(self.env, include_completed=True):
            yield self.build_doc(milestone)

class MilestoneSearchParticipant(BaseSearchParticipant):
    implements(ISearchParticipant)

    participant_type = MILESTONE_TYPE
    required_permission = 'MILESTONE_VIEW'

    default_facets = [
        IndexFields.PRODUCT,
    ]
    default_grid_fields = [
        MilestoneFields.ID, MilestoneFields.DUE, MilestoneFields.COMPLETED]
    prefix = MILESTONE_TYPE

    default_facets = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_facets',
        default=",".join(default_facets),
        doc="""Default facets applied to search view of specific resource""",
        doc_domain='bhsearch')

    default_view = Option(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_view',
        doc = """If true, show grid as default view for specific resource in
            Bloodhound Search results""", doc_domain='bhsearch')

    default_grid_fields = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_grid_fields',
        default=",".join(default_grid_fields),
        doc="""Default fields for grid view for specific resource""",
        doc_domain='bhsearch')

    #ISearchParticipant members
    def get_title(self):
        return "Milestone"

    def format_search_results(self, res):
        #TODO: add better milestone rendering

        name = res['hilited_name'] or res['name']
        product = res.get('product')
        if product:
            return tag(u'[', product, u'] Milestone:', name)
        else:
            return tag(u'Milestone:', name)

########NEW FILE########
__FILENAME__ = ticket_search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Ticket specifics for Bloodhound Search plugin."""
from bhsearch import BHSEARCH_CONFIG_SECTION
from bhsearch.api import (ISearchParticipant, BloodhoundSearchApi,
    IIndexParticipant, IndexFields)
from bhsearch.search_resources.base import BaseIndexer, BaseSearchParticipant
from bhsearch.utils import get_product
from genshi.builder import tag
from trac.ticket.api import TicketSystem
from trac.ticket import Ticket
from trac.config import ListOption, Option
from trac.core import implements
from trac.resource import IResourceChangeListener
from trac.ticket.model import Component

TICKET_TYPE = u"ticket"

class TicketFields(IndexFields):
    SUMMARY = "summary"
    MILESTONE = 'milestone'
    COMPONENT = 'component'
    KEYWORDS = "keywords"
    RESOLUTION = "resolution"
    CHANGES = 'changes'
    OWNER = 'owner'

class TicketIndexer(BaseIndexer):
    implements(IResourceChangeListener, IIndexParticipant)

    optional_fields = {
        'component': TicketFields.COMPONENT,
        'description': TicketFields.CONTENT,
        'keywords': TicketFields.KEYWORDS,
        'milestone': TicketFields.MILESTONE,
        'summary': TicketFields.SUMMARY,
        'status': TicketFields.STATUS,
        'resolution': TicketFields.RESOLUTION,
        'reporter': TicketFields.AUTHOR,
        'owner': TicketFields.OWNER,
    }

    def __init__(self):
        self.fields = TicketSystem(self.env).get_ticket_fields()
        self.text_area_fields = set(
            f['name'] for f in self.fields if f['type'] =='textarea')

    #IResourceChangeListener methods
    def match_resource(self, resource):
        if isinstance(resource, (Component, Ticket)):
            return True
        return False

    def resource_created(self, resource, context):
        # pylint: disable=unused-argument
        if isinstance(resource, Ticket):
            self._index_ticket(resource)

    def resource_changed(self, resource, old_values, context):
        # pylint: disable=unused-argument
        if isinstance(resource, Ticket):
            self._index_ticket(resource)
        elif isinstance(resource, Component):
            self._component_changed(resource, old_values)

    def resource_deleted(self, resource, context):
        # pylint: disable=unused-argument
        if isinstance(resource, Ticket):
            self._ticket_deleted(resource)

    def resource_version_deleted(self, resource, context):
        pass

    def _component_changed(self, component, old_values):
        if "name" in old_values:
            old_name = old_values["name"]
            try:
                search_api = BloodhoundSearchApi(self.env)
                with search_api.start_operation() as operation_context:
                    TicketIndexer(self.env).reindex_tickets(
                        search_api,
                        operation_context,
                        component=component.name)
            except Exception, e:
                if self.silence_on_error:
                    self.log.error("Error occurs during renaming Component \
                    from %s to %s. The error will not be propagated. \
                    Exception: %s",
                    old_name, component.name, e)
                else:
                    raise


    def _ticket_deleted(self, ticket):
        """Called when a ticket is deleted."""
        try:
            search_api = BloodhoundSearchApi(self.env)
            search_api.delete_doc(ticket.product, TICKET_TYPE, ticket.id)
        except Exception, e:
            if self.silence_on_error:
                self.log.error("Error occurs during deleting ticket. \
                    The error will not be propagated. Exception: %s", e)
            else:
                raise

    def reindex_tickets(self,
                        search_api,
                        operation_context,
                        **kwargs):
        for ticket in self._fetch_tickets(**kwargs):
            self._index_ticket(ticket, search_api, operation_context)

    def _fetch_tickets(self,  **kwargs):
        for ticket_id in self._fetch_ids(**kwargs):
            yield Ticket(self.env, ticket_id)

    def _fetch_ids(self, **kwargs):
        sql = "SELECT id FROM ticket"
        args = []
        conditions = []
        for key, value in kwargs.iteritems():
            args.append(value)
            conditions.append(key + "=%s")
        if conditions:
            sql = sql + " WHERE " + " AND ".join(conditions)
        for row in self.env.db_query(sql, args):
            yield int(row[0])

    def _index_ticket(self, ticket, search_api=None, operation_context=None):
        try:
            if not search_api:
                search_api = BloodhoundSearchApi(self.env)
            doc = self.build_doc(ticket)
            search_api.add_doc(doc, operation_context)
        except Exception, e:
            if self.silence_on_error:
                self.log.error("Error occurs during ticket indexing. \
                    The error will not be propagated. Exception: %s", e)
            else:
                raise

    #IIndexParticipant members
    def build_doc(self, trac_doc):
        ticket = trac_doc
        searchable_name = '#%(ticket.id)s %(ticket.id)s' %\
                          {'ticket.id': ticket.id}
        doc = {
            IndexFields.ID: str(ticket.id),
            IndexFields.NAME: searchable_name,
            '_stored_' + IndexFields.NAME: str(ticket.id),
            IndexFields.TYPE: TICKET_TYPE,
            IndexFields.TIME: ticket.time_changed,
            IndexFields.PRODUCT: get_product(self.env).prefix,
        }
        # TODO: Add support for moving tickets between products.


        for field, index_field in self.optional_fields.iteritems():
            if field in ticket.values:
                field_content = ticket.values[field]
                if field in self.text_area_fields:
                    field_content = self.wiki_formatter.format(field_content)
                doc[index_field] = field_content

        doc[TicketFields.CHANGES] = u'\n\n'.join(
            [self.wiki_formatter.format(x[4]) for x in ticket.get_changelog()
             if x[2] == u'comment'])
        return doc

    def get_entries_for_index(self):
        for ticket in self._fetch_tickets():
            yield self.build_doc(ticket)

class TicketSearchParticipant(BaseSearchParticipant):
    implements(ISearchParticipant)

    participant_type = TICKET_TYPE
    required_permission = 'TICKET_VIEW'

    default_facets = [
        IndexFields.PRODUCT,
        TicketFields.STATUS,
        TicketFields.MILESTONE,
        TicketFields.COMPONENT,
        ]
    default_grid_fields = [
        TicketFields.ID,
        TicketFields.SUMMARY,
        TicketFields.STATUS,
        TicketFields.MILESTONE,
        TicketFields.COMPONENT,
        ]
    prefix = TICKET_TYPE

    default_facets = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_facets',
        default=",".join(default_facets),
        doc="""Default facets applied to search view of specific resource""",
        doc_domain='bhsearch')

    default_view = Option(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_view',
        doc = """If true, show grid as default view for specific resource in
            Bloodhound Search results""", doc_domain='bhsearch')

    default_grid_fields = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_grid_fields',
        default = ",".join(default_grid_fields),
        doc="""Default fields for grid view for specific resource""",
        doc_domain='bhsearch')

    #ISearchParticipant members
    def get_title(self):
        return "Ticket"

    def format_search_results(self, res):
        if not TicketFields.STATUS in res:
            stat = 'undefined_status'
            css_class = 'undefined_status'
        else:
            css_class = res[TicketFields.STATUS]
            if res[TicketFields.STATUS] == 'closed':
                resolution = ""
                if 'resolution' in res:
                    resolution = res['resolution']
                stat = '%s: %s' % (res['status'], resolution)
            else:
                stat = res[TicketFields.STATUS]

        id = res['hilited_id'] or res['id']
        id = tag.span(u'#', id, class_=css_class)
        summary = res['hilited_summary'] or res['summary']
        product = res.get('product')
        if product:
            return tag(u'[', product, u'] ', id, u': ', summary, u' (%s)' % stat)
        else:
            return tag(id, u': ', summary, u' (%s)' % stat)

########NEW FILE########
__FILENAME__ = wiki_search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Wiki specifics for Bloodhound Search plugin."""
from bhsearch import BHSEARCH_CONFIG_SECTION
from bhsearch.api import (ISearchParticipant, BloodhoundSearchApi,
    IIndexParticipant, IndexFields)
from bhsearch.search_resources.base import BaseIndexer, BaseSearchParticipant
from bhsearch.utils import get_product
from trac.core import implements
from trac.config import ListOption, Option
from trac.wiki import IWikiChangeListener, WikiSystem, WikiPage
from genshi.builder import tag

WIKI_TYPE = u"wiki"


class WikiIndexer(BaseIndexer):
    implements(IWikiChangeListener, IIndexParticipant)

    #IWikiChangeListener methods
    def wiki_page_added(self, page):
        """Index a recently created ticket."""
        self._index_wiki(page)


    def wiki_page_changed(self, page, version, t, comment, author, ipnr):
        """Reindex a recently modified ticket."""
        # pylint: disable=too-many-arguments, unused-argument
        self._index_wiki(page)

    def wiki_page_deleted(self, page):
        """Called when a ticket is deleted."""
        try:
            search_api = BloodhoundSearchApi(self.env)
            search_api.delete_doc(
                get_product(self.env).prefix, WIKI_TYPE, page.name)
        except Exception, e:
            if self.silence_on_error.lower() == "true":
                self.log.error("Error occurs during wiki indexing. \
                    The error will not be propagated. Exception: %s", e)
            else:
                raise

    def wiki_page_version_deleted(self, page):
        """Called when a version of a page has been deleted."""
        self._index_wiki(page)

    def wiki_page_renamed(self, page, old_name):
        """Called when a page has been renamed."""
        try:
            doc = self.build_doc(page)
            search_api = BloodhoundSearchApi(self.env)
            search_api.change_doc_id(doc, old_name)
        except Exception, e:
            if self.silence_on_error:
                self.log.error("Error occurs during renaming wiki from %s \
                    to %s. The error will not be propagated. Exception: %s",
                old_name, page.name, e)
            else:
                raise

    def _index_wiki(self, page):
        try:
            doc = self.build_doc(page)
            search_api = BloodhoundSearchApi(self.env)
            search_api.add_doc(doc)
        except Exception, e:
            page_name = None
            if page is not None:
                page_name = page.name
            if self.silence_on_error:
                self.log.error("Error occurs during wiki indexing: %s. \
                    The error will not be propagated. Exception: %s",
                    page_name, e)
            else:
                raise

    #IIndexParticipant members
    def build_doc(self, trac_doc):
        page = trac_doc
        #This is very naive prototype implementation
        #TODO: a lot of improvements must be added here!!!
        searchable_name = page.name + ' ' + \
            WikiSystem(self.env).format_page_name(page.name, split=True)

        doc = {
            IndexFields.ID: page.name,
            IndexFields.NAME: searchable_name,
            '_stored_' + IndexFields.NAME: page.name,
            IndexFields.TYPE: WIKI_TYPE,
            IndexFields.TIME: page.time,
            IndexFields.AUTHOR: page.author,
            IndexFields.CONTENT: self.wiki_formatter.format(page.text),
            IndexFields.PRODUCT: get_product(self.env).prefix,
        }
        return doc

    def get_entries_for_index(self):
        page_names = WikiSystem(self.env).get_pages()
        for page_name in page_names:
            page = WikiPage(self.env, page_name)
            yield self.build_doc(page)

class WikiSearchParticipant(BaseSearchParticipant):
    implements(ISearchParticipant)

    participant_type = WIKI_TYPE
    required_permission = 'WIKI_VIEW'

    default_facets = [
        IndexFields.PRODUCT,
    ]
    default_grid_fields = [
        IndexFields.ID,
        IndexFields.TIME,
        IndexFields.AUTHOR,
        IndexFields.CONTENT,
    ]
    prefix = WIKI_TYPE

    default_facets = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_facets',
        default=",".join(default_facets),
        doc="""Default facets applied to search view of specific resource""",
        doc_domain='bhsearch')

    default_view = Option(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_view',
        doc = """If true, show grid as default view for specific resource in
            Bloodhound Search results""", doc_domain='bhsearch')

    default_grid_fields = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_grid_fields',
        default = ",".join(default_grid_fields),
        doc="""Default fields for grid view for specific resource""",
        doc_domain='bhsearch')

    #ISearchParticipant members
    def get_title(self):
        return "Wiki"

    def format_search_results(self, res):
        title = res['hilited_name'] or res['name']
        product = res.get('product')
        if product:
            return tag(u'[', product, u'] ', title)
        else:
            return tag(title)

########NEW FILE########
__FILENAME__ = security
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.
from itertools import groupby
import os

from trac.core import Component, implements, ExtensionPoint
from trac.perm import PermissionSystem
from tracopt.perm.authz_policy import AuthzPolicy
from whoosh import query

from multiproduct.env import ProductEnvironment

from bhsearch.api import (IDocIndexPreprocessor, IndexFields,
                          IQueryPreprocessor, ISearchParticipant)
from bhsearch.utils import get_product, instance_for_every_env, is_enabled


class SecurityPreprocessor(Component):
    participants = ExtensionPoint(ISearchParticipant)

    def __init__(self):
        self._required_permissions = {}
        for participant in self.participants:
            permission = participant.get_required_permission()
            doc_type = participant.get_participant_type()
            self._required_permissions[doc_type] = permission

    def check_permission(self, doc, context):
        product, doctype, id = doc.get('product'), doc['type'], doc['id']
        username = context.req.authname
        env = self.env
        if product:
            env = ProductEnvironment(self.env, product)
        perm = PermissionSystem(env)
        action = self._required_permissions[doctype]
        return perm.check_permission(action, username, id)

    def update_security_filter(self, query_parameters, allowed=(), denied=()):
        security_filter = self.create_security_filter(query_parameters)
        security_filter.add_allowed(allowed)
        security_filter.add_denied(denied)

    def create_security_filter(self, query_parameters):
        security_filter = self.find_security_filter(query_parameters['filter'])
        if not security_filter:
            security_filter = SecurityFilter()
            if query_parameters['filter']:
                query_parameters['filter'] = query.And([query_parameters['filter'],
                                                        security_filter])
            else:
                query_parameters['filter'] = security_filter
        return security_filter

    def find_security_filter(self, existing_query):
        queue = [existing_query]
        while queue:
            token = queue.pop(0)
            if isinstance(token, SecurityFilter):
                return token
            if isinstance(token, query.CompoundQuery):
                queue.extend(token.subqueries)


class DefaultSecurityPreprocessor(SecurityPreprocessor):
    implements(IDocIndexPreprocessor, IQueryPreprocessor)

    # IDocIndexPreprocessor methods
    def pre_process(self, doc):
        permission = self._required_permissions[doc[IndexFields.TYPE]]
        doc[IndexFields.REQUIRED_PERMISSION] = permission

    # IQueryPreprocessor methods
    def query_pre_process(self, query_parameters, context=None):
        if context is None:
            return

        def allowed_documents():
            #todo: add special case handling for trac_admin and product_owner
            for product, perm in self._get_all_user_permissions(context):
                if product:
                    prod_term = query.Term(IndexFields.PRODUCT, product)
                else:
                    prod_term = query.Not(query.Every(IndexFields.PRODUCT))
                perm_term = query.Term(IndexFields.REQUIRED_PERMISSION, perm)
                yield query.And([prod_term, perm_term])

        self.update_security_filter(query_parameters,
                                    allowed=allowed_documents())

    def _get_all_user_permissions(self, context):
        username = context.req.authname
        permissions = []
        for perm in instance_for_every_env(self.env, PermissionSystem):
            prefix = get_product(perm.env).prefix
            for action in self._required_permissions.itervalues():
                if perm.check_permission(action, username):
                    permissions.append((prefix, action))
        return permissions


class AuthzSecurityPreprocessor(SecurityPreprocessor):
    implements(IQueryPreprocessor)

    def __init__(self):
        SecurityPreprocessor.__init__(self)
        ps = PermissionSystem(self.env)
        self.enabled = (is_enabled(self.env, AuthzPolicy)
                        and any(isinstance(policy, AuthzPolicy)
                                for policy in ps.policies))

    # IQueryPreprocessor methods
    def query_pre_process(self, query_parameters, context=None):
        if not self.enabled:
            return

        permissions = self.get_user_permissions(context.req.authname)
        allowed_docs, denied_docs = [], []
        for product, doc_type, doc_id, perm, denied in permissions:
            term_spec = []
            if product:
                term_spec.append(query.Term(IndexFields.PRODUCT, product))
            else:
                term_spec.append(query.Not(query.Every(IndexFields.PRODUCT)))

            if doc_type != '*':
                term_spec.append(query.Term(IndexFields.TYPE, doc_type))
            if doc_id != '*':
                term_spec.append(query.Term(IndexFields.ID, doc_id))
            term_spec.append(query.Term(IndexFields.REQUIRED_PERMISSION, perm))
            term_spec = query.And(term_spec)
            if denied:
                denied_docs.append(term_spec)
            else:
                allowed_docs.append(term_spec)
        self.update_security_filter(query_parameters, allowed_docs, denied_docs)

    def get_user_permissions(self, username):
        for policy in instance_for_every_env(self.env, AuthzPolicy):
            product = get_product(policy.env).prefix
            self.refresh_config(policy)

            for doc_type, doc_id, perm, denied in self.get_relevant_permissions(policy, username):
                yield product, doc_type, doc_id, perm, denied

    def get_relevant_permissions(self, policy, username):
        ps = PermissionSystem(self.env)
        relevant_permissions = set(self._required_permissions.itervalues())
        user_permissions = self.get_all_user_permissions(policy, username)
        for doc_type, doc_id, permissions in user_permissions:
            for deny, perms in groupby(permissions,
                                       key=lambda p: p.startswith('!')):
                if deny:
                    for p in ps.expand_actions([p[1:] for p in perms]):
                        if p in relevant_permissions:
                            yield doc_type, doc_id, p, True
                else:
                    for p in ps.expand_actions(perms):
                        if p in relevant_permissions:
                            yield doc_type, doc_id, p, False

    def get_all_user_permissions(self, policy, username):
        relevant_users = self.get_relevant_users(username)
        for doc_type, doc_id, section in self.get_all_permissions(policy):
            for who, permissions in section.iteritems():
                if who in relevant_users or \
                        who in policy.groups_by_user.get(username, []):
                    if isinstance(permissions, basestring):
                        permissions = [permissions]
                    yield doc_type, doc_id, permissions

    def get_all_permissions(self, policy):
        for section_name in policy.authz.sections:
            if section_name == 'groups':
                continue
            if '/' in section_name:
                continue  # advanced permissions are not supported at the moment

            type_id = section_name.split('@', 1)[0]
            if ':' in type_id:
                doc_type, doc_id = type_id.split(':')
            else:
                doc_type, doc_id = '**'
            yield doc_type, doc_id, policy.authz[section_name]

    def get_relevant_users(self, username):
        if username and username != 'anonymous':
            return ['*', 'authenticated', username]
        else:
            return ['*', 'anonymous']

    def refresh_config(self, policy):
        if (
            policy.authz_file and not policy.authz_mtime
            or os.path.getmtime(policy.get_authz_file()) > policy.authz_mtime
        ):
            policy.parse_authz()


class SecurityFilter(query.AndNot):
    def __init__(self):
        super(SecurityFilter, self).__init__(query.NullQuery, query.NullQuery)

    def add_allowed(self, allowed):
        if self.a == query.NullQuery:
            self.a = query.Or([])

        self.a.subqueries.extend(allowed)
        self.subqueries = (self.a, self.b)

    def add_denied(self, denied):
        if self.b == query.NullQuery:
            self.b = query.Or([])

        self.b.subqueries.extend(denied)
        self.subqueries = (self.a, self.b)

    def __repr__(self):
        r = "%s(allow=%r, deny=%r)" % (self.__class__.__name__,
                                       self.a, self.b)
        return r

########NEW FILE########
__FILENAME__ = api
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.
import shutil

from bhsearch.api import BloodhoundSearchApi, ASC, SortInstruction, IIndexParticipant, IndexFields
from bhsearch.query_parser import DefaultQueryParser
from bhsearch.search_resources.base import BaseIndexer
from bhsearch.search_resources.ticket_search import TicketSearchParticipant
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.whoosh_backend import WhooshBackend
from trac.core import implements, ComponentMeta


class ApiQueryWithWhooshTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(ApiQueryWithWhooshTestCase, self).setUp(create_req=True)
        WhooshBackend(self.env).recreate_index()
        self.search_api = BloodhoundSearchApi(self.env)
        self.ticket_participant = TicketSearchParticipant(self.env)
        self.query_parser = DefaultQueryParser(self.env)

    def tearDown(self):
        shutil.rmtree(self.env.path)
        self.env.reset_db()

    def test_can_search_free_description(self):
        #arrange
        self.insert_ticket("dummy summary", description="aaa keyword bla")
        #act
        results = self.search_api.query("keyword")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)

    def test_can_query_free_summary(self):
        #arrange
        self.insert_ticket("summary1 keyword")
        #act
        results = self.search_api.query("keyword")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)

    def test_can_query_strict_summary(self):
        #arrange
        self.insert_ticket("summary1 keyword")
        self.insert_ticket("summary2", description = "bla keyword")
        #act
        results = self.search_api.query("summary:keyword")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)

    def test_that_summary_hit_is_higher_than_description(self):
        #arrange
        self.insert_ticket("summary1 keyword")
        self.insert_ticket("summary2", description = "bla keyword")
        #act
        results = self.search_api.query("keyword")
        self.print_result(results)
        #assert
        self.assertEqual(2, results.hits)
        docs = results.docs
        self.assertEqual("summary1 keyword", docs[0]["summary"])
        self.assertEqual("summary2", docs[1]["summary"])

    def test_other_conditions_applied(self):
        #arrange
        self.insert_ticket("summary1 keyword", status="closed")
        self.insert_ticket("summary2", description = "bla keyword")
        self.insert_ticket("summary3", status="closed")
        #act
        results = self.search_api.query("keyword status:closed")
        self.print_result(results)
        #assert
        self.assertEqual(1, results.hits)
        docs = results.docs
        self.assertEqual("summary1 keyword", docs[0]["summary"])

    def test_that_filter_queries_applied(self):
        #arrange
        self.insert_ticket("t1", status="closed", component = "c1")
        self.insert_ticket("t2", status="closed", component = "c1")
        self.insert_ticket("t3", status="closed",
            component = "NotInFilterCriteria")
        #act
        results = self.search_api.query(
            "*",
            filter= ['status:"closed"', 'component:"c1"'],
            sort= [SortInstruction("id", ASC)]
        )
        self.print_result(results)
        #assert
        self.assertEqual(2, results.hits)
        docs = results.docs
        self.assertEqual("t1", docs[0]["summary"])
        self.assertEqual("t2", docs[1]["summary"])

    def test_that_upgrading_environment_adds_documents_to_index(self):
        self.insert_ticket("t1")
        self.insert_ticket("t2")

        self.search_api.upgrade_environment(self.env.db_transaction)

        results = self.search_api.query("type:ticket")

        self.assertEqual(2, results.hits)

    def test_can_index_wiki_with_same_id_from_different_products(self):
        with self.product('p1'):
            self.insert_wiki('title', 'content')
        with self.product('p2'):
            self.insert_wiki('title', 'content 2')

        results = self.search_api.query("type:wiki")

        self.assertEqual(results.hits, 2)

    def test_upgrade_index_with_no_product(self):
        """See #773"""

        class NoProductIndexer(BaseIndexer):
            implements(IIndexParticipant)

            def get_entries_for_index(self):
                yield {
                    IndexFields.TYPE: 'noproduct',
                    IndexFields.ID: '1'
                }

        self.search_api.rebuild_index()

        self.unregister(NoProductIndexer)

    @staticmethod
    def unregister(component):
        ComponentMeta._components.remove(component)
        for interface in component.__dict__.get('_implements', ()):
            ComponentMeta._registry.get(interface).remove(component)

#TODO: check this later
#    @unittest.skip("Check with Whoosh community")
#    def test_can_search_id_and_summary(self):
#        #arrange
#        self.insert_ticket("summary1")
#        self.insert_ticket("summary2 1")
#        #act
#        results = self.search_api.query("1")
#        self.print_result(results)
#        #assert
#        self.assertEqual(2, results.hits)
#        docs = results.docs
#        self.assertEqual("summary1", docs[0]["summary"])


def suite():
    return unittest.makeSuite(ApiQueryWithWhooshTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = base
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""
Test utils methods
"""
import contextlib
import shutil
import tempfile

from trac.test import EnvironmentStub, Mock, MockPerm
from trac.ticket import Ticket, Milestone
from trac.web import Href, arg_list_to_args
from trac.wiki import WikiPage

from bhsearch.tests import unittest
from bhsearch.web_ui import BloodhoundSearchModule

BASE_PATH = "/main/"


class BaseBloodhoundSearchTest(unittest.TestCase):

    def setUp(self, enabled=None, create_req=False, enable_security=False):
        if not enabled:
            enabled = ['trac.*', 'bhsearch.*']
        if not enable_security:
            disabled = ['bhsearch.security.*']
        else:
            disabled = []

        self.env = EnvironmentStub(enable=enabled, disable=disabled)
        self.env.path = tempfile.mkdtemp('bhsearch-tempenv')
        self.env.config.set('bhsearch', 'silence_on_error', "False")
        if create_req:
            self.req = Mock(
                perm=MockPerm(),
                chrome={'logo': {}, 'links': {}},
                href=Href("/main"),
                base_path=BASE_PATH,
                path_info='/bhsearch',
                args=arg_list_to_args([]),
                authname='x',
            )
            self.context = Mock(req=self.req)

        # Test without multiproduct.
        if hasattr(self.env, 'parent'):
            del self.env.parent

    def tearDown(self):
        shutil.rmtree(self.env.path)
        self.env.reset_db()

    def print_result(self, result):
        self.env.log.debug("Received result: %s", result.__dict__)

    def create_dummy_ticket(self, summary = None):
        if not summary:
            summary = 'Hello World'
        data = {'component': 'foo', 'milestone': 'bar'}
        return self.create_ticket(summary, reporter='john', **data)

    def create_ticket(self, summary, **kw):
        ticket = Ticket(self.env)
        ticket["summary"] = summary
        for k, v in kw.items():
            ticket[k] = v
        return ticket

    def insert_ticket(self, summary, **kw):
        """Helper for inserting a ticket into the database"""
        ticket = self.create_ticket(summary, **kw)
        ticket.insert()
        return ticket

    def create_wiki(self, name, text,  **kw):
        page = WikiPage(self.env, name)
        page.text = text
        for k, v in kw.items():
            page[k] = v
        return page

    def insert_wiki(self, name, text = None, **kw):
        text = text or "Dummy text"
        page = self.create_wiki(name, text, **kw)
        return page.save("dummy author", "dummy comment", "::1")

    def insert_milestone(self, name, description = None):
        milestone = self.create_milestone(
            name = name,
            description = description)
        milestone.insert()
        return milestone

    def create_milestone(self, name, description = None):
        milestone = Milestone(self.env)
        milestone.name = name
        if description is not None:
            milestone.description = description
        return milestone

    def change_milestone(self, name_to_change, name=None, description=None):
        milestone = Milestone(self.env, name_to_change)
        if name is not None:
            milestone.name = name
        if description is not None:
            milestone.description = description
        milestone.update()
        return milestone

    def process_request(self):
        # pylint: disable=unused-variable
        url, data, x = BloodhoundSearchModule(self.env).process_request(
            self.req)
        self.env.log.debug("Received url: %s data: %s", url, data)
        if 'results' in data:
            self.env.log.debug("results: %s", data["results"].__dict__)
        return data

    @contextlib.contextmanager
    def product(self, prefix=''):
        has_parent = hasattr(self.env, 'parent')
        has_product = hasattr(self.env, 'product')
        if has_parent:
            old_parent = self.env.parent
        if has_product:
            old_product = self.env.product

        self.env.parent = self.env
        self.env.product = Mock(prefix=prefix)
        yield

        if has_parent:
            self.env.parent = old_parent
        else:
            del self.env.parent
        if has_product:
            self.env.product = old_product
        else:
            del self.env.product

########NEW FILE########
__FILENAME__ = index_with_whoosh
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import shutil

from bhsearch.api import BloodhoundSearchApi
from bhsearch.search_resources.milestone_search import MilestoneIndexer
from bhsearch.search_resources.ticket_search import TicketIndexer
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.whoosh_backend import WhooshBackend


class IndexWhooshTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(IndexWhooshTestCase, self).setUp()
        self.whoosh_backend = WhooshBackend(self.env)
        self.whoosh_backend.recreate_index()
        self.search_api = BloodhoundSearchApi(self.env)

    def tearDown(self):
        shutil.rmtree(self.env.path)
        self.env.reset_db()

    def test_can_index_ticket(self):
        ticket = self.create_dummy_ticket()
        TicketIndexer(self.env).resource_created(ticket, None)

        results = self.search_api.query("*:*")
        self.print_result(results)
        self.assertEqual(1, results.hits)

    def test_that_ticket_indexed_when_inserted_in_db(self):
        ticket = self.create_dummy_ticket()
        ticket.insert()
        results = self.search_api.query("*:*")
        self.print_result(results)
        self.assertEqual(1, results.hits)

    def test_can_reindex_twice(self):
        self.insert_ticket("t1")
        self.whoosh_backend.recreate_index()
        #act
        self.search_api.rebuild_index()
         #just to test that index was re-created
        self.search_api.rebuild_index()
        #assert
        results = self.search_api.query("*:*")
        self.assertEqual(1, results.hits)

    def test_can_reindex_tickets(self):
        self.insert_ticket("t1")
        self.insert_ticket("t2")
        self.insert_ticket("t3")
        self.whoosh_backend.recreate_index()
        #act
        self.search_api.rebuild_index()
        #assert
        results = self.search_api.query("*:*")
        self.print_result(results)
        self.assertEqual(3, results.hits)

    def test_can_reindex_wiki(self):
        self.insert_wiki("page1", "some text")
        self.insert_wiki("page2", "some text")
        self.whoosh_backend.recreate_index()
        #act
        self.search_api.rebuild_index()
        #assert
        results = self.search_api.query("*:*")
        self.print_result(results)
        self.assertEqual(2, results.hits)

    def test_can_reindex_mixed_types(self):
        self.insert_wiki("page1", "some text")
        self.insert_ticket("t1")
        self.whoosh_backend.recreate_index()
        #act
        self.search_api.rebuild_index()
        #assert
        results = self.search_api.query("*:*")
        self.print_result(results)
        self.assertEqual(2, results.hits)

    def test_can_reindex_milestones(self):
        MilestoneIndexer(self.env)
        self.insert_milestone("M1")
        self.insert_milestone("M2")
        self.whoosh_backend.recreate_index()
        #act
        self.search_api.rebuild_index()
        #assert
        results = self.search_api.query("*:*")
        self.print_result(results)
        self.assertEqual(2, results.hits)

def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(IndexWhooshTestCase, 'test'))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = query_parser
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.test import Mock

from bhsearch.query_parser import DefaultQueryParser
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from whoosh import query


class MetaKeywordsParsingTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(MetaKeywordsParsingTestCase, self).setUp()
        self.parser = DefaultQueryParser(self.env)

    def test_can_parse_keyword_ticket(self):
        parsed_query = self.parser.parse("$ticket")
        self.assertEqual(parsed_query, query.Term('type', 'ticket'))

    def test_can_parse_NOT_keyword_ticket(self):
        parsed_query = self.parser.parse("NOT $ticket")
        self.assertEqual(parsed_query,
                         query.Not(
                             query.Term('type', 'ticket')))

    def test_can_parse_keyword_wiki(self):
        parsed_query = self.parser.parse("$wiki")
        self.assertEqual(parsed_query, query.Term('type', 'wiki'))

    def test_can_parse_keyword_resolved(self):
        parsed_query = self.parser.parse("$resolved")
        self.assertEqual(parsed_query,
                         query.Or([query.Term('status', 'resolved'),
                                   query.Term('status', 'closed')]))

    def test_can_parse_meta_keywords_that_resolve_to_meta_keywords(self):
        parsed_query = self.parser.parse("$unresolved")
        self.assertEqual(parsed_query,
                         query.Not(
                         query.Or([query.Term('status', 'resolved'),
                                   query.Term('status', 'closed')])))

    def test_can_parse_complex_query(self):
        parsed_query = self.parser.parse("content:test $ticket $unresolved")

        self.assertEqual(parsed_query,
                         query.And([
                             query.Term('content', 'test'),
                             query.Term('type', 'ticket'),
                             query.Not(
                                 query.Or([query.Term('status', 'resolved'),
                                           query.Term('status', 'closed')])
                             )
                         ]))

    def test_can_parse_keyword_me(self):
        context = self._mock_context_with_username('username')

        parsed_query = self.parser.parse("author:$me", context)

        self.assertEqual(parsed_query, query.Term('author', 'username'))

    def test_can_parse_keyword_my(self):
        context = self._mock_context_with_username('username')

        parsed_query = self.parser.parse("$my", context)

        self.assertEqual(parsed_query, query.Term('owner', 'username'))

    def _mock_context_with_username(self, username):
        context = Mock(
            req=Mock(
                authname=username
            )
        )
        return context


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(MetaKeywordsParsingTestCase, 'test'))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = query_suggestion
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from bhsearch.api import BloodhoundSearchApi
from bhsearch.query_suggestion import SuggestionFields
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.web_ui import RequestParameters, RequestContext
from bhsearch.whoosh_backend import WhooshBackend


class QuerySuggestionTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(QuerySuggestionTestCase, self).setUp(create_req=True)
        self.whoosh_backend = WhooshBackend(self.env)
        self.whoosh_backend.recreate_index()

        self.search_api = BloodhoundSearchApi(self.env)

    def test_fills_suggestion_field(self):
        self.insert_ticket("test")
        self.insert_milestone("test")
        self.insert_wiki("name", "test")

        results = self.search_api.query("%s:test" % SuggestionFields.BASKET)

        self.assertEqual(results.hits, 3)

    def test_provides_suggestions(self):
        self.insert_ticket("test")
        self.req.args[RequestParameters.QUERY] = "tesk"

        data = self.process_request()

        self.assertIn(RequestContext.DATA_QUERY_SUGGESTION, data)
        suggestion = data[RequestContext.DATA_QUERY_SUGGESTION]
        self.assertEqual(suggestion['query'], 'test')
        self.assertIn('q=test', suggestion['href'])

    def test_provides_suggestions_for_multi_term_queries(self):
        self.insert_ticket("another test")
        self.req.args[RequestParameters.QUERY] = "another tesk"

        data = self.process_request()

        suggestion = data[RequestContext.DATA_QUERY_SUGGESTION]
        self.assertEqual(suggestion['query'], 'another test')

    def test_provides_suggestions_for_queries_with_unknown_words(self):
        self.insert_ticket("test")
        self.req.args[RequestParameters.QUERY] = "another tesk"

        data = self.process_request()

        suggestion = data[RequestContext.DATA_QUERY_SUGGESTION]
        self.assertEqual(suggestion['query'], 'another test')

    def test_suggestion_href_contains_used_filters(self):
        self.insert_ticket("test")
        self.req.args[RequestParameters.QUERY] = "tesk"
        self.req.args[RequestParameters.FILTER_QUERY] = ['filter']

        data = self.process_request()

        suggestion = data[RequestContext.DATA_QUERY_SUGGESTION]
        self.assertIn('fq=filter', suggestion['href'])


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(QuerySuggestionTestCase))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = real_index_view
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import os

from trac.test import EnvironmentStub, Mock, MockPerm
from trac.web import Href, arg_list_to_args

from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.web_ui import RequestParameters
from bhsearch.whoosh_backend import WhooshBackend
from whoosh import query


class RealIndexTestCase(BaseBloodhoundSearchTest):
    """
    This test case is not supposed to be run from CI tool.
    The purpose of the class is to work with real Bloodhound Search Index and
    should be used for debugging purposes only
    """
    def setUp(self):
        self.env = EnvironmentStub(enable=['bhsearch.*'])
        current_current_dir = os.getcwd()

        real_env_path = os.path.join(
            current_current_dir,
            "../../../installer/bloodhound/environments/main")
        self.env.path = real_env_path
        self.whoosh_backend = WhooshBackend(self.env)

        self.req = Mock(
            perm=MockPerm(),
            chrome={'logo': {}},
            href=Href("/main"),
            args=arg_list_to_args([]),
        )

    def test_read_all(self):
        result = self.whoosh_backend.query(
            query.Every()
        )
        self.print_result(result)

        result = self.whoosh_backend.query(
            query.Every()
        )
        self.print_result(result)
        self.assertLessEqual(1, result.hits)

    def test_read_with_type_facet(self):
        result = self.whoosh_backend.query(
            query.Every()
        )
        self.print_result(result)

        result = self.whoosh_backend.query(
            query.Every(),
            facets=["type"]
        )
        self.print_result(result)
        self.assertLessEqual(1, result.hits)

    def test_read_from_search_module(self):
        self.req.args[RequestParameters.QUERY] = "*"
        self.process_request()

def suite():
    pass

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = base
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.test import MockPerm
from trac.web import Href
from trac.wiki import format_to_html

from bhsearch.search_resources.base import SimpleSearchWikiSyntaxFormatter
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest


class SimpleSearchWikiSyntaxFormatterTestCase(BaseBloodhoundSearchTest):

    def setUp(self):
        super(SimpleSearchWikiSyntaxFormatterTestCase, self).setUp(
            create_req=True,
        )
        self.text_formatter = SimpleSearchWikiSyntaxFormatter(self.env)

    def test_can_format_header(self):
        wiki_content = """= Header #overview
        some text"""
        result = self._call_format(wiki_content)
        self.assertEqual("Header overview some text", result)

    def test_can_format_code(self):
        wiki_content = """{{{
        some code
        }}}
        text"""
        result = self._call_format(wiki_content)
        self.assertEqual("some code text", result)

    def test_can_format_anchor(self):
        wiki_content = """sometext1
        [#point1]
        sometext2
        """
        result = self._call_format(wiki_content)
        self.assertEqual("sometext1 point1 sometext2", result)

    def test_can_format_wiki_link(self):
        self.assertEqual(
            "wiki:SomePage p1", self._call_format("[wiki:SomePage p1]"))

    def test_can_format_sample_wiki_link(self):
        self.assertEqual("WikiPage", self._call_format("WikiPage"))

    def test_can_format_makro(self):
        """
        Makro links must be formatted as text
        """
        self.assertEqual(
            "TicketQuery(keywords~x, formattable, colid)",
            self._call_format(
                "[[TicketQuery(keywords=~x, format=table, col=id)]]"))

    def test_can_format_stared_font_makers(self):
        self.assertEqual(
            "bold, italic, WikiCreole style",
            self._call_format(
                "**bold**, //italic//, **//WikiCreole style//**"))

    @unittest.skip("TODO")
    def test_can_format_non_wiki_camel_case(self):
        self.assertEqual("WikiPage", self._call_format("!WikiPage"))

    def _call_format(self, wiki_content):
        result = self.text_formatter.format(wiki_content)
        self.env.log.debug(
            "Input text:\n%s\nFormatted text:\n%s",
            wiki_content,
            result)
        return result

    @unittest.skip("Use for debug purposes only")
    def test_run_html_formatter(self):
        wiki_content = "!WikiSyntax"
        page = self.create_wiki("Dummy wiki", wiki_content)
        from trac.mimeview.api import RenderingContext
        context = RenderingContext(
            page.resource,
            href=Href('/'),
            perm=MockPerm(),
        )
        context.req = None # 1.0 FIXME .req shouldn't be required by formatter
        format_to_html(self.env, context, wiki_content)


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(
        unittest.makeSuite(SimpleSearchWikiSyntaxFormatterTestCase, 'test'))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = changeset_search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.core import Component, implements
from trac.versioncontrol import Changeset
from trac.versioncontrol.api import (
    IRepositoryConnector, Repository, RepositoryManager)

from bhsearch.api import BloodhoundSearchApi
from bhsearch.search_resources.changeset_search import (
    ChangesetSearchParticipant)
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.whoosh_backend import WhooshBackend


class ChangesetIndexerEventsTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(ChangesetIndexerEventsTestCase, self).setUp()
        self.whoosh_backend = WhooshBackend(self.env)
        self.whoosh_backend.recreate_index()
        self.search_api = BloodhoundSearchApi(self.env)
        self.repository_manager = RepositoryManager(self.env)
        self.inject_dummy_repository()

    def test_can_index_added_changeset(self):
        rev = self.insert_changeset("Changed document 1.")

        results = self.search_api.query("*:*")

        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual('%s/dummy' % rev, doc["id"])
        self.assertEqual('dummy', doc["repository"])
        self.assertEqual('1', doc["revision"])
        self.assertEqual("Changed document 1.", doc["message"])

    def test_can_index_modified_changeset(self):
        rev = self.insert_changeset("Changed document 1.")
        self.modify_changeset(rev, "Added document 1.")

        results = self.search_api.query("*:*")

        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual('%s/dummy' % rev, doc["id"])
        self.assertEqual('dummy', doc["repository"])
        self.assertEqual('1', doc["revision"])
        self.assertEqual("Added document 1.", doc["message"])

    def insert_changeset(self, message, author=None, date=None, revision=None):
        rev = self.repository.add_changeset(revision, message, author, date)
        self.repository_manager.notify("changeset_added", 'dummy', [rev])
        return rev

    def modify_changeset(self, rev, message=None, author=None, date=None):
        changeset = self.repository.get_changeset(rev)
        if message is not None:
            changeset.message = message
        if author is not None:
            changeset.author = author
        if date is not None:
            changeset.date = date
        self.repository_manager.notify("changeset_modified", "dummy", [rev])

    def inject_dummy_repository(self):
        # pylint: disable=protected-access,attribute-defined-outside-init
        self.repository = DummyRepositry()
        self.repository_connector = DummyRepositoryConnector(self.env)
        self.repository_connector.repository = self.repository
        self.repository_manager._all_repositories = {
            'dummy': dict(dir='dirname', type='dummy')}
        self.repository_manager._connectors = {
            'dummy': (self.repository_connector, 100)}


class ChangesetSearchParticipantTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(ChangesetSearchParticipantTestCase, self).setUp()
        self.changeset_search = ChangesetSearchParticipant(self.env)

    def test_can_get_default_grid_fields(self):
        grid_fields = self.changeset_search.get_default_view_fields("grid")
        self.env.log.debug("grid_fields: %s", grid_fields)
        self.assertGreater(len(grid_fields), 0)

    def test_can_get_default_facets(self):
        default_facets = self.changeset_search.get_default_facets()
        self.env.log.debug("default_facets: %s", default_facets)
        self.assertIsNotNone(default_facets)

    def test_can_get_is_grid_view_defaults(self):
        default_grid_fields = self.changeset_search.get_default_view_fields(
            "grid")
        self.env.log.debug("default_grid_fields: %s", default_grid_fields)
        self.assertIsNotNone(default_grid_fields)

class DummyRepositoryConnector(Component):
    implements(IRepositoryConnector)

    repository = None

    def get_supported_types(self):
        return ('dummy', 100)

    def get_repository(self, repos_type, repos_dir, params):
        # pylint: disable=unused-argument
        return self.repository


class DummyRepositry(Repository):
    # pylint: disable=abstract-method
    name = "dummy.git"

    def __init__(self):
        super(DummyRepositry, self).__init__(
            "DummyRepo", dict(name='dummy', id='id'), None)
        self.changesets = {}
        self.revisions = []
        self.last_rev = 0

    def add_changeset(self, rev, message, author, date, changes=()):
        if rev is None:
            rev = self.last_rev = self.last_rev + 1
        changeset = Changeset(self, str(rev), message, author, date)
        changeset.get_changes = lambda: changes
        self.changesets[changeset.rev] = changeset
        self.revisions.append(changeset.rev)
        return str(rev)

    def get_changeset(self, rev):
        return self.changesets[rev]

    def get_changesets(self, start, stop):
        for rev in self.revisions:
            yield self.changesets[rev]

    def normalize_rev(self, rev):
        return rev

    def get_changes(self, old_path, old_rev, new_path, new_rev,
                    ignore_ancestry=1):
        return ()


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(
        unittest.makeSuite(ChangesetIndexerEventsTestCase, 'test'))
    test_suite.addTest(
        unittest.makeSuite(ChangesetSearchParticipantTestCase, 'test'))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = milestone_search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.ticket import Milestone

from bhsearch.api import BloodhoundSearchApi
from bhsearch.search_resources.milestone_search import (
    MilestoneSearchParticipant)
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.whoosh_backend import WhooshBackend


class MilestoneIndexerEventsTestCase(BaseBloodhoundSearchTest):
    DUMMY_MILESTONE_NAME = "dummyName"

    def setUp(self):
        super(MilestoneIndexerEventsTestCase, self).setUp()
        self.whoosh_backend = WhooshBackend(self.env)
        self.whoosh_backend.recreate_index()
        self.search_api = BloodhoundSearchApi(self.env)

    def test_can_index_created_milestone(self):
        #arrange
        self.insert_milestone(self.DUMMY_MILESTONE_NAME, "dummy text")
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual(self.DUMMY_MILESTONE_NAME, doc["id"])
        self.assertEqual("dummy text", doc["content"])
        self.assertEqual("milestone", doc["type"])
        self.assertNotIn("due", doc )

    def test_can_index_minimal_milestone(self):
        #arrange
        self.insert_milestone(self.DUMMY_MILESTONE_NAME)
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual(self.DUMMY_MILESTONE_NAME, doc["id"])
        self.assertNotIn("content", doc)


    def test_can_index_renamed_milestone(self):
        #arrange
        self.insert_milestone(self.DUMMY_MILESTONE_NAME, "dummy text")
        self.change_milestone(
            self.DUMMY_MILESTONE_NAME,
            name="updated name",
            description="updated description",
        )
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual("updated name", doc["id"])
        self.assertEqual("updated description", doc["content"])

    def test_can_index_changed_milestone(self):
        #arrange
        self.insert_milestone(self.DUMMY_MILESTONE_NAME, "dummy text")
        self.change_milestone(
            self.DUMMY_MILESTONE_NAME,
            description="updated description",
        )
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual(self.DUMMY_MILESTONE_NAME, doc["id"])
        self.assertEqual("updated description", doc["content"])

    def test_can_index_delete(self):
        #arrange
        self.insert_milestone(self.DUMMY_MILESTONE_NAME)
        results = self.search_api.query("*")
        self.assertEqual(1, results.hits)
        #act
        Milestone(self.env, self.DUMMY_MILESTONE_NAME).delete()
        #assert
        results = self.search_api.query("*")
        self.print_result(results)
        self.assertEqual(0, results.hits)

    def test_can_reindex_minimal_milestone(self):
        #arrange
        self.insert_milestone(self.DUMMY_MILESTONE_NAME)
        self.whoosh_backend.recreate_index()
        #act
        self.search_api.rebuild_index()
        #assert
        results = self.search_api.query("*:*")
        self.print_result(results)
        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual(self.DUMMY_MILESTONE_NAME, doc["id"])
        self.assertEqual("milestone", doc["type"])

    def test_that_tickets_updated_after_milestone_renaming(self):
        #asser
        INITIAL_MILESTONE = "initial_milestone"
        RENAMED_MILESTONE = "renamed_name"
        milestone = self.insert_milestone(INITIAL_MILESTONE)
        self.insert_ticket("T1", milestone=INITIAL_MILESTONE)
        self.insert_ticket("T2", milestone=INITIAL_MILESTONE)
        #act
        milestone.name = RENAMED_MILESTONE
        milestone.update()
        #assert
        results = self.search_api.query("type:ticket")
        self.print_result(results)
        self.assertEqual(2, results.hits)
        self.assertEqual(RENAMED_MILESTONE, results.docs[0]["milestone"])
        self.assertEqual(RENAMED_MILESTONE, results.docs[1]["milestone"])

    def test_that_tickets_updated_after_milestone_delete_no_retarget(self):
        #asser
        INITIAL_MILESTONE = "initial_milestone"
        milestone = self.insert_milestone(INITIAL_MILESTONE)
        self.insert_ticket("T1", milestone=INITIAL_MILESTONE)
        self.insert_ticket("T2", milestone=INITIAL_MILESTONE)
        #act
        milestone.delete()
        #assert
        results = self.search_api.query("type:ticket")
        self.print_result(results)
        self.assertEqual(2, results.hits)
        self.assertNotIn("milestone", results.docs[0])
        self.assertNotIn("milestone", results.docs[1])

    def test_that_tickets_updated_after_milestone_delete_with_retarget(self):
        #asser
        INITIAL_MILESTONE = "initial_milestone"
        RETARGET_MILESTONE = "retarget_milestone"
        milestone = self.insert_milestone(INITIAL_MILESTONE)
        self.insert_milestone(RETARGET_MILESTONE)
        self.insert_ticket("T1", milestone=INITIAL_MILESTONE)
        self.insert_ticket("T2", milestone=INITIAL_MILESTONE)
        #act
        milestone.delete(retarget_to=RETARGET_MILESTONE)
        #assert
        results = self.search_api.query("type:ticket")
        self.print_result(results)
        self.assertEqual(2, results.hits)
        self.assertEqual(RETARGET_MILESTONE, results.docs[0]["milestone"])
        self.assertEqual(RETARGET_MILESTONE, results.docs[1]["milestone"])

    def test_fills_product_field_if_product_is_set(self):
        with self.product('p'):
            self.insert_milestone("T1")

        results = self.search_api.query("*")
        self.assertEqual(results.docs[0]["product"], 'p')

    def test_can_work_if_env_does_not_have_product(self):
        if 'product' in self.env:
            del self.env["product"]

        self.insert_milestone("T1")

        results = self.search_api.query("*")
        self.assertEqual(results.hits, 1)
        self.assertNotIn("product", results.docs[0])


class MilestoneSearchParticipantTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(MilestoneSearchParticipantTestCase, self).setUp()
        self.milestone_search = MilestoneSearchParticipant(self.env)

    def test_can_get_default_grid_fields(self):
        grid_fields = self.milestone_search.get_default_view_fields("grid")
        self.env.log.debug("grid_fields: %s", grid_fields)
        self.assertGreater(len(grid_fields), 0)

    def test_can_get_default_facets(self):
        default_facets = self.milestone_search.get_default_facets()
        self.env.log.debug("default_facets: %s", default_facets)
        self.assertIsNotNone(default_facets)

    def test_can_get_is_grid_view_defaults(self):
        default_grid_fields = self.milestone_search.get_default_view_fields(
            "grid")
        self.env.log.debug("default_grid_fields: %s", default_grid_fields)
        self.assertIsNotNone(default_grid_fields)

def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(
        unittest.makeSuite(MilestoneIndexerEventsTestCase, 'test'))
    test_suite.addTest(
        unittest.makeSuite(MilestoneSearchParticipantTestCase, 'test'))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = ticket_search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from trac.ticket.model import Component

from bhsearch.api import BloodhoundSearchApi
from bhsearch.search_resources.ticket_search import TicketIndexer
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.whoosh_backend import WhooshBackend


class TicketIndexerTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(TicketIndexerTestCase, self).setUp()
        self.whoosh_backend = WhooshBackend(self.env)
        self.whoosh_backend.recreate_index()
        self.ticket_indexer = TicketIndexer(self.env)
        self.search_api = BloodhoundSearchApi(self.env)
        self.env.config.set('bhsearch', 'silence_on_error', "False")

    def tearDown(self):
        pass

    def test_does_not_raise_exception_by_default(self):
        self.env.config.set('bhsearch', 'silence_on_error', "True")
        self.ticket_indexer.resource_created(None, None)

    def test_raise_exception_if_configured(self):
        self.env.config.set('bhsearch', 'silence_on_error', "False")
        self.assertRaises(
            Exception,
            self.ticket_indexer.resource_created,
            None)

    def test_can_strip_wiki_syntax(self):
        #act
        self.insert_ticket("T1", description=" = Header")
        #assert
        results = self.search_api.query("*:*")
        self.print_result(results)
        self.assertEqual(1, results.hits)
        self.assertEqual("Header", results.docs[0]["content"])

    def test_that_tickets_updated_after_component_renaming(self):
        #arrange
        INITIAL_COMPONENT = "initial_name"
        RENAMED_COMPONENT = "renamed_name"
        component = self._insert_component(INITIAL_COMPONENT)
        self.insert_ticket("T1", component=INITIAL_COMPONENT)
        self.insert_ticket("T2", component=INITIAL_COMPONENT)
        #act
        component.name = RENAMED_COMPONENT
        component.update()
        #arrange
        results = self.search_api.query("*")
        self.print_result(results)
        for doc in results.docs:
            self.assertEqual(RENAMED_COMPONENT, doc["component"])

    def test_that_ticket_updated_after_changing(self):
        #arrange
        ticket = self.insert_ticket("T1", description="some text")
        #act
        CHANGED_SUMMARY = "T1 changed"
        ticket["summary"] = CHANGED_SUMMARY
        ticket.save_changes()
        #arrange
        results = self.search_api.query("*")
        self.print_result(results)
        self.assertEqual(CHANGED_SUMMARY, results.docs[0]["summary"])

    def test_fills_product_field_if_product_is_set(self):
        with self.product('p'):
            self.insert_ticket("T1")

        results = self.search_api.query("*")
        self.assertEqual(results.docs[0]["product"], 'p')

    def test_can_work_if_env_does_not_have_product(self):
        if 'product' in self.env:
            del self.env["product"]

        self.insert_ticket("T1")

        results = self.search_api.query("*")
        self.assertEqual(results.hits, 1)
        self.assertNotIn("product", results.docs[0])

    def _insert_component(self, name):
        component = Component(self.env)
        component.name = name
        component.insert()
        return component


def suite():
    return unittest.makeSuite(TicketIndexerTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = wiki_search
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.
import shutil

from trac.wiki import WikiSystem, WikiPage

from bhsearch.api import BloodhoundSearchApi
from bhsearch.query_parser import DefaultQueryParser
from bhsearch.search_resources.wiki_search import (
    WikiIndexer, WikiSearchParticipant)
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.whoosh_backend import WhooshBackend


class WikiIndexerSilenceOnExceptionTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(WikiIndexerSilenceOnExceptionTestCase, self).setUp()
        self.env.config.set('bhsearch', 'silence_on_error', "True")
        self.wiki_indexer = WikiIndexer(self.env)

    def tearDown(self):
        pass

    def test_does_not_raise_exception_on_add(self):
        self.wiki_indexer.wiki_page_added(None)

    def test_raise_exception_if_configured(self):
        self.env.config.set('bhsearch', 'silence_on_error', "False")
        self.assertRaises(
            Exception,
            self.wiki_indexer.wiki_page_added,
            None)

class WikiIndexerEventsTestCase(BaseBloodhoundSearchTest):
    DUMMY_PAGE_NAME = "dummyName"

    def setUp(self):
        super(WikiIndexerEventsTestCase, self).setUp()
        self.wiki_system = WikiSystem(self.env)
        self.whoosh_backend = WhooshBackend(self.env)
        self.whoosh_backend.recreate_index()
        self.search_api = BloodhoundSearchApi(self.env)
        self.wiki_participant = WikiSearchParticipant(self.env)
        self.query_parser = DefaultQueryParser(self.env)

    def tearDown(self):
        shutil.rmtree(self.env.path)
        self.env.reset_db()

    def test_can_add_new_wiki_page_to_index(self):
        #arrange
        self.insert_wiki(self.DUMMY_PAGE_NAME, "dummy text")
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual(self.DUMMY_PAGE_NAME, doc["id"])
        self.assertEqual("dummy text", doc["content"])
        self.assertEqual("wiki", doc["type"])

    def test_can_delete_wiki_page_from_index(self):
        #arrange
        self.insert_wiki(self.DUMMY_PAGE_NAME)
        WikiPage(self.env, self.DUMMY_PAGE_NAME).delete()
        #act
        results = self.search_api.query("*.*")
        #assert
        self.print_result(results)
        self.assertEqual(0, results.hits)

    def test_can_index_changed_event(self):
        #arrange
        self.insert_wiki(self.DUMMY_PAGE_NAME, "Text to be changed")
        page = WikiPage(self.env, self.DUMMY_PAGE_NAME)
        page.text = "changed text with keyword"
        page.save("anAuthor", "some comment", "::1")
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        doc = results.docs[0]
        self.assertEqual("changed text with keyword", doc["content"])

    def test_can_index_renamed_event(self):
        #arrange
        self.insert_wiki(self.DUMMY_PAGE_NAME)
        page = WikiPage(self.env, self.DUMMY_PAGE_NAME)
        page.rename("NewPageName")
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        self.assertEqual("NewPageName", results.docs[0]["id"])

    def test_can_index_version_deleted_event(self):
        #arrange
        self.insert_wiki(self.DUMMY_PAGE_NAME, "version1")
        page = WikiPage(self.env, self.DUMMY_PAGE_NAME)
        page.text = "version 2"
        page.save("anAuthor", "some comment", "::1")
        page.delete(version=2)
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        self.assertEqual("version1", results.docs[0]["content"])

    def test_can_strip_wiki_formatting(self):
        #arrange
        self.insert_wiki(self.DUMMY_PAGE_NAME, " = Header")
        #act
        results = self.search_api.query("*:*")
        #assert
        self.print_result(results)
        self.assertEqual(1, results.hits)
        self.assertEqual("Header", results.docs[0]["content"])

    def test_fills_product_field_if_product_is_set(self):
        with self.product('p'):
            self.insert_wiki(self.DUMMY_PAGE_NAME, "content")

        results = self.search_api.query("*")
        self.assertEqual(results.docs[0]["product"], 'p')

    def test_can_work_if_env_does_not_have_product(self):
        if 'product' in self.env:
            del self.env["product"]

        self.insert_wiki(self.DUMMY_PAGE_NAME, "content")

        results = self.search_api.query("*")
        self.assertEqual(results.hits, 1)
        self.assertNotIn("product", results.docs[0])


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(
        WikiIndexerSilenceOnExceptionTestCase, 'test'))
    test_suite.addTest(unittest.makeSuite(WikiIndexerEventsTestCase, 'test'))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = security
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""
This module contains tests of search security using the actual permission
system backend.
"""
import contextlib
import os
from bhsearch.security import SecurityFilter

try:
    import configobj
except ImportError:
    configobj = None

from trac.perm import (
    DefaultPermissionPolicy, PermissionCache, PermissionSystem
)
from bhsearch.api import BloodhoundSearchApi
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.whoosh_backend import WhooshBackend
from multiproduct.api import MultiProductSystem, ProductEnvironment

# TODO: Convince trac to register modules without these imports
from trac.wiki import web_ui
from bhsearch import security


class SecurityTest(BaseBloodhoundSearchTest):
    def setUp(self, enabled=[]):
        super(SecurityTest, self).setUp(
            enabled=enabled + ['trac.*', 'trac.wiki.*',
                               'bhsearch.*', 'multiproduct.*'],
            create_req=True,
            enable_security=True,
        )
        self.env.parent = None
        self.product_envs = []
        self.req.perm = PermissionCache(self.env, 'x')

        self._setup_multiproduct()
        self._disable_trac_caches()
        self._create_whoosh_index()

        self.search_api = BloodhoundSearchApi(self.env)
        self._add_products('p1', 'p2')

    def _setup_multiproduct(self):
        try:
            MultiProductSystem(self.env)\
                .upgrade_environment(self.env.db_transaction)
        except self.env.db_exc.OperationalError:
            # table remains but content is deleted
            self._add_products('@')
        self.env.enable_multiproduct_schema()

    def _disable_trac_caches(self):
        DefaultPermissionPolicy.CACHE_EXPIRY = 0
        self._clear_permission_caches()

    def _create_whoosh_index(self):
        WhooshBackend(self.env).recreate_index()

    def _add_products(self, *products, **kwargs):
        owner = kwargs.pop('owner', '')
        with self.env.db_direct_transaction as db:
            for product in products:
                db("INSERT INTO bloodhound_product (prefix, owner) "
                   " VALUES ('%s', '%s')" % (product, owner))
                product = ProductEnvironment(self.env, product)
                self.product_envs.append(product)

    @contextlib.contextmanager
    def product(self, prefix=''):
        global_env = self.env
        self.env = ProductEnvironment(global_env, prefix)
        yield
        self.env = global_env

    def _add_permission(self, username='', permission='', product=''):
        with self.env.db_direct_transaction as db:
            db("INSERT INTO permission (username, action, product)"
               "VALUES ('%s', '%s', '%s')" %
               (username, permission, product))
        self._clear_permission_caches()

    def _clear_permission_caches(self):
        for env in [self.env] + self.product_envs:
            del PermissionSystem(env).store._all_permissions


class MultiProductSecurityTestCase(SecurityTest):
    def test_applies_security(self):
        self.insert_ticket('ticket 1')

        with self.product('p1'):
            self.insert_wiki('page 1', 'content')
            self.insert_ticket('ticket 2')
        with self.product('p2'):
            self.insert_wiki('page 2', 'content 2')
            self.insert_ticket('ticket 3')

        results = self.search_api.query("type:wiki", context=self.context)
        self.assertEqual(0, results.hits)

        self._add_permission('x', 'WIKI_VIEW')
        results = self.search_api.query("type:wiki", context=self.context)
        self.assertEqual(0, results.hits)

        self._add_permission('x', 'WIKI_VIEW', 'p1')
        results = self.search_api.query("type:wiki", context=self.context)
        self.assertEqual(1, results.hits)

        self._add_permission('x', 'WIKI_VIEW', 'p2')
        results = self.search_api.query("type:wiki", context=self.context)
        self.assertEqual(2, results.hits)

        self._add_permission('x', 'TICKET_VIEW', 'p2')
        results = self.search_api.query("*", context=self.context)
        self.assertEqual(3, results.hits)

        self._add_permission('x', 'TICKET_VIEW', 'p1')
        results = self.search_api.query("*", context=self.context)
        self.assertEqual(4, results.hits)

        self._add_permission('x', 'TICKET_VIEW')
        results = self.search_api.query("*", context=self.context)
        self.assertEqual(5, results.hits)

    def test_admin_has_access(self):
        with self.product('p1'):
            self.insert_wiki('page 1', 'content')
        self._add_permission('x', 'TRAC_ADMIN')
        results = self.search_api.query("*", context=self.context)
        self.assertEqual(1, results.hits)

    def test_admin_granted_in_product_should_not_have_access(self):
        with self.product('p1'):
            self.insert_wiki('page 1', 'content')

        self._add_permission('x', 'TRAC_ADMIN', 'p1')
        results = self.search_api.query("*", context=self.context)
        self.assertEqual(1, results.hits)

    def test_product_owner_has_access(self):
        self._add_products('p3', owner='x')
        with self.product('p3'):
            self.insert_ticket("ticket")

        results = self.search_api.query("*", context=self.context)
        self.assertEqual(1, results.hits)

    def test_user_with_no_permissions(self):
        with self.product('p1'):
            self.insert_wiki('page 1', 'content')
        results = self.search_api.query("type:wiki", context=self.context)
        self.assertEqual(0, results.hits)

    def test_adding_security_filters_retains_existing_filters(self):
        with self.product('p1'):
            self.insert_ticket("ticket 1")
            self.insert_ticket("ticket 2", status="closed")
        with self.product('p2'):
            self.insert_ticket("ticket 3", status="closed")

        self._add_permission('x', 'TICKET_VIEW', 'p1')
        self._add_permission('x', 'TICKET_VIEW', 'p2')

        results = self.search_api.query(
            "*",
            filter=["status:closed"],
            context=self.context
        )
        self.assertEqual(2, results.hits)

    def test_product_dropdown_with_no_permission(self):
        self._add_permission('x', 'SEARCH_VIEW')
        data = self.process_request()

        product_list = data['search_product_list']
        self.assertEqual(2, len(product_list))

    def test_product_dropdown_with_trac_admin_permission(self):
        self._add_permission('x', 'SEARCH_VIEW')
        self._add_permission('x', 'TRAC_ADMIN')
        data = self.process_request()

        product_list = data['search_product_list']
        self.assertEqual(5, len(product_list))

    def test_product_dropdown_with_product_view_permissions(self):
        self._add_permission('x', 'SEARCH_VIEW')
        self._add_permission('x', 'PRODUCT_VIEW', '@')
        data = self.process_request()

        product_list = data['search_product_list']
        self.assertEqual(3, len(product_list))

    def test_check_permission_is_called_with_advanced_security(self):
        self.env.config.set('bhsearch', 'advanced_security', "True")
        self.insert_ticket('ticket 1')
        with self.product('p1'):
            self.insert_wiki('page 1', 'content')
            self.insert_ticket('ticket 2')
        with self.product('p2'):
            self.insert_wiki('page 2', 'content 2')
            self.insert_ticket('ticket 3')
        self._add_permission('x', 'TRAC_ADMIN')

        calls = []

        def check_permission(self, doc, context):
            # pylint: disable=unused-argument
            calls.append((doc, context))
            return True

        security.SecurityPreprocessor.check_permission = check_permission

        results = self.search_api.query(
            "*",
            context=self.context
        )

        self.assertEqual(5, results.hits)
        self.assertEqual(5, len(calls))

    def test_advanced_security_overrides_normal_permissions(self):
        self.env.config.set('bhsearch', 'advanced_security', "True")
        self.insert_ticket('ticket 1')
        with self.product('p1'):
            self.insert_ticket('ticket 2')
        self._add_permission('x', 'TRAC_ADMIN')

        security.SecurityPreprocessor.check_permission = \
            lambda x, doc, z: doc.get('product', None) == 'p1'

        results = self.search_api.query(
            "*",
            context=self.context
        )

        self.assertEqual(1, results.hits)


class AuthzSecurityTestCase(SecurityTest):
    def setUp(self, enabled=()):
        SecurityTest.setUp(self, enabled=['tracopt.perm.authz_policy.*'])
        self.authz_config = os.path.join(self.env.path, 'authz.conf')
        self.env.config['authz_policy'].set('authz_file', self.authz_config)
        self.env.config['trac'].set('permission_policies',
                                    'AuthzPolicy,DefaultPermissionPolicy,'
                                    'LegacyAttachmentPolicy')

        # Create some dummy objects
        self.insert_ticket('ticket 1')
        self.insert_ticket('ticket 2')
        self.insert_wiki('page 1', 'content')
        with self.product('p1'):
            self.insert_ticket('ticket 1 in p1')
            self.insert_wiki('page 1', 'content')

    def write_authz_config(self, content):
        with open(self.authz_config, 'w') as authz_config:
            authz_config.write(content)

    def test_authz_permissions(self):
        self._add_permission('x', 'WIKI_VIEW')
        self.write_authz_config("""
            [*]
            * = TICKET_VIEW, !WIKI_VIEW
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(3, results.hits)
        results = self.search_api.query("type:wiki", context=self.context)
        self.assertEqual(0, results.hits)

    def test_granular_permissions(self):
        self.write_authz_config("""
            [ticket:1]
            * = TICKET_VIEW
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(2, results.hits)
        self.assertEqual(u'1', results.docs[0]['id'])

    def test_deny_overrides_default_permissions(self):
        self._add_permission('x', 'TICKET_VIEW')
        self.write_authz_config("""
            [*]
            x = !TICKET_VIEW
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(0, results.hits)

    def test_includes_wildcard_rows_for_registered_users(self):
        self.write_authz_config("""
            [*]
            * = TICKET_VIEW
            [ticket:1]
            * = !TICKET_VIEW
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(1, results.hits)

    def test_includes_wildcard_rows_for_anonymous_users(self):
        self.req.authname = 'anonymous'
        self.write_authz_config("""
            [*]
            * = TICKET_VIEW
            [ticket:1]
            * = !TICKET_VIEW
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(1, results.hits)

    def test_includes_authenticated_rows_for_registered_users(self):
        self.write_authz_config("""
            [*]
            * = TICKET_VIEW
            [ticket:1]
            authenticated = !TICKET_VIEW
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(1, results.hits)

    def test_includes_named_rows_for_registered_users(self):
        self.write_authz_config("""
            [*]
            * = TICKET_VIEW
            [ticket:1]
            x = !TICKET_VIEW
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(1, results.hits)

    def test_includes_named_rows_for_anonymous_users(self):
        self.req.authname = 'anonymous'
        self.write_authz_config("""
            [*]
            * = TICKET_VIEW
            [ticket:1]
            anonymous = !TICKET_VIEW
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(1, results.hits)

    def test_understands_groups(self):
        self.write_authz_config("""
            [groups]
            admins = x
            [*]
            @admins = TICKET_VIEW
            [ticket:1]
            * = !TRAC_ADMIN
        """)

        results = self.search_api.query("type:ticket", context=self.context)
        self.assertEqual(1, results.hits)


class SecurityFilterTests(unittest.TestCase):
    def test_hash(self):
        sf = SecurityFilter()
        hash(sf)


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(MultiProductSecurityTestCase))
    if configobj:
        suite.addTest(unittest.makeSuite(AuthzSecurityTestCase))
    suite.addTest(unittest.makeSuite(SecurityFilterTests))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest="suite")

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

from urllib import urlencode, unquote, unquote_plus

from trac.core import TracError
from trac.search.web_ui import SearchModule as TracSearchModule
from trac.test import Mock, MockPerm
from trac.util import format_datetime
from trac.util.datefmt import FixedOffset
from trac.web import Href, RequestDone, arg_list_to_args, parse_arg_list

from bhsearch import web_ui
from bhsearch.api import ASC, DESC, SortInstruction
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.web_ui import BloodhoundSearchModule, RequestParameters
from bhsearch.whoosh_backend import WhooshBackend

BASE_PATH = "/main/"
BHSEARCH_URL = BASE_PATH + "bhsearch"
DEFAULT_DOCS_PER_PAGE = 10


class WebUiTestCaseWithWhoosh(BaseBloodhoundSearchTest):
    def setUp(self):
        super(WebUiTestCaseWithWhoosh, self).setUp(
            create_req=True,
        )
        self.req.redirect = self.redirect

        whoosh_backend = WhooshBackend(self.env)
        whoosh_backend.recreate_index()

        self.req.redirect = self.redirect
        self.redirect_url = None
        self.redirect_permanent = None

        self.old_product_environment = web_ui.ProductEnvironment
        self._inject_mocked_product_environment()

    def _inject_mocked_product_environment(self):
        class MockProductEnvironment(object):
            def __init__(self, env, product):
                # pylint: disable=unused-argument
                self.product = product

            def href(self, *args):
                return ('/main/products/%s/' % self.product) + '/'.join(args)

            def abs_href(self, *args):
                return 'http://example.org' + self.href(*args)

            from multiproduct.env import ProductEnvironment
            resolve_href = ProductEnvironment.resolve_href

        web_ui.ProductEnvironment = MockProductEnvironment

    def tearDown(self):
        web_ui.ProductEnvironment = self.old_product_environment

    def redirect(self, url, permanent=False):
        self.redirect_url = url
        self.redirect_permanent = permanent
        raise RequestDone

    def test_can_process_empty_request(self):
        data = self.process_request()
        self.assertEqual("", data["query"])

    def test_can_process_query_empty_data(self):
        self.req.args[RequestParameters.QUERY] = "bla"
        data = self.process_request()
        self.assertEqual("bla", data["query"])
        self.assertEqual([], data["results"].items)

    def test_can_process_first_page(self):
        self._insert_tickets(5)
        self.req.args[RequestParameters.QUERY] = "summary:test"
        data = self.process_request()
        self.assertEqual("summary:test", data["query"])
        self.assertEqual(5, len(data["results"].items))

    def test_can_return_utc_time(self):
        #arrange
        ticket = self.insert_ticket("bla")
        ticket_time = ticket.time_changed
        #act
        self.req.args[RequestParameters.QUERY] = "*:*"
        data = self.process_request()
        result_items = data["results"].items
        #assert
        self.assertEqual(1, len(result_items))
        result_datetime = result_items[0]["date"]
        self.env.log.debug(
            "Ticket time: %s, Returned time: %s",
            ticket_time,
            result_datetime)
        self.assertEqual(format_datetime(ticket_time), result_items[0]["date"])

    def test_can_return_user_time(self):
        #arrange
        ticket = self.insert_ticket("bla")
        ticket_time = ticket.time_changed
        #act
        tzinfo = FixedOffset(60, 'GMT +1:00')
        self.req.tz = tzinfo
        self.req.args[RequestParameters.QUERY] = "*:*"
        data = self.process_request()
        result_items = data["results"].items
        #asset
        self.assertEqual(1, len(result_items))
        expected_datetime = format_datetime(ticket_time, tzinfo=tzinfo)
        result_datetime = result_items[0]["date"]
        self.env.log.debug(
            "Ticket time: %s, Formatted time: %s ,Returned time: %s",
            ticket_time, expected_datetime, result_datetime)
        self.assertEqual(expected_datetime, result_datetime)

    def test_ticket_href(self):
        self._insert_tickets(1)
        self.req.args[RequestParameters.QUERY] = "*:*"
        data = self.process_request()
        docs = data["results"].items
        self.assertEqual(1, len(docs))
        self.assertEqual("/main/ticket/1", docs[0]["href"])

    def test_product_ticket_href(self):
        with self.product('xxx'):
            self._insert_tickets(1)
        self.req.args[RequestParameters.QUERY] = "*:*"
        data = self.process_request()
        docs = data["results"].items
        self.assertEqual(1, len(docs))
        self.assertEqual("/main/products/xxx/ticket/1", docs[0]["href"])

    def test_page_href(self):
        self._insert_tickets(DEFAULT_DOCS_PER_PAGE+1)
        self.req.args[RequestParameters.QUERY] = "*:*"
        data = self.process_request()
        shown_pages = data["results"].shown_pages
        second_page_href = shown_pages[1]["href"]
        self.assertIn("page=2", second_page_href)
        self.assertIn("q=*%3A*", second_page_href)

    def test_can_apply_type_parameter(self):
        #arrange
        self.insert_ticket("summary1 keyword", status="closed")
        self.insert_ticket("summary2 keyword", status="new")
        self.insert_wiki("dummyTitle", "Some text")
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.TYPE] = "ticket"
        #act
        data = self.process_request()
        #assert
        extra_search_options = dict(data["extra_search_fields"])
        self.assertEqual("ticket", extra_search_options['type'])

    def test_type_parameter_in_links(self):
        self._insert_tickets(12)
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.PAGELEN] = "4"
        self.req.args[RequestParameters.PAGE] = "2"
        data = self.process_request()
        results = data["results"]
        docs = results.items
        self.assertEquals(4, len(docs))

        next_chrome_link = self.req.chrome['links']['next'][0]["href"]
        self.assertIn('type=ticket', next_chrome_link)
        self.assertIn('page=3', next_chrome_link)

        prev_chrome_link = self.req.chrome['links']['prev'][0]["href"]
        self.assertIn('type=ticket', prev_chrome_link)
        self.assertIn('page=1', prev_chrome_link)

        self.assertIn('type=ticket', data["page_href"])

        for page in results.shown_pages:
            self.assertIn('type=ticket', page["href"])

    def test_that_type_facet_is_in_default_search(self):
        #arrange
        self._insert_tickets(2)
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        self.assertEquals(1, len(data["facet_counts"]))

    def test_can_return_facets_counts_for_tickets(self):
        #arrange
        self.insert_ticket("T1", status="new", milestone="m1")
        self.insert_ticket("T2", status="closed")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        facet_counts = dict(data["facet_counts"])
        status_counts = facet_counts["status"]
        self.assertEquals(1, status_counts["new"]["count"])
        self.assertEquals(1, status_counts["closed"]["count"])

    def test_can_create_href_for_facet_counts(self):
        #arrange
        self.insert_ticket("T1", status="new")
        self.insert_ticket("T2", status="closed")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        facet_counts = dict(data["facet_counts"])
        status_counts = facet_counts["status"]
        self.assertEquals(1, status_counts["new"]["count"])
        self.assertIn("fq=status%3A%22new%22", status_counts["new"]["href"])

    def test_can_handle_none_in_facet_counts(self):
        #arrange
        self.insert_ticket("T1")
        self.insert_ticket("T2")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        facet_counts = dict(data["facet_counts"])
        status_counts = facet_counts["status"]
        empty_status_count = status_counts[None]
        self.assertEquals(2, empty_status_count["count"])
        self.assertIn(
            'fq=NOT+(status:*)',
            unquote(empty_status_count["href"]))

    def test_can_return_empty_facets_result_for_wiki_pages(self):
        #arrange
        self.insert_wiki("W1", "Some text")
        #act
        self.req.args[RequestParameters.TYPE] = "wiki"
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        facet_counts = data["facet_counts"]
        self.assertEquals([], facet_counts)

    def test_can_accept_multiple_filter_query_parameters(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new")
        self.insert_ticket("T2", component="c1", status="new")
        self.insert_ticket("T3",)
        self._insert_wiki_pages(2)
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.FILTER_QUERY] = [
            'component:"c1"', 'status:"new"']
        data = self.process_request()
        #assert
        page_href = data["page_href"]
        self.assertIn(urlencode({'fq': 'component:"c1"'}), page_href)
        self.assertIn(urlencode({'fq': 'status:"new"'}), page_href)

        docs = data["results"].items
        self.assertEqual(2, len(docs))

    def test_can_handle_empty_facet_result(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new")
        self.insert_ticket("T2", component="c1", status="new")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.FILTER_QUERY] = ['component:"c1"']
        data = self.process_request()
        #assert
        facet_counts = dict(data["facet_counts"])

        milestone_facet_count = facet_counts["milestone"]
        self.env.log.debug(unquote(milestone_facet_count[None]["href"]))

    def test_can_handle_multiple_same(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new")
        self.insert_ticket("T2", component="c1", status="new")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.FILTER_QUERY] = ['component:"c1"']
        data = self.process_request()
        #assert
        facet_counts = dict(data["facet_counts"])

        component_facet_count = facet_counts["component"]
        c1_href = component_facet_count["c1"]["href"]
        self.env.log.debug(unquote(c1_href))
        self.assertEquals(
            1,
            self._count_parameter_in_url(c1_href, "fq", 'component:"c1"'))

    def test_can_return_current_filter_queries(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new")
        self.insert_ticket("T2", component="c1", status="new")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.FILTER_QUERY] = [
            'component:"c1"',
            'status:"new"']
        data = self.process_request()
        #assert
        current_filter_queries = data["active_filter_queries"]
        self.assertEquals(3, len(current_filter_queries))

        type_filter = current_filter_queries[0]
        self.assertEquals('Ticket', type_filter["label"])
        self.assertNotIn("type=", type_filter["href"])
        self.assertNotIn('fq=', unquote(type_filter["href"]))

        component_filter = current_filter_queries[1]
        self.assertEquals('component:"c1"', component_filter["label"])
        self.assertIn('type=ticket', component_filter["href"])
        self.assertNotIn('fq=component:"c1"',
                         unquote(component_filter["href"]))
        self.assertIn('fq=status:"new"', unquote(component_filter["href"]))

        status_filter = current_filter_queries[2]
        self.assertEquals('status:"new"', status_filter["label"])
        self.assertIn('type=ticket', status_filter["href"])
        self.assertIn('fq=component:"c1"', unquote(status_filter["href"]))
        self.assertNotIn('fq=status:"new"', unquote(status_filter["href"]))

    def test_can_return_missing_milestone(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new")
        self.insert_ticket("T2", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.FILTER_QUERY] = ["NOT (milestone:*)"]
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        items = data["results"].items
        self.assertEquals(1, len(items))

    def test_can_return_no_results_for_missing_milestone(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        self.insert_ticket("T2", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.FILTER_QUERY] = ["NOT (milestone:*)"]
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        items = data["results"].items
        self.assertEquals(0, len(items))

    def test_that_type_facet_has_href_to_type(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        ticket_facet_href = dict(data["facet_counts"])["type"]["ticket"]["href"]
        ticket_facet_href = unquote(ticket_facet_href)
        self.assertIn("type=ticket", ticket_facet_href)
        self.assertNotIn("fq=", ticket_facet_href)

    def test_that_there_is_no_quick_jump_on_ordinary_query(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        self.assertNotIn("quickjump", data)

    def test_can_redirect_on_ticket_id_query(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "#1"
        self.assertRaises(RequestDone, self.process_request)
        #assert
        self.assertEqual('/main/ticket/1', self.redirect_url)

    def test_can_return_quick_jump_data_on_noquickjump(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "#1"
        self.req.args[RequestParameters.NO_QUICK_JUMP] = "1"
        data = self.process_request()
        #assert
        quick_jump_data = data["quickjump"]
        self.assertEqual('T1 (new)', quick_jump_data["description"])
        self.assertEqual('/main/ticket/1', quick_jump_data["href"])

    def test_that_ticket_search_can_return_in_grid(self):
        #arrange
        self.env.config.set(
            'bhsearch',
            'ticket_is_grid_view_default',
            'True')
        self.env.config.set(
            'bhsearch',
            'ticket_default_grid_fields',
            'id,status,milestone,component')
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.VIEW] = "grid"
        data = self.process_request()
        #assert
        grid_data = data["headers"]
        self.assertIsNotNone(grid_data)
        fields = [column["name"] for column in grid_data]
        self.assertEquals(["id", "status", "milestone", "component"], fields)

    def test_that_grid_is_switched_off_by_default(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        self.assertNotIn("headers", data)
        self.assertNotIn("view", data)

    def test_that_grid_is_switched_off_by_default_for_ticket(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.TYPE] = "ticket"
        data = self.process_request()
        #assert
        self.assertNotIn("headers", data)
        self.assertNotIn("view", data)

    def test_can_returns_all_views(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        all_views = data["all_views"]
        free_view = all_views[0]
        self.assertTrue(free_view["is_active"])
        self.assertNotIn("view=", free_view["href"])
        grid = all_views[1]
        self.assertFalse(grid["is_active"])
        self.assertIn("view=grid", grid["href"])

    def test_that_active_view_is_not_set_if_not_requested(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        self.assertNotIn("active_view", data)

    def test_that_active_view_is_set_if_requested(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.VIEW] = "grid"
        data = self.process_request()
        #assert
        extra_search_options = dict(data["extra_search_fields"])
        self.assertEqual("grid", extra_search_options["view"])

    def test_can_apply_sorting(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        self.insert_ticket("T2", component="c1", status="new", milestone="B")
        self.insert_ticket("T3", component="c3", status="new", milestone="C")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.SORT] = "component, milestone desc"
        data = self.process_request()
        #assert
        api_sort = data["debug"]["api_parameters"]["sort"]
        self.assertEqual(
            [
                SortInstruction("component", ASC),
                SortInstruction("milestone", DESC),
            ],
            api_sort)
        ids = [item["summary"] for item in data["results"].items]
        self.assertEqual(["T2", "T1", "T3"], ids)

    def test_that_title_is_set_for_free_text_view(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        data = self.process_request()
        #assert
        self.assertIn("title", data["results"].items[0])

    def test_that_grid_header_has_correct_sort_when_default_sorting(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.VIEW] = "grid"
        data = self.process_request()
        #assert
        headers = data["headers"]
        id_header = self._find_header(headers, "id")
        self.assertIn("sort=id+asc", id_header["href"])
        self.assertEquals(None, id_header["sort"])

        time_header = self._find_header(headers, "time")
        self.assertIn("sort=time+asc", time_header["href"])
        self.assertEquals(None, time_header["sort"])

    def test_that_grid_header_has_correct_sort_if_acs_sorting(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.QUERY] = "*"
        self.req.args[RequestParameters.VIEW] = "grid"
        self.req.args[RequestParameters.SORT] = "id"

        data = self.process_request()
        #assert
        headers = data["headers"]
        id_header = self._find_header(headers, "id")
        self.assertIn("sort=id+desc", id_header["href"])
        self.assertEquals("asc", id_header["sort"])

    def test_that_active_sort_is_set(self):
        #arrange
        self.insert_ticket("T1", component="c1", status="new", milestone="A")
        #act
        self.req.args[RequestParameters.SORT] = "id, time desc"

        data = self.process_request()
        #assert
        extra_search_options = dict(data["extra_search_fields"])
        self.assertEqual("id, time desc", extra_search_options["sort"])

    def test_that_document_summary_contains_highlighted_search_terms(self):
        term = "searchterm"
        long_text = "foo " * 200 + term + " bar" * 100
        self.insert_wiki("Dummy title", long_text)

        self.req.args[RequestParameters.QUERY] = term
        data = self.process_request()

        content = str(data["results"].items[0]["hilited_content"])
        matched_term = '<em>%s</em>' % term
        self.assertIn(matched_term, content)

    def test_that_only_matched_terms_are_highlighted(self):
        term = "search_term"
        self.insert_wiki(term, term)

        self.req.args[RequestParameters.QUERY] = "name:%s" % term
        data = self.process_request()

        title = str(data["results"].items[0]["title"])
        content = str(data["results"].items[0]["content"])
        matched_term = '<em>%s</em>' % term
        self.assertIn(matched_term, title)
        self.assertNotIn(matched_term, content)

    def test_that_matched_terms_in_title_are_highlighted(self):
        term = "search_term"
        self.insert_wiki(term, 'content')
        self.insert_ticket(term)

        self.req.args[RequestParameters.QUERY] = term
        data = self.process_request()

        for row in data["results"].items:
            title = str(row["title"])
            matched_term = '<em>%s</em>' % term
            self.assertIn(matched_term, str(title))

    def test_that_html_tags_are_escaped(self):
        term = "search_term"
        content = '%s <b>%s</b>' % (term, term)
        self.insert_wiki(term, content)

        self.req.args[RequestParameters.QUERY] = "content:%s" % term
        data = self.process_request()

        content = str(data["results"].items[0]["hilited_content"])
        matched_term = '<em>%s</em>' % term
        self.assertIn(matched_term, content)
        self.assertNotIn('<b>', content)
        self.assertIn('&lt;b&gt;', content)

    def test_that_id_is_displayed_even_if_it_doesnt_contain_query_terms(self):
        id, term = "1", "search_term"
        self.insert_ticket(term, id=id)
        self.insert_wiki(id, term)

        self.req.args[RequestParameters.QUERY] = term
        data = self.process_request()

        for row in data["results"].items:
            title = row["title"]
            self.assertIn(id, str(title))

    def test_that_id_is_highlighted_in_title(self):
        self.insert_ticket("some summary")
        id = "1"
        self.req.args[RequestParameters.QUERY] = id
        data = self.process_request()
        row = data["results"].items[0]
        title = row["title"]
        self.assertIn('<em>%s</em>' % id, str(title))

    def test_that_content_summary_is_trimmed(self):
        content = "foo " * 1000
        self.insert_wiki("title", content)

        data = self.process_request()

        for row in data["results"].items:
            self.assertLess(len(row['content']), 500)
            self.assertLess(len(row['hilited_content']), 500)

    def test_compatibility_with_legacy_search(self):
        self.env.config.set('bhsearch', 'enable_redirect', "True")
        self.req.path_info = '/search'

        self.assertRaises(RequestDone, self.process_request)
        self.assertIn('/bhsearch', self.redirect_url)
        self.assertEqual(self.redirect_permanent, True)

        self.req.args['wiki'] = 'on'
        self.assertRaises(RequestDone, self.process_request)
        redirect_url = unquote_plus(self.redirect_url)
        self.assertIn('/bhsearch', redirect_url)
        self.assertIn('type=wiki', redirect_url)
        self.assertEqual(self.redirect_permanent, True)

        self.req.args['ticket'] = 'on'
        self.assertRaises(RequestDone, self.process_request)
        redirect_url = unquote_plus(self.redirect_url)
        self.assertIn('fq=type:(ticket OR wiki)', redirect_url)
        self.assertIn('/bhsearch', self.redirect_url)
        self.assertEqual(self.redirect_permanent, True)

        self.req.args['milestone'] = 'on'
        self.assertRaises(RequestDone, self.process_request)
        redirect_url = unquote_plus(self.redirect_url)
        self.assertIn('fq=type:(ticket OR wiki OR milestone)', redirect_url)
        self.assertIn('/bhsearch', self.redirect_url)
        self.assertEqual(self.redirect_permanent, True)

        self.req.args['changeset'] = 'on'
        self.assertRaises(RequestDone, self.process_request)
        redirect_url = unquote_plus(self.redirect_url)
        self.assertIn(
            'fq=type:(ticket OR wiki OR milestone OR changeset)', redirect_url)
        self.assertIn('/bhsearch', self.redirect_url)
        self.assertEqual(self.redirect_permanent, True)

    def test_opensearch_integration(self):
        # pylint: disable=unused-variable
        self.req.path_info = '/bhsearch/opensearch'
        bhsearch = BloodhoundSearchModule(self.env)

        url, data, x = bhsearch.process_request(self.req)

        self.assertEqual(url, 'opensearch.xml')

    def test_returns_correct_handler(self):
        bhsearch = BloodhoundSearchModule(self.env)
        tracsearch = self.env[TracSearchModule]

        class PathInfoSetter(object):
            # pylint: disable=incomplete-protocol
            def __setitem__(other, key, value):
                if key == "PATH_INFO":
                    self.req.path_info = value
        self.req.environ = PathInfoSetter()

        self.env.config.set('bhsearch', 'enable_redirect', "True")

        self.req.path_info = '/search'
        self.assertIs(bhsearch.pre_process_request(self.req, tracsearch),
                      bhsearch)

        self.req.path_info = '/bhsearch'
        self.assertIs(bhsearch.pre_process_request(self.req, tracsearch),
                      bhsearch)

        self.env.config.set('bhsearch', 'enable_redirect', "False")
        # With redirect disabled, handler should not be changed.
        self.req.path_info = '/search'
        self.assertIs(bhsearch.pre_process_request(self.req, None),
                      None)

        self.req.path_info = '/bhsearch'
        self.assertIs(bhsearch.pre_process_request(self.req, None),
                      None)

    def test_that_correct_search_handle_is_selected_for_quick_search(self):
        bhsearch = BloodhoundSearchModule(self.env)

        def process_request(path, enable_redirect, is_default):
            # pylint: disable=unused-variable
            self.req.path_info = path
            self.env.config.set('bhsearch', 'enable_redirect',
                                str(enable_redirect))
            self.env.config.set('bhsearch', 'is_default', str(is_default))
            template, data, content_type = \
                bhsearch.post_process_request(self.req, '', {}, '')
            return data

        data = process_request('/', enable_redirect=False, is_default=False)
        self.assertIn('search_handler', data)
        self.assertEqual(data['search_handler'], self.req.href.search())

        data = process_request('/', enable_redirect=True, is_default=False)
        self.assertIn('search_handler', data)
        self.assertEqual(data['search_handler'], self.req.href.bhsearch())

        data = process_request('/', enable_redirect=False, is_default=True)
        self.assertIn('search_handler', data)
        self.assertEqual(data['search_handler'], self.req.href.bhsearch())

        data = process_request('/', enable_redirect=True, is_default=True)
        self.assertIn('search_handler', data)
        self.assertEqual(data['search_handler'], self.req.href.bhsearch())

        for is_default in [False, True]:
            data = process_request('/search',
                                   enable_redirect=False,
                                   is_default=is_default)
            self.assertIn('search_handler', data)
            self.assertEqual(data['search_handler'], self.req.href.search())

        for is_default in [False, True]:
            data = process_request('/search',
                                   enable_redirect=True,
                                   is_default=is_default)
            self.assertIn('search_handler', data)
            self.assertEqual(data['search_handler'], self.req.href.bhsearch())

        for enable_redirect in [False, True]:
            for is_default in [False, True]:
                data = process_request('/bhsearch',
                                       enable_redirect=enable_redirect,
                                       is_default=is_default)
                self.assertIn('search_handler', data)
                self.assertEqual(data['search_handler'],
                                 self.req.href.bhsearch())

    def test_that_active_query_is_set(self):
        #arrange
        self.insert_ticket("Ticket 1", component="c1", status="new")
        self.insert_ticket("Ticket 2", component="c1", status="new")
        #act
        self.req.args[RequestParameters.TYPE] = "ticket"
        self.req.args[RequestParameters.QUERY] = "Ticket"
        self.req.args[RequestParameters.FILTER_QUERY] = [
            'component:"c1"',
            'status:"new"']
        data = self.process_request()
        #assert
        active_query = data["active_query"]
        self.assertEqual(active_query["label"], '"Ticket"')
        self.assertEqual(active_query["query"], "Ticket")
        self.assertNotIn("?q=", unquote(active_query["href"]))
        self.assertNotIn("&q=", unquote(active_query["href"]))
        self.assertIn("fq=", unquote(active_query["href"]))

    def test_redirects_if_product_env_is_used_to_access_search(self):
        self.env.config.set('bhsearch', 'global_quicksearch', "True")

        with self.product('xxx'):
            self.assertRaises(RequestDone, self.process_request)

        self.assertIn('/bhsearch', self.redirect_url)
        self.assertNotIn('/products', self.redirect_url)
        self.assertNotIn('product_prefix=xxx', self.redirect_url)
        self.assertTrue(self.redirect_permanent)

    def test_adds_product_filter_when_global_quicksearch_is_disabled(self):
        self.env.config.set('bhsearch', 'global_quicksearch', "false")

        with self.product('xxx'):
            self.assertRaises(RequestDone, self.process_request)

        self.assertIn('/bhsearch', self.redirect_url)
        self.assertNotIn('/products', self.redirect_url)
        self.assertIn('product_prefix=xxx', self.redirect_url)
        self.assertTrue(self.redirect_permanent)

    def _find_header(self, headers, name):
        for header in headers:
            if header["name"] == name:
                return header
        raise Exception("Header not found: %s" % name)

    def _count_parameter_in_url(self, url, parameter_name, value):
        parameter_to_find = (parameter_name, value)
        parsed_parameters = parse_arg_list(url)
        i = 0
        for parameter in parsed_parameters:
            if parameter == parameter_to_find:
                i += 1

        return i

    def _assertResourceType(self, type, label, active, href_contains=None):
        self.assertEquals(label, type["label"])
        self.assertEquals(active, type["active"])
        if href_contains:
            self.assertIn(href_contains, type["href"])

    def _insert_tickets(self, n):
        for i in range(1, n+1):
            self.insert_ticket("test %s" % i)

    def _insert_wiki_pages(self, n):
        for i in range(1, n+1):
            self.insert_wiki("test %s" % i)


class RequestParametersTest(unittest.TestCase):
    def setUp(self):
        self.req = Mock(
            perm=MockPerm(),
            chrome={'logo': {}},
            href=Href("/main"),
            base_path=BASE_PATH,
            args=arg_list_to_args([]),
        )

    def test_can_parse_multiple_sort_terms(self):
        self.assertEqual(
            None,
            self._evaluate_sort("  "))
        self.assertEqual(
            None,
            self._evaluate_sort(" ,  , "))
        self.assertEqual(
            [SortInstruction("f1", ASC)],
            self._evaluate_sort(" f1 "))
        self.assertEqual(
            [SortInstruction("f1", ASC)],
            self._evaluate_sort(" f1 asc"))
        self.assertEqual(
            [SortInstruction("f1", DESC)],
            self._evaluate_sort("f1  desc"))
        self.assertEqual(
            [SortInstruction("f1", ASC), SortInstruction("f2", DESC)],
            self._evaluate_sort("f1, f2 desc"))

    def test_can_raise_error_on_invalid_sort_term(self):
        self.assertRaises(
            TracError,
            self._evaluate_sort,
            "f1  desc bb")

    def test_can_create_href_with_single_sort(self):
        href = RequestParameters(self.req).create_href(
            sort=SortInstruction("field1", ASC))
        href = unquote(href)
        self.assertIn("sort=field1+asc", href)

    def test_can_create_href_with_multiple_sort(self):
        href = RequestParameters(self.req).create_href(
            sort=[
                SortInstruction("field1", ASC),
                SortInstruction("field2", DESC),
            ])
        href = unquote(href)
        self.assertIn("sort=field1+asc,+field2+desc", href)

    def _evaluate_sort(self, sort_condition):
        self.req.args[RequestParameters.SORT] = sort_condition
        parameters = RequestParameters(self.req)
        return parameters.sort


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(WebUiTestCaseWithWhoosh))
    test_suite.addTest(unittest.makeSuite(RequestParametersTest))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = whoosh_backend
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.
from datetime import datetime
import os
import shutil
import tempfile

from trac.util.datefmt import FixedOffset, utc

from bhsearch.api import ASC, DESC, SCORE, SortInstruction
from bhsearch.query_parser import DefaultQueryParser
from bhsearch.tests import unittest
from bhsearch.tests.base import BaseBloodhoundSearchTest
from bhsearch.whoosh_backend import WhooshBackend
from whoosh import index, query, sorting
from whoosh.fields import ID, KEYWORD, TEXT, Schema
from whoosh.qparser import MultifieldParser, MultifieldPlugin, PhrasePlugin, \
    QueryParser, WhitespacePlugin


class WhooshBackendTestCase(BaseBloodhoundSearchTest):
    def setUp(self):
        super(WhooshBackendTestCase, self).setUp()
        self.whoosh_backend = WhooshBackend(self.env)
        self.whoosh_backend.recreate_index()
        self.parser = DefaultQueryParser(self.env)

    def test_can_retrieve_docs(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        self.whoosh_backend.add_doc(dict(id="2", type="ticket"))
        result = self.whoosh_backend.query(
            query.Every(),
            sort = [SortInstruction("id", ASC)],
        )
        self.print_result(result)
        self.assertEqual(2, result.hits)
        docs = result.docs
        self.assertEqual(
            {'id': u'1', 'type': u'ticket', 'unique_id': u'ticket:1',
             'score': 0},
            docs[0])
        self.assertEqual(
            {'id': u'2', 'type': u'ticket', 'unique_id': u'ticket:2',
             'score': 1},
            docs[1])

    def test_can_return_all_fields(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        result = self.whoosh_backend.query(query.Every())
        self.print_result(result)
        docs = result.docs
        self.assertEqual(
            {'id': u'1', 'type': u'ticket', 'unique_id': u'ticket:1',
                "score": 1.0},
            docs[0])

    def test_can_select_fields(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        result = self.whoosh_backend.query(query.Every(),
            fields=("id", "type"))
        self.print_result(result)
        docs = result.docs
        self.assertEqual(
            {'id': '1', 'type': 'ticket'},
            docs[0])

    def test_can_survive_after_restart(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        whoosh_backend2 = WhooshBackend(self.env)
        whoosh_backend2.add_doc(dict(id="2", type="ticket"))
        result = whoosh_backend2.query(query.Every())
        self.assertEqual(2, result.hits)

    def test_can_apply_multiple_sort_conditions_asc(self):
        self.whoosh_backend.add_doc(dict(id="2", type="ticket2"))
        self.whoosh_backend.add_doc(dict(id="3", type="ticket1"))
        self.whoosh_backend.add_doc(dict(id="4", type="ticket3"))
        self.whoosh_backend.add_doc(dict(id="1", type="ticket1"))
        result = self.whoosh_backend.query(
            query.Every(),
            sort = [SortInstruction("type", ASC), SortInstruction("id", ASC)],
            fields=("id", "type"),
        )
        self.print_result(result)
        self.assertEqual([{'type': 'ticket1', 'id': '1'},
                          {'type': 'ticket1', 'id': '3'},
                          {'type': 'ticket2', 'id': '2'},
                          {'type': 'ticket3', 'id': '4'}],
            result.docs)

    def test_can_apply_multiple_sort_conditions_desc(self):
        self.whoosh_backend.add_doc(dict(id="2", type="ticket2"))
        self.whoosh_backend.add_doc(dict(id="3", type="ticket1"))
        self.whoosh_backend.add_doc(dict(id="4", type="ticket3"))
        self.whoosh_backend.add_doc(dict(id="1", type="ticket1"))
        result = self.whoosh_backend.query(
            query.Every(),
            sort = [SortInstruction("type", ASC), SortInstruction("id", DESC)],
            fields=("id", "type"),
        )
        self.print_result(result)
        self.assertEqual([{'type': 'ticket1', 'id': '3'},
                          {'type': 'ticket1', 'id': '1'},
                          {'type': 'ticket2', 'id': '2'},
                          {'type': 'ticket3', 'id': '4'}],
            result.docs)

    def test_can_sort_by_score_and_date(self):
        the_first_date = datetime(2012, 12, 1)
        the_second_date = datetime(2012, 12, 2)
        the_third_date = datetime(2012, 12, 3)

        exact_match_string = "texttofind"
        not_exact_match_string = "texttofind bla"

        self.whoosh_backend.add_doc(dict(
            id="1",
            type="ticket",
            summary=not_exact_match_string,
            time=the_first_date,
        ))
        self.whoosh_backend.add_doc(dict(
            id="2",
            type="ticket",
            summary=exact_match_string,
            time=the_second_date,
        ))
        self.whoosh_backend.add_doc(dict(
            id="3",
            type="ticket",
            summary=not_exact_match_string,
            time=the_third_date,
        ))
        self.whoosh_backend.add_doc(dict(
            id="4",
            type="ticket",
            summary="some text out of search scope",
            time=the_third_date,
        ))

        parsed_query = self.parser.parse("summary:texttofind")

        result = self.whoosh_backend.query(
            parsed_query,
            sort = [
                SortInstruction(SCORE, ASC),
                SortInstruction("time", DESC)
            ],
        )
        self.print_result(result)
        self.assertEqual(3, result.hits)
        docs = result.docs
        #must be found first, because the highest score (of exact match)
        self.assertEqual("2", docs[0]["id"])
        #must be found second, because the time order DESC
        self.assertEqual("3", docs[1]["id"])
        #must be found third, because the time order DESC
        self.assertEqual("1", docs[2]["id"])

    def test_can_do_facet_count(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket", product="A"))
        self.whoosh_backend.add_doc(dict(id="2", type="ticket", product="B"))
        self.whoosh_backend.add_doc(dict(id="3", type="wiki", product="A"))
        result = self.whoosh_backend.query(
            query.Every(),
            sort = [SortInstruction("type", ASC), SortInstruction("id", DESC)],
            fields=("id", "type"),
            facets= ("type", "product")
        )
        self.print_result(result)
        self.assertEqual(3, result.hits)
        facets = result.facets
        self.assertEqual({"ticket":2, "wiki":1}, facets["type"])
        self.assertEqual({"A":2, "B":1}, facets["product"])

    def test_can_do_facet_if_filed_missing_TODO(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        self.whoosh_backend.add_doc(dict(id="2", type="ticket", status="New"))
        result = self.whoosh_backend.query(
            query.Every(),
            facets= ("type", "status")
        )
        self.print_result(result)
        self.assertEqual(2, result.hits)
        facets = result.facets
        self.assertEqual({"ticket":2}, facets["type"])
        self.assertEqual({None: 1, 'New': 1}, facets["status"])

    def test_can_return_empty_result(self):
        result = self.whoosh_backend.query(
            query.Every(),
            sort = [SortInstruction("type", ASC), SortInstruction("id", DESC)],
            fields=("id", "type"),
            facets= ("type", "product")
        )
        self.print_result(result)
        self.assertEqual(0, result.hits)

    def test_can_search_time_with_utc_tzinfo(self):
        time = datetime(2012, 12, 13, 11, 8, 34, 711957,
            tzinfo=FixedOffset(0, 'UTC'))
        self.whoosh_backend.add_doc(dict(id="1", type="ticket", time=time))
        result = self.whoosh_backend.query(query.Every())
        self.print_result(result)
        self.assertEqual(time, result.docs[0]["time"])

    def test_can_search_time_without_tzinfo(self):
        time = datetime(2012, 12, 13, 11, 8, 34, 711957, tzinfo=None)
        self.whoosh_backend.add_doc(dict(id="1", type="ticket", time=time))
        result = self.whoosh_backend.query(query.Every())
        self.print_result(result)
        self.assertEqual(time.replace(tzinfo=utc), result.docs[0]["time"])

    def test_can_search_time_with_non_utc_tzinfo(self):
        hours = 8
        tz_diff = 1
        time = datetime(2012, 12, 13, 11, hours, 34, 711957,
            tzinfo=FixedOffset(tz_diff, "just_one_timezone"))
        self.whoosh_backend.add_doc(dict(id="1", type="ticket", time=time))
        result = self.whoosh_backend.query(query.Every())
        self.print_result(result)
        self.assertEqual(datetime(2012, 12, 13, 11, hours-tz_diff, 34, 711957,
                    tzinfo=utc), result.docs[0]["time"])


    def test_can_apply_filter_and_facet(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        self.whoosh_backend.add_doc(dict(id="2", type="wiki" ))
        result = self.whoosh_backend.query(
            query.Every(),
            filter=query.Term("type", "ticket"),
            facets=["type"]
        )
        self.print_result(result)
        self.assertEqual(1, result.hits)
        self.assertEqual("ticket", result.docs[0]["type"])

    @unittest.skip("TODO clarify behavior on Whoosh mail list")
    def test_can_search_id_and_summary_TODO(self):
        #arrange
        self.insert_ticket("test x")
        self.insert_ticket("test 1")

        fieldboosts = dict(
            id = 1,
            summary = 1,
        )

        mfp = MultifieldPlugin(list(fieldboosts.keys()),)
        pins = [WhitespacePlugin,
                PhrasePlugin,
                mfp]
        parser =  QueryParser(None, WhooshBackend.SCHEMA, plugins=pins)

        parsed_query = parser.parse("1")
        result = self.whoosh_backend.query(parsed_query)
        self.print_result(result)
        self.assertEqual(2, result.hits)

    def test_no_index_error_when_counting_facet_on_missing_field(self):
        """
        Whoosh 2.4.1 raises "IndexError: list index out of range"
        when search contains facets on field that is missing in at least one
        document in the index. The error manifests only when index contains
        more than one segment

        Introduced workaround should solve this problem.
        """
        #add more tickets to make sure we have more than one segment in index
        count = 20
        for i in range(count):
            self.insert_ticket("test %s" % (i))

        result = self.whoosh_backend.query(
            query.Every(),
            facets=["milestone"]
        )
        self.assertEquals(count, result.hits)

    def test_can_query_missing_field_and_type(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        self.whoosh_backend.add_doc(dict(id="2", type="ticket", milestone="A"))
        self.whoosh_backend.add_doc(dict(id="3", type="wiki"))
        filter = self.parser.parse_filters(["NOT (milestone:*)", "type:ticket"])
        result = self.whoosh_backend.query(
            query.Every(),
            filter=filter,
        )
        self.print_result(result)
        self.assertEqual(1, result.hits)
        self.assertEqual("1", result.docs[0]["id"])


    def test_can_query_missing_field(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        self.whoosh_backend.add_doc(dict(id="2", type="ticket", milestone="A"))
        filter = self.parser.parse_filters(["NOT (milestone:*)"])
        result = self.whoosh_backend.query(
            query.Every(),
            filter=filter,
        )
        self.print_result(result)
        self.assertEqual(1, result.hits)
        self.assertEqual("1", result.docs[0]["id"])


    @unittest.skip("TODO clarify behavior on Whoosh mail list")
    def test_can_query_missing_field_and_type_with_no_results(self):
        self.whoosh_backend.add_doc(dict(id="1", type="ticket"))
        self.whoosh_backend.add_doc(dict(id="3", type="wiki"))
        filter = self.parser.parse_filters(["NOT (milestone:*)", "type:ticket"])
        result = self.whoosh_backend.query(
            query.Every(),
            filter=filter,
        )
        self.print_result(result)
        self.assertEqual(0, result.hits)

    def test_can_highlight_given_terms(self):
        term = 'search_term'
        text = "foo foo %s bar bar" % term
        self.whoosh_backend.add_doc(dict(id="1", type="ticket", content=text))
        self.whoosh_backend.add_doc(dict(id="3", type="wiki", content=text))
        search_query = self.parser.parse(term)

        result = self.whoosh_backend.query(
            search_query,
            highlight=True,
            highlight_fields=['content', 'summary']
        )
        self.print_result(result)

        self.assertEqual(len(result.highlighting), 2)
        for highlight in result.highlighting:
            self.assertIn(self._highlighted(term), highlight['content'])
            self.assertEquals("", highlight['summary'])

    def test_that_highlighting_escapes_html(self):
        term = 'search_term'
        text = "bla <a href=''>%s bar</a> bla" % term
        self.whoosh_backend.add_doc(dict(id="1", type="ticket", content=text))
        search_query = self.parser.parse(term)

        result = self.whoosh_backend.query(
            search_query,
            highlight=True,
            highlight_fields=['content']
        )
        self.print_result(result)

        self.assertEqual(len(result.highlighting), 1)
        highlight = result.highlighting[0]
        self.assertEquals(
            "bla &lt;a href=''&gt;<em>search_term</em> bar&lt;/a&gt; bla",
            highlight['content'])

    def test_highlights_all_text_fields_by_default(self):
        term = 'search_term'
        text = "foo foo %s bar bar" % term
        self.whoosh_backend.add_doc(dict(id="1", type="ticket", content=text))
        self.whoosh_backend.add_doc(dict(id="3", type="wiki", content=text))
        search_query = self.parser.parse(term)

        result = self.whoosh_backend.query(
            search_query,
            highlight=True,
        )
        self.print_result(result)

        self.assertEqual(len(result.highlighting), 2)
        for highlight in result.highlighting:
            self.assertIn('content', highlight)
            self.assertIn('summary', highlight)
            self.assertIn(self._highlighted(term), highlight['content'])

    def test_only_highlights_terms_in_fields_that_match_query(self):
        term = 'search_term'
        self.whoosh_backend.add_doc(dict(id=term, type="wiki", content=term))
        self.whoosh_backend.add_doc(dict(id=term, type="ticket", summary=term))
        search_query = self.parser.parse('id:%s' % term)

        result = self.whoosh_backend.query(
            search_query,
            highlight=True,
            highlight_fields=["id", "content", "summary"]
        )
        self.print_result(result)

        self.assertEqual(len(result.highlighting), 2)
        for highlight in result.highlighting:
            self.assertIn(self._highlighted(term), highlight['id'])
            self.assertNotIn(self._highlighted(term), highlight['summary'])
            self.assertNotIn(self._highlighted(term), highlight['content'])

    def _highlighted(self, term):
        return '<em>%s</em>' % term


class WhooshIndexCreationTests(BaseBloodhoundSearchTest):
    def setUp(self):
        super(WhooshIndexCreationTests, self).setUp()
        self.index_dir = os.path.join(self.env.path, 'whoosh_index')
        if not os.path.exists(self.index_dir):
            os.mkdir(self.index_dir)

    def test_does_not_automatically_create_index(self):
        whoosh_backend = WhooshBackend(self.env)

        self.assertIs(whoosh_backend.index, None)
        self.assertEqual(whoosh_backend.is_index_outdated(), True)

        whoosh_backend.recreate_index()
        self.assertEqual(whoosh_backend.is_index_outdated(), False)
        self.assertIsNot(whoosh_backend.index, None)

    def test_detects_that_index_needs_upgrade(self):
        wrong_schema = Schema(content=TEXT())
        index.create_in(self.index_dir, schema=wrong_schema)

        whoosh_backend = WhooshBackend(self.env)
        self.assertEqual(whoosh_backend.is_index_outdated(), True)

        whoosh_backend.recreate_index()
        self.assertEqual(whoosh_backend.is_index_outdated(), False)


class WhooshFunctionalityTestCase(unittest.TestCase):
    def setUp(self):
        self.index_dir = tempfile.mkdtemp('whoosh_index')

    def tearDown(self):
        shutil.rmtree(self.index_dir)

    def test_groupedby_empty_field(self):
        schema = Schema(
                unique_id=ID(stored=True, unique=True),
                id=ID(stored=True),
                type=ID(stored=True),
                status=KEYWORD(stored=True),
                content=TEXT(stored=True),
                )

        ix = index.create_in(self.index_dir, schema=schema)
        with ix.writer() as w:
            w.add_document(unique_id=u"1", type=u"type1")
            w.add_document(unique_id=u"2", type=u"type2", status=u"New")

        facet_fields = (u"type", u"status" )
        groupedby = facet_fields
        with ix.searcher() as s:
            r = s.search(
                query.Every(),
                groupedby=groupedby,
                maptype=sorting.Count,
            )
            facets = self._load_facets(r)
        self.assertEquals(
            {'status': {None: 1, 'New': 1}, 'type': {'type1': 1, 'type2': 1}},
            facets)

    def _load_facets(self, non_paged_results):
        facet_names = non_paged_results.facet_names()
        if not facet_names:
            return None
        facets_result = dict()
        for name in facet_names:
            facets_result[name] = non_paged_results.groups(name)
        return facets_result

    def test_can_auto_commit(self):
        # pylint: disable=unused-argument

        schema = Schema(
                unique_id=ID(stored=True, unique=True),
                type=ID(stored=True),
                )

        ix = index.create_in(self.index_dir, schema=schema)
        with ix.writer() as w:
            w.add_document(unique_id=u"1", type=u"type1")
            w.add_document(unique_id=u"2", type=u"type2")

        with ix.searcher() as s:
            results = s.search(query.Every())
            self.assertEquals(2, len(results))

    def test_can_auto_cancel(self):
        schema = Schema(
                unique_id=ID(stored=True, unique=True),
                type=ID(stored=True),
                )

        ix = index.create_in(self.index_dir, schema=schema)
        try:
            with ix.writer() as w:
                w.add_document(unique_id=u"1", type=u"type1")
                w.add_document(unique_id=u"2", type=u"type2")
                raise Exception("some exception")
        except Exception:
            pass

        with ix.searcher() as s:
            results = s.search(query.Every())
            self.assertEquals(0, len(results))

    def test_handles_stop_words_in_queries(self):
        schema = WhooshBackend.SCHEMA
        ix = index.create_in(self.index_dir, schema=schema)
        with ix.writer() as w:
            w.add_document(content=u"A nice sentence with stop words.")

        with ix.searcher() as s:
            query_text = u"with stop"

            # field_names both ignore stop words
            q = MultifieldParser(['content', 'summary'],
                                 WhooshBackend.SCHEMA).parse(query_text)
            self.assertEqual(unicode(q.simplify(s)),
                             u'((content:with OR summary:with) AND '
                             u'(content:stop OR summary:stop))')
            self.assertEqual(len(s.search(q)), 1)

            # 'content' and 'id' ignores stop words
            q = MultifieldParser(['content', 'id'],
                                 WhooshBackend.SCHEMA).parse(query_text)
            self.assertEqual(unicode(q.simplify(s)),
                             u'((content:with OR id:with) AND '
                             u'(content:stop OR id:stop))')
            self.assertEqual(len(s.search(q)), 1)

    def test_can_filter_to_no_results(self):
        schema = Schema(
            id=ID(stored=True),
            filter=TEXT(stored=True),
        )

        ix = index.create_in(self.index_dir, schema=schema)
        with ix.writer() as w:
            w.add_document(id=u"1", filter=u"f1")
            w.add_document(id=u"2", filter=u"f2")

        with ix.searcher() as s:
            r = s.search(
                query.Every(),
                filter=QueryParser('', schema).parse(u"filter:other")
            )
        self.assertEquals(len(r), 0)


def suite():
    test_suite = unittest.TestSuite()
    test_suite.addTest(unittest.makeSuite(WhooshBackendTestCase))
    test_suite.addTest(unittest.makeSuite(WhooshFunctionalityTestCase))
    return test_suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = translation
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Translation functions and classes.
"""

from trac.util.translation import domain_functions

#------------------------------------------------------
#    Internationalization
#------------------------------------------------------

_, ngettext, tag_, tagn_, gettext, N_, add_domain = \
   domain_functions('bhsearch', ('_', 'ngettext', 'tag_', 'tagn_',
                                'gettext', 'N_', 'add_domain'))

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Bloodhound Search user interface."""
import copy
from collections import defaultdict

import pkg_resources
from bhsearch import BHSEARCH_CONFIG_SECTION
import re

from trac.core import Component, implements, TracError
from genshi.builder import tag
from genshi import HTML
from trac.perm import IPermissionRequestor
from trac.search import shorten_result
from trac.config import OrderedExtensionsOption, ListOption, Option, BoolOption
from trac.util.presentation import Paginator
from trac.util.datefmt import format_datetime, user_time
from trac.web import IRequestHandler, IRequestFilter
from trac.util.html import find_element
from trac.web.chrome import (ITemplateProvider,
                             add_link, add_stylesheet, prevnext_nav,
                             web_context)
from bhsearch.api import (BloodhoundSearchApi, ISearchParticipant, SCORE, ASC,
                          DESC, IndexFields, SortInstruction)
from bhsearch.utils import get_global_env, using_multiproduct
from bhsearch.utils.translation import _
from trac.wiki.formatter import extract_link
from multiproduct.env import ProductEnvironment
from multiproduct.web_ui import ProductModule

SEARCH_PERMISSION = 'SEARCH_VIEW'
DEFAULT_RESULTS_PER_PAGE = 10
SEARCH_URL = '/search'
BHSEARCH_URL = '/bhsearch'
SEARCH_URLS_RE = re.compile(r'/(?P<prefix>bh)?search(?P<suffix>.*)')


class RequestParameters(object):
    """
    Helper class for parameter parsing and creation of bhsearch specific URLs.

    Lifecycle of the class must be per request
    """
    QUERY = "q"
    PAGE = "page"
    TYPE = "type"
    NO_QUICK_JUMP = "noquickjump"
    PAGELEN = "pagelen"
    FILTER_QUERY = "fq"
    VIEW = "view"
    SORT = "sort"
    DEBUG = "debug"
    PRODUCT = "product_prefix"
    PRODUCT_ID = "productid"

    def __init__(self, req, href=None):
        # pylint: disable=too-many-branches
        self.req = req
        self.href = href or req.href

        self.original_query = req.args.getfirst(self.QUERY)
        if self.original_query is None:
            self.query = ""
        else:
            self.query = self.original_query.strip()

        self.no_quick_jump = int(req.args.getfirst(self.NO_QUICK_JUMP, '0'))

        self.view = req.args.getfirst(self.VIEW)
        self.filter_queries = req.args.getlist(self.FILTER_QUERY)
        self.filter_queries = self._remove_possible_duplications(
            self.filter_queries)

        self.sort_string = req.args.getfirst(self.SORT)
        self.sort = self._parse_sort(self.sort_string)

        self.pagelen = int(req.args.getfirst(
            RequestParameters.PAGELEN,
            DEFAULT_RESULTS_PER_PAGE))
        self.page = int(req.args.getfirst(self.PAGE, '1'))
        self.type = req.args.getfirst(self.TYPE)

        self.product = req.args.getfirst(self.PRODUCT)
        self.debug = int(req.args.getfirst(self.DEBUG, '0'))

        self.params = {
            RequestParameters.FILTER_QUERY: []
        }

        if self.original_query is not None:
            self.params[self.QUERY] = self.original_query
        if self.no_quick_jump > 0:
            self.params[self.NO_QUICK_JUMP] = self.no_quick_jump
        if self.view is not None:
            self.params[self.VIEW] = self.view
        if self.pagelen != DEFAULT_RESULTS_PER_PAGE:
            self.params[self.PAGELEN] = self.pagelen
        if self.page > 1:
            self.params[self.PAGE] = self.page
        if self.type:
            self.params[self.TYPE] = self.type
        if self.product is not None:
            self.params[self.PRODUCT] = self.product
        if self.filter_queries:
            self.params[RequestParameters.FILTER_QUERY] = self.filter_queries
        if self.sort_string:
            self.params[RequestParameters.SORT] = self.sort_string
        if self.debug:
            self.params[RequestParameters.DEBUG] = self.debug

    def _parse_sort(self, sort_string):
        if not sort_string:
            return None
        sort_terms = sort_string.split(",")
        sort = []

        for term in sort_terms:
            term = term.strip()
            if not term:
                continue
            term_parts = term.split()
            parts_count = len(term_parts)
            if parts_count == 1:
                sort.append(SortInstruction(term_parts[0], ASC))
            elif parts_count == 2:
                sort.append(SortInstruction(term_parts[0], term_parts[1]))
            else:
                raise TracError("Invalid sort term %s " % term)

        return sort if sort else None

    def _remove_possible_duplications(self, parameters_list):
        seen = set()
        return [parameter for parameter in parameters_list
                if parameter not in seen and not seen.add(parameter)]

    def create_href(
            self,
            page=None,
            type=None,
            skip_type=False,
            skip_page=False,
            additional_filter=None,
            force_filters=None,
            view=None,
            skip_view=False,
            sort=None,
            skip_sort=False,
            query=None,
            skip_query=False,
            product=None,
            skip_product=False,
    ):
        # pylint: disable=too-many-locals,too-many-branches
        params = copy.deepcopy(self.params)

        if skip_sort:
            self._delete_if_exists(params, self.SORT)
        elif sort:
            params[self.SORT] = self._create_sort_expression(sort)

        #noquickjump parameter should be always set to 1 for urls
        params[self.NO_QUICK_JUMP] = 1

        if skip_view:
            self._delete_if_exists(params, self.VIEW)
        elif view:
            params[self.VIEW] = view

        if skip_page:
            self._delete_if_exists(params, self.PAGE)
        elif page:
            params[self.PAGE] = page

        if skip_type:
            self._delete_if_exists(params, self.TYPE)
        elif type:
            params[self.TYPE] = type

        if additional_filter and\
           additional_filter not in params[self.FILTER_QUERY]:
            params[self.FILTER_QUERY].append(additional_filter)
        elif force_filters is not None:
            params[self.FILTER_QUERY] = force_filters

        if skip_query:
            self._delete_if_exists(params, self.QUERY)
        elif query is not None:
            params[self.QUERY] = query

        if skip_product:
            self._delete_if_exists(params, self.PRODUCT)
        elif product is not None:
            params[self.PRODUCT] = product

        return self.href.bhsearch(**params)

    def _create_sort_expression(self, sort):
        """
        Accepts single sort instruction e.g. SortInstruction(field, ASC) or
        list of sort instructions e.g.
        [SortInstruction(field1, ASC), SortInstruction(field2, DESC)]
        """
        if not sort:
            return None

        if isinstance(sort, SortInstruction):
            return sort.build_sort_expression()

        return ", ".join([item.build_sort_expression() for item in sort])


    def _delete_if_exists(self, params, name):
        if name in params:
            del params[name]


class BloodhoundSearchModule(Component):
    """Main search page"""
    implements(IPermissionRequestor, IRequestHandler,
        ITemplateProvider, IRequestFilter
        #           IWikiSyntaxProvider #todo: implement later
    )

    search_participants = OrderedExtensionsOption(
        'bhsearch',
        'search_participants',
        ISearchParticipant,
        "TicketSearchParticipant, WikiSearchParticipant",
        include_missing=True
    )

    prefix = "all"
    default_grid_fields = [
        IndexFields.PRODUCT,
        IndexFields.ID,
        IndexFields.TYPE,
        IndexFields.TIME,
        IndexFields.AUTHOR,
        IndexFields.CONTENT,
    ]

    default_facets = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_facets',
        default=",".join([IndexFields.PRODUCT, IndexFields.TYPE]),
        doc="""Default facets applied to search view of all resources""",
        doc_domain='bhsearch')

    default_view = Option(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_view',
        doc="""If true, show grid as default view for specific resource in
            Bloodhound Search results""", doc_domain='bhsearch')

    all_grid_fields = ListOption(
        BHSEARCH_CONFIG_SECTION,
        prefix + '_default_grid_fields',
        default=",".join(default_grid_fields),
        doc="""Default fields for grid view for specific resource""",
        doc_domain='bhsearch')

    default_search = BoolOption(
        BHSEARCH_CONFIG_SECTION,
        'is_default',
        default=False,
        doc="""Searching from quicksearch uses bhsearch.""",
        doc_domain='bhsearch')

    redirect_enabled = BoolOption(
        BHSEARCH_CONFIG_SECTION,
        'enable_redirect',
        default=False,
        doc="""Redirect links pointing to trac search to bhsearch""",
        doc_domain='bhsearch')

    global_quicksearch = BoolOption(
        BHSEARCH_CONFIG_SECTION,
        'global_quicksearch',
        default=True,
        doc="""Quicksearch searches all products, even when used
            in product env.""", doc_domain='bhsearch')

    query_suggestions_enabled = BoolOption(
        BHSEARCH_CONFIG_SECTION,
        'query_suggestions',
        default=True,
        doc="""Display query suggestions.""", doc_domain='bhsearch'
    )

    # IPermissionRequestor methods
    def get_permission_actions(self):
        return [SEARCH_PERMISSION]

    # IRequestHandler methods
    def match_request(self, req):
        return re.match('^%s' % BHSEARCH_URL, req.path_info) is not None

    def process_request(self, req):
        req.perm.assert_permission(SEARCH_PERMISSION)

        if self._is_opensearch_request(req):
            return ('opensearch.xml', {},
                    'application/opensearchdescription+xml')

        request_context = RequestContext(
            self.env,
            req,
            self.search_participants,
            self.default_view,
            self.all_grid_fields,
            self.default_facets,
            self.global_quicksearch,
            self.query_suggestions_enabled,
        )

        if request_context.requires_redirect:
            req.redirect(request_context.parameters.create_href(), True)

        # compatibility with legacy search
        req.search_query = request_context.parameters.query

        query_result = BloodhoundSearchApi(self.env).query(
            request_context.parameters.query,
            pagenum=request_context.page,
            pagelen=request_context.pagelen,
            sort=request_context.sort,
            fields=request_context.fields,
            facets=request_context.facets,
            filter=request_context.query_filter,
            highlight=True,
            context=request_context,
        )

        request_context.process_results(query_result)
        return self._return_data(req, request_context.data)

    def _is_opensearch_request(self, req):
        return req.path_info == BHSEARCH_URL + '/opensearch'

    def _return_data(self, req, data):
        add_stylesheet(req, 'common/css/search.css')
        return 'bhsearch.html', data, None

    # ITemplateProvider methods
    def get_htdocs_dirs(self):
    #        return [('bhsearch',
    #                 pkg_resources.resource_filename(__name__, 'htdocs'))]
        return []

    def get_templates_dirs(self):
        return [pkg_resources.resource_filename(__name__, 'templates')]

    # IRequestFilter methods
    def pre_process_request(self, req, handler):
        if SEARCH_URLS_RE.match(req.path_info):
            if self.redirect_enabled:
                return self
        return handler

    def post_process_request(self, req, template, data, content_type):
        if data is None:
            return template, data, content_type

        if self.redirect_enabled:
            data['search_handler'] = req.href.bhsearch()
        elif req.path_info.startswith(SEARCH_URL):
            data['search_handler'] = req.href.search()
        elif self.default_search or req.path_info.startswith(BHSEARCH_URL):
            data['search_handler'] = req.href.bhsearch()
        else:
            data['search_handler'] = req.href.search()
        return template, data, content_type


class RequestContext(object):
    DATA_ACTIVE_FILTER_QUERIES = 'active_filter_queries'
    DATA_ACTIVE_PRODUCT = 'active_product'
    DATA_ACTIVE_QUERY = 'active_query'
    DATA_BREADCRUMBS_TEMPLATE = 'resourcepath_template'
    DATA_HEADERS = "headers"
    DATA_ALL_VIEWS = "all_views"
    DATA_VIEW = "view"
    DATA_VIEW_GRID = "grid"
    DATA_FACET_COUNTS = 'facet_counts'
    DATA_DEBUG = 'debug'
    DATA_PAGE_HREF = 'page_href'
    DATA_RESULTS = 'results'
    DATA_PRODUCT_LIST = 'search_product_list'
    DATA_QUERY = 'query'
    DATA_QUICK_JUMP = "quickjump"
    DATA_QUERY_SUGGESTION = 'query_suggestion'
    DATA_SEARCH_EXTRAS = 'extra_search_fields'

    #bhsearch may support more pluggable views later
    VIEWS_SUPPORTED = (
        (None, "Free text"),
        (DATA_VIEW_GRID, "Grid"),
    )

    VIEWS_WITH_KNOWN_FIELDS = [DATA_VIEW_GRID]
    OBLIGATORY_FIELDS_TO_SELECT = [IndexFields.ID, IndexFields.TYPE]
    DEFAULT_SORT = [SortInstruction(SCORE, ASC), SortInstruction("time", DESC)]

    def __init__(
            self,
            env,
            req,
            search_participants,
            default_view,
            all_grid_fields,
            default_facets,
            global_quicksearch,
            query_suggestions,
            ):
        self.env = env
        self.req = req
        self.requires_redirect = False
        self._handle_multiproduct_parameters(req, global_quicksearch)
        self.parameters = RequestParameters(
            req,
            href=get_global_env(self.env).href
        )
        self.data = {
            self.DATA_QUERY: self.parameters.query,
            self.DATA_SEARCH_EXTRAS: [],
        }
        self.search_participants = search_participants
        self.default_view = default_view
        self.all_grid_fields = all_grid_fields
        self.default_facets = default_facets
        self.view = None
        self.page = self.parameters.page
        self.pagelen = self.parameters.pagelen
        self.query_suggestions = query_suggestions

        if self.parameters.sort:
            self.sort = self.parameters.sort
        else:
            self.sort = self.DEFAULT_SORT

        self.allowed_participants, self.sorted_participants = \
            self._get_allowed_participants(req)

        if self.parameters.type in self.allowed_participants:
            self.active_type = self.parameters.type
            self.active_participant = self.allowed_participants[
                                      self.active_type]
        else:
            self.active_type = None
            self.active_participant = None

        self.active_product = self.parameters.product

        self._prepare_active_type()
        self._prepare_hidden_search_fields()
        self._prepare_quick_jump()

        # Compatibility with trac search
        self._process_legacy_type_filters(req, search_participants)
        if not req.path_info.startswith(BHSEARCH_URL):
            self.requires_redirect = True

        self.fields = self._prepare_fields_and_view()
        self.query_filter = self._prepare_query_filter()
        self.facets = self._prepare_facets()

    def _handle_multiproduct_parameters(self, req, global_quicksearch):
        if not using_multiproduct(self.env):
            return

        if self.env.parent is not None:
            if not global_quicksearch:
                req.args[RequestParameters.PRODUCT] = \
                    self.env.product.prefix
            self.requires_redirect = True

    def _get_allowed_participants(self, req):
        allowed_participants = {}
        ordered_participants = []
        for participant in self.search_participants:
            if participant.is_allowed(req):
                allowed_participants[
                    participant.get_participant_type()] = participant
                ordered_participants.append(participant)
        return allowed_participants, ordered_participants

    def _prepare_active_type(self):
        active_type = self.parameters.type
        if active_type and active_type not in self.allowed_participants:
            raise TracError(_("Unsupported resource type: '%(name)s'",
                            name=active_type))

    def _prepare_hidden_search_fields(self):
        if self.active_type:
            self.data[self.DATA_SEARCH_EXTRAS].append(
                (RequestParameters.TYPE, self.active_type)
            )

        if self.parameters.product:
            self.data[self.DATA_SEARCH_EXTRAS].append(
                (RequestParameters.PRODUCT, self.parameters.product)
            )

        if self.parameters.view:
            self.data[self.DATA_SEARCH_EXTRAS].append(
                (RequestParameters.VIEW, self.parameters.view)
            )
        if self.parameters.sort:
            self.data[self.DATA_SEARCH_EXTRAS].append(
                (RequestParameters.SORT, self.parameters.sort_string)
            )
        for filter_query in self.parameters.filter_queries:
            self.data[self.DATA_SEARCH_EXTRAS].append(
                (RequestParameters.FILTER_QUERY, filter_query)
            )

    def _prepare_quick_jump(self):
        if not self.parameters.query:
            return
        check_result = self._check_quickjump(
            self.req,
            self.parameters.query)
        if check_result:
            self.data[self.DATA_QUICK_JUMP] = check_result

    #the method below is "copy/paste" from trac search/web_ui.py
    def _check_quickjump(self, req, kwd):
        """Look for search shortcuts"""
        # pylint: disable=maybe-no-member
        noquickjump = int(req.args.get('noquickjump', '0'))
        # Source quickjump   FIXME: delegate to ISearchSource.search_quickjump
        quickjump_href = None
        if kwd[0] == '/':
            quickjump_href = req.href.browser(kwd)
            name = kwd
            description = _('Browse repository path %(path)s', path=kwd)
        else:
            context = web_context(req, 'search')
            link = find_element(extract_link(self.env, context, kwd), 'href')
            if link is not None:
                quickjump_href = link.attrib.get('href')
                name = link.children
                description = link.attrib.get('title', '')
        if quickjump_href:
            # Only automatically redirect to local quickjump links
            base_path = req.base_path.replace('@', '%40')
            redirect_href = quickjump_href.replace('@', '%40')
            if not redirect_href.startswith(base_path or '/'):
                noquickjump = True
            if noquickjump:
                return {'href': quickjump_href, 'name': tag.EM(name),
                        'description': description}
            else:
                req.redirect(quickjump_href)

    def _prepare_fields_and_view(self):
        self._add_views_selector()
        self.view = self._get_view()
        if self.view:
            self.data[self.DATA_VIEW] = self.view
        fields_to_select = None
        if self.view in self.VIEWS_WITH_KNOWN_FIELDS:
            if self.active_participant:
                fields_in_view = self.active_participant.\
                    get_default_view_fields(self.view)
            elif self.view == self.DATA_VIEW_GRID:
                fields_in_view = self.all_grid_fields
            else:
                raise TracError("Unsupported view: %s" % self.view)
            self.data[self.DATA_HEADERS] = [self._create_headers_item(field)
                                        for field in fields_in_view]
            fields_to_select = self._add_obligatory_fields(
                fields_in_view)
        return fields_to_select

    def _add_views_selector(self):
        active_view = self.parameters.view

        all_views = []
        for view, label in self.VIEWS_SUPPORTED:
            all_views.append(dict(
                label=_(label),
                href=self.parameters.create_href(
                    view=view, skip_view=(view is None)),
                is_active=(view == active_view)
            ))
        self.data[self.DATA_ALL_VIEWS] = all_views

    def _get_view(self):
        view = self.parameters.view
        if view is None:
            if self.active_participant:
                view = self.active_participant.get_default_view()
            else:
                view = self.default_view
        if view is not None:
            view =  view.strip().lower()
        if view == "":
            view = None
        return view

    def _add_obligatory_fields(self, fields_in_view):
        fields_to_select = list(fields_in_view)
        for obligatory_field in self.OBLIGATORY_FIELDS_TO_SELECT:
            if obligatory_field is not fields_to_select:
                fields_to_select.append(obligatory_field)
        return fields_to_select

    def _create_headers_item(self, field):
        current_sort_direction = self._get_current_sort_direction_for_field(
            field)
        href_sort_direction = DESC if current_sort_direction == ASC else ASC
        return dict(
            name=field,
            href=self.parameters.create_href(
                skip_page=True,
                sort=SortInstruction(field, href_sort_direction)
            ),
            #TODO:add translated column label. Now it is really temporary
            # workaround
            label=field,
            sort=current_sort_direction,
        )

    def _get_current_sort_direction_for_field(self, field):
        if self.sort and len(self.sort) == 1:
            single_sort = self.sort[0]
            if single_sort.field == field:
                return single_sort.order
        return None

    def _prepare_query_filter(self):
        query_filters = list(self.parameters.filter_queries)
        if self.active_type:
            query_filters.append(
                self._create_term_expression(
                    IndexFields.TYPE, self.active_type))
        if self.active_product is not None:
            query_filters.append(self._create_term_expression(
                IndexFields.PRODUCT, self.active_product or None)
            )
        return query_filters

    def _create_term_expression(self, field, field_value):
        if field_value is None:
            query = "NOT (%s:*)" % field
        elif isinstance(field_value, basestring):
            query = '%s:"%s"' % (field, field_value)
        else:
            query = '%s:%s' % (field, field_value)
        return query

    def _prepare_facets(self):
        #TODO: add possibility of specifying facets in query parameters
        if self.active_participant:
            facets = self.active_participant.get_default_facets()
        else:
            facets = self.default_facets
        return facets

    def _process_legacy_type_filters(self, req, search_participants):
        legacy_type_filters = [sp.get_participant_type()
                               for sp in search_participants
                               if sp.get_participant_type() in req.args]
        if legacy_type_filters:
            params = self.parameters.params
            if len(legacy_type_filters) == 1:
                self.parameters.type = params[RequestParameters.TYPE] = \
                    legacy_type_filters[0]
            else:
                filter_queries = self.parameters.filter_queries
                if params[RequestParameters.FILTER_QUERY] is not filter_queries:
                    params[RequestParameters.FILTER_QUERY] = filter_queries
                filter_queries.append(
                    'type:(%s)' % ' OR '.join(legacy_type_filters)
                )
            self.requires_redirect = True

    def _process_doc(self, doc):
        ui_doc = dict(doc)
        if doc.get('product'):
            env = ProductEnvironment(self.env, doc['product'])
            product_href = ProductEnvironment.resolve_href(env, self.env)
            # pylint: disable=too-many-function-args
            ui_doc["href"] = product_href(doc['type'], doc['id'])
        else:
            ui_doc["href"] = self.req.href(doc['type'], doc['id'])

        if doc['content']:
            ui_doc['content'] = shorten_result(doc['content'])

        if doc['time']:
            ui_doc['date'] = user_time(self.req, format_datetime, doc['time'])

        is_free_text_view = self.view is None
        if is_free_text_view:
            participant = self.allowed_participants[doc['type']]
            ui_doc['title'] = participant.format_search_results(doc)
        return ui_doc

    def _prepare_results(self, result_docs, hits):
        ui_docs = [self._process_doc(doc) for doc in result_docs]

        results = Paginator(
            ui_docs,
            self.page - 1,
            self.pagelen,
            hits)

        self._prepare_shown_pages(results)
        results.current_page = {'href': None,
                                'class': 'current',
                                'string': str(results.page + 1),
                                'title': None}

        parameters = self.parameters
        if results.has_next_page:
            next_href = parameters.create_href(page=parameters.page + 1)
            add_link(self.req, 'next', next_href, _('Next Page'))

        if results.has_previous_page:
            prev_href = parameters.create_href(page=parameters.page - 1)
            add_link(self.req, 'prev', prev_href, _('Previous Page'))

        self.data[self.DATA_RESULTS] = results
        prevnext_nav(self.req, _('Previous'), _('Next'))

    def _prepare_shown_pages(self, results):
        shown_pages = results.get_shown_pages(self.pagelen)
        page_data = []
        for shown_page in shown_pages:
            page_href = self.parameters.create_href(page=shown_page)
            page_data.append([page_href, None, str(shown_page),
                              'page ' + str(shown_page)])
        fields = ['href', 'class', 'string', 'title']
        results.shown_pages = [dict(zip(fields, p)) for p in page_data]

    def process_results(self, query_result):
        docs = self._prepare_docs(query_result.docs,
                                  query_result.highlighting)
        self._prepare_results(docs, query_result.hits)
        self._prepare_result_facet_counts(query_result.facets)
        self._prepare_breadcrumbs()
        self._prepare_query_suggestion(query_result.query_suggestion)
        self.data[self.DATA_DEBUG] = query_result.debug
        if self.parameters.debug:
            self.data[self.DATA_DEBUG]['enabled'] = True
            self.data[self.DATA_SEARCH_EXTRAS].append(('debug', '1'))
        self.data[self.DATA_PAGE_HREF] = self.parameters.create_href()

    def _prepare_result_facet_counts(self, result_facets):
        """
        Sample query_result.facets content returned by query
        {
           'component': {None:2},
           'milestone': {None:1, 'm1':1},
        }

        returned facet_count contains href parameters:
        {
           'component': {None: {'count':2, href:'...'},
           'milestone': {
                            None: {'count':1,, href:'...'},
                            'm1':{'count':1, href:'...'}
                        },
        }

        """
        facet_counts = []
        if result_facets:
            for field in self.facets:
                if field == IndexFields.PRODUCT and \
                        not using_multiproduct(self.env):
                    continue
                facets_dict = result_facets.get(field, {})
                per_field_dict = dict()
                for field_value, count in facets_dict.iteritems():
                    if field == IndexFields.TYPE:
                        href = self.parameters.create_href(
                            skip_page=True,
                            force_filters=[],
                            type=field_value)
                    elif field == IndexFields.PRODUCT:
                        href = self.parameters.create_href(
                            skip_page=True,
                            product=field_value or u'',
                        )
                    else:
                        href = self.parameters.create_href(
                            skip_page=True,
                            additional_filter=self._create_term_expression(
                                field,
                                field_value)
                        )
                    per_field_dict[field_value] = dict(
                        count=count,
                        href=href
                    )
                facet_counts.append((_(field), per_field_dict))

        self.data[self.DATA_FACET_COUNTS] = facet_counts

    def _prepare_docs(self, docs, highlights):
        new_docs = []
        for doc, highlight in zip(docs, highlights):
            doc = defaultdict(str, doc)
            for field in highlight.iterkeys():
                highlighted_field = 'hilited_%s' % field
                if highlight[field]:
                    fragment = self._create_genshi_fragment(highlight[field])
                    doc[highlighted_field] = fragment
                else:
                    doc[highlighted_field] = ''
            new_docs.append(doc)
        return new_docs

    def _create_genshi_fragment(self, html_fragment):
        return tag(HTML(html_fragment))

    def _prepare_breadcrumbs(self):
        self._prepare_breadcrumbs_template()
        self._prepare_product_breadcrumb()
        self._prepare_query_filter_breadcrumbs()

    def _prepare_breadcrumbs_template(self):
        self.data[self.DATA_BREADCRUMBS_TEMPLATE] = 'bhsearch_breadcrumbs.html'

    def _prepare_product_breadcrumb(self):
        if not using_multiproduct(self.env):
            return
        product_search = lambda x: self.parameters.create_href(product=x)
        all_products_search = self.parameters.create_href(skip_product=True)

        global_product = [(u'', _(u'Global product'), product_search(u''))]
        products = \
            ProductModule.get_product_list(self.env, self.req, product_search)
        all_products = [(None, _(u'All products'), all_products_search)]

        search_product_list = global_product + products + all_products

        # pylint: disable=unused-variable
        for prefix, name, url in search_product_list:
            if prefix == self.active_product:
                self.data[self.DATA_ACTIVE_PRODUCT] = name
                break
        else:
            self.data[self.DATA_ACTIVE_PRODUCT] = self.active_product
        self.data[self.DATA_PRODUCT_LIST] = search_product_list

    def _prepare_query_filter_breadcrumbs(self):
        current_filters = self.parameters.filter_queries

        def remove_filter_from_list(filter_to_remove):
            new_filters = list(current_filters)
            new_filters.remove(filter_to_remove)
            return new_filters

        if self.active_type:
            type_query = self._create_term_expression('type', self.active_type)
            type_filters = [dict(
                href=self.parameters.create_href(skip_type=True,
                                                 force_filters=[]),
                label=unicode(self.active_type).capitalize(),
                query=type_query,
            )]
        else:
            type_filters = []

        active_filter_queries = [
            dict(
                href=self.parameters.create_href(
                    force_filters=remove_filter_from_list(filter_query)
                ),
                label=filter_query,
                query=filter_query,
            ) for filter_query in self.parameters.filter_queries
        ]
        active_query = dict(
            href=self.parameters.create_href(skip_query=True),
            label=u'"%s"' % self.parameters.query,
            query=self.parameters.query
        )

        self.data[self.DATA_ACTIVE_FILTER_QUERIES] = \
            type_filters + active_filter_queries
        self.data[self.DATA_ACTIVE_QUERY] = active_query

    def _prepare_query_suggestion(self, suggestion):
        if self.query_suggestions and suggestion is not None:
            self.data[self.DATA_QUERY_SUGGESTION] = dict(
                query=suggestion,
                href=self.parameters.create_href(query=suggestion)
            )
        else:
            self.data[self.DATA_QUERY_SUGGESTION] = None

########NEW FILE########
__FILENAME__ = whoosh_backend
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

r"""Whoosh specific backend for Bloodhound Search plugin."""

import os
from datetime import datetime

from trac.core import Component, implements, TracError
from trac.config import Option, IntOption
from trac.env import ISystemInfoProvider
from trac.util.datefmt import utc

import whoosh
from whoosh import index, analysis
from whoosh.collectors import FilterCollector
from whoosh.fields import Schema, ID, DATETIME, KEYWORD, TEXT
from whoosh.writing import AsyncWriter

from bhsearch import BHSEARCH_CONFIG_SECTION
from bhsearch.api import ISearchBackend, DESC, QueryResult, SCORE
from bhsearch.security import SecurityPreprocessor
from bhsearch.utils import get_global_env

UNIQUE_ID = "unique_id"


class WhooshBackend(Component):
    """
    Implements Whoosh SearchBackend interface
    """
    implements(ISearchBackend, ISystemInfoProvider)

    index_dir_setting = Option(
        BHSEARCH_CONFIG_SECTION,
        'whoosh_index_dir',
        default='whoosh_index',
        doc="""Relative path is resolved relatively to the
        directory of the environment.""", doc_domain='bhsearch')

    advanced_security = Option(
        BHSEARCH_CONFIG_SECTION,
        'advanced_security',
        default=False,
        doc="Check view permission for each document when retrieving results.",
        doc_domain='bhsearch'
    )

    max_fragment_size = IntOption(
        BHSEARCH_CONFIG_SECTION,
        'max_fragment_size',
        default=240,
        doc="The maximum number of characters allowed in a fragment.",
        doc_domain='bhsearch')

    fragment_surround = IntOption(
        BHSEARCH_CONFIG_SECTION,
        'fragment_surround',
        default=60,
        doc="""The number of extra characters of context to add both before
        the first matched term and after the last matched term.""",
        doc_domain='bhsearch')

    #This is schema prototype. It will be changed later
    #TODO: add other fields support, add dynamic field support.
    #Schema must be driven by index participants
    SCHEMA = Schema(
        unique_id=ID(stored=True, unique=True),
        id=ID(stored=True),
        type=ID(stored=True),
        product=ID(stored=True),
        milestone=ID(stored=True),
        time=DATETIME(stored=True),
        due=DATETIME(stored=True),
        completed=DATETIME(stored=True),
        author=ID(stored=True),
        component=ID(stored=True),
        status=ID(stored=True),
        resolution=ID(stored=True),
        keywords=KEYWORD(scorable=True),
        summary=TEXT(stored=True,
                     analyzer=analysis.StandardAnalyzer(stoplist=None)),
        content=TEXT(stored=True,
                     analyzer=analysis.StandardAnalyzer(stoplist=None)),
        changes=TEXT(analyzer=analysis.StandardAnalyzer(stoplist=None)),
        owner=TEXT(stored=True,
                   analyzer=analysis.SimpleAnalyzer()),
        repository=TEXT(stored=True,
                        analyzer=analysis.SimpleAnalyzer()),
        revision=TEXT(stored=True,
                      analyzer=analysis.SimpleAnalyzer()),
        message=TEXT(stored=True,
                     analyzer=analysis.SimpleAnalyzer()),
        required_permission=ID(),
        name=TEXT(stored=True,
                  analyzer=analysis.SimpleAnalyzer()),
        query_suggestion_basket=TEXT(analyzer=analysis.SimpleAnalyzer(),
                                     spelling=True),
        relations=KEYWORD(lowercase=True, commas=True),
    )

    def __init__(self):
        self.index_dir = self.index_dir_setting
        if not os.path.isabs(self.index_dir):
            self.index_dir = os.path.join(get_global_env(self.env).path,
                                          self.index_dir)
        if index.exists_in(self.index_dir):
            self.index = index.open_dir(self.index_dir)
        else:
            self.index = None

    # ISystemInfoProvider methods

    def get_system_info(self):
        yield 'Whoosh', whoosh.versionstring()

    # ISearchBackend methods

    def start_operation(self):
        return self._create_writer()

    def _create_writer(self):
        return AsyncWriter(self.index)

    def add_doc(self, doc, operation_context=None):
        """Add any type of  document index.

        The contents should be a dict with fields matching the search schema.
        The only required fields are type and id, everything else is optional.
        """
        writer = operation_context
        is_local_writer = False
        if writer is None:
            is_local_writer = True
            writer = self._create_writer()

        self._reformat_doc(doc)
        doc[UNIQUE_ID] = self._create_unique_id(doc.get("product", ''),
                                                doc["type"],
                                                doc["id"])
        self.log.debug("Doc to index: %s", doc)
        try:
            writer.update_document(**doc)
            if is_local_writer:
                writer.commit()
        except:
            if is_local_writer:
                writer.cancel()
            raise

    def _reformat_doc(self, doc):
        """
        Strings must be converted unicode format accepted by Whoosh.
        """
        for key, value in doc.items():
            if key is None:
                del doc[None]
            elif value is None:
                del doc[key]
            elif isinstance(value, basestring) and value == "":
                del doc[key]
            else:
                doc[key] = self._to_whoosh_format(value)

    def delete_doc(self, product, doc_type, doc_id, operation_context=None):
        unique_id = self._create_unique_id(product, doc_type, doc_id)
        self.log.debug('Removing document from the index: %s', unique_id)
        writer = operation_context
        is_local_writer = False
        if writer is None:
            is_local_writer = True
            writer = self._create_writer()
        try:
            writer.delete_by_term(UNIQUE_ID, unique_id)
            if is_local_writer:
                writer.commit()
        except:
            if is_local_writer:
                writer.cancel()
            raise

    def optimize(self):
        writer = AsyncWriter(self.index)
        writer.commit(optimize=True)

    def is_index_outdated(self):
        return self.index is None or not self.index.schema == self.SCHEMA

    def recreate_index(self):
        self.log.info('Creating Whoosh index in %s' % self.index_dir)
        self._make_dir_if_not_exists()
        self.index = index.create_in(self.index_dir, schema=self.SCHEMA)
        return self.index

    def query(self,
              query,
              query_string=None,
              sort=None,
              fields=None,
              filter=None,
              facets=None,
              pagenum=1,
              pagelen=20,
              highlight=False,
              highlight_fields=None,
              context=None):
        # pylint: disable=too-many-locals
        with self.index.searcher() as searcher:
            self._apply_advanced_security(searcher, context)

            highlight_fields = self._prepare_highlight_fields(highlight,
                                                              highlight_fields)

            sortedby = self._prepare_sortedby(sort)

            #TODO: investigate how faceting is applied to multi-value fields
            #e.g. keywords. For now, just pass facets lit to Whoosh API
            #groupedby = self._prepare_groupedby(facets)
            groupedby = facets

            query_parameters = dict(
                query=query,
                pagenum=pagenum,
                pagelen=pagelen,
                sortedby=sortedby,
                groupedby=groupedby,
                maptype=whoosh.sorting.Count,
                filter=filter,
            )
            self.env.log.debug("Whoosh query to execute: %s",
                               query_parameters)
            raw_page = searcher.search_page(**query_parameters)
            results = self._process_results(raw_page,
                                            fields,
                                            highlight_fields,
                                            query_parameters)
            if query_string is not None:
                c = searcher.correct_query(query, query_string)
                results.query_suggestion = c.string
            try:
                actual_query = unicode(query.simplify(searcher))
                results.debug['actual_query'] = actual_query
            # pylint: disable=bare-except
            except:
                # Simplify has a bug that causes it to fail sometimes.
                pass
        return results

    def _apply_advanced_security(self, searcher, context=None):
        if not self.advanced_security:
            return

        old_collector = searcher.collector
        security_processor = SecurityPreprocessor(self.env)

        def check_permission(doc):
            return security_processor.check_permission(doc, context)

        def collector(*args, **kwargs):
            c = old_collector(*args, **kwargs)
            if isinstance(c, FilterCollector):
                c = AdvancedFilterCollector(
                    c.child, c.allow, c.restrict, check_permission
                )
            else:
                c = AdvancedFilterCollector(
                    c, None, None, check_permission
                )
            return c
        searcher.collector = collector

    def _create_unique_id(self, product, doc_type, doc_id):
        if product:
            return u"%s:%s:%s" % (product, doc_type, doc_id)
        else:
            return u"%s:%s" % (doc_type, doc_id)

    def _to_whoosh_format(self, value):
        if isinstance(value, basestring):
            value = unicode(value)
        elif isinstance(value, datetime):
            value = self._convert_date_to_tz_naive_utc(value)
        return value

    def _convert_date_to_tz_naive_utc(self, value):
        """Convert datetime to naive utc datetime
        Whoosh can not read  from index datetime values passed from Trac with
        tzinfo=trac.util.datefmt.FixedOffset because of non-empty
        constructor of FixedOffset"""
        if value.tzinfo:
            utc_time = value.astimezone(utc)
            value = utc_time.replace(tzinfo=None)
        return value

    def _from_whoosh_format(self, value):
        if isinstance(value, datetime):
            value = utc.localize(value)
        return value

    def _prepare_groupedby(self, facets):
        if not facets:
            return None
        groupedby = whoosh.sorting.Facets()
        for facet_name in facets:
            groupedby.add_field(
                facet_name,
                allow_overlap=True,
                maptype=whoosh.sortingwhoosh.Count)
        return groupedby

    def _prepare_sortedby(self, sort):
        if not sort:
            return None
        sortedby = []
        for sort_instruction in sort:
            field = sort_instruction.field
            order = sort_instruction.order
            if field.lower() == SCORE:
                if self._is_desc(order):
                    #We can implement tis later by our own ScoreFacet with
                    # "score DESC" support
                    raise TracError(
                        "Whoosh does not support DESC score ordering.")
                sort_condition = whoosh.sorting.ScoreFacet()
            else:
                sort_condition = whoosh.sorting.FieldFacet(
                    field,
                    reverse=self._is_desc(order))
            sortedby.append(sort_condition)
        return sortedby

    def _prepare_highlight_fields(self, highlight, highlight_fields):
        if not highlight:
            return ()

        if not highlight_fields:
            highlight_fields = self._all_highlightable_fields()

        return highlight_fields

    def _all_highlightable_fields(self):
        return [name for name, field in self.SCHEMA.items()
                if self._is_highlightable(field)]

    def _is_highlightable(self, field):
        return not isinstance(field, whoosh.fields.DATETIME) and field.stored

    def _is_desc(self, order):
        return (order.lower()==DESC)

    def _process_results(self,
                         page,
                         fields,
                         highlight_fields,
                         search_parameters=None):
        # It's important to grab the hits first before slicing. Otherwise, this
        # can cause pagination failures.
        """
        :type fields: iterator
        :type page: ResultsPage
        """
        results = QueryResult()
        results.hits = page.total
        results.total_page_count = page.pagecount
        results.page_number = page.pagenum
        results.offset = page.offset
        results.facets = self._load_facets(page)

        docs = []
        highlighting = []
        for retrieved_record in page:
            result_doc = self._process_record(fields, retrieved_record)
            docs.append(result_doc)

            result_highlights = self._create_highlights(highlight_fields,
                                                        retrieved_record)
            highlighting.append(result_highlights)
        results.docs = docs
        results.highlighting = highlighting

        results.debug["search_parameters"] = search_parameters
        return results

    def _process_record(self, fields, retrieved_record):
        result_doc = dict()
        #add score field by default
        if not fields or SCORE in fields:
            score = retrieved_record.score
            result_doc[SCORE] = score

        if fields:
            for field in fields:
                if field in retrieved_record:
                    result_doc[field] = retrieved_record[field]
        else:
            for key, value in retrieved_record.items():
                result_doc[key] = value

        for key, value in result_doc.iteritems():
            result_doc[key] = self._from_whoosh_format(value)
        return result_doc

    def _load_facets(self, page):
        """This method can be also used by unit-tests"""
        non_paged_results = page.results
        facet_names = non_paged_results.facet_names()
        if not facet_names:
            return None
        facets_result = dict()
        for name in facet_names:
            facets_result[name] = non_paged_results.groups(name)
        return facets_result

    def _make_dir_if_not_exists(self):
        if not os.path.exists(self.index_dir):
            os.mkdir(self.index_dir)

        if not os.access(self.index_dir, os.W_OK):
            raise TracError(
                "The path to Whoosh index '%s' is not writable for the\
                 current user."
                % self.index_dir)

    def _create_highlights(self, fields, record):
        result_highlights = dict()
        fragmenter = whoosh.highlight.ContextFragmenter(
            self.max_fragment_size,
            self.fragment_surround,
        )
        highlighter = whoosh.highlight.Highlighter(
            formatter=WhooshEmFormatter(),
            fragmenter=fragmenter)

        for field in fields:
            if field in record:
                highlighted = highlighter.highlight_hit(record, field)
            else:
                highlighted = ''
            result_highlights[field] = highlighted
        return result_highlights


class WhooshEmFormatter(whoosh.highlight.HtmlFormatter):
    template = '<em>%(t)s</em>'


class AdvancedFilterCollector(FilterCollector):
    """An advanced filter collector, accepting a callback function that
    will be called for each document to determine whether it should be
    filtered out or not.

    Please note that it can be slow. Very slow.
    """

    def __init__(self, child, allow, restrict, filter_func=None):
        FilterCollector.__init__(self, child, allow, restrict)
        self.filter_func = filter_func

    def collect_matches(self):
        child = self.child
        _allow = self._allow
        _restrict = self._restrict

        if _allow is not None or _restrict is not None:
            filtered_count = self.filtered_count
            for sub_docnum in child.matches():
                global_docnum = self.offset + sub_docnum
                if ((_allow is not None and global_docnum not in _allow)
                    or (_restrict is not None and global_docnum in _restrict)):
                    filtered_count += 1
                    continue

                if self.filter_func:
                    doc = self.subsearcher.stored_fields(sub_docnum)
                    if not self.filter_func(doc):
                        filtered_count += 1
                        continue

                child.collect(sub_docnum)
            # pylint: disable=attribute-defined-outside-init
            self.filtered_count = filtered_count
        else:
            # If there was no allow or restrict set, don't do anything special,
            # just forward the call to the child collector
            child.collect_matches()

########NEW FILE########
__FILENAME__ = theme
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import sys

from genshi.builder import tag
from genshi.core import TEXT
from genshi.filters.transform import Transformer
from genshi.output import DocType

from trac.config import ListOption, Option
from trac.core import Component, TracError, implements
from trac.mimeview.api import get_mimetype
from trac.resource import get_resource_url, Neighborhood, Resource
from trac.ticket.model import Ticket, Milestone
from trac.ticket.notification import TicketNotifyEmail
from trac.ticket.web_ui import TicketModule
from trac.util.compat import set
from trac.util.presentation import to_json
from trac.versioncontrol.web_ui.browser import BrowserModule
from trac.web.api import IRequestFilter, IRequestHandler, ITemplateStreamFilter
from trac.web.chrome import (add_stylesheet, add_warning, INavigationContributor,
                             ITemplateProvider, prevnext_nav, Chrome, add_script)
from trac.wiki.admin import WikiAdmin
from trac.wiki.formatter import format_to_html

from themeengine.api import ThemeBase, ThemeEngineSystem

from bhdashboard.util import dummy_request
from bhdashboard.web_ui import DashboardModule
from bhdashboard import wiki

from multiproduct.env import ProductEnvironment
from multiproduct.web_ui import PRODUCT_RE, ProductModule
from bhtheme.translation import _, add_domain

try:
    from multiproduct.ticket.web_ui import ProductTicketModule
except ImportError:
    ProductTicketModule = None

class BloodhoundTheme(ThemeBase):
    """Look and feel of Bloodhound issue tracker.
    """
    template = htdocs = css = screenshot = disable_trac_css = True
    disable_all_trac_css = True
    BLOODHOUND_KEEP_CSS = set(
        (
            'diff.css', 'code.css'
        )
    )
    BLOODHOUND_TEMPLATE_MAP = {
        # Admin
        'admin_accountsconfig.html': ('bh_admin_accountsconfig.html', '_modify_admin_breadcrumb'),
        'admin_accountsnotification.html': ('bh_admin_accountsnotification.html', '_modify_admin_breadcrumb'),
        'admin_basics.html': ('bh_admin_basics.html', '_modify_admin_breadcrumb'),
        'admin_components.html': ('bh_admin_components.html', '_modify_admin_breadcrumb'),
        'admin_enums.html': ('bh_admin_enums.html', '_modify_admin_breadcrumb'),
        'admin_logging.html': ('bh_admin_logging.html', '_modify_admin_breadcrumb'),
        'admin_milestones.html': ('bh_admin_milestones.html', '_modify_admin_breadcrumb'),
        'admin_perms.html': ('bh_admin_perms.html', '_modify_admin_breadcrumb'),
        'admin_plugins.html': ('bh_admin_plugins.html', '_modify_admin_breadcrumb'),
        'admin_products.html': ('bh_admin_products.html', '_modify_admin_breadcrumb'),
        'admin_repositories.html': ('bh_admin_repositories.html', '_modify_admin_breadcrumb'),
        'admin_users.html': ('bh_admin_users.html', '_modify_admin_breadcrumb'),
        'admin_versions.html': ('bh_admin_versions.html', '_modify_admin_breadcrumb'),

        # no template substitutions below - use the default template,
        # but call the modifier nonetheless
        'repository_links.html': ('repository_links.html', '_modify_admin_breadcrumb'),

        # Preferences
        'prefs.html': ('bh_prefs.html', None),
        'prefs_account.html': ('bh_prefs_account.html', None),
        'prefs_advanced.html': ('bh_prefs_advanced.html', None),
        'prefs_datetime.html': ('bh_prefs_datetime.html', None),
        'prefs_general.html': ('bh_prefs_general.html', None),
        'prefs_keybindings.html': ('bh_prefs_keybindings.html', None),
        'prefs_language.html': ('bh_prefs_language.html', None),
        'prefs_pygments.html': ('bh_prefs_pygments.html', None),
        'prefs_userinterface.html': ('bh_prefs_userinterface.html', None),

        # Search
        'search.html': ('bh_search.html', '_modify_search_data'),

        # Wiki
        'wiki_delete.html': ('bh_wiki_delete.html', None),
        'wiki_diff.html': ('bh_wiki_diff.html', None),
        'wiki_edit.html': ('bh_wiki_edit.html', None),
        'wiki_rename.html': ('bh_wiki_rename.html', None),
        'wiki_view.html': ('bh_wiki_view.html', '_modify_wiki_page_path'),

        # Ticket
        'diff_view.html': ('bh_diff_view.html', None),
        'manage.html': ('manage.html', '_modify_resource_breadcrumb'),
        'milestone_edit.html': ('bh_milestone_edit.html', '_modify_roadmap_page'),
        'milestone_delete.html': ('bh_milestone_delete.html', '_modify_roadmap_page'),
        'milestone_view.html': ('bh_milestone_view.html', '_modify_roadmap_page'),
        'query.html': ('bh_query.html', '_add_products_general_breadcrumb'),
        'report_delete.html': ('bh_report_delete.html', '_add_products_general_breadcrumb'),
        'report_edit.html': ('bh_report_edit.html', '_add_products_general_breadcrumb'),
        'report_list.html': ('bh_report_list.html', '_add_products_general_breadcrumb'),
        'report_view.html': ('bh_report_view.html', '_add_products_general_breadcrumb'),
        'roadmap.html': ('bh_roadmap.html', '_modify_roadmap_page'),
        'ticket.html': ('bh_ticket.html', '_modify_ticket'),
        'ticket_delete.html': ('bh_ticket_delete.html', None),
        'ticket_preview.html': ('bh_ticket_preview.html', None),

        # Attachment
        'attachment.html': ('bh_attachment.html', None),
        'preview_file.html': ('bh_preview_file.html', None),

        # Version control
        'browser.html': ('bh_browser.html', '_modify_browser'),
        'changeset.html': ('bh_changeset.html', None),
        'diff_form.html': ('bh_diff_form.html', None),
        'dir_entries.html': ('bh_dir_entries.html', None),
        'revisionlog.html': ('bh_revisionlog.html', '_modify_browser'),

        # Multi Product
        'product_view.html': ('bh_product_view.html', '_add_products_general_breadcrumb'),
        'product_list.html': ('bh_product_list.html', '_modify_product_list'),
        'product_edit.html': ('bh_product_edit.html', '_add_products_general_breadcrumb'),

        # General purpose
        'about.html': ('bh_about.html', None),
        'history_view.html': ('bh_history_view.html', None),
        'timeline.html': ('bh_timeline.html', None),

        # Account manager plugin
        'account_details.html': ('bh_account_details.html', None),
        'login.html': ('bh_login.html', None),
        'register.html': ('bh_register.html', None),
        'reset_password.html': ('bh_reset_password.html', None),
        'user_table.html': ('bh_user_table.html', None),
        'verify_email.html': ('bh_verify_email.html', None),
    }
    BOOTSTRAP_CSS_DEFAULTS = (
        # ('XPath expression', ['default', 'bootstrap', 'css', 'classes'])
        ("body//table[not(contains(@class, 'table'))]",  # TODO: Accurate ?
         ['table', 'table-condensed']),
    )

    labels_application_short = Option('labels', 'application_short',
        'Bloodhound', """A short version of application name most commonly
        displayed in text, titles and labels""", doc_domain='bhtheme')

    labels_application_full = Option('labels', 'application_full',
        'Apache Bloodhound', """This is full name with trade mark and
        everything, it is currently used in footers and about page only""",
                                     doc_domain='bhtheme')

    labels_footer_left_prefix = Option('labels', 'footer_left_prefix', '',
        """Text to display before full application name in footers""",
                                       doc_domain='bhtheme')

    labels_footer_left_postfix = Option('labels', 'footer_left_postfix', '',
        """Text to display after full application name in footers""",
                                        doc_domain='bhtheme')

    labels_footer_right = Option('labels', 'footer_right', '',
        """Text to use as the right aligned footer""", doc_domain='bhtheme')

    _wiki_pages = None
    Chrome.default_html_doctype = DocType.HTML5

    implements(IRequestFilter, INavigationContributor, ITemplateProvider,
               ITemplateStreamFilter)

    from trac.web import main
    main.default_tracker = 'http://issues.apache.org/bloodhound'

    def _get_whitelabelling(self):
        """Gets the whitelabelling config values"""
        return {
            'application_short': self.labels_application_short,
            'application_full': self.labels_application_full,
            'footer_left_prefix': self.labels_footer_left_prefix,
            'footer_left_postfix': self.labels_footer_left_postfix,
            'footer_right': self.labels_footer_right,
            'application_version': application_version
        }

    # ITemplateStreamFilter methods

    def filter_stream(self, req, method, filename, stream, data):
        """Insert default Bootstrap CSS classes if rendering
        legacy templates (i.e. determined by template name prefix)
        and renames wiki guide links.
        """
        tx = Transformer('body')

        def add_classes(classes):
            """Return a function ensuring CSS classes will be there for element.
            """
            def attr_modifier(name, event):
                attrs = event[1][1]
                class_list = attrs.get(name, '').split()
                self.log.debug('BH Theme : Element classes ' + str(class_list))

                out_classes = ' '.join(set(class_list + classes))
                self.log.debug('BH Theme : Inserting class ' + out_classes)
                return out_classes
            return attr_modifier

        # Insert default bootstrap CSS classes if necessary
        for xpath, classes in self.BOOTSTRAP_CSS_DEFAULTS:
            tx = tx.end().select(xpath) \
                .attr('class', add_classes(classes))

        # Rename wiki guide links
        tx = tx.end() \
            .select("body//a[contains(@href,'/wiki/%s')]" % wiki.GUIDE_NAME) \
            .map(lambda text: wiki.new_name(text), TEXT)

        # Rename trac error
        app_short = self.labels_application_short
        tx = tx.end() \
            .select("body//div[@class='error']/h1") \
            .map(lambda text: text.replace("Trac", app_short), TEXT)

        return stream | tx

    # IRequestFilter methods

    def pre_process_request(self, req, handler):
        """Pre process request filter"""
        def hwiki(*args, **kw):

            def new_name(name):
                new_name = wiki.new_name(name)
                if new_name != name:
                    if not self._wiki_pages:
                        wiki_admin = WikiAdmin(self.env)
                        self._wiki_pages = wiki_admin.get_wiki_list()
                    if new_name in self._wiki_pages:
                        return new_name
                return name

            a = tuple([new_name(x) for x in args])
            return req.href.__call__("wiki", *a, **kw)

        req.href.wiki = hwiki

        return handler

    def post_process_request(self, req, template, data, content_type):
        """Post process request filter.
        Removes all trac provided css if required"""

        if template is None and data is None and \
                sys.exc_info() == (None, None, None):
            return template, data, content_type

        def is_active_theme():
            is_active = False
            active_theme = ThemeEngineSystem(self.env).theme
            if active_theme is not None:
                this_theme_name = self.get_theme_names().next()
                is_active = active_theme['name'] == this_theme_name
            return is_active

        req.chrome['labels'] = self._get_whitelabelling()

        if data is not None:
            data['product_list'] = \
                ProductModule.get_product_list(self.env, req)

        links = req.chrome.get('links', {})
        # replace favicon if appropriate
        if self.env.project_icon == 'common/trac.ico':
            bh_icon = 'theme/img/bh.ico'
            new_icon = {'href': req.href.chrome(bh_icon),
                        'type': get_mimetype(bh_icon)}
            if links.get('icon'):
                links.get('icon')[0].update(new_icon)
            if links.get('shortcut icon'):
                links.get('shortcut icon')[0].update(new_icon)

        is_active_theme = is_active_theme()
        if self.disable_all_trac_css and is_active_theme:
            # Move 'admin' entry from mainnav to metanav
            for i, entry in enumerate(req.chrome['nav'].get('mainnav', [])):
                if entry['name'] == 'admin':
                    req.chrome['nav'].setdefault('metanav', []) \
                       .append(req.chrome['nav']['mainnav'].pop(i))

            if self.disable_all_trac_css:
                stylesheets = links.get('stylesheet', [])
                if stylesheets:
                    path = '/chrome/common/css/'
                    _iter = ([ss, ss.get('href', '')] for ss in stylesheets)
                    links['stylesheet'] = \
                        [ss for ss, href in _iter if not path in href or
                         href.rsplit('/', 1)[-1] in self.BLOODHOUND_KEEP_CSS]
            template, modifier = \
                self.BLOODHOUND_TEMPLATE_MAP.get(template, (template, None))
            if modifier is not None:
                modifier = getattr(self, modifier)
                modifier(req, template, data, content_type, is_active_theme)

        if is_active_theme and data is not None:
            data['responsive_layout'] = \
                self.env.config.getbool('bloodhound', 'responsive_layout',
                                        'true')
            data['bhrelations'] = \
                self.env.config.getbool('components', 'bhrelations.*', 'false')

        if req.locale is not None:
            add_script(req, 'theme/bloodhound/%s.js' % req.locale)

        return template, data, content_type

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        """Ensure dashboard htdocs will be there even if
        `bhdashboard.web_ui.DashboardModule` is disabled.
        """
        if not self.env.is_component_enabled(DashboardModule):
            return DashboardModule(self.env).get_htdocs_dirs()

    def get_templates_dirs(self):
        """Ensure dashboard templates will be there even if
        `bhdashboard.web_ui.DashboardModule` is disabled.
        """
        if not self.env.is_component_enabled(DashboardModule):
            return DashboardModule(self.env).get_templates_dirs()

    # Request modifiers

    def _modify_search_data(self, req, template, data, content_type, is_active):
        """Insert breadcumbs and context navigation items in search web UI
        """
        if is_active:
            # Insert query string in search box (see bloodhound_theme.html)
            req.search_query = data.get('query')
            # Context nav
            prevnext_nav(req, _('Previous'), _('Next'))
        # Breadcrumbs nav
        data['resourcepath_template'] = 'bh_path_search.html'

    def _modify_wiki_page_path(self, req, template, data, content_type,
                               is_active):
        """Override wiki breadcrumbs nav items
        """
        if is_active:
            data['resourcepath_template'] = 'bh_path_wikipage.html'

    def _modify_roadmap_page(self, req, template, data, content_type,
                             is_active):
        """Insert roadmap.css + products breadcrumb
        """
        add_stylesheet(req, 'dashboard/css/roadmap.css')
        self._add_products_general_breadcrumb(req, template, data,
                                              content_type, is_active)
        data['milestone_list'] = [m.name for m in Milestone.select(self.env)]
        req.chrome['ctxtnav'] = []

    def _modify_ticket(self, req, template, data, content_type, is_active):
        """Ticket modifications
        """
        self._modify_resource_breadcrumb(req, template, data, content_type,
                                         is_active)

        #add a creation event to the changelog if the ticket exists
        ticket = data['ticket']
        if ticket.exists:
            data['changes'] = [{'comment': '',
                                'author': ticket['reporter'],
                                'fields': {u'reported': {'label': u'Reported'},
                                           },
                                'permanent': 1,
                                'cnum': 0,
                                'date': ticket['time'],
                                },
                               ] + data['changes']
        #and set default order
        if not req.session.get('ticket_comments_order'):
            req.session['ticket_comments_order'] = 'newest'

    def _modify_resource_breadcrumb(self, req, template, data, content_type,
                                    is_active):
        """Provides logic for breadcrumb resource permissions
        """
        if data and ('ticket' in data.keys()) and data['ticket'].exists:
            data['resourcepath_template'] = 'bh_path_ticket.html'
            # determine path permissions
            for resname, permname in [('milestone', 'MILESTONE_VIEW'),
                                      ('product', 'PRODUCT_VIEW')]:
                res = Resource(resname, data['ticket'][resname])
                data['path_show_' + resname] = permname in req.perm(res)

            # add milestone list + current milestone to the breadcrumb
            data['milestone_list'] = [m.name
                                      for m in Milestone.select(self.env)]
            mname = data['ticket']['milestone']
            if mname:
                data['milestone'] = Milestone(self.env, mname)

    def _modify_admin_breadcrumb(self, req, template, data, content_type, is_active):
        # override 'normal' product list with the admin one

        def admin_url(prefix):
            env = ProductEnvironment.lookup_env(self.env, prefix)
            href = ProductEnvironment.resolve_href(env, self.env)
            return href.admin()

        global_settings = (None, _('(Global settings)'), admin_url(None))

        data['admin_product_list'] = [global_settings] + \
            ProductModule.get_product_list(self.env, req, admin_url)

        if isinstance(req.perm.env, ProductEnvironment):
            product = req.perm.env.product
            data['admin_current_product'] = \
                (product.prefix, product.name,
                 req.href.products(product.prefix, 'admin'))
        else:
            data['admin_current_product'] = global_settings
        data['resourcepath_template'] = 'bh_path_general.html'

    def _modify_browser(self, req, template, data, content_type, is_active):
        """Locate path to file in breadcrumbs area rather than title.
        Add browser-specific CSS.
        """
        data.update({
            'resourcepath_template': 'bh_path_links.html',
            'path_depth_limit': 2
        })
        add_stylesheet(req, 'theme/css/browser.css')

    def _add_products_general_breadcrumb(self, req, template, data,
                                         content_type, is_active):
        if isinstance(req.perm.env, ProductEnvironment):
            data['resourcepath_template'] = 'bh_path_general.html'

    def _modify_product_list(self, req, template, data, content_type,
                             is_active):
        """Transform products list into media list by adding
        configured product icon as well as further navigation items.
        """
        products = data.pop('products')
        context = data['context']
        with self.env.db_query as db:
            icons = db.execute("""
                SELECT product, value FROM bloodhound_productconfig
                WHERE product IN (%s) AND section='project' AND
                option='icon'""" % ', '.join(["%s"] * len(products)),
                tuple(p.prefix for p in products))
        icons = dict(icons)
        data['thumbsize'] = 64
        # FIXME: Gray icon for missing products
        no_thumbnail = req.href('chrome/theme/img/bh.ico')
        product_ctx = lambda item: context.child(item.resource)

        def product_media_data(icons, product):
            return dict(href=product.href(),
                        thumb=icons.get(product.prefix, no_thumbnail),
                        title=product.name,
                        description=format_to_html(self.env,
                                                   product_ctx(product),
                                                   product.description),
                        links={'extras': (([{'href': req.href.products(
                                                product.prefix, action='edit'),
                                             'title': _('Edit product %(prefix)s',
                                                        prefix=product.prefix),
                                             'icon': tag.i(class_='icon-edit'),
                                             'label': _('Edit')},]
                                           if 'PRODUCT_MODIFY' in req.perm
                                           else []) +
                                          [{'href': product.href(),
                                            'title': _('Home page'),
                                            'icon': tag.i(class_='icon-home'),
                                            'label': _('Home')},
                                           {'href': product.href.dashboard(),
                                            'title': _('Tickets dashboard'),
                                            'icon': tag.i(class_='icon-tasks'),
                                            'label': _('Tickets')},
                                           {'href': product.href.wiki(),
                                            'title': _('Wiki'),
                                            'icon': tag.i(class_='icon-book'),
                                            'label': _('Wiki')}]),
                               'main': {'href': product.href(),
                                        'title': None,
                                        'icon': tag.i(class_='icon-chevron-right'),
                                        'label': _('Browse')}})

        data['products'] = [product_media_data(icons, product)
                            for product in products]

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return

    def get_navigation_items(self, req):
        if 'BROWSER_VIEW' in req.perm and 'VERSIONCONTROL_ADMIN' in req.perm:
            bm = self.env[BrowserModule]
            if bm and not list(bm.get_navigation_items(req)):
                yield ('mainnav', 'browser',
                       tag.a(_('Source'),
                             href=req.href.wiki('TracRepositoryAdmin')))


class QuickCreateTicketDialog(Component):
    implements(IRequestFilter, IRequestHandler)

    qct_fields = ListOption('ticket', 'quick_create_fields',
                            'product, version, type',
        doc="""Multiple selection fields displayed in create ticket menu""",
                            doc_domain='bhtheme')

    def __init__(self, *args, **kwargs):
        import pkg_resources
        locale_dir = pkg_resources.resource_filename(__name__, 'locale')
        add_domain(self.env.path, locale_dir)
        super(QuickCreateTicketDialog, self).__init__(*args, **kwargs)

    # IRequestFilter(Interface):

    def pre_process_request(self, req, handler):
        """Nothing to do.
        """
        return handler

    def post_process_request(self, req, template, data, content_type):
        """Append necessary ticket data
        """
        try:
            tm = self._get_ticket_module()
        except TracError:
            # no ticket module so no create ticket button
            return template, data, content_type

        if (template, data, content_type) != (None,) * 3:  # TODO: Check !
            if data is None:
                data = {}
            dum_req = dummy_request(self.env)
            dum_req.perm = req.perm
            ticket = Ticket(self.env)
            tm._populate(dum_req, ticket, False)
            all_fields = dict([f['name'], f]
                              for f in tm._prepare_fields(dum_req, ticket)
                              if f['type'] == 'select')

            product_field = all_fields.get('product')
            if product_field:
                # When at product scope, set the default selection to the
                # product at current scope. When at global scope the default
                # selection is determined by [ticket] default_product
                if self.env.product and \
                        self.env.product.prefix in product_field['options']:
                    product_field['value'] = self.env.product.prefix
                # Transform the options field to dictionary of product
                # attributes and filter out products for which user doesn't
                #  have TICKET_CREATE permission
                product_field['options'] = [
                    dict(value=p,
                         new_ticket_url=dum_req.href.products(p, 'newticket'),
                         description=ProductEnvironment.lookup_env(self.env, p)
                                                       .product.name
                    )
                for p in product_field['options']
                    if req.perm.has_permission('TICKET_CREATE',
                                               Neighborhood('product', p)
                                               .child(None, None))]
            else:
                msg = _("Missing ticket field '%(field)s'.", field='product')
                if ProductTicketModule is not None and \
                        self.env[ProductTicketModule] is not None:
                    # Display warning alert to users
                    add_warning(req, msg)
                else:
                    # Include message in logs since this might be a failure
                    self.log.warning(msg)
            data['qct'] = {
                'fields': [all_fields[k] for k in self.qct_fields
                           if k in all_fields],
                'hidden_fields': [all_fields[k] for k in all_fields.keys()
                                  if k not in self.qct_fields] }
        return template, data, content_type

    # IRequestHandler methods

    def match_request(self, req):
        """Handle requests sent to /qct
        """
        m = PRODUCT_RE.match(req.path_info)
        return req.path_info == '/qct' or \
            (m and m.group('pathinfo').strip('/') == 'qct')

    def process_request(self, req):
        """Forward new ticket request to `trac.ticket.web_ui.TicketModule`
        but return plain text suitable for AJAX requests.
        """
        try:
            tm = self._get_ticket_module()
            req.perm.require('TICKET_CREATE')
            summary = req.args.pop('field_summary', '')
            desc = ""
            attrs = dict([k[6:], v] for k, v in req.args.iteritems()
                         if k.startswith('field_'))
            product, tid = self.create(req, summary, desc, attrs, True)
        except Exception, exc:
            self.log.exception("BH: Quick create ticket failed %s" % (exc,))
            req.send(str(exc), 'plain/text', 500)
        else:
            tres = Neighborhood('product', product)('ticket', tid)
            href = req.href
            req.send(to_json({'product': product, 'id': tid,
                              'url': get_resource_url(self.env, tres, href)}),
                     'application/json')

    def _get_ticket_module(self):
        ptm = None
        if ProductTicketModule is not None:
            ptm = self.env[ProductTicketModule]
        tm = self.env[TicketModule]
        if not (tm is None) ^ (ptm is None):
            raise TracError('Unable to load TicketModule (disabled)?')
        if tm is None:
            tm = ptm
        return tm

    # Public API
    def create(self, req, summary, description, attributes={}, notify=False):
        """ Create a new ticket, returning the ticket ID.

        PS: Borrowed from XmlRpcPlugin.
        """
        if 'product' in attributes:
            env = self.env.parent or self.env
            if attributes['product']:
                env = ProductEnvironment(env, attributes['product'])
        else:
            env = self.env

        t = Ticket(env)
        t['summary'] = summary
        t['description'] = description
        t['reporter'] = req.authname
        for k, v in attributes.iteritems():
            t[k] = v
        t['status'] = 'new'
        t['resolution'] = ''
        t.insert()

        if notify:
            try:
                tn = TicketNotifyEmail(env)
                tn.notify(t, newticket=True)
            except Exception, e:
                self.log.exception("Failure sending notification on creation "
                                   "of ticket #%s: %s" % (t.id, e))
        return t['product'], t.id

from pkg_resources import get_distribution
application_version = get_distribution('BloodhoundTheme').version

########NEW FILE########
__FILENAME__ = translation
# -*- coding: UTF-8 -*-

#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.


r"""Project dashboard for Apache(TM) Bloodhound

Translation functions and classes.
"""

from trac.util.translation import domain_functions

#------------------------------------------------------
#    Internationalization
#------------------------------------------------------

_, ngettext, tag_, tagn_, gettext, N_, add_domain = \
   domain_functions('bhtheme', ('_', 'ngettext', 'tag_', 'tagn_',
                                'gettext', 'N_', 'add_domain'))

########NEW FILE########
__FILENAME__ = createdigest
#!/usr/bin/env python
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Simple htdigest file creation.
Saves the need for an installed htdigest program"""

import os
import shutil
import sys
from tempfile import mkstemp
from optparse import OptionParser
from hashlib import md5
from getpass import getpass

DEFAULT_USER = 'admin'
DEFAULT_REALM = 'default'
DEFAULT_FILE = 'default.htdigest'

def htdigest_create(filename, user, realm, password, path=''):
    """Create an htdigest file by adding the user to the file
    Just in case an htdigest file already exists, this function will copy the
    data line by line into a temporary file, commenting out any lines that match
    the user and realm data. The new entry is then appended before the temporary
    copy is moved back to the original location"""

    user_realm = ':'.join((user, realm))
    digest = md5(':'.join((user_realm, password))).hexdigest()
    data = ':'.join((user_realm, digest)) + '\n'

    filepath = os.path.join(path, filename)
    temp, tempfilepath = mkstemp()
    with open(tempfilepath,'w') as tempdigestfile:
        if os.path.exists(filepath):
            with open(filepath) as origdigestfile:
                for line in origdigestfile:
                    if line.strip().startswith(user_realm + ':'):
                        tempdigestfile.write('#' + line)
                    else:
                        tempdigestfile.write(line)
        tempdigestfile.write(data)
    os.close(temp)
    if os.path.exists(filepath):
        os.remove(filepath)
    shutil.move(tempfilepath, filepath)

def main():
    """Parse arguments and run the  function"""

    parser = OptionParser()
    parser.add_option('-f', '--digestfile', dest='digestfile',
                      help='htdigest filename')
    parser.add_option('-r', '--realm', dest='realm',
                      help='authentication realm')
    parser.add_option('-u', '--user', dest='user',
                      help='user name')
    parser.add_option('-p', '--password', dest='password',
                      help='password for USER')

    (opts, args) = parser.parse_args()

    if not opts.digestfile:
        input_file = raw_input('Enter the file [%s]: ' % DEFAULT_FILE)
        opts.digestfile = input_file if input_file else DEFAULT_FILE
    path, filename = os.path.split(opts.digestfile)

    if not opts.user:
        input_user = raw_input('Enter the user [%s]: ' % DEFAULT_USER)
        opts.user = input_user if input_user else DEFAULT_USER

    if not opts.password:
        attempts = 3
        for attempt in range(attempts):
            if attempt > 0:
                print "Passwords empty or did not match. Please try again",
                print "(attempt %d/%d)""" % (attempt+1, attempts)
            password1 = getpass('Enter a new password for "%s": ' % opts.user)
            password2 = getpass('Please reenter the password: ')
            if password1 and password1 == password2:
                opts.password = password1
                break
        if not opts.password:
            print "Passwords did not match. Quitting."
            sys.exit(1)

    if not opts.realm:
        input_realm = raw_input('Enter the auth realm [%s]: ' % DEFAULT_REALM)
        opts.realm = input_realm if input_realm else DEFAULT_REALM

    htdigest_create(filename, opts.user, opts.realm, opts.password, path)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = tests
# -*- coding: utf-8 -*-
#
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

"""Tests for bloodhound_setup.py"""

import unittest
import shutil
import os
from tempfile import mkdtemp, NamedTemporaryFile
from bloodhound_setup import backupfile, BloodhoundSetup
from functools import partial

class BackupfileTest(unittest.TestCase):
    """Unit tests for backupfile routine"""
    def setUp(self):
        self.tempdir = mkdtemp()
        self.original = NamedTemporaryFile(dir=self.tempdir)

    def tearDown(self):
        self.original.close()
        shutil.rmtree(self.tempdir)

    def test_backup_creates_new_file(self):
        """Checks that a new file is created"""
        orig = self.original.name
        new = backupfile(orig)
        self.assertNotEqual(orig, new)
        self.assert_(os.path.exists(orig))
        self.assert_(os.path.exists(new))

    def test_multiple_backup_creates_new_files(self):
        """Checks that, for a small finite number of backups, multiple
        backups do not overwrite old backups. The limit is effectively 65"""
        orig = self.original.name
        backups = [backupfile(orig) for i in range(65)]
        unique_set = set([orig, ] + backups)
        self.assertEqual(len(unique_set), 66)

class BloodhoundSetupTest(unittest.TestCase):
    def setUp(self):
        self.tempdir = mkdtemp()
        self.bhs = BloodhoundSetup({})
        self.basedata =  {'section': {'option1': 'option1value',
                              'option2': 'option2value',},}

    def tearDown(self):
        shutil.rmtree(self.tempdir)

    def test_db_str_no_options(self):
        """Checks that giving no options at all has defaults enough to create
        a sqlite db string"""
        self.assertEqual(self.bhs._generate_db_str({}), 'sqlite:' +
                         os.path.join('db', 'bloodhound.db'))

    def test_db_str_provided_db_string(self):
        """Checks that if a dbstring is provided it will not be respected above
        other options"""
        dbstr = 'sillyexample'
        options = {'dbstring': dbstr,}
        self.assertEqual(self.bhs._generate_db_str(options), dbstr)

    def test_writeconfig_create_basic_config(self):
        filepath = os.path.join(self.tempdir, 'basic.ini')
        data =  [self.basedata]
        self.bhs.writeconfig(filepath, data)
        self.assert_(os.path.exists(filepath))
        #check the file
        with file(filepath) as f:
            fdata = f.read()
            self.assertIn('option1value', fdata)

    def test_writeconfig_update_config(self):
        """Checks that writing a new config with non-overlapping values updates
        an existing file"""
        filepath = os.path.join(self.tempdir, 'basic.ini')
        data =  [self.basedata]
        self.bhs.writeconfig(filepath, data)
        newdata = [{'section': {'option3': 'option3value',},}]
        self.bhs.writeconfig(filepath, newdata)
        #check the file
        with file(filepath) as f:
            fdata = f.read()
            self.assertIn('option3value', fdata)

    def test_writeconfig_update_config_overwrite_values(self):
        """Checks that writing a new config with non-overlapping values updates
        an existing file"""
        filepath = os.path.join(self.tempdir, 'basic.ini')
        data =  [self.basedata]
        self.bhs.writeconfig(filepath, data)
        newdata = [{'section': {'option2': 'newopt2value',},}]
        self.bhs.writeconfig(filepath, newdata)
        with file(filepath) as f:
            fdata = f.read()
            self.assertIn('newopt2value', fdata)
            self.assertNotIn('option2value', fdata)

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = bugzilla2trac
#!/usr/bin/env python

"""
Import a Bugzilla items into a Trac database.

Requires:  Trac 0.9b1 from http://trac.edgewall.org/
           Python 2.3 from http://www.python.org/
           MySQL >= 3.23 from http://www.mysql.org/
           or PostGreSQL 8.4 from http://www.postgresql.org/
           or SQLite 3 from http://www.sqlite.org/

Thanks:    Mark Rowe <mrowe@bluewire.net.nz>
            for original TracDatabase class

Copyright 2004, Dmitry Yusupov <dmitry_yus@yahoo.com>

Many enhancements, Bill Soudan <bill@soudan.net>
Other enhancements, Florent Guillaume <fg@nuxeo.com>
Reworked, Jeroen Ruigrok van der Werven <asmodai@in-nomine.org>
Jeff Moreland <hou5e@hotmail.com>

$Id: bugzilla2trac.py 11490 2013-01-13 15:18:06Z rblank $
"""

from __future__ import with_statement

import re

###
### Conversion Settings -- edit these before running if desired
###

# Bugzilla version.  You can find this in Bugzilla's globals.pl file.
#
# Currently, the following bugzilla versions are known to work:
#   2.11 (2110), 2.16.5 (2165), 2.16.7 (2167),  2.18.3 (2183), 2.19.1 (2191),
#   2.23.3 (2233), 3.04.4 (3044)
#
# If you run this script on a version not listed here and it is successful,
# please file a ticket at http://trac.edgewall.org
#
BZ_VERSION = 3044

# MySQL connection parameters for the Bugzilla database.  These can also
# be specified on the command line.
BZ_DB = ""
BZ_HOST = ""
BZ_USER = ""
BZ_PASSWORD = ""

# Path to the Trac environment.
TRAC_ENV = "/usr/local/trac"

# If true, all existing Trac tickets and attachments will be removed
# prior to import.
TRAC_CLEAN = True

# Enclose imported ticket description and comments in a {{{ }}}
# preformat block?  This formats the text in a fixed-point font.
PREFORMAT_COMMENTS = False

# Replace bug numbers in comments with #xyz
REPLACE_BUG_NO = False

# Severities
SEVERITIES = [
    ("blocker",  "1"),
    ("critical", "2"),
    ("major",    "3"),
    ("normal",   "4"),
    ("minor",    "5"),
    ("trivial",  "6")
]

# Priorities
# If using the default Bugzilla priorities of P1 - P5, do not change anything
# here.
# If you have other priorities defined please change the P1 - P5 mapping to
# the order you want.  You can also collapse multiple priorities on bugzilla's
# side into the same priority on Trac's side, simply adjust PRIORITIES_MAP.
PRIORITIES = [
    ("highest", "1"),
    ("high",    "2"),
    ("normal",  "3"),
    ("low",     "4"),
    ("lowest",  "5")
]

# Bugzilla: Trac
# NOTE: Use lowercase.
PRIORITIES_MAP = {
    "p1": "highest",
    "p2": "high",
    "p3": "normal",
    "p4": "low",
    "p5": "lowest"
}

# By default, all bugs are imported from Bugzilla.  If you add a list
# of products here, only bugs from those products will be imported.
PRODUCTS = []
# These Bugzilla products will be ignored during import.
IGNORE_PRODUCTS = []

# These milestones are ignored
IGNORE_MILESTONES = ["---"]

# Don't import user names and passwords into htpassword if
# user is disabled in bugzilla? (i.e. profiles.DisabledText<>'')
IGNORE_DISABLED_USERS = True

# These logins are converted to these user ids
LOGIN_MAP = {
    #'some.user@example.com': 'someuser',
}

# These emails are removed from CC list
IGNORE_CC = [
    #'loser@example.com',
]

# The 'component' field in Trac can come either from the Product or
# or from the Component field of Bugzilla. COMPONENTS_FROM_PRODUCTS
# switches the behavior.
# If COMPONENTS_FROM_PRODUCTS is True:
# - Bugzilla Product -> Trac Component
# - Bugzilla Component -> Trac Keyword
# IF COMPONENTS_FROM_PRODUCTS is False:
# - Bugzilla Product -> Trac Keyword
# - Bugzilla Component -> Trac Component
COMPONENTS_FROM_PRODUCTS = False

# If COMPONENTS_FROM_PRODUCTS is True, the default owner for each
# Trac component is inferred from a default Bugzilla component.
DEFAULT_COMPONENTS = ["default", "misc", "main"]

# This mapping can assign keywords in the ticket entry to represent
# products or components (depending on COMPONENTS_FROM_PRODUCTS).
# The keyword will be ignored if empty.
KEYWORDS_MAPPING = {
    #'Bugzilla_product_or_component': 'Keyword',
    "default": "",
    "misc": "",
    }

# If this is True, products or components are all set as keywords
# even if not mentionned in KEYWORDS_MAPPING.
MAP_ALL_KEYWORDS = True

# Custom field mappings
CUSTOMFIELD_MAP = {
    #'Bugzilla_field_name': 'Trac_customfield_name',
    #'op_sys': 'os',
    #'cf_featurewantedby': 'wanted_by',
    #'product': 'product'
}

# Bug comments that should not be imported.  Each entry in list should
# be a regular expression.
IGNORE_COMMENTS = [
   "^Created an attachment \(id="
]

###########################################################################
### You probably don't need to change any configuration past this line. ###
###########################################################################

# Bugzilla status to Trac status translation map.
#
# NOTE: bug activity is translated as well, which may cause bug
# activity to be deleted (e.g. resolved -> closed in Bugzilla
# would translate into closed -> closed in Trac, so we just ignore the
# change).
#
# There is some special magic for open in the code:  if there is no
# Bugzilla owner, open is mapped to 'new' instead.
STATUS_TRANSLATE = {
  "unconfirmed": "new",
  "open":        "assigned",
  "resolved":    "closed",
  "verified":    "closed",
  "released":    "closed"
}

# Translate Bugzilla statuses into Trac keywords.  This provides a way
# to retain the Bugzilla statuses in Trac.  e.g. when a bug is marked
# 'verified' in Bugzilla it will be assigned a VERIFIED keyword.
STATUS_KEYWORDS = {
  "verified": "VERIFIED",
  "released": "RELEASED"
}

# Some fields in Bugzilla do not have equivalents in Trac.  Changes in
# fields listed here will not be imported into the ticket change history,
# otherwise you'd see changes for fields that don't exist in Trac.
IGNORED_ACTIVITY_FIELDS = ["everconfirmed"]

# Regular expression and its replacement
# this expression will update references to bugs 1 - 99999 that
# have the form "bug 1" or "bug #1"
BUG_NO_RE = re.compile(r"\b(bug #?)([0-9]{1,5})\b", re.I)
BUG_NO_REPL = r"#\2"

###
### Script begins here
###

import os
import sys
import string
import StringIO

import MySQLdb
import MySQLdb.cursors
from trac.attachment import Attachment
from trac.env import Environment

if not hasattr(sys, 'setdefaultencoding'):
    reload(sys)

sys.setdefaultencoding('latin1')

# simulated Attachment class for trac.add
#class Attachment:
#    def __init__(self, name, data):
#        self.filename = name
#        self.file = StringIO.StringIO(data.tostring())

# simple field translation mapping.  if string not in
# mapping, just return string, otherwise return value
class FieldTranslator(dict):
    def __getitem__(self, item):
        if not dict.has_key(self, item):
            return item

        return dict.__getitem__(self, item)

statusXlator = FieldTranslator(STATUS_TRANSLATE)

class TracDatabase(object):
    def __init__(self, path):
        self.env = Environment(path)
        self.loginNameCache = {}
        self.fieldNameCache = {}
        from trac.db.api import DatabaseManager
	self.using_postgres = \
                DatabaseManager(self.env).connection_uri.startswith("postgres:")

    def hasTickets(self):
        return int(self.env.db_query("SELECT count(*) FROM ticket")[0][0] > 0)

    def assertNoTickets(self):
        if self.hasTickets():
            raise Exception("Will not modify database with existing tickets!")

    def setSeverityList(self, s):
        """Remove all severities, set them to `s`"""
        self.assertNoTickets()

        with self.env.db_transaction as db:
            db("DELETE FROM enum WHERE type='severity'")
            for value, i in s:
                print "  inserting severity '%s' - '%s'" % (value, i)
                db("""INSERT INTO enum (type, name, value)
                      VALUES (%s, %s, %s)""",
                   ("severity", value, i))

    def setPriorityList(self, s):
        """Remove all priorities, set them to `s`"""
        self.assertNoTickets()

        with self.env.db_transaction as db:
            db("DELETE FROM enum WHERE type='priority'")
            for value, i in s:
                print "  inserting priority '%s' - '%s'" % (value, i)
                db("INSERT INTO enum (type, name, value) VALUES (%s, %s, %s)",
                   ("priority", value, i))

    def setComponentList(self, l, key):
        """Remove all components, set them to `l`"""
        self.assertNoTickets()

        with self.env.db_transaction as db:
            db("DELETE FROM component")
            for comp in l:
                print "  inserting component '%s', owner '%s'" % \
                                (comp[key], comp['owner'])
                db("INSERT INTO component (name, owner) VALUES (%s, %s)",
                   (comp[key], comp['owner']))

    def setVersionList(self, v, key):
        """Remove all versions, set them to `v`"""
        self.assertNoTickets()

        with self.env.db_transaction as db:
            db("DELETE FROM version")
            for vers in v:
                print "  inserting version '%s'" % (vers[key])
                db("INSERT INTO version (name) VALUES (%s)",
                   (vers[key],))

    def setMilestoneList(self, m, key):
        """Remove all milestones, set them to `m`"""
        self.assertNoTickets()

        with self.env.db_transaction as db:
            db("DELETE FROM milestone")
            for ms in m:
                milestone = ms[key]
                print "  inserting milestone '%s'" % (milestone)
                db("INSERT INTO milestone (name) VALUES (%s)",
                   (milestone,))

    def addTicket(self, id, time, changetime, component, severity, priority,
                  owner, reporter, cc, version, milestone, status, resolution,
                  summary, description, keywords, customfields):

        desc = description
        type = "defect"

        if SEVERITIES:
            if severity.lower() == "enhancement":
                severity = "minor"
                type = "enhancement"

        else:
            if priority.lower() == "enhancement":
                priority = "minor"
                type = "enhancement"

        if PREFORMAT_COMMENTS:
            desc = '{{{\n%s\n}}}' % desc

        if REPLACE_BUG_NO:
            if BUG_NO_RE.search(desc):
                desc = re.sub(BUG_NO_RE, BUG_NO_REPL, desc)

        if PRIORITIES_MAP.has_key(priority):
            priority = PRIORITIES_MAP[priority]

        print "  inserting ticket %s -- %s" % (id, summary)

        with self.env.db_transaction as db:
            db("""INSERT INTO ticket (id, type, time, changetime, component,
                                      severity, priority, owner, reporter, cc,
                                      version, milestone, status, resolution,
                                      summary, description, keywords)
                  VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                          %s, %s, %s, %s)
                  """, (id, type, datetime2epoch(time),
                        datetime2epoch(changetime), component, severity,
                        priority, owner, reporter, cc, version, milestone,
                        status.lower(), resolution, summary, desc, keywords))

        if self.using_postgres:
            with self.env.db_transaction as db:
                c = db.cursor()
                c.execute("""
                    SELECT SETVAL('ticket_id_seq', MAX(id)) FROM ticket;
                    SELECT SETVAL('report_id_seq', MAX(id)) FROM report""")
                ticket_id = db.get_last_id(c, 'ticket')

        # add all custom fields to ticket
        for name, value in customfields.iteritems():
            self.addTicketCustomField(ticket_id, name, value)

        return ticket_id

    def addTicketCustomField(self, ticket_id, field_name, field_value):
        if field_value == None:
            return
        self.env.db_transaction("""
            INSERT INTO ticket_custom (ticket, name, value) VALUES (%s, %s, %s)
            """, (ticket_id, field_name, field_value))

    def addTicketComment(self, ticket, time, author, value):
        comment = value

        if PREFORMAT_COMMENTS:
          comment = '{{{\n%s\n}}}' % comment

        if REPLACE_BUG_NO:
            if BUG_NO_RE.search(comment):
                comment = re.sub(BUG_NO_RE, BUG_NO_REPL, comment)

        with self.env.db_transaction as db:
            db("""INSERT INTO ticket_change (ticket, time, author, field,
                                             oldvalue, newvalue)
                  VALUES (%s, %s, %s, %s, %s, %s)
                  """, (ticket, datetime2epoch(time), author, 'comment', '',
                        comment))

    def addTicketChange(self, ticket, time, author, field, oldvalue, newvalue):

        if field == "owner":
            if LOGIN_MAP.has_key(oldvalue):
                oldvalue = LOGIN_MAP[oldvalue]
            if LOGIN_MAP.has_key(newvalue):
                newvalue = LOGIN_MAP[newvalue]

        if field == "priority":
            if PRIORITIES_MAP.has_key(oldvalue.lower()):
                oldvalue = PRIORITIES_MAP[oldvalue.lower()]
            if PRIORITIES_MAP.has_key(newvalue.lower()):
                newvalue = PRIORITIES_MAP[newvalue.lower()]

        # Doesn't make sense if we go from highest -> highest, for example.
        if oldvalue == newvalue:
            return

        with self.env.db_transaction as db:
            db("""INSERT INTO ticket_change (ticket, time, author, field,
                                             oldvalue, newvalue)
                  VALUES (%s, %s, %s, %s, %s, %s)
                  """, (ticket, datetime2epoch(time), author, field,
                        oldvalue, newvalue))

    def addAttachment(self, author, a):
        if a['filename'] != '':
            description = a['description']
            id = a['bug_id']
            filename = a['filename']
            filedata = StringIO.StringIO(a['thedata'])
            filesize = len(filedata.getvalue())
            time = a['creation_ts']
            print "    ->inserting attachment '%s' for ticket %s -- %s" % \
                    (filename, id, description)
            attachment = Attachment(self.env, 'ticket', id)
            attachment.author = author
            attachment.description = description
            attachment.insert(filename, filedata, filesize,
                              datetime2epoch(time))
            del attachment

    def getLoginName(self, cursor, userid):
        if userid not in self.loginNameCache:
            cursor.execute("SELECT * FROM profiles WHERE userid = %s", (userid))
            loginName = cursor.fetchall()

            if loginName:
                loginName = loginName[0]['login_name']
            else:
                print """WARNING: unknown bugzilla userid %d, recording as
                         anonymous""" % (userid)
                loginName = "anonymous"

            loginName = LOGIN_MAP.get(loginName, loginName)

            self.loginNameCache[userid] = loginName

        return self.loginNameCache[userid]

    def getFieldName(self, cursor, fieldid):
        if fieldid not in self.fieldNameCache:
            # fielddefs.fieldid got changed to fielddefs.id in Bugzilla
            # 2.23.3.
            if BZ_VERSION >= 2233:
                cursor.execute("SELECT * FROM fielddefs WHERE id = %s",
                               (fieldid))
            else:
                cursor.execute("SELECT * FROM fielddefs WHERE fieldid = %s",
                               (fieldid))
            fieldName = cursor.fetchall()

            if fieldName:
                fieldName = fieldName[0]['name'].lower()
            else:
                print "WARNING: unknown bugzilla fieldid %d, \
                                recording as unknown" % (userid)
                fieldName = "unknown"

            self.fieldNameCache[fieldid] = fieldName

        return self.fieldNameCache[fieldid]

def makeWhereClause(fieldName, values, negative=False):
    if not values:
        return ''
    if negative:
        connector, op = ' AND ', '!='
    else:
        connector, op = ' OR ', '='
    clause = connector.join(["%s %s '%s'" % (fieldName, op, value)
                             for value in values])
    return ' (' + clause + ')'

def convert(_db, _host, _user, _password, _env, _force):
    activityFields = FieldTranslator()

    # account for older versions of bugzilla
    print "Using Bugzilla v%s schema." % BZ_VERSION
    if BZ_VERSION == 2110:
        activityFields['removed'] = "oldvalue"
        activityFields['added'] = "newvalue"

    # init Bugzilla environment
    print "Bugzilla MySQL('%s':'%s':'%s':'%s'): connecting..." % \
            (_db, _host, _user, ("*" * len(_password)))
    mysql_con = MySQLdb.connect(host=_host,
                user=_user, passwd=_password, db=_db, compress=1,
                cursorclass=MySQLdb.cursors.DictCursor,
                charset='utf8')
    mysql_cur = mysql_con.cursor()

    # init Trac environment
    print "Trac SQLite('%s'): connecting..." % (_env)
    trac = TracDatabase(_env)

    # force mode...
    if _force == 1:
        print "\nCleaning all tickets..."
        with trac.env.db_transaction as db:
            db("DELETE FROM ticket_change")
            db("DELETE FROM ticket")
            db("DELETE FROM ticket_custom")
            db("DELETE FROM attachment")
        attachments_dir = os.path.join(os.path.normpath(trac.env.path),
                                       "attachments")
        # Straight from the Python documentation.
        for root, dirs, files in os.walk(attachments_dir, topdown=False):
            for name in files:
                os.remove(os.path.join(root, name))
            for name in dirs:
                os.rmdir(os.path.join(root, name))
        if not os.stat(attachments_dir):
            os.mkdir(attachments_dir)
        print "All tickets cleaned..."


    print "\n0. Filtering products..."
    if BZ_VERSION >= 2180:
        mysql_cur.execute("SELECT name FROM products")
    else:
        mysql_cur.execute("SELECT product AS name FROM products")
    products = []
    for line in mysql_cur.fetchall():
        product = line['name']
        if PRODUCTS and product not in PRODUCTS:
            continue
        if product in IGNORE_PRODUCTS:
            continue
        products.append(product)
    PRODUCTS[:] = products
    print "  Using products", " ".join(PRODUCTS)

    print "\n1. Import severities..."
    trac.setSeverityList(SEVERITIES)

    print "\n2. Import components..."
    if not COMPONENTS_FROM_PRODUCTS:
        if BZ_VERSION >= 2180:
            sql = """SELECT DISTINCT c.name AS name, c.initialowner AS owner
                               FROM components AS c, products AS p
                               WHERE c.product_id = p.id AND"""
            sql += makeWhereClause('p.name', PRODUCTS)
        else:
            sql = "SELECT value AS name, initialowner AS owner FROM components"
            sql += " WHERE" + makeWhereClause('program', PRODUCTS)
        mysql_cur.execute(sql)
        components = mysql_cur.fetchall()
        for component in components:
            component['owner'] = trac.getLoginName(mysql_cur,
                                                   component['owner'])
        trac.setComponentList(components, 'name')
    else:
        if BZ_VERSION >= 2180:
            sql = ("SELECT p.name AS product, c.name AS comp, "
                   " c.initialowner AS owner "
                   "FROM components c, products p "
                   "WHERE c.product_id = p.id AND" +
                   makeWhereClause('p.name', PRODUCTS))
        else:
            sql = ("SELECT program AS product, value AS comp, "
                   " initialowner AS owner "
                   "FROM components WHERE" +
                   makeWhereClause('program', PRODUCTS))
        mysql_cur.execute(sql)
        lines = mysql_cur.fetchall()
        all_components = {} # product -> components
        all_owners = {} # product, component -> owner
        for line in lines:
            product = line['product']
            comp = line['comp']
            owner = line['owner']
            all_components.setdefault(product, []).append(comp)
            all_owners[(product, comp)] = owner
        component_list = []
        for product, components in all_components.items():
            # find best default owner
            default = None
            for comp in DEFAULT_COMPONENTS:
                if comp in components:
                    default = comp
                    break
            if default is None:
                default = components[0]
            owner = all_owners[(product, default)]
            owner_name = trac.getLoginName(mysql_cur, owner)
            component_list.append({'product': product, 'owner': owner_name})
        trac.setComponentList(component_list, 'product')

    print "\n3. Import priorities..."
    trac.setPriorityList(PRIORITIES)

    print "\n4. Import versions..."
    if BZ_VERSION >= 2180:
        sql = """SELECT DISTINCTROW v.value AS value
                               FROM products p, versions v"""
        sql += " WHERE v.product_id = p.id AND"
        sql += makeWhereClause('p.name', PRODUCTS)
    else:
        sql = "SELECT DISTINCTROW value FROM versions"
        sql += " WHERE" + makeWhereClause('program', PRODUCTS)
    mysql_cur.execute(sql)
    versions = mysql_cur.fetchall()
    trac.setVersionList(versions, 'value')

    print "\n5. Import milestones..."
    sql = "SELECT DISTINCT value FROM milestones"
    sql += " WHERE" + makeWhereClause('value', IGNORE_MILESTONES, negative=True)
    mysql_cur.execute(sql)
    milestones = mysql_cur.fetchall()
    trac.setMilestoneList(milestones, 'value')

    print "\n6. Retrieving bugs..."
    if BZ_VERSION >= 2180:
        sql = """SELECT DISTINCT b.*, c.name AS component, p.name AS product
                            FROM bugs AS b, components AS c, products AS p """
        sql += " WHERE" + makeWhereClause('p.name', PRODUCTS)
        sql += " AND b.product_id = p.id"
        sql += " AND b.component_id = c.id"
        sql += " ORDER BY b.bug_id"
    else:
        sql = """SELECT DISTINCT b.*, c.value AS component, p.product AS product
                            FROM bugs AS b, components AS c, products AS p """
        sql += " WHERE" + makeWhereClause('p.product', PRODUCTS)
        sql += " AND b.product = p.product"
        sql += " AND b.component = c.value"
        sql += " ORDER BY b.bug_id"
    mysql_cur.execute(sql)
    bugs = mysql_cur.fetchall()


    print "\n7. Import bugs and bug activity..."
    for bug in bugs:

        bugid = bug['bug_id']

        ticket = {}
        keywords = []
        ticket['id'] = bugid
        ticket['time'] = bug['creation_ts']
        ticket['changetime'] = bug['delta_ts']
        if COMPONENTS_FROM_PRODUCTS:
            ticket['component'] = bug['product']
        else:
            ticket['component'] = bug['component']

        if SEVERITIES:
            ticket['severity'] = bug['bug_severity']
            ticket['priority'] = bug['priority'].lower()
        else:
            # use bugzilla severities as trac priorities, and ignore bugzilla
            # priorities
            ticket['severity'] = ''
            ticket['priority'] = bug['bug_severity']

        ticket['owner'] = trac.getLoginName(mysql_cur, bug['assigned_to'])
        ticket['reporter'] = trac.getLoginName(mysql_cur, bug['reporter'])

        # pack bugzilla fields into dictionary of trac custom field
        # names and values
        customfields = {}
        for bugfield, customfield in CUSTOMFIELD_MAP.iteritems():
            customfields[customfield] = bug[bugfield]
        ticket['customfields'] = customfields

        mysql_cur.execute("SELECT * FROM cc WHERE bug_id = %s", bugid)
        cc_records = mysql_cur.fetchall()
        cc_list = []
        for cc in cc_records:
            cc_list.append(trac.getLoginName(mysql_cur, cc['who']))
        cc_list = [cc for cc in cc_list if cc not in IGNORE_CC]
        ticket['cc'] = string.join(cc_list, ', ')

        ticket['version'] = bug['version']

        target_milestone = bug['target_milestone']
        if target_milestone in IGNORE_MILESTONES:
            target_milestone = ''
        ticket['milestone'] = target_milestone

        bug_status = bug['bug_status'].lower()
        ticket['status'] = statusXlator[bug_status]
        ticket['resolution'] = bug['resolution'].lower()

        # a bit of extra work to do open tickets
        if bug_status == 'open':
            if owner != '':
                ticket['status'] = 'assigned'
            else:
                ticket['status'] = 'new'

        ticket['summary'] = bug['short_desc']

        mysql_cur.execute("SELECT * FROM longdescs WHERE bug_id = %s" % bugid)
        longdescs = list(mysql_cur.fetchall())

        # check for empty 'longdescs[0]' field...
        if len(longdescs) == 0:
            ticket['description'] = ''
        else:
            ticket['description'] = longdescs[0]['thetext']
            del longdescs[0]

        for desc in longdescs:
            ignore = False
            for comment in IGNORE_COMMENTS:
                if re.match(comment, desc['thetext']):
                    ignore = True

            if ignore:
                    continue

            trac.addTicketComment(ticket=bugid,
                time = desc['bug_when'],
                author=trac.getLoginName(mysql_cur, desc['who']),
                value = desc['thetext'])

        mysql_cur.execute("""SELECT * FROM bugs_activity WHERE bug_id = %s
                             ORDER BY bug_when""" % bugid)
        bugs_activity = mysql_cur.fetchall()
        resolution = ''
        ticketChanges = []
        keywords = []
        for activity in bugs_activity:
            field_name = trac.getFieldName(mysql_cur, activity['fieldid']).lower()

            removed = activity[activityFields['removed']]
            added = activity[activityFields['added']]

            # statuses and resolutions are in lowercase in trac
            if field_name == "resolution" or field_name == "bug_status":
                removed = removed.lower()
                added = added.lower()

            # remember most recent resolution, we need this later
            if field_name == "resolution":
                resolution = added.lower()

            add_keywords = []
            remove_keywords = []

            # convert bugzilla field names...
            if field_name == "bug_severity":
                if SEVERITIES:
                    field_name = "severity"
                else:
                    field_name = "priority"
            elif field_name == "assigned_to":
                field_name = "owner"
            elif field_name == "bug_status":
                field_name = "status"
                if removed in STATUS_KEYWORDS:
                    remove_keywords.append(STATUS_KEYWORDS[removed])
                if added in STATUS_KEYWORDS:
                    add_keywords.append(STATUS_KEYWORDS[added])
                added = statusXlator[added]
                removed = statusXlator[removed]
            elif field_name == "short_desc":
                field_name = "summary"
            elif field_name == "product" and COMPONENTS_FROM_PRODUCTS:
                field_name = "component"
            elif ((field_name == "product" and not COMPONENTS_FROM_PRODUCTS) or
                  (field_name == "component" and COMPONENTS_FROM_PRODUCTS)):
                if MAP_ALL_KEYWORDS or removed in KEYWORDS_MAPPING:
                    kw = KEYWORDS_MAPPING.get(removed, removed)
                    if kw:
                        remove_keywords.append(kw)
                if MAP_ALL_KEYWORDS or added in KEYWORDS_MAPPING:
                    kw = KEYWORDS_MAPPING.get(added, added)
                    if kw:
                        add_keywords.append(kw)
                if field_name == "component":
                    # just keep the keyword change
                    added = removed = ""
            elif field_name == "target_milestone":
                field_name = "milestone"
                if added in IGNORE_MILESTONES:
                    added = ""
                if removed in IGNORE_MILESTONES:
                    removed = ""

            ticketChange = {}
            ticketChange['ticket'] = bugid
            ticketChange['time'] = activity['bug_when']
            ticketChange['author'] = trac.getLoginName(mysql_cur,
                                                       activity['who'])
            ticketChange['field'] = field_name
            ticketChange['oldvalue'] = removed
            ticketChange['newvalue'] = added

            if add_keywords or remove_keywords:
                # ensure removed ones are in old
                old_keywords = keywords + [kw for kw in remove_keywords if kw
                                           not in keywords]
                # remove from new
                keywords = [kw for kw in keywords if kw not in remove_keywords]
                # add to new
                keywords += [kw for kw in add_keywords if kw not in keywords]
                if old_keywords != keywords:
                    ticketChangeKw = ticketChange.copy()
                    ticketChangeKw['field'] = "keywords"
                    ticketChangeKw['oldvalue'] = ' '.join(old_keywords)
                    ticketChangeKw['newvalue'] = ' '.join(keywords)
                    ticketChanges.append(ticketChangeKw)

            if field_name in IGNORED_ACTIVITY_FIELDS:
                continue

            # Skip changes that have no effect (think translation!).
            if added == removed:
                continue

            # Bugzilla splits large summary changes into two records.
            for oldChange in ticketChanges:
              if (field_name == "summary"
                  and oldChange['field'] == ticketChange['field']
                  and oldChange['time'] == ticketChange['time']
                  and oldChange['author'] == ticketChange['author']):
                  oldChange['oldvalue'] += " " + ticketChange['oldvalue']
                  oldChange['newvalue'] += " " + ticketChange['newvalue']
                  break
              # cc and attachments.isobsolete sometime appear
              # in different activities with same time
              if ((field_name == "cc" or field_name == "attachments.isobsolete") \
                  and oldChange['time'] == ticketChange['time']):
                  oldChange['newvalue'] += ", " + ticketChange['newvalue']
                  break
            else:
                ticketChanges.append (ticketChange)

        for ticketChange in ticketChanges:
            trac.addTicketChange (**ticketChange)

        # For some reason, bugzilla v2.11 seems to clear the resolution
        # when you mark a bug as closed.  Let's remember it and restore
        # it if the ticket is closed but there's no resolution.
        if not ticket['resolution'] and ticket['status'] == "closed":
            ticket['resolution'] = resolution

        bug_status = bug['bug_status']
        if bug_status in STATUS_KEYWORDS:
            kw = STATUS_KEYWORDS[bug_status]
            if kw not in keywords:
                keywords.append(kw)

        product = bug['product']
        if product in KEYWORDS_MAPPING and not COMPONENTS_FROM_PRODUCTS:
            kw = KEYWORDS_MAPPING.get(product, product)
            if kw and kw not in keywords:
                keywords.append(kw)

        component = bug['component']
        if (COMPONENTS_FROM_PRODUCTS and \
            (MAP_ALL_KEYWORDS or component in KEYWORDS_MAPPING)):
            kw = KEYWORDS_MAPPING.get(component, component)
            if kw and kw not in keywords:
                keywords.append(kw)

        ticket['keywords'] = string.join(keywords)
        ticketid = trac.addTicket(**ticket)

        if BZ_VERSION >= 2210:
            mysql_cur.execute("SELECT attachments.*, attach_data.thedata "
                              "FROM attachments, attach_data "
                              "WHERE attachments.bug_id = %s AND "
                              "attachments.attach_id = attach_data.id" % bugid)
        else:
            mysql_cur.execute("SELECT * FROM attachments WHERE bug_id = %s" %
                              bugid)
        attachments = mysql_cur.fetchall()
        for a in attachments:
            author = trac.getLoginName(mysql_cur, a['submitter_id'])
            trac.addAttachment(author, a)

    print "\n8. Importing users and passwords..."
    if BZ_VERSION >= 2164:
        selectlogins = "SELECT login_name, cryptpassword FROM profiles";
        if IGNORE_DISABLED_USERS:
            selectlogins = selectlogins + " WHERE disabledtext=''"
        mysql_cur.execute(selectlogins)
        users = mysql_cur.fetchall()
    else:
        users = ()
    htpasswd = file("htpasswd", 'w')
    for user in users:
        if LOGIN_MAP.has_key(user['login_name']):
            login = LOGIN_MAP[user['login_name']]
        else:
            login = user['login_name']

        htpasswd.write(login + ":" + user['cryptpassword'] + "\n")

    htpasswd.close()
    print "  Bugzilla users converted to htpasswd format, see 'htpasswd'."

    print "\nAll tickets converted."

def log(msg):
    print "DEBUG: %s" % (msg)

def datetime2epoch(dt) :
    import time
    return time.mktime(dt.timetuple()) * 1000000

def usage():
    print """bugzilla2trac - Imports a bug database from Bugzilla into Trac.

Usage: bugzilla2trac.py [options]

Available Options:
  --db <MySQL dbname>              - Bugzilla's database name
  --tracenv /path/to/trac/env      - Full path to Trac db environment
  -h | --host <MySQL hostname>     - Bugzilla's DNS host name
  -u | --user <MySQL username>     - Effective Bugzilla's database user
  -p | --passwd <MySQL password>   - Bugzilla's user password
  -c | --clean                     - Remove current Trac tickets before
                                     importing
  -n | --noseverities              - import Bugzilla severities as Trac
                                     priorities and forget Bugzilla priorities
  --help | help                    - This help info

Additional configuration options can be defined directly in the script.
"""
    sys.exit(0)

def main():
    global BZ_DB, BZ_HOST, BZ_USER, BZ_PASSWORD, TRAC_ENV, TRAC_CLEAN
    global SEVERITIES, PRIORITIES, PRIORITIES_MAP
    if len (sys.argv) > 1:
    	if sys.argv[1] in ['--help','help'] or len(sys.argv) < 4:
    	    usage()
    	iter = 1
    	while iter < len(sys.argv):
    	    if sys.argv[iter] in ['--db'] and iter+1 < len(sys.argv):
    	        BZ_DB = sys.argv[iter+1]
    	        iter = iter + 1
    	    elif sys.argv[iter] in ['-h', '--host'] and iter+1 < len(sys.argv):
    	        BZ_HOST = sys.argv[iter+1]
    	        iter = iter + 1
    	    elif sys.argv[iter] in ['-u', '--user'] and iter+1 < len(sys.argv):
    	        BZ_USER = sys.argv[iter+1]
    	        iter = iter + 1
    	    elif sys.argv[iter] in ['-p', '--passwd'] and iter+1 < len(sys.argv):
    	        BZ_PASSWORD = sys.argv[iter+1]
    	        iter = iter + 1
    	    elif sys.argv[iter] in ['--tracenv'] and iter+1 < len(sys.argv):
    	        TRAC_ENV = sys.argv[iter+1]
    	        iter = iter + 1
    	    elif sys.argv[iter] in ['-c', '--clean']:
    	        TRAC_CLEAN = 1
            elif sys.argv[iter] in ['-n', '--noseverities']:
                # treat Bugzilla severites as Trac priorities
                PRIORITIES = SEVERITIES
                SEVERITIES = []
                PRIORITIES_MAP = {}
    	    else:
    	        print "Error: unknown parameter: " + sys.argv[iter]
    	        sys.exit(0)
    	    iter = iter + 1

    convert(BZ_DB, BZ_HOST, BZ_USER, BZ_PASSWORD, TRAC_ENV, TRAC_CLEAN)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = checkwiki
#!/usr/bin/python
#
# Check/update default wiki pages from the Trac project website.
#
# Note: This is a development tool used in Trac packaging/QA, not something
#       particularly useful for end-users.
#
# Author: Daniel Lundin <daniel@edgewall.com>

import httplib
import re
import sys
import getopt

# Pages to include in distribution
wiki_pages = [
 "CamelCase",
 "InterMapTxt",
 "InterTrac",
 "InterWiki",
 "PageTemplates",
 "RecentChanges",
 "TitleIndex",
 "TracAccessibility",
 "TracAdmin",
 "TracBackup",
 "TracBatchModify",
 "TracBrowser",
 "TracCgi",
 "TracChangeset",
 "TracEnvironment",
 "TracFastCgi",
 "TracFineGrainedPermissions",
 "TracGuide",
 "TracImport",
 "TracIni",
 "TracInstall",
 "TracInterfaceCustomization",
 "TracLinks",
 "TracLogging",
 "TracModPython",
 "TracModWSGI",
 "TracNavigation",
 "TracNotification",
 "TracPermissions",
 "TracPlugins",
 "TracQuery",
 "TracReports",
 "TracRepositoryAdmin",
 "TracRevisionLog",
 "TracRoadmap",
 "TracRss",
 "TracSearch",
 "TracStandalone",
 "TracSupport",
 "TracSyntaxColoring",
 "TracTickets",
 "TracTicketsCustomFields",
 "TracTimeline",
 "TracUnicode",
 "TracUpgrade",
 "TracWiki",
 "TracWorkflow",
 "WikiDeletePage",
 "WikiFormatting",
 "WikiHtml",
 "WikiMacros",
 "WikiNewPage",
 "WikiPageNames",
 "WikiProcessors",
 "WikiRestructuredText",
 "WikiRestructuredTextLinks"
 ]

def get_page_from_file(prefix, pname):
    d = ''
    try:
        f = open(pname ,'r')
        d = f.read()
        f.close()
    except Exception:
        print "Missing page: %s" % pname
    return d

def get_page_from_web(prefix, pname):
    host = "trac.edgewall.org"
    rfile = "/wiki/%s%s?format=txt" % (prefix, pname)
    c = httplib.HTTPConnection(host)
    c.request("GET", rfile)
    print "Getting", rfile
    r = c.getresponse()
    d = r.read()
    if r.status == 200 and d:
        f = open(pname, 'w+')
        f.write(d.replace('\r\n', '\n'))
        f.close()
    else:
        print "Missing or empty page"
    c.close()
    return d

def check_links(data):
    def get_refs(t, refs=[]):
        r = "(?P<wikilink>(^|(?<=[^A-Za-z]))[!]?[A-Z][a-z/]+(?:[A-Z][a-z/]+)+)"
        m = re.search (r, t)
        if not m:
            refs.sort()
            result = []
            orf = None
            for rf in refs:
                if rf != orf:
                    result.append(rf)
                    orf = rf
            return result
        refs.append(m.group())
        return get_refs( t[m.end():], refs)
    for p in data.keys():
        links = get_refs(data[p], [])
        for l in links:
            if l not in data.keys():
                print "Broken link:  %s -> %s" % (p, l)

if __name__ == '__main__':
    try:
        opts, args = getopt.getopt(sys.argv[1:], "dCp:")
    except getopt.GetoptError:
        # print help information and exit:
        print "%s [-d] [-C] [-p prefix] [PAGE ...]" % sys.argv[0]
        print "\t-d        -- Download pages from the main project wiki."
        print "\t-C        -- Try to check links (currently broken)"
        print "\t-p prefix -- When downloading, prepend 'prefix/' to the page."
        sys.exit()
    get_page = get_page_from_file
    prefix = ''
    check = False
    for o,a in opts:
        if o == '-d':
            get_page = get_page_from_web
        elif o == '-p':
            prefix = a+'/'
        elif o == '-C':
            check = True
    data = {}
    for p in args or wiki_pages:
        data[p] = get_page(prefix, p)
    if check:
        check_links(data)


########NEW FILE########
__FILENAME__ = emailfilter
#!/usr/bin/python
"""
emailfilter.py -- Email tickets to Trac.

A simple MTA filter to create Trac tickets from inbound emails.

Copyright 2005, Daniel Lundin <daniel@edgewall.com>
Copyright 2005, Edgewall Software

Please note:

This is only a starting point. See
 * http://trac.edgewall.org/ticket/5327 and
 * http://trac-hacks.org/intertrac/EmailtoTracScript
for more complete and advanced examples.

The scripts reads emails from stdin and inserts directly into a Trac database.
MIME headers are mapped as follows:

    * From: => Reporter
    * Subject: => Summary
    * Body => Description

How to use
----------
 * Set TRAC_ENV_PATH to the path of your project's Trac environment
 * Configure script as a mail (pipe) filter with your MTA
    typically, this involves adding a line like this to /etc/aliases:
       somename: |/path/to/email2trac.py
    Check your MTA's documentation for specifics.

Todo
----
  * Configure target database through env variable?
  * Handle/discard HTML parts
  * Attachment support
"""

TRAC_ENV_PATH = '/var/trac/test'

import email
import sys

from trac.env import Environment
from trac.ticket import Ticket


class TicketEmailParser(object):

    env = None

    def __init__(self, env):
        self.env = env

    def parse(self, fp):
        msg = email.message_from_file(fp)
        tkt = Ticket(self.env)
        tkt['status'] = 'new'
        tkt['reporter'] = msg['from']
        tkt['summary'] = msg['subject']
        for part in msg.walk():
            if part.get_content_type() == 'text/plain':
                tkt['description'] = part.get_payload(decode=1).strip()

        if tkt.values.get('description'):
            tkt.insert()

if __name__ == '__main__':
    env = Environment(TRAC_ENV_PATH, create=0)
    tktparser = TicketEmailParser(env)
    tktparser.parse(sys.stdin)

########NEW FILE########
__FILENAME__ = htdigest
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# Copyright (C) 2006 Matthew Good <matt@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Matthew Good <matt@matt-good.net>

import errno
import fileinput
from getpass import getpass
from hashlib import md5
from optparse import OptionParser
import sys


def ask_pass():
    pass1 = getpass('New password: ')
    pass2 = getpass('Re-type new password: ')
    if pass1 != pass2:
        print >>sys.stderr, "They don't match, sorry"
        sys.exit(1)
    return pass1

def get_digest(userprefix, password=None):
    if password == None:
        password = ask_pass()
    return make_digest(userprefix, password)

def make_digest(userprefix, password):
    return userprefix + md5(userprefix + password).hexdigest()

usage = "%prog [-c] [-b] passwordfile realm username"
parser = OptionParser(usage=usage)
parser.add_option('-c', action='store_true', dest='create', default=False,
                  help='Create a new file')
parser.add_option('-b', action='store_true', dest='batch', default=False,
                  help='Batch mode, password on the commandline.')

opts, args = parser.parse_args()

try:
    if opts.batch:
        filename, realm, username, password = args
    else:
        filename, realm, username = args
        password = None
except ValueError:
    parser.error('Wrong number of arguments')

prefix = '%s:%s:' % (username, realm)

if opts.create:
    try:
        f = open(filename, 'w')
    except EnvironmentError, e:
        if e.errno == errno.EACCES:
            print >>sys.stderr, 'Unable to update file', filename
            sys.exit(1)
        else:
            raise
    try:
        print >>f, get_digest(prefix, password)
    finally:
        f.close()
else:
    try:
        matched = False
        for line in fileinput.input(filename, inplace=True):
            if line.startswith(prefix):
                if not matched:
                    print get_digest(prefix, password)
                matched = True
            else:
                print line,
        if not matched:
            f = open(filename, 'a')
            try:
                print >>f, get_digest(prefix, password)
            finally:
                f.close()
    except EnvironmentError, e:
        if e.errno == errno.ENOENT:
            print >>sys.stderr, 'Could not open passwd file %s for reading.' \
                                % filename
            print >>sys.stderr, 'Use -c option to create a new one.'
            sys.exit(1)
        elif e.errno == errno.EACCES:
            print >>sys.stderr, 'Unable to update file', filename
            sys.exit(1)
        else:
            raise

########NEW FILE########
__FILENAME__ = htpasswd
#!/usr/bin/python
"""Replacement for htpasswd"""
# Original author: Eli Carter

import os
import sys
import random
from optparse import OptionParser

# We need a crypt module, but Windows doesn't have one by default.  Try to find
# one, and tell the user if we can't.
try:
    import crypt
except ImportError:
    try:
        import fcrypt as crypt
    except ImportError:
        sys.stderr.write("Cannot find a crypt module.  "
                         "Possibly http://carey.geek.nz/code/python-fcrypt/\n")
        sys.exit(1)


def salt():
    """Returns a string of 2 randome letters"""
    letters = 'abcdefghijklmnopqrstuvwxyz' \
              'ABCDEFGHIJKLMNOPQRSTUVWXYZ' \
              '0123456789/.'
    return random.choice(letters) + random.choice(letters)


class HtpasswdFile:
    """A class for manipulating htpasswd files."""

    def __init__(self, filename, create=False):
        self.entries = []
        self.filename = filename
        if not create:
            if os.path.exists(self.filename):
                self.load()
            else:
                raise Exception("%s does not exist" % self.filename)

    def load(self):
        """Read the htpasswd file into memory."""
        lines = open(self.filename, 'r').readlines()
        self.entries = []
        for line in lines:
            username, pwhash = line.split(':')
            entry = [username, pwhash.rstrip()]
            self.entries.append(entry)

    def save(self):
        """Write the htpasswd file to disk"""
        open(self.filename, 'w').writelines(["%s:%s\n" % (entry[0], entry[1])
                                             for entry in self.entries])

    def update(self, username, password):
        """Replace the entry for the given user, or add it if new."""
        pwhash = crypt.crypt(password, salt())
        matching_entries = [entry for entry in self.entries
                            if entry[0] == username]
        if matching_entries:
            matching_entries[0][1] = pwhash
        else:
            self.entries.append([username, pwhash])

    def delete(self, username):
        """Remove the entry for the given user."""
        self.entries = [entry for entry in self.entries
                        if entry[0] != username]


def main():
    """%prog [-c] -b filename username password
    Create or update an htpasswd file"""
    # For now, we only care about the use cases that affect tests/functional.py
    parser = OptionParser(usage=main.__doc__)
    parser.add_option('-b', action='store_true', dest='batch', default=False,
        help='Batch mode; password is passed on the command line IN THE CLEAR.'
        )
    parser.add_option('-c', action='store_true', dest='create', default=False,
        help='Create a new htpasswd file, overwriting any existing file.')
    parser.add_option('-D', action='store_true', dest='delete_user',
        default=False, help='Remove the given user from the password file.')

    options, args = parser.parse_args()

    def syntax_error(msg):
        """Utility function for displaying fatal error messages with usage
        help.
        """
        sys.stderr.write("Syntax error: " + msg)
        sys.stderr.write(parser.get_usage())
        sys.exit(1)

    if not options.batch:
        syntax_error("Only batch mode is supported\n")

    # Non-option arguments
    if len(args) < 2:
        syntax_error("Insufficient number of arguments.\n")
    filename, username = args[:2]
    if options.delete_user:
        if len(args) != 2:
            syntax_error("Incorrect number of arguments.\n")
        password = None
    else:
        if len(args) != 3:
            syntax_error("Incorrect number of arguments.\n")
        password = args[2]

    passwdfile = HtpasswdFile(filename, create=options.create)

    if options.delete_user:
        passwdfile.delete(username)
    else:
        passwdfile.update(username, password)

    passwdfile.save()


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = l10n_diff_index
# Copyright (C) 2013 Edgewall Software
# This file is distributed under the same license as the Trac project.

"""

L10N tool which prepares an index of "interesting" changes found in a
.diff.

Skipped changes are:
 - the changes for which the msgid has changed
 - removal only of msgstr content


Example workflow 1), review changes to the 'fr' translation before
committing:

  make diff-fr | less


Example workflow 2), force a pull of all changes from Transifex::

  make update updateopts=-N
  tx pull -f
  make update updateopts=-N
  svn diff > tx.diff
  python l10n_diff_index.py tx.diff
  svn revert -R .

And then use either::

  emacs tx.diff.index --eval '(grep-mode)'

or::

  vim -c :cbuffer -c :copen tx.diff.index

This makes it easier to go through the potentially interesting changes
only, and apply the corresponding chunks if needed.

"""

from bisect import bisect_left
import re

interesting_changes_re = re.compile(r'''
                                               \n
       \s (?: msgid(?:_plural)?\s)? ".*"       \n  # ' ' msgid or "...",
   (?:
       [-\s]  ".*"                             \n  # ' ' or - "...",
   |
       -      msgstr(?:\[\d+\])? \s ".*"       \n  # or the -msgstr
   )*

 (?:
     ( \+     msgstr(?:\[\d+\])? \s "[^"].*" ) \n  # \1 is a non-empty +msgstr
 |
       [+\s]  msgstr(?:\[\d+\])? \s ".*"       \n  # or after the msgstr,
   (?: [-\s]  ".*"                             \n  # optional ' ' or -"...",
   )*
     ( \+     "[^"].*" )                           # \2 is a non-empty +"..."
 )
''', re.MULTILINE | re.VERBOSE)

def index_diffs(path, diffs):
    linenums = []
    re.sub(r'\n', lambda m: linenums.append(m.start()), diffs)
    index = []
    for m in interesting_changes_re.finditer(diffs):
        line = m.group(m.lastindex)
        if line.startswith(('+"Project-Id-Version:', '+"PO-Revision-Date:')):
            continue
        pos = m.start(m.lastindex)
        index.append((bisect_left(linenums, pos) + 1, line))
    return index

def write_index_for(path):
    diffs = unicode(file(path, 'rb').read(), 'utf-8')
    changes = index_diffs(path, diffs)
    if changes:
        index = path + '.index'
        with file(index, 'wb') as idx:
            for n, line in changes:
                print>>idx, (u"%s:%s: %s" % (path, n, line)).encode('utf-8')
        print "%s: %d changes indexed in %s" % (path, len(changes), index)
    else:
        print "%s: no interesting changes" % (path,)

if __name__ == '__main__':
    import sys
    for path in sys.argv[1:]:
        write_index_for(path)

########NEW FILE########
__FILENAME__ = l10n_reset_en_GB
# Copyright (C) 2013 Edgewall Software
# This file is distributed under the same license as the Trac project.

"""

L10N tool which copies all msgid to the msgstr.

This can be useful to verify the actual changes in the en_UK message
catalogs.

"""

import re


msgid_msgstr_re = re.compile(r'''
    (                                             # \1 "en_US"
                                          \r?\n
                msgid \s ".*"             \r?\n
        (?: (?: msgid_plural \s )? ".*"   \r?\n
        )*
    )
    (                                             # \2 "en_GB"
                msgstr.* \s ".*"          \r?\n
        (?: (?: msgstr.* \s )? ".*"       \r?\n
        )*                                \r?\n
    )
    ''', re.MULTILINE | re.VERBOSE)

def reset_file(path):
    with file(path, 'rb+') as f:
        eol = '\r\n'
        content = f.read()
        if eol not in content:
            eol = '\n'
        def reset_msgstr(m):
            msgid, msgstr = m.groups()
            if '\nmsgid_plural' in msgid:
                msgstr = (msgid
                          .replace(eol + 'msgid_plural', eol + 'msgstr[1]')
                          .replace(eol + 'msgid', 'msgstr[0]'))
            else:
                msgstr = msgid.replace(eol + 'msgid', 'msgstr')
            return msgid + msgstr + eol
        sanitized, nsub = msgid_msgstr_re.subn(reset_msgstr, content)
        if nsub:
            print("reset %d messages to en_US in %s" % (nsub, path))
            f.seek(0)
            f.write(sanitized)
            f.truncate()
        else:
            print("no messages found in %s" % (path,))


if __name__ == '__main__':
    import sys
    for path in sys.argv[1:]:
        reset_file(path)

########NEW FILE########
__FILENAME__ = l10n_revert_lineno_conflicts
# Copyright (C) 2013 Edgewall Software
# This file is distributed under the same license as the Trac project.

"""

L10N tool which takes a list of .po in conflicted state and revert
ignorable changes.

It resolve the conflicts for which "theirs" changes consist solely of
line number changes, by reverting to the working copy content.

This makes it easier to merge translation .po files across branches.

"""

import re

ignore_lineno_re = re.compile(r'''
          <<<< .* \n
    ( (?: [^=] .* \n )+)   # \1 == "working copy"
          ==== .* \n
    ( (?: \#   .* \n )+)   # \2 == comment only for "theirs"
          >>>> .* \n
    ''', re.MULTILINE | re.VERBOSE)

def sanitize_file(path):
    with file(path, 'rb+') as f:
        sanitized, nsub = ignore_lineno_re.subn(r'\1', f.read())
        if nsub:
            print("reverted %d ignorable changes in %s" % (nsub, path))
            f.seek(0)
            f.write(sanitized)
            f.truncate()
        else:
            print("no ignorable changes in %s" % (path,))

if __name__ == '__main__':
    import sys
    for path in sys.argv[1:]:
        sanitize_file(path)

########NEW FILE########
__FILENAME__ = migrateticketmodel
#!/usr/bin/env python
#
# This script completely migrates a <= 0.8.x Trac environment to use the new
# default ticket model introduced in Trac 0.9.
#
# In particular, this means that the severity field is removed (or rather
# disabled by removing all possible values), and the priority values are
# changed to the more meaningful new defaults.
#
# Make sure to make a backup of the Trac environment before running this!

from __future__ import with_statement

import os
import sys

from trac.env import open_environment
from trac.ticket.model import Priority, Severity

priority_mapping = {
    'highest':  'blocker',
    'high':     'critical',
    'normal':   'major',
    'low':      'minor',
    'lowest':   'trivial'
}

def main():
    if len(sys.argv) < 2:
        print >> sys.stderr, 'usage: %s /path/to/projenv' \
                             % os.path.basename(sys.argv[0])
        sys.exit(2)

    env = open_environment(sys.argv[1])
    with env.db_transaction:
        for oldprio, newprio in priority_mapping.items():
            priority = Priority(env, oldprio)
            priority.name = newprio
            priority.update()

        for severity in list(Severity.select(env)):
            severity.delete()

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = sourceforge2trac
"""
Import a Sourceforge project's tracker items into a Trac database.

Requires:
   Trac 1.0 from http://trac.edgewall.org/
   Python 2.5 from http://www.python.org/

1.0 clean-up by cboos **untested**, use at your own risks and send patches

The Sourceforge tracker items can be exported from the 'Backup' page
of the project admin section. Substitute XXXXX with project id:
https://sourceforge.net/export/xml_export2.php?group_id=XXXXX


Initial version for Trac 0.7 and old artiface SF export format is
Copyright 2004, Mark Rowe <mrowe@bluewire.net.nz>

Version for Trac 0.11 and SF XML2 export format, completely rewritten
except TracDatabase class is
Copyright 2010, anatoly techtonik <techtonik@php.net>
HGID: 92fd15e8398c

$Id$


Uses Trac 0.11 DB format version 21
SourceForge XML Export format identified by the header:
<!DOCTYPE project_export SYSTEM "http://sourceforge.net/export/sf_project_export_0.2.dtd">

Works with all DB backends. Attachments are not downloaded, but inserted
as links to SF tracker.


Ticket Types, Priorities and Resolutions
----------------------------------------
Conversion kills default Trac ticket types:
- defect      1
- enhancement 2
- task        3

and priorities:
- blocker  1
- critical 2
- major    3
- minor    4
- trivial  5

and resolutions:
- fixed      1
- invalid    2
- wontfix    3
- duplicate  4
- worksforme 5


Versions and Milestones
-----------------------
Kills versions and milestones from existing Trac DB


Mapping
-------
tracker_name == ticket_type
group_name == version
category_name == component

user nobody == anonymous


Not implemented (feature:reason)
--------------------------------
attachments:made as a comment with links to attachments stored on SF
            (type,id,filename,size,time,description,author,ipnr)
ticket_custom:unknown (ticket,name,value)
history:imported only for summary, priority. closed date and owner fields

severities:no field in source data
"""


#: rename users from SF to Trac
user_map = {"nobody":"anonymous"}



complete_msg = """
Conversion complete.

You may want to login into Trac to verify names for ticket owners. You may
also want to rename ticket types and priorities to default.
"""

from __future__ import with_statement

from xml.etree.ElementTree import ElementTree
import time
import sys

import trac.env

# --- utility
class DBNotEmpty(Exception):
    def __str__(self):
        return "Will not modify database with existing tickets!"

class FlatXML(object):
    """Flat XML is XML without element attributes. Also each element
       may contain other elements or text, but not both.

       This object mirrors XML structure into own properties for convenient
       access to tree elements, i.e. flat.trackers[2].groups[2].group_name

       Uses recursion.
    """

    def __init__(self, el=None):
        """el is ElementTree element"""
        if el:
            self.merge(el)

    def merge(self, el):
        """merge supplied ElementTree element into current object"""
        for c in el:
            if len(c.getchildren()) == 0:
                if c.text != None and len(c.text.strip()) != 0:
                   self.__setattr__(c.tag, c.text)
                else:
                   self.__setattr__(c.tag, [])
            else: #if c.getchildren()[0].tag == c.tag[:-1]:
                # c is a set of elements
                self.__setattr__(c.tag, [FlatXML(x) for x in c.getchildren()])


    def __str__(self):
        buf = ""
        for sub in self.__dict__:
            val = self.__dict__[sub]
            if type(val) != list:
                buf += "%s : %s\n" % (sub, val)
            else:
                for x in val:
                    buf += "\n  ".join(x.__str__().split("\n"))
        return buf

    def __repr__(self):
        buf = ""
        for sub in self.__dict__:
            val = self.__dict__[sub]
            if type(val) != list:
                buf += "<%s>%s</%s>\n" % (sub, val, sub)
            else:
                for x in val:
                    buf += "\n  ".join(x.__repr__().split("\n"))
        return buf


# --- SF data model
class Tracker(FlatXML):
    """
 <trackers>
  <tracker>
   <url>http://sourceforge.net/?group_id=175454&#38;atid=873299</url>
   <tracker_id>873299</tracker_id>
   <name>Bugs</name>
   <description>Bug Tracking System</description>
   <is_public>All site users</is_public>
   <allow_anon>Yes</allow_anon>
   <email_updates>Send to goblinhack@gmail.com</email_updates>
   <due_period>2592000</due_period>
   <submit_instructions></submit_instructions>
   <browse_instructions></browse_instructions>
   <status_timeout>1209600</status_timeout>
   <due_period_initial>0</due_period_initial>
   <due_period_update>0</due_period_update>
   <reopen_on_comment>1</reopen_on_comment>
   <canned_responses>
   </canned_responses>
   <groups>
    <group>
     <id>632324</id>
      <group_name>v1.0 (example)</group_name>
    </group>
   </groups>
   <categories>
    <category>
     <id>885178</id>
      <category_name>Interface (example)</category_name>
     <auto_assignee>nobody</auto_assignee>
    </category>
   </categories>
   <resolutions>
    <resolution>
     <id>1</id>
     <name>Fixed</name>
    </resolution>
    <resolution>
     <id>2</id>
     <name>Invalid</name>
    </resolution>
    ...
   </resolutions>
   <statuses>
    <status>
      <id>1</id>
      <name>Open</name>
    </status>
    <status>
      <id>2</id>
      <name>Closed</name>
    </status>
    <status>
      <id>3</id>
      <name>Deleted</name>
    </status>
    <status>
      <id>4</id>
      <name>Pending</name>
    </status>
   </statuses>
   ...
   <tracker_items>
    <tracker_item>
<url>http://sourceforge.net/support/tracker.php?aid=2471428</url>
<id>2471428</id>
<status_id>2</status_id>
<category_id>100</category_id>
<group_id>100</group_id>
<resolution_id>100</resolution_id>
<submitter>sbluen</submitter>
<assignee>nobody</assignee>
<closer>goblinhack</closer>
<submit_date>1230400444</submit_date>
<close_date>1231087612</close_date>
<priority>5</priority>
<summary>glitch with edge of level</summary>
<details>The mini-laser that the future soldier carries is so powerful that it even lets me go outside the level. I stand at the top edge of the level and then shoot up, and then it gets me somewhere where I am not supposed to go.</details>
<is_private>0</is_private>
<followups>
 <followup>
  <id>2335316</id>
  <submitter>goblinhack</submitter>
  <date>1175610236</date>
  <details>Logged In: YES
  user_id=1577972
  Originator: NO

  does this happen every game or just once?

  you could send me the saved file and I'll try and load it - old
  versions harldy ever work with newer versions - need to add some
  kind of warnings on that

  tx</details>
 </followup>
 ...
</followups>
<attachments>
 <attachment>
  <url>http://sourceforge.net/tracker/download.php?group_id=175454&#38;atid=873299&#38;file_id=289080&#38;aid=</url>
  <id>289080</id>
  <filename>your_most_recent_game.gz</filename>
  <description>my saved game</description>
  <filesize>112968</filesize>
  <filetype>application/x-gzip</filetype>
  <date>1218987770</date>
  <submitter>sbluen</submitter>
 </attachment>
...
</attachments>
<history_entries>
 <history_entry>
  <id>7304242</id>
  <field_name>IP</field_name>
  <old_value>Artifact Created: 76.173.48.148</old_value>
  <date>1230400444</date>
  <updator>sbluen</updator>
 </history_entry>
 ...
</history_entries>
    </tracker_item>
    ...
   </tracker_items>
  ...
  </tracker>
 </trackers>
    """
    def __init__(self, e):
        self.merge(e)


class ExportedProjectData(object):
    """Project data container as Python object.
    """
    def __init__(self, f):
        """Data parsing"""

        self.trackers = []    #: tracker properties and data
        self.groups = []      #: groups []
        self.priorities = []  #: priorities used
        self.resolutions = [] #: resolutions (index, name)
        self.tickets = []     #: all tickets
        self.statuses = []    #: status (idx, name)

        self.used_resolutions = {} #: id:name
        self.used_categories  = {} #: id:name
        # id '100' means no category
        self.used_categories['100'] = None
        self.users = {}       #: id:name

        root = ElementTree().parse(f)

        self.users = dict([(FlatXML(u).userid, FlatXML(u).username)
                          for u in root.find('referenced_users')])

        for tracker in root.find('trackers'):
            tr = Tracker(tracker)
            self.trackers.append(tr)

            # groups-versions
            for grp in tr.groups:
                # group ids are tracker-specific even if names match
                g = (grp.id, grp.group_name)
                if g not in self.groups:
                    self.groups.append(g)

            # resolutions
            for res in tr.resolutions:
                r = (res.id, res.name)
                if r not in self.resolutions:
                    self.resolutions.append(r)

            # statuses
            self.statuses = [(s.id, s.name) for s in tr.statuses]

            # tickets
            for tck in tr.tracker_items:
                if type(tck) == str: print repr(tck)
                self.tickets.append(tck)
                if int(tck.priority) not in self.priorities:
                    self.priorities.append(int(tck.priority))
                res_id = getattr(tck, "resolution_id", None)
                if res_id is not None and res_id not in self.used_resolutions:
                    for idx, name in self.resolutions:
                        if idx == res_id: break
                    self.used_resolutions[res_id] = \
                            dict(self.resolutions)[res_id]
                # used categories
                categories = dict(self.get_categories(tr, noowner=True))
                if tck.category_id not in self.used_categories:
                    self.used_categories[tck.category_id] = \
                            categories[tck.category_id]

        # sorting everything
        self.trackers.sort(key=lambda x:x.name)
        self.groups.sort()
        self.priorities.sort()

    def get_categories(self, tracker=None, noid=False, noowner=False):
        """ SF categories : Trac components
            (id, name, owner) tuples for specified tracker or all trackers
            if noid or noowner flags are set, specified tuple attribute is
            stripped
        """
        trs = [tracker] if tracker is not None else self.trackers
        categories = []
        for tr in trs:
            for cat in tr.categories:
                c = (cat.id, cat.category_name, cat.auto_assignee)
                if c not in categories:
                    categories.append(c)
        #: sort by name
        if noid:
            categories.sort()
        else:
            categories.sort(key=lambda x:x[1])
        if noowner:
            categories = [x[:2] for x in categories]
        if noid:
            categories = [x[1:] for x in categories]
        return categories


class TracDatabase(object):
    def __init__(self, path):
        self.env = trac.env.Environment(path)

    def hasTickets(self):
        return int(self.env.db_query("SELECT count(*) FROM ticket")[0][0]) > 0

    def dbCheck(self):
        if self.hasTickets():
            raise DBNotEmpty

    def setTypeList(self, s):
        """Remove all types, set them to `s`"""
        self.dbCheck()
        with self.env.db_transaction as db:
            db("DELETE FROM enum WHERE type='ticket_type'")
            for i, value in enumerate(s):
                db("INSERT INTO enum (type, name, value) VALUES (%s, %s, %s)",
                   ("ticket_type", value, i))

    def setPriorityList(self, s):
        """Remove all priorities, set them to `s`"""
        self.dbCheck()
        with self.env.db_transaction as db:
            db("DELETE FROM enum WHERE type='priority'")
            for i, value in enumerate(s):
                db("INSERT INTO enum (type, name, value) VALUES (%s, %s, %s)",
                   ("priority", value, i))

    def setResolutionList(self, t):
        """Remove all resolutions, set them to `t` (index, name)"""
        self.dbCheck()
        with self.env.db_transaction as db:
            db("DELETE FROM enum WHERE type='resolution'")
            for value, name in t:
                db("INSERT INTO enum (type, name, value) VALUES (%s, %s, %s)",
                   ("resolution", name, value))

    def setComponentList(self, t):
        """Remove all components, set them to `t` (name, owner)"""
        self.dbCheck()
        with self.env.db_transaction as db:
            db("DELETE FROM component")
            for name, owner in t:
                db("INSERT INTO component (name, owner) VALUES (%s, %s)",
                   (name, owner))

    def setVersionList(self, v):
        """Remove all versions, set them to `v`"""
        self.dbCheck()
        with self.env.db_transaction as db:
            db("DELETE FROM version")
            for value in v:
                # time and description are also available
                db("INSERT INTO version (name) VALUES (%s)", value)

    def setMilestoneList(self, m):
        """Remove all milestones, set them to `m` ("""
        self.dbCheck()
        with self.env.db_transaction as db:
            db("DELETE FROM milestone")
            for value in m:
                # due, completed, description are also available
                db("INSERT INTO milestone (name) VALUES (%s)", value)

    def addTicket(self, type, time, changetime, component,
                  priority, owner, reporter, cc,
                  version, milestone, status, resolution,
                  summary, description, keywords):
        """ ticket table db21.py format

        id              integer PRIMARY KEY,
        type            text,           -- the nature of the ticket
        time            integer,        -- the time it was created
        changetime      integer,
        component       text,
        severity        text,
        priority        text,
        owner           text,           -- who is this ticket assigned to
        reporter        text,
        cc              text,           -- email addresses to notify
        version         text,           --
        milestone       text,           --
        status          text,
        resolution      text,
        summary         text,           -- one-line summary
        description     text,           -- problem description (long)
        keywords        text
        """
        if status.lower() == 'open':
            if owner != '':
                status = 'assigned'
            else:
                status = 'new'

        with self.env.db_transaction as db:
            c = db.cursor()
            c.execute("""
                INSERT INTO ticket (type, time, changetime, component,
                                    priority, owner, reporter, cc, version,
                                    milestone, status, resolution, summary,
                                    description, keywords)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                        %s, %s)
                """, (type, time, changetime, component, priority, owner,
                      reporter, cc, version, milestone, status.lower(),
                      resolution, summary, '%s' % description, keywords))
            return db.get_last_id(c, 'ticket')

    def addTicketComment(self, ticket, time, author, value):
        with self.env.db_transaction as db:
            db("""
                INSERT INTO ticket_change (ticket, time, author, field,
                                           oldvalue, newvalue)
                VALUES (%s, %s, %s, %s, %s, %s)
                """, (ticket, time, author, 'comment', '', '%s' % value))

    def addTicketChange(self, ticket, time, author, field, oldvalue, newvalue):
        with self.env.db_transaction as db:
            db("""INSERT INTO ticket_change (ticket, time, author, field,
                                             oldvalue, newvalue)
                  VALUES (%s, %s, %s, %s, %s, %s)
                  """, (ticket, time, author, field, oldvalue, newvalue))


def importData(f, env, opt):
    project = ExportedProjectData(f)
    trackers = project.trackers

    trac = TracDatabase(env)

    # Data conversion
    typeList = [x.name for x in trackers]
    print("%d trackers will be converted to the following ticket types:\n  %s" \
        % (len(trackers), typeList))

    used_cat_names = set(project.used_categories.values())
    #: make names unique, forget about competing owners (the last one wins)
    components = dict(project.get_categories(noid=True)).items()
    components.sort()
    components = [x for x in components if x[0] in used_cat_names]
    print "%d out of %d categories are used and will be converted to the following components:\n  %s" \
        % (len(components), len(project.get_categories()), components)
    print "..renaming component owners:"
    for i,c in enumerate(components):
        if c[1] in user_map:
            components[i] = (c[0], user_map[c[1]])
    print "  %s" % components

    print "%d groups which will be converted to the following versions:\n  %s" \
        % (len(project.groups), project.groups)
    print "%d resolutions found :\n  %s" \
        % (len(project.resolutions), project.resolutions)
    resolutions = [(k,project.used_resolutions[k])
                   for k in project.used_resolutions]
    resolutions.sort(key=lambda x:int(x[0]))
    print ".. only %d used will be imported:\n  %s" \
        % (len(resolutions), resolutions)
    print "Priorities used so far: %s" % project.priorities
    if not(raw_input("Continue [y/N]?").lower() == 'y'):
        sys.exit()

    # Data save
    trac.setTypeList(typeList)
    trac.setComponentList(components)
    trac.setPriorityList(range(min(project.priorities),
                               max(project.priorities)))
    trac.setVersionList(set([x[1] for x in project.groups]))
    trac.setResolutionList(resolutions)
    trac.setMilestoneList([])

    for tracker in project.trackers:
      # id 100 means no component selected
      component_lookup = dict(project.get_categories(noowner=True) +
                              [("100", None)])
      for t in tracker.tracker_items:
        i = trac.addTicket(type=tracker.name,
                           time=int(t.submit_date),
                           changetime=int(t.submit_date),
                           component=component_lookup[t.category_id],
                           priority=t.priority,
                           owner=t.assignee \
                                   if t.assignee not in user_map \
                                   else user_map[t.assignee],
                           reporter=t.submitter \
                                   if t.submitter not in user_map \
                                   else user_map[t.submitter],
                           cc=None,
                           # 100 means no group selected
                           version=dict(project.groups +
                                        [("100", None)])[t.group_id],
                           milestone=None,
                           status=dict(project.statuses)[t.status_id],
                           resolution=dict(resolutions)[t.resolution_id] \
                                   if hasattr(t, "resolution_id") else None,
                           summary=t.summary,
                           description=t.details,
                           keywords='sf' + t.id)

        print 'Imported %s as #%d' % (t.id, i)

        if len(t.attachments):
            attmsg = "SourceForge attachments:\n"
            for a in t.attachments:
                attmsg = attmsg + " * [%s %s] (%s) - added by '%s' %s [[BR]] "\
                         % (a.url+t.id, a.filename, a.filesize+" bytes",
                            user_map.get(a.submitter, a.submitter),
                            time.strftime("%Y-%m-%d %H:%M:%S",
                                          time.localtime(int(a.date))))
                attmsg = attmsg + "''%s ''\n" % (a.description or '')
                # empty description is as empty list
            trac.addTicketComment(ticket=i,
                                  time=time.strftime("%Y-%m-%d %H:%M:%S",
                                          time.localtime(int(t.submit_date))),
                                  author=None, value=attmsg)
            print '    added information about %d attachments for #%d' % \
                    (len(t.attachments), i)

        for msg in t.followups:
            """
            <followup>
            <id>3280792</id>
            <submitter>goblinhack</submitter>
            <date>1231087739</date>
            <details>done</details>
            </followup>
            """
            trac.addTicketComment(ticket=i,
                                  time=msg.date,
                                  author=msg.submitter,
                                  value=msg.details)
        if t.followups:
            print '    imported %d messages for #%d' % (len(t.followups), i)

        # Import history
        """
        <history_entry>
        <id>4452195</id>
        <field_name>resolution_id</field_name>
        <old_value>100</old_value>
        <date>1176043865</date>
        <updator>goblinhack</updator>
        </history_entry>
        """
        revision = t.__dict__.copy()

        # iterate the history in reverse order and update ticket revision from
        # current (last) to initial
        changes = 0
        for h in sorted(t.history_entries, reverse=True):
            """
             Processed fields (field - notes):
            IP         - no target field, just skip
            summary
            priority
            close_date
            assigned_to

             Fields not processed (field: explanation):
            File Added - TODO
            resolution_id - need to update used_resolutions
            status_id
            artifact_group_id
            category_id
            group_id
            """
            f = None
            if h.field_name in ("IP",):
                changes += 1
                continue
            elif h.field_name in ("summary", "priority"):
                f = h.field_name
                oldvalue = h.old_value
                newvalue = revision.get(h.field_name, None)
            elif h.field_name == 'assigned_to':
                f = "owner"
                newvalue = revision['assignee']
                if h.old_value == '100': # was not assigned
                    revision['assignee'] = None
                    oldvalue = None
                else:
                    username = project.users[h.old_value]
                    if username in user_map: username = user_map[username]
                    revision['assignee'] = oldvalue = username
            elif h.field_name == 'close_date' and revision['close_date'] != 0:
                f = 'status'
                oldvalue = 'assigned'
                newvalue = 'closed'

            if f:
                changes += 1
                trac.addTicketChange(ticket=i,
                                     time=h.date,
                                     author=h.updator,
                                     field=f,
                                     oldvalue=oldvalue,
                                     newvalue=newvalue)

            if h.field_name != 'assigned_to':
                revision[h.field_name] = h.old_value
        if changes:
            print '    processed %d out of %d history items for #%d' % \
                    (changes, len(t.history_entries), i)


def main():
    import optparse
    p = optparse.OptionParser(
            "Usage: %prog xml_export.xml /path/to/trac/environment")
    opt, args = p.parse_args()
    if len(args) != 2:
        p.error("Incorrect number of arguments")

    try:
        importData(open(args[0]), args[1], opt)
    except DBNotEmpty, e:
        print 'Error:', e
        sys.exit(1)

    print complete_msg


if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = migrate_original_to_basic
#!/usr/bin/python
import sys

import trac.env
from trac.ticket.default_workflow import load_workflow_config_snippet

def main():
    """Rewrite the ticket-workflow section of the config; and change all
    'assigned' tickets to 'accepted'.
    """
    if len(sys.argv) != 2:
        print "Usage: %s path_to_trac_environment" % sys.argv[0]
        sys.exit(1)
    tracdir = sys.argv[1]
    trac_env = trac.env.open_environment(tracdir)

    # Update the config...
    old_workflow = trac_env.config.options('ticket-workflow')
    for name, value in old_workflow:
        trac_env.config.remove('ticket-workflow', name)
    load_workflow_config_snippet(trac_env.config, 'basic-workflow.ini')
    trac_env.config.save()

    # Update the ticket statuses...
    trac_env.db_transaction("""
        UPDATE ticket SET status = 'accepted' WHERE status = 'assigned'
        """)

if __name__ == '__main__':
    main()

########NEW FILE########
__FILENAME__ = workflow_parser
#!/usr/bin/env python

import sys
import getopt
import locale

import pkg_resources
pkg_resources.require('Trac')

from trac.config import Configuration
from trac.ticket.default_workflow import parse_workflow_config

_debug = False
def debug(s):
    if _debug:
        sys.stderr.write(s)

def readconfig(filename):
    """Returns a list of raw config options"""
    config = Configuration(filename)
    rawactions = list(config.options('ticket-workflow'))
    debug("%s\n" % str(rawactions))
    if not rawactions:
        sys.stderr.write("ERROR: You don't seem to have a [ticket-workflow] "
                         "section.\n")
        sys.exit(1)
    return rawactions

class ColorScheme(object):
    # cyan, yellow are too light in color
    colors = ['black', 'blue', 'red', 'green', 'purple', 'orange', 'darkgreen']
    def __init__(self):
        self.mapping = {}
        self.coloruse = [0,] * len(self.colors)
    def get_color(self, name):
        try:
            colornum = self.mapping[name]
        except(KeyError):
            self.mapping[name] = colornum = self.pick_color(name)
        self.coloruse[colornum] += 1
        return self.colors[colornum]
    def pick_color(self, name):
        """Pick a color that has not been used much so far."""
        return self.coloruse.index(min(self.coloruse))

def actions2graphviz(actions, show_ops=False, show_perms=False):
    """Returns a list of lines to be fed to graphviz."""
    # The size value makes it easier to create a useful printout.
    color_scheme = ColorScheme()
    digraph_lines = ["""
digraph G {
  center=1
  size="10,8"
  { rank=source; new [ shape=invtrapezium ] }
  { rank=sink; closed [ shape=trapezium ] }
    """]
    for action, attributes in actions.items():
        label = [attributes['name'], ]
        if show_ops:
            label += attributes['operations']
        if show_perms:
            label += attributes['permissions']
        if 'set_resolution' in attributes:
            label += ['(' + attributes['set_resolution'] + ')']
        for oldstate in attributes['oldstates']:
            color = color_scheme.get_color(attributes['name'])
            digraph_lines.append(
                '  "%s" -> "%s" [label="%s" color=%s fontcolor=%s]' % \
                (oldstate, attributes['newstate'], '\\n'.join(label), color,
                 color))
    digraph_lines.append('}')
    return digraph_lines

def main(filename, output, show_ops=False, show_perms=False):
    # Read in the config
    rawactions = readconfig(filename)

    # Parse the config information
    actions = parse_workflow_config(rawactions)

    # Convert to graphviz
    digraph_lines = actions2graphviz(actions, show_ops, show_perms)

    # And output
    output.write(unicode.encode('\n'.join(digraph_lines), locale.getpreferredencoding()))

def usage(output):
    output.write('workflow_parser [options] configfile.ini [output.dot]\n'
                 '-h --help shows this message\n'
                 '-o --operations include operations in the graph\n'
                 '-p --permissions include permissions in the graph\n'
    )

if __name__ == '__main__':
    show_ops = False
    show_perms = False
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'hop', ['help', 'operations',
                                                         'permissions'])
    except getopt.GetoptError:
        usage(sys.stderr)
        sys.exit(1)

    for option, argument in opts:
        if option in ('-h', '--help'):
            usage(sys.stdout)
            sys.exit(0)
        elif option in ('-o', '--operations'):
            show_ops = True
        elif option in ('-p', '--permissions'):
            show_perms = True

    if not args:
        sys.stderr.write('Syntax error: config filename required.\n')
        usage(sys.stderr)
        sys.stderr.flush()
        sys.exit(1)
    ini_filename = args[0]
    if len(args) > 1:
        output = open(args[1], 'w')
    else:
        output = sys.stdout

    main(ini_filename, output, show_ops, show_perms)

########NEW FILE########
__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# Trac documentation build configuration file, created by
# sphinx-quickstart on Wed May 14 09:05:13 2008.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# The contents of this file are pickled, so don't put values in the
# namespace that aren't pickleable (module imports are okay, they're
# removed automatically).
#
# All configuration values have a default value; values that are
# commented out serve to show the default value.

import sys, os

# General substitutions.
project = 'Trac'
copyright = '2012, Edgewall Software'
url = 'http://trac.edgewall.org'

# The default replacements for |version| and |release|, also used in various
# other places throughout the built documents.
#
# The short X.Y version.
version = '1.0.1'
# The full version, including alpha/beta/rc tags.
release = '1.0.1'

# Devel or Release mode for the documentation (if devel, include TODOs,
# can also be used in conditionals: .. ifconfig :: devel)
devel = True

if devel:
    release += 'dev'



# If your extensions are in another directory, add it here. If the
# directory is relative to the documentation root, use os.path.abspath
# to make it absolute, like shown here.
# sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))

# General configuration
# ---------------------

# Add any Sphinx extension module names here, as strings.
# They can be extensions coming with Sphinx (named 'sphinx.ext.*')
# or your custom ones.

extensions = []

# -- Autodoc

extensions.append('sphinx.ext.autodoc')

autoclass_content = 'both'
autodoc_member_order = 'bysource'

# -- Conditional content (see setup() below)
extensions.append('sphinx.ext.ifconfig')

# -- Link to other Sphinx documentations
extensions.append('sphinx.ext.intersphinx')

intersphinx_mapping = {'python': ('http://docs.python.org/2.7', None)}

# -- Keep track of :todo: items
extensions.append('sphinx.ext.todo')

todo_include_todos = devel

# -- PDF support via http://code.google.com/p/rst2pdf/
try:
    import rst2pdf
    extensions.append('rst2pdf.pdfbuilder')
except ImportError:
    pass


# Add any paths that contain templates here, relative to this directory.
#templates_path = ['utils/templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The master toctree document.
master_doc = 'index'


# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
today_fmt = '%B %d, %Y'

# List of documents that shouldn't be included in the build.
unused_docs = []

# List of directories, relative to source directories, that shouldn't be searched
# for source files.
exclude_patterns = [
]

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'trac'

# The default role is a reference to some Python object
default_role = 'py:obj'


# Options for HTML output
# -----------------------

# The style sheet to use for HTML and HTML Help pages. A file of that name
# must exist either in Sphinx' static/ path, or in one of the custom paths
# given in html_static_path.
html_style = 'tracsphinx.css'

html_theme = 'sphinxdoc'

html_theme_options = {
#    'linkcolor': '#B00',
#    'visitedlinkcolor': '#B00',
}


# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# The name of an image file (within the static path) to place at the top of
# the sidebar.
html_logo = 'images/trac_logo.png'

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['utils/']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
html_use_modindex = True

# If true, the reST sources are included in the HTML build as _sources/<name>.
#html_copy_source = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# If nonempty, this is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = ''

# Output file base name for HTML help builder.
htmlhelp_basename = 'Tracdoc'


modindex_common_prefix = ['trac.', 'tracopt.']


# Options for LaTeX output
# ------------------------

# The paper size ('letter' or 'a4').
#latex_paper_size = 'letter'

# The font size ('10pt', '11pt' or '12pt').
#latex_font_size = '10pt'

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, document class [howto/manual]).
latex_documents = [
  ('index', 'Trac.tex', 'Trac API Documentation', 'The Trac Team', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# Additional stuff for the LaTeX preamble.
#latex_preamble = ''

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_use_modindex = True



# Options for PDF output
# ----------------------
# (initially copied from
#  http://rst2pdf.googlecode.com/svn/tags/0.16/doc/manual.txt)

# Grouping the document tree into PDF files. List of tuples
# (source start file, target name, title, author, options).
#
# If there is more than one author, separate them with \\.
# For example: r'Guido van Rossum\\Fred L. Drake, Jr., editor'
#
# The options element is a dictionary that lets you override
# this config per-document.
# For example,
# ('index', u'MyProject', u'My Project', u'Author Name',
#  dict(pdf_compressed = True))
# would mean that specific document would be compressed
# regardless of the global pdf_compressed setting.

pdf_documents = [
    ('index', 'trac_dev', project, u'The Trac Team'),
]

# A comma-separated list of custom stylesheets (latest has higher precedence)
pdf_stylesheets = [
    'sphinx',
    'a4',
    'trac',
    os.path.join(os.path.dirname(__file__), 'utils', 'trac_dev_pdf.style')
]

# Create a compressed PDF
# Use True/False or 1/0
# Example: compressed=True
pdf_compressed = True

# A colon-separated list of folders to search for fonts. Example:
# pdf_font_path = ['/usr/share/fonts', '/usr/share/texmf-dist/fonts/']

# Language to be used for hyphenation support
pdf_language = "en_US"

# Mode for literal blocks wider than the frame. Can be
# overflow, shrink or truncate
pdf_fit_mode = "shrink"

# Section level that forces a break page.
# For example: 1 means top-level sections start in a new page
# 0 means disabled
pdf_break_level = 1

# When a section starts in a new page, force it to be 'even', 'odd',
# or just use 'any'
#pdf_breakside = 'any'

# Insert footnotes where they are defined instead of
# at the end.
#pdf_inline_footnotes = True

# verbosity level. 0 1 or 2
#pdf_verbosity = 0

# If false, no index is generated.
pdf_use_index = True

# If false, no modindex is generated.
pdf_use_modindex = True

# If false, no coverpage is generated.
#pdf_use_coverpage = True

# Name of the cover page template to use
#pdf_cover_template = 'sphinxcover.tmpl'

# Documents to append as an appendix to all manuals.
#pdf_appendices = []

# Enable experimental feature to split table cells. Use it
# if you get "DelayedTable too big" errors
#pdf_splittables = False

# Set the default DPI for images
#pdf_default_dpi = 72

# Enable rst2pdf extension modules (default is only vectorpdf)
# you need vectorpdf if you want to use sphinx's graphviz support
#pdf_extensions = ['vectorpdf']

# Page template name for "regular" pages
#pdf_page_template = 'cutePage'

# Show Table Of Contents at the beginning?
#pdf_use_toc = True

# How many levels deep should the table of contents be?
pdf_toc_depth = 9999

# Add section number to section references
pdf_use_numbered_links = False

# Background images fitting mode
pdf_fit_background_mode = 'scale'

def setup(app):
    # adding role for linking to InterTrac targets on t.e.o
    from docutils import nodes
    from docutils.parsers.rst import roles

    def teo_role(name, rawtext, text, lineno, inliner, options={}, content=[]):
        # special case ticket references
        if text[0] == '#':
            ref = url + '/ticket/' + text[1:]
        else:
            ref = url + '/intertrac/' + text
        roles.set_classes(options)
        node = nodes.reference(rawtext, text, refuri=ref, **options)
        return [node], []
    roles.register_canonical_role('teo', teo_role)

    def extensionpoints_role(name, rawtext, text, lineno, inliner, options={},
                             content=[]):
        ref = url + '/wiki/TracDev/PluginDevelopment/ExtensionPoints/' + text
        roles.set_classes(options)
        node = nodes.reference(rawtext, text + " extension point",
                               refuri=ref, **options)
        return [node], []
    roles.register_canonical_role('extensionpoints', extensionpoints_role)

    # ifconfig variables
    app.add_config_value('devel', '', True)

########NEW FILE########
__FILENAME__ = checkapidoc
# -*- coding:  utf-8 -*-

"""Trac API doc checker

Verify that all symbols belonging to modules already documented in the doc/api
Sphinx sources are referenced.

See http://trac.edgewall.org/wiki/TracDev/ApiDocs
"""

import fnmatch
import os
import re
import sys

excluded_docs = ['index.rst']
api_doc = 'doc/api'

def usage(cmd):
    print "Usage: %s [FILE...]" % (cmd,)
    print
    print "FILE is a %s file and can be a glob pattern." % (api_doc,)
    print "If no files are given, check all."
    exit(0)

def main(argv):
    api_files = rst_files = [rst for rst in os.listdir('doc/api')
                             if fnmatch.fnmatch(rst, '*.rst')
                             and rst not in excluded_docs]
    cmd = argv.pop(0)
    def has(*options):
        for opt in options:
            if opt in argv:
                return argv.pop(argv.index(opt))
    if has('-h', '--help'):
        usage(cmd)
    verbose = has('-v', '--verbose')
    only_documented = not has('-a', '--all')
    if argv:
        given_files = []
        for arg in argv:
            arg = arg.replace('\\', '/').replace(api_doc + '/', '')
            arg = arg.replace('.rst', '') + '.rst'
            if '*' in arg: # glob pattern
                given_files += [rst for rst in api_files
                                if fnmatch.fnmatch(rst, arg)]
            elif arg in api_files:
                given_files.append(arg)
        api_files = given_files
    rst_basenames = sorted(f[:-4] for f in rst_files)
    for rst in api_files:
        basename = rst.replace('.rst', '')
        if verbose or len(api_files) > 1:
            print "== Checking %s ... " % (rst,)
        check_api_doc(basename, verbose, only_documented,
                      any(f.startswith(basename) and f != basename
                          for f in rst_basenames))


def check_api_doc(basename, verbose, only_documented, has_submodules):
    module_name = basename.replace('_', '.')
    try:
        module = __import__(module_name, globals(), {}, ['__all__'])
    except ImportError, e:
        print "Skipping %s (%s)" % (basename, e)
        return
    all = getattr(module, '__all__', None)
    if not all:
        print "Warning: %s doesn't define __all__, using exported symbols." % (
            module_name,)
        all = get_default_symbols(module, only_documented, has_submodules)
    no_apidoc = getattr(module, '__no_apidoc__', None)
    if no_apidoc:
        if isinstance(no_apidoc, basestring):
            no_apidoc = [s.strip() for s in no_apidoc.split()]
        all = list(set(all) - set(no_apidoc))
    symbols, keywords = get_sphinx_documented_symbols(basename + '.rst')
    for symbol in sorted(all):
        if symbol in symbols:
            if verbose:
                print " - OK %14s :: %s" % (
                    keywords[symbols.index(symbol)], symbol)
        else:
            value = getattr(module, symbol)
            cls = getattr(value, '__class__', None)
            keyword = 'data'
            if cls.__name__ in ('function', 'instancemethod'):
                keyword = 'function'
            elif cls.__name__ == 'module':
                keyword = 'module'
            else:
                keyword = 'class'
            print " * .. %14s :: %s" % ('auto' + keyword, symbol)


sphinx_doc_re = re.compile(r'''
^.. \s+ ((?:py:|auto)(?:module|class|function|attribute)|data)  # keyword
                                     \s* :: \s* ([\w\.]+)       # symbol
''', re.MULTILINE | re.VERBOSE)

def get_sphinx_documented_symbols(rst):
    doc = file(os.path.join(api_doc, rst)).read()
    symbols, keywords = [], []
    for k, s in sphinx_doc_re.findall(doc):
        symbols.append(s.split('.')[-1])
        keywords.append(k)
    return symbols, keywords


def get_default_symbols(module, only_documented, has_submodules):
    public = get_public_symbols(module) - get_imported_symbols(module,
                                                               has_submodules)
    # eliminate modules
    all = []
    for symbol in public:
        try:
            __import__(symbol)
        except ImportError:
            all.append(symbol)
    # only keep symbols having a docstring
    if only_documented:
        documented = []
        for symbol in all:
            value = getattr(module, symbol)
            if value.__doc__ and (not getattr(value, '__class__', None) or
                                  value.__doc__ != value.__class__.__doc__):
                documented.append(symbol)
        all = documented
    return all

def get_public_symbols(m):
    return set(symbol for symbol in dir(m) if not symbol.startswith('_'))

import_from_re = re.compile(r'''
^ \s* from \s+ ([\w\.]+) \s+ import \s+   # module
(                                \*       # all symbols
|       %s (?: [\s\\]* , [\s\\]* %s)*     # list of symbols
| \( \s* %s (?: \s* , \s* %s)* \s* \)     # list of symbols in parenthesis
)
''' % ((r'(?:\w+|\w+\s+as\s+\w+)',) * 4), re.MULTILINE | re.VERBOSE)

remove_original_re = re.compile(r'\w+\s+as', re.MULTILINE)

def get_imported_symbols(module, has_submodules):
    src_filename = module.__file__.replace('\\', '/').replace('.pyc', '.py')
    if src_filename.endswith('/__init__.py') and not has_submodules:
        return set()
    src = file(src_filename).read()
    imported = set()
    for mod, symbol_list in import_from_re.findall(src):
        symbol_list = symbol_list.strip()
        if symbol_list == '*':
            try:
                imported_module = __import__(mod, globals(), {}, ['__all__'])
                symbols = set(getattr(imported_module, '__all__', None) or
                              get_public_symbols(imported_module))
            except ImportError:
                print "Warning: 'from %s import *' couldn't be resolved" % (
                    mod,)
                continue
        else:
            if symbol_list and symbol_list[0] == '(' and symbol_list[-1] == ')':
                symbol_list = symbol_list[1:-1]
            symbols = set(remove_original_re.sub('', symbol_list)
                          .replace('\\', '').replace(',', ' ').split())
        imported |= symbols
    return imported


if __name__ == '__main__':
    main(sys.argv)

########NEW FILE########
__FILENAME__ = runepydoc
# Simple wrapper script needed to run epydoc

import sys

try:
    from epydoc.cli import cli
except ImportError:
    print>>sys.stderr, "No epydoc installed (see http://epydoc.sourceforge.net)"
    sys.exit(2)


# Epydoc 3.0.1 has some trouble running with recent Docutils (>= 0.6),
# so we work around this bug, following the lines of the fix in
# https://bugs.gentoo.org/attachment.cgi?id=210118
# (see http://bugs.gentoo.org/287546)

try:
    from docutils.nodes import Text
    if not hasattr(Text, 'data'):
        setattr(Text, 'data', property(lambda self: self.astext()))
except ImportError:
    print>>sys.stderr, "docutils is needed for running epydoc " \
        "(see http://docutils.sourceforge.net)"
    sys.exit(2)

# Epydoc doesn't allow much control over the generated graphs. This is
# bad especially for the class graph for Component which has a lot of
# subclasses, so we need to force Left-to-Right mode.

# from epydoc.docwriter.html import HTMLWriter
# HTMLWriter_render_graph = HTMLWriter.render_graph
# def render_graph_LR(self, graph):
#     if graph:
#         graph.body += 'rankdir=LR\n'
#     return HTMLWriter_render_graph(self, graph)
# HTMLWriter.render_graph = render_graph_LR

# Well, LR mode doesn't really look better...
# the ASCII-art version seems better in most cases.


# Workaround "visiting unknown node type" error due to `.. note ::`
# This was due to the lack of Admonitions transforms. Add it.

from epydoc.markup.restructuredtext import _DocumentPseudoWriter
from docutils.transforms import writer_aux

orig_get_transforms = _DocumentPseudoWriter.get_transforms
def pseudo_get_transforms(self):
    return orig_get_transforms(self) + [writer_aux.Admonitions]
_DocumentPseudoWriter.get_transforms = pseudo_get_transforms

# Run epydoc
cli()


########NEW FILE########
__FILENAME__ = HelloWorld
"""Example macro."""

revision = "$Rev: 11490 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/HelloWorld.py $"

#
# The following shows the code for macro, old-style.
#
# The `execute` function serves no purpose other than to illustrate
# the example, it will not be used anymore.
#
# ---- (ignore in your own macro) ----
# --
from trac.util import escape

def execute(hdf, txt, env):
    # Currently hdf is set only when the macro is called
    # From a wiki page
    if hdf:
        hdf['wiki.macro.greeting'] = 'Hello World'

    # args will be `None` if the macro is called without parenthesis.
    args = txt or 'No arguments'

    # then, as `txt` comes from the user, it's important to guard against
    # the possibility to inject malicious HTML/Javascript, by using `escape()`:
    return 'Hello World, args = ' + escape(args)
# --
# ---- (ignore in your own macro) ----


#
# The following is the converted new-style macro
#
# ---- (reuse for your own macro) ----
# --
from trac.wiki.macros import WikiMacroBase

class HelloWorldMacro(WikiMacroBase):
    _description = cleandoc_(
    """Simple HelloWorld macro.

    Note that the name of the class is meaningful:
     - it must end with "Macro"
     - what comes before "Macro" ends up being the macro name

    The documentation of the class (i.e. what you're reading)
    will become the documentation of the macro, as shown by
    the !MacroList macro (usually used in the TracWikiMacros page).
    """)

    def expand_macro(self, formatter, name, args):
        """Return some output that will be displayed in the Wiki content.

        `name` is the actual name of the macro (no surprise, here it'll be
        `'HelloWorld'`),
        `args` is the text enclosed in parenthesis at the call of the macro.
          Note that if there are ''no'' parenthesis (like in, e.g.
          [[HelloWorld]]), then `args` is `None`.
        """
        return 'Hello World, args = ' + unicode(args)

    # Note that there's no need to HTML escape the returned data,
    # as the template engine (Genshi) will do it for us.
# --
# ---- (reuse for your own macro) ----

########NEW FILE########
__FILENAME__ = milestone_to_version
import re

from trac.config import Option
from trac.core import *
from trac.resource import ResourceNotFound
from trac.ticket.api import IMilestoneChangeListener
from trac.ticket.model import Version

revision = "$Rev: 11490 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/milestone_to_version.py $"


class MilestoneToVersion(Component):
    """Automatically create a version when a milestone is completed.

    Sample plugin demonstrating the IMilestoneChangeListener interface.
    Creates a version from a just-completed milestone based on whether the
    milestone's name matches a specified pattern.
    """

    implements(IMilestoneChangeListener)

    pattern = Option('milestone_to_version', 'pattern',
                     r'(?i)(?:v(?:er)?\.?|version)?\s*(?P<version>\d.*)',
        """A regular expression to match the names of milestones that should be
        made into versions when they are completed. The pattern must include
        one named group called 'version' that matches the version number
        itself.""")

    def milestone_created(self, milestone):
        pass

    def milestone_changed(self, milestone, old_values):
        if not milestone.is_completed or 'completed' not in old_values \
                or old_values['completed'] is not None:
            return
        m = re.match(self.pattern, milestone.name)
        if not m:
            return
        version_name = m.groupdict().get('version')
        if not version_name:
            return
        try:
            version = Version(self.env, version_name)
            if not version.time:
                version.time = milestone.completed
                version.update()
                self.log.info('Existing version "%s" updated with completion '
                              'time from milestone "%s"' %
                              (version.name, milestone.name))
            else:
                self.log.info('Version "%s" already exists.  No new version '
                              'created from milestone "%s"' %
                              (version.name, milestone.name))
        except ResourceNotFound:
            version = Version(self.env)
            version.name = version_name
            version.time = milestone.completed
            version.insert()
            self.log.info('New version "%s" created from completed milstone '
                          '"%s".' % (version.name, milestone.name))

    def milestone_deleted(self, milestone):
        pass

########NEW FILE########
__FILENAME__ = debug_perm
from trac.core import *
from trac.perm import IPermissionPolicy, PermissionCache
from trac.resource import Resource

revision = "$Rev$"
url = "$URL$"

class DebugPolicy(Component):
    """Verify the well-formedness of the permission checks.

    **This plugin is only useful for Trac Development.**

    Once this plugin is enabled, you'll have to insert it at the appropriate
    place in your list of permission policies, e.g.
    {{{
    [trac]
    permission_policies = DebugPolicy, SecurityTicketsPolicy, AuthzPolicy,
                          DefaultPermissionPolicy, LegacyAttachmentPolicy
    }}}
    """

    implements(IPermissionPolicy)

    # IPermissionPolicy methods

    def check_permission(self, action, username, resource, perm):
        if resource:
            assert resource is None or isinstance(resource, Resource)
        assert isinstance(perm, PermissionCache)
        self.log.info("does '%s' have %s on %r?", username, action, resource)

########NEW FILE########
__FILENAME__ = public_wiki_policy
from fnmatch import fnmatchcase

from trac.config import Option
from trac.core import *
from trac.perm import IPermissionPolicy

revision = "$Rev: 11490 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/permissions/public_wiki_policy.py $"

class PublicWikiPolicy(Component):
    """Allow public access to some wiki pages.

    This is a sample permission policy plugin illustrating how to check
    permission on realms.

    Don't forget to integrate that plugin in the appropriate place in the
    list of permission policies:
    {{{
    [trac]
    permission_policies = PublicWikiPolicy, DefaultPermissionPolicy
    }}}

    Then you can configure which pages you want to make public:
    {{{
    [public_wiki]
    view = Public*
    modify = PublicSandbox/*
    }}}

    """

    implements(IPermissionPolicy)

    view = Option('public_wiki', 'view', 'Public*',
            """Case-sensitive glob pattern used for granting view permission on
            all Wiki pages matching it.""")

    modify = Option('public_wiki', 'modify', 'Public*',
            """Case-sensitive glob pattern used for granting modify permissions
            on all Wiki pages matching it.""")

    def check_permission(self, action, username, resource, perm):
        if resource: # fine-grained permission check
            if resource.realm == 'wiki': # wiki realm or resource
                if resource.id: # ... it's a resource
                    if action == 'WIKI_VIEW': # (think 'VIEW' here)
                        pattern = self.view
                    else:
                        pattern = self.modify
                    if fnmatchcase(resource.id, pattern):
                        return True
                else: # ... it's a realm
                    return True
                    # this policy ''may'' grant permissions on some wiki pages
        else: # coarse-grained permission check
            #
            # support for the legacy permission checks: no resource specified
            # and realm information in the action name itself.
            #
            if action.startswith('WIKI_'):
                return True
                # this policy ''may'' grant permissions on some wiki pages


########NEW FILE########
__FILENAME__ = vulnerability_tickets
from trac.core import *
from trac.perm import IPermissionPolicy, IPermissionRequestor

revision = "$Rev: 11490 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/permissions/vulnerability_tickets.py $"

class SecurityTicketsPolicy(Component):
    """Prevent public access to security sensitive tickets.

    Add the VULNERABILITY_VIEW permission as a pre-requisite for any
    other permission check done on tickets that have the words
    "security" or "vulnerability" in the summary or keywords fields.

    Once this plugin is enabled, you'll have to insert it at the appropriate
    place in your list of permission policies, e.g.
    {{{
    [trac]
    permission_policies = SecurityTicketsPolicy, AuthzPolicy,
                          DefaultPermissionPolicy, LegacyAttachmentPolicy
    }}}
    """

    implements(IPermissionPolicy, IPermissionRequestor)

    # IPermissionPolicy methods

    def check_permission(self, action, username, resource, perm):
        # We add the 'VULNERABILITY_VIEW' pre-requisite for any action
        # other than 'VULNERABILITY_VIEW' itself, as this would lead
        # to recursion.
        if action == 'VULNERABILITY_VIEW':
            return

        # Check whether we're dealing with a ticket resource
        while resource:
            if resource.realm == 'ticket':
                break
            resource = resource.parent

        if resource and resource.realm == 'ticket' and resource.id is not None:
            for keywords, summary in self.env.db_query(
                    "SELECT keywords, summary FROM ticket WHERE id=%s",
                    (resource.id,)):
                fields = ''.join(f for f in (keywords, summary) if f).lower()
                if 'security' in fields or 'vulnerability' in fields:
                    if 'VULNERABILITY_VIEW' not in perm:
                        return False

    # IPermissionRequestor methods

    def get_permission_actions(self):
        yield 'VULNERABILITY_VIEW'

########NEW FILE########
__FILENAME__ = revision_links
"""Sample Wiki syntax extension plugin."""

from genshi.builder import tag

from trac.core import *
from trac.util.text import shorten_line
from trac.versioncontrol.api import NoSuchChangeset, RepositoryManager
from trac.versioncontrol.web_ui import ChangesetModule
from trac.wiki.api import IWikiSyntaxProvider

revision = "$Rev: 11490 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/revision_links.py $"

class RevisionLinks(Component):
    """Adds a few more ways to refer to changesets."""

    implements(IWikiSyntaxProvider)

    KEYWORDS = ['[Rr]ev(?:ision)?', '[Cc]hangeset']

    # IWikiSyntaxProvider methods

    def get_wiki_syntax(self):
        def revlink(f, match, fullmatch):
            elts = match.split()
            rev = elts[1] # ignore keyword
            reponame = ''
            if len(elts) > 2: # reponame specified
                reponame = elts[-1]
            return self._format_revision_link(f, 'revision', reponame, rev, rev,
                                              fullmatch)

        yield (r"!?(?:%s)\s+%s(?:\s+in\s+\w+)?" %
               ("|".join(self.KEYWORDS), ChangesetModule.CHANGESET_ID), revlink)

    def get_link_resolvers(self):
        def resolverev(f, ns, rev, label, fullmatch):
            return self._format_revision_link(f, ns, '', rev, label, fullmatch)
        yield ('revision', resolverev)

    def _format_revision_link(self, formatter, ns, reponame, rev, label,
                              fullmatch=None):
        rev, params, fragment = formatter.split_link(rev)
        try:
            repos = RepositoryManager(self.env).get_repository(reponame)
            if repos:
                changeset = repos.get_changeset(rev)
                return tag.a(label, class_="changeset",
                             title=shorten_line(changeset.message),
                             href=(formatter.href.changeset(rev) +
                                   params + fragment))
        except NoSuchChangeset:
            pass
        return tag.a(label, class_="missing changeset", rel="nofollow",
                     href=formatter.href.changeset(rev))


########NEW FILE########
__FILENAME__ = Timestamp
"""Inserts the current time (in seconds) into the wiki page."""

revision = "$Rev: 10617 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/Timestamp.py $"

#
# The following shows the code for macro, old-style.
#
# The `execute` function serves no purpose other than to illustrate
# the example, it will not be used anymore.
#
# ---- (ignore in your own macro) ----
# --
import time # Trac before version 0.11 was using `time` module

def execute(hdf, txt, env):
    t = time.localtime()
    return "<b>%s</b>" % time.strftime('%c', t)
# --
# ---- (ignore in your own macro) ----


#
# The following is the converted new-style macro
#
# ---- (reuse for your own macro) ----
# --
from datetime import datetime
# Note: since Trac 0.11, datetime objects are used internally

from genshi.builder import tag

from trac.util.datefmt import format_datetime, utc
from trac.wiki.macros import WikiMacroBase

class TimestampMacro(WikiMacroBase):
    _description = "Inserts the current time (in seconds) into the wiki page."

    def expand_macro(self, formatter, name, args):
        t = datetime.now(utc)
        return tag.b(format_datetime(t, '%c'))
# --
# ---- (reuse for your own macro) ----

########NEW FILE########
__FILENAME__ = CodeReview
from genshi.builder import tag

from trac.core import implements,Component
from trac.ticket.api import ITicketActionController
from trac.ticket.default_workflow import ConfigurableTicketWorkflow
from trac.perm import IPermissionRequestor
from trac.config import Option, ListOption

revision = "$Rev: 11490 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/workflow/CodeReview.py $"

class CodeReviewActionController(Component):
    """Support for simple code reviews.

    The action that supports the `code_review` operation will present
    an extra choice for the review decision. Depending on that decision,
    a specific state will be selected.

    Example (from the enterprise-review-workflow.ini):
    {{{
    review = in_review -> *
    review.name = review as
    review.operations = code_review
    review.code_review =
      approve -> in_QA,
      approve as noted -> post_review,
      request changes -> in_work
    }}}
    Don't forget to add the `CodeReviewActionController` to the workflow
    option in the `[ticket]` section in TracIni.
    If there is no other workflow option, the line will look like this:
    {{{
    workflow = ConfigurableTicketWorkflow,CodeReviewActionController
    }}}
    """

    implements(ITicketActionController, IPermissionRequestor)

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['TICKET_REVIEW']

    # ITicketActionController methods

    def get_ticket_actions(self, req, ticket):
        # The review action is available in those status where it has been
        # configured, for those users who have the TICKET_REVIEW permission, as
        # long as they are not the owner of the ticket (you can't review your
        # own work!).
        actions_we_handle = []
        if req.authname != ticket['owner'] and \
                    'TICKET_REVIEW' in req.perm(ticket.resource):
            controller = ConfigurableTicketWorkflow(self.env)
            actions_we_handle = controller.get_actions_by_operation_for_req(
                req, ticket, 'code_review')
        self.log.debug('code review handles actions: %r' % actions_we_handle)
        return actions_we_handle

    def get_all_status(self):
        all_status = set()
        controller = ConfigurableTicketWorkflow(self.env)
        ouractions = controller.get_actions_by_operation('code_review')
        for weight, action in ouractions:
            status = [status for option, status in
                      self._get_review_options(action)]
            all_status.update(status)
        return all_status

    def render_ticket_action_control(self, req, ticket, action):
        id, grade = self._get_grade(req, action)

        review_options = self._get_review_options(action)
        actions = ConfigurableTicketWorkflow(self.env).actions

        selected_value = grade or review_options[0][0]

        label = actions[action]['name']
        control = tag(["as: ",
                       tag.select([tag.option(option, selected=
                                              (option == selected_value or
                                               None))
                                   for option, status in review_options],
                                  name=id, id=id)])
        if grade:
            new_status = self._get_new_status(req, ticket, action,
                                              review_options)
            hint = "Next status will be '%s'" % new_status
        else:
            hint = "Next status will be one of " + \
                   ', '.join(["'%s'" % status
                              for option, status in review_options])
        return (label, control, hint)

    def get_ticket_changes(self, req, ticket, action):
        new_status = self._get_new_status(req, ticket, action)
        return {'status': new_status or 'new'}

    def apply_action_side_effects(self, req, ticket, action):
        pass

    # Internal methods

    def _get_grade(self, req, action):
        id = action + '_code_review_result'
        return id, req.args.get(id)

    def _get_review_options(self, action):
        return [[x.strip() for x in raw_option.split('->')]
                for raw_option in self.config.getlist('ticket-workflow',
                                                      action + '.code_review')]

    def _get_new_status(self, req, ticket, action, review_options=None):
        id, grade = self._get_grade(req, action)
        if not review_options:
            review_options = self._get_review_options(action)
        for option, status in review_options:
            if grade == option:
                return status

########NEW FILE########
__FILENAME__ = DeleteTicket
from genshi.builder import tag

from trac.core import implements,Component
from trac.ticket.api import ITicketActionController
from trac.perm import IPermissionRequestor

revision = "$Rev: 11490 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/workflow/DeleteTicket.py $"

class DeleteTicketActionController(Component):
    """Provides the admin with a way to delete a ticket.

    Illustrates how to create an action controller with side-effects.

    Don't forget to add `DeleteTicketActionController` to the workflow
    option in the `[ticket]` section in TracIni.
    If there is no other workflow option, the line will look like this:
    {{{
    workflow = ConfigurableTicketWorkflow,DeleteTicketActionController
    }}}
    """

    implements(ITicketActionController, IPermissionRequestor)

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['TICKET_DELETE']

    # ITicketActionController methods

    def get_ticket_actions(self, req, ticket):
        actions = []
        if 'TICKET_DELETE' in req.perm(ticket.resource):
            actions.append((0,'delete'))
        return actions

    def get_all_status(self):
        return []

    def render_ticket_action_control(self, req, ticket, action):
        return ("delete ticket", '', "This ticket will be deleted.")

    def get_ticket_changes(self, req, ticket, action):
        return {}

    def apply_action_side_effects(self, req, ticket, action):
        # Be paranoid here, as this should only be called when
        # action is delete...
        if action == 'delete':
            ticket.delete()

########NEW FILE########
__FILENAME__ = MilestoneOperation
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Franz Mayer <franz.mayer@gefasoft.de>
#
# "THE BEER-WARE LICENSE" (Revision 42):
# <franz.mayer@gefasoft.de> wrote this file.  As long as you retain this
# notice you can do whatever you want with this stuff. If we meet some day,
# and you think this stuff is worth it, you can buy me a beer in return.
# Franz Mayer
#
# Author: Franz Mayer <franz.mayer@gefasoft.de>

from genshi.builder import tag

from trac.core import Component, implements
from trac.resource import ResourceNotFound
from trac.ticket.api import ITicketActionController
from trac.ticket.default_workflow import ConfigurableTicketWorkflow
from trac.ticket.model import Milestone
from trac.util.translation import _
from trac.web.chrome import add_warning

revision = "$Rev$"
url = "$URL$"

class MilestoneOperation(Component):
    """Sets milestone for specific status.

=== Example ===
{{{
[ticket-workflow]
resolve.operations = set_resolution,set_milestone
resolve.milestone = invalid,wontfix,duplicate,worksforme->rejected
}}}

When setting status to `duplicate` the milestone will automatically change
to `rejected`.

'''Note:''' if user has changed milestone manually, this workflow operation
has ''no effect''!

=== Configuration ===
Don't forget to add `MilestoneOperation` to the workflow option
in `[ticket]` section. If there is no workflow option, the line will look
like this:
{{{
[ticket]
workflow = ConfigurableTicketWorkflow,MilestoneOperation
}}}
"""

    implements(ITicketActionController)

    def get_ticket_actions(self, req, ticket):
        actions_we_handle = []
        if req.authname != 'anonymous' and \
                    'TICKET_MODIFY' in req.perm(ticket.resource):
            controller = ConfigurableTicketWorkflow(self.env)
            actions_we_handle = controller.get_actions_by_operation_for_req(
                req, ticket, 'set_milestone')
        self.log.debug('set_milestone handles actions: %r' % actions_we_handle)
        return actions_we_handle

    def get_all_status(self):
        return []

    def render_ticket_action_control(self, req, ticket, action):
        actions = ConfigurableTicketWorkflow(self.env).actions
        label = actions[action]['name']
        res_ms = self.__get_resolution_milestone_dict(ticket, action)
        resolutions = ''
        milestone = None
        for i, resolution in enumerate(res_ms):
            if i > 0:
                resolutions = "%s, '%s'" % (resolutions, resolution)
            else:
                resolutions = "'%s'" % resolution
                milestone = res_ms[resolution]
        hint = _("For resolution %(resolutions)s the milestone will be "
                 "set to '%(milestone)s'.",
                 resolutions=resolutions, milestone=milestone)
        return (label, None, hint)

    def get_ticket_changes(self, req, ticket, action):
        if action == 'resolve' and \
                req.args and 'action_resolve_resolve_resolution' in req.args:
            old_milestone = ticket._old.get('milestone') or None
            user_milestone = ticket['milestone'] or None
            # If there's no user defined milestone, we try to set it
            # using the defined resolution -> milestone mapping.
            if old_milestone is None:
                new_status = req.args['action_resolve_resolve_resolution']
                new_milestone = self.__get_new_milestone(ticket, action,
                                                         new_status)
                # ... but we don't reset it to None unless it was None
                if new_milestone is not None or user_milestone is None:
                    try:
                        milestone = Milestone(self.env, new_milestone)
                        self.log.info('changed milestone from %s to %s' %
                                      (old_milestone, new_milestone) )
                        return {'milestone': new_milestone}
                    except ResourceNotFound:
                        add_warning(req, _("Milestone %(name)s does not exist.",
                                           name=new_milestone))
        return {}

    def apply_action_side_effects(self, req, ticket, action):
        pass

    def __get_new_milestone(self, ticket, action, new_status):
        """Determines the new status"""
        if new_status:
            res_ms = self.__get_resolution_milestone_dict(ticket, action)
            return res_ms.get(new_status)

    def __get_resolution_milestone_dict(self, ticket, action):
        transitions = self.config.get('ticket-workflow',
                                      action + '.milestone').strip()
        transition = [x.strip() for x in transitions.split('->')]
        resolutions = [y.strip() for y in transition[0].split(',')]
        res_milestone = {}
        for res in resolutions:
            res_milestone[res] = transition[1]
        return res_milestone

########NEW FILE########
__FILENAME__ = StatusFixer
from genshi.builder import tag

from trac.core import Component, implements
from trac.ticket.api import ITicketActionController, TicketSystem
from trac.perm import IPermissionRequestor

revision = "$Rev: 11075 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/workflow/StatusFixer.py $"

class StatusFixerActionController(Component):
    """Provides the admin with a way to correct a ticket's status.

    This plugin is especially useful when you made changes to your workflow,
    and some ticket status are no longer valid. The tickets that are in those
    status can then be set to some valid state.

    Don't forget to add `StatusFixerActionController` to the workflow
    option in the `[ticket]` section in TracIni.
    If there is no other workflow option, the line will look like this:
    {{{
    workflow = ConfigurableTicketWorkflow,StatusFixerActionController
    }}}
    """

    implements(ITicketActionController, IPermissionRequestor)

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['TICKET_STATUSFIX']

    # ITicketActionController methods

    def get_ticket_actions(self, req, ticket):
        actions = []
        if 'TICKET_STATUSFIX' in req.perm(ticket.resource):
            actions.append((0, 'force_status'))
        return actions

    def get_all_status(self):
        """Return all the status that are present in the database,
        so that queries for status no longer in use can be made.
        """
        return [status for status, in
                self.env.db_query("SELECT DISTINCT status FROM ticket")]

    def render_ticket_action_control(self, req, ticket, action):
        # Need to use the list of all status so you can't manually set
        # something to an invalid state.
        selected_value = req.args.get('force_status_value', 'new')
        all_status = TicketSystem(self.env).get_all_status()
        render_control = tag.select(
            [tag.option(x, selected=(x == selected_value and 'selected' or
                                     None)) for x in all_status],
            id='force_status_value', name='force_status_value')
        return ("force status to:", render_control,
                "The next status will be the selected one")

    def get_ticket_changes(self, req, ticket, action):
        return {'status': req.args.get('force_status_value')}

    def apply_action_side_effects(self, req, ticket, action):
        pass

########NEW FILE########
__FILENAME__ = VoteOperation
from genshi.builder import tag

from trac.core import implements,Component
from trac.ticket.api import ITicketActionController
from trac.ticket.default_workflow import ConfigurableTicketWorkflow
from trac.ticket.model import Priority, Ticket
#from trac.perm import IPermissionRequestor # (TODO)

revision = "$Rev: 11490 $"
url = "$URL: http://svn.edgewall.org/repos/trac/tags/trac-1.0.1/sample-plugins/workflow/VoteOperation.py $"

class VoteOperation(Component):
    """Provides a simplistic vote feature.

    This is a sample action controller illustrating how to create additional
    ''operations''.

    Don't forget to add `VoteOperation` to the workflow
    option in the `[ticket]` section in TracIni.
    If there is no other workflow option, the line will look like this:
    {{{
    workflow = ConfigurableTicketWorkflow,VoteOperation
    }}}
    """

    implements(ITicketActionController)

    def get_ticket_actions(self, req, ticket):
        controller = ConfigurableTicketWorkflow(self.env)
        return controller.get_actions_by_operation_for_req(req, ticket, 'vote')

    def get_all_status(self):
        return []

    def render_ticket_action_control(self, req, ticket, action):
        id = 'vote_%s_result' % (action, )
        selected_value = req.args.get(id, 'for')
        options = ['for', 'against']
        return ("vote",
                tag.select([tag.option(x, selected=(x == selected_value or
                                                    None))
                            for x in options], name=id, id=id),
                "Vote on the issue, raising or lowering its priority")

    def get_ticket_changes(self, req, ticket, action):
        id = 'vote_%s_result' % (action, )
        selected = req.args.get(id, 'for')
        priorities = list(Priority.select(self.env))
        orig_ticket = Ticket(self.env, ticket.id)
        current_priority = int(Priority(self.env, name=
                                        orig_ticket['priority']).value)
        if selected == 'for':
            # priorities are 1-based, not 0-based
            new_value = max(1, current_priority - 1)
        else:
            maxval = max([int(p.value) for p in priorities])
            new_value = min(maxval, current_priority + 1)
        return {'priority': [p.name for p in priorities
                             if int(p.value) == new_value][0]}

    def apply_action_side_effects(self, req, ticket, action):
        pass

########NEW FILE########
__FILENAME__ = about
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2005 Daniel Lundin <daniel@edgewall.com>
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

import re

from genshi.builder import tag

from trac.core import *
from trac.loader import get_plugin_info
from trac.perm import IPermissionRequestor
from trac.util.translation import _
from trac.web import IRequestHandler
from trac.web.chrome import INavigationContributor


class AboutModule(Component):
    """"About Trac" page provider, showing version information from
    third-party packages, as well as configuration information."""

    required = True

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler)

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'about'

    def get_navigation_items(self, req):
        yield ('metanav', 'about',
               tag.a(_('About Trac'), href=req.href.about()))

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['CONFIG_VIEW']

    # IRequestHandler methods

    def match_request(self, req):
        return re.match(r'/about(?:_trac)?(?:/.+)?$', req.path_info)

    def process_request(self, req):
        data = {'systeminfo': None, 'plugins': None, 'config': None}

        if 'CONFIG_VIEW' in req.perm('config', 'systeminfo'):
            # Collect system information
            data['systeminfo'] = self.env.get_systeminfo()

        if 'CONFIG_VIEW' in req.perm('config', 'plugins'):
            # Collect plugin information
            data['plugins'] = get_plugin_info(self.env)

        if 'CONFIG_VIEW' in req.perm('config', 'ini'):
            # Collect config information
            defaults = self.config.defaults(self.compmgr)
            sections = []
            for section in self.config.sections(self.compmgr):
                options = []
                default_options = defaults.get(section, {})
                for name, value in self.config.options(section, self.compmgr):
                    default = default_options.get(name) or ''
                    options.append({
                        'name': name, 'value': value,
                        'modified': unicode(value) != unicode(default)
                    })
                options.sort(key=lambda o: o['name'])
                sections.append({'name': section, 'options': options})
            sections.sort(key=lambda s: s['name'])
            data['config'] = sections

        return 'about.html', data, None

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os.path
import sys
import traceback

from trac.core import *
from trac.util.text import levenshtein_distance
from trac.util.translation import _


console_date_format = '%Y-%m-%d'
console_datetime_format = '%Y-%m-%d %H:%M:%S'
console_date_format_hint = 'YYYY-MM-DD'


class IAdminPanelProvider(Interface):
    """Extension point interface for adding panels to the web-based
    administration interface.
    """

    def get_admin_panels(req):
        """Return a list of available admin panels.

        The items returned by this function must be tuples of the form
        `(category, category_label, page, page_label)`.
        """

    def render_admin_panel(req, category, page, path_info):
        """Process a request for an admin panel.

        This function should return a tuple of the form `(template, data)`,
        where `template` is the name of the template to use and `data` is the
        data to be passed to the template.
        """


class AdminCommandError(TracError):
    """Exception raised when an admin command cannot be executed."""
    def __init__(self, msg, show_usage=False, cmd=None):
        TracError.__init__(self, msg)
        self.show_usage = show_usage
        self.cmd = cmd


class IAdminCommandProvider(Interface):
    """Extension point interface for adding commands to the console
    administration interface `trac-admin`.
    """

    def get_admin_commands():
        """Return a list of available admin commands.

        The items returned by this function must be tuples of the form
        `(command, args, help, complete, execute)`, where `command` contains
        the space-separated command and sub-command names, `args` is a string
        describing the command arguments and `help` is the help text. The
        first paragraph of the help text is taken as a short help, shown in the
        list of commands.

        `complete` is called to auto-complete the command arguments, with the
        current list of arguments as its only argument. It should return a list
        of relevant values for the last argument in the list.

        `execute` is called to execute the command, with the command arguments
        passed as positional arguments.
        """


class AdminCommandManager(Component):
    """trac-admin command manager."""

    providers = ExtensionPoint(IAdminCommandProvider)

    def get_command_help(self, args=[]):
        """Return help information for a set of commands."""
        commands = []
        for provider in self.providers:
            for cmd in provider.get_admin_commands() or []:
                parts = cmd[0].split()
                if parts[:len(args)] == args:
                    commands.append(cmd[:3])
        commands.sort()
        return commands

    def complete_command(self, args, cmd_only=False):
        """Perform auto-completion on the given arguments."""
        comp = []
        for provider in self.providers:
            for cmd in provider.get_admin_commands() or []:
                parts = cmd[0].split()
                plen = min(len(parts), len(args) - 1)
                if args[:plen] != parts[:plen]:         # Prefix doesn't match
                    continue
                elif len(args) <= len(parts):           # Command name
                    comp.append(parts[len(args) - 1])
                elif not cmd_only:                      # Arguments
                    if cmd[3] is None:
                        return []
                    return cmd[3](args[len(parts):]) or []
        return comp

    def execute_command(self, *args):
        """Execute a command given by a list of arguments."""
        args = list(args)
        for provider in self.providers:
            for cmd in provider.get_admin_commands() or []:
                parts = cmd[0].split()
                if args[:len(parts)] == parts:
                    f = cmd[4]
                    fargs = args[len(parts):]
                    try:
                        return f(*fargs)
                    except AdminCommandError, e:
                        e.cmd = ' '.join(parts)
                        raise
                    except TypeError, e:
                        tb = traceback.extract_tb(sys.exc_info()[2])
                        if len(tb) == 1:
                            raise AdminCommandError(_("Invalid arguments"),
                                                    show_usage=True,
                                                    cmd=' '.join(parts))
                        raise
        raise AdminCommandError(_("Command not found"), show_usage=True)

    def get_similar_commands(self, arg, n=5):
        if not arg:
            return []

        cmds = set()
        for provider in self.providers:
            for cmd in provider.get_admin_commands() or []:
                cmds.add(cmd[0].split()[0]) # use only first token

        def score(cmd, arg):
            if cmd.startswith(arg):
                return 0
            return levenshtein_distance(cmd, arg) / float(len(cmd) + len(arg))
        similars = sorted((score(cmd, arg), cmd) for cmd in cmds)
        similars = [cmd for val, cmd in similars if val <= 0.5]
        return similars[:n]


class PrefixList(list):
    """A list of prefixes for command argument auto-completion."""
    def complete(self, text):
        return list(set(a for a in self if a.startswith(text)))


def path_startswith(path, prefix):
    return os.path.normcase(path).startswith(os.path.normcase(prefix))


class PathList(list):
    """A list of paths for command argument auto-completion."""
    def complete(self, text):
        """Return the items in the list matching text."""
        matches = list(set(a for a in self if path_startswith(a, text)))
        if len(matches) == 1 and not os.path.isdir(matches[0]):
            matches[0] += ' '
        return matches


def get_dir_list(path, dirs_only=False):
    """Return a list of paths to filesystem entries in the same directory
    as the given path."""
    dname = os.path.dirname(path)
    d = os.path.join(os.getcwd(), dname)
    result = PathList()
    try:
        dlist = os.listdir(d)
    except OSError:
        return result
    for entry in dlist:
        path = os.path.normpath(os.path.join(dname, entry))
        try:
            if os.path.isdir(path):
                result.append(os.path.join(path, ''))
            elif not dirs_only:
                result.append(path)
        except OSError:
            pass
    return result

########NEW FILE########
__FILENAME__ = console
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2010 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from __future__ import with_statement

import cmd
import locale
import os.path
import pkg_resources
from shlex import shlex
import StringIO
import sys
import traceback

from trac import __version__ as VERSION
from trac.admin import AdminCommandError, AdminCommandManager
from trac.core import TracError
from trac.env import Environment
from trac.ticket.model import *
from trac.util import translation
from trac.util.html import html
from trac.util.text import console_print, exception_to_unicode, printout, \
                           printerr, raw_input, to_unicode, \
                           getpreferredencoding
from trac.util.translation import _, ngettext, get_negotiated_locale, \
                                  has_babel, cleandoc_
from trac.versioncontrol.api import RepositoryManager
from trac.wiki.admin import WikiAdmin
from trac.wiki.macros import WikiMacroBase

TRAC_VERSION = pkg_resources.get_distribution('Trac').version
rl_completion_suppress_append = None
LANG = os.environ.get('LANG')

def find_readline_lib():
    """Return the name (and possibly the full path) of the readline library
    linked to the readline module.
    """
    import readline
    with open(readline.__file__, "rb") as f:
        data = f.read()
    import re
    m = re.search('\0([^\0]*libreadline[^\0]*)\0', data)
    if m:
        return m.group(1)
    return None


class TracAdmin(cmd.Cmd):
    intro = ''
    doc_header = 'Trac Admin Console %(version)s\n' \
                 'Available Commands:\n' \
                 % {'version': TRAC_VERSION}
    ruler = ''
    prompt = "Trac> "
    envname = None
    __env = None
    needs_upgrade = None

    def __init__(self, envdir=None):
        cmd.Cmd.__init__(self)
        try:
            import readline
            delims = readline.get_completer_delims()
            for c in '-/:()\\':
                delims = delims.replace(c, '')
            readline.set_completer_delims(delims)

            # Work around trailing space automatically inserted by libreadline
            # until Python gets fixed, see http://bugs.python.org/issue5833
            import ctypes
            lib_name = find_readline_lib()
            if lib_name is not None:
                lib = ctypes.cdll.LoadLibrary(lib_name)
                global rl_completion_suppress_append
                rl_completion_suppress_append = ctypes.c_int.in_dll(lib,
                                            "rl_completion_suppress_append")
        except Exception:
            pass
        self.interactive = False
        if envdir:
            self.env_set(os.path.abspath(envdir))

    def emptyline(self):
        pass

    def onecmd(self, line):
        """`line` may be a `str` or an `unicode` object"""
        try:
            if isinstance(line, str):
                if self.interactive:
                    encoding = sys.stdin.encoding
                else:
                    encoding = getpreferredencoding() # sys.argv
                line = to_unicode(line, encoding)
            if self.interactive:
                line = line.replace('\\', '\\\\')
            rv = cmd.Cmd.onecmd(self, line) or 0
        except SystemExit:
            raise
        except AdminCommandError, e:
            printerr(_("Error: %(msg)s", msg=to_unicode(e)))
            if e.show_usage:
                print
                self.do_help(e.cmd or self.arg_tokenize(line)[0])
            rv = 2
        except TracError, e:
            printerr(exception_to_unicode(e))
            rv = 2
        except Exception, e:
            printerr(exception_to_unicode(e))
            rv = 2
            if self.env_check():
                self.env.log.error("Exception in trac-admin command: %s",
                                   exception_to_unicode(e, traceback=True))
        if not self.interactive:
            return rv

    def run(self):
        self.interactive = True
        printout(_("""Welcome to trac-admin %(version)s
Interactive Trac administration console.
Copyright (C) 2003-2013 Edgewall Software

Type:  '?' or 'help' for help on commands.
        """, version=TRAC_VERSION))
        self.cmdloop()

    ##
    ## Environment methods
    ##

    def env_set(self, envname, env=None):
        self.envname = envname
        self.prompt = "Trac [%s]> " % self.envname
        if env is not None:
            self.__env = env

    def env_check(self):
        if not self.__env:
            try:
                self._init_env()
            except Exception:
                return False
        return True

    @property
    def env(self):
        try:
            if not self.__env:
                self._init_env()
            return self.__env
        except Exception, e:
            printerr(_("Failed to open environment: %(err)s",
                       err=exception_to_unicode(e, traceback=True)))
            sys.exit(1)

    def _init_env(self):
        self.__env = env = Environment(self.envname)
        # fixup language according to env settings
        if has_babel:
            default = env.config.get('trac', 'default_language', '')
            negotiated = get_negotiated_locale([LANG, default])
            if negotiated:
                translation.activate(negotiated)

    ##
    ## Utility methods
    ##

    def arg_tokenize(self, argstr):
        """`argstr` is an `unicode` string

        ... but shlex is not unicode friendly.
        """
        lex = shlex(argstr.encode('utf-8'), posix=True)
        lex.whitespace_split = True
        lex.commenters = ''
        if os.name == 'nt':
            lex.escape = ''
        return [unicode(token, 'utf-8') for token in lex] or ['']

    def word_complete(self, text, words):
        words = list(set(a for a in words if a.startswith(text)))
        if len(words) == 1:
            words[0] += ' '     # Only one choice, skip to next arg
        return words

    @staticmethod
    def split_help_text(text):
        import re
        paragraphs = re.split(r'(?m)(?:^[ \t]*\n){1,}', text)
        return [re.sub(r'(?m)\s+', ' ', each.strip())
                for each in paragraphs]

    @classmethod
    def print_doc(cls, docs, stream=None, short=False, long=False):
        if stream is None:
            stream = sys.stdout
        docs = [doc for doc in docs if doc[2]]
        if not docs:
            return
        if short:
            max_len = max(len(doc[0]) for doc in docs)
            for (cmd, args, doc) in docs:
                paragraphs = cls.split_help_text(doc)
                console_print(stream, '%s  %s' % (cmd.ljust(max_len),
                                                  paragraphs[0]))
        else:
            import textwrap
            for (cmd, args, doc) in docs:
                paragraphs = cls.split_help_text(doc)
                console_print(stream, '%s %s\n' % (cmd, args))
                console_print(stream, '    %s\n' % paragraphs[0])
                if (long or len(docs) == 1) and len(paragraphs) > 1:
                    for paragraph in paragraphs[1:]:
                        console_print(stream, textwrap.fill(paragraph, 79,
                            initial_indent='    ', subsequent_indent='    ')
                            + '\n')

    ##
    ## Command dispatcher
    ##

    def complete_line(self, text, line, cmd_only=False):
        if rl_completion_suppress_append is not None:
            rl_completion_suppress_append.value = 1
        args = self.arg_tokenize(line)
        if line and line[-1] == ' ':    # Space starts new argument
            args.append('')
        if self.env_check():
            cmd_mgr = AdminCommandManager(self.env)
            try:
                comp = cmd_mgr.complete_command(args, cmd_only)
            except Exception, e:
                printerr()
                printerr(_('Completion error: %(err)s',
                           err=exception_to_unicode(e)))
                self.env.log.error("trac-admin completion error: %s",
                                   exception_to_unicode(e, traceback=True))
                comp = []
        if len(args) == 1:
            comp.extend(name[3:] for name in self.get_names()
                        if name.startswith('do_'))
        try:
            return comp.complete(text)
        except AttributeError:
            return self.word_complete(text, comp)

    def completenames(self, text, line, begidx, endidx):
        return self.complete_line(text, line, True)

    def completedefault(self, text, line, begidx, endidx):
        return self.complete_line(text, line)

    def default(self, line):
        try:
            if not self.__env:
                self._init_env()
            if self.needs_upgrade is None:
                self.needs_upgrade = self.__env.needs_upgrade()
        except TracError, e:
            raise AdminCommandError(to_unicode(e))
        except Exception, e:
            raise AdminCommandError(exception_to_unicode(e))
        args = self.arg_tokenize(line)
        if args[0] == 'upgrade':
            self.needs_upgrade = None
        elif self.needs_upgrade:
            raise TracError(_('The Trac Environment needs to be upgraded.\n\n'
                              'Run "trac-admin %(path)s upgrade"',
                              path=self.envname))
        cmd_mgr = AdminCommandManager(self.env)
        return cmd_mgr.execute_command(*args)

    ##
    ## Available Commands
    ##

    ## Help
    _help_help = [('help', '', 'Show documentation')]

    @classmethod
    def all_docs(cls, env=None):
        docs = (cls._help_help + cls._help_initenv)
        if env is not None:
            docs.extend(AdminCommandManager(env).get_command_help())
        return docs

    def complete_help(self, text, line, begidx, endidx):
        return self.complete_line(text, line[5:], True)

    def do_help(self, line=None):
        arg = self.arg_tokenize(line)
        if arg[0]:
            doc = getattr(self, "_help_" + arg[0], None)
            if doc is None and self.env_check():
                cmd_mgr = AdminCommandManager(self.env)
                doc = cmd_mgr.get_command_help(arg)
            if doc:
                self.print_doc(doc)
            else:
                printerr(_("No documentation found for '%(cmd)s'."
                           " Use 'help' to see the list of commands.",
                           cmd=' '.join(arg)))
                cmds = cmd_mgr.get_similar_commands(arg[0])
                if cmds:
                    printout('')
                    printout(ngettext("Did you mean this?",
                                      "Did you mean one of these?",
                                      len(cmds)))
                    for cmd in cmds:
                        printout('    ' + cmd)
        else:
            printout(_("trac-admin - The Trac Administration Console "
                       "%(version)s", version=TRAC_VERSION))
            if not self.interactive:
                print
                printout(_("Usage: trac-admin </path/to/projenv> "
                           "[command [subcommand] [option ...]]\n")
                    )
                printout(_("Invoking trac-admin without command starts "
                           "interactive mode.\n"))
            env = self.env if self.env_check() else None
            self.print_doc(self.all_docs(env), short=True)


    ## Quit / EOF
    _help_quit = [('quit', '', 'Exit the program')]
    _help_exit = _help_quit
    _help_EOF = _help_quit

    def do_quit(self, line):
        print
        sys.exit()

    do_exit = do_quit # Alias
    do_EOF = do_quit # Alias


    ## Initenv
    _help_initenv = [
        ('initenv', '[<projectname> <db> [<repostype> <repospath>]]',
         """Create and initialize a new environment

         If no arguments are given, then the required parameters are requested
         interactively.

         One or more optional arguments --inherit=PATH can be used to specify
         the "[inherit] file" option at environment creation time, so that only
         the options not already specified in one of the global configuration
         files are written to the conf/trac.ini file of the newly created
         environment. Relative paths are resolved relative to the "conf"
         directory of the new environment.
         """)]

    def do_initdb(self, line):
        self.do_initenv(line)

    def get_initenv_args(self):
        returnvals = []
        printout(_("Creating a new Trac environment at %(envname)s",
                   envname=self.envname))
        printout(_("""
Trac will first ask a few questions about your environment
in order to initialize and prepare the project database.

 Please enter the name of your project.
 This name will be used in page titles and descriptions.
"""))
        dp = 'My Project'
        returnvals.append(raw_input(_("Project Name [%(default)s]> ",
                                      default=dp)).strip() or dp)
        printout(_("""
 Please specify the connection string for the database to use.
 By default, a local SQLite database is created in the environment
 directory. It is also possible to use an already existing
 PostgreSQL database (check the Trac documentation for the exact
 connection string syntax).
"""))
        ddb = 'sqlite:db/trac.db'
        prompt = _("Database connection string [%(default)s]> ", default=ddb)
        returnvals.append(raw_input(prompt).strip() or ddb)
        print
        return returnvals

    def do_initenv(self, line):
        def initenv_error(msg):
            printerr(_("Initenv for '%(env)s' failed.", env=self.envname),
                     "\n" + msg)
        if self.env_check():
            initenv_error(_("Does an environment already exist?"))
            return 2

        if os.path.exists(self.envname) and os.listdir(self.envname):
            initenv_error(_("Directory exists and is not empty."))
            return 2

        if not os.path.exists(os.path.dirname(self.envname)):
            initenv_error(_("Base directory '%(env)s' does not exist. Please "
                            "create it manually and retry.",
                            env=os.path.dirname(self.envname)))
            return 2

        arg = self.arg_tokenize(line)
        inherit_paths = []
        add_wiki = True
        i = 0
        while i < len(arg):
            item = arg[i]
            if item.startswith('--inherit='):
                inherit_paths.append(arg.pop(i)[10:])
            elif item.startswith('--nowiki'):
                add_wiki = False
                arg.pop(i)
            else:
                i += 1
        arg = arg or [''] # Reset to usual empty in case we popped the only one
        project_name = None
        db_str = None
        repository_type = None
        repository_dir = None
        if len(arg) == 1 and not arg[0]:
            project_name, db_str = self.get_initenv_args()
        elif len(arg) == 2:
            project_name, db_str = arg
        elif len(arg) == 4:
            project_name, db_str, repository_type, repository_dir = arg
        else:
            initenv_error('Wrong number of arguments: %d' % len(arg))
            return 2

        try:
            printout(_("Creating and Initializing Project"))
            options = [
                ('project', 'name', project_name),
                ('trac', 'database', db_str),
            ]
            if repository_dir:
                options.extend([
                    ('trac', 'repository_type', repository_type),
                    ('trac', 'repository_dir', repository_dir),
                ])
            if inherit_paths:
                options.append(('inherit', 'file',
                                ",\n      ".join(inherit_paths)))
            try:
                self.__env = Environment(self.envname, create=True,
                                         options=options)
            except Exception, e:
                initenv_error(_('Failed to create environment.'))
                printerr(e)
                traceback.print_exc()
                sys.exit(1)

            if add_wiki:
                # Add a few default wiki pages
                printout(_(" Installing default wiki pages"))
                pages_dir = pkg_resources.resource_filename('trac.wiki',
                                                            'default-pages')
                WikiAdmin(self.__env).load_pages(pages_dir)

            if repository_dir:
                try:
                    repos = RepositoryManager(self.__env).get_repository('')
                    if repos:
                        printout(_(" Indexing default repository"))
                        repos.sync(self._resync_feedback)
                except TracError, e:
                    printerr(_("""
---------------------------------------------------------------------
Warning: couldn't index the default repository.

This can happen for a variety of reasons: wrong repository type,
no appropriate third party library for this repository type,
no actual repository at the specified repository path...

You can nevertheless start using your Trac environment, but
you'll need to check again your trac.ini file and the [trac]
repository_type and repository_path settings.
"""))
        except Exception, e:
            initenv_error(to_unicode(e))
            traceback.print_exc()
            return 2

        printout(_("""
---------------------------------------------------------------------
Project environment for '%(project_name)s' created.

You may now configure the environment by editing the file:

  %(config_path)s

If you'd like to take this new project environment for a test drive,
try running the Trac standalone web server `tracd`:

  tracd --port 8000 %(project_path)s

Then point your browser to http://localhost:8000/%(project_dir)s.
There you can also browse the documentation for your installed
version of Trac, including information on further setup (such as
deploying Trac to a real web server).

The latest documentation can also always be found on the project
website:

  http://trac.edgewall.org/

Congratulations!
""", project_name=project_name, project_path=self.envname,
           project_dir=os.path.basename(self.envname),
           config_path=os.path.join(self.envname, 'conf', 'trac.ini')))

    def _resync_feedback(self, rev):
        sys.stdout.write(' [%s]\r' % rev)
        sys.stdout.flush()


class TracAdminHelpMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Display help for trac-admin commands.

    Examples:
    {{{
    [[TracAdminHelp]]               # all commands
    [[TracAdminHelp(wiki)]]         # all wiki commands
    [[TracAdminHelp(wiki export)]]  # the "wiki export" command
    [[TracAdminHelp(upgrade)]]      # the upgrade command
    }}}
    """)

    def expand_macro(self, formatter, name, content):
        if content:
            arg = content.strip().split()
            doc = getattr(TracAdmin, "_help_" + arg[0], None)
            if doc is None:
                cmd_mgr = AdminCommandManager(self.env)
                doc = cmd_mgr.get_command_help(arg)
            if not doc:
                raise TracError('Unknown trac-admin command "%s"' % content)
        else:
            doc = TracAdmin.all_docs(self.env)
        buf = StringIO.StringIO()
        TracAdmin.print_doc(doc, buf, long=True)
        return html.PRE(buf.getvalue(), class_='wiki')


def run(args=None):
    """Main entry point."""
    if args is None:
        args = sys.argv[1:]
    locale = None
    if has_babel:
        import babel
        try:
            locale = get_negotiated_locale([LANG]) or babel.Locale.default()
        except babel.UnknownLocaleError:
            pass
        translation.activate(locale)
    admin = TracAdmin()
    if len(args) > 0:
        if args[0] in ('-h', '--help', 'help'):
            return admin.onecmd(' '.join(['help'] + args[1:]))
        elif args[0] in ('-v','--version'):
            printout(os.path.basename(sys.argv[0]), TRAC_VERSION)
        else:
            env_path = os.path.abspath(args[0])
            try:
                unicode(env_path, 'ascii')
            except UnicodeDecodeError:
                printerr(_("Non-ascii environment path '%(path)s' not "
                           "supported.", path=to_unicode(env_path)))
                sys.exit(2)
            admin.env_set(env_path)
            if len(args) > 1:
                s_args = ' '.join(["'%s'" % c for c in args[2:]])
                command = args[1] + ' ' + s_args
                return admin.onecmd(command)
            else:
                while True:
                    try:
                        admin.run()
                    except KeyboardInterrupt:
                        admin.do_quit('')
    else:
        return admin.onecmd("help")


if __name__ == '__main__':
    pkg_resources.require('Trac==%s' % VERSION)
    sys.exit(run())

########NEW FILE########
__FILENAME__ = console
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Tim Moloney <t.moloney@verizon.net>

import difflib
import os
import re
import sys
import unittest
from StringIO import StringIO

# IAdminCommandProvider implementations
import trac.admin.api
import trac.attachment
import trac.perm
import trac.ticket.admin
import trac.versioncontrol.admin
import trac.versioncontrol.api
import trac.versioncontrol.web_ui
import trac.wiki.admin

# IPermissionRequestor implementations (for 'permission' related tests)
import trac.about
import trac.admin.web_ui
import trac.config
import trac.ticket.api
import trac.ticket.report
import trac.ticket.roadmap
import trac.ticket.web_ui
import trac.search.web_ui
import trac.timeline.web_ui
import trac.wiki.web_ui

from trac.admin import console, console_date_format
from trac.test import EnvironmentStub
from trac.util.datefmt import format_date, get_date_format_hint
from trac.web.tests.session import _prep_session_table

STRIP_TRAILING_SPACE = re.compile(r'( +)$', re.MULTILINE)


def load_expected_results(file, pattern):
    """Reads the file, named file, which contains test results separated by the
    regular expression pattern.

    The test results are returned as a dictionary.
    """
    expected = {}
    compiled_pattern = re.compile(pattern)
    f = open(file, 'r')
    for line in f:
        line = line.rstrip().decode('utf-8')
        match = compiled_pattern.search(line)
        if match:
            test = match.groups()[0]
            expected[test] = ''
        else:
            expected[test] += line + '\n'
    f.close()
    return expected


class TracadminTestCase(unittest.TestCase):
    """
    Tests the output of trac-admin and is meant to be used with
    .../trac/tests.py.
    """

    expected_results = load_expected_results(
            os.path.join(os.path.split(__file__)[0], 'console-tests.txt'),
            '===== (test_[^ ]+) =====')

    def setUp(self):
        self.env = EnvironmentStub(default_data=True, enable=('trac.*',),
                                   disable=('trac.tests.*',))
        self._admin = console.TracAdmin()
        self._admin.env_set('', self.env)

        # Set test date to 11th Jan 2004
        self._test_date = '2004-01-11'

    def tearDown(self):
        self.env = None

    def _execute(self, cmd, strip_trailing_space=True, input=None):
        _in = sys.stdin
        _err = sys.stderr
        _out = sys.stdout
        try:
            if input:
                sys.stdin = StringIO(input.encode('utf-8'))
                sys.stdin.encoding = 'utf-8' # fake input encoding
            sys.stderr = sys.stdout = out = StringIO()
            out.encoding = 'utf-8' # fake output encoding
            retval = None
            try:
                retval = self._admin.onecmd(cmd)
            except SystemExit:
                pass
            value = out.getvalue()
            if isinstance(value, str): # reverse what print_listing did
                value = value.decode('utf-8')
            # DEBUG: uncomment in case of `AssertionError: 0 != 2` in tests
            #if retval != 0:
            #    print>>_err, value
            if strip_trailing_space:
                return retval, STRIP_TRAILING_SPACE.sub('', value)
            else:
                return retval, value
        finally:
            sys.stdin = _in
            sys.stderr = _err
            sys.stdout = _out

    def assertEqual(self, expected_results, output):
        if not (isinstance(expected_results, basestring) and \
                isinstance(output, basestring)):
            return unittest.TestCase.assertEqual(self, expected_results, output)
        def diff():
            # Create a useful delta between the output and the expected output
            output_lines = ['%s\n' % x for x in output.split('\n')]
            expected_lines = ['%s\n' % x for x in expected_results.split('\n')]
            return ''.join(difflib.unified_diff(expected_lines, output_lines,
                                                'expected', 'actual'))
        if '[...]' in expected_results:
            m = re.match(expected_results.replace('[...]', '.*'), output,
                         re.MULTILINE)
            unittest.TestCase.assertTrue(self, m,
                                         "%r != %r\n%s" % (expected_results,
                                                           output, diff()))
        else:
            unittest.TestCase.assertEqual(self, expected_results, output,
                                          "%r != %r\n%s" % (expected_results,
                                                            output, diff()))
    # Help test

    def test_help_ok(self):
        """
        Tests the 'help' command in trac-admin.  Since the 'help' command
        has no command arguments, it is hard to call it incorrectly.  As
        a result, there is only this one test.
        """
        from trac import __version__

        test_name = sys._getframe().f_code.co_name
        d = {'version': __version__,
             'date_format_hint': get_date_format_hint()}
        expected_results = self.expected_results[test_name] % d
        rv, output = self._execute('help')
        self.assertEqual(0, rv)
        self.assertEqual(expected_results, output)

    # Attachment tests

    def test_attachment_list_empty(self):
        """
        Tests the 'attachment list' command in trac-admin, on a wiki page that
        doesn't have any attachments.
        """
        # FIXME: Additional tests should be written for the other 'attachment'
        #        commands. This requires being able to control the current
        #        time, which in turn would require centralizing the time
        #        provider, for example in the environment object.
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('attachment list wiki:WikiStart')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    # Config tests

    def test_config_get(self):
        """
        Tests the 'config get' command in trac-admin.  This particular
        test gets the project name from the config.
        """
        test_name = sys._getframe().f_code.co_name
        self.env.config.set('project', 'name', 'Test project')
        rv, output = self._execute('config get project name')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_config_set(self):
        """
        Tests the 'config set' command in trac-admin.  This particular
        test sets the project name using an option value containing a space.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('config set project name "Test project"')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)
        self.assertEqual('Test project',
                         self.env.config.get('project', 'name'))

    def test_config_remove(self):
        """
        Tests the 'config remove' command in trac-admin.  This particular
        test removes the project name from the config, therefore reverting
        the option to the default value.
        """
        test_name = sys._getframe().f_code.co_name
        self.env.config.set('project', 'name', 'Test project')
        rv, output = self._execute('config remove project name')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)
        self.assertEqual('My Project', self.env.config.get('project', 'name'))

    # Permission tests

    def test_permission_list_ok(self):
        """
        Tests the 'permission list' command in trac-admin.  Since this command
        has no command arguments, it is hard to call it incorrectly.  As
        a result, there is only this one test.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_add_one_action_ok(self):
        """
        Tests the 'permission add' command in trac-admin.  This particular
        test passes valid arguments to add one permission and checks for
        success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('permission add test_user WIKI_VIEW')
        rv, output = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_add_multiple_actions_ok(self):
        """
        Tests the 'permission add' command in trac-admin.  This particular
        test passes valid arguments to add multiple permissions and checks for
        success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('permission add test_user LOG_VIEW FILE_VIEW')
        rv, output = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_add_already_exists(self):
        """
        Tests the 'permission add' command in trac-admin.  This particular
        test passes a permission that already exists and checks for the
        message. Other permissions passed are added.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('permission add anonymous WIKI_CREATE '
                                   'WIKI_VIEW WIKI_MODIFY')
        self.assertEqual(0, rv)
        rv, output2 = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output + output2)

    def test_permission_remove_one_action_ok(self):
        """
        Tests the 'permission remove' command in trac-admin.  This particular
        test passes valid arguments to remove one permission and checks for
        success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('permission remove anonymous TICKET_MODIFY')
        rv, output = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_remove_multiple_actions_ok(self):
        """
        Tests the 'permission remove' command in trac-admin.  This particular
        test passes valid arguments to remove multiple permission and checks
        for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('permission remove anonymous WIKI_CREATE WIKI_MODIFY')
        rv, output = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_remove_all_actions_for_user(self):
        """
        Tests the 'permission remove' command in trac-admin.  This particular
        test removes all permissions for anonymous.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('permission remove anonymous *')
        rv, output = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_remove_action_for_all_users(self):
        """
        Tests the 'permission remove' command in trac-admin.  This particular
        test removes the TICKET_CREATE permission from all users.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('permission add anonymous TICKET_CREATE')
        self._execute('permission remove * TICKET_CREATE')
        rv, output = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_remove_unknown_user(self):
        """
        Tests the 'permission remove' command in trac-admin.  This particular
        test tries removing a permission from an unknown user.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('permission remove joe TICKET_VIEW')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_remove_action_not_granted(self):
        """
        Tests the 'permission remove' command in trac-admin.  This particular
        test tries removing TICKET_CREATE from user anonymous, who doesn't
        have that permission.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('permission remove anonymous TICKET_CREATE')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_export_ok(self):
        """
        Tests the 'permission export' command in trac-admin.  This particular
        test exports the default permissions to stdout.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('permission export')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_permission_import_ok(self):
        """
        Tests the 'permission import' command in trac-admin.  This particular
        test exports additional permissions, removes them and imports them back.
        """
        test_name = sys._getframe().f_code.co_name
        user = u'test_user\u0250'
        self._execute('permission add ' + user + ' WIKI_VIEW')
        self._execute('permission add ' + user + ' TICKET_VIEW')
        rv, output = self._execute('permission export')
        self._execute('permission remove ' + user + ' *')
        rv, output = self._execute('permission import', input=output)
        self.assertEqual(0, rv)
        self.assertEqual('', output)
        rv, output = self._execute('permission list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    # Component tests

    def test_component_list_ok(self):
        """
        Tests the 'component list' command in trac-admin.  Since this command
        has no command arguments, it is hard to call it incorrectly.  As
        a result, there is only this one test.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('component list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_component_add_ok(self):
        """
        Tests the 'component add' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('component add new_component new_user')
        rv, output = self._execute('component list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_component_add_error_already_exists(self):
        """
        Tests the 'component add' command in trac-admin.  This particular
        test passes a component name that already exists and checks for an
        error message.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('component add component1 new_user')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_component_rename_ok(self):
        """
        Tests the 'component rename' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('component rename component1 changed_name')
        rv, output = self._execute('component list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_component_rename_error_bad_component(self):
        """
        Tests the 'component rename' command in trac-admin.  This particular
        test tries to rename a component that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('component rename bad_component changed_name')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_component_rename_error_bad_new_name(self):
        """
        Tests the 'component rename' command in trac-admin.  This particular
        test tries to rename a component to a name that already exists.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('component rename component1 component2')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_component_chown_ok(self):
        """
        Tests the 'component chown' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('component chown component2 changed_owner')
        rv, output = self._execute('component list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_component_chown_error_bad_component(self):
        """
        Tests the 'component chown' command in trac-admin.  This particular
        test tries to change the owner of a component that does not
        exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('component chown bad_component changed_owner')
        self.assertEqual(2, rv)
        # We currently trigger a deprecation warning with py26 so we
        # can currrently only verify that the end of the output string is
        # correct
        self.assertEqual(output.endswith(self.expected_results[test_name]), True)

    def test_component_remove_ok(self):
        """
        Tests the 'component remove' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('component remove component1')
        rv, output = self._execute('component list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_component_remove_error_bad_component(self):
        """
        Tests the 'component remove' command in trac-admin.  This particular
        test tries to remove a component that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('component remove bad_component')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    # Ticket-type tests

    def test_ticket_type_list_ok(self):
        """
        Tests the 'ticket_type list' command in trac-admin.  Since this command
        has no command arguments, it is hard to call it incorrectly.  As
        a result, there is only this one test.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('ticket_type list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_add_ok(self):
        """
        Tests the 'ticket_type add' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('ticket_type add new_type')
        rv, output = self._execute('ticket_type list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_add_error_already_exists(self):
        """
        Tests the 'ticket_type add' command in trac-admin.  This particular
        test passes a ticket type that already exists and checks for an error
        message.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('ticket_type add defect')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_change_ok(self):
        """
        Tests the 'ticket_type change' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('ticket_type change defect bug')
        rv, output = self._execute('ticket_type list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_change_error_bad_type(self):
        """
        Tests the 'ticket_type change' command in trac-admin.  This particular
        test tries to change a priority that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('ticket_type change bad_type changed_type')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_change_error_bad_new_name(self):
        """
        Tests the 'ticket_type change' command in trac-admin.  This particular
        test tries to change a ticket type to another type that already exists.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('ticket_type change defect task')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_remove_ok(self):
        """
        Tests the 'ticket_type remove' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('ticket_type remove task')
        rv, output = self._execute('ticket_type list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_remove_error_bad_type(self):
        """
        Tests the 'ticket_type remove' command in trac-admin.  This particular
        test tries to remove a ticket type that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('ticket_type remove bad_type')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_order_down_ok(self):
        """
        Tests the 'ticket_type order' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('ticket_type order defect down')
        rv, output = self._execute('ticket_type list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_order_up_ok(self):
        """
        Tests the 'ticket_type order' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('ticket_type order enhancement up')
        rv, output = self._execute('ticket_type list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_ticket_type_order_error_bad_type(self):
        """
        Tests the 'priority order' command in trac-admin.  This particular
        test tries to reorder a priority that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('ticket_type order bad_type up')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    # Priority tests

    def test_priority_list_ok(self):
        """
        Tests the 'priority list' command in trac-admin.  Since this command
        has no command arguments, it is hard to call it incorrectly.  As
        a result, there is only this one test.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('priority list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_add_ok(self):
        """
        Tests the 'priority add' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('priority add new_priority')
        rv, output = self._execute('priority list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_add_many_ok(self):
        """
        Tests adding more than 10 priority values.  This makes sure that
        ordering is preserved when adding more than 10 values.
        """
        test_name = sys._getframe().f_code.co_name
        for i in xrange(11):
            self._execute('priority add p%s' % i)
        rv, output = self._execute('priority list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_add_error_already_exists(self):
        """
        Tests the 'priority add' command in trac-admin.  This particular
        test passes a priority name that already exists and checks for an
        error message.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('priority add blocker')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_change_ok(self):
        """
        Tests the 'priority change' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('priority change major normal')
        rv, output = self._execute('priority list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_change_error_bad_priority(self):
        """
        Tests the 'priority change' command in trac-admin.  This particular
        test tries to change a priority that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('priority change bad_priority changed_name')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_change_error_bad_new_name(self):
        """
        Tests the 'priority change' command in trac-admin.  This particular
        test tries to change a priority to a name that already exists.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('priority change major minor')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_remove_ok(self):
        """
        Tests the 'priority remove' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('priority remove major')
        rv, output = self._execute('priority list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_remove_error_bad_priority(self):
        """
        Tests the 'priority remove' command in trac-admin.  This particular
        test tries to remove a priority that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('priority remove bad_priority')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_order_down_ok(self):
        """
        Tests the 'priority order' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('priority order blocker down')
        rv, output = self._execute('priority list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_order_up_ok(self):
        """
        Tests the 'priority order' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('priority order critical up')
        rv, output = self._execute('priority list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_priority_order_error_bad_priority(self):
        """
        Tests the 'priority order' command in trac-admin.  This particular
        test tries to reorder a priority that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('priority remove bad_priority')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    # Severity tests

    def test_severity_list_ok(self):
        """
        Tests the 'severity list' command in trac-admin.  Since this command
        has no command arguments, it is hard to call it incorrectly.  As
        a result, there is only this one test.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('severity list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_add_ok(self):
        """
        Tests the 'severity add' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('severity add new_severity')
        rv, output = self._execute('severity list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_add_error_already_exists(self):
        """
        Tests the 'severity add' command in trac-admin.  This particular
        test passes a severity name that already exists and checks for an
        error message.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('severity add blocker')
        rv, output = self._execute('severity add blocker')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_change_ok(self):
        """
        Tests the 'severity add' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('severity add critical')
        self._execute('severity change critical "end-of-the-world"')
        rv, output = self._execute('severity list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_change_error_bad_severity(self):
        """
        Tests the 'severity change' command in trac-admin.  This particular
        test tries to change a severity that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('severity change bad_severity changed_name')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_change_error_bad_new_name(self):
        """
        Tests the 'severity change' command in trac-admin.  This particular
        test tries to change a severity to a name that already exists.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('severity add major')
        self._execute('severity add critical')
        rv, output = self._execute('severity change critical major')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_remove_ok(self):
        """
        Tests the 'severity add' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('severity remove trivial')
        rv, output = self._execute('severity list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_remove_error_bad_severity(self):
        """
        Tests the 'severity remove' command in trac-admin.  This particular
        test tries to remove a severity that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('severity remove bad_severity')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_order_down_ok(self):
        """
        Tests the 'severity order' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('severity add foo')
        self._execute('severity add bar')
        self._execute('severity order foo down')
        rv, output = self._execute('severity list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_order_up_ok(self):
        """
        Tests the 'severity order' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('severity add foo')
        self._execute('severity add bar')
        self._execute('severity order bar up')
        rv, output = self._execute('severity list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_severity_order_error_bad_severity(self):
        """
        Tests the 'severity order' command in trac-admin.  This particular
        test tries to reorder a priority that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('severity remove bad_severity')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    # Version tests

    def test_version_list_ok(self):
        """
        Tests the 'version list' command in trac-admin.  Since this command
        has no command arguments, it is hard to call it incorrectly.  As
        a result, there is only this one test.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('version list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_add_ok(self):
        """
        Tests the 'version add' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('version add 9.9 "%s"' % self._test_date)
        rv, output = self._execute('version list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_add_error_already_exists(self):
        """
        Tests the 'version add' command in trac-admin.  This particular
        test passes a version name that already exists and checks for an
        error message.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('version add 1.0 "%s"' % self._test_date)
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_rename_ok(self):
        """
        Tests the 'version rename' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('version rename 1.0 9.9')
        rv, output = self._execute('version list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_rename_error_bad_version(self):
        """
        Tests the 'version rename' command in trac-admin.  This particular
        test tries to rename a version that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('version rename bad_version changed_name')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_time_ok(self):
        """
        Tests the 'version time' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('version time 2.0 "%s"' % self._test_date)
        rv, output = self._execute('version list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_time_unset_ok(self):
        """
        Tests the 'version time' command in trac-admin.  This particular
        test passes valid arguments for unsetting the date.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('version time 2.0 "%s"' % self._test_date)
        self._execute('version time 2.0 ""')
        rv, output = self._execute('version list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_time_error_bad_version(self):
        """
        Tests the 'version time' command in trac-admin.  This particular
        test tries to change the time on a version that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('version time bad_version "%s"'
                                   % self._test_date)
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_remove_ok(self):
        """
        Tests the 'version remove' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('version remove 1.0')
        rv, output = self._execute('version list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_version_remove_error_bad_version(self):
        """
        Tests the 'version remove' command in trac-admin.  This particular
        test tries to remove a version that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('version remove bad_version')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    # Milestone tests

    def test_milestone_list_ok(self):
        """
        Tests the 'milestone list' command in trac-admin.  Since this command
        has no command arguments, it is hard to call it incorrectly.  As
        a result, there is only this one test.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('milestone list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_add_ok(self):
        """
        Tests the 'milestone add' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('milestone add new_milestone "%s"' % self._test_date)
        rv, output = self._execute('milestone list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_add_utf8_ok(self):
        """
        Tests the 'milestone add' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute(u'milestone add \xa9tat_final "%s"'  #\xc2\xa9
                              % self._test_date)
        rv, output = self._execute('milestone list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_add_error_already_exists(self):
        """
        Tests the 'milestone add' command in trac-admin.  This particular
        test passes a milestone name that already exists and checks for an
        error message.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('milestone add milestone1 "%s"'
                                   % self._test_date)
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_rename_ok(self):
        """
        Tests the 'milestone rename' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('milestone rename milestone1 changed_milestone')
        rv, output = self._execute('milestone list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_rename_error_bad_milestone(self):
        """
        Tests the 'milestone rename' command in trac-admin.  This particular
        test tries to rename a milestone that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('milestone rename bad_milestone changed_name')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_due_ok(self):
        """
        Tests the 'milestone due' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('milestone due milestone2 "%s"' % self._test_date)
        rv, output = self._execute('milestone list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_due_unset_ok(self):
        """
        Tests the 'milestone due' command in trac-admin.  This particular
        test passes valid arguments for unsetting the due date.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('milestone due milestone2 "%s"' % self._test_date)
        self._execute('milestone due milestone2 ""')
        rv, output = self._execute('milestone list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_due_error_bad_milestone(self):
        """
        Tests the 'milestone due' command in trac-admin.  This particular
        test tries to change the due date on a milestone that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('milestone due bad_milestone "%s"'
                                   % self._test_date)
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_completed_ok(self):
        """
        Tests the 'milestone completed' command in trac-admin.  This particular
        test passes valid arguments and checks for success.
        """
        test_name = sys._getframe().f_code.co_name

        self._execute('milestone completed milestone2 "%s"' % self._test_date)
        rv, output = self._execute('milestone list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_completed_error_bad_milestone(self):
        """
        Tests the 'milestone completed' command in trac-admin.  This particular
        test tries to change the completed date on a milestone that does not
        exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('milestone completed bad_milestone "%s"'
                                   % self._test_date)
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_remove_ok(self):
        """
        Tests the 'milestone remove' command in trac-admin.  This particular
        test passes a valid argument and checks for success.
        """
        test_name = sys._getframe().f_code.co_name
        self._execute('milestone remove milestone3')
        rv, output = self._execute('milestone list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_milestone_remove_error_bad_milestone(self):
        """
        Tests the 'milestone remove' command in trac-admin.  This particular
        test tries to remove a milestone that does not exist.
        """
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('milestone remove bad_milestone')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_backslash_use_ok(self):
        test_name = sys._getframe().f_code.co_name
        if self._admin.interactive:
            self._execute('version add \\')
        else:
            self._execute(r"version add '\'")
        rv, output = self._execute('version list')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_session_list_no_sessions(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session list authenticated')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_session_list_authenticated(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session list authenticated')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_session_list_anonymous(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session list anonymous')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_session_list_all(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        if self._admin.interactive:
            rv, output = self._execute("session list *")
        else:
            rv, output = self._execute("session list '*'")
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_session_list_authenticated_sid(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session list name00')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_session_list_anonymous_sid(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session list name10:0')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def test_session_list_missing_sid(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session list thisdoesntexist')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_add_missing_sid(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session add')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_add_duplicate_sid(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session add name00')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_add_sid_all(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session add john John john@example.org')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list john')
        self.assertEqual(self.expected_results[test_name]
                         % {'today': format_date(None, console_date_format)},
                         output)

    def  test_session_add_sid(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session add john')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list john')
        self.assertEqual(self.expected_results[test_name]
                         % {'today': format_date(None, console_date_format)},
                         output)

    def  test_session_add_sid_name(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session add john John')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list john')
        self.assertEqual(self.expected_results[test_name]
                         % {'today': format_date(None, console_date_format)},
                         output)

    def  test_session_set_attr_name(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session set name name00 JOHN')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list name00')
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_set_attr_email(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session set email name00 JOHN@EXAMPLE.ORG')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list name00')
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_set_attr_missing_attr(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session set')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_set_attr_missing_value(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session set name john')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_set_attr_missing_sid(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session set name')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_set_attr_nonexistent_sid(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session set name john foo')
        self.assertEqual(2, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_delete_sid(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session delete name00')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list nam00')
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_delete_missing_params(self):
        test_name = sys._getframe().f_code.co_name
        rv, output = self._execute('session delete')
        self.assertEqual(0, rv)
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_delete_anonymous(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session delete anonymous')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list *')
        self.assertEqual(self.expected_results[test_name], output)

    def test_session_delete_multiple_sids(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env)
        rv, output = self._execute('session delete name00 name01 name02 '
                                   'name03')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list *')
        self.assertEqual(self.expected_results[test_name], output)

    def  test_session_purge_age(self):
        test_name = sys._getframe().f_code.co_name
        _prep_session_table(self.env, spread_visits=True)
        rv, output = self._execute('session purge 20100112')
        self.assertEqual(0, rv)
        rv, output = self._execute('session list *')
        self.assertEqual(self.expected_results[test_name], output)


def suite():
    return unittest.makeSuite(TracadminTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = functional
#!/usr/bin/python
from trac.tests.functional import *
from trac.util.text import unicode_to_base64, unicode_from_base64

class TestBasicSettings(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Check basic settings."""
        self._tester.go_to_admin()
        tc.formvalue('modbasic', 'url', 'https://my.example.com/something')
        tc.submit()
        tc.find('https://my.example.com/something')


class TestLoggingNone(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Turn off logging."""
        # For now, we just check that it shows up.
        self._tester.go_to_admin()
        tc.follow('Logging')
        tc.find('trac.log')
        tc.formvalue('modlog', 'log_type', 'none')
        tc.submit()
        tc.find('selected="selected">None</option')


class TestLoggingToFile(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Turn logging back on."""
        # For now, we just check that it shows up.
        self._tester.go_to_admin()
        tc.follow('Logging')
        tc.find('trac.log')
        tc.formvalue('modlog', 'log_type', 'file')
        tc.formvalue('modlog', 'log_file', 'trac.log2')
        tc.formvalue('modlog', 'log_level', 'INFO')
        tc.submit()
        tc.find('selected="selected">File</option')
        tc.find('id="log_file".*value="trac.log2"')
        tc.find('selected="selected">INFO</option>')


class TestLoggingToFileNormal(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Setting logging back to normal."""
        # For now, we just check that it shows up.
        self._tester.go_to_admin()
        tc.follow('Logging')
        tc.find('trac.log')
        tc.formvalue('modlog', 'log_file', 'trac.log')
        tc.formvalue('modlog', 'log_level', 'DEBUG')
        tc.submit()
        tc.find('selected="selected">File</option')
        tc.find('id="log_file".*value="trac.log"')
        tc.find('selected="selected">DEBUG</option>')


class TestCreatePermissionGroup(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Create a permissions group"""
        self._tester.go_to_admin()
        tc.follow('Permissions')
        tc.find('Manage Permissions')
        tc.formvalue('addperm', 'gp_subject', 'somegroup')
        tc.formvalue('addperm', 'action', 'REPORT_CREATE')
        tc.submit()
        somegroup = unicode_to_base64('somegroup')
        REPORT_CREATE = unicode_to_base64('REPORT_CREATE')
        tc.find('%s:%s' % (somegroup, REPORT_CREATE))


class TestAddUserToGroup(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Add a user to a permissions group"""
        self._tester.go_to_admin()
        tc.follow('Permissions')
        tc.find('Manage Permissions')
        tc.formvalue('addsubj', 'sg_subject', 'authenticated')
        tc.formvalue('addsubj', 'sg_group', 'somegroup')
        tc.submit()
        authenticated = unicode_to_base64('authenticated')
        somegroup = unicode_to_base64('somegroup')
        tc.find('%s:%s' % (authenticated, somegroup))


class TestRemoveUserFromGroup(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Remove a user from a permissions group"""
        self._tester.go_to_admin()
        tc.follow('Permissions')
        tc.find('Manage Permissions')
        authenticated = unicode_to_base64('authenticated')
        somegroup = unicode_to_base64('somegroup')
        tc.find('%s:%s' % (authenticated, somegroup))
        tc.formvalue('revokeform', 'sel', '%s:%s' % (authenticated, somegroup))
        tc.submit()
        tc.notfind('%s:%s' % (authenticated, somegroup))


class TestRemovePermissionGroup(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Remove a permissions group"""
        self._tester.go_to_admin()
        tc.follow('Permissions')
        tc.find('Manage Permissions')
        somegroup = unicode_to_base64('somegroup')
        REPORT_CREATE = unicode_to_base64('REPORT_CREATE')
        tc.find('%s:%s' % (somegroup, REPORT_CREATE))
        tc.formvalue('revokeform', 'sel', '%s:%s' % (somegroup, REPORT_CREATE))
        tc.submit()
        tc.notfind('%s:%s' % (somegroup, REPORT_CREATE))
        tc.notfind(somegroup)


class TestPluginSettings(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Check plugin settings."""
        self._tester.go_to_admin()
        tc.follow('Plugins')
        tc.find('Manage Plugins')
        tc.find('Install Plugin')


def functionalSuite(suite=None):
    if not suite:
        import trac.tests.functional.testcases
        suite = trac.tests.functional.testcases.functionalSuite()
    suite.addTest(TestBasicSettings())
    suite.addTest(TestLoggingNone())
    suite.addTest(TestLoggingToFile())
    suite.addTest(TestLoggingToFileNormal())
    suite.addTest(TestCreatePermissionGroup())
    suite.addTest(TestAddUserToGroup())
    suite.addTest(TestRemoveUserFromGroup())
    suite.addTest(TestRemovePermissionGroup())
    suite.addTest(TestPluginSettings())
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005 Jonas Borgstrm <jonas@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.com/license.html.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>

from __future__ import with_statement

from functools import partial
import os
import pkg_resources
import re
import shutil

try:
    from babel.core import Locale
except ImportError:
    Locale = None

from genshi import HTML
from genshi.builder import tag

from trac.admin.api import IAdminPanelProvider
from trac.core import *
from trac.loader import get_plugin_info, get_plugins_dir
from trac.perm import PermissionSystem, IPermissionRequestor
from trac.util.datefmt import all_timezones
from trac.util.text import exception_to_unicode, \
                            unicode_to_base64, unicode_from_base64
from trac.util.translation import _, get_available_locales, ngettext
from trac.web import HTTPNotFound, IRequestHandler
from trac.web.chrome import add_notice, add_stylesheet, \
                            add_warning, Chrome, INavigationContributor, \
                            ITemplateProvider
from trac.wiki.formatter import format_to_html

try:
    from webadmin import IAdminPageProvider
except ImportError:
    IAdminPageProvider = None

try:
    from acct_mgr.admin import AccountManagerAdminPanel
except:
    AccountManagerAdminPanel = None


class AdminModule(Component):
    """Web administration interface provider and panel manager."""

    implements(INavigationContributor, IRequestHandler, ITemplateProvider)

    panel_providers = ExtensionPoint(IAdminPanelProvider)
    if IAdminPageProvider:
        old_providers = ExtensionPoint(IAdminPageProvider)
    else:
        old_providers = None

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'admin'

    def get_navigation_items(self, req):
        # The 'Admin' navigation item is only visible if at least one
        # admin panel is available
        panels, providers = self._get_panels(req)
        if panels:
            yield 'mainnav', 'admin', tag.a(_('Admin'), href=req.href.admin(),
                                            title=_('Administration'))

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match('/admin(?:/([^/]+)(?:/([^/]+)(?:/(.+))?)?)?$',
                         req.path_info)
        if match:
            req.args['cat_id'] = match.group(1)
            req.args['panel_id'] = match.group(2)
            req.args['path_info'] = match.group(3)
            return True

    def process_request(self, req):
        panels, providers = self._get_panels(req)
        if not panels:
            raise HTTPNotFound(_('No administration panels available'))

        def _panel_order(p1, p2):
            if p1[::2] == ('general', 'basics'):
                return -1
            elif p2[::2] == ('general', 'basics'):
                return 1
            elif p1[0] == 'general':
                if p2[0] == 'general':
                    return cmp(p1[1:], p2[1:])
                return -1
            elif p2[0] == 'general':
                if p1[0] == 'general':
                    return cmp(p1[1:], p2[1:])
                return 1
            return cmp(p1, p2)
        panels.sort(_panel_order)

        cat_id = req.args.get('cat_id') or panels[0][0]
        panel_id = req.args.get('panel_id')
        path_info = req.args.get('path_info')
        if not panel_id:
            try:
                panel_id = filter(
                            lambda panel: panel[0] == cat_id, panels)[0][2]
            except IndexError:
                raise HTTPNotFound(_('Unknown administration panel'))

        provider = providers.get((cat_id, panel_id), None)
        if not provider:
            raise HTTPNotFound(_('Unknown administration panel'))

        if hasattr(provider, 'render_admin_panel'):
            template, data = provider.render_admin_panel(req, cat_id, panel_id,
                                                         path_info)

        else: # support for legacy WebAdmin panels
            data = {}
            cstmpl, ct = provider.process_admin_request(req, cat_id, panel_id,
                                                        path_info)
            output = cstmpl.render()

            title = _("Untitled")
            for panel in panels:
                if (panel[0], panel[2]) == (cat_id, panel_id):
                    title = panel[3]

            data.update({'page_title': title, 'page_body': HTML(output)})
            template = 'admin_legacy.html'

        data.update({
            'active_cat': cat_id, 'active_panel': panel_id,
            'panel_href': partial(req.href, 'admin', cat_id, panel_id),
            'panels': [{
                'category': {'id': panel[0], 'label': panel[1]},
                'panel': {'id': panel[2], 'label': panel[3]}
            } for panel in panels]
        })

        add_stylesheet(req, 'common/css/admin.css')
        return template, data, None

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        return [pkg_resources.resource_filename('trac.admin', 'templates')]

    # Internal methods

    def _get_panels(self, req):
        """Return a list of available admin panels."""
        panels = []
        providers = {}

        for provider in self.panel_providers:
            add_provider = True
            if AccountManagerAdminPanel is not None and \
               isinstance(provider, AccountManagerAdminPanel) and \
               getattr(self.env, 'parent', None):
                add_provider = False

            if add_provider:
                p = list(provider.get_admin_panels(req) or [])
                for panel in p:
                    providers[(panel[0], panel[2])] = provider
                panels += p

        # Add panels contributed by legacy WebAdmin plugins
        if IAdminPageProvider:
            for provider in self.old_providers:
                p = list(provider.get_admin_pages(req))
                for page in p:
                    providers[(page[0], page[2])] = provider
                panels += p

        return panels, providers


def _save_config(config, req, log, notices=None):
    """Try to save the config, and display either a success notice or a
    failure warning.
    """
    try:
        config.save()
        if notices is None:
            notices = [_('Your changes have been saved.')]
        for notice in notices:
            add_notice(req, notice)
    except Exception, e:
        log.error('Error writing to trac.ini: %s', exception_to_unicode(e))
        add_warning(req, _('Error writing to trac.ini, make sure it is '
                           'writable by the web server. Your changes have '
                           'not been saved.'))


class BasicsAdminPanel(Component):

    implements(IAdminPanelProvider)

    # IAdminPanelProvider methods

    def get_admin_panels(self, req):
        if 'TRAC_ADMIN' in req.perm:
            yield ('general', _('General'), 'basics', _('Basic Settings'))

    def render_admin_panel(self, req, cat, page, path_info):
        req.perm.require('TRAC_ADMIN')

        if Locale:
            locales = [Locale.parse(locale)
                       for locale in  get_available_locales()]
            languages = sorted((str(locale), locale.display_name)
                               for locale in locales)
        else:
            locales, languages = [], []

        if req.method == 'POST':
            for option in ('name', 'url', 'descr'):
                self.config.set('project', option, req.args.get(option))

            default_timezone = req.args.get('default_timezone')
            if default_timezone not in all_timezones:
                default_timezone = ''
            self.config.set('trac', 'default_timezone', default_timezone)

            default_language = req.args.get('default_language')
            if default_language not in locales:
                default_language = ''
            self.config.set('trac', 'default_language', default_language)

            default_date_format = req.args.get('default_date_format')
            if default_date_format != 'iso8601':
                default_date_format = ''
            self.config.set('trac', 'default_date_format', default_date_format)

            _save_config(self.config, req, self.log)
            req.redirect(req.href.admin(cat, page))

        default_timezone = self.config.get('trac', 'default_timezone')
        default_language = self.config.get('trac', 'default_language')
        default_date_format = self.config.get('trac', 'default_date_format')

        data = {
            'default_timezone': default_timezone,
            'timezones': all_timezones,
            'default_language': default_language.replace('-', '_'),
            'languages': languages,
            'default_date_format': default_date_format,
        }
        Chrome(self.env).add_textarea_grips(req)
        return 'admin_basics.html', data


class LoggingAdminPanel(Component):

    implements(IAdminPanelProvider)

    # IAdminPanelProvider methods

    def get_admin_panels(self, req):
        if 'TRAC_ADMIN' in req.perm and not getattr(self.env, 'parent', None):
            yield ('general', _('General'), 'logging', _('Logging'))

    def render_admin_panel(self, req, cat, page, path_info):
        if getattr(self.env, 'parent', None):
            raise PermissionError()
        log_type = self.env.log_type
        log_level = self.env.log_level
        log_file = self.env.log_file
        log_dir = os.path.join(self.env.path, 'log')

        log_types = [
            dict(name='none', label=_('None'), selected=log_type == 'none', disabled=False),
            dict(name='stderr', label=_('Console'),
                 selected=log_type == 'stderr', disabled=False),
            dict(name='file', label=_('File'), selected=log_type == 'file',
                 disabled=False),
            dict(name='syslog', label=_('Syslog'), disabled=os.name != 'posix',
                 selected=log_type in ('unix', 'syslog')),
            dict(name='eventlog', label=_('Windows event log'),
                 disabled=os.name != 'nt',
                 selected=log_type in ('winlog', 'eventlog', 'nteventlog')),
        ]

        log_levels = ['CRITICAL', 'ERROR', 'WARNING', 'INFO', 'DEBUG']

        if req.method == 'POST':
            changed = False

            new_type = req.args.get('log_type')
            if new_type not in [t['name'] for t in log_types]:
                raise TracError(
                    _('Unknown log type %(type)s', type=new_type),
                    _('Invalid log type')
                )
            if new_type != log_type:
                self.config.set('logging', 'log_type', new_type)
                changed = True
                log_type = new_type

            if log_type == 'none':
                self.config.remove('logging', 'log_level')
                changed = True
            else:
                new_level = req.args.get('log_level')
                if new_level not in log_levels:
                    raise TracError(
                        _('Unknown log level %(level)s', level=new_level),
                        _('Invalid log level'))
                if new_level != log_level:
                    self.config.set('logging', 'log_level', new_level)
                    changed = True
                    log_level = new_level

            if log_type == 'file':
                new_file = req.args.get('log_file', 'trac.log')
                if new_file != log_file:
                    self.config.set('logging', 'log_file', new_file)
                    changed = True
                    log_file = new_file
                if not log_file:
                    raise TracError(_('You must specify a log file'),
                                    _('Missing field'))
            else:
                self.config.remove('logging', 'log_file')
                changed = True

            if changed:
                _save_config(self.config, req, self.log),
            req.redirect(req.href.admin(cat, page))

        data = {
            'type': log_type, 'types': log_types,
            'level': log_level, 'levels': log_levels,
            'file': log_file, 'dir': log_dir
        }
        return 'admin_logging.html', {'log': data}


class PermissionAdminPanel(Component):

    implements(IAdminPanelProvider, IPermissionRequestor)

    # IPermissionRequestor methods
    def get_permission_actions(self):
        actions = ['PERMISSION_GRANT', 'PERMISSION_REVOKE']
        return actions + [('PERMISSION_ADMIN', actions)]

    # IAdminPanelProvider methods
    def get_admin_panels(self, req):
        if 'PERMISSION_GRANT' in req.perm or 'PERMISSION_REVOKE' in req.perm:
            yield ('general', _('General'), 'perm', _('Permissions'))

    def render_admin_panel(self, req, cat, page, path_info):
        perm = PermissionSystem(self.env)
        all_permissions = perm.get_all_permissions()
        all_actions = perm.get_actions()

        if req.method == 'POST':
            subject = req.args.get('subject', '').strip()
            action = req.args.get('action')
            group = req.args.get('group', '').strip()

            if subject and subject.isupper() or \
                   group and group.isupper():
                raise TracError(_('All upper-cased tokens are reserved for '
                                  'permission names'))

            # Grant permission to subject
            if req.args.get('add') and subject and action:
                req.perm.require('PERMISSION_GRANT')
                if action not in all_actions:
                    raise TracError(_('Unknown action'))
                req.perm.require(action)
                if (subject, action) not in all_permissions:
                    perm.grant_permission(subject, action)
                    add_notice(req, _('The subject %(subject)s has been '
                                      'granted the permission %(action)s.',
                                      subject=subject, action=action))
                    req.redirect(req.href.admin(cat, page))
                else:
                    add_warning(req, _('The permission %(action)s was already '
                                       'granted to %(subject)s.',
                                       action=action, subject=subject))

            # Add subject to group
            elif req.args.get('add') and subject and group:
                req.perm.require('PERMISSION_GRANT')
                for action in perm.get_user_permissions(group):
                    if not action in all_actions: # plugin disabled?
                        self.env.log.warn("Adding %s to group %s: " \
                            "Permission %s unavailable, skipping perm check." \
                            % (subject, group, action))
                    else:
                        req.perm.require(action)
                if (subject, group) not in all_permissions:
                    perm.grant_permission(subject, group)
                    add_notice(req, _('The subject %(subject)s has been added '
                                      'to the group %(group)s.',
                                      subject=subject, group=group))
                    req.redirect(req.href.admin(cat, page))
                else:
                    add_warning(req, _('The subject %(subject)s was already '
                                       'added to the group %(group)s.',
                                       subject=subject, group=group))

            # Remove permissions action
            elif req.args.get('remove') and req.args.get('sel'):
                req.perm.require('PERMISSION_REVOKE')
                sel = req.args.get('sel')
                sel = sel if isinstance(sel, list) else [sel]
                for key in sel:
                    subject, action = key.split(':', 1)
                    subject = unicode_from_base64(subject)
                    action = unicode_from_base64(action)
                    if (subject, action) in perm.get_all_permissions():
                        perm.revoke_permission(subject, action)
                add_notice(req, _('The selected permissions have been '
                                  'revoked.'))
                req.redirect(req.href.admin(cat, page))

        perms = [perm for perm in all_permissions if perm[1].isupper()]
        groups = [perm for perm in all_permissions if not perm[1].isupper()]

        return 'admin_perms.html', {
            'actions': all_actions, 'perms': perms, 'groups': groups,
            'unicode_to_base64': unicode_to_base64
        }


class PluginAdminPanel(Component):

    implements(IAdminPanelProvider)

    # IAdminPanelProvider methods

    def get_admin_panels(self, req):
        if 'TRAC_ADMIN' in req.perm and not getattr(self.env, 'parent', None):
            yield ('general', _('General'), 'plugin', _('Plugins'))

    def render_admin_panel(self, req, cat, page, path_info):
        if getattr(self.env, 'parent', None):
            raise PermissionError()
        req.perm.require('TRAC_ADMIN')

        if req.method == 'POST':
            if 'install' in req.args:
                self._do_install(req)
            elif 'uninstall' in req.args:
                self._do_uninstall(req)
            else:
                self._do_update(req)
            anchor = ''
            if req.args.has_key('plugin'):
                anchor = '#no%d' % (int(req.args.get('plugin')) + 1)
            req.redirect(req.href.admin(cat, page) + anchor)

        return self._render_view(req)

    # Internal methods

    def _do_install(self, req):
        """Install a plugin."""
        if not req.args.has_key('plugin_file'):
            raise TracError(_('No file uploaded'))
        upload = req.args['plugin_file']
        if isinstance(upload, unicode) or not upload.filename:
            raise TracError(_('No file uploaded'))
        plugin_filename = upload.filename.replace('\\', '/').replace(':', '/')
        plugin_filename = os.path.basename(plugin_filename)
        if not plugin_filename:
            raise TracError(_('No file uploaded'))
        if not plugin_filename.endswith('.egg') and \
                not plugin_filename.endswith('.py'):
            raise TracError(_('Uploaded file is not a Python source file or '
                              'egg'))

        target_path = os.path.join(self.env.path, 'plugins', plugin_filename)
        if os.path.isfile(target_path):
            raise TracError(_('Plugin %(name)s already installed',
                              name=plugin_filename))

        self.log.info('Installing plugin %s', plugin_filename)
        flags = os.O_CREAT + os.O_WRONLY + os.O_EXCL
        try:
            flags += os.O_BINARY
        except AttributeError:
            # OS_BINARY not available on every platform
            pass
        with os.fdopen(os.open(target_path, flags, 0666), 'w') as target_file:
            shutil.copyfileobj(upload.file, target_file)
            self.log.info('Plugin %s installed to %s', plugin_filename,
                          target_path)
        # TODO: Validate that the uploaded file is actually a valid Trac plugin

        # Make the environment reset itself on the next request
        self.env.config.touch()

    def _do_uninstall(self, req):
        """Uninstall a plugin."""
        plugin_filename = req.args.get('plugin_filename')
        if not plugin_filename:
            return
        plugin_path = os.path.join(self.env.path, 'plugins', plugin_filename)
        if not os.path.isfile(plugin_path):
            return
        self.log.info('Uninstalling plugin %s', plugin_filename)
        os.remove(plugin_path)

        # Make the environment reset itself on the next request
        self.env.config.touch()

    def _do_update(self, req):
        """Update component enablement."""
        components = req.args.getlist('component')
        enabled = req.args.getlist('enable')
        added, removed = [], []

        # FIXME: this needs to be more intelligent and minimize multiple
        # component names to prefix rules

        for component in components:
            is_enabled = bool(self.env.is_component_enabled(component))
            must_enable = component in enabled
            if is_enabled != must_enable:
                self.config.set('components', component,
                                'disabled' if is_enabled else 'enabled')
                self.log.info('%sabling component %s',
                              'Dis' if is_enabled else 'En', component)
                if must_enable:
                    added.append(component)
                else:
                    removed.append(component)

        if added or removed:
            def make_list(items):
                parts = [item.rsplit('.', 1) for item in items]
                return tag.table(tag.tbody(
                    tag.tr(tag.td(c, class_='trac-name'),
                           tag.td('(%s.*)' % m, class_='trac-name'))
                    for m, c in parts), class_='trac-pluglist')

            added.sort()
            removed.sort()
            notices = []
            if removed:
                msg = ngettext('The following component has been disabled:',
                               'The following components have been disabled:',
                               len(removed))
                notices.append(tag(msg, make_list(removed)))
            if added:
                msg = ngettext('The following component has been enabled:',
                               'The following components have been enabled:',
                               len(added))
                notices.append(tag(msg, make_list(added)))

            _save_config(self.config, req, self.log, notices)

    def _render_view(self, req):
        plugins = get_plugin_info(self.env, include_core=True)

        def safe_wiki_to_html(context, text):
            try:
                return format_to_html(self.env, context, text)
            except Exception, e:
                self.log.error('Unable to render component documentation: %s',
                               exception_to_unicode(e, traceback=True))
                return tag.pre(text)

        data = {
            'plugins': plugins, 'show': req.args.get('show'),
            'readonly': not os.access(get_plugins_dir(self.env),
                                      os.F_OK + os.W_OK),
            'safe_wiki_to_html': safe_wiki_to_html,
        }
        return 'admin_plugins.html', data

########NEW FILE########
__FILENAME__ = attachment
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

from cStringIO import StringIO
from datetime import datetime
import errno
import os.path
import posixpath
import re
import shutil
import sys
import unicodedata

from genshi.builder import tag

from trac.admin import AdminCommandError, IAdminCommandProvider, PrefixList, \
                       console_datetime_format, get_dir_list
from trac.config import BoolOption, IntOption
from trac.core import *
from trac.mimeview import *
from trac.perm import PermissionError, IPermissionPolicy
from trac.resource import *
from trac.search import search_to_sql, shorten_result
from trac.util import content_disposition, get_reporter_id
from trac.util.compat import sha1
from trac.util.datefmt import format_datetime, from_utimestamp, \
                              to_datetime, to_utimestamp, utc
from trac.util.text import exception_to_unicode, path_to_unicode, \
                           pretty_size, print_table, unicode_unquote
from trac.util.translation import _, tag_
from trac.web import HTTPBadRequest, IRequestHandler, RequestDone
from trac.web.chrome import (INavigationContributor, add_ctxtnav, add_link,
                             add_stylesheet, web_context, add_warning)
from trac.web.href import Href
from trac.wiki.api import IWikiSyntaxProvider
from trac.wiki.formatter import format_to


class InvalidAttachment(TracError):
    """Exception raised when attachment validation fails."""


class IAttachmentChangeListener(Interface):
    """Extension point interface for components that require
    notification when attachments are created or deleted."""

    def attachment_added(attachment):
        """Called when an attachment is added."""

    def attachment_deleted(attachment):
        """Called when an attachment is deleted."""

    def attachment_reparented(attachment, old_parent_realm, old_parent_id):
        """Called when an attachment is reparented."""


class IAttachmentManipulator(Interface):
    """Extension point interface for components that need to
    manipulate attachments.

    Unlike change listeners, a manipulator can reject changes being
    committed to the database."""

    def prepare_attachment(req, attachment, fields):
        """Not currently called, but should be provided for future
        compatibility."""

    def validate_attachment(req, attachment):
        """Validate an attachment after upload but before being stored
        in Trac environment.

        Must return a list of ``(field, message)`` tuples, one for
        each problem detected. ``field`` can be any of
        ``description``, ``username``, ``filename``, ``content``, or
        `None` to indicate an overall problem with the
        attachment. Therefore, a return value of ``[]`` means
        everything is OK."""

class ILegacyAttachmentPolicyDelegate(Interface):
    """Interface that can be used by plugins to seemlessly participate
       to the legacy way of checking for attachment permissions.

       This should no longer be necessary once it becomes easier to
       setup fine-grained permissions in the default permission store.
    """

    def check_attachment_permission(action, username, resource, perm):
        """Return the usual `True`/`False`/`None` security policy
           decision appropriate for the requested action on an
           attachment.

            :param action: one of ATTACHMENT_VIEW, ATTACHMENT_CREATE,
                                  ATTACHMENT_DELETE
            :param username: the user string
            :param resource: the `~trac.resource.Resource` for the
                             attachment. Note that when
                             ATTACHMENT_CREATE is checked, the
                             resource ``.id`` will be `None`.
            :param perm: the permission cache for that username and resource
            """


class Attachment(object):

    def __init__(self, env, parent_realm_or_attachment_resource,
                 parent_id=None, filename=None, db=None):
        if isinstance(parent_realm_or_attachment_resource, Resource):
            self.resource = parent_realm_or_attachment_resource
        else:
            self.resource = Resource(parent_realm_or_attachment_resource,
                                     parent_id).child('attachment', filename)
        self.env = env
        self.parent_realm = self.resource.parent.realm
        self.parent_id = unicode(self.resource.parent.id)
        if self.resource.id:
            self._fetch(self.resource.id)
        else:
            self.filename = None
            self.description = None
            self.size = None
            self.date = None
            self.author = None
            self.ipnr = None

    def _set_filename(self, val):
        self.resource.id = val

    filename = property(lambda self: self.resource.id, _set_filename)

    def _from_database(self, filename, description, size, time, author, ipnr):
        self.filename = filename
        self.description = description
        self.size = int(size) if size else 0
        self.date = from_utimestamp(time or 0)
        self.author = author
        self.ipnr = ipnr

    def _fetch(self, filename):
        for row in self.env.db_query("""
                SELECT filename, description, size, time, author, ipnr
                FROM attachment WHERE type=%s AND id=%s AND filename=%s
                ORDER BY time
                """, (self.parent_realm, unicode(self.parent_id), filename)):
            self._from_database(*row)
            break
        else:
            self.filename = filename
            raise ResourceNotFound(_("Attachment '%(title)s' does not exist.",
                                     title=self.title),
                                   _('Invalid Attachment'))

    # _get_path() and _get_hashed_filename() are class methods so that they
    # can be used in db28.py.

    @classmethod
    def _get_path(cls, env_path, parent_realm, parent_id, filename):
        """Get the path of an attachment.

        WARNING: This method is used by db28.py for moving attachments from
        the old "attachments" directory to the "files" directory. Please check
        all changes so that they don't break the upgrade.
        """
        path = os.path.join(env_path, 'files', 'attachments',
                            parent_realm)
        hash = sha1(parent_id.encode('utf-8')).hexdigest()
        path = os.path.join(path, hash[0:3], hash)
        if filename:
            path = os.path.join(path, cls._get_hashed_filename(filename))
        return os.path.normpath(path)

    _extension_re = re.compile(r'\.[A-Za-z0-9]+\Z')

    @classmethod
    def _get_hashed_filename(cls, filename):
        """Get the hashed filename corresponding to the given filename.

        WARNING: This method is used by db28.py for moving attachments from
        the old "attachments" directory to the "files" directory. Please check
        all changes so that they don't break the upgrade.
        """
        hash = sha1(filename.encode('utf-8')).hexdigest()
        match = cls._extension_re.search(filename)
        return hash + match.group(0) if match else hash

    @property
    def path(self):
        return self._get_path(self.env.path, self.parent_realm, self.parent_id,
                              self.filename)

    @property
    def title(self):
        return '%s:%s: %s' % (self.parent_realm, self.parent_id, self.filename)

    def delete(self, db=None):
        """Delete the attachment, both the record in the database and
        the file itself.

        .. versionchanged :: 1.0
           the `db` parameter is no longer needed
           (will be removed in version 1.1.1)
        """
        assert self.filename, "Cannot delete non-existent attachment"

        with self.env.db_transaction as db:
            db("""
                DELETE FROM attachment WHERE type=%s AND id=%s AND filename=%s
                    """, (self.parent_realm, self.parent_id, self.filename))
            path = self.path
            if os.path.isfile(path):
                try:
                    os.unlink(path)
                except OSError, e:
                    self.env.log.error("Failed to delete attachment "
                                       "file %s: %s",
                                       path,
                                       exception_to_unicode(e, traceback=True))
                    raise TracError(_("Could not delete attachment"))

        self.env.log.info("Attachment removed: %s" % self.title)

        for listener in AttachmentModule(self.env).change_listeners:
            listener.attachment_deleted(self)
        ResourceSystem(self.env).resource_deleted(self)

    def reparent(self, new_realm, new_id):
        assert self.filename, "Cannot reparent non-existent attachment"
        new_id = unicode(new_id)
        new_path = self._get_path(self.env.path, new_realm, new_id,
                                  self.filename)

        # Make sure the path to the attachment is inside the environment
        # attachments directory
        attachments_dir = os.path.join(os.path.normpath(self.env.path),
                                       'files', 'attachments')
        commonprefix = os.path.commonprefix([attachments_dir, new_path])
        if commonprefix != attachments_dir:
            raise TracError(_('Cannot reparent attachment "%(att)s" as '
                              '%(realm)s:%(id)s is invalid',
                              att=self.filename, realm=new_realm, id=new_id))

        if os.path.exists(new_path):
            raise TracError(_('Cannot reparent attachment "%(att)s" as '
                              'it already exists in %(realm)s:%(id)s',
                              att=self.filename, realm=new_realm, id=new_id))
        with self.env.db_transaction as db:
            db("""UPDATE attachment SET type=%s, id=%s
                  WHERE type=%s AND id=%s AND filename=%s
                  """, (new_realm, new_id, self.parent_realm, self.parent_id,
                        self.filename))
            dirname = os.path.dirname(new_path)
            if not os.path.exists(dirname):
                os.makedirs(dirname)
            path = self.path
            if os.path.isfile(path):
                try:
                    os.rename(path, new_path)
                except OSError, e:
                    self.env.log.error("Failed to move attachment file %s: %s",
                                       path,
                                       exception_to_unicode(e, traceback=True))
                    raise TracError(_("Could not reparent attachment %(name)s",
                                      name=self.filename))

        old_realm, old_id = self.parent_realm, self.parent_id
        self.parent_realm, self.parent_id = new_realm, new_id
        self.resource = Resource(new_realm, new_id).child('attachment',
                                                          self.filename)

        self.env.log.info("Attachment reparented: %s" % self.title)

        for listener in AttachmentModule(self.env).change_listeners:
            if hasattr(listener, 'attachment_reparented'):
                listener.attachment_reparented(self, old_realm, old_id)
        old_values = dict()
        if self.parent_realm != old_realm:
            old_values["parent_realm"] = old_realm
        if self.parent_id != old_id:
            old_values["parent_id"] = old_id
        ResourceSystem(self.env).resource_changed(self, old_values=old_values)

    def insert(self, filename, fileobj, size, t=None, db=None):
        """Create a new Attachment record and save the file content.

        .. versionchanged :: 1.0
           the `db` parameter is no longer needed
           (will be removed in version 1.1.1)
        """
        self.size = int(size) if size else 0
        self.filename = None
        if t is None:
            t = datetime.now(utc)
        elif not isinstance(t, datetime): # Compatibility with 0.11
            t = to_datetime(t, utc)
        self.date = t

        # Make sure the path to the attachment is inside the environment
        # attachments directory
        attachments_dir = os.path.join(os.path.normpath(self.env.path),
                                       'files', 'attachments')
        dir = self.path
        commonprefix = os.path.commonprefix([attachments_dir, dir])
        if commonprefix != attachments_dir:
            raise TracError(_('Cannot create attachment "%(att)s" as '
                              '%(realm)s:%(id)s is invalid',
                              att=filename, realm=self.parent_realm,
                              id=self.parent_id))

        if not os.access(dir, os.F_OK):
            os.makedirs(dir)
        filename, targetfile = self._create_unique_file(dir, filename)
        with targetfile:
            with self.env.db_transaction as db:
                db("INSERT INTO attachment VALUES (%s,%s,%s,%s,%s,%s,%s,%s)",
                   (self.parent_realm, self.parent_id, filename, self.size,
                    to_utimestamp(t), self.description, self.author,
                    self.ipnr))
                shutil.copyfileobj(fileobj, targetfile)
                self.resource.id = self.filename = filename

                self.env.log.info("New attachment: %s by %s", self.title,
                                  self.author)

        for listener in AttachmentModule(self.env).change_listeners:
            listener.attachment_added(self)
        ResourceSystem(self.env).resource_created(self)


    @classmethod
    def select(cls, env, parent_realm, parent_id, db=None):
        """Iterator yielding all `Attachment` instances attached to
        resource identified by `parent_realm` and `parent_id`.

        .. versionchanged :: 1.0
           the `db` parameter is no longer needed
           (will be removed in version 1.1.1)
        """
        for row in env.db_query("""
                SELECT filename, description, size, time, author, ipnr
                FROM attachment WHERE type=%s AND id=%s ORDER BY time
                """, (parent_realm, unicode(parent_id))):
            attachment = Attachment(env, parent_realm, parent_id)
            attachment._from_database(*row)
            yield attachment

    @classmethod
    def delete_all(cls, env, parent_realm, parent_id, db=None):
        """Delete all attachments of a given resource.

        .. versionchanged :: 1.0
           the `db` parameter is no longer needed
           (will be removed in version 1.1.1)
        """
        attachment_dir = None
        with env.db_transaction as db:
            for attachment in cls.select(env, parent_realm, parent_id, db):
                attachment_dir = os.path.dirname(attachment.path)
                attachment.delete()
        if attachment_dir:
            try:
                os.rmdir(attachment_dir)
            except OSError, e:
                env.log.error("Can't delete attachment directory %s: %s",
                    attachment_dir, exception_to_unicode(e, traceback=True))

    @classmethod
    def reparent_all(cls, env, parent_realm, parent_id, new_realm, new_id):
        """Reparent all attachments of a given resource to another resource."""
        attachment_dir = None
        with env.db_transaction as db:
            for attachment in list(cls.select(env, parent_realm, parent_id,
                                              db)):
                attachment_dir = os.path.dirname(attachment.path)
                attachment.reparent(new_realm, new_id)
        if attachment_dir:
            try:
                os.rmdir(attachment_dir)
            except OSError, e:
                env.log.error("Can't delete attachment directory %s: %s",
                    attachment_dir, exception_to_unicode(e, traceback=True))

    def open(self):
        path = self.path
        self.env.log.debug('Trying to open attachment at %s', path)
        try:
            fd = open(path, 'rb')
        except IOError:
            raise ResourceNotFound(_("Attachment '%(filename)s' not found",
                                     filename=self.filename))
        return fd

    def _create_unique_file(self, dir, filename):
        parts = os.path.splitext(filename)
        flags = os.O_CREAT + os.O_WRONLY + os.O_EXCL
        if hasattr(os, 'O_BINARY'):
            flags += os.O_BINARY
        idx = 1
        while 1:
            path = os.path.join(dir, self._get_hashed_filename(filename))
            try:
                return filename, os.fdopen(os.open(path, flags, 0666), 'w')
            except OSError, e:
                if e.errno != errno.EEXIST:
                    raise
                idx += 1
                # A sanity check
                if idx > 100:
                    raise Exception('Failed to create unique name: ' + path)
                filename = '%s.%d%s' % (parts[0], idx, parts[1])


class AttachmentModule(Component):

    implements(IRequestHandler, INavigationContributor, IWikiSyntaxProvider,
               IResourceManager)

    change_listeners = ExtensionPoint(IAttachmentChangeListener)
    manipulators = ExtensionPoint(IAttachmentManipulator)

    CHUNK_SIZE = 4096

    max_size = IntOption('attachment', 'max_size', 262144,
        """Maximum allowed file size (in bytes) for ticket and wiki
        attachments.""")

    max_zip_size = IntOption('attachment', 'max_zip_size', 2097152,
        """Maximum allowed total size (in bytes) for an attachment list to be
        downloadable as a `.zip`. Set this to -1 to disable download as `.zip`.
        (''since 1.0'')""")

    render_unsafe_content = BoolOption('attachment', 'render_unsafe_content',
                                       'false',
        """Whether attachments should be rendered in the browser, or
        only made downloadable.

        Pretty much any file may be interpreted as HTML by the browser,
        which allows a malicious user to attach a file containing cross-site
        scripting attacks.

        For public sites where anonymous users can create attachments it is
        recommended to leave this option disabled (which is the default).""")

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return req.args.get('realm')

    def get_navigation_items(self, req):
        return []

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/(raw-|zip-)?attachment/([^/]+)(?:/(.*))?$',
                         req.path_info)
        if match:
            format, realm, path = match.groups()
            if format:
                req.args['format'] = format[:-1]
            req.args['realm'] = realm
            if path:
                req.args['path'] = path
            return True

    def process_request(self, req):
        parent_id = None
        parent_realm = req.args.get('realm')
        path = req.args.get('path')
        filename = None

        if not parent_realm or not path:
            raise HTTPBadRequest(_('Bad request'))

        parent_realm = Resource(parent_realm)
        action = req.args.get('action', 'view')
        if action == 'new':
            parent_id = path.rstrip('/')
        else:
            last_slash = path.rfind('/')
            if last_slash == -1:
                parent_id, filename = path, ''
            else:
                parent_id, filename = path[:last_slash], path[last_slash + 1:]

        parent = parent_realm(id=parent_id)

        # Link the attachment page to parent resource
        parent_name = get_resource_name(self.env, parent)
        parent_url = get_resource_url(self.env, parent, req.href)
        add_link(req, 'up', parent_url, parent_name)
        add_ctxtnav(req, _('Back to %(parent)s', parent=parent_name),
                    parent_url)

        if not filename: # there's a trailing '/'
            if req.args.get('format') == 'zip':
                self._download_as_zip(req, parent)
            elif action != 'new':
                return self._render_list(req, parent)

        attachment = Attachment(self.env, parent.child('attachment', filename))

        if req.method == 'POST':
            if action == 'new':
                data = self._do_save(req, attachment)
            elif action == 'delete':
                self._do_delete(req, attachment)
        elif action == 'delete':
            data = self._render_confirm_delete(req, attachment)
        elif action == 'new':
            data = self._render_form(req, attachment)
        else:
            data = self._render_view(req, attachment)

        add_stylesheet(req, 'common/css/code.css')
        return 'attachment.html', data, None

    # IWikiSyntaxProvider methods

    def get_wiki_syntax(self):
        return []

    def get_link_resolvers(self):
        yield ('raw-attachment', self._format_link)
        yield ('attachment', self._format_link)

    # Public methods

    def viewable_attachments(self, context):
        """Return the list of viewable attachments in the given context.

        :param context: the `~trac.mimeview.api.RenderingContext`
                        corresponding to the parent
                        `~trac.resource.Resource` for the attachments
        """
        parent = context.resource
        attachments = []
        for attachment in Attachment.select(self.env, parent.realm, parent.id):
            if 'ATTACHMENT_VIEW' in context.perm(attachment.resource):
                attachments.append(attachment)
        return attachments

    def attachment_data(self, context):
        """Return a data dictionary describing the list of viewable
        attachments in the current context.
        """
        attachments = self.viewable_attachments(context)
        parent = context.resource
        total_size = sum(attachment.size for attachment in attachments)
        new_att = parent.child('attachment')
        return {'attach_href': get_resource_url(self.env, new_att,
                                                context.href),
                'download_href': get_resource_url(self.env, new_att,
                                                  context.href, format='zip')
                                 if total_size <= self.max_zip_size else None,
                'can_create': 'ATTACHMENT_CREATE' in context.perm(new_att),
                'attachments': attachments,
                'parent': context.resource}

    def get_history(self, start, stop, realm):
        """Return an iterable of tuples describing changes to attachments on
        a particular object realm.

        The tuples are in the form (change, realm, id, filename, time,
        description, author). `change` can currently only be `created`.

        FIXME: no iterator
        """
        for realm, id, filename, ts, description, author in \
                self.env.db_query("""
                SELECT type, id, filename, time, description, author
                FROM attachment WHERE time > %s AND time < %s AND type = %s
                """, (to_utimestamp(start), to_utimestamp(stop), realm)):
            time = from_utimestamp(ts or 0)
            yield ('created', realm, id, filename, time, description, author)

    def get_timeline_events(self, req, resource_realm, start, stop):
        """Return an event generator suitable for ITimelineEventProvider.

        Events are changes to attachments on resources of the given
        `resource_realm.realm`.
        """
        for change, realm, id, filename, time, descr, author in \
                self.get_history(start, stop, resource_realm.realm):
            attachment = resource_realm(id=id).child('attachment', filename)
            if 'ATTACHMENT_VIEW' in req.perm(attachment):
                yield ('attachment', time, author, (attachment, descr), self)

    def render_timeline_event(self, context, field, event):
        attachment, descr = event[3]
        if field == 'url':
            return self.get_resource_url(attachment, context.href)
        elif field == 'title':
            name = get_resource_name(self.env, attachment.parent)
            title = get_resource_summary(self.env, attachment.parent)
            return tag_("%(attachment)s attached to %(resource)s",
                        attachment=tag.em(os.path.basename(attachment.id)),
                        resource=tag.em(name, title=title))
        elif field == 'description':
            return format_to(self.env, None, context.child(attachment.parent),
                             descr)

    def get_search_results(self, req, resource_realm, terms):
        """Return a search result generator suitable for ISearchSource.

        Search results are attachments on resources of the given
        `resource_realm.realm` whose filename, description or author match
        the given terms.
        """
        with self.env.db_query as db:
            sql_query, args = search_to_sql(
                    db, ['filename', 'description', 'author'], terms)
            for id, time, filename, desc, author in db("""
                    SELECT id, time, filename, description, author
                    FROM attachment WHERE type = %s AND """ + sql_query,
                    (resource_realm.realm,) + args):
                attachment = resource_realm(id=id).child('attachment', filename)
                if 'ATTACHMENT_VIEW' in req.perm(attachment):
                    yield (get_resource_url(self.env, attachment, req.href),
                           get_resource_shortname(self.env, attachment),
                           from_utimestamp(time), author,
                           shorten_result(desc, terms))

    # IResourceManager methods

    def get_resource_realms(self):
        yield 'attachment'

    def get_resource_url(self, resource, href, **kwargs):
        """Return an URL to the attachment itself.

        A `format` keyword argument equal to `'raw'` will be converted
        to the raw-attachment prefix.
        """
        if not resource.parent:
            return None
        format = kwargs.get('format')
        prefix = 'attachment'
        if format in ('raw', 'zip'):
            kwargs.pop('format')
            prefix = format + '-attachment'
        parent_href = unicode_unquote(get_resource_url(self.env,
                            resource.parent(version=None), Href('')))
        if not resource.id:
            # link to list of attachments, which must end with a trailing '/'
            # (see process_request)
            return href(prefix, parent_href, '', **kwargs)
        else:
            return href(prefix, parent_href, resource.id, **kwargs)

    def get_resource_description(self, resource, format=None, **kwargs):
        if not resource.parent:
            return _("Unparented attachment %(id)s", id=resource.id)
        nbhprefix = ResourceSystem(self.env).neighborhood_prefix(
                resource.neighborhood)
        if format == 'compact':
            return '%s%s (%s)' % (nbhprefix, resource.id,
                    get_resource_name(self.env, resource.parent))
        elif format == 'summary':
            return Attachment(self.env, resource).description
        if resource.id:
            desc = _("Attachment '%(id)s' in %(parent)s", id=resource.id,
                     parent=get_resource_name(self.env, resource.parent))
        else:
            desc = _("Attachments of %(parent)s",
                     parent=get_resource_name(self.env, resource.parent))
        if resource.neighborhood is not None:
            desc = nbhprefix + desc
        return desc

    def resource_exists(self, resource):
        try:
            attachment = Attachment(self.env, resource)
            return os.path.exists(attachment.path)
        except ResourceNotFound:
            return False

    # Internal methods

    def _do_save(self, req, attachment):
        req.perm(attachment.resource).require('ATTACHMENT_CREATE')
        parent_resource = attachment.resource.parent
        if not resource_exists(self.env, parent_resource):
            raise ResourceNotFound(
                _("%(parent)s doesn't exist, can't create attachment",
                  parent=get_resource_name(self.env, parent_resource)))

        if 'cancel' in req.args:
            req.redirect(get_resource_url(self.env, parent_resource, req.href))

        upload = req.args['attachment']
        if not hasattr(upload, 'filename') or not upload.filename:
            raise TracError(_('No file uploaded'))
        if hasattr(upload.file, 'fileno'):
            size = os.fstat(upload.file.fileno())[6]
        else:
            upload.file.seek(0, 2) # seek to end of file
            size = upload.file.tell()
            upload.file.seek(0)
        if size == 0:
            raise TracError(_("Can't upload empty file"))

        # Maximum attachment size (in bytes)
        max_size = self.max_size
        if max_size >= 0 and size > max_size:
            raise TracError(_('Maximum attachment size: %(num)s bytes',
                              num=max_size), _('Upload failed'))

        # We try to normalize the filename to unicode NFC if we can.
        # Files uploaded from OS X might be in NFD.
        filename = unicodedata.normalize('NFC', unicode(upload.filename,
                                                        'utf-8'))
        filename = filename.strip()
        # Replace backslashes with slashes if filename is Windows full path
        if filename.startswith('\\') or re.match(r'[A-Za-z]:\\', filename):
            filename = filename.replace('\\', '/')
        # We want basename to be delimited by only slashes on all platforms
        filename = posixpath.basename(filename)
        if not filename:
            raise TracError(_('No file uploaded'))
        # Now the filename is known, update the attachment resource
        attachment.filename = filename
        attachment.description = req.args.get('description', '')
        attachment.author = get_reporter_id(req, 'author')
        attachment.ipnr = req.remote_addr

        # Validate attachment
        valid = True
        for manipulator in self.manipulators:
            for field, message in manipulator.validate_attachment(req,
                                                                  attachment):
                valid = False
                if field:
                    add_warning(req,
                        _('Attachment field %(field)s is invalid: %(message)s',
                          field=field, message=message))
                else:
                    add_warning(req,
                        _('Invalid attachment: %(message)s', message=message))
        if not valid:
            # Display the attach form with pre-existing data
            # NOTE: Local file path not known, file field cannot be repopulated
            add_warning(req, _('Note: File must be selected again.'))
            data = self._render_form(req, attachment)
            data['is_replace'] = req.args.get('replace')
            return data

        if req.args.get('replace'):
            try:
                old_attachment = Attachment(self.env,
                                            attachment.resource(id=filename))
                if not (req.authname and req.authname != 'anonymous' \
                        and old_attachment.author == req.authname) \
                   and 'ATTACHMENT_DELETE' \
                                        not in req.perm(attachment.resource):
                    raise PermissionError(msg=_("You don't have permission to "
                        "replace the attachment %(name)s. You can only "
                        "replace your own attachments. Replacing other's "
                        "attachments requires ATTACHMENT_DELETE permission.",
                        name=filename))
                if (not attachment.description.strip() and
                    old_attachment.description):
                    attachment.description = old_attachment.description
                old_attachment.delete()
            except TracError:
                pass # don't worry if there's nothing to replace
        attachment.insert(filename, upload.file, size)

        req.redirect(get_resource_url(self.env, attachment.resource(id=None),
                                      req.href))

    def _do_delete(self, req, attachment):
        req.perm(attachment.resource).require('ATTACHMENT_DELETE')

        parent_href = get_resource_url(self.env, attachment.resource.parent,
                                       req.href)
        if 'cancel' in req.args:
            req.redirect(parent_href)

        attachment.delete()
        req.redirect(parent_href)

    def _render_confirm_delete(self, req, attachment):
        req.perm(attachment.resource).require('ATTACHMENT_DELETE')
        return {'mode': 'delete',
                'title': _('%(attachment)s (delete)',
                           attachment=get_resource_name(self.env,
                                                        attachment.resource)),
                'attachment': attachment}

    def _render_form(self, req, attachment):
        req.perm(attachment.resource).require('ATTACHMENT_CREATE')
        return {'mode': 'new', 'author': get_reporter_id(req),
            'attachment': attachment, 'max_size': self.max_size}

    def _download_as_zip(self, req, parent, attachments=None):
        if attachments is None:
            attachments = self.viewable_attachments(web_context(req, parent))
        total_size = sum(attachment.size for attachment in attachments)
        if total_size > self.max_zip_size:
            raise TracError(_("Maximum total attachment size: %(num)s bytes",
                              num=self.max_zip_size), _("Download failed"))

        req.send_response(200)
        req.send_header('Content-Type', 'application/zip')
        filename = 'attachments-%s-%s.zip' % \
                   (parent.realm, re.sub(r'[/\\:]', '-', unicode(parent.id)))
        req.send_header('Content-Disposition',
                        content_disposition('inline', filename))

        from zipfile import ZipFile, ZipInfo, ZIP_DEFLATED

        buf = StringIO()
        zipfile = ZipFile(buf, 'w', ZIP_DEFLATED)
        for attachment in attachments:
            zipinfo = ZipInfo()
            zipinfo.filename = attachment.filename.encode('utf-8')
            zipinfo.flag_bits |= 0x800 # filename is encoded with utf-8
            zipinfo.date_time = attachment.date.utctimetuple()[:6]
            zipinfo.compress_type = ZIP_DEFLATED
            if attachment.description:
                zipinfo.comment = attachment.description.encode('utf-8')
            zipinfo.external_attr = 0644 << 16L # needed since Python 2.5
            try:
                with attachment.open() as fd:
                    zipfile.writestr(zipinfo, fd.read())
            except ResourceNotFound:
                pass # skip missing files
        zipfile.close()

        zip_str = buf.getvalue()
        req.send_header("Content-Length", len(zip_str))
        req.end_headers()
        req.write(zip_str)
        raise RequestDone()

    def _render_list(self, req, parent):
        data = {
            'mode': 'list',
            'attachment': None, # no specific attachment
            'attachments': self.attachment_data(web_context(req, parent))
        }

        return 'attachment.html', data, None

    def _render_view(self, req, attachment):
        req.perm(attachment.resource).require('ATTACHMENT_VIEW')
        can_delete = 'ATTACHMENT_DELETE' in req.perm(attachment.resource)
        req.check_modified(attachment.date, str(can_delete))

        data = {'mode': 'view',
                'title': get_resource_name(self.env, attachment.resource),
                'attachment': attachment}

        with attachment.open() as fd:
            mimeview = Mimeview(self.env)

            # MIME type detection
            str_data = fd.read(1000)
            fd.seek(0)

            mime_type = mimeview.get_mimetype(attachment.filename, str_data)

            # Eventually send the file directly
            format = req.args.get('format')
            if format == 'zip':
                self._download_as_zip(req, attachment.resource.parent,
                                      [attachment])
            elif format in ('raw', 'txt'):
                if not self.render_unsafe_content:
                    # Force browser to download files instead of rendering
                    # them, since they might contain malicious code enabling
                    # XSS attacks
                    req.send_header('Content-Disposition', 'attachment')
                if format == 'txt':
                    mime_type = 'text/plain'
                elif not mime_type:
                    mime_type = 'application/octet-stream'
                if 'charset=' not in mime_type:
                    charset = mimeview.get_charset(str_data, mime_type)
                    mime_type = mime_type + '; charset=' + charset
                req.send_file(attachment.path, mime_type)

            # add ''Plain Text'' alternate link if needed
            if (self.render_unsafe_content and
                mime_type and not mime_type.startswith('text/plain')):
                plaintext_href = get_resource_url(self.env,
                                                  attachment.resource,
                                                  req.href, format='txt')
                add_link(req, 'alternate', plaintext_href, _('Plain Text'),
                         mime_type)

            # add ''Original Format'' alternate link (always)
            raw_href = get_resource_url(self.env, attachment.resource,
                                        req.href, format='raw')
            add_link(req, 'alternate', raw_href, _('Original Format'),
                     mime_type)

            self.log.debug("Rendering preview of file %s with mime-type %s"
                           % (attachment.filename, mime_type))

            data['preview'] = mimeview.preview_data(
                web_context(req, attachment.resource), fd,
                os.fstat(fd.fileno()).st_size, mime_type,
                attachment.filename, raw_href, annotations=['lineno'])
            return data

    def _format_link(self, formatter, ns, target, label):
        link, params, fragment = formatter.split_link(target)
        ids = link.split(':', 2)
        attachment = None
        if len(ids) == 3:
            known_realms = ResourceSystem(self.env).get_known_realms()
            # new-style attachment: TracLinks (filename:realm:id)
            if ids[1] in known_realms:
                attachment = Resource(ids[1], ids[2]).child('attachment',
                                                            ids[0])
            else: # try old-style attachment: TracLinks (realm:id:filename)
                if ids[0] in known_realms:
                    attachment = Resource(ids[0], ids[1]).child('attachment',
                                                                ids[2])
        else: # local attachment: TracLinks (filename)
            attachment = formatter.resource.child('attachment', link)
        if attachment and 'ATTACHMENT_VIEW' in formatter.perm(attachment):
            try:
                model = Attachment(self.env, attachment)
                raw_href = get_resource_url(self.env, attachment,
                                            formatter.href, format='raw')
                if ns.startswith('raw'):
                    return tag.a(label, class_='attachment',
                                 href=raw_href + params,
                                 title=get_resource_name(self.env, attachment))
                href = get_resource_url(self.env, attachment, formatter.href)
                title = get_resource_name(self.env, attachment)
                return tag(tag.a(label, class_='attachment', title=title,
                                 href=href + params),
                           tag.a(u'\u200b', class_='trac-rawlink',
                                 href=raw_href + params, title=_("Download")))
            except ResourceNotFound:
                pass
            # FIXME: should be either:
            #
            # model = Attachment(self.env, attachment)
            # if model.exists:
            #     ...
            #
            # or directly:
            #
            # if attachment.exists:
            #
            # (related to #4130)
        return tag.a(label, class_='missing attachment')


class LegacyAttachmentPolicy(Component):

    implements(IPermissionPolicy)

    delegates = ExtensionPoint(ILegacyAttachmentPolicyDelegate)

    # IPermissionPolicy methods

    _perm_maps = {
        'ATTACHMENT_CREATE': {'ticket': 'TICKET_APPEND', 'wiki': 'WIKI_MODIFY',
                              'milestone': 'MILESTONE_MODIFY'},
        'ATTACHMENT_VIEW': {'ticket': 'TICKET_VIEW', 'wiki': 'WIKI_VIEW',
                            'milestone': 'MILESTONE_VIEW'},
        'ATTACHMENT_DELETE': {'ticket': 'TICKET_ADMIN', 'wiki': 'WIKI_DELETE',
                              'milestone': 'MILESTONE_DELETE'},
    }

    def check_permission(self, action, username, resource, perm):
        perm_map = self._perm_maps.get(action)
        if not perm_map or not resource or resource.realm != 'attachment':
            return
        legacy_action = perm_map.get(resource.parent.realm)
        if legacy_action:
            decision = legacy_action in perm(resource.parent)
            if not decision:
                self.log.debug('LegacyAttachmentPolicy denied %s access to '
                               '%s. User needs %s' %
                               (username, resource, legacy_action))
            return decision
        else:
            for d in self.delegates:
                decision = d.check_attachment_permission(action, username,
                        resource, perm)
                if decision is not None:
                    return decision


class AttachmentAdmin(Component):
    """trac-admin command provider for attachment administration."""

    implements(IAdminCommandProvider)

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('attachment list', '<realm:id>',
               """List attachments of a resource

               The resource is identified by its realm and identifier.""",
               self._complete_list, self._do_list)
        yield ('attachment add', '<realm:id> <path> [author] [description]',
               """Attach a file to a resource

               The resource is identified by its realm and identifier. The
               attachment will be named according to the base name of the file.
               """,
               self._complete_add, self._do_add)
        yield ('attachment remove', '<realm:id> <name>',
               """Remove an attachment from a resource

               The resource is identified by its realm and identifier.""",
               self._complete_remove, self._do_remove)
        yield ('attachment export', '<realm:id> <name> [destination]',
               """Export an attachment from a resource to a file or stdout

               The resource is identified by its realm and identifier. If no
               destination is specified, the attachment is output to stdout.
               """,
               self._complete_export, self._do_export)

    def get_realm_list(self):
        rs = ResourceSystem(self.env)
        return PrefixList([each + ":" for each in rs.get_known_realms()])

    def split_resource(self, resource):
        result = resource.split(':', 1)
        if len(result) != 2:
            raise AdminCommandError(_("Invalid resource identifier '%(id)s'",
                                      id=resource))
        return result

    def get_attachment_list(self, resource):
        (realm, id) = self.split_resource(resource)
        return [a.filename for a in Attachment.select(self.env, realm, id)]

    def _complete_list(self, args):
        if len(args) == 1:
            return self.get_realm_list()

    def _complete_add(self, args):
        if len(args) == 1:
            return self.get_realm_list()
        elif len(args) == 2:
            return get_dir_list(args[1])

    def _complete_remove(self, args):
        if len(args) == 1:
            return self.get_realm_list()
        elif len(args) == 2:
            return self.get_attachment_list(args[0])

    def _complete_export(self, args):
        if len(args) < 3:
            return self._complete_remove(args)
        elif len(args) == 3:
            return get_dir_list(args[2])

    def _do_list(self, resource):
        (realm, id) = self.split_resource(resource)
        print_table([(a.filename, pretty_size(a.size), a.author,
                      format_datetime(a.date, console_datetime_format),
                      a.description)
                     for a in Attachment.select(self.env, realm, id)],
                    [_('Name'), _('Size'), _('Author'), _('Date'),
                     _('Description')])

    def _do_add(self, resource, path, author='trac', description=''):
        (realm, id) = self.split_resource(resource)
        attachment = Attachment(self.env, realm, id)
        attachment.author = author
        attachment.description = description
        with open(path, 'rb') as f:
            attachment.insert(os.path.basename(path), f, os.path.getsize(path))

    def _do_remove(self, resource, name):
        (realm, id) = self.split_resource(resource)
        attachment = Attachment(self.env, realm, id, name)
        attachment.delete()

    def _do_export(self, resource, name, destination=None):
        (realm, id) = self.split_resource(resource)
        attachment = Attachment(self.env, realm, id, name)
        if destination is not None:
            if os.path.isdir(destination):
                destination = os.path.join(destination, name)
            if os.path.isfile(destination):
                raise AdminCommandError(_("File '%(name)s' exists",
                                          name=path_to_unicode(destination)))
        with attachment.open() as input:
            output = open(destination, "wb") if destination is not None \
                     else sys.stdout
            try:
                shutil.copyfileobj(input, output)
            finally:
                if destination is not None:
                    output.close()


########NEW FILE########
__FILENAME__ = cache
# -*- coding: utf-8 -*-
#
# Copyright (C) 2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.com/license.html.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/.

from __future__ import with_statement

from .core import Component
from .util import arity
from .util.concurrency import ThreadLocal, threading

__all__ = ['CacheManager', 'cached']


_id_to_key = {}

def key_to_id(s):
    """Return a hash of the given property key."""
    # This is almost the same algorithm as Python's string hash,
    # except we only keep a 31-bit result.
    result = ord(s[0]) << 7 if s else 0
    for c in s:
        result = ((1000003 * result) & 0x7fffffff) ^ ord(c)
    result ^= len(s)
    _id_to_key[result] = s
    return result


class CachedPropertyBase(object):
    """Base class for cached property descriptors"""

    def __init__(self, retriever):
        self.retriever = retriever
        self.__doc__ = retriever.__doc__

    def make_key(self, cls):
        attr = self.retriever.__name__
        for base in cls.mro():
            if base.__dict__.get(attr) is self:
                cls = base
                break
        return '%s.%s.%s' % (cls.__module__, cls.__name__, attr)


class CachedSingletonProperty(CachedPropertyBase):
    """Cached property descriptor for classes behaving as singletons
    in the scope of one `~trac.env.Environment` instance.

    This means there will be no more than one cache to monitor in the
    database for this kind of cache. Therefore, using only "static"
    information for the key is enough. For the same reason it is also
    safe to store the corresponding id as a property of the descriptor
    instance.
    """

    def __get__(self, instance, owner):
        if instance is None:
            return self
        try:
            id = self.id
        except AttributeError:
            id = self.id = key_to_id(self.make_key(owner))
        return CacheManager(instance.env).get(id, self.retriever, instance)

    def __delete__(self, instance):
        try:
            id = self.id
        except AttributeError:
            id = self.id = key_to_id(self.make_key(instance.__class__))
        CacheManager(instance.env).invalidate(id)


class CachedProperty(CachedPropertyBase):
    """Cached property descriptor for classes having potentially
    multiple instances associated to a single `~trac.env.Environment`
    instance.

    As we'll have potentiall many different caches to monitor for this
    kind of cache, the key needs to be augmented by a string unique to
    each instance of the owner class.  As the resulting id will be
    different for each instance of the owner class, we can't store it
    as a property of the descriptor class, so we store it back in the
    attribute used for augmenting the key (``key_attr``).
    """

    def __init__(self, retriever, key_attr):
        super(CachedProperty, self).__init__(retriever)
        self.key_attr = key_attr

    def __get__(self, instance, owner):
        if instance is None:
            return self
        id = getattr(instance, self.key_attr)
        if isinstance(id, str):
            id = key_to_id(self.make_key(owner) + ':' + id)
            setattr(instance, self.key_attr, id)
        return CacheManager(instance.env).get(id, self.retriever, instance)

    def __delete__(self, instance):
        id = getattr(instance, self.key_attr)
        if isinstance(id, str):
            id = key_to_id(self.make_key(instance.__class__) + ':' + id)
            setattr(instance, self.key_attr, id)
        CacheManager(instance.env).invalidate(id)


def cached(fn_or_attr=None):
    """Method decorator creating a cached attribute from a data
    retrieval method.

    Accessing the cached attribute gives back the cached value.  The
    data retrieval method is transparently called by the
    `CacheManager` on first use after the program start or after the
    cache has been invalidated.  Invalidating the cache for this value
    is done by ``del``\ eting the attribute.

    Note that the cache validity is maintained using the `cache` table
    in the database.  Cache invalidation is performed within a
    transaction block, and can be nested within another transaction
    block.

    When the decorator is used in a class for which instances behave
    as singletons within the scope of a given `~trac.env.Environment`
    (typically `~trac.core.Component` classes), the key used to
    identify the attribute in the database is constructed from the
    names of the containing module, class and retriever method::

        class WikiSystem(Component):
            @cached
            def pages(self):
                return set(name for name, in self.env.db_query(
                               "SELECT DISTINCT name FROM wiki"))

    Otherwise, when the decorator is used in non-"singleton" objects,
    a string specifying the name of an attribute containing a string
    unique to the instance must be passed to the decorator. This value
    will be appended to the key constructed from module, class and
    method name::

        class SomeClass(object):
            def __init__(self, env, name):
                self.env = env
                self.name = name
                self._metadata_id = name

            @cached('_metadata_id')
            def metadata(self):
                ...

    Note that in this case the key attribute is overwritten with a
    hash of the key on first access, so it should not be used for any
    other purpose.

    In either case, this decorator requires that the object on which
    it is used has an ``env`` attribute containing the application
    `~trac.env.Environment`.

    .. versionchanged:: 1.0
        The data retrieval method used to be called with a single
        argument ``db`` containing a reference to a database
        connection.  This is the same connection that can be retrieved
        via the normal `~trac.env.Environment.db_query` or
        `~trac.env.Environment.db_transaction`, so this is no longer
        needed, though methods supporting that argument are still
        supported (but will be removed in version 1.1.1).
    """
    if hasattr(fn_or_attr, '__call__'):
        return CachedSingletonProperty(fn_or_attr)
    def decorator(fn):
        return CachedProperty(fn, fn_or_attr)
    return decorator


class CacheManager(Component):
    """Cache manager."""

    required = True

    def __init__(self):
        self._cache = {}
        self._local = ThreadLocal(meta=None, cache=None)
        self._lock = threading.RLock()

    # Public interface

    def reset_metadata(self):
        """Reset per-request cache metadata."""
        self._local.meta = self._local.cache = None

    def get(self, id, retriever, instance):
        """Get cached or fresh data for the given id."""
        # Get cache metadata
        local_meta = self._local.meta
        local_cache = self._local.cache
        if local_meta is None:
            # First cache usage in this request, retrieve cache metadata
            # from the database and make a thread-local copy of the cache
            meta = self.env.db_query("SELECT id, generation FROM cache")
            self._local.meta = local_meta = dict(meta)
            self._local.cache = local_cache = self._cache.copy()

        db_generation = local_meta.get(id, -1)

        # Try the thread-local copy first
        try:
            (data, generation) = local_cache[id]
            if generation == db_generation:
                return data
        except KeyError:
            pass

        with self.env.db_query as db:
            with self._lock:
                # Get data from the process cache
                try:
                    (data, generation) = local_cache[id] = self._cache[id]
                    if generation == db_generation:
                        return data
                except KeyError:
                    generation = None   # Force retrieval from the database

                # Check if the process cache has the newest version, as it may
                # have been updated after the metadata retrieval
                for db_generation, in db(
                        "SELECT generation FROM cache WHERE id=%s", (id,)):
                    break
                else:
                    db_generation = -1
                if db_generation == generation:
                    return data

                # Retrieve data from the database
                if arity(retriever) == 2:
                    data = retriever(instance, db)
                else:
                    data = retriever(instance)
                local_cache[id] = self._cache[id] = (data, db_generation)
                local_meta[id] = db_generation
                return data

    def invalidate(self, id):
        """Invalidate cached data for the given id."""
        with self.env.db_transaction as db:
            with self._lock:
                # Invalidate in other processes

                # The row corresponding to the cache may not exist in the table
                # yet.
                #  - If the row exists, the UPDATE increments the generation,
                #    the SELECT returns a row and we're done.
                #  - If the row doesn't exist, the UPDATE does nothing, but
                #    starts a transaction. The SELECT then returns nothing,
                #    and we can safely INSERT a new row.
                db("UPDATE cache SET generation=generation+1 WHERE id=%s",
                   (id,))
                if not db("SELECT generation FROM cache WHERE id=%s", (id,)):
                    db("INSERT INTO cache VALUES (%s, %s, %s)",
                       (id, 0, _id_to_key.get(id, '<unknown>')))

                # Invalidate in this process
                self._cache.pop(id, None)

                # Invalidate in this thread
                try:
                    del self._local.cache[id]
                except (KeyError, TypeError):
                    pass

########NEW FILE########
__FILENAME__ = config
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2007 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from __future__ import with_statement

from ConfigParser import ConfigParser
from copy import deepcopy
import os.path

from trac.admin import AdminCommandError, IAdminCommandProvider
from trac.core import *
from trac.util import AtomicFile, as_bool
from trac.util.compat import cleandoc
from trac.util.text import printout, to_unicode, CRLF
from trac.util.translation import _, N_

__all__ = ['Configuration', 'ConfigSection', 'Option', 'BoolOption',
           'IntOption', 'FloatOption', 'ListOption', 'ChoiceOption',
           'PathOption', 'ExtensionOption', 'OrderedExtensionsOption',
           'ConfigurationError']

# Retained for backward-compatibility, use as_bool() instead
_TRUE_VALUES = ('yes', 'true', 'enabled', 'on', 'aye', '1', 1, True)

_use_default = object()

def _to_utf8(basestr):
    return to_unicode(basestr).encode('utf-8')


class ConfigurationError(TracError):
    """Exception raised when a value in the configuration file is not valid."""
    title = N_('Configuration Error')


class Configuration(object):
    """Thin layer over `ConfigParser` from the Python standard library.

    In addition to providing some convenience methods, the class remembers
    the last modification time of the configuration file, and reparses it
    when the file has changed.
    """
    def __init__(self, filename, params={}):
        self.filename = filename
        self.parser = ConfigParser()
        self._old_sections = {}
        self.parents = []
        self._lastmtime = 0
        self._sections = {}
        self.parse_if_needed(force=True)

    def __contains__(self, name):
        """Return whether the configuration contains a section of the given
        name.
        """
        return name in self.sections()

    def __getitem__(self, name):
        """Return the configuration section with the specified name."""
        if name not in self._sections:
            self._sections[name] = Section(self, name)
        return self._sections[name]

    def __repr__(self):
        return '<%s %r>' % (self.__class__.__name__, self.filename)

    def get(self, section, key, default=''):
        """Return the value of the specified option.

        Valid default input is a string. Returns a string.
        """
        return self[section].get(key, default)

    def getbool(self, section, key, default=''):
        """Return the specified option as boolean value.

        If the value of the option is one of "yes", "true", "enabled", "on",
        or "1", this method wll return `True`, otherwise `False`.

        Valid default input is a string or a bool. Returns a bool.

        (since Trac 0.9.3, "enabled" added in 0.11)
        """
        return self[section].getbool(key, default)

    def getint(self, section, key, default=''):
        """Return the value of the specified option as integer.

        If the specified option can not be converted to an integer, a
        `ConfigurationError` exception is raised.

        Valid default input is a string or an int. Returns an int.

        (since Trac 0.10)
        """
        return self[section].getint(key, default)

    def getfloat(self, section, key, default=''):
        """Return the value of the specified option as float.

        If the specified option can not be converted to a float, a
        `ConfigurationError` exception is raised.

        Valid default input is a string, float or int. Returns a float.

        (since Trac 0.12)
        """
        return self[section].getfloat(key, default)

    def getlist(self, section, key, default='', sep=',', keep_empty=False):
        """Return a list of values that have been specified as a single
        comma-separated option.

        A different separator can be specified using the `sep` parameter. If
        the `keep_empty` parameter is set to `True`, empty elements are
        included in the list.

        Valid default input is a string or a list. Returns a string.

        (since Trac 0.10)
        """
        return self[section].getlist(key, default, sep, keep_empty)

    def getpath(self, section, key, default=''):
        """Return a configuration value as an absolute path.

        Relative paths are resolved relative to the location of this
        configuration file.

        Valid default input is a string. Returns a normalized path.

        (enabled since Trac 0.11.5)
        """
        return self[section].getpath(key, default)

    def set(self, section, key, value):
        """Change a configuration value.

        These changes are not persistent unless saved with `save()`.
        """
        self[section].set(key, value)

    def defaults(self, compmgr=None):
        """Returns a dictionary of the default configuration values
        (''since 0.10'').

        If `compmgr` is specified, return only options declared in components
        that are enabled in the given `ComponentManager`.
        """
        defaults = {}
        for (section, key), option in Option.get_registry(compmgr).items():
            defaults.setdefault(section, {})[key] = option.default
        return defaults

    def options(self, section, compmgr=None):
        """Return a list of `(name, value)` tuples for every option in the
        specified section.

        This includes options that have default values that haven't been
        overridden. If `compmgr` is specified, only return default option
        values for components that are enabled in the given `ComponentManager`.
        """
        return self[section].options(compmgr)

    def remove(self, section, key):
        """Remove the specified option."""
        self[section].remove(key)

    def sections(self, compmgr=None, defaults=True):
        """Return a list of section names.

        If `compmgr` is specified, only the section names corresponding to
        options declared in components that are enabled in the given
        `ComponentManager` are returned.
        """
        sections = set([to_unicode(s) for s in self.parser.sections()])
        for parent in self.parents:
            sections.update(parent.sections(compmgr, defaults=False))
        if defaults:
            sections.update(self.defaults(compmgr))
        return sorted(sections)

    def has_option(self, section, option, defaults=True):
        """Returns True if option exists in section in either the project
        trac.ini or one of the parents, or is available through the Option
        registry.

        (since Trac 0.11)
        """
        section_str = _to_utf8(section)
        if self.parser.has_section(section_str):
            if _to_utf8(option) in self.parser.options(section_str):
                return True
        for parent in self.parents:
            if parent.has_option(section, option, defaults=False):
                return True
        return defaults and (section, option) in Option.registry

    def save(self):
        """Write the configuration options to the primary file."""
        if not self.filename:
            return

        # Only save options that differ from the defaults
        sections = []
        for section in self.sections():
            section_str = _to_utf8(section)
            options = []
            for option in self[section]:
                default_str = None
                for parent in self.parents:
                    if parent.has_option(section, option, defaults=False):
                        default_str = _to_utf8(parent.get(section, option))
                        break
                option_str = _to_utf8(option)
                current_str = False
                if self.parser.has_option(section_str, option_str):
                    current_str = self.parser.get(section_str, option_str)
                if current_str is not False and current_str != default_str:
                    options.append((option_str, current_str))
            if options:
                sections.append((section_str, sorted(options)))

        # At this point, all the strings in `sections` are UTF-8 encoded `str`
        try:
            with AtomicFile(self.filename, 'w') as fileobj:
                fileobj.write('# -*- coding: utf-8 -*-\n\n')
                for section, options in sections:
                    fileobj.write('[%s]\n' % section)
                    for key_str, val_str in options:
                        if to_unicode(key_str) in self[section].overridden:
                            fileobj.write('# %s = <inherited>\n' % key_str)
                        else:
                            val_str = val_str.replace(CRLF, '\n') \
                                             .replace('\n', '\n ')
                            fileobj.write('%s = %s\n' % (key_str, val_str))
                    fileobj.write('\n')
            self._old_sections = deepcopy(self.parser._sections)
        except Exception:
            # Revert all changes to avoid inconsistencies
            self.parser._sections = deepcopy(self._old_sections)
            raise

    def parse_if_needed(self, force=False):
        if not self.filename or not os.path.isfile(self.filename):
            return False

        changed = False
        modtime = os.path.getmtime(self.filename)
        if force or modtime > self._lastmtime:
            self._sections = {}
            self.parser._sections = {}
            if not self.parser.read(self.filename):
                raise TracError(_("Error reading '%(file)s', make sure it is "
                                  "readable.", file=self.filename))
            self._lastmtime = modtime
            self._old_sections = deepcopy(self.parser._sections)
            changed = True

        if changed:
            self.parents = []
            if self.parser.has_option('inherit', 'file'):
                for filename in self.parser.get('inherit', 'file').split(','):
                    filename = to_unicode(filename.strip())
                    if not os.path.isabs(filename):
                        filename = os.path.join(os.path.dirname(self.filename),
                                                filename)
                    self.parents.append(Configuration(filename))
        else:
            for parent in self.parents:
                changed |= parent.parse_if_needed(force=force)

        if changed:
            self._cache = {}
        return changed

    def touch(self):
        if self.filename and os.path.isfile(self.filename) \
           and os.access(self.filename, os.W_OK):
            os.utime(self.filename, None)

    def set_defaults(self, compmgr=None):
        """Retrieve all default values and store them explicitly in the
        configuration, so that they can be saved to file.

        Values already set in the configuration are not overridden.
        """
        for section, default_options in self.defaults(compmgr).items():
            for name, value in default_options.items():
                if not self.parser.has_option(_to_utf8(section),
                                              _to_utf8(name)):
                    if any(parent[section].contains(name, defaults=False)
                           for parent in self.parents):
                        value = None
                    self.set(section, name, value)


class Section(object):
    """Proxy for a specific configuration section.

    Objects of this class should not be instantiated directly.
    """
    __slots__ = ['config', 'name', 'overridden', '_cache']

    def __init__(self, config, name):
        self.config = config
        self.name = name
        self.overridden = {}
        self._cache = {}

    def contains(self, key, defaults=True):
        if self.config.parser.has_option(_to_utf8(self.name), _to_utf8(key)):
            return True
        for parent in self.config.parents:
            if parent[self.name].contains(key, defaults=False):
                return True
        return defaults and Option.registry.has_key((self.name, key))

    __contains__ = contains

    def iterate(self, compmgr=None, defaults=True):
        """Iterate over the options in this section.

        If `compmgr` is specified, only return default option values for
        components that are enabled in the given `ComponentManager`.
        """
        options = set()
        name_str = _to_utf8(self.name)
        if self.config.parser.has_section(name_str):
            for option_str in self.config.parser.options(name_str):
                option = to_unicode(option_str)
                options.add(option.lower())
                yield option
        for parent in self.config.parents:
            for option in parent[self.name].iterate(defaults=False):
                loption = option.lower()
                if loption not in options:
                    options.add(loption)
                    yield option
        if defaults:
            for section, option in Option.get_registry(compmgr).keys():
                if section == self.name and option.lower() not in options:
                    yield option

    __iter__ = iterate

    def __repr__(self):
        return '<%s [%s]>' % (self.__class__.__name__, self.name)

    def get(self, key, default=''):
        """Return the value of the specified option.

        Valid default input is a string. Returns a string.
        """
        cached = self._cache.get(key, _use_default)
        if cached is not _use_default:
            return cached
        name_str = _to_utf8(self.name)
        key_str = _to_utf8(key)
        if self.config.parser.has_option(name_str, key_str):
            value = self.config.parser.get(name_str, key_str)
        else:
            for parent in self.config.parents:
                value = parent[self.name].get(key, _use_default)
                if value is not _use_default:
                    break
            else:
                if default is not _use_default:
                    option = Option.registry.get((self.name, key))
                    value = option.default if option else _use_default
                else:
                    value = _use_default
        if value is _use_default:
            return default
        if not value:
            value = u''
        elif isinstance(value, basestring):
            value = to_unicode(value)
        self._cache[key] = value
        return value

    def getbool(self, key, default=''):
        """Return the value of the specified option as boolean.

        This method returns `True` if the option value is one of "yes", "true",
        "enabled", "on", or non-zero numbers, ignoring case. Otherwise `False`
        is returned.

        Valid default input is a string or a bool. Returns a bool.
        """
        return as_bool(self.get(key, default))

    def getint(self, key, default=''):
        """Return the value of the specified option as integer.

        If the specified option can not be converted to an integer, a
        `ConfigurationError` exception is raised.

        Valid default input is a string or an int. Returns an int.
        """
        value = self.get(key, default)
        if not value:
            return 0
        try:
            return int(value)
        except ValueError:
            raise ConfigurationError(
                    _('[%(section)s] %(entry)s: expected integer, got %(value)s',
                      section=self.name, entry=key, value=repr(value)))

    def getfloat(self, key, default=''):
        """Return the value of the specified option as float.

        If the specified option can not be converted to a float, a
        `ConfigurationError` exception is raised.

        Valid default input is a string, float or int. Returns a float.
        """
        value = self.get(key, default)
        if not value:
            return 0.0
        try:
            return float(value)
        except ValueError:
            raise ConfigurationError(
                    _('[%(section)s] %(entry)s: expected float, got %(value)s',
                      section=self.name, entry=key, value=repr(value)))

    def getlist(self, key, default='', sep=',', keep_empty=True):
        """Return a list of values that have been specified as a single
        comma-separated option.

        A different separator can be specified using the `sep` parameter. If
        the `keep_empty` parameter is set to `False`, empty elements are omitted
        from the list.

        Valid default input is a string or a list. Returns a list.
        """
        value = self.get(key, default)
        if not value:
            return []
        if isinstance(value, basestring):
            items = [item.strip() for item in value.split(sep)]
        else:
            items = list(value)
        if not keep_empty:
            items = [item for item in items if item not in (None, '')]
        return items

    def getpath(self, key, default=''):
        """Return the value of the specified option as a path, relative to
        the location of this configuration file.

        Valid default input is a string. Returns a normalized path.
        """
        path = self.get(key, default)
        if not path:
            return default
        if not os.path.isabs(path):
            path = os.path.join(os.path.dirname(self.config.filename), path)
        return os.path.normcase(os.path.realpath(path))

    def options(self, compmgr=None):
        """Return `(key, value)` tuples for every option in the section.

        This includes options that have default values that haven't been
        overridden. If `compmgr` is specified, only return default option
        values for components that are enabled in the given `ComponentManager`.
        """
        for key in self.iterate(compmgr):
            yield key, self.get(key)

    def set(self, key, value):
        """Change a configuration value.

        These changes are not persistent unless saved with `save()`.
        """
        self._cache.pop(key, None)
        name_str = _to_utf8(self.name)
        key_str = _to_utf8(key)
        if not self.config.parser.has_section(name_str):
            self.config.parser.add_section(name_str)
        if value is None:
            self.overridden[key] = True
            value_str = ''
        else:
            value_str = _to_utf8(value)
        return self.config.parser.set(name_str, key_str, value_str)

    def remove(self, key):
        """Delete a key from this section.

        Like for `set()`, the changes won't persist until `save()` gets called.
        """
        name_str = _to_utf8(self.name)
        if self.config.parser.has_section(name_str):
            self._cache.pop(key, None)
            self.config.parser.remove_option(_to_utf8(self.name), _to_utf8(key))


def _get_registry(cls, compmgr=None):
    """Return the descriptor registry.

    If `compmgr` is specified, only return descriptors for components that
    are enabled in the given `ComponentManager`.
    """
    if compmgr is None:
        return cls.registry

    from trac.core import ComponentMeta
    components = {}
    for comp in ComponentMeta._components:
        for attr in comp.__dict__.itervalues():
            if isinstance(attr, cls):
                components[attr] = comp

    return dict(each for each in cls.registry.iteritems()
                if each[1] not in components
                   or compmgr.is_enabled(components[each[1]]))


class ConfigSection(object):
    """Descriptor for configuration sections."""

    registry = {}

    @staticmethod
    def get_registry(compmgr=None):
        """Return the section registry, as a `dict` mapping section names to
        `ConfigSection` objects.

        If `compmgr` is specified, only return sections for components that are
        enabled in the given `ComponentManager`.
        """
        return _get_registry(ConfigSection, compmgr)

    def __init__(self, name, doc, doc_domain='tracini'):
        """Create the configuration section."""
        self.name = name
        self.registry[self.name] = self
        self.__doc__ = cleandoc(doc)
        self.doc_domain = doc_domain

    def __get__(self, instance, owner):
        if instance is None:
            return self
        config = getattr(instance, 'config', None)
        if config and isinstance(config, Configuration):
            return config[self.name]

    def __repr__(self):
        return '<%s [%s]>' % (self.__class__.__name__, self.name)


class Option(object):
    """Descriptor for configuration options."""

    registry = {}

    def accessor(self, section, name, default):
        return section.get(name, default)

    @staticmethod
    def get_registry(compmgr=None):
        """Return the option registry, as a `dict` mapping `(section, key)`
        tuples to `Option` objects.

        If `compmgr` is specified, only return options for components that are
        enabled in the given `ComponentManager`.
        """
        return _get_registry(Option, compmgr)

    def __init__(self, section, name, default=None, doc='',
                 doc_domain='tracini'):
        """Create the configuration option.

        @param section: the name of the configuration section this option
            belongs to
        @param name: the name of the option
        @param default: the default value for the option
        @param doc: documentation of the option
        """
        self.section = section
        self.name = name
        self.default = default
        self.registry[(self.section, self.name)] = self
        self.__doc__ = cleandoc(doc)
        self.doc_domain = doc_domain

    def __get__(self, instance, owner):
        if instance is None:
            return self
        config = getattr(instance, 'config', None)
        if config and isinstance(config, Configuration):
            section = config[self.section]
            value = self.accessor(section, self.name, self.default)
            return value

    def __set__(self, instance, value):
        raise AttributeError, 'can\'t set attribute'

    def __repr__(self):
        return '<%s [%s] "%s">' % (self.__class__.__name__, self.section,
                                   self.name)


class BoolOption(Option):
    """Descriptor for boolean configuration options."""
    def accessor(self, section, name, default):
        return section.getbool(name, default)


class IntOption(Option):
    """Descriptor for integer configuration options."""
    def accessor(self, section, name, default):
        return section.getint(name, default)


class FloatOption(Option):
    """Descriptor for float configuration options."""
    def accessor(self, section, name, default):
        return section.getfloat(name, default)


class ListOption(Option):
    """Descriptor for configuration options that contain multiple values
    separated by a specific character.
    """

    def __init__(self, section, name, default=None, sep=',', keep_empty=False,
                 doc='', doc_domain='tracini'):
        Option.__init__(self, section, name, default, doc, doc_domain)
        self.sep = sep
        self.keep_empty = keep_empty

    def accessor(self, section, name, default):
        return section.getlist(name, default, self.sep, self.keep_empty)


class ChoiceOption(Option):
    """Descriptor for configuration options providing a choice among a list
    of items.

    The default value is the first choice in the list.
    """

    def __init__(self, section, name, choices, doc='', doc_domain='tracini'):
        Option.__init__(self, section, name, _to_utf8(choices[0]), doc,
                        doc_domain)
        self.choices = set(_to_utf8(choice).strip() for choice in choices)

    def accessor(self, section, name, default):
        value = section.get(name, default)
        if value not in self.choices:
            raise ConfigurationError(
                    _('[%(section)s] %(entry)s: expected one of '
                      '(%(choices)s), got %(value)s',
                      section=section.name, entry=name, value=repr(value),
                      choices=', '.join('"%s"' % c
                                        for c in sorted(self.choices))))
        return value


class PathOption(Option):
    """Descriptor for file system path configuration options.

    Relative paths are resolved to absolute paths using the directory
    containing the configuration file as the reference.
    """
    def accessor(self, section, name, default):
        return section.getpath(name, default)


class ExtensionOption(Option):

    def __init__(self, section, name, interface, default=None, doc='',
                 doc_domain='tracini'):
        Option.__init__(self, section, name, default, doc, doc_domain)
        self.xtnpt = ExtensionPoint(interface)

    def __get__(self, instance, owner):
        if instance is None:
            return self
        value = Option.__get__(self, instance, owner)
        for impl in self.xtnpt.extensions(instance):
            if impl.__class__.__name__ == value:
                return impl
        raise AttributeError('Cannot find an implementation of the "%s" '
                             'interface named "%s".  Please update the option '
                             '%s.%s in trac.ini.'
                             % (self.xtnpt.interface.__name__, value,
                                self.section, self.name))


class OrderedExtensionsOption(ListOption):
    """A comma separated, ordered, list of components implementing `interface`.
    Can be empty.

    If `include_missing` is true (the default) all components implementing the
    interface are returned, with those specified by the option ordered first."""

    def __init__(self, section, name, interface, default=None,
                 include_missing=True, doc='', doc_domain='tracini'):
        ListOption.__init__(self, section, name, default, doc=doc,
                            doc_domain=doc_domain)
        self.xtnpt = ExtensionPoint(interface)
        self.include_missing = include_missing

    def __get__(self, instance, owner):
        if instance is None:
            return self
        order = ListOption.__get__(self, instance, owner)
        components = []
        for impl in self.xtnpt.extensions(instance):
            if self.include_missing or impl.__class__.__name__ in order:
                components.append(impl)

        def compare(x, y):
            x, y = x.__class__.__name__, y.__class__.__name__
            if x not in order:
                return int(y in order)
            if y not in order:
                return -int(x in order)
            return cmp(order.index(x), order.index(y))
        components.sort(compare)
        return components


class ConfigurationAdmin(Component):
    """trac-admin command provider for trac.ini administration."""

    implements(IAdminCommandProvider)

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('config get', '<section> <option>',
               'Get the value of the given option in "trac.ini"',
               self._complete_config, self._do_get)
        yield ('config remove', '<section> <option>',
               'Remove the specified option from "trac.ini"',
               self._complete_config, self._do_remove)
        yield ('config set', '<section> <option> <value>',
               'Set the value for the given option in "trac.ini"',
               self._complete_config, self._do_set)

    def _complete_config(self, args):
        if len(args) == 1:
            return self.config.sections()
        elif len(args) == 2:
            return [name for (name, value) in self.config[args[0]].options()]

    def _do_get(self, section, option):
        if not self.config.has_option(section, option):
            raise AdminCommandError(
                _("Option '%(option)s' doesn't exist in section '%(section)s'",
                  option=option, section=section))
        printout(self.config.get(section, option))

    def _do_set(self, section, option, value):
        self.config.set(section, option, value)
        self.config.save()
        if section == 'inherit' and option == 'file':
            self.config.parse_if_needed(force=True) # Full reload

    def _do_remove(self, section, option):
        if not self.config.has_option(section, option):
            raise AdminCommandError(
                _("Option '%(option)s' doesn't exist in section '%(section)s'",
                  option=option, section=section))
        self.config.remove(section, option)
        self.config.save()
        if section == 'inherit' and option == 'file':
            self.config.parse_if_needed(force=True) # Full reload

########NEW FILE########
__FILENAME__ = core
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2011 Edgewall Software
# Copyright (C) 2003-2004 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

__all__ = ['Component', 'ExtensionPoint', 'implements', 'Interface',
           'TracError']


def N_(string):
    """No-op translation marker, inlined here to avoid importing from
    `trac.util`.
    """
    return string


class TracError(Exception):
    """Exception base class for errors in Trac."""

    title = N_('Trac Error')

    def __init__(self, message, title=None, show_traceback=False):
        """If message is a genshi.builder.tag object, everything up to
        the first <p> will be displayed in the red box, and everything
        after will be displayed below the red box.  If title is given,
        it will be displayed as the large header above the error
        message.
        """
        from trac.util.translation import gettext
        Exception.__init__(self, message)
        self._message = message
        self.title = title or gettext(self.title)
        self.show_traceback = show_traceback

    message = property(lambda self: self._message,
                       lambda self, v: setattr(self, '_message', v))

    def __unicode__(self):
        return unicode(self.message)


class Interface(object):
    """Marker base class for extension point interfaces."""


class ExtensionPoint(property):
    """Marker class for extension points in components."""

    def __init__(self, interface):
        """Create the extension point.

        :param interface: the `Interface` subclass that defines the
                          protocol for the extension point
        """
        property.__init__(self, self.extensions)
        self.interface = interface
        self.__doc__ = ("List of components that implement `~%s.%s`" %
                        (self.interface.__module__, self.interface.__name__))

    def extensions(self, component):
        """Return a list of components that declare to implement the
        extension point interface.
        """
        classes = ComponentMeta._registry.get(self.interface, ())
        components = [component.compmgr[cls] for cls in classes]
        return [c for c in components if c]

    def __repr__(self):
        """Return a textual representation of the extension point."""
        return '<ExtensionPoint %s>' % self.interface.__name__


class ComponentMeta(type):
    """Meta class for components.

    Takes care of component and extension point registration.
    """
    _components = []
    _registry = {}

    def __new__(mcs, name, bases, d):
        """Create the component class."""

        def nonrecursive_init(cls):
            """Replaces __init__ of the class with one that checks for
            recursion"""
            original_init = cls.__init__
            compmgrs = set()
            def new_init(self, *args, **kwargs):
                """Only run the original __init__ once per component manager"""
                if self.compmgr not in compmgrs:
                    try:
                        compmgrs.add(self.compmgr)
                        original_init(self, *args, **kwargs)
                    finally:
                        compmgrs.remove(self.compmgr)
            cls.__init__ = new_init
            return cls

        new_class = nonrecursive_init(type.__new__(mcs, name, bases, d))
        if name == 'Component':
            # Don't put the Component base class in the registry
            return new_class

        if d.get('abstract'):
            # Don't put abstract component classes in the registry
            return new_class

        ComponentMeta._components.append(new_class)
        registry = ComponentMeta._registry
        for cls in new_class.__mro__:
            for interface in cls.__dict__.get('_implements', ()):
                classes = registry.setdefault(interface, [])
                if new_class not in classes:
                    classes.append(new_class)

        return new_class

    def __call__(cls, *args, **kwargs):
        """Return an existing instance of the component if it has
        already been activated, otherwise create a new instance.
        """
        # If this component is also the component manager, just invoke that
        if issubclass(cls, ComponentManager):
            self = cls.__new__(cls)
            self.compmgr = self
            self.__init__(*args, **kwargs)
            return self

        # The normal case where the component is not also the component manager
        compmgr = args[0]
        self = compmgr.components.get(cls)
        # Note that this check is racy, we intentionally don't use a
        # lock in order to keep things simple and avoid the risk of
        # deadlocks, as the impact of having temporarily two (or more)
        # instances for a given `cls` is negligible.
        if self is None:
            self = cls.__new__(cls)
            self.compmgr = compmgr
            compmgr.component_activated(self)
            self.__init__()
            # Only register the instance once it is fully initialized (#9418)
            compmgr.components[cls] = self
        return self


class Component(object):
    """Base class for components.

    Every component can declare what extension points it provides, as
    well as what extension points of other components it extends.
    """
    __metaclass__ = ComponentMeta

    @staticmethod
    def implements(*interfaces):
        """Can be used in the class definition of `Component`
        subclasses to declare the extension points that are extended.
        """
        import sys

        frame = sys._getframe(1)
        locals_ = frame.f_locals

        # Some sanity checks
        assert locals_ is not frame.f_globals and '__module__' in locals_, \
               'implements() can only be used in a class definition'

        locals_.setdefault('_implements', []).extend(interfaces)


implements = Component.implements


class ComponentManager(object):
    """The component manager keeps a pool of active components."""

    def __init__(self):
        """Initialize the component manager."""
        self.components = {}
        self.enabled = {}
        if isinstance(self, Component):
            self.components[self.__class__] = self

    def __contains__(self, cls):
        """Return wether the given class is in the list of active
        components."""
        return cls in self.components

    def __getitem__(self, cls):
        """Activate the component instance for the given class, or
        return the existing instance if the component has already been
        activated.
        """
        if not self.is_enabled(cls):
            return None
        component = self.components.get(cls)

        # Leave other manager components out of extension point lists
        # see bh:comment:5:ticket:438 and ticket:11121
        if not component and not issubclass(cls, ComponentManager) :
            if cls not in ComponentMeta._components:
                raise TracError('Component "%s" not registered' % cls.__name__)
            try:
                component = cls(self)
            except TypeError, e:
                raise TracError('Unable to instantiate component %r (%s)' %
                                (cls, e))
        return component

    def is_enabled(self, cls):
        """Return whether the given component class is enabled."""
        if cls not in self.enabled:
            self.enabled[cls] = self.is_component_enabled(cls)
        return self.enabled[cls]

    def disable_component(self, component):
        """Force a component to be disabled.

        :param component: can be a class or an instance.
        """
        if not isinstance(component, type):
            component = component.__class__
        self.enabled[component] = False
        self.components[component] = None

    def component_activated(self, component):
        """Can be overridden by sub-classes so that special
        initialization for components can be provided.
        """

    def is_component_enabled(self, cls):
        """Can be overridden by sub-classes to veto the activation of
        a component.

        If this method returns `False`, the component was disabled
        explicitly.  If it returns `None`, the component was neither
        enabled nor disabled explicitly. In both cases, the component
        with the given class will not be available.
        """
        return True

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import os
import time
import urllib

from trac.config import BoolOption, IntOption, Option
from trac.core import *
from trac.util.concurrency import ThreadLocal
from trac.util.text import unicode_passwd
from trac.util.translation import _

from .pool import ConnectionPool
from .util import ConnectionWrapper


def with_transaction(env, db=None):
    """Function decorator to emulate a context manager for database
    transactions.

    >>> def api_method(p1, p2):
    >>>     result[0] = value1
    >>>     @with_transaction(env)
    >>>     def implementation(db):
    >>>         # implementation
    >>>         result[0] = value2
    >>>     return result[0]

    In this example, the `implementation()` function is called
    automatically right after its definition, with a database
    connection as an argument. If the function completes, a COMMIT is
    issued on the connection. If the function raises an exception, a
    ROLLBACK is issued and the exception is re-raised. Nested
    transactions are supported, and a COMMIT will only be issued when
    the outermost transaction block in a thread exits.

    This mechanism is intended to replace the former practice of
    getting a database connection with `env.get_db_cnx()` and issuing
    an explicit commit or rollback, for mutating database
    accesses. Its automatic handling of commit, rollback and nesting
    makes it much more robust.

    The optional `db` argument is intended for legacy code and should
    not be used in new code.

    :deprecated: This decorator is in turn deprecated in favor of
                 context managers now that python 2.4 support has been
                 dropped. Use instead the new context manager,
                 `QueryContextManager` and
                 `TransactionContextManager`, which makes for much
                 simpler to write code:

    >>> def api_method(p1, p2):
    >>>     result = value1
    >>>     with env.db_transaction as db:
    >>>         # implementation
    >>>         result = value2
    >>>     return result

    """
    dbm = DatabaseManager(env)
    _transaction_local = dbm._transaction_local

    def transaction_wrapper(fn):
        ldb = _transaction_local.wdb
        if db is not None:
            if ldb is None:
                _transaction_local.wdb = db
                try:
                    fn(db)
                finally:
                    _transaction_local.wdb = None
            else:
                assert ldb is db, "Invalid transaction nesting"
                fn(db)
        elif ldb:
            fn(ldb)
        else:
            ldb = _transaction_local.wdb = dbm.get_connection()
            try:
                fn(ldb)
                ldb.commit()
                _transaction_local.wdb = None
            except:
                _transaction_local.wdb = None
                ldb.rollback()
                ldb = None
                raise
    return transaction_wrapper


class DbContextManager(object):
    """Database Context Manager

    The outermost `DbContextManager` will close the connection.
    """

    db = None

    def __init__(self, env):
        self.dbmgr = DatabaseManager(env)

    def execute(self, query, params=None):
        """Shortcut for directly executing a query."""
        with self as db:
            return db.execute(query, params)

    __call__ = execute

    def executemany(self, query, params=None):
        """Shortcut for directly calling "executemany" on a query."""
        with self as db:
            return db.executemany(query, params)


class TransactionContextManager(DbContextManager):
    """Transactioned Database Context Manager for retrieving a
    `~trac.db.util.ConnectionWrapper`.

    The outermost such context manager will perform a commit upon
    normal exit or a rollback after an exception.
    """

    def __enter__(self):
        db = self.dbmgr._transaction_local.wdb # outermost writable db
        if not db:
            db = self.dbmgr._transaction_local.rdb # reuse wrapped connection
            if db:
                db = ConnectionWrapper(db.cnx, db.log)
            else:
                db = self.dbmgr.get_connection()
            self.dbmgr._transaction_local.wdb = self.db = db
        return db

    def __exit__(self, et, ev, tb):
        if self.db:
            self.dbmgr._transaction_local.wdb = None
            if et is None:
                self.db.commit()
            else:
                self.db.rollback()
            if not self.dbmgr._transaction_local.rdb:
                self.db.close()


class QueryContextManager(DbContextManager):
    """Database Context Manager for retrieving a read-only
    `~trac.db.util.ConnectionWrapper`.
    """

    def __enter__(self):
        db = self.dbmgr._transaction_local.rdb # outermost readonly db
        if not db:
            db = self.dbmgr._transaction_local.wdb # reuse wrapped connection
            if db:
                db = ConnectionWrapper(db.cnx, db.log, readonly=True)
            else:
                db = self.dbmgr.get_connection(readonly=True)
            self.dbmgr._transaction_local.rdb = self.db = db
        return db

    def __exit__(self, et, ev, tb):
        if self.db:
            self.dbmgr._transaction_local.rdb = None
            if not self.dbmgr._transaction_local.wdb:
                self.db.close()


class IDatabaseConnector(Interface):
    """Extension point interface for components that support the
    connection to relational databases.
    """

    def get_supported_schemes():
        """Return the connection URL schemes supported by the
        connector, and their relative priorities as an iterable of
        `(scheme, priority)` tuples.

        If `priority` is a negative number, this is indicative of an
        error condition with the connector. An error message should be
        attached to the `error` attribute of the connector.
        """

    def get_connection(path, log=None, **kwargs):
        """Create a new connection to the database."""

    def get_exceptions():
        """Return an object (typically a module) containing all the
        backend-specific exception types as attributes, named
        according to the Python Database API
        (http://www.python.org/dev/peps/pep-0249/).
        """

    def init_db(path, schema=None, log=None, **kwargs):
        """Initialize the database."""

    def to_sql(table):
        """Return the DDL statements necessary to create the specified
        table, including indices."""

    def backup(dest):
        """Backup the database to a location defined by
        trac.backup_dir"""


class DatabaseManager(Component):
    """Component used to manage the `IDatabaseConnector` implementations."""

    connectors = ExtensionPoint(IDatabaseConnector)

    connection_uri = Option('trac', 'database', 'sqlite:db/trac.db',
        """Database connection
        [wiki:TracEnvironment#DatabaseConnectionStrings string] for this
        project""")

    backup_dir = Option('trac', 'backup_dir', 'db',
        """Database backup location""")

    timeout = IntOption('trac', 'timeout', '20',
        """Timeout value for database connection, in seconds.
        Use '0' to specify ''no timeout''. ''(Since 0.11)''""")

    debug_sql = BoolOption('trac', 'debug_sql', False,
        """Show the SQL queries in the Trac log, at DEBUG level.
        ''(Since 0.11.5)''""")

    def __init__(self):
        self._cnx_pool = None
        self._transaction_local = ThreadLocal(wdb=None, rdb=None)

    def init_db(self):
        connector, args = self.get_connector()
        from trac.db_default import schema
        args['schema'] = schema
        connector.init_db(**args)

    def get_connection(self, readonly=False):
        """Get a database connection from the pool.

        If `readonly` is `True`, the returned connection will purposedly
        lack the `rollback` and `commit` methods.
        """
        if not self._cnx_pool:
            connector, args = self.get_connector()
            self._cnx_pool = ConnectionPool(5, connector, **args)
        db = self._cnx_pool.get_cnx(self.timeout or None)
        if readonly:
            db = ConnectionWrapper(db, readonly=True)
        return db

    def get_exceptions(self):
        return self.get_connector()[0].get_exceptions()

    def shutdown(self, tid=None):
        if self._cnx_pool:
            self._cnx_pool.shutdown(tid)
            if not tid:
                self._cnx_pool = None

    def backup(self, dest=None):
        """Save a backup of the database.

        :param dest: base filename to write to.

        Returns the file actually written.
        """
        connector, args = self.get_connector()
        if not dest:
            backup_dir = self.backup_dir
            if not os.path.isabs(backup_dir):
                backup_dir = os.path.join(self.env.path, backup_dir)
            db_str = self.config.get('trac', 'database')
            db_name, db_path = db_str.split(":", 1)
            dest_name = '%s.%i.%d.bak' % (db_name, self.env.get_version(),
                                          int(time.time()))
            dest = os.path.join(backup_dir, dest_name)
        else:
            backup_dir = os.path.dirname(dest)
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        return connector.backup(dest)

    def get_connector(self):
        scheme, args = _parse_db_str(self.connection_uri)
        candidates = [
            (priority, connector)
            for connector in self.connectors
            for scheme_, priority in connector.get_supported_schemes()
            if scheme_ == scheme
        ]
        if not candidates:
            raise TracError(_('Unsupported database type "%(scheme)s"',
                              scheme=scheme))
        priority, connector = max(candidates)
        if priority < 0:
            raise TracError(connector.error)

        if scheme == 'sqlite':
            if args['path'] == ':memory:':
                # Special case for SQLite in-memory database, always get
                # the /same/ connection over
                pass
            elif not args['path'].startswith('/'):
                # Special case for SQLite to support a path relative to the
                # environment directory
                args['path'] = os.path.join(self.env.path,
                                            args['path'].lstrip('/'))

        if self.debug_sql:
            args['log'] = self.log
        return connector, args

    _get_connector = get_connector  # For 0.11 compatibility


def get_column_names(cursor):
    """Retrieve column names from a cursor, if possible."""
    return [unicode(d[0], 'utf-8') if isinstance(d[0], str) else d[0]
            for d in cursor.description] if cursor.description else []


def _parse_db_str(db_str):
    scheme, rest = db_str.split(':', 1)

    if not rest.startswith('/'):
        if scheme == 'sqlite':
            # Support for relative and in-memory SQLite connection strings
            host = None
            path = rest
        else:
            raise TracError(_('Unknown scheme "%(scheme)s"; database '
                              'connection string must start with {scheme}:/',
                              scheme=scheme))
    else:
        if not rest.startswith('//'):
            host = None
            rest = rest[1:]
        elif rest.startswith('///'):
            host = None
            rest = rest[3:]
        else:
            rest = rest[2:]
            if '/' not in rest:
                host = rest
                rest = ''
            else:
                host, rest = rest.split('/', 1)
        path = None

    if host and '@' in host:
        user, host = host.split('@', 1)
        if ':' in user:
            user, password = user.split(':', 1)
        else:
            password = None
        if user:
            user = urllib.unquote(user)
        if password:
            password = unicode_passwd(urllib.unquote(password))
    else:
        user = password = None
    if host and ':' in host:
        host, port = host.split(':')
        port = int(port)
    else:
        port = None

    if not path:
        path = '/' + rest
    if os.name == 'nt':
        # Support local paths containing drive letters on Win32
        if len(rest) > 1 and rest[1] == '|':
            path = "%s:%s" % (rest[0], rest[2:])

    params = {}
    if '?' in path:
        path, qs = path.split('?', 1)
        qs = qs.split('&')
        for param in qs:
            name, value = param.split('=', 1)
            value = urllib.unquote(value)
            params[name] = value

    args = zip(('user', 'password', 'host', 'port', 'path', 'params'),
               (user, password, host, port, path, params))
    return scheme, dict([(key, value) for key, value in args if value])

########NEW FILE########
__FILENAME__ = mysql_backend
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005 Jeff Weiss <trac@jeffweiss.org>
# Copyright (C) 2006 Andres Salomon <dilinger@athenacr.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os, re, types

from genshi.core import Markup

from trac.core import *
from trac.config import Option
from trac.db.api import IDatabaseConnector, _parse_db_str
from trac.db.util import ConnectionWrapper, IterableCursor
from trac.util import as_int, get_pkginfo
from trac.util.compat import close_fds
from trac.util.text import exception_to_unicode, to_unicode
from trac.util.translation import _

_like_escape_re = re.compile(r'([/_%])')

try:
    import MySQLdb
    import MySQLdb.cursors
    has_mysqldb = True

    class MySQLUnicodeCursor(MySQLdb.cursors.Cursor):
        def _convert_row(self, row):
            return tuple(v.decode('utf-8') if isinstance(v, str) else v
                         for v in row)
        def fetchone(self):
            row = super(MySQLUnicodeCursor, self).fetchone()
            return self._convert_row(row) if row else None
        def fetchmany(self, num):
            rows = super(MySQLUnicodeCursor, self).fetchmany(num)
            return [self._convert_row(row) for row in rows] \
                   if rows is not None else []
        def fetchall(self):
            rows = super(MySQLUnicodeCursor, self).fetchall()
            return [self._convert_row(row) for row in rows] \
                   if rows is not None else []
except ImportError:
    has_mysqldb = False

# Mapping from "abstract" SQL types to DB-specific types
_type_map = {
    'int64': 'bigint',
}


class MySQLConnector(Component):
    """Database connector for MySQL version 4.1 and greater.

    Database URLs should be of the form:
    {{{
    mysql://user[:password]@host[:port]/database[?param1=value&param2=value]
    }}}
    The following parameters are supported:
     * `compress`: Enable compression (0 or 1)
     * `init_command`: Command to run once the connection is created
     * `named_pipe`: Use a named pipe to connect on Windows (0 or 1)
     * `read_default_file`: Read default client values from the given file
     * `read_default_group`: Configuration group to use from the default file
     * `unix_socket`: Use a Unix socket at the given path to connect
    """
    implements(IDatabaseConnector)

    mysqldump_path = Option('trac', 'mysqldump_path', 'mysqldump',
        """Location of mysqldump for MySQL database backups""")

    def __init__(self):
        self._version = None
        self.error = None

    def get_supported_schemes(self):
        if not has_mysqldb:
            self.error = _("Cannot load Python bindings for MySQL")
        yield ('mysql', -1 if self.error else 1)

    def get_connection(self, path, log=None, user=None, password=None,
                       host=None, port=None, params={}):
        cnx = MySQLConnection(path, log, user, password, host, port, params)
        if not self._version:
            self._version = get_pkginfo(MySQLdb).get('version',
                                                     MySQLdb.__version__)
            mysql_info = 'server: "%s", client: "%s", thread-safe: %s' % \
                         (cnx.cnx.get_server_info(),
                          MySQLdb.get_client_info(),
                          MySQLdb.thread_safe())
            self.env.systeminfo.extend([('MySQL', mysql_info),
                                        ('MySQLdb', self._version)])
            self.required = True
        return cnx

    def get_exceptions(self):
        return MySQLdb

    def init_db(self, path, schema=None, log=None, user=None, password=None,
                host=None, port=None, params={}):
        cnx = self.get_connection(path, log, user, password, host, port,
                                  params)
        cursor = cnx.cursor()
        utf8_size = {'utf8': 3, 'utf8mb4': 4}.get(cnx.charset)
        if schema is None:
            from trac.db_default import schema
        for table in schema:
            for stmt in self.to_sql(table, utf8_size=utf8_size):
                self.log.debug(stmt)
                cursor.execute(stmt)
        cnx.commit()

    def _collist(self, table, columns, utf8_size=3):
        """Take a list of columns and impose limits on each so that indexing
        works properly.

        Some Versions of MySQL limit each index prefix to 1000 bytes total,
        with a max of 767 bytes per column.
        """
        cols = []
        limit_col = 767 / utf8_size
        limit = min(1000 / (utf8_size * len(columns)), limit_col)
        for c in columns:
            name = '`%s`' % c
            table_col = filter((lambda x: x.name == c), table.columns)
            if len(table_col) == 1 and table_col[0].type.lower() == 'text':
                if table_col[0].key_size is not None:
                    name += '(%d)' % min(table_col[0].key_size, limit_col)
                elif name == '`rev`':
                    name += '(20)'
                elif name == '`path`':
                    name += '(%d)' % limit_col
                elif name == '`change_type`':
                    name += '(2)'
                else:
                    name += '(%s)' % limit
            # For non-text columns, we simply throw away the extra bytes.
            # That could certainly be optimized better, but for now let's KISS.
            cols.append(name)
        return ','.join(cols)

    def to_sql(self, table, utf8_size=3):
        sql = ['CREATE TABLE %s (' % table.name]
        coldefs = []
        for column in table.columns:
            ctype = column.type
            ctype = _type_map.get(ctype, ctype)
            if column.auto_increment:
                ctype = 'INT UNSIGNED NOT NULL AUTO_INCREMENT'
                # Override the column type, as a text field cannot
                # use auto_increment.
                column.type = 'int'
            coldefs.append('    `%s` %s' % (column.name, ctype))
        if len(table.key) > 0:
            coldefs.append('    PRIMARY KEY (%s)' %
                           self._collist(table, table.key,
                                         utf8_size=utf8_size))
        sql.append(',\n'.join(coldefs) + '\n)')
        yield '\n'.join(sql)

        for index in table.indices:
            unique = 'UNIQUE' if index.unique else ''
            yield 'CREATE %s INDEX %s_%s_idx ON %s (%s);' % (unique, table.name,
                  '_'.join(index.columns), table.name,
                  self._collist(table, index.columns, utf8_size=utf8_size))

    def alter_column_types(self, table, columns):
        """Yield SQL statements altering the type of one or more columns of
        a table.

        Type changes are specified as a `columns` dict mapping column names
        to `(from, to)` SQL type tuples.
        """
        alterations = []
        for name, (from_, to) in sorted(columns.iteritems()):
            to = _type_map.get(to, to)
            if to != _type_map.get(from_, from_):
                alterations.append((name, to))
        if alterations:
            yield "ALTER TABLE %s %s" % (table,
                ', '.join("MODIFY %s %s" % each
                          for each in alterations))

    def backup(self, dest_file):
        from subprocess import Popen, PIPE
        db_url = self.env.config.get('trac', 'database')
        scheme, db_prop = _parse_db_str(db_url)
        db_params = db_prop.setdefault('params', {})
        db_name = os.path.basename(db_prop['path'])

        args = [self.mysqldump_path]
        if 'host' in db_prop:
            args.extend(['-h', db_prop['host']])
        if 'port' in db_prop:
            args.extend(['-P', str(db_prop['port'])])
        if 'user' in db_prop:
            args.extend(['-u', db_prop['user']])
        for name, value in db_params.iteritems():
            if name == 'compress' and as_int(value, 0):
                args.append('--compress')
            elif name == 'named_pipe' and as_int(value, 0):
                args.append('--protocol=pipe')
            elif name == 'read_default_file': # Must be first
                args.insert(1, '--defaults-file=' + value)
            elif name == 'unix_socket':
                args.extend(['--protocol=socket', '--socket=' + value])
            elif name not in ('init_command', 'read_default_group'):
                self.log.warning("Invalid connection string parameter '%s'",
                                 name)
        args.extend(['-r', dest_file, db_name])

        environ = os.environ.copy()
        if 'password' in db_prop:
            environ['MYSQL_PWD'] = str(db_prop['password'])
        try:
            p = Popen(args, env=environ, stderr=PIPE, close_fds=close_fds)
        except OSError, e:
            raise TracError(_("Unable to run %(path)s: %(msg)s",
                              path=self.mysqldump_path,
                              msg=exception_to_unicode(e)))
        errmsg = p.communicate()[1]
        if p.returncode != 0:
            raise TracError(_("mysqldump failed: %(msg)s",
                              msg=to_unicode(errmsg.strip())))
        if not os.path.exists(dest_file):
            raise TracError(_("No destination file created"))
        return dest_file


class MySQLConnection(ConnectionWrapper):
    """Connection wrapper for MySQL."""

    poolable = True

    def __init__(self, path, log, user=None, password=None, host=None,
                 port=None, params={}):
        if path.startswith('/'):
            path = path[1:]
        if password == None:
            password = ''
        if port == None:
            port = 3306
        opts = {}
        for name, value in params.iteritems():
            if name in ('init_command', 'read_default_file',
                        'read_default_group', 'unix_socket'):
                opts[name] = value
            elif name in ('compress', 'named_pipe'):
                opts[name] = as_int(value, 0)
            else:
                self.log.warning("Invalid connection string parameter '%s'",
                                 name)
        cnx = MySQLdb.connect(db=path, user=user, passwd=password, host=host,
                              port=port, charset='utf8', **opts)
        if hasattr(cnx, 'encoders'):
            # 'encoders' undocumented but present since 1.2.1 (r422)
            cnx.encoders[Markup] = cnx.encoders[types.UnicodeType]
        cursor = cnx.cursor()
        cursor.execute("SHOW VARIABLES WHERE "
                       " variable_name='character_set_database'")
        self.charset = cursor.fetchone()[1]
        if self.charset != 'utf8':
            cnx.query("SET NAMES %s" % self.charset)
            cnx.store_result()
        ConnectionWrapper.__init__(self, cnx, log)
        self._is_closed = False

    def cast(self, column, type):
        if type == 'int' or type == 'int64':
            type = 'signed'
        elif type == 'text':
            type = 'char'
        return 'CAST(%s AS %s)' % (column, type)

    def concat(self, *args):
        return 'concat(%s)' % ', '.join(args)

    def like(self):
        """Return a case-insensitive LIKE clause."""
        return "LIKE %%s COLLATE %s_general_ci ESCAPE '/'" % self.charset

    def like_escape(self, text):
        return _like_escape_re.sub(r'/\1', text)

    def quote(self, identifier):
        """Return the quoted identifier."""
        return "`%s`" % identifier.replace('`', '``')

    def get_last_id(self, cursor, table, column='id'):
        return cursor.lastrowid

    def update_sequence(self, cursor, table, column='id'):
        # MySQL handles sequence updates automagically
        pass

    def rollback(self):
        self.cnx.ping()
        try:
            self.cnx.rollback()
        except MySQLdb.ProgrammingError:
            self._is_closed = True

    def close(self):
        if not self._is_closed:
            try:
                self.cnx.close()
            except MySQLdb.ProgrammingError:
                pass # this error would mean it's already closed.  So, ignore
            self._is_closed = True

    def cursor(self):
        return IterableCursor(MySQLUnicodeCursor(self.cnx), self.log)

########NEW FILE########
__FILENAME__ = pool
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import os
import time

from trac.core import TracError
from trac.db.util import ConnectionWrapper
from trac.util.concurrency import threading
from trac.util.text import exception_to_unicode
from trac.util.translation import _


class TimeoutError(Exception):
    """Exception raised by the connection pool when no connection has become
    available after a given timeout."""


class PooledConnection(ConnectionWrapper):
    """A database connection that can be pooled. When closed, it gets returned
    to the pool.
    """

    def __init__(self, pool, cnx, key, tid, log=None):
        ConnectionWrapper.__init__(self, cnx, log)
        self._pool = pool
        self._key = key
        self._tid = tid

    def close(self):
        if self.cnx:
            cnx = self.cnx
            self.cnx = None
            self.log = None
            self._pool._return_cnx(cnx, self._key, self._tid)

    def __del__(self):
        self.close()



class ConnectionPoolBackend(object):
    """A process-wide LRU-based connection pool.
    """
    def __init__(self, maxsize):
        self._available = threading.Condition(threading.RLock())
        self._maxsize = maxsize
        self._active = {}
        self._pool = []
        self._pool_key = []
        self._pool_time = []
        self._waiters = 0

    def get_cnx(self, connector, kwargs, timeout=None):
        cnx = None
        log = kwargs.get('log')
        key = unicode(kwargs)
        start = time.time()
        tid = threading._get_ident()
        # Get a Connection, either directly or a deferred one
        with self._available:
            # First choice: Return the same cnx already used by the thread
            if (tid, key) in self._active:
                cnx, num = self._active[(tid, key)]
                num += 1
            else:
                if self._waiters == 0:
                    cnx = self._take_cnx(connector, kwargs, key, tid)
                if not cnx:
                    self._waiters += 1
                    self._available.wait()
                    self._waiters -= 1
                    cnx = self._take_cnx(connector, kwargs, key, tid)
                num = 1
            if cnx:
                self._active[(tid, key)] = (cnx, num)

        deferred = num == 1 and isinstance(cnx, tuple)
        err = None
        if deferred:
            # Potentially lenghty operations must be done without lock held
            op, cnx = cnx
            try:
                if op == 'ping':
                    cnx.ping()
                elif op == 'close':
                    cnx.close()
                if op in ('close', 'create'):
                    cnx = connector.get_connection(**kwargs)
            except TracError, e:
                err = e
                cnx = None
            except Exception, e:
                if log:
                    log.error('Exception caught on %s', op, exc_info=True)
                err = e
                cnx = None

        if cnx:
            if deferred:
                # replace placeholder with real Connection
                with self._available:
                    self._active[(tid, key)] = (cnx, num)
            return PooledConnection(self, cnx, key, tid, log)

        if deferred:
            # cnx couldn't be reused, clear placeholder
            with self._available:
                del self._active[(tid, key)]
            if op == 'ping': # retry
                return self.get_cnx(connector, kwargs)

        # if we didn't get a cnx after wait(), something's fishy...
        timeout = time.time() - start
        errmsg = _("Unable to get database connection within %(time)d seconds.",
                   time=timeout)
        if err:
            errmsg += " (%s)" % exception_to_unicode(err)
        raise TimeoutError(errmsg)

    def _take_cnx(self, connector, kwargs, key, tid):
        """Note: _available lock must be held when calling this method."""
        # Second best option: Reuse a live pooled connection
        if key in self._pool_key:
            idx = self._pool_key.index(key)
            self._pool_key.pop(idx)
            self._pool_time.pop(idx)
            cnx = self._pool.pop(idx)
            # If possible, verify that the pooled connection is
            # still available and working.
            if hasattr(cnx, 'ping'):
                return ('ping', cnx)
            return cnx
        # Third best option: Create a new connection
        elif len(self._active) + len(self._pool) < self._maxsize:
            return ('create', None)
        # Forth best option: Replace a pooled connection with a new one
        elif len(self._active) < self._maxsize:
            # Remove the LRU connection in the pool
            cnx = self._pool.pop(0)
            self._pool_key.pop(0)
            self._pool_time.pop(0)
            return ('close', cnx)

    def _return_cnx(self, cnx, key, tid):
        # Decrement active refcount, clear slot if 1
        with self._available:
            assert (tid, key) in self._active
            cnx, num = self._active[(tid, key)]
            if num == 1:
                del self._active[(tid, key)]
            else:
                self._active[(tid, key)] = (cnx, num - 1)
        if num == 1:
            # Reset connection outside of critical section
            try:
                cnx.rollback() # resets the connection
            except Exception:
                cnx.close()
                cnx = None
            # Connection available, from reuse or from creation of a new one
            with self._available:
                if cnx and cnx.poolable:
                    self._pool.append(cnx)
                    self._pool_key.append(key)
                    self._pool_time.append(time.time())
                self._available.notify()

    def shutdown(self, tid=None):
        """Close pooled connections not used in a while"""
        delay = 120
        if tid is None:
            delay = 0
        when = time.time() - delay
        with self._available:
            if tid is None: # global shutdown, also close active connections
                for db, num in self._active.values():
                    db.close()
                self._active = {}
            while self._pool_time and self._pool_time[0] <= when:
                db = self._pool.pop(0)
                db.close()
                self._pool_key.pop(0)
                self._pool_time.pop(0)


_pool_size = int(os.environ.get('TRAC_DB_POOL_SIZE', 10))
_backend = ConnectionPoolBackend(_pool_size)


class ConnectionPool(object):
    def __init__(self, maxsize, connector, **kwargs):
        # maxsize not used right now but kept for api compatibility
        self._connector = connector
        self._kwargs = kwargs

    def get_cnx(self, timeout=None):
        return _backend.get_cnx(self._connector, self._kwargs, timeout)

    def shutdown(self, tid=None):
        _backend.shutdown(tid)


########NEW FILE########
__FILENAME__ = postgres_backend
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

import re, os

from genshi import Markup

from trac.core import *
from trac.config import Option
from trac.db.api import IDatabaseConnector, _parse_db_str
from trac.db.util import ConnectionWrapper, IterableCursor
from trac.util import get_pkginfo
from trac.util.compat import close_fds
from trac.util.text import empty, exception_to_unicode, to_unicode
from trac.util.translation import _

has_psycopg = False
try:
    import psycopg2 as psycopg
    import psycopg2.extensions
    from psycopg2 import DataError, ProgrammingError
    from psycopg2.extensions import register_type, UNICODE, \
                                    register_adapter, AsIs, QuotedString

    register_type(UNICODE)
    register_adapter(Markup, lambda markup: QuotedString(unicode(markup)))
    register_adapter(type(empty), lambda empty: AsIs("''"))

    has_psycopg = True
except ImportError:
    pass

_like_escape_re = re.compile(r'([/_%])')

# Mapping from "abstract" SQL types to DB-specific types
_type_map = {
    'int64': 'bigint',
}


def assemble_pg_dsn(path, user=None, password=None, host=None, port=None):
    """Quote the parameters and assemble the DSN."""

    dsn = {'dbname': path, 'user': user, 'password': password, 'host': host,
           'port': port}
    return ' '.join(["%s='%s'" % (k,v) for k,v in dsn.iteritems() if v])


class PostgreSQLConnector(Component):
    """Database connector for PostgreSQL.

    Database URLs should be of the form:
    {{{
    postgres://user[:password]@host[:port]/database[?schema=my_schema]
    }}}
    """
    implements(IDatabaseConnector)

    pg_dump_path = Option('trac', 'pg_dump_path', 'pg_dump',
        """Location of pg_dump for Postgres database backups""")

    def __init__(self):
        self._version = None
        self.error = None

    def get_supported_schemes(self):
        if not has_psycopg:
            self.error = _("Cannot load Python bindings for PostgreSQL")
        yield ('postgres', -1 if self.error else 1)

    def get_connection(self, path, log=None, user=None, password=None,
                       host=None, port=None, params={}):
        cnx = PostgreSQLConnection(path, log, user, password, host, port,
                                   params)
        if not self._version:
            self._version = get_pkginfo(psycopg).get('version',
                                                     psycopg.__version__)
            self.env.systeminfo.append(('psycopg2', self._version))
            self.required = True
        return cnx

    def get_exceptions(self):
        return psycopg

    def init_db(self, path, schema=None, log=None, user=None, password=None,
                host=None, port=None, params={}):
        cnx = self.get_connection(path, log, user, password, host, port,
                                  params)
        cursor = cnx.cursor()
        if cnx.schema:
            cursor.execute('CREATE SCHEMA "%s"' % cnx.schema)
            cursor.execute('SET search_path TO %s', (cnx.schema,))
        if schema is None:
            from trac.db_default import schema
        for table in schema:
            for stmt in self.to_sql(table):
                cursor.execute(stmt)
        cnx.commit()

    def to_sql(self, table):
        sql = ['CREATE TABLE "%s" (' % table.name]
        coldefs = []
        for column in table.columns:
            ctype = column.type
            ctype = _type_map.get(ctype, ctype)
            if column.auto_increment:
                ctype = 'SERIAL'
            if len(table.key) == 1 and column.name in table.key:
                ctype += ' PRIMARY KEY'
            coldefs.append('    "%s" %s' % (column.name, ctype))
        if len(table.key) > 1:
            coldefs.append('    CONSTRAINT "%s_pk" PRIMARY KEY ("%s")'
                           % (table.name, '","'.join(table.key)))
        sql.append(',\n'.join(coldefs) + '\n)')
        yield '\n'.join(sql)
        for index in table.indices:
            unique = 'UNIQUE' if index.unique else ''
            yield 'CREATE %s INDEX "%s_%s_idx" ON "%s" ("%s")' % \
                    (unique, table.name,
                     '_'.join(index.columns), table.name,
                     '","'.join(index.columns))

    def alter_column_types(self, table, columns):
        """Yield SQL statements altering the type of one or more columns of
        a table.

        Type changes are specified as a `columns` dict mapping column names
        to `(from, to)` SQL type tuples.
        """
        alterations = []
        for name, (from_, to) in sorted(columns.iteritems()):
            to = _type_map.get(to, to)
            if to != _type_map.get(from_, from_):
                alterations.append((name, to))
        if alterations:
            yield "ALTER TABLE %s %s" % (table,
                ', '.join("ALTER COLUMN %s TYPE %s" % each
                          for each in alterations))

    def backup(self, dest_file):
        from subprocess import Popen, PIPE
        db_url = self.env.config.get('trac', 'database')
        scheme, db_prop = _parse_db_str(db_url)
        db_params = db_prop.setdefault('params', {})
        db_name = os.path.basename(db_prop['path'])

        args = [self.pg_dump_path, '-C', '--inserts', '-x', '-Z', '8']
        if 'user' in db_prop:
            args.extend(['-U', db_prop['user']])
        if 'host' in db_params:
            host = db_params['host']
        else:
            host = db_prop.get('host')
        if host:
            args.extend(['-h', host])
            if '/' not in host:
                args.extend(['-p', str(db_prop.get('port', '5432'))])

        if 'schema' in db_params:
            try:
                p = Popen([self.pg_dump_path, '--version'], stdout=PIPE,
                          close_fds=close_fds)
            except OSError, e:
                raise TracError(_("Unable to run %(path)s: %(msg)s",
                                  path=self.pg_dump_path,
                                  msg=exception_to_unicode(e)))
            # Need quote for -n (--schema) option in PostgreSQL 8.2+
            version = p.communicate()[0]
            if re.search(r' 8\.[01]\.', version):
                args.extend(['-n', db_params['schema']])
            else:
                args.extend(['-n', '"%s"' % db_params['schema']])

        dest_file += ".gz"
        args.extend(['-f', dest_file, db_name])

        environ = os.environ.copy()
        if 'password' in db_prop:
            environ['PGPASSWORD'] = str(db_prop['password'])
        try:
            p = Popen(args, env=environ, stderr=PIPE, close_fds=close_fds)
        except OSError, e:
            raise TracError(_("Unable to run %(path)s: %(msg)s",
                              path=self.pg_dump_path,
                              msg=exception_to_unicode(e)))
        errmsg = p.communicate()[1]
        if p.returncode != 0:
            raise TracError(_("pg_dump failed: %(msg)s",
                              msg=to_unicode(errmsg.strip())))
        if not os.path.exists(dest_file):
            raise TracError(_("No destination file created"))
        return dest_file


class PostgreSQLConnection(ConnectionWrapper):
    """Connection wrapper for PostgreSQL."""

    poolable = True

    def __init__(self, path, log=None, user=None, password=None, host=None,
                 port=None, params={}):
        if path.startswith('/'):
            path = path[1:]
        if 'host' in params:
            host = params['host']

        cnx = psycopg.connect(assemble_pg_dsn(path, user, password, host,
                                              port))

        cnx.set_client_encoding('UNICODE')
        try:
            self.schema = None
            if 'schema' in params:
                self.schema = params['schema']
                cnx.cursor().execute('SET search_path TO %s', (self.schema,))
                cnx.commit()
        except (DataError, ProgrammingError):
            cnx.rollback()
        ConnectionWrapper.__init__(self, cnx, log)

    def cast(self, column, type):
        # Temporary hack needed for the union of selects in the search module
        return 'CAST(%s AS %s)' % (column, _type_map.get(type, type))

    def concat(self, *args):
        return '||'.join(args)

    def like(self):
        """Return a case-insensitive LIKE clause."""
        return "ILIKE %s ESCAPE '/'"

    def like_escape(self, text):
        return _like_escape_re.sub(r'/\1', text)

    def quote(self, identifier):
        """Return the quoted identifier."""
        return '"%s"' % identifier.replace('"', '""')

    def get_last_id(self, cursor, table, column='id'):
        cursor.execute("""SELECT CURRVAL('"%s_%s_seq"')""" % (table, column))
        return cursor.fetchone()[0]

    def update_sequence(self, cursor, table, column='id'):
        cursor.execute("""
            SELECT setval('"%s_%s_seq"', (SELECT MAX(%s) FROM %s))
            """ % (table, column, column, table))

    def cursor(self):
        return IterableCursor(self.cnx.cursor(), self.log)


########NEW FILE########
__FILENAME__ = schema
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>


class Table(object):
    """Declare a table in a database schema."""

    def __init__(self, name, key=[]):
        self.name = name
        self.columns = []
        self.indices = []
        self.key = key
        if isinstance(key, basestring):
            self.key = [key]

    def __getitem__(self, objs):
        self.columns = [o for o in objs if isinstance(o, Column)]
        self.indices = [o for o in objs if isinstance(o, Index)]
        return self


class Column(object):
    """Declare a table column in a database schema."""

    def __init__(self, name, type='text', size=None, key_size=None,
                 auto_increment=False):
        self.name = name
        self.type = type
        self.size = size
        self.key_size = key_size
        self.auto_increment = auto_increment


class Index(object):
    """Declare an index for a database schema."""

    def __init__(self, columns, unique=False):
        self.columns = columns
        self.unique = unique

########NEW FILE########
__FILENAME__ = sqlite_backend
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2010 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

import os
import re
import weakref

from trac.config import ListOption
from trac.core import *
from trac.db.api import IDatabaseConnector
from trac.db.util import ConnectionWrapper, IterableCursor
from trac.util import get_pkginfo, getuser
from trac.util.translation import _

_like_escape_re = re.compile(r'([/_%])')

try:
    import pysqlite2.dbapi2 as sqlite
    have_pysqlite = 2
except ImportError:
    try:
        import sqlite3 as sqlite
        have_pysqlite = 2
    except ImportError:
        have_pysqlite = 0

if have_pysqlite == 2:
    # Force values to integers because PySQLite 2.2.0 had (2, 2, '0')
    sqlite_version = tuple([int(x) for x in sqlite.sqlite_version_info])
    sqlite_version_string = sqlite.sqlite_version

    class PyFormatCursor(sqlite.Cursor):
        def _rollback_on_error(self, function, *args, **kwargs):
            try:
                return function(self, *args, **kwargs)
            except sqlite.DatabaseError:
                self.cnx.rollback()
                raise
        def execute(self, sql, args=None):
            if args:
                sql = sql % (('?',) * len(args))
            return self._rollback_on_error(sqlite.Cursor.execute, sql,
                                           args or [])
        def executemany(self, sql, args):
            if not args:
                return
            sql = sql % (('?',) * len(args[0]))
            return self._rollback_on_error(sqlite.Cursor.executemany, sql,
                                           args)

    # EagerCursor taken from the example in pysqlite's repository:
    #
    #   http://code.google.com/p/pysqlite/source/browse/misc/eager.py
    #
    # Only change is to subclass it from PyFormatCursor instead of
    # sqlite.Cursor.

    class EagerCursor(PyFormatCursor):
        def __init__(self, con):
            PyFormatCursor.__init__(self, con)
            self.rows = []
            self.pos = 0

        def execute(self, *args):
            result = PyFormatCursor.execute(self, *args)
            self.rows = PyFormatCursor.fetchall(self)
            self.pos = 0
            return result

        def fetchone(self):
            try:
                row = self.rows[self.pos]
                self.pos += 1
                return row
            except IndexError:
                return None

        def fetchmany(self, num=None):
            if num is None:
                num = self.arraysize

            result = self.rows[self.pos:self.pos+num]
            self.pos += num
            return result

        def fetchall(self):
            result = self.rows[self.pos:]
            self.pos = len(self.rows)
            return result


# Mapping from "abstract" SQL types to DB-specific types
_type_map = {
    'int': 'integer',
    'int64': 'integer',
}


def _to_sql(table):
    sql = ["CREATE TABLE %s (" % table.name]
    coldefs = []
    for column in table.columns:
        ctype = column.type.lower()
        ctype = _type_map.get(ctype, ctype)
        if column.auto_increment:
            ctype = "integer PRIMARY KEY"
        elif len(table.key) == 1 and column.name in table.key:
            ctype += " PRIMARY KEY"
        coldefs.append("    %s %s" % (column.name, ctype))
    if len(table.key) > 1:
        coldefs.append("    UNIQUE (%s)" % ','.join(table.key))
    sql.append(',\n'.join(coldefs) + '\n);')
    yield '\n'.join(sql)
    for index in table.indices:
        unique = 'UNIQUE' if index.unique else ''
        yield "CREATE %s INDEX %s_%s_idx ON %s (%s);" % (unique, table.name,
              '_'.join(index.columns), table.name, ','.join(index.columns))


class SQLiteConnector(Component):
    """Database connector for SQLite.

    Database URLs should be of the form:
    {{{
    sqlite:path/to/trac.db
    }}}
    """
    implements(IDatabaseConnector)

    extensions = ListOption('sqlite', 'extensions',
        doc="""Paths to sqlite extensions, relative to Trac environment's
        directory or absolute. (''since 0.12'')""")

    memory_cnx = None

    def __init__(self):
        self._version = None
        self.error = None
        self._extensions = None

    def get_supported_schemes(self):
        if not have_pysqlite:
            self.error = _("Cannot load Python bindings for SQLite")
        elif sqlite_version >= (3, 3, 3) and sqlite.version_info[0] == 2 and \
                sqlite.version_info < (2, 0, 7):
            self.error = _("Need at least PySqlite %(version)s or higher",
                           version='2.0.7')
        elif (2, 5, 2) <= sqlite.version_info < (2, 5, 5):
            self.error = _("PySqlite 2.5.2 - 2.5.4 break Trac, please use "
                           "2.5.5 or higher")
        yield ('sqlite', -1 if self.error else 1)

    def get_connection(self, path, log=None, params={}):
        if not self._version:
            self._version = get_pkginfo(sqlite).get(
                'version', '%d.%d.%s' % sqlite.version_info)
            self.env.systeminfo.extend([('SQLite', sqlite_version_string),
                                        ('pysqlite', self._version)])
            self.required = True
        # construct list of sqlite extension libraries
        if self._extensions is None:
            self._extensions = []
            for extpath in self.extensions:
                if not os.path.isabs(extpath):
                    extpath = os.path.join(self.env.path, extpath)
                self._extensions.append(extpath)
        params['extensions'] = self._extensions
        if path == ':memory:':
            if not self.memory_cnx:
                self.memory_cnx = SQLiteConnection(path, log, params)
            return self.memory_cnx
        else:
            return SQLiteConnection(path, log, params)

    def get_exceptions(self):
        return sqlite

    def init_db(self, path, schema=None, log=None, params={}):
        if path != ':memory:':
            # make the directory to hold the database
            if os.path.exists(path):
                raise TracError(_("Database already exists at %(path)s",
                                  path=path))
            dir = os.path.dirname(path)
            if not os.path.exists(dir):
                os.makedirs(dir)
            if isinstance(path, unicode): # needed with 2.4.0
                path = path.encode('utf-8')
            # this direct connect will create the database if needed
            cnx = sqlite.connect(path,
                                 timeout=int(params.get('timeout', 10000)))
        else:
            cnx = self.get_connection(path, log, params)
        cursor = cnx.cursor()
        if schema is None:
            from trac.db_default import schema
        for table in schema:
            for stmt in self.to_sql(table):
                cursor.execute(stmt)
        cnx.commit()

    def to_sql(self, table):
        return _to_sql(table)

    def alter_column_types(self, table, columns):
        """Yield SQL statements altering the type of one or more columns of
        a table.

        Type changes are specified as a `columns` dict mapping column names
        to `(from, to)` SQL type tuples.
        """
        for name, (from_, to) in sorted(columns.iteritems()):
            if _type_map.get(to, to) != _type_map.get(from_, from_):
                raise NotImplementedError('Conversion from %s to %s is not '
                                          'implemented' % (from_, to))
        return ()

    def backup(self, dest_file):
        """Simple SQLite-specific backup of the database.

        @param dest_file: Destination file basename
        """
        import shutil
        db_str = self.config.get('trac', 'database')
        try:
            db_str = db_str[:db_str.index('?')]
        except ValueError:
            pass
        db_name = os.path.join(self.env.path, db_str[7:])
        shutil.copy(db_name, dest_file)
        if not os.path.exists(dest_file):
            raise TracError(_("No destination file created"))
        return dest_file


class SQLiteConnection(ConnectionWrapper):
    """Connection wrapper for SQLite."""

    __slots__ = ['_active_cursors', '_eager']

    poolable = have_pysqlite and sqlite_version >= (3, 3, 8) \
                             and sqlite.version_info >= (2, 5, 0)

    def __init__(self, path, log=None, params={}):
        assert have_pysqlite > 0
        self.cnx = None
        if path != ':memory:':
            if not os.access(path, os.F_OK):
                raise TracError(_('Database "%(path)s" not found.', path=path))

            dbdir = os.path.dirname(path)
            if not os.access(path, os.R_OK + os.W_OK) or \
                   not os.access(dbdir, os.R_OK + os.W_OK):
                raise TracError(
                    _('The user %(user)s requires read _and_ write '
                      'permissions to the database file %(path)s '
                      'and the directory it is located in.',
                      user=getuser(), path=path))

        self._active_cursors = weakref.WeakKeyDictionary()
        timeout = int(params.get('timeout', 10.0))
        self._eager = params.get('cursor', 'eager') == 'eager'
        # eager is default, can be turned off by specifying ?cursor=
        if isinstance(path, unicode): # needed with 2.4.0
            path = path.encode('utf-8')
        cnx = sqlite.connect(path, detect_types=sqlite.PARSE_DECLTYPES,
                             check_same_thread=sqlite_version < (3, 3, 1),
                             timeout=timeout)
        # load extensions
        extensions = params.get('extensions', [])
        if len(extensions) > 0:
            cnx.enable_load_extension(True)
            for ext in extensions:
                cnx.load_extension(ext)
            cnx.enable_load_extension(False)

        ConnectionWrapper.__init__(self, cnx, log)

    def cursor(self):
        cursor = self.cnx.cursor((PyFormatCursor, EagerCursor)[self._eager])
        self._active_cursors[cursor] = True
        cursor.cnx = self
        return IterableCursor(cursor, self.log)

    def rollback(self):
        for cursor in self._active_cursors.keys():
            cursor.close()
        self.cnx.rollback()

    def cast(self, column, type):
        if sqlite_version >= (3, 2, 3):
            return 'CAST(%s AS %s)' % (column, _type_map.get(type, type))
        elif type == 'int':
            # hack to force older SQLite versions to convert column to an int
            return '1*' + column
        else:
            return column

    def concat(self, *args):
        return '||'.join(args)

    def like(self):
        """Return a case-insensitive LIKE clause."""
        if sqlite_version >= (3, 1, 0):
            return "LIKE %s ESCAPE '/'"
        else:
            return 'LIKE %s'

    def like_escape(self, text):
        if sqlite_version >= (3, 1, 0):
            return _like_escape_re.sub(r'/\1', text)
        else:
            return text

    def quote(self, identifier):
        """Return the quoted identifier."""
        return "`%s`" % identifier.replace('`', '``')

    def get_last_id(self, cursor, table, column='id'):
        return cursor.lastrowid

    def update_sequence(self, cursor, table, column='id'):
        # SQLite handles sequence updates automagically
        # http://www.sqlite.org/autoinc.html
        pass

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-

from __future__ import with_statement

import os
import unittest

from trac.db.api import DatabaseManager, _parse_db_str, get_column_names, \
                        with_transaction
from trac.test import EnvironmentStub, Mock
from trac.util.concurrency import ThreadLocal


class Connection(object):

    committed = False
    rolledback = False

    def commit(self):
        self.committed = True

    def rollback(self):
        self.rolledback = True


class Error(Exception):
    pass


def make_env(get_cnx):
    return Mock(components={DatabaseManager:
             Mock(get_connection=get_cnx,
                  _transaction_local=ThreadLocal(wdb=None, rdb=None))})


class WithTransactionTest(unittest.TestCase):

    def test_successful_transaction(self):
        db = Connection()
        env = make_env(lambda: db)
        @with_transaction(env)
        def do_transaction(db):
            self.assertTrue(not db.committed and not db.rolledback)
        self.assertTrue(db.committed and not db.rolledback)

    def test_failed_transaction(self):
        db = Connection()
        env = make_env(lambda: db)
        try:
            @with_transaction(env)
            def do_transaction(db):
                self.assertTrue(not db.committed and not db.rolledback)
                raise Error()
            self.fail()
        except Error:
            pass
        self.assertTrue(not db.committed and db.rolledback)

    def test_implicit_nesting_success(self):
        env = make_env(Connection)
        dbs = [None, None]
        @with_transaction(env)
        def level0(db):
            dbs[0] = db
            @with_transaction(env)
            def level1(db):
                dbs[1] = db
                self.assertTrue(not db.committed and not db.rolledback)
            self.assertTrue(not db.committed and not db.rolledback)
        self.assertTrue(dbs[0] is not None)
        self.assertTrue(dbs[0] is dbs[1])
        self.assertTrue(dbs[0].committed and not dbs[0].rolledback)

    def test_implicit_nesting_failure(self):
        env = make_env(Connection)
        dbs = [None, None]
        try:
            @with_transaction(env)
            def level0(db):
                dbs[0] = db
                try:
                    @with_transaction(env)
                    def level1(db):
                        dbs[1] = db
                        self.assertTrue(not db.committed and not db.rolledback)
                        raise Error()
                    self.fail()
                except Error:
                    self.assertTrue(not db.committed and not db.rolledback)
                    raise
            self.fail()
        except Error:
            pass
        self.assertTrue(dbs[0] is not None)
        self.assertTrue(dbs[0] is dbs[1])
        self.assertTrue(not dbs[0].committed and dbs[0].rolledback)

    def test_explicit_success(self):
        db = Connection()
        env = make_env(lambda: None)
        @with_transaction(env, db)
        def do_transaction(idb):
            self.assertTrue(idb is db)
            self.assertTrue(not db.committed and not db.rolledback)
        self.assertTrue(not db.committed and not db.rolledback)

    def test_explicit_failure(self):
        db = Connection()
        env = make_env(lambda: None)
        try:
            @with_transaction(env, db)
            def do_transaction(idb):
                self.assertTrue(idb is db)
                self.assertTrue(not db.committed and not db.rolledback)
                raise Error()
            self.fail()
        except Error:
            pass
        self.assertTrue(not db.committed and not db.rolledback)

    def test_implicit_in_explicit_success(self):
        db = Connection()
        env = make_env(lambda: db)
        dbs = [None, None]
        @with_transaction(env, db)
        def level0(db):
            dbs[0] = db
            @with_transaction(env)
            def level1(db):
                dbs[1] = db
                self.assertTrue(not db.committed and not db.rolledback)
            self.assertTrue(not db.committed and not db.rolledback)
        self.assertTrue(dbs[0] is not None)
        self.assertTrue(dbs[0] is dbs[1])
        self.assertTrue(not dbs[0].committed and not dbs[0].rolledback)

    def test_implicit_in_explicit_failure(self):
        db = Connection()
        env = make_env(lambda: db)
        dbs = [None, None]
        try:
            @with_transaction(env, db)
            def level0(db):
                dbs[0] = db
                @with_transaction(env)
                def level1(db):
                    dbs[1] = db
                    self.assertTrue(not db.committed and not db.rolledback)
                    raise Error()
                self.fail()
            self.fail()
        except Error:
            pass
        self.assertTrue(dbs[0] is not None)
        self.assertTrue(dbs[0] is dbs[1])
        self.assertTrue(not dbs[0].committed and not dbs[0].rolledback)

    def test_explicit_in_implicit_success(self):
        db = Connection()
        env = make_env(lambda: db)
        dbs = [None, None]
        @with_transaction(env)
        def level0(db):
            dbs[0] = db
            @with_transaction(env, db)
            def level1(db):
                dbs[1] = db
                self.assertTrue(not db.committed and not db.rolledback)
            self.assertTrue(not db.committed and not db.rolledback)
        self.assertTrue(dbs[0] is not None)
        self.assertTrue(dbs[0] is dbs[1])
        self.assertTrue(dbs[0].committed and not dbs[0].rolledback)

    def test_explicit_in_implicit_failure(self):
        db = Connection()
        env = make_env(lambda: db)
        dbs = [None, None]
        try:
            @with_transaction(env)
            def level0(db):
                dbs[0] = db
                @with_transaction(env, db)
                def level1(db):
                    dbs[1] = db
                    self.assertTrue(not db.committed and not db.rolledback)
                    raise Error()
                self.fail()
            self.fail()
        except Error:
            pass
        self.assertTrue(dbs[0] is not None)
        self.assertTrue(dbs[0] is dbs[1])
        self.assertTrue(not dbs[0].committed and dbs[0].rolledback)

    def test_invalid_nesting(self):
        env = make_env(Connection)
        try:
            @with_transaction(env)
            def level0(db):
                @with_transaction(env, Connection())
                def level1(db):
                    raise Error()
                raise Error()
            raise Error()
        except AssertionError:
            pass



class ParseConnectionStringTestCase(unittest.TestCase):

    def test_sqlite_relative(self):
        # Default syntax for specifying DB path relative to the environment
        # directory
        self.assertEqual(('sqlite', {'path': 'db/trac.db'}),
                         _parse_db_str('sqlite:db/trac.db'))

    def test_sqlite_absolute(self):
        # Standard syntax
        self.assertEqual(('sqlite', {'path': '/var/db/trac.db'}),
                         _parse_db_str('sqlite:///var/db/trac.db'))
        # Legacy syntax
        self.assertEqual(('sqlite', {'path': '/var/db/trac.db'}),
                         _parse_db_str('sqlite:/var/db/trac.db'))

    def test_sqlite_with_timeout_param(self):
        # In-memory database
        self.assertEqual(('sqlite', {'path': 'db/trac.db',
                                     'params': {'timeout': '10000'}}),
                         _parse_db_str('sqlite:db/trac.db?timeout=10000'))

    def test_sqlite_windows_path(self):
        # In-memory database
        os_name = os.name
        try:
            os.name = 'nt'
            self.assertEqual(('sqlite', {'path': 'C:/project/db/trac.db'}),
                             _parse_db_str('sqlite:C|/project/db/trac.db'))
        finally:
            os.name = os_name

    def test_postgres_simple(self):
        self.assertEqual(('postgres', {'host': 'localhost', 'path': '/trac'}),
                         _parse_db_str('postgres://localhost/trac'))

    def test_postgres_with_port(self):
        self.assertEqual(('postgres', {'host': 'localhost', 'port': 9431,
                                       'path': '/trac'}),
                         _parse_db_str('postgres://localhost:9431/trac'))

    def test_postgres_with_creds(self):
        self.assertEqual(('postgres', {'user': 'john', 'password': 'letmein',
                                       'host': 'localhost', 'port': 9431,
                                       'path': '/trac'}),
                 _parse_db_str('postgres://john:letmein@localhost:9431/trac'))

    def test_postgres_with_quoted_password(self):
        self.assertEqual(('postgres', {'user': 'john', 'password': ':@/',
                                       'host': 'localhost', 'path': '/trac'}),
                     _parse_db_str('postgres://john:%3a%40%2f@localhost/trac'))

    def test_mysql_simple(self):
        self.assertEqual(('mysql', {'host': 'localhost', 'path': '/trac'}),
                     _parse_db_str('mysql://localhost/trac'))

    def test_mysql_with_creds(self):
        self.assertEqual(('mysql', {'user': 'john', 'password': 'letmein',
                                    'host': 'localhost', 'port': 3306,
                                    'path': '/trac'}),
                     _parse_db_str('mysql://john:letmein@localhost:3306/trac'))


class StringsTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()

    def test_insert_unicode(self):
        self.env.db_transaction(
                "INSERT INTO system (name,value) VALUES (%s,%s)",
                ('test-unicode', u'nicde'))
        self.assertEqual([(u'nicde',)], self.env.db_query(
            "SELECT value FROM system WHERE name='test-unicode'"))

    def test_insert_empty(self):
        from trac.util.text import empty
        self.env.db_transaction(
                "INSERT INTO system (name,value) VALUES (%s,%s)",
                ('test-empty', empty))
        self.assertEqual([(u'',)], self.env.db_query(
            "SELECT value FROM system WHERE name='test-empty'"))

    def test_insert_markup(self):
        from genshi.core import Markup
        self.env.db_transaction(
                "INSERT INTO system (name,value) VALUES (%s,%s)",
                ('test-markup', Markup(u'<em>mrkup</em>')))
        self.assertEqual([(u'<em>mrkup</em>',)], self.env.db_query(
            "SELECT value FROM system WHERE name='test-markup'"))

    def test_quote(self):
        db = self.env.get_db_cnx()
        cursor = db.cursor()
        cursor.execute('SELECT 1 AS %s' % \
                       db.quote(r'alpha\`\"\'\\beta``gamma""delta'))
        self.assertEqual(r'alpha\`\"\'\\beta``gamma""delta',
                         get_column_names(cursor)[0])


class ConnectionTestCase(unittest.TestCase):
    def setUp(self):
        self.env = EnvironmentStub()

    def tearDown(self):
        self.env.reset_db()

    def test_get_last_id(self):
        id1 = id2 = None
        q = "INSERT INTO report (author) VALUES ('anonymous')"
        with self.env.db_transaction as db:
            cursor = db.cursor()
            cursor.execute(q)
            # Row ID correct before...
            id1 = db.get_last_id(cursor, 'report')
            self.assertNotEqual(0, id1)
            db.commit()
            cursor.execute(q)
            # ... and after commit()
            db.commit()
            id2 = db.get_last_id(cursor, 'report')
            self.assertEqual(id1 + 1, id2)

    def test_update_sequence(self):
        self.env.db_transaction(
            "INSERT INTO report (id, author) VALUES (42, 'anonymous')")
        with self.env.db_transaction as db:
            cursor = db.cursor()
            db.update_sequence(cursor, 'report', 'id')
        self.env.db_transaction(
            "INSERT INTO report (author) VALUES ('next-id')")
        self.assertEqual(43, self.env.db_query(
                "SELECT id FROM report WHERE author='next-id'")[0][0])


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(ParseConnectionStringTestCase, 'test'))
    suite.addTest(unittest.makeSuite(StringsTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ConnectionTestCase, 'test'))
    suite.addTest(unittest.makeSuite(WithTransactionTest, 'test'))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = functional
#!/usr/bin/python

import os
from trac.tests.functional import *


class DatabaseBackupTestCase(FunctionalTestCaseSetup):
    def runTest(self):
        """Testing backup"""
        env = self._testenv.get_trac_environment()
        # raises TracError if backup fails
        backup_file = env.backup()
        self.assertTrue(os.path.exists(backup_file),
                        'Backup file was not created.')
        self.assertNotEqual(os.path.getsize(backup_file), 0,
                            'Backup file is zero length.')


def functionalSuite(suite=None):
    if not suite:
        import trac.tests.functional.testcases
        suite = trac.tests.functional.testcases.functionalSuite()
    suite.addTest(DatabaseBackupTestCase())
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='functionalSuite')


########NEW FILE########
__FILENAME__ = mysql_test
# -*- coding: utf-8 -*-
#
# Copyright (C) 2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import unittest

from trac.db.mysql_backend import MySQLConnector
from trac.test import EnvironmentStub


class MySQLTableAlterationSQLTest(unittest.TestCase):
    def setUp(self):
        self.env = EnvironmentStub()

    def test_alter_column_types(self):
        connector = MySQLConnector(self.env)
        sql = connector.alter_column_types('milestone',
                                           {'due': ('int', 'int64'),
                                            'completed': ('int', 'int64')})
        sql = list(sql)
        self.assertEqual([
            "ALTER TABLE milestone "
                "MODIFY completed bigint, "
                "MODIFY due bigint",
            ], sql)

    def test_alter_column_types_same(self):
        connector = MySQLConnector(self.env)
        sql = connector.alter_column_types('milestone',
                                           {'due': ('int', 'int'),
                                            'completed': ('int', 'int64')})
        sql = list(sql)
        self.assertEqual([
            "ALTER TABLE milestone "
                "MODIFY completed bigint",
            ], sql)

    def test_alter_column_types_none(self):
        connector = MySQLConnector(self.env)
        sql = connector.alter_column_types('milestone',
                                           {'due': ('int', 'int')})
        self.assertEqual([], list(sql))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(MySQLTableAlterationSQLTest, 'test'))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = postgres_test
# -*- coding: utf-8 -*-

import re
import unittest

from trac.db import Table, Column, Index
from trac.db.postgres_backend import PostgreSQLConnector, assemble_pg_dsn
from trac.test import EnvironmentStub


class PostgresTableCreationSQLTest(unittest.TestCase):
    def setUp(self):
        self.env = EnvironmentStub()

    def _unroll_generator(self, generator):
        items = []
        for item in generator:
            items.append(item)
        return items

    def _normalize_sql(self, sql_generator):
        normalized_commands = []
        whitespace_regex = re.compile(r'\s+')
        commands = self._unroll_generator(sql_generator)
        for command in commands:
            command = command.replace('\n', '')
            command = whitespace_regex.sub(' ', command)
            normalized_commands.append(command)
        return normalized_commands

    def test_quote_table_name(self):
        table = Table('foo bar')
        table[Column('name'),]
        sql_generator = PostgreSQLConnector(self.env).to_sql(table)
        sql_commands = self._normalize_sql(sql_generator)
        self.assertEqual(1, len(sql_commands))
        self.assertEqual('CREATE TABLE "foo bar" ( "name" text)',
                         sql_commands[0])

    def test_quote_column_names(self):
        table = Table('foo')
        table[Column('my name'),]
        sql_generator = PostgreSQLConnector(self.env).to_sql(table)
        sql_commands = self._normalize_sql(sql_generator)
        self.assertEqual(1, len(sql_commands))
        self.assertEqual('CREATE TABLE "foo" ( "my name" text)',
                         sql_commands[0])

    def test_quote_compound_primary_key_declaration(self):
        table = Table('foo bar', key=['my name', 'your name'])
        table[Column('my name'), Column('your name'),]
        sql_generator = PostgreSQLConnector(self.env).to_sql(table)
        sql_commands = self._normalize_sql(sql_generator)
        self.assertEqual(1, len(sql_commands))
        expected_sql = 'CREATE TABLE "foo bar" ( "my name" text, ' + \
                       '"your name" text, CONSTRAINT "foo bar_pk" ' +\
                       'PRIMARY KEY ("my name","your name"))'
        self.assertEqual(expected_sql, sql_commands[0])

    def test_quote_index_declaration(self):
        table = Table('foo')
        table[Column('my name'), Index(['my name'])]
        sql_generator = PostgreSQLConnector(self.env).to_sql(table)
        sql_commands = self._normalize_sql(sql_generator)
        self.assertEqual(2, len(sql_commands))
        self.assertEqual('CREATE TABLE "foo" ( "my name" text)',
                         sql_commands[0])
        index_sql = 'CREATE INDEX "foo_my name_idx" ON "foo" ("my name")'
        self.assertEqual(index_sql, sql_commands[1])

    def test_quote_index_declaration_for_multiple_indexes(self):
        table = Table('foo')
        table[Column('a'), Column('b'),
              Index(['a', 'b'])]
        sql_generator = PostgreSQLConnector(self.env).to_sql(table)
        sql_commands = self._normalize_sql(sql_generator)
        self.assertEqual(2, len(sql_commands))
        self.assertEqual('CREATE TABLE "foo" ( "a" text, "b" text)',
                         sql_commands[0])
        index_sql = 'CREATE INDEX "foo_a_b_idx" ON "foo" ("a","b")'
        self.assertEqual(index_sql, sql_commands[1])

    def test_assemble_dsn(self):
        values = [
            {'path': 't', 'user': 't'},
            {'path': 't', 'password': 't'},
            {'path': 't', 'host': 't'},
            {'path': 't', 'port': 't'},
            {'path': 't', 'password': 't', 'user': 't'},
            {'path': 't', 'host': 't', 'user': 't'},
            {'path': 't', 'user': 't', 'port': 't'},
            {'path': 't', 'host': 't', 'password': 't'},
            {'path': 't', 'password': 't', 'port': 't'},
            {'path': 't', 'host': 't', 'port': 't'},
            {'path': 't', 'host': 't', 'password': 't', 'user': 't'},
            {'path': 't', 'password': 't', 'user': 't', 'port': 't'},
            {'path': 't', 'host': 't', 'user': 't', 'port': 't'},
            {'path': 't', 'host': 't', 'password': 't', 'port': 't'},
        ]
        for orig in values:
            dsn = assemble_pg_dsn(**orig)
            for k, v in orig.iteritems():
                orig[k] = "'%s'" % v
                continue
            orig['dbname'] = "'t'"
            del orig['path']
            new_values = {'dbname': "'t'"}
            for key_value in dsn.split(' '):
                k, v = key_value.split('=')
                new_values[k] = v
                continue
            self.assertEqual(new_values, orig)
            continue


class PostgresTableAlterationSQLTest(unittest.TestCase):
    def setUp(self):
        self.env = EnvironmentStub()

    def test_alter_column_types(self):
        connector = PostgreSQLConnector(self.env)
        sql = connector.alter_column_types('milestone',
                                           {'due': ('int', 'int64'),
                                            'completed': ('int', 'int64')})
        sql = list(sql)
        self.assertEqual([
            "ALTER TABLE milestone "
                "ALTER COLUMN completed TYPE bigint, "
                "ALTER COLUMN due TYPE bigint",
            ], sql)

    def test_alter_column_types_same(self):
        connector = PostgreSQLConnector(self.env)
        sql = connector.alter_column_types('milestone',
                                           {'due': ('int', 'int'),
                                            'completed': ('int', 'int64')})
        sql = list(sql)
        self.assertEqual([
            "ALTER TABLE milestone "
                "ALTER COLUMN completed TYPE bigint",
            ], sql)

    def test_alter_column_types_none(self):
        connector = PostgreSQLConnector(self.env)
        sql = connector.alter_column_types('milestone',
                                           {'due': ('int', 'int')})
        self.assertEqual([], list(sql))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(PostgresTableCreationSQLTest, 'test'))
    suite.addTest(unittest.makeSuite(PostgresTableAlterationSQLTest, 'test'))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-
#
# Copyright (C) 2010 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import unittest

from trac.db.util import sql_escape_percent

# TODO: test IterableCursor, ConnectionWrapper

class SQLEscapeTestCase(unittest.TestCase):
    def test_sql_escape_percent(self):
        self.assertEqual("%", sql_escape_percent("%"))
        self.assertEqual("'%%'", sql_escape_percent("'%'"))
        self.assertEqual("''%''", sql_escape_percent("''%''"))
        self.assertEqual("'''%%'''", sql_escape_percent("'''%'''"))
        self.assertEqual("'''%%'", sql_escape_percent("'''%'"))
        self.assertEqual("%s", sql_escape_percent("%s"))
        self.assertEqual("% %", sql_escape_percent("% %"))
        self.assertEqual("%s %i", sql_escape_percent("%s %i"))
        self.assertEqual("'%%s'", sql_escape_percent("'%s'"))
        self.assertEqual("'%% %%'", sql_escape_percent("'% %'"))
        self.assertEqual("'%%s %%i'", sql_escape_percent("'%s %i'"))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(SQLEscapeTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2006 Matthew Good <trac@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>


def sql_escape_percent(sql):
    import re
    return re.sub("'((?:[^']|(?:''))*)'",
                  lambda m: m.group(0).replace('%', '%%'), sql)


class IterableCursor(object):
    """Wrapper for DB-API cursor objects that makes the cursor iterable
    and escapes all "%"s used inside literal strings with parameterized
    queries.

    Iteration will generate the rows of a SELECT query one by one.
    """
    __slots__ = ['cursor', 'log']

    def __init__(self, cursor, log=None):
        self.cursor = cursor
        self.log = log

    def __getattr__(self, name):
        return getattr(self.cursor, name)

    def __iter__(self):
        while True:
            row = self.cursor.fetchone()
            if not row:
                return
            yield row

    def execute(self, sql, args=None):
        if self.log:
            self.log.debug('SQL: %s', sql)
            try:
                if args:
                    self.log.debug('args: %r', args)
                    r = self.cursor.execute(sql_escape_percent(sql), args)
                else:
                    r = self.cursor.execute(sql)
                rows = getattr(self.cursor, 'rows', None)
                if rows is not None:
                    self.log.debug("prefetch: %d rows", len(rows))
                return r
            except Exception, e:
                self.log.debug('execute exception: %r', e)
                raise
        if args:
            return self.cursor.execute(sql_escape_percent(sql), args)
        return self.cursor.execute(sql)

    def executemany(self, sql, args):
        if self.log:
            self.log.debug('SQL: %r', sql)
            self.log.debug('args: %r', args)
            if not args:
                return
            try:
                if args[0]:
                    return self.cursor.executemany(sql_escape_percent(sql),
                                                   args)
                return self.cursor.executemany(sql, args)
            except Exception, e:
                self.log.debug('executemany exception: %r', e)
                raise
        if not args:
            return
        if args[0]:
            return self.cursor.executemany(sql_escape_percent(sql), args)
        return self.cursor.executemany(sql, args)


class ConnectionWrapper(object):
    """Generic wrapper around connection objects.

    :since 0.12: This wrapper no longer makes cursors produced by the
                 connection iterable using `IterableCursor`.

    :since 1.0: added a 'readonly' flag preventing the forwarding of
                `commit` and `rollback`
    """
    __slots__ = ('cnx', 'log', 'readonly')

    def __init__(self, cnx, log=None, readonly=False):
        self.cnx = cnx
        self.log = log
        self.readonly = readonly

    def __getattr__(self, name):
        if self.readonly and name in ('commit', 'rollback'):
            raise AttributeError
        return getattr(self.cnx, name)

    def execute(self, query, params=None):
        """Execute an SQL `query`

        The optional `params` is a tuple containing the parameter
        values expected by the query.

        If the query is a SELECT, return all the rows ("fetchall").
        When more control is needed, use `cursor()`.
        """
        dql = self.check_select(query)
        cursor = self.cnx.cursor()
        cursor.execute(query, params)
        rows = cursor.fetchall() if dql else None
        cursor.close()
        return rows

    __call__ = execute

    def executemany(self, query, params=None):
        """Execute an SQL `query`, on a sequence of tuples ("executemany").

        The optional `params` is a sequence of tuples containing the
        parameter values expected by the query.

        If the query is a SELECT, return all the rows ("fetchall").
        When more control is needed, use `cursor()`.
        """
        dql = self.check_select(query)
        cursor = self.cnx.cursor()
        cursor.executemany(query, params)
        rows = cursor.fetchall() if dql else None
        cursor.close()
        return rows

    def check_select(self, query):
        """Verify if the query is compatible according to the readonly nature
        of the wrapped Connection.

        :return: `True` if this is a SELECT
        :raise: `ValueError` if this is not a SELECT and the wrapped
                Connection is read-only.
        """
        dql = query.lstrip().startswith('SELECT')
        if self.readonly and not dql:
            raise ValueError("a 'readonly' connection can only do a SELECT")
        return dql

########NEW FILE########
__FILENAME__ = db_default
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Daniel Lundin <daniel@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>

from trac.db import Table, Column, Index

# Database version identifier. Used for automatic upgrades.
db_version = 29

def __mkreports(reports):
    """Utility function used to create report data in same syntax as the
    default data. This extra step is done to simplify editing the default
    reports."""
    result = []
    for report in reports:
        result.append((None, report[0], report[2], report[1]))
    return result


##
## Database schema
##

schema = [
    # Common
    Table('system', key='name')[
        Column('name'),
        Column('value')],
    Table('permission', key=('username', 'action'))[
        Column('username'),
        Column('action')],
    Table('auth_cookie', key=('cookie', 'ipnr', 'name'))[
        Column('cookie'),
        Column('name'),
        Column('ipnr'),
        Column('time', type='int')],
    Table('session', key=('sid', 'authenticated'))[
        Column('sid'),
        Column('authenticated', type='int'),
        Column('last_visit', type='int'),
        Index(['last_visit']),
        Index(['authenticated'])],
    Table('session_attribute', key=('sid', 'authenticated', 'name'))[
        Column('sid'),
        Column('authenticated', type='int'),
        Column('name'),
        Column('value')],
    Table('cache', key='id')[
        Column('id', type='int'),
        Column('generation', type='int'),
        Column('key')],

    # Attachments
    Table('attachment', key=('type', 'id', 'filename'))[
        Column('type'),
        Column('id'),
        Column('filename'),
        Column('size', type='int'),
        Column('time', type='int64'),
        Column('description'),
        Column('author'),
        Column('ipnr')],

    # Wiki system
    Table('wiki', key=('name', 'version'))[
        Column('name'),
        Column('version', type='int'),
        Column('time', type='int64'),
        Column('author'),
        Column('ipnr'),
        Column('text'),
        Column('comment'),
        Column('readonly', type='int'),
        Index(['time'])],

    # Version control cache
    Table('repository', key=('id', 'name'))[
        Column('id', type='int'),
        Column('name'),
        Column('value')],
    Table('revision', key=('repos', 'rev'))[
        Column('repos', type='int'),
        Column('rev', key_size=20),
        Column('time', type='int64'),
        Column('author'),
        Column('message'),
        Index(['repos', 'time'])],
    Table('node_change', key=('repos', 'rev', 'path', 'change_type'))[
        Column('repos', type='int'),
        Column('rev', key_size=20),
        Column('path', key_size=255),
        Column('node_type', size=1),
        Column('change_type', size=1, key_size=2),
        Column('base_path'),
        Column('base_rev'),
        Index(['repos', 'rev'])],

    # Ticket system
    Table('ticket', key='id')[
        Column('id', auto_increment=True),
        Column('type'),
        Column('time', type='int64'),
        Column('changetime', type='int64'),
        Column('component'),
        Column('severity'),
        Column('priority'),
        Column('owner'),
        Column('reporter'),
        Column('cc'),
        Column('version'),
        Column('milestone'),
        Column('status'),
        Column('resolution'),
        Column('summary'),
        Column('description'),
        Column('keywords'),
        Index(['time']),
        Index(['status'])],
    Table('ticket_change', key=('ticket', 'time', 'field'))[
        Column('ticket', type='int'),
        Column('time', type='int64'),
        Column('author'),
        Column('field'),
        Column('oldvalue'),
        Column('newvalue'),
        Index(['ticket']),
        Index(['time'])],
    Table('ticket_custom', key=('ticket', 'name'))[
        Column('ticket', type='int'),
        Column('name'),
        Column('value')],
    Table('enum', key=('type', 'name'))[
        Column('type'),
        Column('name'),
        Column('value')],
    Table('component', key='name')[
        Column('name'),
        Column('owner'),
        Column('description')],
    Table('milestone', key='name')[
        Column('name'),
        Column('due', type='int64'),
        Column('completed', type='int64'),
        Column('description')],
    Table('version', key='name')[
        Column('name'),
        Column('time', type='int64'),
        Column('description')],

    # Report system
    Table('report', key='id')[
        Column('id', auto_increment=True),
        Column('author'),
        Column('title'),
        Column('query'),
        Column('description')],
]


##
## Default Reports
##

def get_reports(db):
    return (
('Active Tickets',
"""\
 * List all active tickets by priority.
 * Color each row based on priority.
""",
"""\
SELECT p.value AS __color__,
   id AS ticket, summary, component, version, milestone, t.type AS type,
   owner, status,
   time AS created,
   changetime AS _changetime, description AS _description,
   reporter AS _reporter
  FROM ticket t
  LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
  WHERE status <> 'closed'
  ORDER BY """ + db.cast('p.value', 'int') + """, milestone, t.type, time
"""),
#----------------------------------------------------------------------------
 ('Active Tickets by Version',
"""\
This report shows how to color results by priority,
while grouping results by version.

Last modification time, description and reporter are included as hidden fields
for useful RSS export.
""",
"""\
SELECT p.value AS __color__,
   version AS __group__,
   id AS ticket, summary, component, version, t.type AS type,
   owner, status,
   time AS created,
   changetime AS _changetime, description AS _description,
   reporter AS _reporter
  FROM ticket t
  LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
  WHERE status <> 'closed'
  ORDER BY (version IS NULL),version, """ + db.cast('p.value', 'int') +
  """, t.type, time
"""),
#----------------------------------------------------------------------------
('Active Tickets by Milestone',
"""\
This report shows how to color results by priority,
while grouping results by milestone.

Last modification time, description and reporter are included as hidden fields
for useful RSS export.
""",
"""\
SELECT p.value AS __color__,
   %s AS __group__,
   id AS ticket, summary, component, version, t.type AS type,
   owner, status,
   time AS created,
   changetime AS _changetime, description AS _description,
   reporter AS _reporter
  FROM ticket t
  LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
  WHERE status <> 'closed'
  ORDER BY (milestone IS NULL),milestone, %s, t.type, time
""" % (db.concat("'Milestone '", 'milestone'), db.cast('p.value', 'int'))),
#----------------------------------------------------------------------------
('Accepted, Active Tickets by Owner',
"""\
List accepted tickets, group by ticket owner, sorted by priority.
""",
"""\
SELECT p.value AS __color__,
   owner AS __group__,
   id AS ticket, summary, component, milestone, t.type AS type, time AS created,
   changetime AS _changetime, description AS _description,
   reporter AS _reporter
  FROM ticket t
  LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
  WHERE status = 'accepted'
  ORDER BY owner, """ + db.cast('p.value', 'int') + """, t.type, time
"""),
#----------------------------------------------------------------------------
('Accepted, Active Tickets by Owner (Full Description)',
"""\
List tickets accepted, group by ticket owner.
This report demonstrates the use of full-row display.
""",
"""\
SELECT p.value AS __color__,
   owner AS __group__,
   id AS ticket, summary, component, milestone, t.type AS type, time AS created,
   description AS _description_,
   changetime AS _changetime, reporter AS _reporter
  FROM ticket t
  LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
  WHERE status = 'accepted'
  ORDER BY owner, """ + db.cast('p.value', 'int') + """, t.type, time
"""),
#----------------------------------------------------------------------------
('All Tickets By Milestone  (Including closed)',
"""\
A more complex example to show how to make advanced reports.
""",
"""\
SELECT p.value AS __color__,
   t.milestone AS __group__,
   (CASE status
      WHEN 'closed' THEN 'color: #777; background: #ddd; border-color: #ccc;'
      ELSE
        (CASE owner WHEN $USER THEN 'font-weight: bold' END)
    END) AS __style__,
   id AS ticket, summary, component, status,
   resolution,version, t.type AS type, priority, owner,
   changetime AS modified,
   time AS _time,reporter AS _reporter
  FROM ticket t
  LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
  ORDER BY (milestone IS NULL), milestone DESC, (status = 'closed'),
        (CASE status WHEN 'closed' THEN changetime ELSE (-1) * %s END) DESC
""" % db.cast('p.value', 'int')),
#----------------------------------------------------------------------------
('My Tickets',
"""\
This report demonstrates the use of the automatically set
USER dynamic variable, replaced with the username of the
logged in user when executed.
""",
"""\
SELECT  __color__, __group,
       (CASE
         WHEN __group = 1 THEN 'Accepted'
         WHEN __group = 2 THEN 'Owned'
         WHEN __group = 3 THEN 'Reported'
         ELSE 'Commented' END) AS __group__,
       ticket, summary, component, version, milestone,
       type, priority, created, _changetime, _description,
       _reporter
FROM (
 SELECT DISTINCT """ + db.cast('p.value', 'int') + """ AS __color__,
      (CASE
         WHEN owner = $USER AND status = 'accepted' THEN 1
         WHEN owner = $USER THEN 2
         WHEN reporter = $USER THEN 3
         ELSE 4 END) AS __group,
       t.id AS ticket, summary, component, version, milestone,
       t.type AS type, priority, t.time AS created,
       t.changetime AS _changetime, description AS _description,
       reporter AS _reporter
  FROM ticket t
  LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
  LEFT JOIN ticket_change tc ON tc.ticket = t.id AND tc.author = $USER
                                AND tc.field = 'comment'
  WHERE t.status <> 'closed'
        AND (owner = $USER OR reporter = $USER OR author = $USER)
) AS sub
ORDER BY __group, __color__, milestone, type, created
"""),
#----------------------------------------------------------------------------
('Active Tickets, Mine first',
"""\
 * List all active tickets by priority.
 * Show all tickets owned by the logged in user in a group first.
""",
"""\
SELECT p.value AS __color__,
   (CASE owner
     WHEN $USER THEN 'My Tickets'
     ELSE 'Active Tickets'
    END) AS __group__,
   id AS ticket, summary, component, version, milestone, t.type AS type,
   owner, status,
   time AS created,
   changetime AS _changetime, description AS _description,
   reporter AS _reporter
  FROM ticket t
  LEFT JOIN enum p ON p.name = t.priority AND p.type = 'priority'
  WHERE status <> 'closed'
  ORDER BY (COALESCE(owner, '') = $USER) DESC, """
  + db.cast('p.value', 'int') + """, milestone, t.type, time
"""))


##
## Default database values
##

# (table, (column1, column2), ((row1col1, row1col2), (row2col1, row2col2)))
def get_data(db):
    return (('component',
              ('name', 'owner'),
                (('component1', 'somebody'),
                 ('component2', 'somebody'))),
            ('milestone',
              ('name', 'due', 'completed'),
                (('milestone1', 0, 0),
                 ('milestone2', 0, 0),
                 ('milestone3', 0, 0),
                 ('milestone4', 0, 0))),
            ('version',
              ('name', 'time'),
                (('1.0', 0),
                 ('2.0', 0))),
            ('enum',
              ('type', 'name', 'value'),
                (('resolution', 'fixed', 1),
                 ('resolution', 'invalid', 2),
                 ('resolution', 'wontfix', 3),
                 ('resolution', 'duplicate', 4),
                 ('resolution', 'worksforme', 5),
                 ('priority', 'blocker', 1),
                 ('priority', 'critical', 2),
                 ('priority', 'major', 3),
                 ('priority', 'minor', 4),
                 ('priority', 'trivial', 5),
                 ('ticket_type', 'defect', 1),
                 ('ticket_type', 'enhancement', 2),
                 ('ticket_type', 'task', 3))),
            ('permission',
              ('username', 'action'),
                (('anonymous', 'LOG_VIEW'),
                 ('anonymous', 'FILE_VIEW'),
                 ('anonymous', 'WIKI_VIEW'),
                 ('authenticated', 'WIKI_CREATE'),
                 ('authenticated', 'WIKI_MODIFY'),
                 ('anonymous', 'SEARCH_VIEW'),
                 ('anonymous', 'REPORT_VIEW'),
                 ('anonymous', 'REPORT_SQL_VIEW'),
                 ('anonymous', 'TICKET_VIEW'),
                 ('authenticated', 'TICKET_CREATE'),
                 ('authenticated', 'TICKET_MODIFY'),
                 ('anonymous', 'BROWSER_VIEW'),
                 ('anonymous', 'TIMELINE_VIEW'),
                 ('anonymous', 'CHANGESET_VIEW'),
                 ('anonymous', 'ROADMAP_VIEW'),
                 ('anonymous', 'MILESTONE_VIEW'))),
            ('system',
              ('name', 'value'),
                (('database_version', str(db_version)),
                 ('initial_database_version', str(db_version)))),
            ('report',
              ('author', 'title', 'query', 'description'),
                __mkreports(get_reports(db))))

########NEW FILE########
__FILENAME__ = dist
# -*- coding: utf-8 -*-
#
# Copyright (C) 2011 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

"""Extra commands for setup.py.

In addition to providing a few extra command classes in `l10n_cmdclass`,
we also modify the standard `distutils.command.build` and
`setuptools.command.install_lib` classes so that the relevant l10n commands
for compiling catalogs are issued upon install.
"""

from __future__ import with_statement

from StringIO import StringIO
from itertools import izip
import os
import re
from tokenize import generate_tokens, COMMENT, NAME, OP, STRING

from distutils import log
from distutils.cmd import Command
from distutils.command.build import build as _build
from distutils.errors import DistutilsOptionError
from setuptools.command.install_lib import install_lib as _install_lib

try:
    from babel.messages.catalog import TranslationError
    from babel.messages.extract import extract_javascript
    from babel.messages.frontend import extract_messages, init_catalog, \
                                        compile_catalog, update_catalog
    from babel.messages.pofile import read_po
    from babel.support import Translations
    from babel.util import parse_encoding

    _GENSHI_MARKUP_SEARCH = re.compile(r'\[[0-9]+:').search


    _DEFAULT_KWARGS_MAPS = {
        'Option': {'doc': 4},
        'BoolOption': {'doc': 4},
        'IntOption': {'doc': 4},
        'FloatOption': {'doc': 4},
        'ListOption': {'doc': 6},
        'ChoiceOption': {'doc': 4},
        'PathOption': {'doc': 4},
        'ExtensionOption': {'doc': 5},
        'OrderedExtensionsOption': {'doc': 6},
    }

    _DEFAULT_CLEANDOC_KEYWORDS = (
        'ConfigSection', 'Option', 'BoolOption', 'IntOption', 'FloatOption',
        'ListOption', 'ChoiceOption', 'PathOption', 'ExtensionOption',
        'OrderedExtensionsOption', 'cleandoc_',
    )

    def extract_python(fileobj, keywords, comment_tags, options):
        """Extract messages from Python source code, This is patched
        extract_python from Babel to support keyword argument mapping.

        `kwargs_maps` option: names of keyword arguments will be mapping to
        index of messages array.

        `cleandoc_keywords` option: a list of keywords to clean up the
        extracted messages with `cleandoc`.
        """
        from trac.util.compat import cleandoc

        funcname = lineno = message_lineno = None
        kwargs_maps = func_kwargs_map = None
        call_stack = -1
        buf = []
        messages = []
        messages_kwargs = {}
        translator_comments = []
        in_def = in_translator_comments = False
        comment_tag = None

        encoding = parse_encoding(fileobj) \
                   or options.get('encoding', 'iso-8859-1')
        kwargs_maps = _DEFAULT_KWARGS_MAPS.copy()
        if 'kwargs_maps' in options:
            kwargs_maps.update(options['kwargs_maps'])
        cleandoc_keywords = set(_DEFAULT_CLEANDOC_KEYWORDS)
        if 'cleandoc_keywords' in options:
            cleandoc_keywords.update(options['cleandoc_keywords'])

        tokens = generate_tokens(fileobj.readline)
        tok = value = None
        for _ in tokens:
            prev_tok, prev_value = tok, value
            tok, value, (lineno, _), _, _ = _
            if call_stack == -1 and tok == NAME and value in ('def', 'class'):
                in_def = True
            elif tok == OP and value == '(':
                if in_def:
                    # Avoid false positives for declarations such as:
                    # def gettext(arg='message'):
                    in_def = False
                    continue
                if funcname:
                    message_lineno = lineno
                    call_stack += 1
                kwarg_name = None
            elif in_def and tok == OP and value == ':':
                # End of a class definition without parens
                in_def = False
                continue
            elif call_stack == -1 and tok == COMMENT:
                # Strip the comment token from the line
                value = value.decode(encoding)[1:].strip()
                if in_translator_comments and \
                        translator_comments[-1][0] == lineno - 1:
                    # We're already inside a translator comment, continue
                    # appending
                    translator_comments.append((lineno, value))
                    continue
                # If execution reaches this point, let's see if comment line
                # starts with one of the comment tags
                for comment_tag in comment_tags:
                    if value.startswith(comment_tag):
                        in_translator_comments = True
                        translator_comments.append((lineno, value))
                        break
            elif funcname and call_stack == 0:
                if tok == OP and value == ')':
                    if buf:
                        message = ''.join(buf)
                        if kwarg_name in func_kwargs_map:
                            messages_kwargs[kwarg_name] = message
                        else:
                            messages.append(message)
                        del buf[:]
                    else:
                        messages.append(None)

                    for name, message in messages_kwargs.iteritems():
                        if name not in func_kwargs_map:
                            continue
                        index = func_kwargs_map[name]
                        while index >= len(messages):
                            messages.append(None)
                        messages[index - 1] = message

                    if funcname in cleandoc_keywords:
                        messages = [m and cleandoc(m) for m in messages]
                    if len(messages) > 1:
                        messages = tuple(messages)
                    else:
                        messages = messages[0]
                    # Comments don't apply unless they immediately preceed the
                    # message
                    if translator_comments and \
                            translator_comments[-1][0] < message_lineno - 1:
                        translator_comments = []

                    yield (message_lineno, funcname, messages,
                           [comment[1] for comment in translator_comments])

                    funcname = lineno = message_lineno = None
                    kwarg_name = func_kwargs_map = None
                    call_stack = -1
                    messages = []
                    messages_kwargs = {}
                    translator_comments = []
                    in_translator_comments = False
                elif tok == STRING:
                    # Unwrap quotes in a safe manner, maintaining the string's
                    # encoding
                    # https://sourceforge.net/tracker/?func=detail&atid=355470&
                    # aid=617979&group_id=5470
                    value = eval('# coding=%s\n%s' % (encoding, value),
                                 {'__builtins__':{}}, {})
                    if isinstance(value, str):
                        value = value.decode(encoding)
                    buf.append(value)
                elif tok == OP and value == '=' and prev_tok == NAME:
                    kwarg_name = prev_value
                elif tok == OP and value == ',':
                    if buf:
                        message = ''.join(buf)
                        if kwarg_name in func_kwargs_map:
                            messages_kwargs[kwarg_name] = message
                        else:
                            messages.append(message)
                        del buf[:]
                    else:
                        messages.append(None)
                    kwarg_name = None
                    if translator_comments:
                        # We have translator comments, and since we're on a
                        # comma(,) user is allowed to break into a new line
                        # Let's increase the last comment's lineno in order
                        # for the comment to still be a valid one
                        old_lineno, old_comment = translator_comments.pop()
                        translator_comments.append((old_lineno+1, old_comment))
            elif call_stack > 0 and tok == OP and value == ')':
                call_stack -= 1
            elif funcname and call_stack == -1:
                funcname = func_kwargs_map = kwarg_name = None
            elif tok == NAME and value in keywords:
                funcname = value
                func_kwargs_map = kwargs_maps.get(funcname, {})
                kwarg_name = None


    def extract_javascript_script(fileobj, keywords, comment_tags, options):
        """Extract messages from Javascript embedding in <script> tags.

        Select <script type="javascript/text"> tags and delegate to
        `extract_javascript`.
        """
        from genshi.core import Stream
        from genshi.input import XMLParser

        out = StringIO()
        stream = Stream(XMLParser(fileobj))
        stream = stream.select('//script[@type="text/javascript"]')
        stream.render(out=out, encoding='utf-8')
        out.seek(0)
        return extract_javascript(out, keywords, comment_tags, options)


    class generate_messages_js(Command):
        """Generating message javascripts command for use ``setup.py`` scripts.
        """

        description = 'generate message javascript files from binary MO files'
        user_options = [
            ('domain=', 'D',
             "domain of PO file (default 'messages')"),
            ('input-dir=', 'I',
             'path to base directory containing the catalogs'),
            ('input-file=', 'i',
             'name of the input file'),
            ('output-dir=', 'O',
             "name of the output directory"),
            ('output-file=', 'o',
             "name of the output file (default "
             "'<output_dir>/<locale>.js')"),
            ('locale=', 'l',
             'locale of the catalog to compile'),
        ]

        def initialize_options(self):
            self.domain = 'messages'
            self.input_dir = None
            self.input_file = None
            self.output_dir = None
            self.output_file = None
            self.locale = None

        def finalize_options(self):
            if not self.input_file and not self.input_dir:
                raise DistutilsOptionError('you must specify either the input '
                                           'file or directory')
            if not self.output_file and not self.output_dir:
                raise DistutilsOptionError('you must specify either the '
                                           'output file or directory')

        def run(self):
            mo_files = []
            js_files = []

            def js_path(dir, locale):
                return os.path.join(dir, locale + '.js')

            if not self.input_file:
                if self.locale:
                    mo_files.append((self.locale,
                                     os.path.join(self.input_dir, self.locale,
                                                  'LC_MESSAGES',
                                                  self.domain + '.mo')))
                    js_files.append(js_path(self.output_dir, self.locale))
                else:
                    for locale in os.listdir(self.input_dir):
                        mo_file = os.path.join(self.input_dir, locale,
                                               'LC_MESSAGES',
                                               self.domain + '.mo')
                        if os.path.exists(mo_file):
                            mo_files.append((locale, mo_file))
                            js_files.append(js_path(self.output_dir, locale))
            else:
                mo_files.append((self.locale, self.input_file))
                if self.output_file:
                    js_files.append(self.output_file)
                else:
                    js_files.append(js_path(self.output_dir, locale))

            if not mo_files:
                raise DistutilsOptionError('no compiled catalogs found')

            if not os.path.isdir(self.output_dir):
                os.mkdir(self.output_dir)

            for idx, (locale, mo_file) in enumerate(mo_files):
                js_file = js_files[idx]
                log.info('generating messages javascript %r to %r',
                         mo_file, js_file)

                with open(mo_file, 'rb') as infile:
                    t = Translations(infile, self.domain)
                    catalog = t._catalog

                with open(js_file, 'w') as outfile:
                    write_js(outfile, catalog, self.domain, locale)


    class check_catalog(Command):
        """Check message catalog command for use ``setup.py`` scripts."""

        description = 'check message catalog files, like `msgfmt --check`'
        user_options = [
            ('domain=', 'D',
             "domain of PO file (default 'messages')"),
            ('input-dir=', 'I',
             'path to base directory containing the catalogs'),
            ('input-file=', 'i',
             'name of the input file'),
            ('locale=', 'l',
             'locale of the catalog to compile'),
        ]

        def initialize_options(self):
            self.domain = 'messages'
            self.input_dir = None
            self.input_file = None
            self.locale = None

        def finalize_options(self):
            if not self.input_file and not self.input_dir:
                raise DistutilsOptionError('you must specify either the input '
                                           'file or directory')

        def run(self):
            for filename in self._get_po_files():
                log.info('checking catalog %s', filename)
                f = open(filename)
                try:
                    catalog = read_po(f, domain=self.domain)
                finally:
                    f.close()
                for message in catalog:
                    for error in self._check_message(catalog, message):
                        log.warn('%s:%d: %s', filename, message.lineno, error)

        def _get_po_files(self):
            if self.input_file:
                return [self.input_file]

            if self.locale:
                return [os.path.join(self.input_dir, self.locale,
                                     'LC_MESSAGES', self.domain + '.po')]

            files = []
            for locale in os.listdir(self.input_dir):
                filename = os.path.join(self.input_dir, locale, 'LC_MESSAGES',
                                        self.domain + '.po')
                if os.path.exists(filename):
                    files.append(filename)
            return sorted(files)

        def _check_message(self, catalog, message):
            errors = [e for e in message.check(catalog)]
            try:
                check_genshi_markup(catalog, message)
            except TranslationError, e:
                errors.append(e)
            return errors


    def check_genshi_markup(catalog, message):
        """Verify the genshi markups in the translation."""
        msgids = message.id
        if not isinstance(msgids, (list, tuple)):
            msgids = (msgids,)
        msgstrs = message.string
        if not isinstance(msgstrs, (list, tuple)):
            msgstrs = (msgstrs,)

        # check using genshi-markup
        if not _GENSHI_MARKUP_SEARCH(msgids[0]):
            return

        for msgid, msgstr in izip(msgids, msgstrs):
            if msgstr:
                _validate_genshi_markup(msgid, msgstr)


    def _validate_genshi_markup(markup, alternative):
        indices_markup = _parse_genshi_markup(markup)
        indices_alternative = _parse_genshi_markup(alternative)
        indices = indices_markup - indices_alternative
        if indices:
            raise TranslationError(
                'genshi markups are unbalanced %s' % \
                ' '.join(['[%d:]' % idx for idx in indices]))


    def _parse_genshi_markup(message):
        from genshi.filters.i18n import parse_msg
        try:
            return set([idx for idx, text in parse_msg(message)
                            if idx > 0])
        except Exception, e:
            raise TranslationError('cannot parse message (%s: %s)' % \
                                   (e.__class__.__name__, unicode(e)))


    def write_js(fileobj, catalog, domain, locale):
        from trac.util.presentation import to_json
        data = {'domain': domain, 'locale': locale}

        messages = {}
        for msgid, msgstr in catalog.iteritems():
            if isinstance(msgid, (list, tuple)):
                messages.setdefault(msgid[0], {})
                messages[msgid[0]][msgid[1]] = msgstr
            elif msgid:
                messages[msgid] = msgstr
            else:
                for line in msgstr.splitlines():
                    line = line.strip()
                    if not line:
                        continue
                    if ':' not in line:
                        continue
                    name, val = line.split(':', 1)
                    name = name.strip().lower()
                    if name == 'plural-forms':
                        data['plural_expr'] = pluralexpr(val)
                        break
        data['messages'] = messages

        fileobj.write('// Generated messages javascript file '
                      'from compiled MO file\n')
        fileobj.write('babel.Translations.load(')
        fileobj.write(to_json(data).encode('utf-8'))
        fileobj.write(').install();\n')

    def pluralexpr(forms):
        match = re.search(r'\bplural\s*=\s*([^;]+)', forms)
        if not match:
            raise ValueError('Failed to parse plural_forms %r' % (forms,))
        return match.group(1)


    def get_command_overriders():
        # 'bdist_wininst' runs a 'build', so make the latter
        # run a 'compile_catalog' before 'build_py'
        class build(_build):
            sub_commands = [('compile_catalog', None)] + _build.sub_commands

        # 'bdist_egg' isn't that nice, all it does is an 'install_lib'
        class install_lib(_install_lib): # playing setuptools' own tricks ;-)
            def l10n_run(self):
                self.run_command('compile_catalog')
            def run(self):
                self.l10n_run()
                _install_lib.run(self)
        return build, install_lib

    def get_l10n_cmdclass():
        build, install_lib = get_command_overriders()
        return {
            'build': build, 'install_lib': install_lib,
            'check_catalog': check_catalog,
        }

    def get_l10n_js_cmdclass():
        build, _install_lib = get_command_overriders()
        build.sub_commands.insert(0, ('generate_messages_js', None))
        build.sub_commands.insert(0, ('compile_catalog_js', None))
        class install_lib(_install_lib):
            def l10n_run(self):
                self.run_command('compile_catalog_js')
                self.run_command('generate_messages_js')
                self.run_command('compile_catalog')
        return {
            'build': build, 'install_lib': install_lib,
            'check_catalog': check_catalog,
            'extract_messages_js': extract_messages,
            'init_catalog_js': init_catalog,
            'compile_catalog_js': compile_catalog,
            'update_catalog_js': update_catalog,
            'generate_messages_js': generate_messages_js,
            'check_catalog_js': check_catalog,
        }

    def get_l10n_trac_cmdclass():
        build, _install_lib = get_command_overriders()
        build.sub_commands.insert(0, ('generate_messages_js', None))
        build.sub_commands.insert(0, ('compile_catalog_js', None))
        build.sub_commands.insert(0, ('compile_catalog_tracini', None))
        class install_lib(_install_lib):
            def l10n_run(self):
                self.run_command('compile_catalog_tracini')
                self.run_command('compile_catalog_js')
                self.run_command('generate_messages_js')
                self.run_command('compile_catalog')
        return {
            'build': build, 'install_lib': install_lib,
            'check_catalog': check_catalog,
            'extract_messages_js': extract_messages,
            'init_catalog_js': init_catalog,
            'compile_catalog_js': compile_catalog,
            'update_catalog_js': update_catalog,
            'generate_messages_js': generate_messages_js,
            'check_catalog_js': check_catalog,
            'extract_messages_tracini': extract_messages,
            'init_catalog_tracini': init_catalog,
            'compile_catalog_tracini': compile_catalog,
            'update_catalog_tracini': update_catalog,
            'check_catalog_tracini': check_catalog,
        }


except ImportError:
    def get_l10n_cmdclass():
        return
    def get_l10n_js_cmdclass():
        return
    def get_l10n_trac_cmdclass():
        return

########NEW FILE########
__FILENAME__ = env
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2011 Edgewall Software
# Copyright (C) 2003-2007 Jonas Borgstrm <jonas@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>

"""Trac Environment model and related APIs."""

from __future__ import with_statement

import os.path
import pkg_resources 
import setuptools
import sys
from urlparse import urlsplit

from trac import db_default
from trac.admin import AdminCommandError, IAdminCommandProvider
from trac.cache import CacheManager
from trac.config import *
from trac.core import Component, ComponentManager, implements, Interface, \
                      ExtensionPoint, TracError
from trac.db.api import (DatabaseManager, QueryContextManager,
                         TransactionContextManager, with_transaction)
from trac.util import copytree, create_file, get_pkginfo, lazy, makedirs, \
                      read_file
from trac.util.compat import sha1
from trac.util.concurrency import threading
from trac.util.text import exception_to_unicode, path_to_unicode, printerr, \
                           printout
from trac.util.translation import _, N_
from trac.versioncontrol import RepositoryManager
from trac.web.href import Href

__all__ = ['Environment', 'IEnvironmentSetupParticipant', 'open_environment']


# Content of the VERSION file in the environment
_VERSION = 'Trac Environment Version 1'


class ISystemInfoProvider(Interface):
    """Provider of system information, displayed in the "About Trac"
    page and in internal error reports.
    """
    def get_system_info():
        """Yield a sequence of `(name, version)` tuples describing the
        name and version information of external packages used by a
        component.
        """


class IEnvironmentSetupParticipant(Interface):
    """Extension point interface for components that need to participate in
    the creation and upgrading of Trac environments, for example to create
    additional database tables.

    Please note that `IEnvironmentSetupParticipant` instances are called in
    arbitrary order. If your upgrades must be ordered consistently, please
    implement the ordering in a single `IEnvironmentSetupParticipant`. See
    the database upgrade infrastructure in Trac core for an example.
    """

    def environment_created():
        """Called when a new Trac environment is created."""

    def environment_needs_upgrade(db):
        """Called when Trac checks whether the environment needs to be
        upgraded.

        Should return `True` if this participant needs an upgrade to
        be performed, `False` otherwise.
        """

    def upgrade_environment(db):
        """Actually perform an environment upgrade.

        Implementations of this method don't need to commit any
        database transactions. This is done implicitly for each
        participant if the upgrade succeeds without an error being
        raised.

        However, if the `upgrade_environment` consists of small,
        restartable, steps of upgrade, it can decide to commit on its
        own after each successful step.
        """


class BackupError(RuntimeError):
    """Exception raised during an upgrade when the DB backup fails."""


class Environment(Component, ComponentManager):
    """Trac environment manager.

    Trac stores project information in a Trac environment. It consists
    of a directory structure containing among other things:

    * a configuration file,
    * project-specific templates and plugins,
    * the wiki and ticket attachments files,
    * the SQLite database file (stores tickets, wiki pages...)
      in case the database backend is sqlite

    """

    implements(ISystemInfoProvider)

    required = True

    system_info_providers = ExtensionPoint(ISystemInfoProvider)
    setup_participants = ExtensionPoint(IEnvironmentSetupParticipant)

    components_section = ConfigSection('components',
        """This section is used to enable or disable components
        provided by plugins, as well as by Trac itself. The component
        to enable/disable is specified via the name of the
        option. Whether its enabled is determined by the option value;
        setting the value to `enabled` or `on` will enable the
        component, any other value (typically `disabled` or `off`)
        will disable the component.

        The option name is either the fully qualified name of the
        components or the module/package prefix of the component. The
        former enables/disables a specific component, while the latter
        enables/disables any component in the specified
        package/module.

        Consider the following configuration snippet:
        {{{
        [components]
        trac.ticket.report.ReportModule = disabled
        webadmin.* = enabled
        }}}

        The first option tells Trac to disable the
        [wiki:TracReports report module].
        The second option instructs Trac to enable all components in
        the `webadmin` package. Note that the trailing wildcard is
        required for module/package matching.

        To view the list of active components, go to the ''Plugins''
        page on ''About Trac'' (requires `CONFIG_VIEW`
        [wiki:TracPermissions permissions]).

        See also: TracPlugins
        """)

    shared_plugins_dir = PathOption('inherit', 'plugins_dir', '',
        """Path to the //shared plugins directory//.

        Plugins in that directory are loaded in addition to those in
        the directory of the environment `plugins`, with this one
        taking precedence.

        (''since 0.11'')""")

    base_url = Option('trac', 'base_url', '',
        """Reference URL for the Trac deployment.

        This is the base URL that will be used when producing
        documents that will be used outside of the web browsing
        context, like for example when inserting URLs pointing to Trac
        resources in notification e-mails.""")

    base_url_for_redirect = BoolOption('trac', 'use_base_url_for_redirect',
            False,
        """Optionally use `[trac] base_url` for redirects.

        In some configurations, usually involving running Trac behind
        a HTTP proxy, Trac can't automatically reconstruct the URL
        that is used to access it. You may need to use this option to
        force Trac to use the `base_url` setting also for
        redirects. This introduces the obvious limitation that this
        environment will only be usable when accessible from that URL,
        as redirects are frequently used. ''(since 0.10.5)''""")

    secure_cookies = BoolOption('trac', 'secure_cookies', False,
        """Restrict cookies to HTTPS connections.

        When true, set the `secure` flag on all cookies so that they
        are only sent to the server on HTTPS connections. Use this if
        your Trac instance is only accessible through HTTPS. (''since
        0.11.2'')""")

    project_name = Option('project', 'name', 'My Project',
        """Name of the project.""")

    project_description = Option('project', 'descr', 'My example project',
        """Short description of the project.""")

    project_url = Option('project', 'url', '',
        """URL of the main project web site, usually the website in
        which the `base_url` resides. This is used in notification
        e-mails.""")

    project_admin = Option('project', 'admin', '',
        """E-Mail address of the project's administrator.""")

    project_admin_trac_url = Option('project', 'admin_trac_url', '.',
        """Base URL of a Trac instance where errors in this Trac
        should be reported.

        This can be an absolute or relative URL, or '.' to reference
        this Trac instance. An empty value will disable the reporting
        buttons.  (''since 0.11.3'')""")

    project_footer = Option('project', 'footer',
                            N_('Visit the Trac open source project at<br />'
                               '<a href="http://trac.edgewall.org/">'
                               'http://trac.edgewall.org/</a>'),
        """Page footer text (right-aligned).""")

    project_icon = Option('project', 'icon', 'common/trac.ico',
        """URL of the icon of the project.""")

    log_type = Option('logging', 'log_type', 'none',
        """Logging facility to use.

        Should be one of (`none`, `file`, `stderr`, `syslog`, `winlog`).""")

    log_file = Option('logging', 'log_file', 'trac.log',
        """If `log_type` is `file`, this should be a path to the
        log-file.  Relative paths are resolved relative to the `log`
        directory of the environment.""")

    log_level = Option('logging', 'log_level', 'DEBUG',
        """Level of verbosity in log.

        Should be one of (`CRITICAL`, `ERROR`, `WARN`, `INFO`, `DEBUG`).""")

    log_format = Option('logging', 'log_format', None,
        """Custom logging format.

        If nothing is set, the following will be used:

        Trac[$(module)s] $(levelname)s: $(message)s

        In addition to regular key names supported by the Python
        logger library (see
        http://docs.python.org/library/logging.html), one could use:

        - $(path)s     the path for the current environment
        - $(basename)s the last path component of the current environment
        - $(project)s  the project name

        Note the usage of `$(...)s` instead of `%(...)s` as the latter form
        would be interpreted by the ConfigParser itself.

        Example:
        `($(thread)d) Trac[$(basename)s:$(module)s] $(levelname)s: $(message)s`

        ''(since 0.10.5)''""")

    def __init__(self, path, create=False, options=[]):
        """Initialize the Trac environment.

        :param path:   the absolute path to the Trac environment
        :param create: if `True`, the environment is created and
                       populated with default data; otherwise, the
                       environment is expected to already exist.
        :param options: A list of `(section, name, value)` tuples that
                        define configuration options
        """
        ComponentManager.__init__(self)

        self.path = path
        self.systeminfo = []
        self._href = self._abs_href = None

        if create:
            self.create(options)
        else:
            self.verify()
            self.setup_config()

        if create:
            for setup_participant in self.setup_participants:
                setup_participant.environment_created()

    def get_systeminfo(self):
        """Return a list of `(name, version)` tuples describing the
        name and version information of external packages used by Trac
        and plugins.
        """
        info = self.systeminfo[:]
        for provider in self.system_info_providers:
            info.extend(provider.get_system_info() or [])
        info.sort(key=lambda (name, version): (name != 'Trac', name.lower()))
        return info

    # ISystemInfoProvider methods

    def get_system_info(self):
        from trac import core, __version__ as VERSION
        yield 'Trac', pkg_resources.resource_string('trac', 'TRAC_VERSION')
        yield 'Bloodhound Trac', get_pkginfo(core).get('version', VERSION)
        yield 'Python', sys.version
        yield 'setuptools', setuptools.__version__
        from trac.util.datefmt import pytz
        if pytz is not None:
            yield 'pytz', pytz.__version__

    def component_activated(self, component):
        """Initialize additional member variables for components.

        Every component activated through the `Environment` object
        gets three member variables: `env` (the environment object),
        `config` (the environment configuration) and `log` (a logger
        object)."""
        component.env = self
        component.config = self.config
        component.log = self.log

    def _component_name(self, name_or_class):
        name = name_or_class
        if not isinstance(name_or_class, basestring):
            name = name_or_class.__module__ + '.' + name_or_class.__name__
        return name.lower()

    @property
    def _component_rules(self):
        try:
            return self._rules
        except AttributeError:
            self._rules = {}
            for name, value in self.components_section.options():
                if name.endswith('.*'):
                    name = name[:-2]
                self._rules[name.lower()] = value.lower() in ('enabled', 'on')
            return self._rules

    def is_component_enabled(self, cls):
        """Implemented to only allow activation of components that are
        not disabled in the configuration.

        This is called by the `ComponentManager` base class when a
        component is about to be activated. If this method returns
        `False`, the component does not get activated. If it returns
        `None`, the component only gets activated if it is located in
        the `plugins` directory of the environment.
        """
        component_name = self._component_name(cls)

        # Disable the pre-0.11 WebAdmin plugin
        # Please note that there's no recommendation to uninstall the
        # plugin because doing so would obviously break the backwards
        # compatibility that the new integration administration
        # interface tries to provide for old WebAdmin extensions
        if component_name.startswith('webadmin.'):
            self.log.info("The legacy TracWebAdmin plugin has been "
                          "automatically disabled, and the integrated "
                          "administration interface will be used "
                          "instead.")
            return False

        rules = self._component_rules
        cname = component_name
        while cname:
            enabled = rules.get(cname)
            if enabled is not None:
                return enabled
            idx = cname.rfind('.')
            if idx < 0:
                break
            cname = cname[:idx]

        # By default, all components in the trac package are enabled
        return component_name.startswith('trac.') or None

    def enable_component(self, cls):
        """Enable a component or module."""
        self._component_rules[self._component_name(cls)] = True

    def verify(self):
        """Verify that the provided path points to a valid Trac environment
        directory."""
        try:
            tag = read_file(os.path.join(self.path, 'VERSION')).splitlines()[0]
            if tag != _VERSION:
                raise Exception("Unknown Trac environment type '%s'" % tag)
        except Exception, e:
            raise TracError("No Trac environment found at %s\n%s"
                            % (self.path, e))

    def get_db_cnx(self):
        """Return a database connection from the connection pool

        :deprecated: Use :meth:`db_transaction` or :meth:`db_query` instead

        `db_transaction` for obtaining the `db` database connection
        which can be used for performing any query
        (SELECT/INSERT/UPDATE/DELETE)::

           with env.db_transaction as db:
               ...

        Note that within the block, you don't need to (and shouldn't)
        call ``commit()`` yourself, the context manager will take care
        of it (if it's the outermost such context manager on the
        stack).


        `db_query` for obtaining a `db` database connection which can
        be used for performing SELECT queries only::

           with env.db_query as db:
               ...
        """
        return DatabaseManager(self).get_connection()

    @lazy
    def db_exc(self):
        """Return an object (typically a module) containing all the
        backend-specific exception types as attributes, named
        according to the Python Database API
        (http://www.python.org/dev/peps/pep-0249/).

        To catch a database exception, use the following pattern::

            try:
                with env.db_transaction as db:
                    ...
            except env.db_exc.IntegrityError, e:
                ...
        """
        return DatabaseManager(self).get_exceptions()

    def with_transaction(self, db=None):
        """Decorator for transaction functions :deprecated:"""
        return with_transaction(self, db)

    def get_read_db(self):
        """Return a database connection for read purposes :deprecated:

        See `trac.db.api.get_read_db` for detailed documentation."""
        return DatabaseManager(self).get_connection(readonly=True)

    @property
    def db_query(self):
        """Return a context manager
        (`~trac.db.api.QueryContextManager`) which can be used to
        obtain a read-only database connection.

        Example::

            with env.db_query as db:
                cursor = db.cursor()
                cursor.execute("SELECT ...")
                for row in cursor.fetchall():
                    ...

        Note that a connection retrieved this way can be "called"
        directly in order to execute a query::

            with env.db_query as db:
                for row in db("SELECT ..."):
                    ...

        :warning: after a `with env.db_query as db` block, though the
          `db` variable is still defined, you shouldn't use it as it
          might have been closed when exiting the context, if this
          context was the outermost context (`db_query` or
          `db_transaction`).

        If you don't need to manipulate the connection itself, this
        can even be simplified to::

            for row in env.db_query("SELECT ..."):
                ...

        """
        return QueryContextManager(self)

    @property
    def db_transaction(self):
        """Return a context manager
        (`~trac.db.api.TransactionContextManager`) which can be used
        to obtain a writable database connection.

        Example::

            with env.db_transaction as db:
                cursor = db.cursor()
                cursor.execute("UPDATE ...")

        Upon successful exit of the context, the context manager will
        commit the transaction. In case of nested contexts, only the
        outermost context performs a commit. However, should an
        exception happen, any context manager will perform a rollback.
        You should *not* call `commit()` yourself within such block,
        as this will force a commit even if that transaction is part
        of a larger transaction.

        Like for its read-only counterpart, you can directly execute a
        DML query on the `db`::

            with env.db_transaction as db:
                db("UPDATE ...")

        :warning: after a `with env.db_transaction` as db` block,
          though the `db` variable is still available, you shouldn't
          use it as it might have been closed when exiting the
          context, if this context was the outermost context
          (`db_query` or `db_transaction`).

        If you don't need to manipulate the connection itself, this
        can also be simplified to::

            env.db_transaction("UPDATE ...")

        """
        return TransactionContextManager(self)

    def shutdown(self, tid=None):
        """Close the environment."""
        RepositoryManager(self).shutdown(tid)
        DatabaseManager(self).shutdown(tid)
        if tid is None:
            self.log.removeHandler(self._log_handler)
            self._log_handler.flush()
            self._log_handler.close()
            del self._log_handler

    def get_repository(self, reponame=None, authname=None):
        """Return the version control repository with the given name,
        or the default repository if `None`.

        The standard way of retrieving repositories is to use the
        methods of `RepositoryManager`. This method is retained here
        for backward compatibility.

        :param reponame: the name of the repository
        :param authname: the user name for authorization (not used
                         anymore, left here for compatibility with
                         0.11)
        """
        return RepositoryManager(self).get_repository(reponame)

    def create(self, options=[]):
        """Create the basic directory structure of the environment,
        initialize the database and populate the configuration file
        with default values.

        If options contains ('inherit', 'file'), default values will
        not be loaded; they are expected to be provided by that file
        or other options.
        """
        # Create the directory structure
        if not os.path.exists(self.path):
            os.mkdir(self.path)
        os.mkdir(self.get_log_dir())
        os.mkdir(self.get_htdocs_dir())
        os.mkdir(os.path.join(self.path, 'plugins'))

        # Create a few files
        create_file(os.path.join(self.path, 'VERSION'), _VERSION + '\n')
        create_file(os.path.join(self.path, 'README'),
                    'This directory contains a Trac environment.\n'
                    'Visit http://trac.edgewall.org/ for more information.\n')

        # Setup the default configuration
        os.mkdir(os.path.join(self.path, 'conf'))
        create_file(os.path.join(self.path, 'conf', 'trac.ini.sample'))
        config = Configuration(os.path.join(self.path, 'conf', 'trac.ini'))
        for section, name, value in options:
            config.set(section, name, value)
        config.save()
        self.setup_config()
        if not any((section, option) == ('inherit', 'file')
                   for section, option, value in options):
            self.config.set_defaults(self)
            self.config.save()

        # Create the database
        DatabaseManager(self).init_db()

    def get_version(self, db=None, initial=False):
        """Return the current version of the database.  If the
        optional argument `initial` is set to `True`, the version of
        the database used at the time of creation will be returned.

        In practice, for database created before 0.11, this will
        return `False` which is "older" than any db version number.

        :since: 0.11

        :since 1.0: deprecation warning: the `db` parameter is no
                    longer used and will be removed in version 1.1.1
        """
        rows = self.db_query("""
                SELECT value FROM system WHERE name='%sdatabase_version'
                """ % ('initial_' if initial else ''))
        return rows and int(rows[0][0])

    def setup_config(self):
        """Load the configuration file."""
        self.config = Configuration(os.path.join(self.path, 'conf', 'trac.ini'),
                                    {'envname': os.path.basename(self.path)})
        self.setup_log()
        from trac.loader import load_components
        plugins_dir = self.shared_plugins_dir
        load_components(self, plugins_dir and (plugins_dir,))

    def get_templates_dir(self):
        """Return absolute path to the templates directory."""
        return os.path.join(self.path, 'templates')

    def get_htdocs_dir(self):
        """Return absolute path to the htdocs directory."""
        return os.path.join(self.path, 'htdocs')

    def get_log_dir(self):
        """Return absolute path to the log directory."""
        return os.path.join(self.path, 'log')

    def setup_log(self):
        """Initialize the logging sub-system."""
        from trac.log import logger_handler_factory
        logtype = self.log_type
        logfile = self.log_file
        if logtype == 'file' and not os.path.isabs(logfile):
            logfile = os.path.join(self.get_log_dir(), logfile)
        format = self.log_format
        logid = 'Trac.%s' % sha1(self.path).hexdigest()
        if format:
            format = format.replace('$(', '%(') \
                     .replace('%(path)s', self.path) \
                     .replace('%(basename)s', os.path.basename(self.path)) \
                     .replace('%(project)s', self.project_name)
        self.log, self._log_handler = logger_handler_factory(
            logtype, logfile, self.log_level, logid, format=format)
        from trac import core, __version__ as VERSION
        self.log.info('-' * 32 + ' environment startup [Trac %s] ' + '-' * 32,
                      get_pkginfo(core).get('version', VERSION))

    def get_known_users(self, cnx=None):
        """Generator that yields information about all known users,
        i.e. users that have logged in to this Trac environment and
        possibly set their name and email.

        This function generates one tuple for every user, of the form
        (username, name, email) ordered alpha-numerically by username.

        :param cnx: the database connection; if ommitted, a new
                    connection is retrieved

        :since 1.0: deprecation warning: the `cnx` parameter is no
                    longer used and will be removed in version 1.1.1
        """
        for username, name, email in self.db_query("""
                SELECT DISTINCT s.sid, n.value, e.value
                FROM session AS s
                 LEFT JOIN session_attribute AS n ON (n.sid=s.sid
                  and n.authenticated=1 AND n.name = 'name')
                 LEFT JOIN session_attribute AS e ON (e.sid=s.sid
                  AND e.authenticated=1 AND e.name = 'email')
                WHERE s.authenticated=1 ORDER BY s.sid
                """):
            yield username, name, email

    def backup(self, dest=None):
        """Create a backup of the database.

        :param dest: Destination file; if not specified, the backup is
                     stored in a file called db_name.trac_version.bak
        """
        return DatabaseManager(self).backup(dest)

    def needs_upgrade(self):
        """Return whether the environment needs to be upgraded."""
        for participant in self.setup_participants:
            with self.db_query as db:
                if participant.environment_needs_upgrade(db):
                    self.log.warn("Component %s requires environment upgrade",
                                  participant)
                    return True
        return False

    def upgrade(self, backup=False, backup_dest=None):
        """Upgrade database.

        :param backup: whether or not to backup before upgrading
        :param backup_dest: name of the backup file
        :return: whether the upgrade was performed
        """
        upgraders = []
        for participant in self.setup_participants:
            with self.db_query as db:
                if participant.environment_needs_upgrade(db):
                    upgraders.append(participant)
        if not upgraders:
            return

        if backup:
            try:
                self.backup(backup_dest)
            except Exception, e:
                raise BackupError(e)

        for participant in upgraders:
            self.log.info("%s.%s upgrading...", participant.__module__,
                          participant.__class__.__name__)
            with self.db_transaction as db:
                participant.upgrade_environment(db)
            # Database schema may have changed, so close all connections
            DatabaseManager(self).shutdown()
        return True

    @property
    def href(self):
        """The application root path"""
        if not self._href:
            self._href = Href(urlsplit(self.abs_href.base)[2])
        return self._href

    @property
    def abs_href(self):
        """The application URL"""
        if not self._abs_href:
            if not self.base_url:
                self.log.warn("base_url option not set in configuration, "
                              "generated links may be incorrect")
                self._abs_href = Href('')
            else:
                self._abs_href = Href(self.base_url)
        return self._abs_href


class EnvironmentSetup(Component):
    """Manage automatic environment upgrades."""

    required = True

    implements(IEnvironmentSetupParticipant)

    # IEnvironmentSetupParticipant methods

    def environment_created(self):
        """Insert default data into the database."""
        with self.env.db_transaction as db:
            for table, cols, vals in db_default.get_data(db):
                db.executemany("INSERT INTO %s (%s) VALUES (%s)"
                   % (table, ','.join(cols), ','.join(['%s' for c in cols])),
                   vals)
        self._update_sample_config()

    def environment_needs_upgrade(self, db):
        dbver = self.env.get_version(db)
        if dbver == db_default.db_version:
            return False
        elif dbver > db_default.db_version:
            raise TracError(_('Database newer than Trac version'))
        self.log.info("Trac database schema version is %d, should be %d",
                      dbver, db_default.db_version)
        return True

    def upgrade_environment(self, db):
        """Each db version should have its own upgrade module, named
        upgrades/dbN.py, where 'N' is the version number (int).
        """
        cursor = db.cursor()
        dbver = self.env.get_version()
        for i in range(dbver + 1, db_default.db_version + 1):
            name  = 'db%i' % i
            try:
                upgrades = __import__('upgrades', globals(), locals(), [name])
                script = getattr(upgrades, name)
            except AttributeError:
                raise TracError(_("No upgrade module for version %(num)i "
                                  "(%(version)s.py)", num=i, version=name))
            script.do_upgrade(self.env, i, cursor)
            cursor.execute("""
                UPDATE system SET value=%s WHERE name='database_version'
                """, (i,))
            self.log.info("Upgraded database version from %d to %d", i - 1, i)
            db.commit()
        self._update_sample_config()

    # Internal methods

    def _update_sample_config(self):
        filename = os.path.join(self.env.path, 'conf', 'trac.ini.sample')
        if not os.path.isfile(filename):
            return
        config = Configuration(filename)
        for section, default_options in config.defaults().iteritems():
            for name, value in default_options.iteritems():
                config.set(section, name, value)
        try:
            config.save()
            self.log.info("Wrote sample configuration file with the new "
                          "settings and their default values: %s",
                          filename)
        except IOError, e:
            self.log.warn("Couldn't write sample configuration file (%s)", e,
                          exc_info=True)


env_cache = {}
env_cache_lock = threading.Lock()

def open_environment(env_path=None, use_cache=False):
    """Open an existing environment object, and verify that the database is up
    to date.

    :param env_path: absolute path to the environment directory; if
                     ommitted, the value of the `TRAC_ENV` environment
                     variable is used
    :param use_cache: whether the environment should be cached for
                      subsequent invocations of this function
    :return: the `Environment` object
    """
    if not env_path:
        env_path = os.getenv('TRAC_ENV')
    if not env_path:
        raise TracError(_('Missing environment variable "TRAC_ENV". '
                          'Trac requires this variable to point to a valid '
                          'Trac environment.'))

    env_path = os.path.normcase(os.path.normpath(env_path))
    if use_cache:
        with env_cache_lock:
            env = env_cache.get(env_path)
            if env and env.config.parse_if_needed():
                # The environment configuration has changed, so shut it down
                # and remove it from the cache so that it gets reinitialized
                env.log.info('Reloading environment due to configuration '
                             'change')
                env.shutdown()
                del env_cache[env_path]
                env = None
            if env is None:
                env = env_cache.setdefault(env_path, open_environment(env_path))
            else:
                CacheManager(env).reset_metadata()
    else:
        env = Environment(env_path)
        needs_upgrade = False
        try:
            needs_upgrade = env.needs_upgrade()
        except Exception, e: # e.g. no database connection
            env.log.error("Exception caught while checking for upgrade: %s",
                          exception_to_unicode(e, traceback=True))
        if needs_upgrade:
            raise TracError(_('The Trac Environment needs to be upgraded.\n\n'
                              'Run "trac-admin %(path)s upgrade"',
                              path=env_path))

    return env


class EnvironmentAdmin(Component):
    """trac-admin command provider for environment administration."""

    implements(IAdminCommandProvider)

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('deploy', '<directory>',
               'Extract static resources from Trac and all plugins',
               None, self._do_deploy)
        yield ('hotcopy', '<backupdir> [--no-database]',
               """Make a hot backup copy of an environment

               The database is backed up to the 'db' directory of the
               destination, unless the --no-database option is
               specified.
               """,
               None, self._do_hotcopy)
        yield ('upgrade', '',
               'Upgrade database to current version',
               None, self._do_upgrade)

    def _do_deploy(self, dest):
        target = os.path.normpath(dest)
        chrome_target = os.path.join(target, 'htdocs')
        script_target = os.path.join(target, 'cgi-bin')

        # Copy static content
        makedirs(target, overwrite=True)
        makedirs(chrome_target, overwrite=True)
        from trac.web.chrome import Chrome
        printout(_("Copying resources from:"))
        for provider in Chrome(self.env).template_providers:
            paths = list(provider.get_htdocs_dirs() or [])
            if not len(paths):
                continue
            printout('  %s.%s' % (provider.__module__,
                                  provider.__class__.__name__))
            for key, root in paths:
                if not root:
                    continue
                source = os.path.normpath(root)
                printout('   ', source)
                if os.path.exists(source):
                    dest = os.path.join(chrome_target, key)
                    copytree(source, dest, overwrite=True)

        # Create and copy scripts
        makedirs(script_target, overwrite=True)
        printout(_("Creating scripts."))
        data = {'env': self.env, 'executable': sys.executable}
        for script in ('cgi', 'fcgi', 'wsgi'):
            dest = os.path.join(script_target, 'trac.' + script)
            template = Chrome(self.env).load_template('deploy_trac.' + script,
                                                      'text')
            stream = template.generate(**data)
            with open(dest, 'w') as out:
                stream.render('text', out=out, encoding='utf-8')

    def _do_hotcopy(self, dest, no_db=None):
        if no_db not in (None, '--no-database'):
            raise AdminCommandError(_("Invalid argument '%(arg)s'", arg=no_db),
                                    show_usage=True)

        if os.path.exists(dest):
            raise TracError(_("hotcopy can't overwrite existing '%(dest)s'",
                              dest=path_to_unicode(dest)))
        import shutil

        # Bogus statement to lock the database while copying files
        with self.env.db_transaction as db:
            db("UPDATE system SET name=NULL WHERE name IS NULL")

            printout(_("Hotcopying %(src)s to %(dst)s ...",
                       src=path_to_unicode(self.env.path),
                       dst=path_to_unicode(dest)))
            db_str = self.env.config.get('trac', 'database')
            prefix, db_path = db_str.split(':', 1)
            skip = []

            if prefix == 'sqlite':
                db_path = os.path.join(self.env.path, os.path.normpath(db_path))
                # don't copy the journal (also, this would fail on Windows)
                skip = [db_path + '-journal', db_path + '-stmtjrnl']
                if no_db:
                    skip.append(db_path)

            try:
                copytree(self.env.path, dest, symlinks=1, skip=skip)
                retval = 0
            except shutil.Error, e:
                retval = 1
                printerr(_("The following errors happened while copying "
                           "the environment:"))
                for (src, dst, err) in e.args[0]:
                    if src in err:
                        printerr('  %s' % err)
                    else:
                        printerr("  %s: '%s'" % (err, path_to_unicode(src)))


            # db backup for non-sqlite
            if prefix != 'sqlite' and not no_db:
                printout(_("Backing up database ..."))
                sql_backup = os.path.join(dest, 'db',
                                          '%s-db-backup.sql' % prefix)
                self.env.backup(sql_backup)

        printout(_("Hotcopy done."))
        return retval

    def _do_upgrade(self, no_backup=None):
        if no_backup not in (None, '-b', '--no-backup'):
            raise AdminCommandError(_("Invalid arguments"), show_usage=True)

        if not self.env.needs_upgrade():
            printout(_("Database is up to date, no upgrade necessary."))
            return

        try:
            self.env.upgrade(backup=no_backup is None)
        except BackupError, e:
            printerr(_("The pre-upgrade backup failed.\nUse '--no-backup' to "
                       "upgrade without doing a backup.\n"))
            raise e.args[0]
        except Exception, e:
            printerr(_("The upgrade failed. Please fix the issue and try "
                       "again.\n"))
            raise

        # Remove wiki-macros if it is empty and warn if it isn't
        wiki_macros = os.path.join(self.env.path, 'wiki-macros')
        try:
            entries = os.listdir(wiki_macros)
        except OSError:
            pass
        else:
            if entries:
                printerr(_("Warning: the wiki-macros directory in the "
                           "environment is non-empty, but Trac\n"
                           "doesn't load plugins from there anymore. "
                           "Please remove it by hand."))
            else:
                try:
                    os.rmdir(wiki_macros)
                except OSError, e:
                    printerr(_("Error while removing wiki-macros: %(err)s\n"
                               "Trac doesn't load plugins from wiki-macros "
                               "anymore. Please remove it by hand.",
                               err=exception_to_unicode(e)))

        printout(_("Upgrade done.\n\n"
                   "You may want to upgrade the Trac documentation now by "
                   "running:\n\n  trac-admin %(path)s wiki upgrade",
                   path=path_to_unicode(self.env.path)))

########NEW FILE########
__FILENAME__ = hooks
#  Licensed to the Apache Software Foundation (ASF) under one
#  or more contributor license agreements.  See the NOTICE file
#  distributed with this work for additional information
#  regarding copyright ownership.  The ASF licenses this file
#  to you under the Apache License, Version 2.0 (the
#  "License"); you may not use this file except in compliance
#  with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing,
#  software distributed under the License is distributed on an
#  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
#  KIND, either express or implied.  See the License for the
#  specific language governing permissions and limitations
#  under the License.

import imp
import inspect
import os
import pkg_resources

from trac.config import Configuration
from trac.env import open_environment
from trac.util import exception_to_unicode
from trac.util.concurrency import threading
from trac.web.api import RequestDone
from trac.web.href import Href
from trac.web.main import RequestWithSession

__all__ = ['environment_factory', 'install_global_hooks']


class EnvironmentFactoryBase(object):
    def open_environment(self, environ, env_path, global_env, use_cache=False):
        raise NotImplementedError("Must override method 'open_environment'")


class RequestFactoryBase(object):
    def create_request(self, env, environ, start_response):
        raise NotImplementedError("Must override method 'create_request'")


def _get_plugins_dir(env_path):
    return os.path.normcase(os.path.realpath(os.path.join(env_path, 'plugins')))


def _get_config(env_path):
    return Configuration(os.path.join(env_path, 'conf', 'trac.ini'),
                         {'envname': os.path.basename(env_path)})


def _hook_load(env_path, hook_path):
    hook_name = os.path.basename(hook_path[:-3])
    plugins_dir = _get_plugins_dir(env_path)
    load_path = os.path.join(plugins_dir, hook_path)
    module = imp.load_source(hook_name, load_path)
    return module


def _get_hook_class(env_path, hook_path, class_type):
    module = _hook_load(env_path, hook_path)
    for (name, cls) in inspect.getmembers(module, inspect.isclass):
        if issubclass(cls, class_type) and \
           not cls is class_type:
            return cls
    return None

_global_hooks_installed = False
_global_hooks_lock = threading.Lock()


def install_global_hooks():
    global _global_hooks_installed, _global_hooks_lock
    if _global_hooks_installed:
        return
    _global_hooks_lock.acquire()
    try:
        if not _global_hooks_installed:
            try:
                # TODO: this is currently hardcoded, maybe it could be made
                # configurable in the future
                import multiproduct.hooks
            except:
                pass
            _global_hooks_installed = True
    finally:
        _global_hooks_lock.release()
    return


def environment_factory(env):
    hook_path = env.config.get('trac', 'environment_factory', default=None)
    return _get_hook_class(env.path, hook_path, EnvironmentFactoryBase) \
           if hook_path else None


def request_factory(env):
    hook_path = env.config.get('trac', 'request_factory', default=None)
    return _get_hook_class(env.path, hook_path, RequestFactoryBase) \
           if hook_path else None


class BootstrapHandlerBase(object):
    """Objects responsible for loading the target environment and
    request objects used in subsequent dispatching. 
    """
    def open_environment(self, environ, start_response):
        """Load and initialize target Trac environment involved in request
        dispatching.

        The following WSGI entries will also be present in `environ` dict:

        ||= WSGI variable =||= Environment variable =||= Comment =||
        || trac.env_path || TRAC_ENV || See wiki:TracModWSGI ||
        || trac.env_parent_dir || TRAC_ENV_PARENT_DIR || See wiki:TracModWSGI||
        || trac.env_index_template || TRAC_ENV_INDEX_TEMPLATE || See wiki:TracInterfaceCustomization ||
        || trac.template_vars || TRAC_TEMPLATE_VARS || See wiki:TracInterfaceCustomization ||
        || trac.locale ||  || Target locale ||
        || trac.base_url || TRAC_BASE_URL || Trac base URL hint ||

        A new entry named 'trac.env_name' identifying environment SHOULD be
        added (e.g. used by tracd to choose authentication realms). 
        As a side-effect the WSGI environment dict (i.e. `environ`) may be
        modified in many different ways to prepare it for subsequent
        dispatching.

        This method may handle the request (e.g. render environment index page)
        in case environment lookup yields void results. In that case it MUST 
        invoke WSGI `write` callable returned by `start_response` and raise 
        `trac.web.api.RequestDone` exception.

        :param environ: WSGI environment dict
        :param start_response: WSGI callback for starting the response
        :return: environment object
        :throws RequestDone: if the request is fully processed while loading
                             target environment e.g. environment index page
        :throws EnvironmentError: if it is impossible to find a way to locate
                                  target environment e.g. TRAC_ENV and 
                                  TRAC_ENV_PARENT_DIR both missing
        :throws Exception: any other exception will be processed by the caller 
                           in order to send a generic error message back to
                           the HTTP client
        """
        raise NotImplementedError("Must override method 'open_environment'")

    def default_probe_environment(self, environ):
        """By default it will invoke `open_environment` and discard the
        resulting environment object. This approach is generic but not
        efficient. Should be overridden whenever possible. 
        """
        # If the expected configuration keys aren't found in the WSGI
        # environment, try looking them up in the process environment variables
        environ.setdefault('trac.env_path', os.getenv('TRAC_ENV'))
        environ.setdefault('trac.env_parent_dir',
                           os.getenv('TRAC_ENV_PARENT_DIR'))
        environ.setdefault('trac.env_index_template',
                           os.getenv('TRAC_ENV_INDEX_TEMPLATE'))
        environ.setdefault('trac.template_vars',
                           os.getenv('TRAC_TEMPLATE_VARS'))
        environ.setdefault('trac.locale', '')
        environ.setdefault('trac.base_url',
                           os.getenv('TRAC_BASE_URL'))

        try:
            self.open_environment(environ, 
                                  lambda status, headers: (lambda data: None))
        except Exception:
            # Handle all exceptions; else potential HTTP protocol violation
            pass

    def probe_environment(self, environ):
        """This method is aimed at providing a lightweight version of
        `open_environment` by solely applying upon `environ` the side effects 
        needed to dispatch the request in environment context.

        By default it will invoke `open_environment` and discard the
        resulting environment object. Specialized versions will have the chance
        to implement more efficient strategies in case environment
        instantiation may be avoided. 

        :return: None
        """
        self.default_probe_environment(environ)
        
    def create_request(self, env, environ, start_response):
        """Instantiate request object used in subsequent request dispatching
        
        :param env: target Trac environment returned by `open_environment`
        :param environ: WSGI environment dict
        :param start_response: WSGI callback for starting the response
        """
        raise NotImplementedError("Must override method 'create_request'")


class DefaultBootstrapHandler(BootstrapHandlerBase):
    """Default bootstrap handler
    
    - Load environment based on URL path.
    - Instantiate RequestWithSession
    
    Notice: This class is a straightforward refactoring of factories
    implementation.
    """
    global_env = None

    def open_environment(self, environ, start_response):
        env_path = environ.get('trac.env_path')
        if env_path:
            environ['trac.env_name'] = os.path.basename(env_path)
        else:
            env_parent_dir = environ.get('trac.env_parent_dir')
            env_paths = environ.get('trac.env_paths')
            if env_parent_dir or env_paths:
                # The first component of the path is the base name of the
                # environment
                path_info = environ.get('PATH_INFO', '').lstrip('/').split('/')
                env_name = path_info.pop(0)
    
                if not env_name:
                    # No specific environment requested, so render an
                    # environment index page
                    send_project_index(environ, start_response, env_parent_dir,
                                       env_paths)
                    raise RequestDone

                environ['trac.env_name'] = env_name
                errmsg = None
    
                # To make the matching patterns of request handlers work, we
                # append the environment name to the `SCRIPT_NAME` variable,
                # and keep only the remaining path in the `PATH_INFO`
                # variable.
                script_name = environ.get('SCRIPT_NAME', '')
                try:
                    script_name = unicode(script_name, 'utf-8')
                    # (as Href expects unicode parameters)
                    environ['SCRIPT_NAME'] = Href(script_name)(env_name)
                    environ['PATH_INFO'] = '/' + '/'.join(path_info)
    
                    if env_parent_dir:
                        env_path = os.path.join(env_parent_dir, env_name)
                    else:
                        env_path = get_environments(environ).get(env_name)
    
                    if not env_path or not os.path.isdir(env_path):
                        errmsg = 'Environment not found'
                except UnicodeDecodeError:
                    errmsg = 'Invalid URL encoding (was %r)' % script_name
    
                if errmsg:
                    write = start_response('404 Not Found',
                                           [('Content-Type', 'text/plain'),
                                            ('Content-Length',
                                             str(len(errmsg)))])
                    write(errmsg)
                    raise RequestDone
    
        if not env_path:
            raise EnvironmentError('The environment options "TRAC_ENV" or '
                                   '"TRAC_ENV_PARENT_DIR" or the mod_python '
                                   'options "TracEnv" or "TracEnvParentDir" '
                                   'are missing. Trac requires one of these '
                                   'options to locate the Trac '
                                   'environment(s).')
        run_once = environ['wsgi.run_once']
    
        env = None
        self.global_env = global_env = None
        try:
            self.global_env = global_env = \
                open_environment(env_path, use_cache=not run_once)
            factory = environment_factory(global_env)
            factory_env = \
                factory().open_environment(environ, env_path, global_env,
                                           use_cache=not run_once) \
                if factory else None
            env = factory_env if factory_env else global_env
        except Exception:
            raise
        return env

    def create_request(self, env, environ, start_response):
        factory = None
        try:
            factory = request_factory(self.global_env)
        except Exception:
            pass
        return factory().create_request(env, environ, start_response) \
               if factory else RequestWithSession(environ, start_response)

default_bootstrap_handler = DefaultBootstrapHandler()


def load_bootstrap_handler(bootstrap_ep, log=None):
    """Load handler for environment lookup and instantiation of request objects

    :param bootstrap_ep: entry point specification
    :param log: file-like object used to report errors
    """
    bootstrap = None
    if bootstrap_ep:
        try:
            ep = pkg_resources.EntryPoint.parse('x = ' + bootstrap_ep)
            bootstrap = ep.load(require=False)
        except Exception, e:
            if log:
                log.write("[FAIL] [Trac] entry point '%s'. Reason %s" %
                          (bootstrap_ep, repr(exception_to_unicode(e))))
    if bootstrap is None:
        bootstrap = default_bootstrap_handler
    return bootstrap


# Recursive imports
from trac.web.main import send_project_index, get_environments

########NEW FILE########
__FILENAME__ = loader
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from glob import glob
import imp
import os.path
import pkg_resources
from pkg_resources import working_set, DistributionNotFound, VersionConflict, \
                          UnknownExtra
import sys

from trac.util import get_doc, get_module_path, get_sources, get_pkginfo
from trac.util.text import exception_to_unicode, to_unicode

__all__ = ['load_components']


def _enable_plugin(env, module):
    """Enable the given plugin module if it wasn't disabled explicitly."""
    if env.is_component_enabled(module) is None:
        env.enable_component(module)

def load_eggs(entry_point_name):
    """Loader that loads any eggs on the search path and `sys.path`."""
    def _load_eggs(env, search_path, auto_enable=None):
        # Note that the following doesn't seem to support unicode search_path
        distributions, errors = working_set.find_plugins(
            pkg_resources.Environment(search_path)
        )
        for dist in distributions:
            if dist not in working_set:
                env.log.debug('Adding plugin %s from %s', dist, dist.location)
                working_set.add(dist)

        def _log_error(item, e):
            ue = exception_to_unicode(e)
            if isinstance(e, DistributionNotFound):
                env.log.debug('Skipping "%s": ("%s" not found)', item, ue)
            elif isinstance(e, VersionConflict):
                env.log.error('Skipping "%s": (version conflict "%s")',
                              item, ue)
            elif isinstance(e, UnknownExtra):
                env.log.error('Skipping "%s": (unknown extra "%s")', item, ue)
            else:
                env.log.error('Skipping "%s": %s', item,
                              exception_to_unicode(e, traceback=True))

        for dist, e in errors.iteritems():
            _log_error(dist, e)

        for entry in sorted(working_set.iter_entry_points(entry_point_name),
                            key=lambda entry: entry.name):
            env.log.debug('Loading %s from %s', entry.name, entry.dist.location)
            try:
                entry.load(require=True)
            except Exception, e:
                _log_error(entry, e)
            else:
                if os.path.dirname(entry.dist.location) == auto_enable:
                    _enable_plugin(env, entry.module_name)
    return _load_eggs

def load_py_files():
    """Loader that look for Python source files in the plugins directories,
    which simply get imported, thereby registering them with the component
    manager if they define any components.
    """
    def _load_py_files(env, search_path, auto_enable=None):
        for path in search_path:
            plugin_files = glob(os.path.join(path, '*.py'))
            for plugin_file in plugin_files:
                try:
                    plugin_name = os.path.basename(plugin_file[:-3])
                    env.log.debug('Loading file plugin %s from %s' % \
                                  (plugin_name, plugin_file))
                    if plugin_name not in sys.modules:
                        module = imp.load_source(plugin_name, plugin_file)
                    if path == auto_enable:
                        _enable_plugin(env, plugin_name)
                except Exception, e:
                    env.log.error('Failed to load plugin from %s: %s',
                                  plugin_file,
                                  exception_to_unicode(e, traceback=True))

    return _load_py_files

def get_plugins_dir(env):
    """Return the path to the `plugins` directory of the environment."""
    plugins_dir = os.path.realpath(os.path.join(env.path, 'plugins'))
    return os.path.normcase(plugins_dir)

def load_components(env, extra_path=None, loaders=(load_eggs('trac.plugins'),
                                                   load_py_files())):
    """Load all plugin components found on the given search path."""
    plugins_dir = get_plugins_dir(env)
    search_path = [plugins_dir]
    if extra_path:
        search_path += list(extra_path)

    for loadfunc in loaders:
        loadfunc(env, search_path, auto_enable=plugins_dir)


def get_plugin_info(env, include_core=False):
    """Return package information about Trac core and installed plugins."""
    path_sources = {}

    def find_distribution(module):
        name = module.__name__
        path = get_module_path(module)
        sources = path_sources.get(path)
        if sources is None:
            sources = path_sources[path] = get_sources(path)
        dist = sources.get(name.replace('.', '/') + '.py')
        if dist is None:
            dist = sources.get(name.replace('.', '/') + '/__init__.py')
        if dist is None:
            # This is a plain Python source file, not an egg
            dist = pkg_resources.Distribution(project_name=name,
                                              version='',
                                              location=module.__file__)
        return dist

    plugins_dir = get_plugins_dir(env)
    plugins = {}
    from trac.core import ComponentMeta
    for component in ComponentMeta._components:
        module = sys.modules[component.__module__]

        dist = find_distribution(module)
        plugin_filename = None
        if os.path.realpath(os.path.dirname(dist.location)) == plugins_dir:
            plugin_filename = os.path.basename(dist.location)

        if dist.project_name not in plugins:
            readonly = True
            if plugin_filename and os.access(dist.location,
                                             os.F_OK + os.W_OK):
                readonly = False
            # retrieve plugin metadata
            info = get_pkginfo(dist)
            if not info:
                info = {}
                for k in ('author', 'author_email', 'home_page', 'url',
                          'license', 'trac'):
                    v = getattr(module, k, '')
                    if v and isinstance(v, basestring):
                        if k == 'home_page' or k == 'url':
                            k = 'home_page'
                            v = v.replace('$', '').replace('URL: ', '')
                        else:
                            v = to_unicode(v)
                        info[k] = v
            else:
                # Info found; set all those fields to "None" that have the
                # value "UNKNOWN" as this is the value for fields that
                # aren't specified in "setup.py"
                for k in info:
                    if info[k] == 'UNKNOWN':
                        info[k] = ''
                    else:
                        # Must be encoded as unicode as otherwise Genshi
                        # may raise a "UnicodeDecodeError".
                        info[k] = to_unicode(info[k])

            # retrieve plugin version info
            version = dist.version
            if not version:
                version = (getattr(module, 'version', '') or
                           getattr(module, 'revision', ''))
                # special handling for "$Rev$" strings
                version = version.replace('$', '').replace('Rev: ', 'r')
            plugins[dist.project_name] = {
                'name': dist.project_name, 'version': version,
                'path': dist.location, 'plugin_filename': plugin_filename,
                'readonly': readonly, 'info': info, 'modules': {},
            }
        modules = plugins[dist.project_name]['modules']
        if module.__name__ not in modules:
            summary, description = get_doc(module)
            plugins[dist.project_name]['modules'][module.__name__] = {
                'summary': summary, 'description': description,
                'components': {},
            }
        full_name = module.__name__ + '.' + component.__name__
        summary, description = get_doc(component)
        c = component
        if c in env and not issubclass(c, env.__class__):
            c = component(env)
        modules[module.__name__]['components'][component.__name__] = {
            'full_name': full_name,
            'summary': summary, 'description': description,
            'enabled': env.is_component_enabled(component),
            'required': getattr(c, 'required', False),
        }
    if not include_core:
        for name in plugins.keys():
            if name.lower() == 'trac':
                plugins.pop(name)
    return sorted(plugins.itervalues(),
                  key=lambda p: (p['name'].lower() != 'trac',
                                 p['name'].lower()))


def match_plugins_to_frames(plugins, frames):
    """Add a `frame_idx` element to plugin information as returned by
    `get_plugin_info()`, containing the index of the highest frame in the
    list that was located in the plugin.
    """
    egg_frames = [(i, f) for i, f in enumerate(frames)
                  if f['filename'].startswith('build/')]

    def find_egg_frame_index(plugin):
        for dist in pkg_resources.find_distributions(plugin['path'],
                                                     only=True):
            try:
                sources = dist.get_metadata('SOURCES.txt')
                for src in sources.splitlines():
                    if src.endswith('.py'):
                        nsrc = src.replace('\\', '/')
                        for i, f in egg_frames:
                            if f['filename'].endswith(nsrc):
                                plugin['frame_idx'] = i
                                return
            except KeyError:
                pass    # Metadata not found

    for plugin in plugins:
        base, ext = os.path.splitext(plugin['path'])
        if ext == '.egg' and egg_frames:
            find_egg_frame_index(plugin)
        else:
            for i, f in enumerate(frames):
                if f['filename'].startswith(base):
                    plugin['frame_idx'] = i
                    break

########NEW FILE########
__FILENAME__ = log
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Daniel Lundin <daniel@edgewall.com>
# Copyright (C) 2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>

import logging
import logging.handlers
import sys

def logger_handler_factory(logtype='syslog', logfile=None, level='WARNING',
                           logid='Trac', format=None):
    logger = logging.getLogger(logid)
    logtype = logtype.lower()
    if logtype == 'file':
        hdlr = logging.FileHandler(logfile)
    elif logtype in ('winlog', 'eventlog', 'nteventlog'):
        # Requires win32 extensions
        hdlr = logging.handlers.NTEventLogHandler(logid,
                                                  logtype='Application')
    elif logtype in ('syslog', 'unix'):
        hdlr = logging.handlers.SysLogHandler('/dev/log')
    elif logtype in ('stderr'):
        hdlr = logging.StreamHandler(sys.stderr)
    else:
        hdlr = logging.handlers.BufferingHandler(0)
        # Note: this _really_ throws away log events, as a `MemoryHandler`
        # would keep _all_ records in case there's no target handler (a bug?)

    if not format:
        format = 'Trac[%(module)s] %(levelname)s: %(message)s'
        if logtype in ('file', 'stderr'):
            format = '%(asctime)s ' + format
    datefmt = ''
    if logtype == 'stderr':
        datefmt = '%X'
    level = level.upper()
    if level in ('DEBUG', 'ALL'):
        logger.setLevel(logging.DEBUG)
    elif level == 'INFO':
        logger.setLevel(logging.INFO)
    elif level == 'ERROR':
        logger.setLevel(logging.ERROR)
    elif level == 'CRITICAL':
        logger.setLevel(logging.CRITICAL)
    else:
        logger.setLevel(logging.WARNING)
    formatter = logging.Formatter(format, datefmt)
    hdlr.setFormatter(formatter)
    logger.addHandler(hdlr)

    # Remember our handler so that we can remove it later
    logger._trac_handler = hdlr

    return logger, hdlr

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2010 Edgewall Software
# Copyright (C) 2004 Daniel Lundin <daniel@edgewall.com>
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2006-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>
#         Christian Boos <cboos@edgewall.org>

"""
File metadata management
------------------------

The `trac.mimeview` package centralizes the intelligence related to
file metadata, principally concerning the `type` (MIME type) of the
content and, if relevant, concerning the text encoding (charset) used
by the content.

There are primarily two approaches for getting the MIME type of a
given file, either taking advantage of existing conventions for the
file name, or examining the file content and applying various
heuristics.

The module also knows how to convert the file content from one type to
another type.

In some cases, only the `url` pointing to the file's content is
actually needed, that's why we avoid to read the file's content when
it's not needed.

The actual `content` to be converted might be a `unicode` object, but
it can also be the raw byte string (`str`) object, or simply an object
that can be `read()`.

.. note:: (for plugin developers)

  The Mimeview API is quite complex and many things there are
  currently a bit difficult to work with (e.g. what an actual
  `content` might be, see the last paragraph of this description).

  So this area is mainly in a ''work in progress'' state, which will
  be improved along the lines described in :teo:`#3332`.

  In particular, if you are interested in writing `IContentConverter`
  and `IHTMLPreviewRenderer` components, note that those interfaces
  will be merged into a new style `IContentConverter`.  Feel free to
  contribute remarks and suggestions for improvements to the
  corresponding ticket (#3332 as well).
"""

import re
from StringIO import StringIO

from genshi import Markup, Stream
from genshi.core import TEXT, START, END, START_NS, END_NS
from genshi.builder import Fragment, tag
from genshi.input import HTMLParser

from trac.config import IntOption, ListOption, Option
from trac.core import *
from trac.resource import Resource
from trac.util import Ranges, content_disposition
from trac.util.text import exception_to_unicode, to_utf8, to_unicode
from trac.util.translation import _, tag_


__all__ = ['Context', 'Mimeview', 'RenderingContext', 'get_mimetype',
           'is_binary', 'detect_unicode', 'content_to_unicode', 'ct_mimetype']

class RenderingContext(object):
    """
    A rendering context specifies ''how'' the content should be rendered.

    It holds together all the needed contextual information that will be
    needed by individual renderer components.

    To that end, a context keeps track of the Href instance (`.href`) which
    should be used as a base for building URLs.

    It also provides a `PermissionCache`  (`.perm`) which can be used to
    restrict the output so that only the authorized information is shown.

    A rendering context may also be associated to some Trac resource which
    will be used as the implicit reference when rendering relative links
    or for retrieving relative content and can be used to retrieve related
    metadata.

    Rendering contexts can be nested, and a new context can be created from
    an existing context using the call syntax. The previous context can be
    retrieved using the `.parent` attribute.

    For example, when rendering a wiki text of a wiki page, the context will
    be associated to a resource identifying that wiki page.

    If that wiki text contains a `[[TicketQuery]]` wiki macro, the macro will
    set up nested contexts for each matching ticket that will be used for
    rendering the ticket descriptions.

    :since: version 0.11
    """

    def __init__(self, resource, href=None, perm=None):
        """Directly create a `RenderingContext`.

        :param resource: the associated resource
        :type resource: `Resource`
        :param href: an `Href` object suitable for creating URLs
        :param perm: a `PermissionCache` object used for restricting the
                     generated output to "authorized" information only.

        The actual `.perm` attribute of the rendering context will be bound
        to the given `resource` so that fine-grained permission checks will
        apply to that.
        """
        self.parent = None #: The parent context, if any
        self.resource = resource
        self.href = href
        self.perm = perm(resource) if perm and resource else perm
        self._hints = None

    @staticmethod
    def from_request(*args, **kwargs):
        """:deprecated: since 1.0, use `web_context` instead."""
        from trac.web.chrome import web_context
        return web_context(*args, **kwargs)

    def __repr__(self):
        path = []
        context = self
        while context:
            if context.resource.realm: # skip toplevel resource
                path.append(repr(context.resource))
            context = context.parent
        return '<%s %s>' % (type(self).__name__, ' - '.join(reversed(path)))

    def child(self, resource=None, id=False, version=False, parent=False):
        """Create a nested rendering context.

        `self` will be the parent for the new nested context.

        :param resource: either a `Resource` object or the realm string for a
                         resource specification to be associated to the new
                         context. If `None`, the resource will be the same
                         as the resource of the parent context.
        :param id: the identifier part of the resource specification
        :param version: the version of the resource specification
        :return: the new context object
        :rtype: `RenderingContext`

        >>> context = RenderingContext('wiki', 'WikiStart')
        >>> ticket1 = Resource('ticket', 1)
        >>> context.child('ticket', 1).resource == ticket1
        True
        >>> context.child(ticket1).resource is ticket1
        True
        >>> context.child(ticket1)().resource is ticket1
        True
        """
        if resource:
            resource = Resource(resource, id=id, version=version,
                                parent=parent)
        else:
            resource = self.resource
        context = RenderingContext(resource, href=self.href, perm=self.perm)
        context.parent = self

        # hack for context instances created by from_request()
        # this is needed because various parts of the code rely on a request
        # object being available, but that will hopefully improve in the
        # future
        if hasattr(self, 'req'):
            context.req = self.req

        return context

    __call__ = child

    def __contains__(self, resource):
        """Check whether a resource is in the rendering path.

        The primary use for this check is to avoid to render the content of a
        resource if we're already embedded in a context associated to that
        resource.

        :param resource: a `Resource` specification which will be checked for
        """
        context = self
        while context:
            if context.resource and \
                   context.resource.realm == resource.realm and \
                   context.resource.id == resource.id:
                # we don't care about version here
                return True
            context = context.parent

    # Rendering hints
    #
    # A rendering hint is a key/value pairs that can influence renderers,
    # wiki formatters and processors in the way they produce their output.
    # The keys are strings, but the values could be anything.
    #
    # In nested contexts, the hints are inherited from their parent context,
    # unless overriden locally.

    def set_hints(self, **keyvalues):
        """Set rendering hints for this rendering context.

        >>> ctx = RenderingContext('timeline')
        >>> ctx.set_hints(wiki_flavor='oneliner', shorten_lines=True)
        >>> t_ctx = ctx('ticket', 1)
        >>> t_ctx.set_hints(wiki_flavor='html', preserve_newlines=True)
        >>> (t_ctx.get_hint('wiki_flavor'), t_ctx.get_hint('shorten_lines'), \
             t_ctx.get_hint('preserve_newlines'))
        ('html', True, True)
        >>> (ctx.get_hint('wiki_flavor'), ctx.get_hint('shorten_lines'), \
             ctx.get_hint('preserve_newlines'))
        ('oneliner', True, None)
        """
        if self._hints is None:
            self._hints = {}
            hints = self._parent_hints()
            if hints is not None:
                self._hints.update(hints)
        self._hints.update(keyvalues)

    def get_hint(self, hint, default=None):
        """Retrieve a rendering hint from this context or an ancestor context.

        >>> ctx = RenderingContext('timeline')
        >>> ctx.set_hints(wiki_flavor='oneliner')
        >>> t_ctx = ctx('ticket', 1)
        >>> t_ctx.get_hint('wiki_flavor')
        'oneliner'
        >>> t_ctx.get_hint('preserve_newlines', True)
        True
        """
        hints = self._hints
        if hints is None:
            hints = self._parent_hints()
            if hints is None:
                return default
        return hints.get(hint, default)

    def has_hint(self, hint):
        """Test whether a rendering hint is defined in this context or in some
        ancestor context.

        >>> ctx = RenderingContext('timeline')
        >>> ctx.set_hints(wiki_flavor='oneliner')
        >>> t_ctx = ctx('ticket', 1)
        >>> t_ctx.has_hint('wiki_flavor')
        True
        >>> t_ctx.has_hint('preserve_newlines')
        False
        """
        hints = self._hints
        if hints is None:
            hints = self._parent_hints()
            if hints is None:
                return False
        return hint in hints

    def _parent_hints(self):
        p = self.parent
        while p and p._hints is None:
            p = p.parent
        return p and p._hints


class Context(RenderingContext):
    """:deprecated: old name kept for compatibility, use `RenderingContext`."""


# Some common MIME types and their associated keywords and/or file extensions

KNOWN_MIME_TYPES = {
    'application/javascript': 'js',
    'application/msword':     'doc dot',
    'application/pdf':        'pdf',
    'application/postscript': 'ps',
    'application/rtf':        'rtf',
    'application/x-sh':       'sh',
    'application/x-csh':      'csh',
    'application/x-troff':    'nroff roff troff',
    'application/x-yaml':     'yml yaml',

    'application/rss+xml':    'rss',
    'application/xsl+xml':    'xsl',
    'application/xslt+xml':   'xslt',

    'image/x-icon':           'ico',
    'image/svg+xml':          'svg',

    'model/vrml':             'vrml wrl',

    'text/css':               'css',
    'text/html':              'html htm',
    'text/plain':             'txt TXT text README INSTALL '
                              'AUTHORS COPYING ChangeLog RELEASE',
    'text/xml':               'xml',

    # see also TEXT_X_TYPES below
    'text/x-csrc':            'c xs',
    'text/x-chdr':            'h',
    'text/x-c++src':          'cc CC cpp C c++ C++',
    'text/x-c++hdr':          'hh HH hpp H',
    'text/x-csharp':          'cs c# C#',
    'text/x-diff':            'patch',
    'text/x-eiffel':          'e',
    'text/x-elisp':           'el',
    'text/x-fortran':         'f',
    'text/x-haskell':         'hs',
    'text/x-ini':             'ini cfg',
    'text/x-objc':            'm mm',
    'text/x-ocaml':           'ml mli',
    'text/x-makefile':        'make mk Makefile GNUMakefile',
    'text/x-pascal':          'pas',
    'text/x-perl':            'pl pm PL',
    'text/x-php':             'php3 php4',
    'text/x-python':          'py',
    'text/x-pyrex':           'pyx',
    'text/x-ruby':            'rb',
    'text/x-scheme':          'scm',
    'text/x-textile':         'txtl',
    'text/x-vba':             'vb vba bas',
    'text/x-verilog':         'v',
    'text/x-vhdl':            'vhd',
}
for t in KNOWN_MIME_TYPES.keys():
    types = KNOWN_MIME_TYPES[t].split()
    if t.startswith('text/x-'):
        types.append(t[len('text/x-'):])
    KNOWN_MIME_TYPES[t] = types

# extend the above with simple (text/x-<something>: <something>) mappings

TEXT_X_TYPES = """
    ada asm asp awk idl inf java ksh lua m4 mail psp rfc rst sql tcl tex zsh
"""
for x in TEXT_X_TYPES.split():
    KNOWN_MIME_TYPES.setdefault('text/x-%s' % x, []).append(x)


# Default mapping from keywords/extensions to known MIME types:

MIME_MAP = {}
for t, exts in KNOWN_MIME_TYPES.items():
    MIME_MAP[t] = t
    for e in exts:
        MIME_MAP[e] = t

# Simple builtin autodetection from the content using a regexp
MODE_RE = re.compile(r"""
      \#!.+?env\s+(\w+)                     # 1. look for shebang with env
    | \#!(?:[/\w.-_]+/)?(\w+)               # 2. look for regular shebang
    | -\*-\s*(?:mode:\s*)?([\w+-]+)\s*-\*-  # 3. look for Emacs' -*- mode -*-
    | vim:.*?(?:syntax|filetype|ft)=(\w+)   # 4. look for VIM's syntax=<n>
    """, re.VERBOSE)

def get_mimetype(filename, content=None, mime_map=MIME_MAP,
                 mime_map_patterns={}):
    """Guess the most probable MIME type of a file with the given name.

    `filename` is either a filename (the lookup will then use the suffix)
    or some arbitrary keyword.

    `content` is either a `str` or an `unicode` string.
    """
    # 0) mimetype from filename pattern (most specific)
    for mimetype, regexp in mime_map_patterns.iteritems():
        if regexp.match(filename):
            return mimetype
    suffix = filename.split('.')[-1]
    if suffix in mime_map:
        # 1) mimetype from the suffix, using the `mime_map`
        return mime_map[suffix]
    else:
        mimetype = None
        try:
            import mimetypes
            # 2) mimetype from the suffix, using the `mimetypes` module
            mimetype = mimetypes.guess_type(filename)[0]
        except Exception:
            pass
        if not mimetype and content:
            match = re.search(MODE_RE, content[:1000] + content[-1000:])
            if match:
                mode = match.group(1) or match.group(2) or match.group(4) or \
                    match.group(3).lower()
                if mode in mime_map:
                    # 3) mimetype from the content, using the `MODE_RE`
                    return mime_map[mode]
            else:
                if is_binary(content):
                    # 4) mimetype from the content, using`is_binary`
                    return 'application/octet-stream'
        return mimetype

def ct_mimetype(content_type):
    """Return the mimetype part of a content type."""
    return (content_type or '').split(';')[0].strip()

def is_binary(data):
    """Detect binary content by checking the first thousand bytes for zeroes.

    Operate on either `str` or `unicode` strings.
    """
    if isinstance(data, str) and detect_unicode(data):
        return False
    return '\0' in data[:1000]

def detect_unicode(data):
    """Detect different unicode charsets by looking for BOMs (Byte Order Mark).

    Operate obviously only on `str` objects.
    """
    if data.startswith('\xff\xfe'):
        return 'utf-16-le'
    elif data.startswith('\xfe\xff'):
        return 'utf-16-be'
    elif data.startswith('\xef\xbb\xbf'):
        return 'utf-8'
    else:
        return None

def content_to_unicode(env, content, mimetype):
    """Retrieve an `unicode` object from a `content` to be previewed.

    In case the raw content had an unicode BOM, we remove it.

    >>> from trac.test import EnvironmentStub
    >>> env = EnvironmentStub()
    >>> content_to_unicode(env, u"\ufeffNo BOM! h\u00e9 !", '')
    u'No BOM! h\\xe9 !'
    >>> content_to_unicode(env, "\xef\xbb\xbfNo BOM! h\xc3\xa9 !", '')
    u'No BOM! h\\xe9 !'

    """
    mimeview = Mimeview(env)
    if hasattr(content, 'read'):
        content = content.read(mimeview.max_preview_size)
    u = mimeview.to_unicode(content, mimetype)
    if u and u[0] == u'\ufeff':
        u = u[1:]
    return u


class IHTMLPreviewRenderer(Interface):
    """Extension point interface for components that add HTML renderers of
    specific content types to the `Mimeview` component.

    .. note::

      This interface will be merged with IContentConverter, as
      conversion to text/html will simply be a particular content
      conversion.

      Note however that the IHTMLPreviewRenderer will still be
      supported for a while through an adapter, whereas the
      IContentConverter interface itself will be changed.

      So if all you want to do is convert to HTML and don't feel like
      following the API changes, you should rather implement this
      interface for the time being.
    """

    #: implementing classes should set this property to True if they
    #: support text content where Trac should expand tabs into spaces
    expand_tabs = False

    #: indicate whether the output of this renderer is source code that can
    #: be decorated with annotations
    returns_source = False

    def get_extra_mimetypes():
        """Augment the Mimeview system with new mimetypes associations.

        This is an optional method. Not implementing the method or
        returning nothing is fine, the component will still be asked
        via `get_quality_ratio` if it supports a known mimetype.  But
        implementing it can be useful when the component knows about
        additional mimetypes which may augment the list of already
        mimetype to keywords associations.

        Generate ``(mimetype, keywords)`` pairs for each additional
        mimetype, with ``keywords`` being a list of keywords or
        extensions that can be used as aliases for the mimetype
        (typically file suffixes or Wiki processor keys).

        .. versionadded:: 1.0
        """

    def get_quality_ratio(mimetype):
        """Return the level of support this renderer provides for the `content`
        of the specified MIME type. The return value must be a number between
        0 and 9, where 0 means no support and 9 means "perfect" support.
        """

    def render(context, mimetype, content, filename=None, url=None):
        """Render an XHTML preview of the raw `content` in a RenderingContext.

        The `content` might be:
         * a `str` object
         * an `unicode` string
         * any object with a `read` method, returning one of the above

        It is assumed that the content will correspond to the given `mimetype`.

        Besides the `content` value, the same content may eventually
        be available through the `filename` or `url` parameters.
        This is useful for renderers that embed objects, using <object> or
        <img> instead of including the content inline.

        Can return the generated XHTML text as a single string or as an
        iterable that yields strings. In the latter case, the list will
        be considered to correspond to lines of text in the original content.
        """


class IHTMLPreviewAnnotator(Interface):
    """Extension point interface for components that can annotate an XHTML
    representation of file contents with additional information."""

    def get_annotation_type():
        """Return a (type, label, description) tuple
        that defines the type of annotation and provides human readable names.
        The `type` element should be unique to the annotator.
        The `label` element is used as column heading for the table,
        while `description` is used as a display name to let the user
        toggle the appearance of the annotation type.
        """

    def get_annotation_data(context):
        """Return some metadata to be used by the `annotate_row` method below.

        This will be called only once, before lines are processed.
        If this raises an error, that annotator won't be used.
        """

    def annotate_row(context, row, number, line, data):
        """Return the XHTML markup for the table cell that contains the
        annotation data.

        `context` is the context corresponding to the content being annotated,
        `row` is the tr Element being built, `number` is the line number being
        processed and `line` is the line's actual content.
        `data` is whatever additional data the `get_annotation_data` method
        decided to provide.
        """


class IContentConverter(Interface):
    """An extension point interface for generic MIME based content
    conversion.

    .. note:: This api will likely change in the future (see :teo:`#3332`)

    """

    def get_supported_conversions():
        """Return an iterable of tuples in the form (key, name, extension,
        in_mimetype, out_mimetype, quality) representing the MIME conversions
        supported and
        the quality ratio of the conversion in the range 0 to 9, where 0 means
        no support and 9 means "perfect" support. eg. ('latex', 'LaTeX', 'tex',
        'text/x-trac-wiki', 'text/plain', 8)"""

    def convert_content(req, mimetype, content, key):
        """Convert the given content from mimetype to the output MIME type
        represented by key. Returns a tuple in the form (content,
        output_mime_type) or None if conversion is not possible."""


class Content(object):
    """A lazy file-like object that only reads `input` if necessary."""
    def __init__(self, input, max_size):
        self.input = input
        self.max_size = max_size
        self.content = None

    def read(self, size=-1):
        if size == 0:
            return ''
        if self.content is None:
            self.content = StringIO(self.input.read(self.max_size))
        return self.content.read(size)

    def reset(self):
        if self.content is not None:
            self.content.seek(0)


class Mimeview(Component):
    """Generic HTML renderer for data, typically source code."""

    required = True

    renderers = ExtensionPoint(IHTMLPreviewRenderer)
    annotators = ExtensionPoint(IHTMLPreviewAnnotator)
    converters = ExtensionPoint(IContentConverter)

    default_charset = Option('trac', 'default_charset', 'utf-8',
        """Charset to be used when in doubt.""")

    tab_width = IntOption('mimeviewer', 'tab_width', 8,
        """Displayed tab width in file preview. (''since 0.9'')""")

    max_preview_size = IntOption('mimeviewer', 'max_preview_size', 262144,
        """Maximum file size for HTML preview. (''since 0.9'')""")

    mime_map = ListOption('mimeviewer', 'mime_map',
        'text/x-dylan:dylan, text/x-idl:ice, text/x-ada:ads:adb',
        doc="""List of additional MIME types and keyword mappings.
        Mappings are comma-separated, and for each MIME type,
        there's a colon (":") separated list of associated keywords
        or file extensions. (''since 0.10'')""")

    mime_map_patterns = ListOption('mimeviewer', 'mime_map_patterns',
        'text/plain:README|INSTALL|COPYING.*',
        doc="""List of additional MIME types associated to filename patterns.
        Mappings are comma-separated, and each mapping consists of a MIME type
        and a Python regexp used for matching filenames, separated by a colon
        (":"). (''since 1.0'')""")

    treat_as_binary = ListOption('mimeviewer', 'treat_as_binary',
        'application/octet-stream, application/pdf, application/postscript, '
        'application/msword,application/rtf,',
        doc="""Comma-separated list of MIME types that should be treated as
        binary data. (''since 0.11.5'')""")

    def __init__(self):
        self._mime_map = None
        self._mime_map_patterns = None

    # Public API

    def get_supported_conversions(self, mimetype):
        """Return a list of target MIME types in same form as
        `IContentConverter.get_supported_conversions()`, but with the converter
        component appended. Output is ordered from best to worst quality."""
        converters = []
        for converter in self.converters:
            conversions = converter.get_supported_conversions() or []
            for k, n, e, im, om, q in conversions:
                if im == mimetype and q > 0:
                    converters.append((k, n, e, im, om, q, converter))
        converters = sorted(converters, key=lambda i: i[-2], reverse=True)
        return converters

    def convert_content(self, req, mimetype, content, key, filename=None,
                        url=None):
        """Convert the given content to the target MIME type represented by
        `key`, which can be either a MIME type or a key. Returns a tuple of
        (content, output_mime_type, extension)."""
        if not content:
            return ('', 'text/plain;charset=utf-8', '.txt')

        # Ensure we have a MIME type for this content
        full_mimetype = mimetype
        if not full_mimetype:
            if hasattr(content, 'read'):
                content = content.read(self.max_preview_size)
            full_mimetype = self.get_mimetype(filename, content)
        if full_mimetype:
            mimetype = ct_mimetype(full_mimetype)   # split off charset
        else:
            mimetype = full_mimetype = 'text/plain' # fallback if not binary

        # Choose best converter
        candidates = list(self.get_supported_conversions(mimetype) or [])
        candidates = [c for c in candidates if key in (c[0], c[4])]
        if not candidates:
            raise TracError(
                _("No available MIME conversions from %(old)s to %(new)s",
                  old=mimetype, new=key))

        # First successful conversion wins
        for ck, name, ext, input_mimettype, output_mimetype, quality, \
                converter in candidates:
            output = converter.convert_content(req, mimetype, content, ck)
            if output:
                return (output[0], output[1], ext)
        raise TracError(
            _("No available MIME conversions from %(old)s to %(new)s",
              old=mimetype, new=key))

    def get_annotation_types(self):
        """Generator that returns all available annotation types."""
        for annotator in self.annotators:
            yield annotator.get_annotation_type()

    def render(self, context, mimetype, content, filename=None, url=None,
               annotations=None, force_source=False):
        """Render an XHTML preview of the given `content`.

        `content` is the same as an `IHTMLPreviewRenderer.render`'s
        `content` argument.

        The specified `mimetype` will be used to select the most appropriate
        `IHTMLPreviewRenderer` implementation available for this MIME type.
        If not given, the MIME type will be infered from the filename or the
        content.

        Return a string containing the XHTML text.

        When rendering with an `IHTMLPreviewRenderer` fails, a warning is added
        to the request associated with the context (if any), unless the
        `disable_warnings` hint is set to `True`.
        """
        if not content:
            return ''
        if not isinstance(context, RenderingContext):
            raise TypeError("RenderingContext expected (since 0.11)")

        # Ensure we have a MIME type for this content
        full_mimetype = mimetype
        if not full_mimetype:
            if hasattr(content, 'read'):
                content = content.read(self.max_preview_size)
            full_mimetype = self.get_mimetype(filename, content)
        if full_mimetype:
            mimetype = ct_mimetype(full_mimetype)   # split off charset
        else:
            mimetype = full_mimetype = 'text/plain' # fallback if not binary

        # Determine candidate `IHTMLPreviewRenderer`s
        candidates = []
        for renderer in self.renderers:
            qr = renderer.get_quality_ratio(mimetype)
            if qr > 0:
                candidates.append((qr, renderer))
        candidates.sort(lambda x, y: cmp(y[0], x[0]))

        # Wrap file-like object so that it can be read multiple times
        if hasattr(content, 'read'):
            content = Content(content, self.max_preview_size)

        # First candidate which renders successfully wins.
        # Also, we don't want to expand tabs more than once.
        expanded_content = None
        for qr, renderer in candidates:
            if force_source and not getattr(renderer, 'returns_source', False):
                continue # skip non-source renderers in force_source mode
            if isinstance(content, Content):
                content.reset()
            try:
                ann_names = ', '.join(annotations) if annotations else \
                           'no annotations'
                self.log.debug('Trying to render HTML preview using %s [%s]',
                               renderer.__class__.__name__, ann_names)

                # check if we need to perform a tab expansion
                rendered_content = content
                if getattr(renderer, 'expand_tabs', False):
                    if expanded_content is None:
                        content = content_to_unicode(self.env, content,
                                                     full_mimetype)
                        expanded_content = content.expandtabs(self.tab_width)
                    rendered_content = expanded_content

                result = renderer.render(context, full_mimetype,
                                         rendered_content, filename, url)
                if not result:
                    continue

                if not (force_source or getattr(renderer, 'returns_source',
                                                False)):
                    # Direct rendering of content
                    if isinstance(result, basestring):
                        if not isinstance(result, unicode):
                            result = to_unicode(result)
                        return Markup(to_unicode(result))
                    elif isinstance(result, Fragment):
                        return result.generate()
                    else:
                        return result

                # Render content as source code
                if annotations:
                    m = context.req.args.get('marks') if context.req else None
                    return self._render_source(context, result, annotations,
                                               m and Ranges(m))
                else:
                    if isinstance(result, list):
                        result = Markup('\n').join(result)
                    return tag.div(class_='code')(tag.pre(result)).generate()

            except Exception, e:
                self.log.warning('HTML preview using %s failed: %s',
                                 renderer.__class__.__name__,
                                 exception_to_unicode(e, traceback=True))
                if context.req and not context.get_hint('disable_warnings'):
                    from trac.web.chrome import add_warning
                    add_warning(context.req,
                        _("HTML preview using %(renderer)s failed (%(err)s)",
                          renderer=renderer.__class__.__name__,
                          err=exception_to_unicode(e)))

    def _render_source(self, context, stream, annotations, marks=None):
        from trac.web.chrome import add_warning
        annotators, labels, titles = {}, {}, {}
        for annotator in self.annotators:
            atype, alabel, atitle = annotator.get_annotation_type()
            if atype in annotations:
                labels[atype] = alabel
                titles[atype] = atitle
                annotators[atype] = annotator
        annotations = [a for a in annotations if a in annotators]

        if isinstance(stream, list):
            stream = HTMLParser(StringIO(u'\n'.join(stream)))
        elif isinstance(stream, unicode):
            text = stream
            def linesplitter():
                for line in text.splitlines(True):
                    yield TEXT, line, (None, -1, -1)
            stream = linesplitter()

        annotator_datas = []
        for a in annotations:
            annotator = annotators[a]
            try:
                data = (annotator, annotator.get_annotation_data(context))
            except TracError, e:
                self.log.warning("Can't use annotator '%s': %s", a, e.message)
                add_warning(context.req, tag.strong(
                    tag_("Can't use %(annotator)s annotator: %(error)s",
                         annotator=tag.em(a), error=tag.pre(e.message))))
                data = (None, None)
            annotator_datas.append(data)

        def _head_row():
            return tag.tr(
                [tag.th(labels[a], class_=a, title=titles[a])
                 for a in annotations] +
                [tag.th(u'\xa0', class_='content')]
            )

        def _body_rows():
            for idx, line in enumerate(_group_lines(stream)):
                row = tag.tr()
                if marks and idx + 1 in marks:
                    row(class_='hilite')
                for annotator, data in annotator_datas:
                    if annotator:
                        annotator.annotate_row(context, row, idx+1, line, data)
                    else:
                        row.append(tag.td())
                row.append(tag.td(line))
                yield row

        return tag.table(class_='code')(
            tag.thead(_head_row()),
            tag.tbody(_body_rows())
        )

    def get_max_preview_size(self):
        """:deprecated: use `max_preview_size` attribute directly."""
        return self.max_preview_size

    def get_charset(self, content='', mimetype=None):
        """Infer the character encoding from the `content` or the `mimetype`.

        `content` is either a `str` or an `unicode` object.

        The charset will be determined using this order:
         * from the charset information present in the `mimetype` argument
         * auto-detection of the charset from the `content`
         * the configured `default_charset`
        """
        if mimetype:
            ctpos = mimetype.find('charset=')
            if ctpos >= 0:
                return mimetype[ctpos + 8:].strip()
        if isinstance(content, str):
            utf = detect_unicode(content)
            if utf is not None:
                return utf
        return self.default_charset

    @property
    def mime_map(self):
        # Extend default extension to MIME type mappings with configured ones
        if not self._mime_map:
            self._mime_map = MIME_MAP.copy()
            # augment mime_map from `IHTMLPreviewRenderer`s
            for renderer in self.renderers:
                if hasattr(renderer, 'get_extra_mimetypes'):
                    for mimetype, kwds in renderer.get_extra_mimetypes() or []:
                        self._mime_map[mimetype] = mimetype
                        for keyword in kwds:
                            self._mime_map[keyword] = mimetype
            # augment/override mime_map from trac.ini
            for mapping in self.config['mimeviewer'].getlist('mime_map'):
                if ':' in mapping:
                    assocations = mapping.split(':')
                    for keyword in assocations: # Note: [0] kept on purpose
                        self._mime_map[keyword] = assocations[0]
        return self._mime_map

    def get_mimetype(self, filename, content=None):
        """Infer the MIME type from the `filename` or the `content`.

        `content` is either a `str` or an `unicode` object.

        Return the detected MIME type, augmented by the
        charset information (i.e. "<mimetype>; charset=..."),
        or `None` if detection failed.
        """

        mimetype = get_mimetype(filename, content, self.mime_map,
                                self.mime_map_patterns)
        charset = None
        if mimetype:
            charset = self.get_charset(content, mimetype)
        if mimetype and charset and not 'charset' in mimetype:
            mimetype += '; charset=' + charset
        return mimetype

    @property
    def mime_map_patterns(self):
        if not self._mime_map_patterns:
            self._mime_map_patterns = {}
            for mapping in self.config['mimeviewer'] \
                    .getlist('mime_map_patterns'):
                if ':' in mapping:
                    mimetype, regexp = mapping.split(':', 1)
                try:
                    self._mime_map_patterns[mimetype] = re.compile(regexp)
                except re.error, e:
                    self.log.warning("mime_map_patterns contains invalid "
                                     "regexp '%s' for mimetype '%s' (%s)",
                                     regexp, mimetype, exception_to_unicode(e))
        return self._mime_map_patterns

    def is_binary(self, mimetype=None, filename=None, content=None):
        """Check if a file must be considered as binary."""
        if not mimetype and filename:
            mimetype = self.get_mimetype(filename, content)
        if mimetype:
            mimetype = ct_mimetype(mimetype)
            if mimetype in self.treat_as_binary:
                return True
        if content is not None and is_binary(content):
            return True
        return False

    def to_utf8(self, content, mimetype=None):
        """Convert an encoded `content` to utf-8.

        :deprecated: since 0.10, you should use `unicode` strings only.
        """
        return to_utf8(content, self.get_charset(content, mimetype))

    def to_unicode(self, content, mimetype=None, charset=None):
        """Convert `content` (an encoded `str` object) to an `unicode` object.

        This calls `trac.util.to_unicode` with the `charset` provided,
        or the one obtained by `Mimeview.get_charset()`.
        """
        if not charset:
            charset = self.get_charset(content, mimetype)
        return to_unicode(content, charset)

    def configured_modes_mapping(self, renderer):
        """Return a MIME type to `(mode,quality)` mapping for given `option`"""
        types, option = {}, '%s_modes' % renderer
        for mapping in self.config['mimeviewer'].getlist(option):
            if not mapping:
                continue
            try:
                mimetype, mode, quality = mapping.split(':')
                types[mimetype] = (mode, int(quality))
            except (TypeError, ValueError):
                self.log.warning("Invalid mapping '%s' specified in '%s' "
                                 "option.", mapping, option)
        return types

    def preview_data(self, context, content, length, mimetype, filename,
                     url=None, annotations=None, force_source=False):
        """Prepares a rendered preview of the given `content`.

        Note: `content` will usually be an object with a `read` method.
        """
        data = {'raw_href': url, 'size': length,
                'max_file_size': self.max_preview_size,
                'max_file_size_reached': False,
                'rendered': None,
                }
        if length >= self.max_preview_size:
            data['max_file_size_reached'] = True
        else:
            result = self.render(context, mimetype, content, filename, url,
                                 annotations, force_source=force_source)
            data['rendered'] = result
        return data

    def send_converted(self, req, in_type, content, selector, filename='file'):
        """Helper method for converting `content` and sending it directly.

        `selector` can be either a key or a MIME Type."""
        from trac.web.api import RequestDone
        content, output_type, ext = self.convert_content(req, in_type,
                                                         content, selector)
        if isinstance(content, unicode):
            content = content.encode('utf-8')
        req.send_response(200)
        req.send_header('Content-Type', output_type)
        req.send_header('Content-Length', len(content))
        if filename:
            req.send_header('Content-Disposition',
                            content_disposition('attachment',
                                                '%s.%s' % (filename, ext)))
        req.end_headers()
        req.write(content)
        raise RequestDone


def _group_lines(stream):
    space_re = re.compile('(?P<spaces> (?: +))|^(?P<tag><\w+.*?>)?( )')
    def pad_spaces(match):
        m = match.group('spaces')
        if m:
            div, mod = divmod(len(m), 2)
            return div * u'\xa0 ' + mod * u'\xa0'
        return (match.group('tag') or '') + u'\xa0'

    def _generate():
        stack = []
        def _reverse():
            for event in reversed(stack):
                if event[0] is START:
                    yield END, event[1][0], event[2]
                else:
                    yield END_NS, event[1][0], event[2]

        for kind, data, pos in stream:
            if kind is TEXT:
                lines = data.split('\n')
                if lines:
                    # First element
                    for e in stack:
                        yield e
                    yield kind, lines.pop(0), pos
                    for e in _reverse():
                        yield e
                    # Subsequent ones, prefix with \n
                    for line in lines:
                        yield TEXT, '\n', pos
                        for e in stack:
                            yield e
                        yield kind, line, pos
                        for e in _reverse():
                            yield e
            else:
                if kind is START or kind is START_NS:
                    stack.append((kind, data, pos))
                elif kind is END or kind is END_NS:
                    stack.pop()
                else:
                    yield kind, data, pos

    buf = []

    # Fix the \n at EOF.
    if not isinstance(stream, list):
        stream = list(stream)
    found_text = False

    for i in range(len(stream)-1, -1, -1):
        if stream[i][0] is TEXT:
            e = stream[i]
            # One chance to strip a \n
            if not found_text and e[1].endswith('\n'):
                stream[i] = (e[0], e[1][:-1], e[2])
            if len(e[1]):
                found_text = True
                break
    if not found_text:
        raise StopIteration

    for kind, data, pos in _generate():
        if kind is TEXT and data == '\n':
            yield Stream(buf[:])
            del buf[:]
        else:
            if kind is TEXT:
                data = space_re.sub(pad_spaces, data)
            buf.append((kind, data, pos))
    if buf:
        yield Stream(buf[:])


# -- Default annotators

class LineNumberAnnotator(Component):
    """Text annotator that adds a column with line numbers."""
    implements(IHTMLPreviewAnnotator)

    # ITextAnnotator methods

    def get_annotation_type(self):
        return 'lineno', _('Line'), _('Line numbers')

    def get_annotation_data(self, context):
        return None

    def annotate_row(self, context, row, lineno, line, data):
        row.append(tag.th(id='L%s' % lineno)(
            tag.a(lineno, href='#L%s' % lineno)
        ))


# -- Default renderers

class PlainTextRenderer(Component):
    """HTML preview renderer for plain text, and fallback for any kind of text
    for which no more specific renderer is available.
    """
    implements(IHTMLPreviewRenderer)

    expand_tabs = True
    returns_source = True

    def get_quality_ratio(self, mimetype):
        if mimetype in Mimeview(self.env).treat_as_binary:
            return 0
        return 1

    def render(self, context, mimetype, content, filename=None, url=None):
        if is_binary(content):
            self.log.debug("Binary data; no preview available")
            return

        self.log.debug("Using default plain text mimeviewer")
        return content_to_unicode(self.env, content, mimetype)


class ImageRenderer(Component):
    """Inline image display.

    This component doesn't need the `content` at all.
    """
    implements(IHTMLPreviewRenderer)

    def get_quality_ratio(self, mimetype):
        if mimetype.startswith('image/'):
            return 8
        return 0

    def render(self, context, mimetype, content, filename=None, url=None):
        if url:
            return tag.div(tag.img(src=url, alt=filename),
                           class_='image-file')


class WikiTextRenderer(Component):
    """HTML renderer for files containing Trac's own Wiki formatting markup."""
    implements(IHTMLPreviewRenderer)

    def get_quality_ratio(self, mimetype):
        if mimetype in ('text/x-trac-wiki', 'application/x-trac-wiki'):
            return 8
        return 0

    def render(self, context, mimetype, content, filename=None, url=None):
        from trac.wiki.formatter import format_to_html
        return format_to_html(self.env, context,
                              content_to_unicode(self.env, content, mimetype))

########NEW FILE########
__FILENAME__ = patch
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>
#         Ludvig Strigeus

import os.path

from trac.core import *
from trac.mimeview.api import content_to_unicode, IHTMLPreviewRenderer, \
                              Mimeview
from trac.util.html import escape, Markup
from trac.util.text import expandtabs
from trac.util.translation import _
from trac.web.chrome import Chrome, add_script, add_stylesheet

__all__ = ['PatchRenderer']


class PatchRenderer(Component):
    """HTML renderer for patches in unified diff format.

    This uses the same layout as in the wiki diff view or the changeset view.
    """

    implements(IHTMLPreviewRenderer)

    # IHTMLPreviewRenderer methods

    def get_quality_ratio(self, mimetype):
        if mimetype in ('text/x-diff', 'text/x-patch'):
            return 8
        return 0

    def render(self, context, mimetype, content, filename=None, rev=None):
        req = context.req
        content = content_to_unicode(self.env, content, mimetype)
        changes = self._diff_to_hdf(content.splitlines(),
                                    Mimeview(self.env).tab_width)
        if not changes or not any(c['diffs'] for c in changes):
            self.log.warning('Invalid unified diff content')
            return
        data = {'diff': {'style': 'inline'}, 'no_id': True,
                'changes': changes, 'longcol': 'File', 'shortcol': ''}

        add_script(req, 'common/js/diff.js')
        add_stylesheet(req, 'common/css/diff.css')
        return Chrome(self.env).render_template(req, 'diff_div.html',
                                                data, fragment=True)

    # Internal methods

    # FIXME: This function should probably share more code with the
    #        trac.versioncontrol.diff module
    def _diff_to_hdf(self, difflines, tabwidth):
        """
        Translate a diff file into something suitable for inclusion in HDF.
        The result is [(filename, revname_old, revname_new, changes)],
        where changes has the same format as the result of
        `trac.versioncontrol.diff.hdf_diff`.

        If the diff cannot be parsed, this method returns None.
        """
        def _markup_intraline_change(fromlines, tolines):
            from trac.versioncontrol.diff import get_change_extent
            for i in xrange(len(fromlines)):
                fr, to = fromlines[i], tolines[i]
                (start, end) = get_change_extent(fr, to)
                if start != 0 or end != 0:
                    last = end+len(fr)
                    fromlines[i] = fr[:start] + '\0' + fr[start:last] + \
                                   '\1' + fr[last:]
                    last = end+len(to)
                    tolines[i] = to[:start] + '\0' + to[start:last] + \
                                 '\1' + to[last:]

        import re
        space_re = re.compile(' ( +)|^ ')
        def htmlify(match):
            div, mod = divmod(len(match.group(0)), 2)
            return div * '&nbsp; ' + mod * '&nbsp;'

        comments = []
        changes = []
        lines = iter(difflines)
        try:
            line = lines.next()
            while True:
                oldpath = oldrev = newpath = newrev = ''
                oldinfo = newinfo = []
                binary = False

                # consume preample, storing free lines in comments
                # (also detect the special case of git binary patches)
                if not line.startswith('--- '):
                    if not line.startswith('Index: ') and line != '=' * 67:
                        comments.append(line)
                    if line == "GIT binary patch":
                        binary = True
                        diffcmd_line = comments[0] # diff --git a/... b/,,,
                        oldpath, newpath = diffcmd_line.split()[-2:]
                        if any(c.startswith('new file') for c in comments):
                            oldpath = '/dev/null'
                        if any(c.startswith('deleted file') for c in comments):
                            newpath = '/dev/null'
                        oldinfo = ['', oldpath]
                        newinfo = ['', newpath]
                        index = [c for c in comments if c.startswith('index ')]
                        if index: # index 8f****78..1e****5c
                            oldrev, newrev = index[0].split()[-1].split('..')
                            oldinfo.append(oldrev)
                            newinfo.append(newrev)
                        line = lines.next()
                        while line:
                            comments.append(line)
                            line = lines.next()
                    else:
                        line = lines.next()
                        continue

                if not oldinfo and not newinfo:
                    # Base filename/version from '--- <file> [rev]'
                    oldinfo = line.split(None, 2)
                    if len(oldinfo) > 1:
                        oldpath = oldinfo[1]
                        if len(oldinfo) > 2:
                            oldrev = oldinfo[2]

                    # Changed filename/version from '+++ <file> [rev]'
                    line = lines.next()
                    if not line.startswith('+++ '):
                        self.log.debug('expected +++ after ---, got ' + line)
                        return None

                    newinfo = line.split(None, 2)
                    if len(newinfo) > 1:
                        newpath = newinfo[1]
                        if len(newinfo) > 2:
                            newrev = newinfo[2]

                shortrev = ('old', 'new')
                if oldpath or newpath:
                    sep = re.compile(r'([/.~\\])')
                    commonprefix = ''.join(os.path.commonprefix(
                        [sep.split(newpath), sep.split(oldpath)]))
                    commonsuffix = ''.join(os.path.commonprefix(
                        [sep.split(newpath)[::-1],
                         sep.split(oldpath)[::-1]])[::-1])
                    if len(commonprefix) > len(commonsuffix):
                        common = commonprefix
                    elif commonsuffix:
                        common = commonsuffix.lstrip('/')
                        a = oldpath[:-len(commonsuffix)]
                        b = newpath[:-len(commonsuffix)]
                        if len(a) < 4 and len(b) < 4:
                            shortrev = (a, b)
                    elif oldpath == '/dev/null':
                        common = _("new file %(new)s",
                                   new=newpath.lstrip('b/'))
                        shortrev = ('-', '+')
                    elif newpath == '/dev/null':
                        common = _("deleted file %(deleted)s",
                                   deleted=oldpath.lstrip('a/'))
                        shortrev = ('+', '-')
                    else:
                        common = '(a) %s vs. (b) %s' % (oldpath, newpath)
                        shortrev = ('a', 'b')
                else:
                    common = ''

                groups = []
                groups_title = []
                changes.append({'change': 'edit', 'props': [],
                                'comments': '\n'.join(comments),
                                'binary': binary,
                                'diffs': groups,
                                'diffs_title': groups_title,
                                'old': {'path': common,
                                        'rev': ' '.join(oldinfo[1:]),
                                        'shortrev': shortrev[0]},
                                'new': {'path': common,
                                        'rev': ' '.join(newinfo[1:]),
                                        'shortrev': shortrev[1]}})
                comments = []
                line = lines.next()
                while line:
                    # "@@ -333,10 +329,8 @@" or "@@ -1 +1 @@ [... title ...]"
                    r = re.match(r'@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@'
                                  '(.*)', line)
                    if not r:
                        break
                    blocks = []
                    groups.append(blocks)
                    fromline, fromend, toline, toend = \
                            [int(x or 1) for x in r.groups()[:4]]
                    groups_title.append(r.group(5))
                    last_type = extra = None

                    fromend += fromline
                    toend += toline
                    line = lines.next()
                    while fromline < fromend or toline < toend or extra:

                        # First character is the command
                        command = ' '
                        if line:
                            command, line = line[0], line[1:]
                        # Make a new block?
                        if (command == ' ') != last_type:
                            last_type = command == ' '
                            kind = 'unmod' if last_type else 'mod'
                            block = {'type': kind,
                                     'base': {'offset': fromline - 1,
                                              'lines': []},
                                     'changed': {'offset': toline - 1,
                                                 'lines': []}}
                            blocks.append(block)
                        else:
                            block = blocks[-1]
                        if command == ' ':
                            sides = ['base', 'changed']
                        elif command == '+':
                            last_side = 'changed'
                            sides = [last_side]
                        elif command == '-':
                            last_side = 'base'
                            sides = [last_side]
                        elif command == '\\' and last_side:
                            meta = block[last_side].setdefault('meta', {})
                            meta[len(block[last_side]['lines'])] = True
                            sides = [last_side]
                        elif command == '@': # ill-formed patch
                            groups_title[-1] = "%s (%s)" % (
                                groups_title[-1],
                                _("this hunk was shorter than expected"))
                            line = '@'+line
                            break
                        else:
                            self.log.debug('expected +, - or \\, got '+command)
                            return None
                        for side in sides:
                            if side == 'base':
                                fromline += 1
                            else:
                                toline += 1
                            block[side]['lines'].append(line)
                        line = lines.next()
                        extra = line and line[0] == '\\'
        except StopIteration:
            pass

        # Go through all groups/blocks and mark up intraline changes, and
        # convert to html
        for o in changes:
            for group in o['diffs']:
                for b in group:
                    base, changed = b['base'], b['changed']
                    f, t = base['lines'], changed['lines']
                    if b['type'] == 'mod':
                        if len(f) == 0:
                            b['type'] = 'add'
                        elif len(t) == 0:
                            b['type'] = 'rem'
                        elif len(f) == len(t):
                            _markup_intraline_change(f, t)
                    for i in xrange(len(f)):
                        line = expandtabs(f[i], tabwidth, '\0\1')
                        line = escape(line, quotes=False)
                        line = '<del>'.join([space_re.sub(htmlify, seg)
                                             for seg in line.split('\0')])
                        line = line.replace('\1', '</del>')
                        f[i] = Markup(line)
                        if 'meta' in base and i in base['meta']:
                            f[i] = Markup('<em>%s</em>') % f[i]
                    for i in xrange(len(t)):
                        line = expandtabs(t[i], tabwidth, '\0\1')
                        line = escape(line, quotes=False)
                        line = '<ins>'.join([space_re.sub(htmlify, seg)
                                             for seg in line.split('\0')])
                        line = line.replace('\1', '</ins>')
                        t[i] = Markup(line)
                        if 'meta' in changed and i in changed['meta']:
                            t[i] = Markup('<em>%s</em>') % t[i]
        return changes

########NEW FILE########
__FILENAME__ = pygments
# -*- coding: utf-8 -*-
#
# Copyright (C) 2006-2009 Edgewall Software
# Copyright (C) 2006 Matthew Good <matt@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# Author: Matthew Good <matt@matt-good.net>

from datetime import datetime
import os
from pkg_resources import resource_filename
import re

from trac.core import *
from trac.config import ListOption, Option
from trac.env import ISystemInfoProvider
from trac.mimeview.api import IHTMLPreviewRenderer, Mimeview
from trac.prefs import IPreferencePanelProvider
from trac.util import get_pkginfo
from trac.util.datefmt import http_date, localtz
from trac.util.translation import _
from trac.web.api import IRequestHandler, HTTPNotFound
from trac.web.chrome import add_notice, add_stylesheet

from genshi import QName, Stream
from genshi.core import Attrs, START, END, TEXT

# Kludge to workaround the lack of absolute imports in Python version prior to
# 2.5
pygments = __import__('pygments', {}, {}, ['lexers', 'styles', 'formatters'])
get_all_lexers = pygments.lexers.get_all_lexers
get_lexer_by_name = pygments.lexers.get_lexer_by_name
HtmlFormatter = pygments.formatters.html.HtmlFormatter
get_all_styles = pygments.styles.get_all_styles
get_style_by_name = pygments.styles.get_style_by_name

__all__ = ['PygmentsRenderer']


class PygmentsRenderer(Component):
    """HTML renderer for syntax highlighting based on Pygments."""

    implements(ISystemInfoProvider, IHTMLPreviewRenderer,
               IPreferencePanelProvider, IRequestHandler)

    default_style = Option('mimeviewer', 'pygments_default_style', 'trac',
        """The default style to use for Pygments syntax highlighting.""")

    pygments_modes = ListOption('mimeviewer', 'pygments_modes',
        '', doc=
        """List of additional MIME types known by Pygments.

        For each, a tuple `mimetype:mode:quality` has to be
        specified, where `mimetype` is the MIME type,
        `mode` is the corresponding Pygments mode to be used
        for the conversion and `quality` is the quality ratio
        associated to this conversion. That can also be used
        to override the default quality ratio used by the
        Pygments render.""")

    expand_tabs = True
    returns_source = True

    QUALITY_RATIO = 7

    EXAMPLE = """<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Hello, world!</title>
    <script>
      jQuery(document).ready(function($) {
        $("h1").fadeIn("slow");
      });
    </script>
  </head>
  <body>
    <h1>Hello, world!</h1>
  </body>
</html>"""

    def __init__(self):
        self._types = None

    # ISystemInfoProvider methods

    def get_system_info(self):
        version = get_pkginfo(pygments).get('version')
        # if installed from source, fallback to the hardcoded version info
        if not version and hasattr(pygments, '__version__'):
            version = pygments.__version__
        yield 'Pygments', version

    # IHTMLPreviewRenderer methods

    def get_extra_mimetypes(self):
        for lexname, aliases, _, mimetypes in get_all_lexers():
            name = aliases[0] if aliases else lexname
            for mimetype in mimetypes:
                yield mimetype, aliases

    def get_quality_ratio(self, mimetype):
        # Extend default MIME type to mode mappings with configured ones
        if self._types is None:
            self._init_types()
        try:
            return self._types[mimetype][1]
        except KeyError:
            return 0

    def render(self, context, mimetype, content, filename=None, rev=None):
        req = context.req
        if self._types is None:
            self._init_types()
        add_stylesheet(req, '/pygments/%s.css' %
                       req.session.get('pygments_style', self.default_style))
        try:
            if len(content) > 0:
                mimetype = mimetype.split(';', 1)[0]
                language = self._types[mimetype][0]
                return self._generate(language, content)
        except (KeyError, ValueError):
            raise Exception("No Pygments lexer found for mime-type '%s'."
                            % mimetype)

    # IPreferencePanelProvider methods

    def get_preference_panels(self, req):
        yield ('pygments', _('Syntax Highlighting'))

    def render_preference_panel(self, req, panel):
        styles = list(get_all_styles())

        if req.method == 'POST':
            style = req.args.get('style')
            if style and style in styles:
                req.session['pygments_style'] = style
                add_notice(req, _('Your preferences have been saved.'))
            req.redirect(req.href.prefs(panel or None))

        output = self._generate('html', self.EXAMPLE)
        return 'prefs_pygments.html', {
            'output': output,
            'selection': req.session.get('pygments_style', self.default_style),
            'styles': styles
        }

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/pygments/(\w+)\.css', req.path_info)
        if match:
            req.args['style'] = match.group(1)
            return True

    def process_request(self, req):
        style = req.args['style']
        try:
            style_cls = get_style_by_name(style)
        except ValueError, e:
            raise HTTPNotFound(e)

        parts = style_cls.__module__.split('.')
        filename = resource_filename('.'.join(parts[:-1]), parts[-1] + '.py')
        mtime = datetime.fromtimestamp(os.path.getmtime(filename), localtz)
        last_modified = http_date(mtime)
        if last_modified == req.get_header('If-Modified-Since'):
            req.send_response(304)
            req.end_headers()
            return

        formatter = HtmlFormatter(style=style_cls)
        content = u'\n\n'.join([
            formatter.get_style_defs('div.code pre'),
            formatter.get_style_defs('table.code td')
        ]).encode('utf-8')

        req.send_response(200)
        req.send_header('Content-Type', 'text/css; charset=utf-8')
        req.send_header('Last-Modified', last_modified)
        req.send_header('Content-Length', len(content))
        req.write(content)

    # Internal methods

    def _init_types(self):
        self._types = {}
        for lexname, aliases, _, mimetypes in get_all_lexers():
            name = aliases[0] if aliases else lexname
            for mimetype in mimetypes:
                self._types[mimetype] = (name, self.QUALITY_RATIO)

        # Pygments currently doesn't know application/javascript
        if 'application/javascript' not in self._types:
            js_entry = self._types.get('text/javascript')
            if js_entry:
                self._types['application/javascript'] = js_entry

        self._types.update(
            Mimeview(self.env).configured_modes_mapping('pygments')
        )

    def _generate(self, language, content):
        lexer = get_lexer_by_name(language, stripnl=False)
        return GenshiHtmlFormatter().generate(lexer.get_tokens(content))


class GenshiHtmlFormatter(HtmlFormatter):
    """A Pygments formatter subclass that generates a Python stream instead
    of writing markup as strings to an output file.
    """

    def _chunk(self, tokens):
        """Groups tokens with the same CSS class in the token stream
        and yields them one by one, along with the CSS class, with the
        values chunked together."""

        last_class = None
        text = []
        for ttype, value in tokens:
            c = self._get_css_class(ttype)
            if c == 'n':
                c = ''
            if c == last_class:
                text.append(value)
                continue

            # If no value, leave the old <span> open.
            if value:
                yield last_class, u''.join(text)
                text = [value]
                last_class = c

        if text:
            yield last_class, u''.join(text)

    def generate(self, tokens):
        pos = (None, -1, -1)
        span = QName('span')
        class_ = QName('class')

        def _generate():
            for c, text in self._chunk(tokens):
                if c:
                    attrs = Attrs([(class_, c)])
                    yield START, (span, attrs), pos
                    yield TEXT, text, pos
                    yield END, span, pos
                else:
                    yield TEXT, text, pos
        return Stream(_generate())

########NEW FILE########
__FILENAME__ = rst
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004 Oliver Rutherfurd
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin
#         Oliver Rutherfurd (initial implementation)
#         Nuutti Kotivuori (role support)
#
# Trac support for reStructured Text, including a custom 'trac' directive
#
# 'trac' directive code by Oliver Rutherfurd, overhauled by cboos.
#
# Inserts `reference` nodes for TracLinks into the document tree.

__docformat__ = 'reStructuredText'

from distutils.version import StrictVersion
try:
    from docutils import nodes
    from docutils.core import publish_parts
    from docutils.parsers import rst
    from docutils import __version__
    has_docutils = True
except ImportError:
    has_docutils = False

from genshi.core import escape

from trac.core import *
from trac.env import ISystemInfoProvider
from trac.mimeview.api import IHTMLPreviewRenderer, content_to_unicode
from trac.util.html import Element, Fragment, Markup, find_element
from trac.util.translation import _
from trac.wiki.api import WikiSystem
from trac.wiki.formatter import WikiProcessor, Formatter, extract_link

if has_docutils and StrictVersion(__version__) < StrictVersion('0.6'):
    # Monkey-patch "raw" role handler in docutils to add a missing check
    # See docutils bug #2845002 on SourceForge
    def raw_role(role, rawtext, text, lineno, inliner, options={}, content=[]):
        if not inliner.document.settings.raw_enabled:
            msg = inliner.reporter.warning('raw (and derived) roles disabled')
            prb = inliner.problematic(rawtext, rawtext, msg)
            return [prb], [msg]
        return _raw_role(role, rawtext, text, lineno, inliner, options,
                         content)

    from docutils.parsers.rst import roles
    raw_role.options = roles.raw_role.options
    _raw_role = roles.raw_role
    roles.raw_role = raw_role
    roles.register_canonical_role('raw', raw_role)

if has_docutils:
    # Register "trac" role handler and directive

    def trac_get_reference(env, context, rawtext, target, text):
        fulltext = target + ' ' + text if text else target
        link = extract_link(env, context, fulltext)
        uri = None
        missing = False
        if isinstance(link, (Element, Fragment)):
            linktext = Markup(link).striptags()
            # the following is a bit hackish, but it takes into account:
            #  - an eventual trailing '?' for missing wiki pages
            #  - space eventually introduced due to split_page_names option
            if linktext.rstrip('?').replace(' ', '') != target:
                text = linktext
            elt = find_element(link, 'href', 'missing')
            if elt is not None:
                uri = elt.attrib.get('href', '')
                missing = 'missing' in elt.attrib.get('class', '').split()
        else:
            uri = context.href.wiki(target)
            missing = not WikiSystem(env).has_page(target)
        if uri or missing:
            reference = nodes.reference(rawtext, text or target)
            reference['refuri'] = uri
            if missing:
                reference['classes'].append('missing')
            return reference

    def trac_directive(name, arguments, options, content, lineno,
                       content_offset, block_text, state, state_machine):
        """Inserts a `reference` node into the document for a given
        `TracLink`_, based on the content of the arguments.

        Usage::

          .. trac:: target [text]

        ``target`` may be any `TracLink`_, provided it doesn't
        embed a space character (e.g. wiki:"..." notation won't work).

        ``[text]`` is optional.  If not given, ``target`` is
        used as the reference text.

        .. _TracLink: http://trac.edgewall.org/wiki/TracLinks
        """
        if hasattr(state.inliner, 'trac'):
            env, context = state.inliner.trac
            link = arguments[0]
            if len(arguments) == 2:
                text = arguments[1]
            else:
                text = None
            reference = trac_get_reference(env, context, block_text, link, text)
            if reference:
                if isinstance(state, rst.states.SubstitutionDef):
                    return [reference]
                p = nodes.paragraph()
                p += reference
                return [p]
            # didn't find a match (invalid TracLink)
            msg = _("%(link)s is not a valid TracLink", link=arguments[0])
            # this is an user facing message, hence localized
        else:
            msg = "No trac context active while rendering"
            # this is more an internal error, not translated.
        # report a warning
        warning = state_machine.reporter.warning(
            msg, nodes.literal_block(block_text, block_text), line=lineno)
        return [warning]

    def trac_role(name, rawtext, text, lineno, inliner, options={},
                  content=[]):
        if hasattr(inliner, 'trac'):
            env, context = inliner.trac
            args  = text.split(" ", 1)
            link = args[0]
            if len(args) == 2:
                text = args[1]
            else:
                text = None
            reference = trac_get_reference(env, context, rawtext, link, text)
            if reference:
                return [reference], []
            msg = _("%(link)s is not a valid TracLink", link=rawtext)
        else:
            msg = "No trac context active while rendering"
        return nodes.warning(None, nodes.literal_block(text, msg)), []

    # 1 required arg, 1 optional arg, spaces allowed in last arg
    trac_directive.arguments = (1, 1, 1)
    trac_directive.options = None
    trac_directive.content = None
    rst.directives.register_directive('trac', trac_directive)
    rst.roles.register_canonical_role('trac', trac_role)

    # Register "code-block" role handler and directive
    # (code derived from the leo plugin rst2)

    def code_formatter(env, context, language, text):
        processor = WikiProcessor(Formatter(env, context), language)
        html = processor.process(text)
        raw = nodes.raw('', html, format='html')
        return raw

    def code_block_role(name, rawtext, text, lineno, inliner, options={},
                        content=[]):
        if not hasattr(inliner, 'trac'):
            return [], []
        env, context = inliner.trac
        language = options.get('language')
        if not language:
            args  = text.split(':', 1)
            language = args[0]
            if len(args) == 2:
                text = args[1]
            else:
                text = ''
        return [code_formatter(env, context, language, text)], []

    def code_block_directive(name, arguments, options, content, lineno,
                             content_offset, block_text, state, state_machine):
        """
        Create a code-block directive for docutils.

        Usage: .. code-block:: language

        If the language can be syntax highlighted it will be.
        """
        if not hasattr(state.inliner, 'trac'):
            return []
        env, context = state.inliner.trac
        language = arguments[0]
        text = '\n'.join(content)
        return [code_formatter(env, context, language, text)]

    # These are documented
    # at http://docutils.sourceforge.net/spec/howto/rst-directives.html.
    code_block_directive.arguments = (
        1, # Number of required arguments.
        0, # Number of optional arguments.
        0) # True if final argument may contain whitespace.

    # A mapping from option name to conversion function.
    code_block_role.options = code_block_directive.options = {
        'language' :
        rst.directives.unchanged # Return the text argument, unchanged
    }
    code_block_directive.content = 1 # True if content is allowed.
    # Register the directive with docutils.
    rst.directives.register_directive('code-block', code_block_directive)
    rst.roles.register_local_role('code-block', code_block_role)


class ReStructuredTextRenderer(Component):
    """HTML renderer for plain text in reStructuredText format."""
    implements(ISystemInfoProvider, IHTMLPreviewRenderer)

    can_render = False

    def __init__(self):
        if has_docutils:
            if StrictVersion(__version__) < StrictVersion('0.3.9'):
                self.log.warning('Docutils version >= %s required, '
                                 '%s found' % ('0.3.9', __version__))
            else:
                self.can_render = True

    # ISystemInfoProvider methods

    def get_system_info(self):
        if has_docutils:
            yield 'Docutils', __version__

    # IHTMLPreviewRenderer methods

    def get_quality_ratio(self, mimetype):
        if self.can_render and mimetype in ('text/x-rst',
                                            'text/prs.fallenstein.rst'):
            return 8
        return 0

    def render(self, context, mimetype, content, filename=None, rev=None):
        # Minimize visual impact of errors
        from docutils.writers import html4css1
        class TracHTMLTranslator(html4css1.HTMLTranslator):
            """Specialized translator with unobtrusive error reporting"""
            def visit_system_message(self, node):
                paragraph = node.children.pop(0)
                message = escape(paragraph.astext()) if paragraph else ''
                backrefs = node['backrefs']
                if backrefs:
                    span = ('<span class="system-message">%s</span>' %
                            (''.join('<a href="#%s" title="%s">?</a>' %
                                     (backref, message)
                                     for backref in backrefs)))
                else:
                    span = ('<span class="system-message" title="%s">?</span>' %
                            message)
                self.body.append(span)
            def depart_system_message(self, node):
                pass
        writer = html4css1.Writer()
        writer.translator_class = TracHTMLTranslator

        inliner = rst.states.Inliner()
        inliner.trac = (self.env, context)
        parser = rst.Parser(inliner=inliner)
        content = content_to_unicode(self.env, content, mimetype)
        parts = publish_parts(content, writer=writer, parser=parser,
                              settings_overrides={'halt_level': 6,
                                                  'warning_stream': False,
                                                  'file_insertion_enabled': 0,
                                                  'raw_enabled': 0,
                                                  'warning_stream': False})
        return parts['html_body']

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import doctest
import unittest
from StringIO import StringIO
import sys

from trac.core import *
from trac.test import EnvironmentStub
from trac.mimeview import api
from trac.mimeview.api import get_mimetype, IContentConverter, Mimeview, \
                              _group_lines
from genshi import Stream, Namespace
from genshi.core import Attrs, TEXT, START, END
from genshi.input import HTMLParser


class GetMimeTypeTestCase(unittest.TestCase):

    def test_from_suffix_using_MIME_MAP(self):
        self.assertEqual('text/plain', get_mimetype('README', None))
        self.assertEqual('text/plain', get_mimetype('README.txt', None))

    def test_from_suffix_using_mimetypes(self):
        accepted = ('image/png', 'image/x-png')
        self.assertTrue(get_mimetype('doc/trac_logo.png', None) in accepted)

    def test_from_content_using_CONTENT_RE(self):
        self.assertEqual('text/x-python',
                         get_mimetype('xxx', """
#!/usr/bin/python
# This is a python script
"""))
        self.assertEqual('text/x-python',
                         get_mimetype('xxx', """
#!/usr/bin/env python
# This is a python script
"""))
        self.assertEqual('text/x-ksh',
                         get_mimetype('xxx', """
#!/bin/ksh
# This is a shell script
"""))
        self.assertEqual('text/x-python',
                         get_mimetype('xxx', """
# -*- Python -*-
# This is a python script
"""))
        self.assertEqual('text/x-ruby',
                         get_mimetype('xxx', """
# -*- mode: ruby -*-
# This is a ruby script
"""))
        self.assertEqual('text/x-python',
                         get_mimetype('xxx', ' ' * 2000 + '# vim: ft=python'))

    def test_from_content_using_is_binary(self):
        self.assertEqual('application/octet-stream',
                         get_mimetype('xxx', "abc\0xyz"))


class MimeviewTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=False,
            enable=['%s.%s' % (self.__module__, c)
                    for c in ['Converter0', 'Converter1', 'Converter2']])

    def tearDown(self):
        pass

    def test_get_supported_conversions(self):
        class Converter0(Component):
            implements(IContentConverter)
            def get_supported_conversions(self):
                yield 'key0', 'Format 0', 'c0', 'text/x-sample', 'text/html', 8

        class Converter2(Component):
            implements(IContentConverter)
            def get_supported_conversions(self):
                yield 'key2', 'Format 2', 'c2', 'text/x-sample', 'text/html', 2

        class Converter1(Component):
            implements(IContentConverter)
            def get_supported_conversions(self):
                yield 'key1', 'Format 1', 'c1', 'text/x-sample', 'text/html', 4

        mimeview = Mimeview(self.env)
        conversions = mimeview.get_supported_conversions('text/x-sample')
        self.assertEqual(Converter0(self.env), conversions[0][-1])
        self.assertEqual(Converter1(self.env), conversions[1][-1])
        self.assertEqual(Converter2(self.env), conversions[2][-1])

class GroupLinesTestCase(unittest.TestCase):

    def test_empty_stream(self):
        # FIXME: this currently fails
        lines = list(_group_lines([]))
        self.assertEqual(len(lines), 0)

    def test_text_only_stream(self):
        input = [(TEXT, "test", (None, -1, -1))]
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), 1)
        self.assertTrue(isinstance(lines[0], Stream))
        self.assertEquals(lines[0].events, input)

    def test_text_only_stream2(self):
        input = [(TEXT, "test\n", (None, -1, -1))]
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), 1)
        self.assertTrue(isinstance(lines[0], Stream))
        self.assertEquals(lines[0].events, [(TEXT, "test", (None, -1, -1))])

    def test_simplespan(self):
        input = HTMLParser(StringIO(u"<span>test</span>"), encoding=None)
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), 1)
        self.assertTrue(isinstance(lines[0], Stream))
        for (a, b) in zip(lines[0], input):
            self.assertEqual(a, b)

    def test_empty_text_stream(self):
        """
        http://trac.edgewall.org/ticket/4336
        """
        input = [(TEXT, "", (None, -1, -1))]
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), 0)

    def test_newline_stream(self):
        input = [(TEXT, "\n", (None, -1, -1))]
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), 1)

    def test_newline_stream2(self):
        input = [(TEXT, "\n\n\n", (None, -1, -1))]
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), 3)

    def test_empty_text_in_span(self):
        """
        http://trac.edgewall.org/ticket/4336
        """
        ns = Namespace('http://www.w3.org/1999/xhtml')
        input = [(START, (ns.span, Attrs([])), (None, -1, -1)),
                 (TEXT, "", (None, -1, -1)),
                 (END, ns.span, (None, -1, -1)),
                ]
        lines = list(_group_lines(input))
        self.assertEqual(len(lines), 0)

    def test_newline(self):
        """
        If the text element does not end with a newline, it's not properly
        closed.
        """
        input = HTMLParser(StringIO(u'<span class="c">a\nb</span>'),
            encoding=None)
        expected = ['<span class="c">a</span>',
                    '<span class="c">b</span>',
                   ]
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), len(expected))
        for a, b in zip(lines, expected):
            self.assertEquals(a.render('html'), b)

    def test_newline2(self):
        """
        Same as test_newline above, but make sure it behaves properly wrt
        the trailing \\n, especially given it's inside an element.
        """
        input = HTMLParser(StringIO(u'<span class="c">a\nb\n</span>'),
            encoding=None)
        expected = ['<span class="c">a</span>',
                    '<span class="c">b</span>',
                   ]
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), len(expected))
        for a, b in zip(lines, expected):
            self.assertEquals(a.render('html'), b)

    def test_multinewline(self):
        """
        ditto.
        """
        input = HTMLParser(StringIO(u'<span class="c">\n\n\na</span>'),
            encoding=None)
        expected = ['<span class="c"></span>',
                    '<span class="c"></span>',
                    '<span class="c"></span>',
                    '<span class="c">a</span>',
                   ]
        lines = list(_group_lines(input))
        self.assertEquals(len(lines), len(expected))
        for a, b in zip(lines, expected):
            self.assertEquals(a.render('html'), b)


def suite():
    suite = unittest.TestSuite()
    suite.addTest(doctest.DocTestSuite(api))
    suite.addTest(unittest.makeSuite(GetMimeTypeTestCase, 'test'))
    suite.addTest(unittest.makeSuite(MimeviewTestCase, 'test'))
    suite.addTest(unittest.makeSuite(GroupLinesTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = patch
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os
import unittest

from genshi.core import Stream
from genshi.input import HTMLParser, XML

from trac.mimeview.api import Mimeview, RenderingContext
from trac.mimeview.patch import PatchRenderer
from trac.test import EnvironmentStub, Mock, MockPerm
from trac.web.chrome import Chrome, web_context
from trac.web.href import Href


class PatchRendererTestCase(unittest.TestCase):

    def setUp(self):
        env = EnvironmentStub(enable=[Chrome, PatchRenderer])
        req = Mock(base_path='', chrome={}, args={}, session={},
                   abs_href=Href('/'), href=Href('/'), locale='',
                   perm=MockPerm(), authname=None, tz=None)
        self.context = web_context(req)
        self.patch = Mimeview(env).renderers[0]
        patch_html = open(os.path.join(os.path.split(__file__)[0],
                                       'patch.html'))
        self.patch_html = Stream(list(HTMLParser(patch_html, encoding='utf-8')))

    def _expected(self, expected_id):
        return self.patch_html.select('//div[@id="%s"]/div' % expected_id)

    def _test(self, expected_id, result):
        expected = self._expected(expected_id).render(encoding='utf-8')
        result = XML(result.render(encoding='utf-8')).render(encoding='utf-8')
        expected, result = expected.splitlines(), result.splitlines()
        for exp, res in zip(expected, result):
            self.assertEquals(exp, res)
        self.assertEquals(len(expected), len(result))

    def test_simple(self):
        """
        Simple patch rendering
        """
        result = self.patch.render(self.context, None, """
--- README.orig 2006-10-27 14:42:04.062500000 +0200
+++ README      2006-10-27 14:42:28.125000000 +0200
@@ -1,5 +1,5 @@
 ----
-base
-base
-base
+be
+the base
+base modified
 .
""")
        self.assertTrue(result)
        self._test('simple', result)

    def test_no_newline_in_base(self):
        """
        Simple regression test for #4027 ("No newline at end of file")
        """
        result = self.patch.render(self.context, None, """
--- nonewline   2006-10-27 08:36:48.453125000 +0200
+++ newline     2006-10-27 08:36:57.187500000 +0200
@@ -1 +1 @@
-ONELINE
\ No newline at end of file
+ONELINE
""")
        self.assertTrue(result)
        self._test('no_newline_in_base', result)

    def test_no_newline_in_changed(self):
        """
        Another simple regression test for #4027 ("No newline at end of file")
        """
        result = self.patch.render(self.context, None, """
--- newline     2006-10-27 08:36:57.187500000 +0200
+++ nonewline   2006-10-27 08:36:48.453125000 +0200
@@ -1 +1 @@
-ONELINE
+ONELINE
\ No newline at end of file
""")
        self.assertTrue(result)
        self._test('no_newline_in_changed', result)
    def test_diff_to_hdf_expandtabs(self):
        """Regression test related to #4557"""
        changes = self.patch._diff_to_hdf(
            ['--- hello.c 1',
             '+++ hello.c 2',
             '@@ -1 +1 @@',
             '-aa\tb',
             '+aaxb'], 8)
        self.assertEquals('aa<del>&nbsp; &nbsp; &nbsp; </del>b',
                          str(changes[0]['diffs'][0][0]['base']['lines'][0]))
        self.assertEquals('aa<ins>x</ins>b',
                          str(changes[0]['diffs'][0][0]['changed']['lines'][0]))

    def test_diff_to_hdf_leading_ws(self):
        """Regression test related to #5795"""
        changes = self.patch._diff_to_hdf(
            ['--- hello.c 1',
             '+++ hello.c 2',
             '@@ -1 +1 @@',
             '-*a',
             '+ *a'], 8)
        self.assertEquals('<del></del>*a',
                          str(changes[0]['diffs'][0][0]['base']['lines'][0]))
        self.assertEquals('<ins>&nbsp;</ins>*a',
                          str(changes[0]['diffs'][0][0]['changed']['lines'][0]))

def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(PatchRendererTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = pygments
# -*- coding: utf-8 -*-
#
# Copyright (C) 2006-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os
import unittest

from genshi.core import Stream, TEXT
from genshi.input import HTMLParser

try:
    pygments = __import__('pygments', {}, {}, [])
    have_pygments = True
except ImportError:
    have_pygments = False

from trac.mimeview.api import Mimeview, RenderingContext
if have_pygments:
    from trac.mimeview.pygments import PygmentsRenderer
from trac.test import EnvironmentStub, Mock
from trac.web.chrome import Chrome, web_context
from trac.web.href import Href


class PygmentsRendererTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(enable=[Chrome, PygmentsRenderer])
        self.pygments = Mimeview(self.env).renderers[0]
        self.req = Mock(base_path='', chrome={}, args={},
                        abs_href=Href('/'), href=Href('/'),
                        session={}, perm=None, authname=None, tz=None)
        self.context = web_context(self.req)
        pygments_html = open(os.path.join(os.path.split(__file__)[0],
                                       'pygments.html'))
        self.pygments_html = Stream(list(HTMLParser(pygments_html, encoding='utf-8')))

    def _expected(self, expected_id):
        return self.pygments_html.select(
            '//div[@id="%s"]/*|//div[@id="%s"]/text())' %
            (expected_id, expected_id))

    def _test(self, expected_id, result):
        expected = str(self._expected(expected_id))
        result = str(result)
        #print "\nE: " + repr(expected)
        #print "\nR: " + repr(result)
        expected, result = expected.splitlines(), result.splitlines()
        for exp, res in zip(expected, result):
            self.assertEquals(exp, res)
        self.assertEquals(len(expected), len(result))

    def test_python_hello(self):
        """
        Simple Python highlighting with Pygments (direct)
        """
        result = self.pygments.render(self.context, 'text/x-python', """
def hello():
        return "Hello World!"
""")
        self.assertTrue(result)
        self._test('python_hello', result)

    def test_python_hello_mimeview(self):
        """
        Simple Python highlighting with Pygments (through Mimeview.render)
        """
        result = Mimeview(self.env).render(self.context, 'text/x-python', """
def hello():
        return "Hello World!"
""")
        self.assertTrue(result)
        self._test('python_hello_mimeview', result)

    def test_newline_content(self):
        """
        The behavior of Pygments changed post-Pygments 0.11.1, and now
        contains all four newlines.  In Pygments 0.11.1 and prior, it only
        has three since stripnl defaults to True.

        See http://trac.edgewall.org/ticket/7705.
        """
        from pkg_resources import parse_version, get_distribution

        result = self.pygments.render(self.context, 'text/x-python', '\n\n\n\n')
        self.assertTrue(result)
        t = "".join([r[1] for r in result if r[0] is TEXT])

        if parse_version(pygments.__version__) > parse_version('0.11.1') \
           or pygments.__version__ == '0.11.1' and 'dev' in \
           get_distribution('Pygments').version:
            self.assertEqual("\n\n\n\n", t)
        else:
            self.assertEqual("\n\n\n", t)

    def test_empty_content(self):
        """
        A '\n' token is generated for an empty file, so we have to bypass
        pygments when rendering empty files.
        """
        result = self.pygments.render(self.context, 'text/x-python', '')
        self.assertEqual(None, result)

    def test_extra_mimetypes(self):
        """
        The text/x-ini mimetype is normally not known by Trac, but
        Pygments supports it.
        """
        mimeview = Mimeview(self.env)
        self.assertEqual('text/x-ini; charset=utf-8',
                         mimeview.get_mimetype('file.ini'))
        self.assertEqual('text/x-ini; charset=utf-8',
                         mimeview.get_mimetype('file.cfg'))
        self.assertEqual('text/x-ini; charset=utf-8',
                         mimeview.get_mimetype('file.text/x-ini'))

def suite():
    suite = unittest.TestSuite()
    if have_pygments:
        suite.addTest(unittest.makeSuite(PygmentsRendererTestCase, 'test'))
    else:
        print 'SKIP: mimeview/tests/pygments (no pygments installed)'
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = txtl
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004 Daniel Lundin
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>

"""Trac support for Textile
See also: http://dealmeida.net/projects/textile/
"""

from trac.core import *
from trac.mimeview.api import IHTMLPreviewRenderer


class TextileRenderer(Component):
    """Renders plain text in Textile format as HTML."""
    implements(IHTMLPreviewRenderer)

    def get_quality_ratio(self, mimetype):
        if mimetype == 'text/x-textile':
            return 8
        return 0

    def render(self, context, mimetype, content, filename=None, rev=None):
        import textile
        return textile.textile(content.encode('utf-8'), encoding='utf-8')

########NEW FILE########
__FILENAME__ = notification
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Daniel Lundin <daniel@edgewall.com>
# Copyright (C) 2005-2006 Emmanuel Blot <emmanuel.blot@free.fr>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os
import re
import smtplib
from subprocess import Popen, PIPE
import time

from genshi.builder import tag

from trac import __version__
from trac.config import BoolOption, ExtensionOption, IntOption, Option
from trac.core import *
from trac.util.compat import close_fds
from trac.util.text import CRLF, fix_eol
from trac.util.translation import _, deactivate, reactivate

MAXHEADERLEN = 76
EMAIL_LOOKALIKE_PATTERN = (
        # the local part
        r"[a-zA-Z0-9.'+_-]+" '@'
        # the domain name part (RFC:1035)
        '(?:[a-zA-Z0-9_-]+\.)+' # labels (but also allow '_')
        '[a-zA-Z](?:[-a-zA-Z\d]*[a-zA-Z\d])?' # TLD
        )


class IEmailSender(Interface):
    """Extension point interface for components that allow sending e-mail."""

    def send(self, from_addr, recipients, message):
        """Send message to recipients."""


class NotificationSystem(Component):

    email_sender = ExtensionOption('notification', 'email_sender',
                                   IEmailSender, 'SmtpEmailSender',
        """Name of the component implementing `IEmailSender`.

        This component is used by the notification system to send emails.
        Trac currently provides `SmtpEmailSender` for connecting to an SMTP
        server, and `SendmailEmailSender` for running a `sendmail`-compatible
        executable. (''since 0.12'')""")

    smtp_enabled = BoolOption('notification', 'smtp_enabled', 'false',
        """Enable email notification.""")

    smtp_from = Option('notification', 'smtp_from', 'trac@localhost',
        """Sender address to use in notification emails.""")

    smtp_from_name = Option('notification', 'smtp_from_name', '',
        """Sender name to use in notification emails.""")

    smtp_from_author = BoolOption('notification', 'smtp_from_author', 'false',
        """Use the action author as the sender of notification emails.
           (''since 1.0'')""")

    smtp_replyto = Option('notification', 'smtp_replyto', 'trac@localhost',
        """Reply-To address to use in notification emails.""")

    smtp_always_cc = Option('notification', 'smtp_always_cc', '',
        """Email address(es) to always send notifications to,
           addresses can be seen by all recipients (Cc:).""")

    smtp_always_bcc = Option('notification', 'smtp_always_bcc', '',
        """Email address(es) to always send notifications to,
           addresses do not appear publicly (Bcc:). (''since 0.10'')""")

    smtp_default_domain = Option('notification', 'smtp_default_domain', '',
        """Default host/domain to append to address that do not specify
           one.""")

    ignore_domains = Option('notification', 'ignore_domains', '',
        """Comma-separated list of domains that should not be considered
           part of email addresses (for usernames with Kerberos domains).""")

    admit_domains = Option('notification', 'admit_domains', '',
        """Comma-separated list of domains that should be considered as
        valid for email addresses (such as localdomain).""")

    mime_encoding = Option('notification', 'mime_encoding', 'none',
        """Specifies the MIME encoding scheme for emails.

        Valid options are 'base64' for Base64 encoding, 'qp' for
        Quoted-Printable, and 'none' for no encoding, in which case mails will
        be sent as 7bit if the content is all ASCII, or 8bit otherwise.
        (''since 0.10'')""")

    use_public_cc = BoolOption('notification', 'use_public_cc', 'false',
        """Recipients can see email addresses of other CC'ed recipients.

        If this option is disabled (the default), recipients are put on BCC.
        (''since 0.10'')""")

    use_short_addr = BoolOption('notification', 'use_short_addr', 'false',
        """Permit email address without a host/domain (i.e. username only).

        The SMTP server should accept those addresses, and either append
        a FQDN or use local delivery. (''since 0.10'')""")

    smtp_subject_prefix = Option('notification', 'smtp_subject_prefix',
                                 '__default__',
        """Text to prepend to subject line of notification emails.

        If the setting is not defined, then the [$project_name] prefix.
        If no prefix is desired, then specifying an empty option
        will disable it. (''since 0.10.1'')""")

    def send_email(self, from_addr, recipients, message):
        """Send message to recipients via e-mail."""
        self.email_sender.send(from_addr, recipients, message)


class SmtpEmailSender(Component):
    """E-mail sender connecting to an SMTP server."""

    implements(IEmailSender)

    smtp_server = Option('notification', 'smtp_server', 'localhost',
        """SMTP server hostname to use for email notifications.""")

    smtp_port = IntOption('notification', 'smtp_port', 25,
        """SMTP server port to use for email notification.""")

    smtp_user = Option('notification', 'smtp_user', '',
        """Username for SMTP server. (''since 0.9'')""")

    smtp_password = Option('notification', 'smtp_password', '',
        """Password for SMTP server. (''since 0.9'')""")

    use_tls = BoolOption('notification', 'use_tls', 'false',
        """Use SSL/TLS to send notifications over SMTP. (''since 0.10'')""")

    def send(self, from_addr, recipients, message):
        # Ensure the message complies with RFC2822: use CRLF line endings
        message = fix_eol(message, CRLF)

        self.log.info("Sending notification through SMTP at %s:%d to %s"
                      % (self.smtp_server, self.smtp_port, recipients))
        server = smtplib.SMTP(self.smtp_server, self.smtp_port)
        # server.set_debuglevel(True)
        if self.use_tls:
            server.ehlo()
            if not server.esmtp_features.has_key('starttls'):
                raise TracError(_("TLS enabled but server does not support " \
                                  "TLS"))
            server.starttls()
            server.ehlo()
        if self.smtp_user:
            server.login(self.smtp_user.encode('utf-8'),
                         self.smtp_password.encode('utf-8'))
        start = time.time()
        server.sendmail(from_addr, recipients, message)
        t = time.time() - start
        if t > 5:
            self.log.warning('Slow mail submission (%.2f s), '
                             'check your mail setup' % t)
        if self.use_tls:
            # avoid false failure detection when the server closes
            # the SMTP connection with TLS enabled
            import socket
            try:
                server.quit()
            except socket.sslerror:
                pass
        else:
            server.quit()


class SendmailEmailSender(Component):
    """E-mail sender using a locally-installed sendmail program."""

    implements(IEmailSender)

    sendmail_path = Option('notification', 'sendmail_path', 'sendmail',
        """Path to the sendmail executable.

        The sendmail program must accept the `-i` and `-f` options.
         (''since 0.12'')""")

    def send(self, from_addr, recipients, message):
        # Use native line endings in message
        message = fix_eol(message, os.linesep)

        self.log.info("Sending notification through sendmail at %s to %s"
                      % (self.sendmail_path, recipients))
        cmdline = [self.sendmail_path, "-i", "-f", from_addr]
        cmdline.extend(recipients)
        self.log.debug("Sendmail command line: %s" % cmdline)
        child = Popen(cmdline, bufsize=-1, stdin=PIPE, stdout=PIPE,
                      stderr=PIPE, close_fds=close_fds)
        out, err = child.communicate(message)
        if child.returncode or err:
            raise Exception("Sendmail failed with (%s, %s), command: '%s'"
                            % (child.returncode, err.strip(), cmdline))


class Notify(object):
    """Generic notification class for Trac.

    Subclass this to implement different methods.
    """

    def __init__(self, env):
        self.env = env
        self.config = env.config

        from trac.web.chrome import Chrome
        self.template = Chrome(self.env).load_template(self.template_name,
                                                       method='text')
        # FIXME: actually, we would need a different
        #        PermissionCache for each recipient
        self.data = Chrome(self.env).populate_data(None, {'CRLF': CRLF})

    def notify(self, resid):
        (torcpts, ccrcpts) = self.get_recipients(resid)
        self.begin_send()
        self.send(torcpts, ccrcpts)
        self.finish_send()

    def get_recipients(self, resid):
        """Return a pair of list of subscribers to the resource 'resid'.

        First list represents the direct recipients (To:), second list
        represents the recipients in carbon copy (Cc:).
        """
        raise NotImplementedError

    def begin_send(self):
        """Prepare to send messages.

        Called before sending begins.
        """

    def send(self, torcpts, ccrcpts):
        """Send message to recipients."""
        raise NotImplementedError

    def finish_send(self):
        """Clean up after sending all messages.

        Called after sending all messages.
        """


class NotifyEmail(Notify):
    """Baseclass for notification by email."""

    from_email = 'trac+tickets@localhost'
    subject = ''
    template_name = None
    nodomaddr_re = re.compile(r'[\w\d_\.\-]+')
    addrsep_re = re.compile(r'[;\s,]+')

    def __init__(self, env):
        Notify.__init__(self, env)

        addrfmt = EMAIL_LOOKALIKE_PATTERN
        admit_domains = self.env.config.get('notification', 'admit_domains')
        if admit_domains:
            pos = addrfmt.find('@')
            domains = '|'.join([x.strip() for x in \
                                admit_domains.replace('.','\.').split(',')])
            addrfmt = r'%s@(?:(?:%s)|%s)' % (addrfmt[:pos], addrfmt[pos+1:],
                                              domains)
        self.shortaddr_re = re.compile(r'\s*(%s)\s*$' % addrfmt)
        self.longaddr_re = re.compile(r'^\s*(.*)\s+<\s*(%s)\s*>\s*$' % addrfmt)
        self._init_pref_encoding()
        domains = self.env.config.get('notification', 'ignore_domains', '')
        self._ignore_domains = [x.strip() for x in domains.lower().split(',')]
        # Get the name and email addresses of all known users
        self.name_map = {}
        self.email_map = {}
        for username, name, email in self.env.get_known_users():
            if name:
                self.name_map[username] = name
            if email:
                self.email_map[username] = email

    def _init_pref_encoding(self):
        from email.Charset import Charset, QP, BASE64, SHORTEST
        self._charset = Charset()
        self._charset.input_charset = 'utf-8'
        self._charset.output_charset = 'utf-8'
        self._charset.input_codec = 'utf-8'
        self._charset.output_codec = 'utf-8'
        pref = self.env.config.get('notification', 'mime_encoding').lower()
        if pref == 'base64':
            self._charset.header_encoding = BASE64
            self._charset.body_encoding = BASE64
        elif pref in ['qp', 'quoted-printable']:
            self._charset.header_encoding = QP
            self._charset.body_encoding = QP
        elif pref == 'none':
            self._charset.header_encoding = SHORTEST
            self._charset.body_encoding = None
        else:
            raise TracError(_('Invalid email encoding setting: %(pref)s',
                              pref=pref))

    def notify(self, resid, subject, author=None):
        self.subject = subject
        config = self.config['notification']
        if not config.getbool('smtp_enabled'):
            return
        from_email, from_name = '', ''
        if author and config.getbool('smtp_from_author'):
            from_email = self.get_smtp_address(author)
            if from_email:
                from_name = self.name_map.get(author, '')
                if not from_name:
                    mo = self.longaddr_re.search(author)
                    if mo:
                        from_name = mo.group(1)
        if not from_email:
            from_email = config.get('smtp_from')
            from_name = config.get('smtp_from_name') or self.env.project_name
        self.replyto_email = config.get('smtp_replyto')
        self.from_email = from_email or self.replyto_email
        self.from_name = from_name
        if not self.from_email and not self.replyto_email:
            raise TracError(tag(
                    tag.p(_('Unable to send email due to identity crisis.')),
                    tag.p(_('Neither %(from_)s nor %(reply_to)s are specified '
                            'in the configuration.',
                            from_=tag.b('notification.from'),
                            reply_to=tag.b('notification.reply_to')))),
                _('SMTP Notification Error'))

        Notify.notify(self, resid)

    def format_header(self, key, name, email=None):
        from email.Header import Header
        maxlength = MAXHEADERLEN-(len(key)+2)
        # Do not sent ridiculous short headers
        if maxlength < 10:
            raise TracError(_("Header length is too short"))
        try:
            tmp = name.encode('ascii')
            header = Header(tmp, 'ascii', maxlinelen=maxlength)
        except UnicodeEncodeError:
            header = Header(name, self._charset, maxlinelen=maxlength)
        if not email:
            return header
        else:
            return '"%s" <%s>' % (header, email)

    def add_headers(self, msg, headers):
        for h in headers:
            msg[h] = self.encode_header(h, headers[h])

    def get_smtp_address(self, address):
        if not address:
            return None

        def is_email(address):
            pos = address.find('@')
            if pos == -1:
                return False
            if address[pos+1:].lower() in self._ignore_domains:
                return False
            return True

        if address == 'anonymous':
            return None
        if address in self.email_map:
            address = self.email_map[address]
        elif not is_email(address) and NotifyEmail.nodomaddr_re.match(address):
            if self.config.getbool('notification', 'use_short_addr'):
                return address
            domain = self.config.get('notification', 'smtp_default_domain')
            if domain:
                address = "%s@%s" % (address, domain)
            else:
                self.env.log.info("Email address w/o domain: %s" % address)
                return None

        mo = self.shortaddr_re.search(address)
        if mo:
            return mo.group(1)
        mo = self.longaddr_re.search(address)
        if mo:
            return mo.group(2)
        self.env.log.info("Invalid email address: %s" % address)
        return None

    def encode_header(self, key, value):
        if isinstance(value, tuple):
            return self.format_header(key, value[0], value[1])
        mo = self.longaddr_re.match(value)
        if mo:
            return self.format_header(key, mo.group(1), mo.group(2))
        return self.format_header(key, value)

    def send(self, torcpts, ccrcpts, mime_headers={}):
        from email.MIMEText import MIMEText
        from email.Utils import formatdate
        stream = self.template.generate(**self.data)
        # don't translate the e-mail stream
        t = deactivate()
        try:
            body = stream.render('text', encoding='utf-8')
        finally:
            reactivate(t)
        public_cc = self.config.getbool('notification', 'use_public_cc')
        headers = {}
        headers['X-Mailer'] = 'Trac %s, by Edgewall Software' % __version__
        headers['X-Trac-Version'] =  __version__
        headers['X-Trac-Project'] =  self.env.project_name
        headers['X-URL'] = self.env.project_url
        headers['Precedence'] = 'bulk'
        headers['Auto-Submitted'] = 'auto-generated'
        headers['Subject'] = self.subject
        headers['From'] = (self.from_name, self.from_email) if self.from_name \
                          else self.from_email
        headers['Reply-To'] = self.replyto_email

        def build_addresses(rcpts):
            """Format and remove invalid addresses"""
            return filter(lambda x: x, \
                          [self.get_smtp_address(addr) for addr in rcpts])

        def remove_dup(rcpts, all):
            """Remove duplicates"""
            tmp = []
            for rcpt in rcpts:
                if not rcpt in all:
                    tmp.append(rcpt)
                    all.append(rcpt)
            return (tmp, all)

        toaddrs = build_addresses(torcpts)
        ccaddrs = build_addresses(ccrcpts)
        accparam = self.config.get('notification', 'smtp_always_cc')
        accaddrs = accparam and \
                   build_addresses(accparam.replace(',', ' ').split()) or []
        bccparam = self.config.get('notification', 'smtp_always_bcc')
        bccaddrs = bccparam and \
                   build_addresses(bccparam.replace(',', ' ').split()) or []

        recipients = []
        (toaddrs, recipients) = remove_dup(toaddrs, recipients)
        (ccaddrs, recipients) = remove_dup(ccaddrs, recipients)
        (accaddrs, recipients) = remove_dup(accaddrs, recipients)
        (bccaddrs, recipients) = remove_dup(bccaddrs, recipients)

        # if there is not valid recipient, leave immediately
        if len(recipients) < 1:
            self.env.log.info('no recipient for a ticket notification')
            return

        pcc = accaddrs
        if public_cc:
            pcc += ccaddrs
            if toaddrs:
                headers['To'] = ', '.join(toaddrs)
        if pcc:
            headers['Cc'] = ', '.join(pcc)
        headers['Date'] = formatdate()
        msg = MIMEText(body, 'plain')
        # Message class computes the wrong type from MIMEText constructor,
        # which does not take a Charset object as initializer. Reset the
        # encoding type to force a new, valid evaluation
        del msg['Content-Transfer-Encoding']
        msg.set_charset(self._charset)
        self.add_headers(msg, headers)
        self.add_headers(msg, mime_headers)
        NotificationSystem(self.env).send_email(self.from_email, recipients,
                                                msg.as_string())

########NEW FILE########
__FILENAME__ = perm
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2004 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import csv
import os
from time import time

from trac.admin import AdminCommandError, IAdminCommandProvider, get_dir_list
from trac.cache import cached
from trac.config import ExtensionOption, OrderedExtensionsOption
from trac.core import *
from trac.resource import get_resource_name, manager_for_neighborhood, \
                          Neighborhood, Resource
from trac.util import file_or_std
from trac.util.text import path_to_unicode, print_table, printout, \
                           stream_encoding, to_unicode, wrap
from trac.util.translation import _

__all__ = ['IPermissionRequestor', 'IPermissionStore', 'IPermissionPolicy',
           'IPermissionGroupProvider', 'PermissionError', 'PermissionSystem']


class PermissionError(StandardError):
    """Insufficient permissions to complete the operation"""

    def __init__ (self, action=None, resource=None, env=None, msg=None):
        StandardError.__init__(self)
        self.action = action
        self.resource = resource
        self.env = env
        self.msg = msg

    def __unicode__ (self):
        if self.action:
            if self.resource:
                return _('%(perm)s privileges are required to perform '
                         'this operation on %(resource)s. You don\'t have the '
                         'required permissions.',
                         perm=self.action,
                         resource=get_resource_name(self.env, self.resource))
            else:
                return _('%(perm)s privileges are required to perform this '
                         'operation. You don\'t have the required '
                         'permissions.', perm=self.action)
        elif self.msg:
            return self.msg
        else:
            return _('Insufficient privileges to perform this operation.')


class IPermissionRequestor(Interface):
    """Extension point interface for components that define actions."""

    def get_permission_actions():
        """Return a list of actions defined by this component.

        The items in the list may either be simple strings, or
        `(string, sequence)` tuples. The latter are considered to be "meta
        permissions" that group several simple actions under one name for
        convenience, adding to it if another component already defined that
        name.
        """


class IPermissionStore(Interface):
    """Extension point interface for components that provide storage and
    management of permissions."""

    def get_user_permissions(username):
        """Return all permissions for the user with the specified name.

        The permissions are returned as a dictionary where the key is the name
        of the permission, and the value is either `True` for granted
        permissions or `False` for explicitly denied permissions."""

    def get_users_with_permissions(permissions):
        """Retrieve a list of users that have any of the specified permissions.

        Users are returned as a list of usernames.
        """

    def get_all_permissions():
        """Return all permissions for all users.

        The permissions are returned as a list of (subject, action)
        formatted tuples."""

    def grant_permission(username, action):
        """Grant a user permission to perform an action."""

    def revoke_permission(username, action):
        """Revokes the permission of the given user to perform an action."""


class IPermissionGroupProvider(Interface):
    """Extension point interface for components that provide information about
    user groups.
    """

    def get_permission_groups(username):
        """Return a list of names of the groups that the user with the specified
        name is a member of."""


class IPermissionPolicy(Interface):
    """A security policy provider used for fine grained permission checks."""

    def check_permission(action, username, resource, perm):
        """Check that the action can be performed by username on the resource

        :param action: the name of the permission
        :param username: the username string or 'anonymous' if there's no
                         authenticated user
        :param resource: the resource on which the check applies.
                         Will be `None`, if the check is a global one and
                         not made on a resource in particular
        :param perm: the permission cache for that username and resource,
                     which can be used for doing secondary checks on other
                     permissions. Care must be taken to avoid recursion.

        :return: `True` if action is allowed, `False` if action is denied,
                 or `None` if indifferent. If `None` is returned, the next
                 policy in the chain will be used, and so on.

        Note that when checking a permission on a realm resource (i.e. when
        `.id` is `None`), this usually corresponds to some preliminary check
        done before making a fine-grained check on some resource.
        Therefore the `IPermissionPolicy` should be conservative and return:

         * `True` if the action *can* be allowed for some resources in
           that realm. Later, for specific resource, the policy will be able
           to return `True` (allow), `False` (deny) or `None` (don't decide).
         * `None` if the action *can not* be performed for *some* resources.
           This corresponds to situation where the policy is only interested
           in returning `False` or `None` on specific resources.
         * `False` if the action *can not* be performed for *any* resource in
           that realm (that's a very strong decision as that will usually
           prevent any fine-grained check to even happen).

        Note that performing permission checks on realm resources may seem
        redundant for now as the action name itself contains the realm, but
        this will probably change in the future (e.g. `'VIEW' in ...`).
        """


class DefaultPermissionStore(Component):
    """Default implementation of permission storage and group management.

    This component uses the `permission` table in the database to store both
    permissions and groups.
    """
    implements(IPermissionStore)

    group_providers = ExtensionPoint(IPermissionGroupProvider)

    def get_user_permissions(self, username):
        """Retrieve the permissions for the given user and return them in a
        dictionary.

        The permissions are stored in the database as (username, action)
        records. There's simple support for groups by using lowercase names for
        the action column: such a record represents a group and not an actual
        permission, and declares that the user is part of that group.
        """
        subjects = set([username])
        for provider in self.group_providers:
            subjects.update(provider.get_permission_groups(username) or [])

        actions = set()
        perms = self._all_permissions
        while True:
            num_users = len(subjects)
            num_actions = len(actions)
            for user, action in perms:
                if user in subjects:
                    if action.isupper() and action not in actions:
                        actions.add(action)
                    if not action.isupper() and action not in subjects:
                        # action is actually the name of the permission
                        # group here
                        subjects.add(action)
            if num_users == len(subjects) and num_actions == len(actions):
                break
        return list(actions)

    def get_users_with_permissions(self, permissions):
        """Retrieve a list of users that have any of the specified permissions

        Users are returned as a list of usernames.
        """
        # get_user_permissions() takes care of the magic 'authenticated' group.
        # The optimized loop we had before didn't.  This is very inefficient,
        # but it works.
        result = set()
        users = set([u[0] for u in self.env.get_known_users()])
        for user in users:
            userperms = self.get_user_permissions(user)
            for group in permissions:
                if group in userperms:
                    result.add(user)
        return list(result)

    def get_all_permissions(self):
        """Return all permissions for all users.

        The permissions are returned as a list of (subject, action)
        formatted tuples."""
        return self._all_permissions


    @cached
    def _all_permissions(self):
        return [(username, action) for username, action in
                self.env.db_query("SELECT username, action FROM permission")]

    def grant_permission(self, username, action):
        """Grants a user the permission to perform the specified action."""
        self.env.db_transaction("INSERT INTO permission VALUES (%s, %s)",
                                (username, action))
        self.log.info("Granted permission for %s to %s", action, username)

        # Invalidate cached property
        del self._all_permissions

    def revoke_permission(self, username, action):
        """Revokes a users' permission to perform the specified action."""
        self.env.db_transaction(
                "DELETE FROM permission WHERE username=%s AND action=%s",
                (username, action))
        self.log.info("Revoked permission for %s to %s", action, username)

        # Invalidate cached property
        del self._all_permissions


class DefaultPermissionGroupProvider(Component):
    """Permission group provider providing the basic builtin permission groups
    'anonymous' and 'authenticated'."""

    required = True

    implements(IPermissionGroupProvider)

    def get_permission_groups(self, username):
        groups = ['anonymous']
        if username and username != 'anonymous':
            groups.append('authenticated')
        return groups


class DefaultPermissionPolicy(Component):
    """Default permission policy using the IPermissionStore system."""

    implements(IPermissionPolicy)

    # Number of seconds a cached user permission set is valid for.
    CACHE_EXPIRY = 5
    # How frequently to clear the entire permission cache
    CACHE_REAP_TIME = 60

    def __init__(self):
        self.permission_cache = {}
        self.last_reap = time()

    # IPermissionPolicy methods

    def check_permission(self, action, username, resource, perm):
        # TODO: Precondition resource.neighborhood is None
        now = time()

        if now - self.last_reap > self.CACHE_REAP_TIME:
            self.permission_cache = {}
            self.last_reap = time()

        timestamp, permissions = self.permission_cache.get(username, (0, None))

        # Cache hit?
        if now - timestamp > self.CACHE_EXPIRY:
            # No, pull permissions from database.
            permissions = PermissionSystem(self.env). \
                          get_user_permissions(username)
            self.permission_cache[username] = (now, permissions)

        return action in permissions or None



class PermissionSystem(Component):
    """Permission management sub-system."""

    required = True

    implements(IPermissionRequestor)

    requestors = ExtensionPoint(IPermissionRequestor)

    store = ExtensionOption('trac', 'permission_store', IPermissionStore,
                            'DefaultPermissionStore',
        """Name of the component implementing `IPermissionStore`, which is used
        for managing user and group permissions.""")

    policies = OrderedExtensionsOption('trac', 'permission_policies',
        IPermissionPolicy,
        'DefaultPermissionPolicy, LegacyAttachmentPolicy',
        False,
        """List of components implementing `IPermissionPolicy`, in the order in
        which they will be applied. These components manage fine-grained access
        control to Trac resources.
        Defaults to the DefaultPermissionPolicy (pre-0.11 behavior) and
        LegacyAttachmentPolicy (map ATTACHMENT_* permissions to realm specific
        ones)""")

    # Number of seconds a cached user permission set is valid for.
    CACHE_EXPIRY = 5
    # How frequently to clear the entire permission cache
    CACHE_REAP_TIME = 60

    def __init__(self):
        self.permission_cache = {}
        self.last_reap = time()

    # Public API

    def grant_permission(self, username, action):
        """Grant the user with the given name permission to perform to specified
        action."""
        if action.isupper() and action not in self.get_actions():
            raise TracError(_('%(name)s is not a valid action.', name=action))

        self.store.grant_permission(username, action)

    def revoke_permission(self, username, action):
        """Revokes the permission of the specified user to perform an action."""
        self.store.revoke_permission(username, action)

    def get_actions_dict(self):
        """Get all actions from permission requestors as a `dict`.

        The keys are the action names. The values are the additional actions
        granted by each action. For simple actions, this is an empty list.
        For meta actions, this is the list of actions covered by the action.
        """
        actions = {}
        for requestor in self.requestors:
            for action in requestor.get_permission_actions() or []:
                if isinstance(action, tuple):
                    actions.setdefault(action[0], []).extend(action[1])
                else:
                    actions.setdefault(action, [])
        return actions

    def get_actions(self, skip=None):
        """Get a list of all actions defined by permission requestors."""
        actions = set()
        for requestor in self.requestors:
            if requestor is skip:
                continue
            for action in requestor.get_permission_actions() or []:
                if isinstance(action, tuple):
                    actions.add(action[0])
                else:
                    actions.add(action)
        return list(actions)

    def get_user_permissions(self, username=None):
        """Return the permissions of the specified user.

        The return value is a dictionary containing all the actions granted to
        the user mapped to `True`. If an action is missing as a key, or has
        `False` as a value, permission is denied."""
        if not username:
            # Return all permissions available in the system
            return dict.fromkeys(self.get_actions(), True)

        # Return all permissions that the given user has
        actions = self.get_actions_dict()
        permissions = {}
        def expand_meta(action):
            if action not in permissions:
                permissions[action] = True
                for a in actions.get(action, ()):
                    expand_meta(a)
        for perm in self.store.get_user_permissions(username) or []:
            expand_meta(perm)
        return permissions

    def get_all_permissions(self):
        """Return all permissions for all users.

        The permissions are returned as a list of (subject, action)
        formatted tuples."""
        return self.store.get_all_permissions() or []

    def get_users_with_permission(self, permission):
        """Return all users that have the specified permission.

        Users are returned as a list of user names.
        """
        now = time()
        if now - self.last_reap > self.CACHE_REAP_TIME:
            self.permission_cache = {}
            self.last_reap = now
        timestamp, permissions = self.permission_cache.get(permission,
                                                           (0, None))
        if now - timestamp <= self.CACHE_EXPIRY:
            return permissions

        parent_map = {}
        for parent, children in self.get_actions_dict().iteritems():
            for child in children:
                parent_map.setdefault(child, set()).add(parent)

        satisfying_perms = set()
        def append_with_parents(action):
            if action not in satisfying_perms:
                satisfying_perms.add(action)
                for action in parent_map.get(action, ()):
                    append_with_parents(action)
        append_with_parents(permission)

        perms = self.store.get_users_with_permissions(satisfying_perms) or []
        self.permission_cache[permission] = (now, perms)
        return perms

    def expand_actions(self, actions):
        """Helper method for expanding all meta actions."""
        all_actions = self.get_actions_dict()
        expanded_actions = set()
        def expand_action(action):
            if action not in expanded_actions:
                expanded_actions.add(action)
                for a in all_actions.get(action, ()):
                    expand_action(a)
        for a in actions:
            expand_action(a)
        return expanded_actions

    def check_permission(self, action, username=None, resource=None, perm=None):
        """Return True if permission to perform action for the given resource
        is allowed."""
        if username is None:
            username = 'anonymous'
        if resource:
            if resource.realm is None:
                resource = None
            elif resource.neighborhood is not None:
                try:
                    compmgr = manager_for_neighborhood(self.env, 
                                                       resource.neighborhood)
                except ResourceNotFound:
                    #FIXME: raise ?
                    return False
                else:
                    return PermissionSystem(compmgr).check_permission(
                            action, username, resource, perm)
        for policy in self.policies:
            decision = policy.check_permission(action, username, resource,
                                               perm)
            if decision is not None:
                if not decision:
                    self.log.debug("%s denies %s performing %s on %r",
                                   policy.__class__.__name__, username,
                                   action, resource)
                return decision
        self.log.debug("No policy allowed %s performing %s on %r",
                       username, action, resource)
        return False

    # IPermissionRequestor methods

    def get_permission_actions(self):
        """Implement the global `TRAC_ADMIN` meta permission.

        Implements also the `EMAIL_VIEW` permission which allows for
        showing email addresses even if `[trac] show_email_addresses`
        is `false`.
        """
        actions = self.get_actions(skip=self)
        actions.append('EMAIL_VIEW')
        return [('TRAC_ADMIN', actions), 'EMAIL_VIEW']


class PermissionCache(object):
    """Cache that maintains the permissions of a single user.

    Permissions are usually checked using the following syntax:

        'WIKI_MODIFY' in perm

    One can also apply more fine grained permission checks and
    specify a specific resource for which the permission should be available:

        'WIKI_MODIFY' in perm('wiki', 'WikiStart')

    If there's already a `page` object available, the check is simply:

        'WIKI_MODIFY' in perm(page.resource)

    If instead of a check, one wants to assert that a given permission is
    available, the following form should be used:

        perm.require('WIKI_MODIFY')

        or

        perm('wiki', 'WikiStart').require('WIKI_MODIFY')

        or

        perm(page.resource).require('WIKI_MODIFY')

    When using `require`,  a `PermissionError` exception is raised if the
    permission is missing.
    """

    __slots__ = ('env', 'username', '_resource', '_cache')

    def __init__(self, env, username=None, resource=None, cache=None,
                 groups=None):
        if resource and resource.neighborhood is not None:
            env = manager_for_neighborhood(env, resource.neighborhood)
            resource = Neighborhood(None, None).child(resource)
        self.env = env
        self.username = username or 'anonymous'
        self._resource = resource
        if cache is None:
            cache = {}
        self._cache = cache

    def _normalize_resource(self, realm_or_resource, id, version):
        if realm_or_resource:
            return Resource(realm_or_resource, id, version)
        else:
            return self._resource

    def __call__(self, realm_or_resource, id=False, version=False):
        """Convenience function for using thus:
            'WIKI_VIEW' in perm(context)
        or
            'WIKI_VIEW' in perm(realm, id, version)
        or
            'WIKI_VIEW' in perm(resource)

        """
        resource = Resource(realm_or_resource, id, version)
        if resource and self._resource and resource == self._resource:
            return self
        else:
            return PermissionCache(self.env, self.username, resource,
                                   self._cache)

    def has_permission(self, action, realm_or_resource=None, id=False,
                       version=False):
        resource = self._normalize_resource(realm_or_resource, id, version)
        return self._has_permission(action, resource)

    def _has_permission(self, action, resource):
        key = (self.username, hash(resource), action)
        cached = self._cache.get(key)
        if cached:
            cache_decision, cache_resource = cached
            if resource == cache_resource:
                return cache_decision
        perm = self
        permsys = PermissionSystem(self.env)
        if resource is not self._resource:
            if resource.neighborhood is not None:
                perm = PermissionCache(self.env, self.username, resource, {})
                permsys = PermissionSystem(manager_for_neighborhood(
                        self.env, resource.neighborhood))
            else:
                perm = PermissionCache(self.env, self.username, resource,
                                       self._cache)
        decision = permsys.check_permission(action, perm.username, resource,
                                            perm)
        self._cache[key] = (decision, resource)
        return decision

    __contains__ = has_permission

    def require(self, action, realm_or_resource=None, id=False, version=False):
        resource = self._normalize_resource(realm_or_resource, id, version)
        if not self._has_permission(action, resource):
            raise PermissionError(action, resource, self.env)
    assert_permission = require

    def permissions(self):
        """Deprecated (but still used by the HDF compatibility layer)"""
        self.env.log.warning("perm.permissions() is deprecated and "
                             "is only present for HDF compatibility")
        perm = PermissionSystem(self.env)
        actions = perm.get_user_permissions(self.username)
        return [action for action in actions if action in self]


class PermissionAdmin(Component):
    """trac-admin command provider for permission system administration."""

    implements(IAdminCommandProvider)

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('permission list', '[user]',
               'List permission rules',
               self._complete_list, self._do_list)
        yield ('permission add', '<user> <action> [action] [...]',
               'Add a new permission rule',
               self._complete_add, self._do_add)
        yield ('permission remove', '<user> <action> [action] [...]',
               'Remove a permission rule',
               self._complete_remove, self._do_remove)
        yield ('permission export', '[file]',
               'Export permission rules to a file or stdout as CSV',
               self._complete_import_export, self._do_export)
        yield ('permission import', '[file]',
               'Import permission rules from a file or stdin as CSV',
               self._complete_import_export, self._do_import)

    def get_user_list(self):
        return set(user for (user, action) in
                   PermissionSystem(self.env).get_all_permissions())

    def get_user_perms(self, user):
        return [action for (subject, action) in
                PermissionSystem(self.env).get_all_permissions()
                if subject == user]

    def _complete_list(self, args):
        if len(args) == 1:
            return self.get_user_list()

    def _complete_add(self, args):
        if len(args) == 1:
            return self.get_user_list()
        elif len(args) >= 2:
            return (set(PermissionSystem(self.env).get_actions())
                    - set(self.get_user_perms(args[0])) - set(args[1:-1]))

    def _complete_remove(self, args):
        if len(args) == 1:
            return self.get_user_list()
        elif len(args) >= 2:
            return set(self.get_user_perms(args[0])) - set(args[1:-1])

    def _complete_import_export(self, args):
        if len(args) == 1:
            return get_dir_list(args[-1])

    def _do_list(self, user=None):
        permsys = PermissionSystem(self.env)
        if user:
            rows = []
            perms = permsys.get_user_permissions(user)
            for action in perms:
                if perms[action]:
                    rows.append((user, action))
        else:
            rows = permsys.get_all_permissions()
        rows.sort()
        print_table(rows, [_('User'), _('Action')])
        print
        printout(_("Available actions:"))
        actions = permsys.get_actions()
        actions.sort()
        text = ', '.join(actions)
        printout(wrap(text, initial_indent=' ', subsequent_indent=' ',
                      linesep='\n'))
        print

    def _do_add(self, user, *actions):
        permsys = PermissionSystem(self.env)
        if user.isupper():
            raise AdminCommandError(_('All upper-cased tokens are reserved '
                                      'for permission names'))
        for action in actions:
            try:
                permsys.grant_permission(user, action)
            except self.env.db_exc.IntegrityError:
                printout(_("The user %(user)s already has permission "
                           "%(action)s.", user=user, action=action))

    def _do_remove(self, user, *actions):
        permsys = PermissionSystem(self.env)
        rows = permsys.get_all_permissions()
        for action in actions:
            found = False
            for u, a in rows:
                if user in (u, '*') and action in (a, '*'):
                    permsys.revoke_permission(u, a)
                    found = True
            if not found:
                raise AdminCommandError(
                    _("Cannot remove permission %(action)s for user %(user)s.",
                      action=action, user=user))

    def _do_export(self, filename=None):
        try:
            with file_or_std(filename, 'wb') as f:
                encoding = stream_encoding(f)
                linesep = os.linesep if filename else '\n'
                writer = csv.writer(f, lineterminator=linesep)
                users = self.get_user_list()
                for user in sorted(users):
                    actions = sorted(self.get_user_perms(user))
                    writer.writerow([s.encode(encoding, 'replace')
                                     for s in [user] + actions])
        except IOError, e:
            raise AdminCommandError(
                _("Cannot export to %(filename)s: %(error)s",
                  filename=path_to_unicode(filename or 'stdout'),
                  error=e.strerror))

    def _do_import(self, filename=None):
        permsys = PermissionSystem(self.env)
        try:
            with file_or_std(filename, 'rb') as f:
                encoding = stream_encoding(f)
                linesep = os.linesep if filename else '\n'
                reader = csv.reader(f, lineterminator=linesep)
                for row in reader:
                    if len(row) < 2:
                        raise AdminCommandError(
                            _("Invalid row %(line)d. Expected <user>, "
                              "<action>, [action], [...]",
                              line=reader.line_num))
                    user = to_unicode(row[0], encoding)
                    actions = [to_unicode(action, encoding)
                               for action in row[1:]]
                    if user.isupper():
                        raise AdminCommandError(
                            _("Invalid user %(user)s on line %(line)d: All "
                              "upper-cased tokens are reserved for permission "
                              "names.", user=user, line=reader.line_num))
                    old_actions = self.get_user_perms(user)
                    for action in set(actions) - set(old_actions):
                        permsys.grant_permission(user, action)
        except csv.Error, e:
            raise AdminCommandError(
                _("Cannot import from %(filename)s line %(line)d: %(error)s ",
                  filename=path_to_unicode(filename or 'stdin'),
                  line=reader.line_num, error=e))
        except IOError, e:
            raise AdminCommandError(
                _("Cannot import from %(filename)s: %(error)s",
                  filename=path_to_unicode(filename or 'stdin'),
                  error=e.strerror))

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from trac.core import *


class IPreferencePanelProvider(Interface):

    def get_preference_panels(req):
        """Return a list of available preference panels.

        The items returned by this function must be tuple of the form
        `(panel, label)`.
        """

    def render_preference_panel(req, panel):
        """Process a request for a preference panel.

        This function should return a tuple of the form `(template, data)`,
        where `template` is the name of the template to use and `data` is the
        data to be passed to the template.
        """

########NEW FILE########
__FILENAME__ = functional
#!/usr/bin/python
from trac.tests.functional import *


#TODO: split this into multiple smaller testcases
class TestPreferences(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Set preferences for admin user"""
        prefs_url = self._tester.url + "/prefs"
        tc.follow('Preferences')
        tc.url(prefs_url)
        tc.notfind('Your preferences have been saved.')
        tc.formvalue('userprefs', 'name', ' System Administrator ')
        tc.formvalue('userprefs', 'email', ' admin@example.com ')
        tc.submit()
        tc.find('Your preferences have been saved.')
        tc.follow('Date & Time')
        tc.url(prefs_url + '/datetime')
        tc.formvalue('userprefs', 'tz', 'GMT -10:00')
        tc.submit()
        tc.find('Your preferences have been saved.')
        tc.follow('General')
        tc.url(prefs_url)
        tc.notfind('Your preferences have been saved.')
        tc.find('value="System Administrator"')
        tc.find(r'value="admin@example\.com"')
        tc.follow('Date & Time')
        tc.url(prefs_url + '/datetime')
        tc.find('GMT -10:00')


class RegressionTestRev5785(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of the fix in r5785"""
        prefs_url = self._tester.url + "/prefs"
        tc.follow('Preferences')
        tc.url(prefs_url)
        tc.follow('Logout')
        tc.notfind(internal_error) # See [5785]
        tc.follow('Login')


class RegressionTestTicket5765(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5765
        Unable to turn off 'Enable access keys' in Preferences
        """
        self._tester.go_to_front()
        tc.follow('Preferences')
        tc.follow('Keyboard Shortcuts')
        tc.formvalue('userprefs', 'accesskeys', True)
        tc.submit()
        tc.find('name="accesskeys".*checked="checked"')
        tc.formvalue('userprefs', 'accesskeys', False)
        tc.submit()
        tc.notfind('name="accesskeys".*checked="checked"')


def functionalSuite(suite=None):
    if not suite:
        import trac.tests.functional.testcases
        suite = trac.tests.functional.testcases.functionalSuite()
    suite.addTest(TestPreferences())
    suite.addTest(RegressionTestRev5785())
    suite.addTest(RegressionTestTicket5765())
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004-2005 Daniel Lundin <daniel@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>

import pkg_resources
import re

try:
    from babel.core import Locale
except ImportError:
    Locale = None

from genshi.builder import tag

from trac.core import *
from trac.prefs.api import IPreferencePanelProvider
from trac.util.datefmt import all_timezones, get_timezone, localtz
from trac.util.translation import _, get_available_locales
from trac.web import HTTPNotFound, IRequestHandler
from trac.web.chrome import add_notice, add_stylesheet, \
                            INavigationContributor, ITemplateProvider


class PreferencesModule(Component):

    panel_providers = ExtensionPoint(IPreferencePanelProvider)

    implements(INavigationContributor, IPreferencePanelProvider,
               IRequestHandler, ITemplateProvider)

    _form_fields = [
        'newsid', 'name', 'email', 'tz', 'lc_time', 'dateinfo',
        'language', 'accesskeys',
        'ui.use_symbols', 'ui.hide_help',
        ]

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'prefs'

    def get_navigation_items(self, req):
        yield ('metanav', 'prefs',
               tag.a(_('Preferences'), href=req.href.prefs()))

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match('/prefs(?:/([^/]+))?$', req.path_info)
        if match:
            req.args['panel_id'] = match.group(1)
            return True

    def process_request(self, req):
        xhr = req.get_header('X-Requested-With') == 'XMLHttpRequest'
        if xhr and req.method == 'POST' and 'save_prefs' in req.args:
            self._do_save_xhr(req)

        panel_id = req.args['panel_id']

        panels = []
        chosen_provider = None

        for provider in self.panel_providers:
            for name, label in provider.get_preference_panels(req) or []:
                if name == panel_id or None:
                    chosen_provider = provider
                panels.append((name, label))
        if not chosen_provider:
            self.log.warn('Unknown preference panel %r', panel_id)
            raise HTTPNotFound(_('Unknown preference panel'))

        template, data = chosen_provider.render_preference_panel(req, panel_id)
        data.update({'active_panel': panel_id, 'panels': panels})

        add_stylesheet(req, 'common/css/prefs.css')
        return template, data, None

    # IPreferencePanelProvider methods

    def get_preference_panels(self, req):
        yield (None, _('General'))
        yield ('datetime', _('Date & Time'))
        yield ('keybindings', _('Keyboard Shortcuts'))
        yield ('userinterface', _('User Interface'))
        if Locale:
            yield ('language', _('Language'))
        if not req.authname or req.authname == 'anonymous':
            yield ('advanced', _('Advanced'))

    def render_preference_panel(self, req, panel):
        if req.method == 'POST':
            if 'restore' in req.args:
                self._do_load(req)
            else:
                self._do_save(req)
            req.redirect(req.href.prefs(panel or None))

        data = {
            'settings': {'session': req.session, 'session_id': req.session.sid},
            'timezones': all_timezones, 'timezone': get_timezone,
            'localtz': localtz
        }

        if Locale:
            locales = [Locale.parse(locale)
                       for locale in get_available_locales()]
            languages = sorted((str(locale), locale.display_name)
                               for locale in locales)
            data['locales'] = locales
            data['languages'] = languages

        return 'prefs_%s.html' % (panel or 'general'), data

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        return [pkg_resources.resource_filename('trac.prefs', 'templates')]

    # Internal methods

    def _do_save_xhr(self, req):
        for key in req.args:
            if not key in ['save_prefs', 'panel_id']:
                req.session[key] = req.args[key]
        req.session.save()
        req.send_no_content()

    def _do_save(self, req):
        for field in self._form_fields:
            val = req.args.get(field, '').strip()
            if val:
                if field == 'tz' and 'tz' in req.session and \
                        val not in all_timezones:
                    del req.session['tz']
                elif field == 'newsid':
                    req.session.change_sid(val)
                elif field == 'accesskeys':
                    req.session[field] = '1'
                else:
                    req.session[field] = val
            elif field in req.session and (field in req.args or
                                           field + '_cb' in req.args):
                del req.session[field]
        add_notice(req, _('Your preferences have been saved.'))

    def _do_load(self, req):
        if req.authname == 'anonymous':
            oldsid = req.args.get('loadsid')
            if oldsid:
                req.session.get_session(oldsid)
                add_notice(req, _('The session has been loaded.'))

########NEW FILE########
__FILENAME__ = resource
# -*- coding: utf-8 -*-
#
# Copyright (C) 2006-2009 Edgewall Software
# Copyright (C) 2006-2007 Alec Thomas <alec@swapoff.org>
# Copyright (C) 2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christian Boos <cboos@edgewall.org>
#         Alec Thomas <alec@swapoff.org>

from trac.core import *
from trac.util.translation import _


class ResourceNotFound(TracError):
    """Thrown when a non-existent resource is requested"""


class IResourceManager(Interface):

    def get_resource_realms():
        """Return resource realms managed by the component.

        :rtype: `basestring` generator
        """

    def get_resource_url(resource, href, **kwargs):
        """Return the canonical URL for displaying the given resource.

        :param resource: a `Resource`
        :param href: an `Href` used for creating the URL

        Note that if there's no special rule associated to this realm for
        creating URLs (i.e. the standard convention of using realm/id applies),
        then it's OK to not define this method.
        """

    def get_resource_description(resource, format='default', context=None,
                                 **kwargs):
        """Return a string representation of the resource, according to the
        `format`.

        :param resource: the `Resource` to describe
        :param format: the kind of description wanted. Typical formats are:
                       `'default'`, `'compact'` or `'summary'`.
        :param context: an optional rendering context to allow rendering rich
                        output (like markup containing links)
        :type context: `ResourceContext`

        Additional keyword arguments can be given as extra information for
        some formats.

        For example, the ticket with the id 123 is represented as:
         - `'#123'` in `'compact'` format,
         - `'Ticket #123'` for the `default` format.
         - `'Ticket #123 (closed defect): This is the summary'` for the
           `'summary'` format

        Note that it is also OK to not define this method if there's no
        special way to represent the resource, in which case the standard
        representations 'realm:id' (in compact mode) or 'Realm id' (in
        default mode) will be used.
        """

    def resource_exists(resource):
        """Check whether the given `resource` exists physically.

        :rtype: bool

        Attempting to retrieve the model object for a non-existing
        resource should raise a `ResourceNotFound` exception.
        (''since 0.11.8'')
        """


class IExternalResourceConnector(Interface):

    def get_supported_neighborhoods():
        """Return supported manager neighborhoods.

        :rtype: `basestring` generator
        """

    def load_manager(neighborhood):
        """Load the component manager identified by a given neighborhood.

        :param neighborhood: manager identifier (i.e. `Neighborhood`)
        :rtype: `trac.core.ComponentManager`
        """

    def manager_exists(neighborhood):
        """Check whether the component manager identified by 
        the given `neighborhood` exists physically.

        :param neighborhood: manager identifier (i.e. `Neighborhood`)
        :rtype: bool

        Attempting to retrieve the manager object for a non-existing
        neighborhood should raise a `ResourceNotFound` exception.
        """


class Neighborhood(object):
    """Neighborhoods are the topmost level in the resources hierarchy. 
    They represent resources managed by a component manager, thereby
    identifying the later. As such, resource neighborhoods serve to
    the purpose of specifying absolute references to resources hosted beyond
    the boundaries of a given component manager. As a side effect they are
    the key used to load component managers at run time.
    """

    __slots__ = ('_realm', '_id')

    @property
    def is_null(self):
        return (self._realm, self._id) == (None, None)

    def __repr__(self):
        if self.is_null:
            return '<Neighborhood (null)>'
        else:
            return '<Neighborhood %s:%s>' % (self._realm, self._id)

    def __eq__(self, other):
        return isinstance(other, Neighborhood) and \
               self._realm == other._realm and \
               self._id == other._id

    def __hash__(self):
        """Hash this resource descriptor, including its hierarchy."""
        return hash((self._realm, self._id))

    @property
    def id(self):
        return None

    @id.setter
    def id(self, value):
        pass

    realm = parent = neighborhood = version = id

    # -- methods for creating other Resource identifiers

    def __new__(cls, neighborhood_or_realm=None, id=False):
        """Create a new Neighborhood object from a specification.

        :param neighborhood_or_realm: this can be either:
           - a `Neighborhood`, which is then used as a base for making a copy
           - a `basestring`, used to specify a `realm`
        :param id: the neighborhood identifier
        :param version: the version or `None` for indicating the latest version

        >>> main = Neighborhood('nbh', 'id')
        >>> repr(main)
        '<Neighborhood nbh:id>'

        >>> Neighborhood(main) is main
        True

        >>> repr(Neighborhood(None))
        '<Neighborhood (null)>'
        """
        realm = neighborhood_or_realm
        if isinstance(neighborhood_or_realm, Neighborhood):
            if id is False:
                return neighborhood_or_realm
            else: # copy and override
                realm = neighborhood_or_realm._realm
        elif id is False:
            id = None
        neighborhood = super(Neighborhood, cls).__new__(cls)
        neighborhood._realm = realm
        neighborhood._id = id
        return neighborhood

    def __call__(self, realm=False, id=False, version=False, parent=False):
        """Create a new Resource using the current resource as a template.

        Optional keyword arguments can be given to override `id` and
        `version`.

        >>> nbh = Neighborhood('nbh', 'id')
        >>> repr(nbh)
        '<Neighborhood nbh:id>'

        >>> main = nbh('wiki', 'WikiStart')
        >>> repr(main)
        "<Resource u'wiki:WikiStart' in Neighborhood nbh:id>"

        >>> Resource(main) is main
        True

        >>> main3 = Resource(main, version=3)
        >>> repr(main3)
        "<Resource u'wiki:WikiStart@3' in Neighborhood nbh:id>"

        >>> main0 = main3(version=0)
        >>> repr(main0)
        "<Resource u'wiki:WikiStart@0' in Neighborhood nbh:id>"

        In a copy, if `id` is overriden, then the original `version` value
        will not be reused.

        >>> repr(Resource(main3, id="WikiEnd"))
        "<Resource u'wiki:WikiEnd' in Neighborhood nbh:id>"

        >>> repr(nbh(None))
        '<Neighborhood nbh:id>'

        Null neighborhood will be used to put absolute resource
        references ban into relative form (i.e. `resource.neiighborhood = None`)

        >>> nullnbh = Neighborhood(None, None)
        >>> repr(nullnbh)
        '<Neighborhood (null)>'

        >>> repr(nullnbh(main))
        "<Resource u'wiki:WikiStart'>"
        >>> repr(nullnbh(main3))
        "<Resource u'wiki:WikiStart@3'>"
        >>> repr(nullnbh(main0))
        "<Resource u'wiki:WikiStart@0'>"
        """
        if (realm, id, version, parent) in ((False, False, False, False),
                                            (None, False, False, False)):
            return self
        else:
            resource = Resource(realm, id, version, parent)
            if resource.neighborhood is not self:
                resource = self._update_parents(resource)
            return resource

    def _update_parents(self, resource):
        if self.is_null and resource.neighborhood is None:
            return resource
        newresource = Resource(resource.realm, resource.id, resource.version, self)
        current = newresource
        parent = resource.parent
        while parent is not None:
            current.parent = Resource(parent.realm, parent.id, parent.version, self)
            current = current.parent
            parent = parent.parent
        return newresource

    # -- methods for retrieving children Resource identifiers

    def child(self, realm, id=False, version=False):
        """Retrieve a child resource for a secondary `realm`.

        Same as `__call__`, except that this one sets the parent to `self`.

        >>> repr(Neighborhood('realm', 'id').child('attachment', 'file.txt'))
        "<Resource u'attachment:file.txt' in Neighborhood realm:id>"
        """
        return self(realm, id, version)


class Resource(object):
    """Resource identifier.

    This specifies as precisely as possible *which* resource from a Trac
    environment is manipulated.

    A resource is identified by:
    (- a `project` identifier) 0.12?
     - a `realm` (a string like `'wiki'` or `'ticket'`)
     - an `id`, which uniquely identifies a resource within its realm.
       If the `id` information is not set, then the resource represents
       the realm as a whole.
     - an optional `version` information.
       If `version` is `None`, this refers by convention to the latest
       version of the resource.

    Some generic and commonly used rendering methods are associated as well
    to the Resource object. Those properties and methods actually delegate
    the real work to the Resource's manager.
    """

    __slots__ = ('realm', 'id', 'version', 'parent', 'neighborhood')

    def __repr__(self):
        path = []
        r = self
        while r:
            name = r.realm
            if r.id:
                name += ':' + unicode(r.id) # id can be numerical
            if r.version is not None:
                name += '@' + unicode(r.version)
            path.append(name or '')
            r = r.parent
        path = reversed(path)
        if self.neighborhood is None:
            return '<Resource %r>' % (', '.join(path))
        else:
            return '<Resource %r in Neighborhood %s:%s>' % (', '.join(path), 
                                                    self.neighborhood._realm,
                                                    self.neighborhood._id)

    def __eq__(self, other):
        return isinstance(other, Resource) and \
               self.realm == other.realm and \
               self.id == other.id and \
               self.version == other.version and \
               self.parent == other.parent and \
               self.neighborhood == other.neighborhood

    def __hash__(self):
        """Hash this resource descriptor, including its hierarchy."""
        path = ()
        current = self
        while current:
            path += (self.realm, self.id, self.version)
            current = current.parent
        if self.neighborhood is not None:
            # FIXME: Collisions !!!
            path = (self.neighborhood._realm, self.neighborhood._id) + path
        else:
            path = (None, None) + path
        return hash(path)

    # -- methods for creating other Resource identifiers

    def __new__(cls, resource_or_realm=None, id=False, version=False,
                parent=False):
        """Create a new Resource object from a specification.

        :param resource_or_realm: this can be either:
           - a `Resource`, which is then used as a base for making a copy
           - a `basestring`, used to specify a `realm`
        :param id: the resource identifier
        :param version: the version or `None` for indicating the latest version

        >>> main = Resource('wiki', 'WikiStart')
        >>> repr(main)
        "<Resource u'wiki:WikiStart'>"

        >>> Resource(main) is main
        True

        >>> main3 = Resource(main, version=3)
        >>> repr(main3)
        "<Resource u'wiki:WikiStart@3'>"

        >>> main0 = main3(version=0)
        >>> repr(main0)
        "<Resource u'wiki:WikiStart@0'>"

        In a copy, if `id` is overriden, then the original `version` value
        will not be reused.

        >>> repr(Resource(main3, id="WikiEnd"))
        "<Resource u'wiki:WikiEnd'>"

        >>> repr(Resource(None))
        "<Resource ''>"
        """
        realm = resource_or_realm
        if isinstance(parent, Neighborhood):
            neighborhood = parent
            parent = False
        else:
            neighborhood = None
        if isinstance(resource_or_realm, Resource):
            if id is False and version is False and parent is False:
                return resource_or_realm
            else: # copy and override
                realm = resource_or_realm.realm
            if id is False:
                id = resource_or_realm.id
            if version is False:
                if id == resource_or_realm.id:
                    version = resource_or_realm.version # could be 0...
                else:
                    version = None
            if parent is False:
                parent = resource_or_realm.parent
            neighborhood = neighborhood or resource_or_realm.neighborhood
        else:
            if id is False:
                id = None
            if version is False:
                version = None
            if parent is False:
                parent = None
            neighborhood = neighborhood or getattr(parent, 'neighborhood', None)
        resource = super(Resource, cls).__new__(cls)
        resource.realm = realm
        resource.id = id
        resource.version = version
        resource.parent = parent
        if neighborhood and neighborhood.is_null:
            neighborhood = None
        resource.neighborhood = neighborhood
        return resource

    def __call__(self, realm=False, id=False, version=False, parent=False):
        """Create a new Resource using the current resource as a template.

        Optional keyword arguments can be given to override `id` and
        `version`.
        """
        return Resource(self if realm is False else realm, id, version, parent)

    # -- methods for retrieving children Resource identifiers

    def child(self, realm, id=False, version=False):
        """Retrieve a child resource for a secondary `realm`.

        Same as `__call__`, except that this one sets the parent to `self`.

        >>> repr(Resource(None).child('attachment', 'file.txt'))
        "<Resource u', attachment:file.txt'>"
        """
        return Resource(realm, id, version, self)

class IResourceChangeListener(Interface):
    """Extension point interface for components that require notification
    when resources are created, modified, or deleted.

    'resource' parameters is instance of the a resource e.g. ticket, milestone
    etc.
    'context' is an action context, may contain author, comment etc. Context
    content depends on a resource type.
    """

    def match_resource(resource):
        """Return whether the listener wants to process the given resource."""

    def resource_created(resource, context):
        """
        Called when a resource is created.
        """

    def resource_changed(resource, old_values, context):
        """Called when a resource is modified.

        `old_values` is a dictionary containing the previous values of the
        resource properties that changed. Properties are specific for resource
        type.
        """

    def resource_deleted(resource, context):
        """Called when a resource is deleted."""

    def resource_version_deleted(resource, context):
        """Called when a version of a resource has been deleted."""


class ResourceSystem(Component):
    """Resource identification and description manager.

    This component makes the link between `Resource` identifiers and their
    corresponding manager `Component`.
    """

    resource_connectors = ExtensionPoint(IExternalResourceConnector)
    resource_managers = ExtensionPoint(IResourceManager)
    change_listeners = ExtensionPoint(IResourceChangeListener)


    def __init__(self):
        self._resource_managers_map = None
        self._resource_connector_map = None

    # Public methods

    def get_resource_manager(self, realm):
        """Return the component responsible for resources in the given `realm`

        :param realm: the realm name
        :return: a `Component` implementing `IResourceManager` or `None`
        """
        # build a dict of realm keys to IResourceManager implementations
        if not self._resource_managers_map:
            map = {}
            for manager in self.resource_managers:
                for manager_realm in manager.get_resource_realms() or []:
                    map[manager_realm] = manager
            self._resource_managers_map = map
        return self._resource_managers_map.get(realm)

    def get_known_realms(self):
        """Return a list of all the realm names of resource managers."""
        realms = []
        for manager in self.resource_managers:
            for realm in manager.get_resource_realms() or []:
                realms.append(realm)
        return realms

    def get_resource_connector(self, realm):
        """Return the component responsible for loading component managers
         given the neighborhood `realm`

        :param realm: the realm name
        :return: a `ComponentManager` implementing `IExternalResourceConnector`
                 or `None`
        """
        # build a dict of neighborhood realm keys to target implementations
        if not self._resource_connector_map:
            map = {}
            for connector in self.resource_connectors:
                for conn_realm in connector.get_supported_neighborhoods() or []:
                    map[conn_realm] = connector
            self._resource_connector_map = map
        return self._resource_connector_map.get(realm)

    def get_known_neighborhoods(self):
        """Return a list of all the realm names of neighborhoods."""
        realms = []
        for connector in self.resource_connectors:
            for realm in connector.get_supported_neighborhoods() or []:
                realms.append(realm)
        return realms

    def load_component_manager(self, neighborhood, default=None):
        """Load the component manager identified by a given instance of
        `Neighborhood` class.

        :throws ResourceNotFound: if there is no connector for neighborhood
        """
        if neighborhood is None or neighborhood._realm is None:
            if default is not None:
                return default
            else:
                raise ResourceNotFound('Unexpected neighborhood %s' % 
                                       (neighborhood,))
        c = self.get_resource_connector(neighborhood._realm)
        if c is None:
            raise ResourceNotFound('Missing connector for neighborhood %s' % 
                                   (neighborhood,))
        return c.load_manager(neighborhood)

    def neighborhood_prefix(self, neighborhood):
        return '' if neighborhood is None \
                  else '[%s:%s] ' % (neighborhood._realm,
                                     neighborhood._id or '') 

    # -- Utilities to trigger resources event notifications

    def resource_created(self, resource, context=None):
        for listener in self.change_listeners:
            if listener.match_resource(resource):
                listener.resource_created(resource, context)

    def resource_changed(self, resource, old_values, context=None):
        for listener in self.change_listeners:
            if listener.match_resource(resource):
                listener.resource_changed(resource, old_values, context)

    def resource_deleted(self, resource, context=None):
        for listener in self.change_listeners:
            if listener.match_resource(resource):
                listener.resource_deleted(resource, context)

    def resource_version_deleted(self, resource, context=None):
        for listener in self.change_listeners:
            if listener.match_resource(resource):
                listener.resource_version_deleted(resource, context)


def manager_for_neighborhood(compmgr, neighborhood):
    """Instantiate a given component manager identified by
    target neighborhood.
    
    :param compmgr: Source component manager.
    :param neighborhood: Target neighborhood
    :throws ResourceNotFound: if there is no connector for neighborhood
    """
    rsys = ResourceSystem(compmgr)
    return rsys.load_component_manager(neighborhood, compmgr)


# -- Utilities for manipulating resources in a generic way

def get_resource_url(env, resource, href, **kwargs):
    """Retrieve the canonical URL for the given resource.

    This function delegates the work to the resource manager for that
    resource if it implements a `get_resource_url` method, otherwise
    reverts to simple '/realm/identifier' style URLs.

    :param env: the `Environment` where `IResourceManager` components live
    :param resource: the `Resource` object specifying the Trac resource
    :param href: an `Href` object used for building the URL

    Additional keyword arguments are translated as query parameters in the URL.

    >>> from trac.test import EnvironmentStub
    >>> from trac.web.href import Href
    >>> env = EnvironmentStub()
    >>> href = Href('/trac.cgi')
    >>> main = Resource('generic', 'Main')
    >>> get_resource_url(env, main, href)
    '/trac.cgi/generic/Main'

    >>> get_resource_url(env, main(version=3), href)
    '/trac.cgi/generic/Main?version=3'

    >>> get_resource_url(env, main(version=3), href)
    '/trac.cgi/generic/Main?version=3'

    >>> get_resource_url(env, main(version=3), href, action='diff')
    '/trac.cgi/generic/Main?action=diff&version=3'

    >>> get_resource_url(env, main(version=3), href, action='diff', version=5)
    '/trac.cgi/generic/Main?action=diff&version=5'

    """
    try:
        rsys = ResourceSystem(manager_for_neighborhood(env,
                                                       resource.neighborhood))
    except ResourceNotFound:
        pass
    else:
        if rsys.env is not env:
            # Use absolute href for external resources
            href = rsys.env.abs_href
        manager = rsys.get_resource_manager(resource.realm)
        if manager and hasattr(manager, 'get_resource_url'):
            return manager.get_resource_url(resource, href, **kwargs)
    args = {'version': resource.version}
    args.update(kwargs)
    return href(resource.realm, resource.id, **args)

def get_resource_description(env, resource, format='default', **kwargs):
    """Retrieve a standardized description for the given resource.

    This function delegates the work to the resource manager for that
    resource if it implements a `get_resource_description` method,
    otherwise reverts to simple presentation of the realm and identifier
    information.

    :param env: the `Environment` where `IResourceManager` components live
    :param resource: the `Resource` object specifying the Trac resource
    :param format: which formats to use for the description

    Additional keyword arguments can be provided and will be propagated
    to resource manager that might make use of them (typically, a `context`
    parameter for creating context dependent output).

    >>> from trac.test import EnvironmentStub
    >>> env = EnvironmentStub()
    >>> main = Resource('generic', 'Main')
    >>> get_resource_description(env, main)
    u'generic:Main'

    >>> get_resource_description(env, main(version=3))
    u'generic:Main'

    >>> get_resource_description(env, main(version=3), format='summary')
    u'generic:Main at version 3'

    """
    try:
        rsys = ResourceSystem(manager_for_neighborhood(env,
                                                       resource.neighborhood))
    except ResourceNotFound:
        rsys = ResourceSystem(env)
    else:
        manager = rsys.get_resource_manager(resource.realm)
        if manager and hasattr(manager, 'get_resource_description'):
            return manager.get_resource_description(resource, format, **kwargs)
    nbhprefix = rsys.neighborhood_prefix(resource.neighborhood) 

    name = u'%s%s:%s' % (nbhprefix, resource.realm, resource.id)
    if format == 'summary':
        name = _('%(name)s at version %(version)s',
                 name=name, version=resource.version)
    return name

def get_resource_name(env, resource):
    return get_resource_description(env, resource)

def get_resource_shortname(env, resource):
    return get_resource_description(env, resource, 'compact')

def get_resource_summary(env, resource):
    return get_resource_description(env, resource, 'summary')

def get_relative_resource(resource, path=''):
    """Build a Resource relative to a reference resource.

    :param path: path leading to another resource within the same realm.
    """
    if path in (None, '', '.'):
        return resource
    else:
        base = unicode(resource.id if path[0] != '/' else '').split('/')
        for comp in path.split('/'):
            if comp == '..':
                if base:
                    base.pop()
            elif comp and comp != '.':
                base.append(comp)
        return resource(id='/'.join(base) if base else None)

def get_relative_url(env, resource, href, path='', **kwargs):
    """Build an URL relative to a resource given as reference.

    :param path: path leading to another resource within the same realm.

    >>> from trac.test import EnvironmentStub
    >>> env = EnvironmentStub()
    >>> from trac.web.href import Href
    >>> href = Href('/trac.cgi')
    >>> main = Resource('wiki', 'Main', version=3)

    Without parameters, return the canonical URL for the resource, like
    `get_resource_url` does.

    >>> get_relative_url(env, main, href)
    '/trac.cgi/wiki/Main?version=3'

    Paths are relative to the given resource:

    >>> get_relative_url(env, main, href, '.')
    '/trac.cgi/wiki/Main?version=3'

    >>> get_relative_url(env, main, href, './Sub')
    '/trac.cgi/wiki/Main/Sub'

    >>> get_relative_url(env, main, href, './Sub/Infra')
    '/trac.cgi/wiki/Main/Sub/Infra'

    >>> get_relative_url(env, main, href, './Sub/')
    '/trac.cgi/wiki/Main/Sub'

    >>> mainsub = main(id='Main/Sub')
    >>> get_relative_url(env, mainsub, href, '..')
    '/trac.cgi/wiki/Main'

    >>> get_relative_url(env, main, href, '../Other')
    '/trac.cgi/wiki/Other'

    References always stay within the current resource realm:

    >>> get_relative_url(env, mainsub, href, '../..')
    '/trac.cgi/wiki'

    >>> get_relative_url(env, mainsub, href, '../../..')
    '/trac.cgi/wiki'

    >>> get_relative_url(env, mainsub, href, '/toplevel')
    '/trac.cgi/wiki/toplevel'

    Extra keyword arguments are forwarded as query parameters:

    >>> get_relative_url(env, main, href, action='diff')
    '/trac.cgi/wiki/Main?action=diff&version=3'

    """
    return get_resource_url(env, get_relative_resource(resource, path),
                            href, **kwargs)

def render_resource_link(env, context, resource, format='default'):
    """Utility for generating a link `Element` to the given resource.

    Some component manager may directly use an extra `context` parameter
    in order to directly generate rich content. Otherwise, the textual output
    is wrapped in a link to the resource.
    """
    from genshi.builder import Element, tag
    link = get_resource_description(env, resource, format, context=context)
    if not isinstance(link, Element):
        link = tag.a(link, href=get_resource_url(env, resource, context.href))
    return link

def resource_exists(env, resource):
    """Checks for resource existence without actually instantiating a model.

        :return: `True` if the resource exists, `False` if it doesn't
        and `None` in case no conclusion could be made (i.e. when
        `IResourceManager.resource_exists` is not implemented).

        >>> from trac.test import EnvironmentStub
        >>> env = EnvironmentStub()

        >>> resource_exists(env, Resource('dummy-realm', 'dummy-id')) is None
        True
        >>> resource_exists(env, Resource('dummy-realm'))
        False
    """
    try:
        ResourceSystem(manager_for_neighborhood(env, resource.neighborhood))
    except ResourceNotFound:
        return False
    manager = ResourceSystem(env).get_resource_manager(resource.realm)
    if manager and hasattr(manager, 'resource_exists'):
        return manager.resource_exists(resource)
    elif resource.id is None:
        return False

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import re

from trac.core import *


class ISearchSource(Interface):
    """Extension point interface for adding search sources to the search
    system.
    """

    def get_search_filters(req):
        """Return a list of filters that this search source supports.

        Each filter must be a `(name, label[, default])` tuple, where `name` is
        the internal name, `label` is a human-readable name for display and
        `default` is an optional boolean for determining whether this filter
        is searchable by default.
        """

    def get_search_results(req, terms, filters):
        """Return a list of search results matching each search term in `terms`.

        The `filters` parameters is a list of the enabled filters, each item
        being the name of the tuples returned by `get_search_events`.

        The events returned by this function must be tuples of the form
        `(href, title, date, author, excerpt).`
        """


def search_to_sql(db, columns, terms):
    """Convert a search query into an SQL WHERE clause and corresponding
    parameters.

    The result is returned as an `(sql, params)` tuple.
    """
    assert columns and terms

    likes = ['%s %s' % (i, db.like()) for i in columns]
    c = ' OR '.join(likes)
    sql = '(' + ') AND ('.join([c] * len(terms)) + ')'
    args = []
    for t in terms:
        args.extend(['%' + db.like_escape(t) + '%'] * len(columns))
    return sql, tuple(args)


def search_to_regexps(terms):
    """Convert search query terms into regular expressions."""
    return [re.compile(re.escape(term)) for term in terms]


def shorten_result(text='', keywords=[], maxlen=240, fuzz=60):
    if not text:
        text = ''
    text_low = text.lower()
    beg = -1
    for k in keywords:
        i = text_low.find(k.lower())
        if (i > -1 and i < beg) or beg == -1:
            beg = i
    excerpt_beg = 0
    if beg > fuzz:
        for sep in ('.', ':', ';', '='):
            eb = text.find(sep, beg - fuzz, beg - 1)
            if eb > -1:
                eb += 1
                break
        else:
            eb = beg - fuzz
        excerpt_beg = eb
    if excerpt_beg < 0:
        excerpt_beg = 0
    msg = text[excerpt_beg:beg+maxlen]
    if beg > fuzz:
        msg = '... ' + msg
    if beg < len(text)-maxlen:
        msg = msg + ' ...'
    return msg

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2004 Jonas Borgstrm <jonas@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>

import pkg_resources
import re

from genshi.builder import tag

from trac.config import IntOption, ListOption
from trac.core import *
from trac.mimeview import RenderingContext
from trac.perm import IPermissionRequestor
from trac.search.api import ISearchSource
from trac.util.datefmt import format_datetime, user_time
from trac.util.html import find_element
from trac.util.presentation import Paginator
from trac.util.text import quote_query_string
from trac.util.translation import _
from trac.web import IRequestHandler
from trac.web.chrome import (INavigationContributor, ITemplateProvider,
                             add_link, add_stylesheet, add_warning,
                             web_context)
from trac.wiki.api import IWikiSyntaxProvider
from trac.wiki.formatter import extract_link


class SearchModule(Component):

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
               ITemplateProvider, IWikiSyntaxProvider)

    search_sources = ExtensionPoint(ISearchSource)

    RESULTS_PER_PAGE = 10

    min_query_length = IntOption('search', 'min_query_length', 3,
        """Minimum length of query string allowed when performing a search.""")

    default_disabled_filters = ListOption('search', 'default_disabled_filters',
        doc="""Specifies which search filters should be disabled by
               default on the search page. This will also restrict the
               filters for the quick search function. The filter names
               defined by default components are: `wiki`, `ticket`,
               `milestone` and `changeset`.  For plugins, look for
               their implementation of the ISearchSource interface, in
               the `get_search_filters()` method, the first member of
               returned tuple. Once disabled, search filters can still
               be manually enabled by the user on the search page.
               (since 0.12)""")

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'search'

    def get_navigation_items(self, req):
        if 'SEARCH_VIEW' in req.perm:
            yield ('mainnav', 'search',
                   tag.a(_('Search'), href=req.href.search(), accesskey=4))

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['SEARCH_VIEW']

    # IRequestHandler methods

    def match_request(self, req):
        return re.match(r'/search(?:/opensearch)?$', req.path_info) is not None

    def process_request(self, req):
        req.perm.assert_permission('SEARCH_VIEW')

        if req.path_info == '/search/opensearch':
            return ('opensearch.xml', {},
                    'application/opensearchdescription+xml')

        query = req.args.get('q')
        available_filters = []
        for source in self.search_sources:
            available_filters.extend(source.get_search_filters(req) or [])
        available_filters.sort(key=lambda f: f[1].lower())

        filters = self._get_selected_filters(req, available_filters)
        data = self._prepare_data(req, query, available_filters, filters)
        if query:
            data['quickjump'] = self._check_quickjump(req, query)
            if query.startswith('!'):
                query = query[1:]

            terms = self._parse_query(req, query)
            if terms:
                results = self._do_search(req, terms, filters)
                if results:
                    data.update(self._prepare_results(req, filters, results))

        add_stylesheet(req, 'common/css/search.css')
        return 'search.html', data, None

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        return [pkg_resources.resource_filename('trac.search', 'templates')]

    # IWikiSyntaxProvider methods

    def get_wiki_syntax(self):
        return []

    def get_link_resolvers(self):
        yield ('search', self._format_link)

    def _format_link(self, formatter, ns, target, label):
        path, query, fragment = formatter.split_link(target)
        if path:
            href = formatter.href.search(q=path)
            if query:
                href += '&' + quote_query_string(query[1:])
        else:
            href = formatter.href.search() + quote_query_string(query)
        href += fragment
        return tag.a(label, class_='search', href=href)

    # IRequestHandler helper methods

    def _get_selected_filters(self, req, available_filters):
        """Return selected filters or the default filters if none was selected.
        """
        filters = [f[0] for f in available_filters if f[0] in req.args]
        if not filters:
            filters = [f[0] for f in available_filters
                       if f[0] not in self.default_disabled_filters and
                       (len(f) < 3 or len(f) > 2 and f[2])]
        return filters

    def _prepare_data(self, req, query, available_filters, filters):
        return {'filters': [{'name': f[0], 'label': f[1],
                             'active': f[0] in filters}
                            for f in available_filters],
                'query': query, 'quickjump': None, 'results': []}

    def _check_quickjump(self, req, kwd):
        """Look for search shortcuts"""
        noquickjump = int(req.args.get('noquickjump', '0'))
        # Source quickjump   FIXME: delegate to ISearchSource.search_quickjump
        quickjump_href = None
        if kwd[0] == '/':
            quickjump_href = req.href.browser(kwd)
            name = kwd
            description = _('Browse repository path %(path)s', path=kwd)
        else:
            context = web_context(req, 'search')
            link = find_element(extract_link(self.env, context, kwd), 'href')
            if link is not None:
                quickjump_href = link.attrib.get('href')
                name = link.children
                description = link.attrib.get('title', '')
        if quickjump_href:
            # Only automatically redirect to local quickjump links
            if not quickjump_href.startswith(req.base_path or '/'):
                noquickjump = True
            if noquickjump:
                return {'href': quickjump_href, 'name': tag.EM(name),
                        'description': description}
            else:
                req.redirect(quickjump_href)

    def _get_search_terms(self, query):
        """Break apart a search query into its various search terms.

        Terms are grouped implicitly by word boundary, or explicitly by (single
        or double) quotes.
        """
        terms = []
        for term in re.split('(".*?")|(\'.*?\')|(\s+)', query):
            if term is not None and term.strip():
                if term[0] == term[-1] and term[0] in "'\"":
                    term = term[1:-1]
                terms.append(term)
        return terms

    def _parse_query(self, req, query):
        """Parse query and refuse those which would result in a huge result set
        """
        terms = self._get_search_terms(query)
        if terms and (len(terms) > 1 or
                      len(terms[0]) >= self.min_query_length):
            return terms

        add_warning(req, _('Search query too short. '
                           'Query must be at least %(num)s characters long.',
                           num=self.min_query_length))

    def _do_search(self, req, terms, filters):
        results = []
        for source in self.search_sources:
            results.extend(source.get_search_results(req, terms, filters)
                           or [])
        return sorted(results, key=lambda x: x[2], reverse=True)

    def _prepare_results(self, req, filters, results):
        page = int(req.args.get('page', '1'))
        results = Paginator(results, page - 1, self.RESULTS_PER_PAGE)
        for idx, result in enumerate(results):
            results[idx] = {'href': result[0], 'title': result[1],
                            'date': user_time(req, format_datetime, result[2]),
                            'author': result[3], 'excerpt': result[4]}

        pagedata = []
        shown_pages = results.get_shown_pages(21)
        for shown_page in shown_pages:
            page_href = req.href.search([(f, 'on') for f in filters],
                                        q=req.args.get('q'),
                                        page=shown_page, noquickjump=1)
            pagedata.append([page_href, None, str(shown_page),
                             'page ' + str(shown_page)])

        fields = ['href', 'class', 'string', 'title']
        results.shown_pages = [dict(zip(fields, p)) for p in pagedata]

        results.current_page = {'href': None, 'class': 'current',
                                'string': str(results.page + 1),
                                'title':None}

        if results.has_next_page:
            next_href = req.href.search(zip(filters, ['on'] * len(filters)),
                                        q=req.args.get('q'), page=page + 1,
                                        noquickjump=1)
            add_link(req, 'next', next_href, _('Next Page'))

        if results.has_previous_page:
            prev_href = req.href.search(zip(filters, ['on'] * len(filters)),
                                        q=req.args.get('q'), page=page - 1,
                                        noquickjump=1)
            add_link(req, 'prev', prev_href, _('Previous Page'))

        page_href = req.href.search(
            zip(filters, ['on'] * len(filters)), q=req.args.get('q'),
            noquickjump=1)
        return {'results': results, 'page_href': page_href}

########NEW FILE########
__FILENAME__ = test
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import doctest
import os
import unittest
import sys

try:
    from babel import Locale
    locale_en = Locale.parse('en_US')
except ImportError:
    locale_en = None

from trac.config import Configuration
from trac.core import Component, ComponentManager
from trac.env import Environment
from trac.db.api import _parse_db_str, DatabaseManager
from trac.db.sqlite_backend import SQLiteConnection
from trac.db.util import ConnectionWrapper
import trac.db.postgres_backend
import trac.db.mysql_backend
from trac.ticket.default_workflow import load_workflow_config_snippet
from trac.util import translation


def Mock(bases=(), *initargs, **kw):
    """
    Simple factory for dummy classes that can be used as replacement for the
    real implementation in tests.

    Base classes for the mock can be specified using the first parameter, which
    must be either a tuple of class objects or a single class object. If the
    bases parameter is omitted, the base class of the mock will be object.

    So to create a mock that is derived from the builtin dict type, you can do:

    >>> mock = Mock(dict)
    >>> mock['foo'] = 'bar'
    >>> mock['foo']
    'bar'

    Attributes of the class are provided by any additional keyword parameters.

    >>> mock = Mock(foo='bar')
    >>> mock.foo
    'bar'

    Objects produces by this function have the special feature of not requiring
    the 'self' parameter on methods, because you should keep data at the scope
    of the test function. So you can just do:

    >>> mock = Mock(add=lambda x,y: x+y)
    >>> mock.add(1, 1)
    2

    To access attributes from the mock object from inside a lambda function,
    just access the mock itself:

    >>> mock = Mock(dict, do=lambda x: 'going to the %s' % mock[x])
    >>> mock['foo'] = 'bar'
    >>> mock.do('foo')
    'going to the bar'

    Because assignments or other types of statements don't work in lambda
    functions, assigning to a local variable from a mock function requires some
    extra work:

    >>> myvar = [None]
    >>> mock = Mock(set=lambda x: myvar.__setitem__(0, x))
    >>> mock.set(1)
    >>> myvar[0]
    1
    """
    if not isinstance(bases, tuple):
        bases = (bases,)
    cls = type('Mock', bases, {})
    mock = cls(*initargs)
    for k, v in kw.items():
        setattr(mock, k, v)
    return mock


class MockPerm(object):
    """Fake permission class. Necessary as Mock can not be used with operator
    overloading."""

    username = ''

    def has_permission(self, action, realm_or_resource=None, id=False,
                       version=False):
        return True
    __contains__ = has_permission

    def __call__(self, realm_or_resource, id=False, version=False):
        return self

    def require(self, action, realm_or_resource=None, id=False, version=False):
        pass
    assert_permission = require


class TestSetup(unittest.TestSuite):
    """
    Test suite decorator that allows a fixture to be setup for a complete
    suite of test cases.
    """
    def setUp(self):
        """Sets up the fixture, and sets self.fixture if needed"""
        pass

    def tearDown(self):
        """Tears down the fixture"""
        pass

    def run(self, result):
        """Setup the fixture (self.setUp), call .setFixture on all the tests,
        and tear down the fixture (self.tearDown)."""
        self.setUp()
        if hasattr(self, 'fixture'):
            for test in self._tests:
                if hasattr(test, 'setFixture'):
                    test.setFixture(self.fixture)
        unittest.TestSuite.run(self, result)
        self.tearDown()
        return result

    def _wrapped_run(self, *args, **kwargs):
        "Python 2.7 / unittest2 compatibility - there must be a better way..."
        self.setUp()
        if hasattr(self, 'fixture'):
            for test in self._tests:
                if hasattr(test, 'setFixture'):
                    test.setFixture(self.fixture)
        unittest.TestSuite._wrapped_run(self, *args, **kwargs)
        self.tearDown()

class TestCaseSetup(unittest.TestCase):
    def setFixture(self, fixture):
        self.fixture = fixture


# -- Database utilities

def get_dburi():
    dburi = os.environ.get('TRAC_TEST_DB_URI')
    if dburi:
        scheme, db_prop = _parse_db_str(dburi)
        # Assume the schema 'tractest' for Postgres
        if scheme == 'postgres' and \
                not db_prop.get('params', {}).get('schema'):
            if '?' in dburi:
                dburi += "&schema=tractest"
            else:
                dburi += "?schema=tractest"
        return dburi
    return 'sqlite::memory:'


def reset_sqlite_db(env, db_prop):
    dbname = os.path.basename(db_prop['path'])
    with env.db_transaction as db:
        tables = db("SELECT name FROM sqlite_master WHERE type='table'")
        for table in tables:
            db("DELETE FROM %s" % table)
        return tables


def reset_postgres_db(env, db_prop):
    with env.db_transaction as db:
        dbname = db.schema
        if dbname:
            # reset sequences
            # information_schema.sequences view is available in PostgreSQL 8.2+
            # however Trac supports PostgreSQL 8.0+, uses
            # pg_get_serial_sequence()
            for seq in db("""
                    SELECT sequence_name FROM (
                        SELECT pg_get_serial_sequence(%s||table_name,
                                                      column_name)
                               AS sequence_name
                        FROM information_schema.columns
                        WHERE table_schema=%s) AS tab
                    WHERE sequence_name IS NOT NULL""",
                    (dbname + '.', dbname)):
                db("ALTER SEQUENCE %s RESTART WITH 1" % seq)
            # clear tables
            tables = db("""SELECT table_name FROM information_schema.tables
                           WHERE table_schema=%s""", (dbname,))
            for table in tables:
                db("DELETE FROM %s" % table)
            # PostgreSQL supports TRUNCATE TABLE as well
            # (see http://www.postgresql.org/docs/8.1/static/sql-truncate.html)
            # but on the small tables used here, DELETE is actually much faster
            return tables


def reset_mysql_db(env, db_prop):
    dbname = os.path.basename(db_prop['path'])
    if dbname:
        with env.db_transaction as db:
            tables = db("""SELECT table_name FROM information_schema.tables
                           WHERE table_schema=%s""", (dbname,))
            for table in tables:
                # TRUNCATE TABLE is prefered to DELETE FROM, as we need to reset
                # the auto_increment in MySQL.
                db("TRUNCATE TABLE %s" % table)
            return tables


# -- Environment stub

class EnvironmentStub(Environment):
    """A stub of the trac.env.Environment object for testing."""

    href = abs_href = None
    global_databasemanager = None

    def __init__(self, default_data=False, enable=None, disable=None,
                 path=None, destroying=False):
        """Construct a new Environment stub object.

        :param default_data: If True, populate the database with some
                             defaults.
        :param enable: A list of component classes or name globs to
                       activate in the stub environment.
        """
        ComponentManager.__init__(self)
        Component.__init__(self)

        self.systeminfo = []

        import trac
        self.path = path
        if self.path is None:
            self.path = os.path.dirname(trac.__file__)
            if not os.path.isabs(self.path):
                self.path = os.path.join(os.getcwd(), self.path)

        # -- configuration
        self.config = Configuration(None)
        # We have to have a ticket-workflow config for ''lots'' of things to
        # work.  So insert the basic-workflow config here.  There may be a
        # better solution than this.
        load_workflow_config_snippet(self.config, 'basic-workflow.ini')
        self.config.set('logging', 'log_level', 'DEBUG')
        self.config.set('logging', 'log_type', 'stderr')
        if enable is not None:
            self.config.set('components', 'trac.*', 'disabled')
        else:
            self.config.set('components', 'tracopt.versioncontrol.svn.*',
                            'enabled')
        for name_or_class in enable or ():
            config_key = self._component_name(name_or_class)
            self.config.set('components', config_key, 'enabled')
        for name_or_class in disable or ():
            config_key = self._component_name(name_or_class)
            self.config.set('components', config_key, 'disabled')

        # -- logging
        from trac.log import logger_handler_factory
        self.log, self._log_handler = logger_handler_factory('test')

        # -- database
        self.config.set('components', 'trac.db.*', 'enabled')
        self.dburi = get_dburi()

        init_global = False
        if self.global_databasemanager:
            self.components[DatabaseManager] = self.global_databasemanager
        else:
            self.config.set('trac', 'database', self.dburi)
            self.global_databasemanager = DatabaseManager(self)
            self.config.set('trac', 'debug_sql', True)
            self.config.set('logging', 'log_type', 'stderr')
            self.config.set('logging', 'log_level', 'DEBUG')
            init_global = not destroying

        if default_data or init_global:
            self.reset_db(default_data)

        from trac.web.href import Href
        self.href = Href('/trac.cgi')
        self.abs_href = Href('http://example.org/trac.cgi')

        self.known_users = []
        translation.activate(locale_en)

    def reset_db(self, default_data=None):
        """Remove all data from Trac tables, keeping the tables themselves.
        :param default_data: after clean-up, initialize with default data
        :return: True upon success
        """
        from trac import db_default
        scheme, db_prop = _parse_db_str(self.dburi)
        tables = []
        remove_sqlite_db = False
        try:
            with self.db_transaction as db:
                db.rollback() # make sure there's no transaction in progress
                # check the database version
                database_version = db(
                    "SELECT value FROM system WHERE name='database_version'")
                if database_version:
                    database_version = int(database_version[0][0])
                if database_version == db_default.db_version:
                    # same version, simply clear the tables (faster)
                    m = sys.modules[__name__]
                    reset_fn = 'reset_%s_db' % scheme
                    if hasattr(m, reset_fn):
                        tables = getattr(m, reset_fn)(self, db_prop)
                else:
                    # different version or version unknown, drop the tables
                    remove_sqlite_db = True
                    self.destroy_db(scheme, db_prop)
        except Exception, e:
            # "Database not found ...",
            # "OperationalError: no such table: system" or the like
            pass

        db = None # as we might shutdown the pool     FIXME no longer needed!

        if scheme == 'sqlite' and remove_sqlite_db:
            path = db_prop['path']
            if path != ':memory:':
                if not os.path.isabs(path):
                    path = os.path.join(self.path, path)
                self.global_databasemanager.shutdown()
                os.remove(path)

        if not tables:
            self.global_databasemanager.init_db()
            # we need to make sure the next get_db_cnx() will re-create
            # a new connection aware of the new data model - see #8518.
            if self.dburi != 'sqlite::memory:':
                self.global_databasemanager.shutdown()

        with self.db_transaction as db:
            if default_data:
                for table, cols, vals in db_default.get_data(db):
                    db.executemany("INSERT INTO %s (%s) VALUES (%s)"
                                   % (table, ','.join(cols),
                                      ','.join(['%s' for c in cols])),
                                   vals)
            else:
                db("INSERT INTO system (name, value) VALUES (%s, %s)",
                   ('database_version', str(db_default.db_version)))

    def destroy_db(self, scheme=None, db_prop=None):
        if not (scheme and db_prop):
            scheme, db_prop = _parse_db_str(self.dburi)
        try:
            with self.db_transaction as db:
                if scheme == 'postgres' and db.schema:
                    db('DROP SCHEMA "%s" CASCADE' % db.schema)
                elif scheme == 'mysql':
                    dbname = os.path.basename(db_prop['path'])
                    for table in db("""
                          SELECT table_name FROM information_schema.tables
                          WHERE table_schema=%s""", (dbname,)):
                        db("DROP TABLE IF EXISTS `%s`" % table)
        except Exception:
            # "TracError: Database not found...",
            # psycopg2.ProgrammingError: schema "tractest" does not exist
            pass
        return False

    # overriden

    def is_component_enabled(self, cls):
        if self._component_name(cls).startswith('__main__.'):
            return True
        return Environment.is_component_enabled(self, cls)

    def get_known_users(self, cnx=None):
        return self.known_users


def locate(fn):
    """Locates a binary on the path.

    Returns the fully-qualified path, or None.
    """
    exec_suffix = '.exe' if os.name == 'nt' else ''

    for p in ["."] + os.environ['PATH'].split(os.pathsep):
        f = os.path.join(p, fn + exec_suffix)
        if os.path.exists(f):
            return f
    return None


INCLUDE_FUNCTIONAL_TESTS = True

def suite():
    import trac.tests
    import trac.admin.tests
    import trac.db.tests
    import trac.mimeview.tests
    import trac.ticket.tests
    import trac.util.tests
    import trac.versioncontrol.tests
    import trac.versioncontrol.web_ui.tests
    import trac.web.tests
    import trac.wiki.tests
    import tracopt.mimeview.tests
    import tracopt.perm.tests
    import tracopt.versioncontrol.git.tests
    import tracopt.versioncontrol.svn.tests

    suite = unittest.TestSuite()
    suite.addTest(trac.tests.basicSuite())
    if INCLUDE_FUNCTIONAL_TESTS:
        suite.addTest(trac.tests.functionalSuite())
    suite.addTest(trac.admin.tests.suite())
    suite.addTest(trac.db.tests.suite())
    suite.addTest(trac.mimeview.tests.suite())
    suite.addTest(trac.ticket.tests.suite())
    suite.addTest(trac.util.tests.suite())
    suite.addTest(trac.versioncontrol.tests.suite())
    suite.addTest(trac.versioncontrol.web_ui.tests.suite())
    suite.addTest(trac.web.tests.suite())
    suite.addTest(trac.wiki.tests.suite())
    suite.addTest(tracopt.mimeview.tests.suite())
    suite.addTest(tracopt.perm.tests.suite())
    suite.addTest(tracopt.versioncontrol.git.tests.suite())
    suite.addTest(tracopt.versioncontrol.svn.tests.suite())
    suite.addTest(doctest.DocTestSuite(sys.modules[__name__]))

    return suite

if __name__ == '__main__':
    #FIXME: this is a bit inelegant
    if '--skip-functional-tests' in sys.argv:
        sys.argv.remove('--skip-functional-tests')
        INCLUDE_FUNCTIONAL_TESTS = False
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = allwiki
import unittest

import trac.tests.wikisyntax
import trac.ticket.tests.wikisyntax
import trac.versioncontrol.web_ui.tests.wikisyntax
import trac.web.tests.wikisyntax
import trac.wiki.tests.wikisyntax
import trac.wiki.tests.formatter

def suite():
    suite = unittest.TestSuite()
    suite.addTest(trac.tests.wikisyntax.suite())
    suite.addTest(trac.ticket.tests.wikisyntax.suite())
    suite.addTest(trac.versioncontrol.web_ui.tests.wikisyntax.suite())
    suite.addTest(trac.web.tests.wikisyntax.suite())
    suite.addTest(trac.wiki.tests.macros.suite())
    suite.addTest(trac.wiki.tests.wikisyntax.suite())
    suite.addTest(trac.wiki.tests.formatter.suite())
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = attachment
# -*- coding: utf-8 -*-

import os.path
import shutil
from StringIO import StringIO
import tempfile
import unittest

from trac.attachment import Attachment, AttachmentModule
from trac.core import Component, implements, TracError
from trac.perm import IPermissionPolicy, PermissionCache
from trac.resource import Resource, resource_exists
from trac.test import EnvironmentStub
from trac.tests.resource import TestResourceChangeListener


hashes = {
    '42': '92cfceb39d57d914ed8b14d0e37643de0797ae56',
    'Foo.Mp3': '95797b6eb253337ff2c54e0881e2b747ec394f51',
    'SomePage': 'd7e80bae461ca8568e794792f5520b603f540e06',
    'Teh bar.jpg': 'ed9102c4aa099e92baf1073f824d21c5e4be5944',
    'Teh foo.txt': 'ab97ba98d98fcf72b92e33a66b07077010171f70',
    'bar.7z': '6c9600ad4d59ac864e6f0d2030c1fc76b4b406cb',
    'bar.jpg': 'ae0faa593abf2b6f8871f6f32fe5b28d1c6572be',
    'foo.$$$': 'eefc6aa745dbe129e8067a4a57637883edd83a8a',
    'foo.2.txt': 'a8fcfcc2ef4e400ee09ae53c1aabd7f5a5fda0c7',
    'foo.txt': '9206ac42b532ef8e983470c251f4e1a365fd636c',
    u'bar.ac': '70d0e3b813fdc756602d82748719a3ceb85cbf29',
    u'berSicht': 'a16c6837f6d3d2cc3addd68976db1c55deb694c8',
}


class TicketOnlyViewsTicket(Component):
    implements(IPermissionPolicy)

    def check_permission(self, action, username, resource, perm):
        if action.startswith('TICKET_'):
            return resource.realm == 'ticket'
        else:
            return None


class AttachmentTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        self.env.path = os.path.join(tempfile.gettempdir(), 'trac-tempenv')
        os.mkdir(self.env.path)
        self.attachments_dir = os.path.join(self.env.path, 'files',
                                            'attachments')
        self.env.config.set('trac', 'permission_policies',
                            'TicketOnlyViewsTicket, LegacyAttachmentPolicy')
        self.env.config.set('attachment', 'max_size', 512)

        self.perm = PermissionCache(self.env)

    def tearDown(self):
        shutil.rmtree(self.env.path)
        self.env.reset_db()

    def test_get_path(self):
        attachment = Attachment(self.env, 'ticket', 42)
        attachment.filename = 'foo.txt'
        self.assertEqual(os.path.join(self.attachments_dir, 'ticket',
                                      hashes['42'][0:3], hashes['42'],
                                      hashes['foo.txt'] + '.txt'),
                         attachment.path)
        attachment = Attachment(self.env, 'wiki', 'SomePage')
        attachment.filename = 'bar.jpg'
        self.assertEqual(os.path.join(self.attachments_dir, 'wiki',
                                      hashes['SomePage'][0:3],
                                      hashes['SomePage'],
                                      hashes['bar.jpg'] + '.jpg'),
                         attachment.path)

    def test_path_extension(self):
        attachment = Attachment(self.env, 'ticket', 42)
        attachment.filename = 'Foo.Mp3'
        self.assertEqual(os.path.join(self.attachments_dir, 'ticket',
                                      hashes['42'][0:3], hashes['42'],
                                      hashes['Foo.Mp3'] + '.Mp3'),
                         attachment.path)
        attachment = Attachment(self.env, 'wiki', 'SomePage')
        attachment.filename = 'bar.7z'
        self.assertEqual(os.path.join(self.attachments_dir, 'wiki',
                                      hashes['SomePage'][0:3],
                                      hashes['SomePage'],
                                      hashes['bar.7z'] + '.7z'),
                         attachment.path)
        attachment = Attachment(self.env, 'ticket', 42)
        attachment.filename = 'foo.$$$'
        self.assertEqual(os.path.join(self.attachments_dir, 'ticket',
                                      hashes['42'][0:3], hashes['42'],
                                      hashes['foo.$$$']),
                         attachment.path)
        attachment = Attachment(self.env, 'wiki', 'SomePage')
        attachment.filename = u'bar.ac'
        self.assertEqual(os.path.join(self.attachments_dir, 'wiki',
                                      hashes['SomePage'][0:3],
                                      hashes['SomePage'],
                                      hashes[u'bar.ac']),
                         attachment.path)

    def test_get_path_encoded(self):
        attachment = Attachment(self.env, 'ticket', 42)
        attachment.filename = 'Teh foo.txt'
        self.assertEqual(os.path.join(self.attachments_dir, 'ticket',
                                      hashes['42'][0:3], hashes['42'],
                                      hashes['Teh foo.txt'] + '.txt'),
                         attachment.path)
        attachment = Attachment(self.env, 'wiki', u'berSicht')
        attachment.filename = 'Teh bar.jpg'
        self.assertEqual(os.path.join(self.attachments_dir, 'wiki',
                                      hashes[u'berSicht'][0:3],
                                      hashes[u'berSicht'],
                                      hashes['Teh bar.jpg'] + '.jpg'),
                         attachment.path)

    def test_select_empty(self):
        self.assertRaises(StopIteration,
                          Attachment.select(self.env, 'ticket', 42).next)
        self.assertRaises(StopIteration,
                          Attachment.select(self.env, 'wiki', 'SomePage').next)

    def test_insert(self):
        attachment = Attachment(self.env, 'ticket', 42)
        attachment.insert('foo.txt', StringIO(''), 0, 1)
        attachment = Attachment(self.env, 'ticket', 42)
        attachment.insert('bar.jpg', StringIO(''), 0, 2)

        attachments = Attachment.select(self.env, 'ticket', 42)
        self.assertEqual('foo.txt', attachments.next().filename)
        self.assertEqual('bar.jpg', attachments.next().filename)
        self.assertRaises(StopIteration, attachments.next)

    def test_insert_unique(self):
        attachment = Attachment(self.env, 'ticket', 42)
        attachment.insert('foo.txt', StringIO(''), 0)
        self.assertEqual('foo.txt', attachment.filename)
        attachment = Attachment(self.env, 'ticket', 42)
        attachment.insert('foo.txt', StringIO(''), 0)
        self.assertEqual('foo.2.txt', attachment.filename)
        self.assertEqual(os.path.join(self.attachments_dir, 'ticket',
                                      hashes['42'][0:3], hashes['42'],
                                      hashes['foo.2.txt'] + '.txt'),
                         attachment.path)
        self.assert_(os.path.exists(attachment.path))

    def test_insert_outside_attachments_dir(self):
        attachment = Attachment(self.env, '../../../../../sth/private', 42)
        self.assertRaises(TracError, attachment.insert, 'foo.txt',
                          StringIO(''), 0)

    def test_delete(self):
        attachment1 = Attachment(self.env, 'wiki', 'SomePage')
        attachment1.insert('foo.txt', StringIO(''), 0)
        attachment2 = Attachment(self.env, 'wiki', 'SomePage')
        attachment2.insert('bar.jpg', StringIO(''), 0)

        attachments = Attachment.select(self.env, 'wiki', 'SomePage')
        self.assertEqual(2, len(list(attachments)))

        attachment1.delete()
        attachment2.delete()

        assert not os.path.exists(attachment1.path)
        assert not os.path.exists(attachment2.path)

        attachments = Attachment.select(self.env, 'wiki', 'SomePage')
        self.assertEqual(0, len(list(attachments)))

    def test_delete_file_gone(self):
        """
        Verify that deleting an attachment works even if the referenced file
        doesn't exist for some reason.
        """
        attachment = Attachment(self.env, 'wiki', 'SomePage')
        attachment.insert('foo.txt', StringIO(''), 0)
        os.unlink(attachment.path)

        attachment.delete()

    def test_reparent(self):
        attachment1 = Attachment(self.env, 'wiki', 'SomePage')
        attachment1.insert('foo.txt', StringIO(''), 0)
        path1 = attachment1.path
        attachment2 = Attachment(self.env, 'wiki', 'SomePage')
        attachment2.insert('bar.jpg', StringIO(''), 0)

        attachments = Attachment.select(self.env, 'wiki', 'SomePage')
        self.assertEqual(2, len(list(attachments)))
        attachments = Attachment.select(self.env, 'ticket', 123)
        self.assertEqual(0, len(list(attachments)))
        assert os.path.exists(path1) and os.path.exists(attachment2.path)

        attachment1.reparent('ticket', 123)
        self.assertEqual('ticket', attachment1.parent_realm)
        self.assertEqual('ticket', attachment1.resource.parent.realm)
        self.assertEqual('123', attachment1.parent_id)
        self.assertEqual('123', attachment1.resource.parent.id)

        attachments = Attachment.select(self.env, 'wiki', 'SomePage')
        self.assertEqual(1, len(list(attachments)))
        attachments = Attachment.select(self.env, 'ticket', 123)
        self.assertEqual(1, len(list(attachments)))
        assert not os.path.exists(path1) and os.path.exists(attachment1.path)
        assert os.path.exists(attachment2.path)

    def test_legacy_permission_on_parent(self):
        """Ensure that legacy action tests are done on parent.  As
        `ATTACHMENT_VIEW` maps to `TICKET_VIEW`, the `TICKET_VIEW` is tested
        against the ticket's resource."""
        attachment = Attachment(self.env, 'ticket', 42)
        self.assert_('ATTACHMENT_VIEW' in self.perm(attachment.resource))

    def test_resource_doesnt_exist(self):
        r = Resource('wiki', 'WikiStart').child('attachment', 'file.txt')
        self.assertEqual(False, AttachmentModule(self.env).resource_exists(r))

    def test_resource_exists(self):
        att = Attachment(self.env, 'wiki', 'WikiStart')
        att.insert('file.txt', StringIO(''), 1)
        self.assertTrue(resource_exists(self.env, att.resource))


class AttachmentResourceChangeListenerTestCase(unittest.TestCase):
    DUMMY_PARENT_REALM = "wiki"
    DUMMY_PARENT_ID = "WikiStart"

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.listener = TestResourceChangeListener(self.env)
        self.listener.resource_type = Attachment
        self.listener.callback = self.listener_callback

    def tearDown(self):
        self.env.reset_db()

    def test_change_listener_created(self):
        attachment = self._create_attachment()
        self.assertEqual('created', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, Attachment))
        self.assertEqual(attachment.filename, self.filename)
        self.assertEqual(attachment.parent_realm, self.parent_realm)
        self.assertEqual(attachment.parent_id, self.parent_id)

    def test_change_listener_reparent(self):
        attachment = self._create_attachment()
        attachment.reparent(self.DUMMY_PARENT_REALM, "SomePage")

        self.assertEqual('changed', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, Attachment))
        self.assertEqual(attachment.filename, self.filename)
        self.assertEqual(attachment.parent_realm, self.parent_realm)
        self.assertEqual("SomePage", self.parent_id)
        self.assertNotIn("parent_realm", self.listener.old_values)
        self.assertEqual(
            self.DUMMY_PARENT_ID, self.listener.old_values["parent_id"])

    def test_change_listener_deleted(self):
        attachment = self._create_attachment()
        attachment.delete()
        self.assertEqual('deleted', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, Attachment))
        self.assertEqual(attachment.filename, self.filename)

    def _create_attachment(self):
        attachment = Attachment(
            self.env, self.DUMMY_PARENT_REALM, self.DUMMY_PARENT_ID)
        attachment.insert('file.txt', StringIO(''), 1)
        return attachment

    def listener_callback(self, action, resource, context, old_values = None):
        self.parent_realm = resource.parent_realm
        self.parent_id = resource.parent_id
        self.filename = resource.filename

def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(AttachmentTestCase, 'test'))
    suite.addTest(unittest.makeSuite(
        AttachmentResourceChangeListenerTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = config
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2007 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from __future__ import with_statement

import os
import tempfile
import time
import unittest

from trac.config import *
from trac.test import Configuration
from trac.util import create_file


class ConfigurationTestCase(unittest.TestCase):

    def setUp(self):
        tmpdir = os.path.realpath(tempfile.gettempdir())
        self.filename = os.path.join(tmpdir, 'trac-test.ini')
        self._write([])
        self._orig_registry = Option.registry
        Option.registry = {}

    def tearDown(self):
        Option.registry = self._orig_registry
        os.remove(self.filename)

    def _read(self):
        return Configuration(self.filename)

    def _write(self, lines):
        with open(self.filename, 'w') as fileobj:
            fileobj.write(('\n'.join(lines + [''])).encode('utf-8'))

    def test_default(self):
        config = self._read()
        self.assertEquals('', config.get('a', 'option'))
        self.assertEquals('value', config.get('a', 'option', 'value'))

        class Foo(object):
            option_a = Option('a', 'option', 'value')

        self.assertEquals('value', config.get('a', 'option'))

    def test_default_bool(self):
        config = self._read()
        self.assertEquals(False, config.getbool('a', 'option'))
        self.assertEquals(True, config.getbool('a', 'option', 'yes'))
        self.assertEquals(True, config.getbool('a', 'option', 1))

        class Foo(object):
            option_a = Option('a', 'option', 'true')

        self.assertEquals(True, config.getbool('a', 'option'))

    def test_default_int(self):
        config = self._read()
        self.assertRaises(ConfigurationError,
                          config.getint, 'a', 'option', 'b')
        self.assertEquals(0, config.getint('a', 'option'))
        self.assertEquals(1, config.getint('a', 'option', '1'))
        self.assertEquals(1, config.getint('a', 'option', 1))

        class Foo(object):
            option_a = Option('a', 'option', '2')

        self.assertEquals(2, config.getint('a', 'option'))

    def test_default_float(self):
        config = self._read()
        self.assertRaises(ConfigurationError,
                          config.getfloat, 'a', 'option', 'b')
        self.assertEquals(0.0, config.getfloat('a', 'option'))
        self.assertEquals(1.2, config.getfloat('a', 'option', '1.2'))
        self.assertEquals(1.2, config.getfloat('a', 'option', 1.2))
        self.assertEquals(1.0, config.getfloat('a', 'option', 1))

        class Foo(object):
            option_a = Option('a', 'option', '2.5')

        self.assertEquals(2.5, config.getfloat('a', 'option'))

    def test_default_path(self):
        config = self._read()
        class Foo(object):
            option_a = PathOption('a', 'opt1', 'file.ini')
            option_b = PathOption('a', 'opt2', '/somewhere/file.ini')
        self.assertEquals('file.ini', config.get('a', 'opt1'))
        self.assertNotEquals('file.ini', config.getpath('a', 'opt1'))
        self.assertTrue(os.path.isabs(config.getpath('a', 'opt1')))
        self.assertEquals('/somewhere/file.ini', os.path.splitdrive(
                config.getpath('a', 'opt2'))[1].replace('\\', '/'))
        self.assertEquals('/none.ini', os.path.splitdrive(
                config.getpath('a', 'opt3', '/none.ini'))[1].replace('\\', '/'))
        self.assertNotEquals('none.ini', config.getpath('a', 'opt3', 'none.ini'))

    def test_read_and_get(self):
        self._write(['[a]', 'option = x'])
        config = self._read()
        self.assertEquals('x', config.get('a', 'option'))
        self.assertEquals('x', config.get('a', 'option', 'y'))
        self.assertEquals('y', config.get('b', 'option2', 'y'))

    def test_read_and_get_unicode(self):
        self._write([u'[]', u'ption = x'])
        config = self._read()
        self.assertEquals('x', config.get(u'', u'ption'))
        self.assertEquals('x', config.get(u'', u'ption', 'y'))
        self.assertEquals('y', config.get('b', u'ption2', 'y'))

    def test_read_and_getbool(self):
        self._write(['[a]', 'option = yes', 'option2 = true',
                     'option3 = eNaBlEd', 'option4 = on',
                     'option5 = 1', 'option6 = 123', 'option7 = 123.456',
                     'option8 = disabled', 'option9 = 0', 'option10 = 0.0'])
        config = self._read()
        self.assertEquals(True, config.getbool('a', 'option'))
        self.assertEquals(True, config.getbool('a', 'option', False))
        self.assertEquals(True, config.getbool('a', 'option2'))
        self.assertEquals(True, config.getbool('a', 'option3'))
        self.assertEquals(True, config.getbool('a', 'option4'))
        self.assertEquals(True, config.getbool('a', 'option5'))
        self.assertEquals(True, config.getbool('a', 'option6'))
        self.assertEquals(True, config.getbool('a', 'option7'))
        self.assertEquals(False, config.getbool('a', 'option8'))
        self.assertEquals(False, config.getbool('a', 'option9'))
        self.assertEquals(False, config.getbool('a', 'option10'))
        self.assertEquals(False, config.getbool('b', 'option_b'))
        self.assertEquals(False, config.getbool('b', 'option_b', False))
        self.assertEquals(False, config.getbool('b', 'option_b', 'disabled'))

    def test_read_and_getint(self):
        self._write(['[a]', 'option = 42'])
        config = self._read()
        self.assertEquals(42, config.getint('a', 'option'))
        self.assertEquals(42, config.getint('a', 'option', 25))
        self.assertEquals(0, config.getint('b', 'option2'))
        self.assertEquals(25, config.getint('b', 'option2', 25))
        self.assertEquals(25, config.getint('b', 'option2', '25'))

    def test_read_and_getfloat(self):
        self._write(['[a]', 'option = 42.5'])
        config = self._read()
        self.assertEquals(42.5, config.getfloat('a', 'option'))
        self.assertEquals(42.5, config.getfloat('a', 'option', 25.3))
        self.assertEquals(0, config.getfloat('b', 'option2'))
        self.assertEquals(25.3, config.getfloat('b', 'option2', 25.3))
        self.assertEquals(25.0, config.getfloat('b', 'option2', 25))
        self.assertEquals(25.3, config.getfloat('b', 'option2', '25.3'))

    def test_read_and_getlist(self):
        self._write(['[a]', 'option = foo, bar, baz'])
        config = self._read()
        self.assertEquals(['foo', 'bar', 'baz'],
                          config.getlist('a', 'option'))
        self.assertEquals([],
                          config.getlist('b', 'option2'))
        self.assertEquals(['foo', 'bar', 'baz'],
                    config.getlist('b', 'option2', ['foo', 'bar', 'baz']))
        self.assertEquals(['foo', 'bar', 'baz'],
                    config.getlist('b', 'option2', 'foo, bar, baz'))

    def test_read_and_getlist_sep(self):
        self._write(['[a]', 'option = foo | bar | baz'])
        config = self._read()
        self.assertEquals(['foo', 'bar', 'baz'],
                          config.getlist('a', 'option', sep='|'))

    def test_read_and_getlist_keep_empty(self):
        self._write(['[a]', 'option = ,bar,baz'])
        config = self._read()
        self.assertEquals(['bar', 'baz'], config.getlist('a', 'option'))
        self.assertEquals(['', 'bar', 'baz'],
                          config.getlist('a', 'option', keep_empty=True))

    def test_read_and_getlist_false_values(self):
        config = self._read()
        values = [None, False, '', 'foo', u'', u'bar',
                  0, 0L, 0.0, 0j, 42, 43.0]
        self.assertEquals([False, 'foo', u'bar', 0, 0L, 0.0, 0j, 42, 43.0],
                          config.getlist('a', 'false', values))
        self.assertEquals(values, config.getlist('a', 'false', values,
                                                 keep_empty=True))

    def test_read_and_choice(self):
        self._write(['[a]', 'option = 2', 'invalid = d'])
        config = self._read()

        class Foo(object):
            # enclose in parentheses to avoid messages extraction
            option = (ChoiceOption)('a', 'option', ['Item1', 2, '3'])
            other = (ChoiceOption)('a', 'other', [1, 2, 3])
            invalid = (ChoiceOption)('a', 'invalid', ['a', 'b', 'c'])

            def __init__(self):
                self.config = config

        foo = Foo()
        self.assertEquals('2', foo.option)
        self.assertEquals('1', foo.other)
        self.assertRaises(ConfigurationError, getattr, foo, 'invalid')

    def test_getpath(self):
        base = os.path.dirname(self.filename)
        config = self._read()
        config.set('a', 'path_a', os.path.join(base, 'here', 'absolute.txt'))
        config.set('a', 'path_b', 'thisdir.txt')
        config.set('a', 'path_c', os.path.join(os.pardir, 'parentdir.txt'))
        self.assertEquals(os.path.join(base, 'here', 'absolute.txt'),
                          config.getpath('a', 'path_a'))
        self.assertEquals(os.path.join(base, 'thisdir.txt'),
                          config.getpath('a', 'path_b'))
        self.assertEquals(os.path.join(os.path.dirname(base), 'parentdir.txt'),
                          config.getpath('a', 'path_c'))

    def test_set_and_save(self):
        config = self._read()
        config.set('b', u'ption0', 'y')
        config.set(u'a', 'ption0', 'x')
        config.set('a', 'option2', "Voil l't")  # UTF-8
        config.set(u'a', 'option1', u"Voil l't") # unicode
        # Note: the following would depend on the locale.getpreferredencoding()
        # config.set('a', 'option3', "Voil\xe0 l'\xe9t\xe9") # latin-1
        self.assertEquals('x', config.get(u'a', u'ption0'))
        self.assertEquals(u"Voil l't", config.get(u'a', 'option1'))
        self.assertEquals(u"Voil l't", config.get(u'a', 'option2'))
        config.save()

        configfile = open(self.filename, 'r')
        self.assertEquals(['# -*- coding: utf-8 -*-\n',
                           '\n',
                           '[a]\n',
                           "option1 = Voil l't\n",
                           "option2 = Voil l't\n",
                           'ption0 = x\n',
                           # "option3 = Voil l't\n",
                           '\n',
                           '[b]\n',
                           'ption0 = y\n',
                           '\n'],
                          configfile.readlines())
        configfile.close()
        config2 = Configuration(self.filename)
        self.assertEquals('x', config2.get(u'a', u'ption0'))
        self.assertEquals(u"Voil l't", config2.get(u'a', 'option1'))
        self.assertEquals(u"Voil l't", config2.get(u'a', 'option2'))
        # self.assertEquals(u"Voil l't", config2.get('a', 'option3'))

    def test_set_and_save_inherit(self):
        def testcb():
            config = self._read()
            config.set('a', 'option2', "Voil l't")  # UTF-8
            config.set('a', 'option1', u"Voil l't") # unicode
            self.assertEquals('x', config.get('a', 'option'))
            self.assertEquals(u"Voil l't", config.get('a', 'option1'))
            self.assertEquals(u"Voil l't", config.get('a', 'option2'))
            config.save()

            configfile = open(self.filename, 'r')
            self.assertEquals(['# -*- coding: utf-8 -*-\n',
                               '\n',
                               '[a]\n',
                               "option1 = Voil l't\n",
                               "option2 = Voil l't\n",
                               '\n',
                               '[inherit]\n',
                               "file = trac-site.ini\n",
                               '\n'],
                              configfile.readlines())
            configfile.close()
            config2 = Configuration(self.filename)
            self.assertEquals('x', config2.get('a', 'option'))
            self.assertEquals(u"Voil l't", config2.get('a', 'option1'))
            self.assertEquals(u"Voil l't", config2.get('a', 'option2'))
        self._test_with_inherit(testcb)

    def test_simple_remove(self):
        self._write(['[a]', 'option = x'])
        config = self._read()
        config.get('a', 'option') # populates the cache
        config.set(u'a', u'ption', u'ne')
        config.remove('a', 'option')
        self.assertEquals('', config.get('a', 'option'))
        config.remove(u'a', u'ption')
        self.assertEquals('', config.get('a', 'ption'))
        config.remove('a', 'option2') # shouldn't fail
        config.remove('b', 'option2') # shouldn't fail

    def test_sections(self):
        self._write(['[a]', 'option = x', '[b]', 'option = y'])
        config = self._read()
        self.assertEquals(['a', 'b'], config.sections())

        class Foo(object):
            # enclose in parentheses to avoid messages extraction
            section_c = (ConfigSection)('c', 'Doc for c')
            option_c = Option('c', 'option', 'value')

        self.assertEquals(['a', 'b', 'c'], config.sections())
        foo = Foo()
        foo.config = config
        self.assert_(foo.section_c is config['c'])
        self.assertEquals('value', foo.section_c.get('option'))

    def test_sections_unicode(self):
        self._write([u'[a]', u'ption = x', '[b]', 'option = y'])
        config = self._read()
        self.assertEquals([u'a', 'b'], config.sections())

        class Foo(object):
            option_c = Option(u'c', 'option', 'value')

        self.assertEquals([u'a', 'b', u'c'], config.sections())

    def test_options(self):
        self._write(['[a]', 'option = x', '[b]', 'option = y'])
        config = self._read()
        self.assertEquals(('option', 'x'), iter(config.options('a')).next())
        self.assertEquals(('option', 'y'), iter(config.options('b')).next())
        self.assertRaises(StopIteration, iter(config.options('c')).next)
        self.assertEquals('option', iter(config['a']).next())
        self.assertEquals('option', iter(config['b']).next())
        self.assertRaises(StopIteration, iter(config['c']).next)

        class Foo(object):
            option_a = Option('a', 'b', 'c')

        self.assertEquals([('option', 'x'), ('b', 'c')],
                                list(config.options('a')))

    def test_options_unicode(self):
        self._write([u'[]', u'ption = x', '[b]', 'option = y'])
        config = self._read()
        self.assertEquals((u'ption', 'x'), iter(config.options(u'')).next())
        self.assertEquals(('option', 'y'), iter(config.options('b')).next())
        self.assertRaises(StopIteration, iter(config.options('c')).next)
        self.assertEquals(u'ption', iter(config['']).next())

        class Foo(object):
            option_a = Option(u'', u'ption2', 'c')

        self.assertEquals([(u'ption', 'x'), (u'ption2', 'c')],
                                list(config.options(u'')))

    def test_has_option(self):
        config = self._read()
        self.assertEquals(False, config.has_option('a', 'option'))
        self.assertEquals(False, 'option' in config['a'])
        self._write(['[a]', 'option = x'])
        config = self._read()
        self.assertEquals(True, config.has_option('a', 'option'))
        self.assertEquals(True, 'option' in config['a'])

        class Foo(object):
            option_a = Option('a', 'option2', 'x2')

        self.assertEquals(True, config.has_option('a', 'option2'))

    def test_has_option_unicode(self):
        config = self._read()
        self.assertEquals(False, config.has_option(u'', u'ption'))
        self.assertEquals(False, u'ption' in config[u''])
        self._write([u'[]', u'ption = x'])
        config = self._read()
        self.assertEquals(True, config.has_option(u'', u'ption'))
        self.assertEquals(True, u'ption' in config[u''])

        class Foo(object):
            option_a = Option(u'', u'ption2', 'x2')

        self.assertEquals(True, config.has_option(u'', u'ption2'))

    def test_reparse(self):
        self._write(['[a]', 'option = x'])
        config = self._read()
        self.assertEquals('x', config.get('a', 'option'))
        time.sleep(2) # needed because of low mtime granularity,
                      # especially on fat filesystems

        self._write(['[a]', 'option = y'])
        config.parse_if_needed()
        self.assertEquals('y', config.get('a', 'option'))

    def test_inherit_one_level(self):
        def testcb():
            config = self._read()
            self.assertEqual('x', config.get('a', 'option'))
            self.assertEqual(['a', 'inherit'], config.sections())
            config.remove('a', 'option') # Should *not* remove option in parent
            self.assertEqual('x', config.get('a', 'option'))
            self.assertEqual([('option', 'x')], list(config.options('a')))
            self.assertEqual(True, 'a' in config)
        self._test_with_inherit(testcb)

    def test_inherit_multiple(self):
        class Foo(object):
            option_b = Option('b', 'option2', 'default')
        base = os.path.dirname(self.filename)
        relsite1 = os.path.join('sub1', 'trac-site1.ini')
        site1 = os.path.join(base, relsite1)
        relsite2 = os.path.join('sub2', 'trac-site2.ini')
        site2 = os.path.join(base, relsite2)
        os.mkdir(os.path.dirname(site1))
        create_file(site1, '[a]\noption1 = x\n'
                           '[c]\noption = 1\npath1 = site1\n')
        try:
            os.mkdir(os.path.dirname(site2))
            create_file(site2, '[b]\noption2 = y\n'
                               '[c]\noption = 2\npath2 = site2\n')
            try:
                self._write(['[inherit]',
                             'file = %s, %s' % (relsite1, relsite2)])
                config = self._read()
                self.assertEqual('x', config.get('a', 'option1'))
                self.assertEqual('y', config.get('b', 'option2'))
                self.assertEqual('1', config.get('c', 'option'))
                self.assertEqual(os.path.join(base, 'site1'),
                                 config.getpath('c', 'path1'))
                self.assertEqual(os.path.join(base, 'site2'),
                                 config.getpath('c', 'path2'))
                self.assertEqual('',
                                 config.getpath('c', 'path3'))
                self.assertEqual(os.path.join(base, 'site4'),
                                 config.getpath('c', 'path4', 'site4'))
            finally:
                os.remove(site2)
                os.rmdir(os.path.dirname(site2))
        finally:
            os.remove(site1)
            os.rmdir(os.path.dirname(site1))

    def _test_with_inherit(self, testcb):
        sitename = os.path.join(tempfile.gettempdir(), 'trac-site.ini')
        try:
            with open(sitename, 'w') as sitefile:
                sitefile.write('[a]\noption = x\n')

            self._write(['[inherit]', 'file = trac-site.ini'])
            testcb()
        finally:
            os.remove(sitename)


def suite():
    return unittest.makeSuite(ConfigurationTestCase, 'test')

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = contentgen
#!/usr/bin/python

import random


try:
    all_words = [x.strip() for x in open('/usr/share/dict/words').readlines() if x.strip().isalpha()]
except Exception:
    all_words = [
        'one',
        'two',
        'three',
        'four',
        'five',
        'six',
        'seven',
        'eight',
        'nine',
        'ten',
    ]

def random_word():
    word = random.choice(all_words)
    # Do not return CamelCase words
    if word[0].isupper():
        word = word.lower().capitalize()
    return word

_random_unique_camels = []
def random_unique_camel():
    """Returns a unique camelcase word pair"""
    while True:
        camel = random_word().title() + random_word().title()
        if not camel in _random_unique_camels:
            break
    _random_unique_camels.append(camel)
    return camel

def random_sentence(word_count=None):
    if word_count == None:
        word_count = random.randint(1, 20)
    words = [random_word() for x in range(word_count)]
    return '%s.' % ' '.join(words)

def random_paragraph(sentence_count=None):
    if sentence_count == None:
        sentence_count = random.randint(1, 10)
    sentences = [random_sentence(random.randint(2, 15)) for x in range(sentence_count)]
    return '  '.join(sentences)

def random_page(paragraph_count=None):
    if paragraph_count == None:
        paragraph_count = random.randint(1, 10)
    paragraphs = [random_paragraph(random.randint(1, 5)) for x in range(paragraph_count)]
    return '\r\n\r\n'.join(paragraphs)

########NEW FILE########
__FILENAME__ = core
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from trac.core import *

import unittest


class ITest(Interface):
    def test():
        """Dummy function."""


class IOtherTest(Interface):
    def other_test():
        """Other dummy function."""


class ComponentTestCase(unittest.TestCase):

    def setUp(self):
        from trac.core import ComponentManager, ComponentMeta
        self.compmgr = ComponentManager()

        # Make sure we have no external components hanging around in the
        # component registry
        self.old_registry = ComponentMeta._registry
        ComponentMeta._registry = {}

    def tearDown(self):
        # Restore the original component registry
        from trac.core import ComponentMeta
        ComponentMeta._registry = self.old_registry

    def test_base_class_not_registered(self):
        """
        Make sure that the Component base class does not appear in the component
        registry.
        """
        from trac.core import ComponentMeta
        assert Component not in ComponentMeta._components
        self.assertRaises(TracError, self.compmgr.__getitem__, Component)

    def test_abstract_component_not_registered(self):
        """
        Make sure that a Component class marked as abstract does not appear in
        the component registry.
        """
        from trac.core import ComponentMeta
        class AbstractComponent(Component):
            abstract = True
        assert AbstractComponent not in ComponentMeta._components
        self.assertRaises(TracError, self.compmgr.__getitem__,
                          AbstractComponent)

    def test_unregistered_component(self):
        """
        Make sure the component manager refuses to manage classes not derived
        from `Component`.
        """
        class NoComponent(object):
            pass
        self.assertRaises(TracError, self.compmgr.__getitem__, NoComponent)

    def test_component_registration(self):
        """
        Verify that classes derived from `Component` are managed by the
        component manager.
        """
        class ComponentA(Component):
            pass
        assert self.compmgr[ComponentA]
        assert ComponentA(self.compmgr)

    def test_component_identity(self):
        """
        Make sure instantiating a component multiple times just returns the
        same instance again.
        """
        class ComponentA(Component):
            pass
        c1 = ComponentA(self.compmgr)
        c2 = ComponentA(self.compmgr)
        assert c1 is c2, 'Expected same component instance'
        c2 = self.compmgr[ComponentA]
        assert c1 is c2, 'Expected same component instance'

    def test_component_initializer(self):
        """
        Makes sure that a components' `__init__` method gets called.
        """
        class ComponentA(Component):
            def __init__(self):
                self.data = 'test'
        self.assertEqual('test', ComponentA(self.compmgr).data)
        ComponentA(self.compmgr).data = 'newtest'
        self.assertEqual('newtest', ComponentA(self.compmgr).data)

    def test_inherited_component_initializer(self):
        """
        Makes sure that a the `__init__` method of a components' super-class
        gets called if the component doesn't override it.
        """
        class ComponentA(Component):
            def __init__(self):
                self.data = 'foo'
        class ComponentB(ComponentA):
            def __init__(self):
                self.data = 'bar'
        class ComponentC(ComponentB):
            pass
        self.assertEqual('bar', ComponentC(self.compmgr).data)
        ComponentC(self.compmgr).data = 'baz'
        self.assertEqual('baz', ComponentC(self.compmgr).data)

    def test_implements_called_outside_classdef(self):
        """
        Verify that calling implements() outside a class definition raises an
        `AssertionError`.
        """
        try:
            implements()
        except AssertionError:
            pass
        else:
            self.fail('Expected AssertionError')

    def test_implements_multiple(self):
        """
        Verify that a component "implementing" an interface more than once
        (e.g. through inheritance) is not called more than once from an
        extension point.
        """
        log = []
        class Parent(Component):
            abstract = True
            implements(ITest)
        class Child(Parent):
            implements(ITest)
            def test(self):
                log.append("call")
        class Other(Component):
            tests = ExtensionPoint(ITest)
        for test in Other(self.compmgr).tests:
            test.test()
        self.assertEqual(["call"], log)

    def test_attribute_access(self):
        """
        Verify that accessing undefined attributes on components raises an
        `AttributeError`.
        """
        class ComponentA(Component):
            pass
        comp = ComponentA(self.compmgr)
        try:
            comp.foo
            self.fail('Expected AttributeError')
        except AttributeError:
            pass

    def test_nonconforming_extender(self):
        """
        Verify that accessing a method of a declared extension point interface
        raises a normal `AttributeError` if the component does not implement
        the method.
        """
        class ComponentA(Component):
            tests = ExtensionPoint(ITest)
        class ComponentB(Component):
            implements(ITest)
        tests = iter(ComponentA(self.compmgr).tests)
        try:
            tests.next().test()
            self.fail('Expected AttributeError')
        except AttributeError:
            pass

    def test_extension_point_with_no_extension(self):
        """
        Verify that accessing an extension point with no extenders returns an
        empty list.
        """
        class ComponentA(Component):
            tests = ExtensionPoint(ITest)
        tests = iter(ComponentA(self.compmgr).tests)
        self.assertRaises(StopIteration, tests.next)

    def test_extension_point_with_one_extension(self):
        """
        Verify that a single component extending an extension point can be
        accessed through the extension point attribute of the declaring
        component.
        """
        class ComponentA(Component):
            tests = ExtensionPoint(ITest)
        class ComponentB(Component):
            implements(ITest)
            def test(self):
                return 'x'
        tests = iter(ComponentA(self.compmgr).tests)
        self.assertEquals('x', tests.next().test())
        self.assertRaises(StopIteration, tests.next)

    def test_extension_point_with_two_extensions(self):
        """
        Verify that two components extending an extension point can be accessed
        through the extension point attribute of the declaring component.
        """
        class ComponentA(Component):
            tests = ExtensionPoint(ITest)
        class ComponentB(Component):
            implements(ITest)
            def test(self):
                return 'x'
        class ComponentC(Component):
            implements(ITest)
            def test(self):
                return 'y'
        results = [test.test() for test in ComponentA(self.compmgr).tests]
        self.assertEquals(['x', 'y'], sorted(results))

    def test_inherited_extension_point(self):
        """
        Verify that extension points are inherited to sub-classes.
        """
        class BaseComponent(Component):
            tests = ExtensionPoint(ITest)
        class ConcreteComponent(BaseComponent):
            pass
        class ExtendingComponent(Component):
            implements(ITest)
            def test(self):
                return 'x'
        tests = iter(ConcreteComponent(self.compmgr).tests)
        self.assertEquals('x', tests.next().test())
        self.assertRaises(StopIteration, tests.next)

    def test_inherited_implements(self):
        """
        Verify that a component with a super-class implementing an extension
        point interface is also registered as implementing that interface.
        """
        class BaseComponent(Component):
            implements(ITest)
            abstract = True
        class ConcreteComponent(BaseComponent):
            pass
        from trac.core import ComponentMeta
        assert ConcreteComponent in ComponentMeta._registry.get(ITest, [])

    def test_inherited_implements_multilevel(self):
        """
        Verify that extension point interfaces are inherited for more than
        one level of inheritance.
        """
        class BaseComponent(Component):
            implements(ITest)
            abstract = True
        class ChildComponent(BaseComponent):
            implements(IOtherTest)
            abstract = True
        class ConcreteComponent(ChildComponent):
            pass
        from trac.core import ComponentMeta
        assert ConcreteComponent in ComponentMeta._registry.get(ITest, [])
        assert ConcreteComponent in ComponentMeta._registry.get(IOtherTest, [])

    def test_component_manager_component(self):
        """
        Verify that a component manager can itself be a component with its own
        extension points.
        """
        from trac.core import ComponentManager
        class ManagerComponent(ComponentManager, Component):
            tests = ExtensionPoint(ITest)
            def __init__(self, foo, bar):
                ComponentManager.__init__(self)
                self.foo, self.bar = foo, bar
        class Extender(Component):
            implements(ITest)
            def test(self):
                return 'x'
        mgr = ManagerComponent('Test', 42)
        assert id(mgr) == id(mgr[ManagerComponent])
        tests = iter(mgr.tests)
        self.assertEquals('x', tests.next().test())
        self.assertRaises(StopIteration, tests.next)

    def test_component_manager_component_isolation(self):
        """
        Verify that a component manager that is also a component will only
        be listed in extension points for components instantiated in
        its scope.

        See bh:comment:5:ticket:438 and #11121
        """
        from trac.core import ComponentManager
        class ManagerComponent(ComponentManager, Component):
            tests = ExtensionPoint(ITest)
            def __init__(self, foo, bar):
                ComponentManager.__init__(self)
                self.foo, self.bar = foo, bar

        class YetAnotherManagerComponent(ComponentManager, Component):
            implements(ITest)
            def __init__(self, foo, bar):
                ComponentManager.__init__(self)
                self.foo, self.bar = foo, bar

            # ITest methods
            def test(self):
                return self.foo + self.bar

        class ComponentA(Component):
            tests = ExtensionPoint(ITest)

        class Extender(Component):
            implements(ITest)
            def test(self):
                return 'x'

        mgr = ManagerComponent('Test', 42)
        yamc = YetAnotherManagerComponent('y', 'z')

        assert yamc[ManagerComponent] is None 
        assert mgr[YetAnotherManagerComponent] is None 
        assert yamc[ComponentManager] is None 
        assert self.compmgr[YetAnotherManagerComponent] is None 
        assert mgr[ComponentManager] is None 
        assert self.compmgr[ManagerComponent] is None 

        self.assertTrue(any(c.__class__ is YetAnotherManagerComponent
                            for c in ComponentA(yamc).tests))
        self.assertFalse(any(c.__class__ is YetAnotherManagerComponent
                             for c in ComponentA(self.compmgr).tests))
        self.assertFalse(any(c.__class__ is YetAnotherManagerComponent
                             for c in ComponentA(mgr).tests))
        self.assertFalse(any(c.__class__ is ManagerComponent
                             for c in ComponentA(yamc).tests))
        self.assertFalse(any(c.__class__ is YetAnotherManagerComponent
                             for c in mgr.tests))

        results = [test.test() for test in ComponentA(yamc).tests]
        self.assertEquals(['x', 'yz'], sorted(results))

        results = [test.test() for test in ComponentA(self.compmgr).tests]
        self.assertEquals(['x'], sorted(results))

        results = [test.test() for test in ComponentA(mgr).tests]
        self.assertEquals(['x'], sorted(results))
        results = [test.test() for test in mgr.tests]
        self.assertEquals(['x'], sorted(results))

    def test_instantiation_doesnt_enable(self):
        """
        Make sure that a component disabled by the ComponentManager is not
        implicitly enabled by instantiating it directly.
        """
        from trac.core import ComponentManager
        class DisablingComponentManager(ComponentManager):
            def is_component_enabled(self, cls):
                return False
        class ComponentA(Component):
            pass
        mgr = DisablingComponentManager()
        instance = ComponentA(mgr)
        self.assertEqual(None, mgr[ComponentA])

def suite():
    return unittest.makeSuite(ComponentTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = env
from __future__ import with_statement

from trac import db_default
from trac.env import Environment

import os.path
import unittest
import tempfile
import shutil


class EnvironmentTestCase(unittest.TestCase):

    def setUp(self):
        env_path = os.path.join(tempfile.gettempdir(), 'trac-tempenv')
        self.addCleanup(self.cleanupEnvPath, env_path)
        self.env = Environment(env_path, create=True)

    def tearDown(self):
        with self.env.db_query as db:
            db.close()
        self.env.shutdown() # really closes the db connections
        shutil.rmtree(self.env.path)

    def cleanupEnvPath(self, path):
        if os.path.exists(path):
            shutil.rmtree(path)

    def test_get_version(self):
        """Testing env.get_version"""
        assert self.env.get_version() == db_default.db_version

    def test_get_known_users(self):
        """Testing env.get_known_users"""
        with self.env.db_transaction as db:
            db.executemany("INSERT INTO session VALUES (%s,%s,0)",
               [('123', 0),('tom', 1), ('joe', 1), ('jane', 1)])
            db.executemany("INSERT INTO session_attribute VALUES (%s,%s,%s,%s)",
               [('123', 0, 'email', 'a@example.com'),
                ('tom', 1, 'name', 'Tom'),
                ('tom', 1, 'email', 'tom@example.com'),
                ('joe', 1, 'email', 'joe@example.com'),
                ('jane', 1, 'name', 'Jane')])
        users = {}
        for username, name, email in self.env.get_known_users():
            users[username] = (name, email)

        assert not users.has_key('anonymous')
        self.assertEqual(('Tom', 'tom@example.com'), users['tom'])
        self.assertEqual((None, 'joe@example.com'), users['joe'])
        self.assertEqual(('Jane', None), users['jane'])


def suite():
    return unittest.makeSuite(EnvironmentTestCase,'test')

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = better_twill
#!/usr/bin/python
"""better_twill is a small wrapper around twill to set some sane defaults and
monkey-patch some better versions of some of twill's methods.
It also handles twill's absense.
"""

import os
from os.path import abspath, dirname, join
import sys
from pkg_resources import parse_version as pv
try:
    from cStringIO import StringIO
except ImportError:
    from StringIO import StringIO

# On OSX lxml needs to be imported before twill to avoid Resolver issues
# somehow caused by the mac specific 'ic' module
try:
    from lxml import etree
except ImportError:
    pass

try:
    import twill
except ImportError:
    twill = None

# When twill tries to connect to a site before the site is up, it raises an
# exception.  In 0.9b1, it's urlib2.URLError, but in -latest, it's
# twill.browser.BrowserStateError.
try:
    from twill.browser import BrowserStateError as ConnectError
except ImportError:
    from urllib2 import URLError as ConnectError


if twill:
    # We want Trac to generate valid html, and therefore want to test against
    # the html as generated by Trac.  "tidy" tries to clean up broken html, and
    # is responsible for one difficult to track down testcase failure (for
    # #5497).  Therefore we turn it off here.
    twill.commands.config('use_tidy', '0')

    # We use a transparent proxy to access the global browser object through
    # twill.get_browser(), as the browser can be destroyed by browser_reset()
    # (see #7472).
    class _BrowserProxy(object):
        def __getattribute__(self, name):
            return getattr(twill.get_browser(), name)

        def __setattr__(self, name, value):
            setattr(twill.get_browser(), name, value)

    # setup short names to reduce typing
    # This twill browser (and the tc commands that use it) are essentially
    # global, and not tied to our test fixture.
    tc = twill.commands
    b = _BrowserProxy()

    # Setup XHTML validation for all retrieved pages
    try:
        from lxml import etree
    except ImportError:
        print "SKIP: validation of XHTML output in functional tests " \
              "(no lxml installed)"
        etree = None

    if etree and pv(etree.__version__) < pv('2.0.0'):
        # 2.0.7 and 2.1.x are known to work.
        print "SKIP: validation of XHTML output in functional tests " \
              "(lxml < 2.0, api incompatibility)"
        etree = None

    if etree:
        class _Resolver(etree.Resolver):
            base_dir = dirname(abspath(__file__))

            def resolve(self, system_url, public_id, context):
                return self.resolve_filename(join(self.base_dir,
                                                  system_url.split("/")[-1]),
                                             context)

        _parser = etree.XMLParser(dtd_validation=True)
        _parser.resolvers.add(_Resolver())
        etree.set_default_parser(_parser)

        def _format_error_log(data, log):
            msg = []
            for entry in log:
                context = data.splitlines()[max(0, entry.line - 5):
                                            entry.line + 6]
                msg.append("\n# %s\n# URL: %s\n# Line %d, column %d\n\n%s\n"
                    % (entry.message, entry.filename,
                       entry.line, entry.column,
                       "\n".join([each.decode('utf-8') for each in context])))
            return "\n".join(msg).encode('ascii', 'xmlcharrefreplace')

        def _validate_xhtml(func_name, *args, **kwargs):
            page = b.get_html()
            if "xhtml1-strict.dtd" not in page:
                return
            etree.clear_error_log()
            try:
                # lxml will try to convert the URL to unicode by itself,
                # this won't work for non-ascii URLs, so help him
                url = b.get_url()
                if isinstance(url, str):
                    url = unicode(url, 'latin1')
                etree.parse(StringIO(page), base_url=url)
            except etree.XMLSyntaxError, e:
                raise twill.errors.TwillAssertionError(
                    _format_error_log(page, e.error_log))

        b._post_load_hooks.append(_validate_xhtml)

    # When we can't find something we expected, or find something we didn't
    # expect, it helps the debugging effort to have a copy of the html to
    # analyze.
    def twill_write_html():
        """Write the current html to a file.  Name the file based on the
        current testcase.
        """
        frame = sys._getframe()
        while frame:
            if frame.f_code.co_name in ('runTest', 'setUp', 'tearDown'):
                testcase = frame.f_locals['self']
                testname = testcase.__class__.__name__
                tracdir = testcase._testenv.tracdir
                break
            frame = frame.f_back
        else:
            # We didn't find a testcase in the stack, so we have no clue what's
            # going on.
            raise Exception("No testcase was found on the stack.  This was "
                "really not expected, and I don't know how to handle it.")

        filename = os.path.join(tracdir, 'log', "%s.html" % testname)
        html_file = open(filename, 'w')
        html_file.write(b.get_html())
        html_file.close()

        return filename

    # Twill isn't as helpful with errors as I'd like it to be, so we replace
    # the formvalue function.  This would be better done as a patch to Twill.
    def better_formvalue(form, field, value, fv=tc.formvalue):
        try:
            fv(form, field, value)
        except (twill.errors.TwillAssertionError,
                twill.utils.ClientForm.ItemNotFoundError), e:
            filename = twill_write_html()
            args = e.args + (filename,)
            raise twill.errors.TwillAssertionError(*args)
    tc.formvalue = better_formvalue
    tc.fv = better_formvalue

    # Twill requires that on pages with more than one form, you have to click a
    # field within the form before you can click submit.  There are a number of
    # cases where the first interaction a user would have with a form is
    # clicking on a button.  This enhancement allows us to specify the form to
    # click on.
    def better_browser_submit(fieldname=None, formname=None, browser=b, old_submit=b.submit):
        if formname is not None: # enhancement to directly specify the form
            browser._browser.form = browser.get_form(formname)
        old_submit(fieldname)

    b.submit = better_browser_submit
    def better_submit(fieldname=None, formname=None):
        b.submit(fieldname, formname)
    tc.submit = better_submit

    # Twill's formfile function leaves a filehandle open which prevents the
    # file from being deleted on Windows.  Since we would just assume use a
    # StringIO object in the first place, allow the file-like object to be
    # provided directly.
    def better_formfile(formname, fieldname, filename, content_type=None,
                        fp=None):
        if not fp:
            filename = filename.replace('/', os.path.sep)
            temp_fp = open(filename, 'rb')
            data = temp_fp.read()
            temp_fp.close()
            fp = StringIO(data)

        form = b.get_form(formname)
        control = b.get_form_field(form, fieldname)

        if not control.is_of_kind('file'):
            raise twill.errors.TwillException('ERROR: field is not a file '
                                              'upload field!')

        b.clicked(form, control)
        control.add_file(fp, content_type, filename)
    tc.formfile = better_formfile

    # Twill's tc.find() does not provide any guidance on what we got instead of
    # what was expected.
    def better_find(what, flags='', tcfind=tc.find):
        try:
            tcfind(what, flags)
        except twill.errors.TwillAssertionError, e:
            filename = twill_write_html()
            args = e.args + (filename,)
            raise twill.errors.TwillAssertionError(*args)
    tc.find = better_find
    def better_notfind(what, flags='', tcnotfind=tc.notfind):
        try:
            tcnotfind(what, flags)
        except twill.errors.TwillAssertionError, e:
            filename = twill_write_html()
            args = e.args + (filename,)
            raise twill.errors.TwillAssertionError(*args)
    tc.notfind = better_notfind
    # Same for tc.url - no hint about what went wrong!
    def better_url(should_be, tcurl=tc.url):
        try:
            tcurl(should_be)
        except twill.errors.TwillAssertionError, e:
            filename = twill_write_html()
            args = e.args + (filename,)
            raise twill.errors.TwillAssertionError(*args)
    tc.url = better_url
else:
    b = tc = None

########NEW FILE########
__FILENAME__ = compat
#!/usr/bin/python
import os
import shutil

from trac.util.compat import close_fds

# On Windows, shutil.rmtree doesn't remove files with the read-only
# attribute set, so this function explicitly removes it on every error
# before retrying.  Even on Linux, shutil.rmtree chokes on read-only
# directories, so we use this version in all cases.
# Fix from http://bitten.edgewall.org/changeset/521
def rmtree(root):
    """Catch shutil.rmtree failures on Windows when files are read-only."""
    def _handle_error(fn, path, excinfo):
        os.chmod(path, 0666)
        fn(path)
    return shutil.rmtree(root, onerror=_handle_error)


########NEW FILE########
__FILENAME__ = svntestenv
import os
import re
from subprocess import call

from testenv import FunctionalTestEnvironment
from trac.tests.functional.compat import close_fds
from trac.tests.functional import logfile

class SvnFunctionalTestEnvironment(FunctionalTestEnvironment):
    def work_dir(self):
        return os.path.join(self.dirname, 'workdir')

    def repo_path_for_initenv(self):
        return os.path.join(self.dirname, 'repo')

    def create_repo(self):
        """
        Initialize a repo of the type :attr:`self.repotype`.
        """
        if call(["svnadmin", "create", self.repo_path_for_initenv()],
                 stdout=logfile, stderr=logfile, close_fds=close_fds):
            raise Exception('unable to create subversion repository')
        if call(['svn', 'co', self.repo_url(), self.work_dir()], stdout=logfile,
                 stderr=logfile, close_fds=close_fds):
            raise Exception('Checkout from %s failed.' % self.repo_url())

    def destroy_repo(self):
        """The deletion of the testenvironment will remove the repo as well."""
        pass

    def repo_url(self):
        """Returns the url of the Subversion repository for this test
        environment.
        """
        repodir = self.repo_path_for_initenv()
        if os.name == 'nt':
            return 'file:///' + repodir.replace("\\", "/")
        else:
            return 'file://' + repodir

    def svn_mkdir(self, paths, msg, username='admin'):
        """Subversion helper to create a new directory within the main
        repository.  Operates directly on the repository url, so a working
        copy need not exist.

        Example::

            self._testenv.svn_mkdir(["abc", "def"], "Add dirs")

        """
        self.call_in_workdir(['svn', '--username=%s' % username, 'mkdir', '-m', msg]
                + [self.repo_url() + '/' + d for d in paths])
        self.call_in_workdir(['svn', 'update'])

    def svn_add(self, filename, data):
        """Subversion helper to add a file to the given path within the main
        repository.

        Example::

            self._testenv.svn_add("root.txt", "Hello World")

        """
        f = open(os.path.join(self.work_dir(), filename), 'w')
        f.write(data)
        f.close()
        self.call_in_workdir(['svn', 'add', filename])
        environ = os.environ.copy()
        environ['LC_ALL'] = 'C'     # Force English messages in svn
        output = self.call_in_workdir(['svn', '--username=admin', 'commit', '-m',
                        'Add %s' % filename, filename], environ=environ)
        try:
            revision = re.search(r'Committed revision ([0-9]+)\.',
                                 output).group(1)
        except Exception, e:
            args = e.args + (output, )
            raise Exception(*args)
        return int(revision)


########NEW FILE########
__FILENAME__ = testcases
# -*- encoding: utf-8 -*-
#!/usr/bin/python
import os
from trac.tests.functional import *


class RegressionTestRev6017(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of the plugin reload fix in r6017"""
        # Setup the DeleteTicket plugin
        plugin = open(os.path.join(self._testenv.command_cwd, 'sample-plugins',
            'workflow', 'DeleteTicket.py')).read()
        open(os.path.join(self._testenv.tracdir, 'plugins', 'DeleteTicket.py'),
             'w').write(plugin)
        env = self._testenv.get_trac_environment()
        prevconfig = env.config.get('ticket', 'workflow')
        env.config.set('ticket', 'workflow',
                       prevconfig + ',DeleteTicketActionController')
        env.config.save()
        env = self._testenv.get_trac_environment() # reloads the environment

        loaded_components = env.compmgr.__metaclass__._components
        delete_plugins = [c for c in loaded_components
                          if 'DeleteTicketActionController' in c.__name__]
        try:
            self.assertEqual(len(delete_plugins), 1,
                             "Plugin loaded more than once.")

        finally:
            # Remove the DeleteTicket plugin
            env.config.set('ticket', 'workflow', prevconfig)
            env.config.save()
            self._testenv.restart()
            for ext in ('py', 'pyc', 'pyo'):
                filename = os.path.join(self._testenv.tracdir, 'plugins',
                                        'DeleteTicket.%s' % ext)
                if os.path.exists(filename):
                    os.unlink(filename)


class RegressionTestTicket3833a(FunctionalTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/3833 a"""
        # Assume the logging is already set to debug.
        traclogfile = open(os.path.join(self._testenv.tracdir, 'log',
                                        'trac.log'))
        # Seek to the end of file so we only look at new log output
        traclogfile.seek(0, 2)
        # Verify that logging is on initially
        env = self._testenv.get_trac_environment()

        env.log.debug("RegressionTestTicket3833 debug1")
        debug1 = traclogfile.read()
        self.assertNotEqual(debug1.find("RegressionTestTicket3833 debug1"), -1,
            'Logging off when it should have been on.\n%r' % debug1)


class RegressionTestTicket3833b(FunctionalTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/3833 b"""
        # Turn logging off, try to log something, and verify that it does
        # not show up.
        traclogfile = open(os.path.join(self._testenv.tracdir, 'log',
                                        'trac.log'))
        # Seek to the end of file so we only look at new log output
        traclogfile.seek(0, 2)
        env = self._testenv.get_trac_environment()

        env.config.set('logging', 'log_level', 'INFO')
        env.config.save()
        env = self._testenv.get_trac_environment()
        env.log.debug("RegressionTestTicket3833 debug2")
        env.log.info("RegressionTestTicket3833 info2")
        debug2 = traclogfile.read()
        self.assertNotEqual(debug2.find("RegressionTestTicket3833 info2"), -1,
                            'Logging at info failed.\n%r' % debug2)
        self.assertEqual(debug2.find("RegressionTestTicket3833 debug2"), -1,
            'Logging still on when it should have been off.\n%r' % debug2)


class RegressionTestTicket3833c(FunctionalTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/3833 c"""
        # Turn logging back on, try to log something, and verify that it
        # does show up.
        traclogfile = open(os.path.join(self._testenv.tracdir, 'log',
                                        'trac.log'))
        # Seek to the end of file so we only look at new log output
        traclogfile.seek(0, 2)
        env = self._testenv.get_trac_environment()

        env.config.set('logging', 'log_level', 'DEBUG')
        time.sleep(2)
        env.config.save()
        #time.sleep(2)
        env = self._testenv.get_trac_environment()
        #time.sleep(2)
        env.log.debug("RegressionTestTicket3833 debug3")
        env.log.info("RegressionTestTicket3833 info3")
        #time.sleep(2)
        debug3 = traclogfile.read()
        message = ''
        success = debug3.find("RegressionTestTicket3833 debug3") != -1
        if not success:
            # Ok, the testcase failed, but we really need logging enabled.
            self._testenv.restart()
            env.log.debug("RegressionTestTicket3833 fixup3")
            fixup3 = traclogfile.read()
            message = 'Logging still off when it should have been on.\n' \
                      '%r\n%r' % (debug3, fixup3)
        self.assert_(success, message)


class RegressionTestTicket5572(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5572"""
        # TODO: this ticket (implemented in r6011) adds a new feature to
        # make the progress bar more configurable.  We need to test this
        # new configurability.


class RegressionTestTicket7209(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/7209"""
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.create_ticket()
        self._tester.add_comment(ticketid)
        self._tester.attach_file_to_ticket(ticketid, tempfilename='hello.txt',
                                           description='Preserved Descr')
        self._tester.go_to_ticket(ticketid)
        tc.find('Preserved Descr')
        # Now replace the existing attachment, and the description should come
        # through.
        self._tester.attach_file_to_ticket(ticketid, tempfilename='hello.txt',
                                           description='', replace=True)
        self._tester.go_to_ticket(ticketid)
        tc.find('Preserved Descr')

        self._tester.attach_file_to_ticket(ticketid, tempfilename='blah.txt',
                                           description='Second Attachment')
        self._tester.go_to_ticket(ticketid)
        tc.find('Second Attachment')

        # This one should get a new description when it's replaced
        # (Second->Other)
        self._tester.attach_file_to_ticket(ticketid, tempfilename='blah.txt',
                                           description='Other Attachment',
                                           replace=True)
        self._tester.go_to_ticket(ticketid)
        tc.find('Other Attachment')
        tc.notfind('Second Attachment')


class RegressionTestTicket9880(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/9880

        Upload of a file which the browsers associates a Content-Type
        of multipart/related (e.g. an .mht file) should succeed.
        """
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.create_ticket()
        self._tester.attach_file_to_ticket(ticketid, tempfilename='hello.mht',
                                           content_type='multipart/related',
                                           data="""
Well, the actual content of the file doesn't matter, the problem is
related to the "multipart/..." content_type associated to the file.
See also http://bugs.python.org/issue15564.
""")


class ErrorPageValidation(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Validate the error page"""
        url = self._tester.url + '/wiki/WikiStart'
        tc.go(url + '?version=bug')
        tc.url(url)
        tc.find(internal_error)


class RegressionTestTicket3663(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Regression test for non-UTF-8 PATH_INFO (#3663)

        Verify that URLs not encoded with UTF-8 are reported as invalid.
        """
        # invalid PATH_INFO
        self._tester.go_to_wiki(u't'.encode('latin1'))
        tc.code(404)
        tc.find('Invalid URL encoding')
        # invalid SCRIPT_NAME
        tc.go(u't'.encode('latin1'))
        tc.code(404)
        tc.find('Invalid URL encoding')


def functionalSuite():
    suite = FunctionalTestSuite()
    return suite


def suite():
    suite = functionalSuite()

    suite.addTest(RegressionTestRev6017())
    suite.addTest(RegressionTestTicket3833a())
    suite.addTest(RegressionTestTicket3833b())
    suite.addTest(RegressionTestTicket3833c())
    suite.addTest(RegressionTestTicket5572())
    suite.addTest(RegressionTestTicket7209())
    suite.addTest(RegressionTestTicket9880())
    suite.addTest(ErrorPageValidation())
    suite.addTest(RegressionTestTicket3663())

    import trac.versioncontrol.tests
    trac.versioncontrol.tests.functionalSuite(suite)
    import trac.ticket.tests
    trac.ticket.tests.functionalSuite(suite)
    import trac.prefs.tests
    trac.prefs.tests.functionalSuite(suite)
    import trac.wiki.tests
    trac.wiki.tests.functionalSuite(suite)
    import trac.timeline.tests
    trac.timeline.tests.functionalSuite(suite)
    import trac.admin.tests
    trac.admin.tests.functionalSuite(suite)
    # The db tests should be last since the backup test occurs there.
    import trac.db.tests
    trac.db.tests.functionalSuite(suite)

    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = testenv
#!/usr/bin/python
# -*- coding: utf-8 -*-
#
"""Object for creating and destroying a Trac environment for testing purposes.
Provides some Trac environment-wide utility functions, and a way to call
:command:`trac-admin` without it being on the path."""

import os
import time
import signal
import sys
import errno
import locale
from subprocess import call, Popen, PIPE, STDOUT

from trac.env import open_environment
from trac.test import EnvironmentStub, get_dburi
from trac.tests.functional.compat import rmtree
from trac.tests.functional import logfile
from trac.tests.functional.better_twill import tc, ConnectError
from trac.util.compat import close_fds

# TODO: refactor to support testing multiple frontends, backends
#       (and maybe repositories and authentication).
#
#     Frontends::
#       tracd, ap2+mod_python, ap2+mod_wsgi, ap2+mod_fastcgi, ap2+cgi,
#       lighty+fastcgi, lighty+cgi, cherrypy+wsgi
#
#     Backends::
#       sqlite3+pysqlite2, postgres+psycopg2 python bindings,
#       mysql+mysqldb with server v4, mysql+mysqldb with server v5
#       (those need to test search escaping, among many other things like long
#       paths in browser and unicode chars being allowed/translating...)

class FunctionalTestEnvironment(object):
    """Common location for convenience functions that work with the test
    environment on Trac.  Subclass this and override some methods if you are
    using a different :term:`VCS`.

    :class:`FunctionalTestEnvironment` requires a `dirname` in which
    the test repository and Trac environment will be created, `port`
    for the :command:`tracd` webserver to run on, and the `url` which
    can access this (usually ``localhost``).
    """

    def __init__(self, dirname, port, url):
        """Create a :class:`FunctionalTestEnvironment`, see the class itself
        for parameter information."""
        self.url = url
        self.command_cwd = os.path.normpath(os.path.join(dirname, '..'))
        self.dirname = os.path.abspath(dirname)
        self.tracdir = os.path.join(self.dirname, "trac")
        self.htpasswd = os.path.join(self.dirname, "htpasswd")
        self.port = port
        self.pid = None
        self.init()
        self.destroy()
        time.sleep(0.1) # Avoid race condition on Windows
        self.create()
        locale.setlocale(locale.LC_ALL, '')

    trac_src = '.'

    @property
    def dburi(self):
        dburi = get_dburi()
        if dburi == 'sqlite::memory:':
            # functional tests obviously can't work with the in-memory database
            dburi = 'sqlite:db/trac.db'
        return dburi

    def destroy(self):
        """Remove all of the test environment data."""
        env = EnvironmentStub(path=self.tracdir, destroying=True)
        env.destroy_db()
        env.shutdown()

        self.destroy_repo()
        if os.path.exists(self.dirname):
            rmtree(self.dirname)

    repotype = 'svn'

    def init(self):
        """ Hook for modifying settings or class attributes before
        any methods are called. """
        pass

    def create_repo(self):
        """Hook for creating the repository."""
        # The default test environment does not include a source repo

    def destroy_repo(self):
        """Hook for removing the repository."""
        # The default test environment does not include a source repo

    def post_create(self, env):
        """Hook for modifying the environment after creation.  For example, to
        set configuration like::

            def post_create(self, env):
                env.config.set('git', 'path', '/usr/bin/git')
                env.config.save()
        """
        pass

    def get_enabled_components(self):
        """Return a list of components that should be enabled after
        environment creation.  For anything more complicated, use the
        :meth:`post_create` method.
        """
        return ['tracopt.versioncontrol.svn.*']

    def create(self):
        """Create a new test environment.
        This sets up Trac, calls :meth:`create_repo` and sets up
        authentication.
        """
        os.mkdir(self.dirname)
        self.create_repo()

        self._tracadmin('initenv', self.tracdir, self.dburi, self.repotype,
                        self.repo_path_for_initenv())
        if call([sys.executable,
                 os.path.join(self.trac_src, 'contrib', 'htpasswd.py'), "-c",
                 "-b", self.htpasswd, "admin", "admin"], close_fds=close_fds,
                 cwd=self.command_cwd):
            raise Exception('Unable to setup admin password')
        self.adduser('user')
        self._tracadmin('permission', 'add', 'admin', 'TRAC_ADMIN')
        # Setup Trac logging
        env = self.get_trac_environment()
        env.config.set('logging', 'log_type', 'file')
        for component in self.get_enabled_components():
            env.config.set('components', component, 'enabled')
        env.config.save()
        self.post_create(env)

    def adduser(self, user):
        """Add a user to the environment.  The password will be set to the
        same as username."""
        if call([sys.executable, os.path.join(self.trac_src, 'contrib',
                 'htpasswd.py'), '-b', self.htpasswd,
                 user, user], close_fds=close_fds, cwd=self.command_cwd):
            raise Exception('Unable to setup password for user "%s"' % user)

    def _tracadmin(self, *args):
        """Internal utility method for calling trac-admin"""
        proc = Popen([sys.executable, os.path.join(self.trac_src, 'trac',
                      'admin', 'console.py'), self.tracdir]
                      + list(args), stdout=PIPE, stderr=STDOUT,
                      close_fds=close_fds, cwd=self.command_cwd)
        out = proc.communicate()[0]
        if proc.returncode:
            print(out)
            logfile.write(out)
            raise Exception('Failed with exitcode %s running trac-admin ' \
                            'with %r' % (proc.returncode, args))

    def start(self):
        """Starts the webserver, and waits for it to come up."""
        if 'FIGLEAF' in os.environ:
            exe = os.environ['FIGLEAF']
            if ' ' in exe: # e.g. 'coverage run'
                args = exe.split()
            else:
                args = [exe]
        else:
            args = [sys.executable]
        options = ["--port=%s" % self.port, "-s", "--hostname=127.0.0.1",
                   "--basic-auth=trac,%s," % self.htpasswd]
        if 'TRAC_TEST_TRACD_OPTIONS' in os.environ:
            options += os.environ['TRAC_TEST_TRACD_OPTIONS'].split()
        args.append(os.path.join(self.trac_src, 'trac', 'web',
                                 'standalone.py'))
        server = Popen(args + options + [self.tracdir],
                       stdout=logfile, stderr=logfile,
                       close_fds=close_fds,
                       cwd=self.command_cwd,
                      )
        self.pid = server.pid
        # Verify that the url is ok
        timeout = 30
        while timeout:
            try:
                tc.go(self.url)
                break
            except ConnectError:
                time.sleep(1)
            timeout -= 1
        else:
            raise Exception('Timed out waiting for server to start.')
        tc.url(self.url)

    def stop(self):
        """Stops the webserver, if running

        FIXME: probably needs a nicer way to exit for coverage to work
        """
        if self.pid:
            if os.name == 'nt':
                # Untested
                res = call(["taskkill", "/f", "/pid", str(self.pid)],
                     stdin=PIPE, stdout=PIPE, stderr=PIPE)
            else:
                os.kill(self.pid, signal.SIGTERM)
                try:
                    os.waitpid(self.pid, 0)
                except OSError, e:
                    if e.errno != errno.ESRCH:
                        raise

    def restart(self):
        """Restarts the webserver"""
        self.stop()
        self.start()

    def get_trac_environment(self):
        """Returns a Trac environment object"""
        return open_environment(self.tracdir, use_cache=True)

    def repo_path_for_initenv(self):
        """Default to no repository"""
        return "''" # needed for Python 2.3 and 2.4 on win32

    def call_in_workdir(self, args, environ=None):
        proc = Popen(args, stdout=PIPE, stderr=logfile,
                     close_fds=close_fds, cwd=self.work_dir(), env=environ)
        (data, _) = proc.communicate()
        if proc.wait():
            raise Exception('Unable to run command %s in %s' %
                            (args, self.work_dir()))

        logfile.write(data)
        return data

########NEW FILE########
__FILENAME__ = tester
#!/usr/bin/python
"""The :class:`FunctionalTester` object provides a higher-level interface to
working with a Trac environment to make test cases more succinct.
"""

from trac.tests.functional import internal_error
from trac.tests.functional.better_twill import tc, b
from trac.tests.contentgen import random_page, random_sentence, random_word, \
    random_unique_camel
from trac.util.text import unicode_quote

try:
    from cStringIO import StringIO
except ImportError:
    from StringIO import StringIO

class FunctionalTester(object):
    """Provides a library of higher-level operations for interacting with a
    test environment.

    It makes assumptions such as knowing what ticket number is next, so
    avoid doing things manually in a :class:`FunctionalTestCase` when you can.
    """

    def __init__(self, url):
        """Create a :class:`FunctionalTester` for the given Trac URL and
        Subversion URL"""
        self.url = url
        self.ticketcount = 0

        # Connect, and login so we can run tests.
        self.go_to_front()
        self.login('admin')

    def login(self, username):
        """Login as the given user"""
        tc.add_auth("", self.url, username, username)
        self.go_to_front()
        tc.find("Login")
        tc.follow("Login")
        # We've provided authentication info earlier, so this should
        # redirect back to the base url.
        tc.find("logged in as %s" % username)
        tc.find("Logout")
        tc.url(self.url)
        tc.notfind(internal_error)

    def logout(self):
        """Logout"""
        tc.follow("Logout")
        tc.notfind(internal_error)

    def create_ticket(self, summary=None, info=None):
        """Create a new (random) ticket in the test environment.  Returns
        the new ticket number.

        :param summary:
            may optionally be set to the desired summary
        :param info:
            may optionally be set to a dictionary of field value pairs for
            populating the ticket.  ``info['summary']`` overrides summary.

        `summary` and `description` default to randomly-generated values.
        """
        self.go_to_front()
        tc.follow('New Ticket')
        tc.notfind(internal_error)
        if summary == None:
            summary = random_sentence(4)
        tc.formvalue('propertyform', 'field_summary', summary)
        tc.formvalue('propertyform', 'field_description', random_page())
        if info:
            for field, value in info.items():
                tc.formvalue('propertyform', 'field_%s' % field, value)
        tc.submit('submit')
        # we should be looking at the newly created ticket
        tc.url(self.url + '/ticket/%s' % (self.ticketcount + 1))
        # Increment self.ticketcount /after/ we've verified that the ticket
        # was created so a failure does not trigger spurious later
        # failures.
        self.ticketcount += 1

        # verify the ticket creation event shows up in the timeline
        self.go_to_timeline()
        tc.formvalue('prefs', 'ticket', True)
        tc.submit()
        tc.find('Ticket.*#%s.*created' % self.ticketcount)

        return self.ticketcount

    def quickjump(self, search):
        """Do a quick search to jump to a page."""
        tc.formvalue('search', 'q', search)
        tc.submit()
        tc.notfind(internal_error)

    def go_to_front(self):
        """Go to the Trac front page"""
        tc.go(self.url)
        tc.url(self.url)
        tc.notfind(internal_error)

    def go_to_ticket(self, ticketid):
        """Surf to the page for the given ticket ID.  Assumes ticket
        exists."""
        ticket_url = self.url + "/ticket/%s" % ticketid
        tc.go(ticket_url)
        tc.url(ticket_url)

    def go_to_wiki(self, name):
        """Surf to the page for the given wiki page."""
        # Used to go based on a quickjump, but if the wiki pagename isn't
        # camel case, that won't work.
        wiki_url = self.url + '/wiki/%s' % name
        tc.go(wiki_url)
        tc.url(wiki_url)

    def go_to_timeline(self):
        """Surf to the timeline page."""
        self.go_to_front()
        tc.follow('Timeline')
        tc.url(self.url + '/timeline')

    def go_to_query(self):
        """Surf to the custom query page."""
        self.go_to_front()
        tc.follow('View Tickets')
        tc.follow('Custom Query')
        tc.url(self.url + '/query')

    def go_to_admin(self):
        """Surf to the webadmin page."""
        self.go_to_front()
        tc.follow('\\bAdmin\\b')

    def go_to_roadmap(self):
        """Surf to the roadmap page."""
        self.go_to_front()
        tc.follow('\\bRoadmap\\b')
        tc.url(self.url + '/roadmap')

    def add_comment(self, ticketid, comment=None):
        """Adds a comment to the given ticket ID, assumes ticket exists."""
        self.go_to_ticket(ticketid)
        if comment is None:
            comment = random_sentence()
        tc.formvalue('propertyform', 'comment', comment)
        tc.submit("submit")
        # Verify we're where we're supposed to be.
        # The fragment is stripped since Python 2.7.1, see:
        # http://trac.edgewall.org/ticket/9990#comment:18
        tc.url(self.url + '/ticket/%s(?:#comment:.*)?$' % ticketid)
        return comment

    def attach_file_to_ticket(self, ticketid, data=None, tempfilename=None,
                              description=None, replace=False,
                              content_type=None):
        """Attaches a file to the given ticket id, with random data if none is
        provided.  Assumes the ticket exists.
        """
        if data is None:
            data = random_page()
        if description is None:
            description = random_sentence()
        if tempfilename is None:
            tempfilename = random_word()

        self.go_to_ticket(ticketid)
        # set the value to what it already is, so that twill will know we
        # want this form.
        tc.formvalue('attachfile', 'action', 'new')
        tc.submit()
        tc.url(self.url + "/attachment/ticket/" \
               "%s/\\?action=new&attachfilebutton=Attach\\+file" % ticketid)
        fp = StringIO(data)
        tc.formfile('attachment', 'attachment', tempfilename,
                    content_type=content_type, fp=fp)
        tc.formvalue('attachment', 'description', description)
        if replace:
            tc.formvalue('attachment', 'replace', True)
        tc.submit()
        tc.url(self.url + '/attachment/ticket/%s/$' % ticketid)
        return tempfilename

    def clone_ticket(self, ticketid):
        """Create a clone of the given ticket id using the clone button."""
        ticket_url = self.url + '/ticket/%s' % ticketid
        tc.go(ticket_url)
        tc.url(ticket_url)
        tc.formvalue('clone', 'clone', 'Clone')
        tc.submit()
        # we should be looking at the newly created ticket
        self.ticketcount += 1
        tc.url(self.url + "/ticket/%s" % self.ticketcount)
        return self.ticketcount

    def create_wiki_page(self, page, content=None):
        """Creates the specified wiki page, with random content if none is
        provided.
        """
        if content == None:
            content = random_page()
        page_url = self.url + "/wiki/" + page
        tc.go(page_url)
        tc.url(page_url)
        tc.find("The page %s does not exist." % page)
        tc.formvalue('modifypage', 'action', 'edit')
        tc.submit()
        tc.url(page_url + '\\?action=edit')

        tc.formvalue('edit', 'text', content)
        tc.submit('save')
        tc.url(page_url+'$')

        # verify the event shows up in the timeline
        self.go_to_timeline()
        tc.formvalue('prefs', 'wiki', True)
        tc.submit()
        tc.find(page + ".*created")

    def attach_file_to_wiki(self, name, data=None, tempfilename=None):
        """Attaches a file to the given wiki page, with random content if none
        is provided.  Assumes the wiki page exists.
        """
        if data == None:
            data = random_page()
        if tempfilename is None:
            tempfilename = random_word()
        self.go_to_wiki(name)
        # set the value to what it already is, so that twill will know we
        # want this form.
        tc.formvalue('attachfile', 'action', 'new')
        tc.submit()
        tc.url(self.url + "/attachment/wiki/" \
               "%s/\\?action=new&attachfilebutton=Attach\\+file" % name)
        fp = StringIO(data)
        tc.formfile('attachment', 'attachment', tempfilename, fp=fp)
        tc.formvalue('attachment', 'description', random_sentence())
        tc.submit()
        tc.url(self.url + '/attachment/wiki/%s/$' % name)
        return tempfilename

    def create_milestone(self, name=None, due=None):
        """Creates the specified milestone, with a random name if none is
        provided.  Returns the name of the milestone.
        """
        if name == None:
            name = random_unique_camel()
        milestone_url = self.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.url(milestone_url)
        tc.formvalue('addmilestone', 'name', name)
        if due:
            # TODO: How should we deal with differences in date formats?
            tc.formvalue('addmilestone', 'duedate', due)
        tc.submit()
        tc.notfind(internal_error)
        tc.notfind('Milestone .* already exists')
        tc.url(milestone_url)
        tc.find(name)

        # Make sure it's on the roadmap.
        tc.follow('Roadmap')
        tc.url(self.url + "/roadmap")
        tc.find('Milestone:.*%s' % name)
        tc.follow(name)
        tc.url('%s/milestone/%s' % (self.url, unicode_quote(name)))
        if not due:
            tc.find('No date set')

        return name

    def create_component(self, name=None, user=None):
        """Creates the specified component, with a random camel-cased name if
        none is provided.  Returns the name."""
        if name == None:
            name = random_unique_camel()
        component_url = self.url + "/admin/ticket/components"
        tc.go(component_url)
        tc.url(component_url)
        tc.formvalue('addcomponent', 'name', name)
        if user != None:
            tc.formvalue('addcomponent', 'owner', user)
        tc.submit()
        # Verify the component appears in the component list
        tc.url(component_url)
        tc.find(name)
        tc.notfind(internal_error)
        # TODO: verify the component shows up in the newticket page
        return name

    def create_enum(self, kind, name=None):
        """Helper to create the specified enum (used for ``priority``,
        ``severity``, etc). If no name is given, a unique random word is used.
        The name is returned.
        """
        if name == None:
            name = random_unique_camel()
        priority_url = self.url + "/admin/ticket/" + kind
        tc.go(priority_url)
        tc.url(priority_url)
        tc.formvalue('addenum', 'name', name)
        tc.submit()
        tc.url(priority_url)
        tc.find(name)
        tc.notfind(internal_error)
        return name

    def create_priority(self, name=None):
        """Create a new priority enum"""
        return self.create_enum('priority', name)

    def create_resolution(self, name=None):
        """Create a new resolution enum"""
        return self.create_enum('resolution', name)

    def create_severity(self, name=None):
        """Create a new severity enum"""
        return self.create_enum('severity', name)

    def create_type(self, name=None):
        """Create a new ticket type enum"""
        return self.create_enum('type', name)

    def create_version(self, name=None, releasetime=None):
        """Create a new version.  The name defaults to a random camel-cased
        word if not provided."""
        version_admin = self.url + "/admin/ticket/versions"
        if name == None:
            name = random_unique_camel()
        tc.go(version_admin)
        tc.url(version_admin)
        tc.formvalue('addversion', 'name', name)
        if releasetime != None:
            tc.formvalue('addversion', 'time', releasetime)
        tc.submit()
        tc.url(version_admin)
        tc.find(name)
        tc.notfind(internal_error)
        # TODO: verify releasetime

    def create_report(self, title, query, description):
        """Create a new report with the given title, query, and description"""
        self.go_to_front()
        tc.follow('View Tickets')
        tc.formvalue('create_report', 'action', 'new') # select the right form
        tc.submit()
        tc.find('New Report')
        tc.notfind(internal_error)
        tc.formvalue('edit_report', 'title', title)
        tc.formvalue('edit_report', 'description', description)
        tc.formvalue('edit_report', 'query', query)
        tc.submit()
        reportnum = b.get_url().split('/')[-1]
        # TODO: verify the url is correct
        # TODO: verify the report number is correct
        # TODO: verify the report does not cause an internal error
        # TODO: verify the title appears on the report list
        return reportnum

    def ticket_set_milestone(self, ticketid, milestone):
        """Set the milestone on a given ticket."""
        self.go_to_ticket(ticketid)
        tc.formvalue('propertyform', 'milestone', milestone)
        tc.submit('submit')
        # TODO: verify the change occurred.

########NEW FILE########
__FILENAME__ = notification
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2006 Emmanuel Blot <emmanuel.blot@free.fr>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Include a basic SMTP server, based on L. Smithson
# (lsmithson@open-networks.co.uk) extensible Python SMTP Server
#
# This file does not contain unit tests, but provides a set of
# classes to run SMTP notification tests
#

import socket
import string
import threading
import re
import base64
import quopri


LF = '\n'
CR = '\r'
email_re = re.compile(r"([\w\d_\.\-])+\@(([\w\d\-])+\.)+([\w\d]{2,4})+")
header_re = re.compile(r'^=\?(?P<charset>[\w\d\-]+)\?(?P<code>[qb])\?(?P<value>.*)\?=$')


class SMTPServerInterface:
    """
    A base class for the imlementation of an application specific SMTP
    Server. Applications should subclass this and overide these
    methods, which by default do nothing.

    A method is defined for each RFC821 command. For each of these
    methods, 'args' is the complete command received from the
    client. The 'data' method is called after all of the client DATA
    is received.

    If a method returns 'None', then a '250 OK'message is
    automatically sent to the client. If a subclass returns a non-null
    string then it is returned instead.
    """

    def helo(self, args):
        return None

    def mail_from(self, args):
        return None

    def rcpt_to(self, args):
        return None

    def data(self, args):
        return None

    def quit(self, args):
        return None

    def reset(self, args):
        return None

#
# Some helper functions for manipulating from & to addresses etc.
#

def strip_address(address):
    """
    Strip the leading & trailing <> from an address.  Handy for
    getting FROM: addresses.
    """
    start = string.index(address, '<') + 1
    end = string.index(address, '>')
    return address[start:end]

def split_to(address):
    """
    Return 'address' as undressed (host, fulladdress) tuple.
    Handy for use with TO: addresses.
    """
    start = string.index(address, '<') + 1
    sep = string.index(address, '@') + 1
    end = string.index(address, '>')
    return (address[sep:end], address[start:end],)


#
# This drives the state for a single RFC821 message.
#
class SMTPServerEngine:
    """
    Server engine that calls methods on the SMTPServerInterface object
    passed at construction time. It is constructed with a bound socket
    connection to a client. The 'chug' method drives the state,
    returning when the client RFC821 transaction is complete.
    """

    ST_INIT = 0
    ST_HELO = 1
    ST_MAIL = 2
    ST_RCPT = 3
    ST_DATA = 4
    ST_QUIT = 5

    def __init__(self, socket, impl):
        self.impl = impl
        self.socket = socket
        self.state = SMTPServerEngine.ST_INIT

    def chug(self):
        """
        Chug the engine, till QUIT is received from the client. As
        each RFC821 message is received, calls are made on the
        SMTPServerInterface methods on the object passed at
        construction time.
        """
        self.socket.send("220 Welcome to Trac notification test server\r\n")
        while 1:
            data = ''
            completeLine = 0
            # Make sure an entire line is received before handing off
            # to the state engine. Thanks to John Hall for pointing
            # this out.
            while not completeLine:
                try:
                    lump = self.socket.recv(1024)
                    if len(lump):
                        data += lump
                        if (len(data) >= 2) and data[-2:] == '\r\n':
                            completeLine = 1
                            if self.state != SMTPServerEngine.ST_DATA:
                                rsp, keep = self.do_command(data)
                            else:
                                rsp = self.do_data(data)
                                if rsp == None:
                                    continue
                            self.socket.send(rsp + "\r\n")
                            if keep == 0:
                                self.socket.close()
                                return
                    else:
                        # EOF
                        return
                except socket.error:
                    return

    def do_command(self, data):
        """Process a single SMTP Command"""
        cmd = data[0:4]
        cmd = string.upper(cmd)
        keep = 1
        rv = None
        if cmd == "HELO":
            self.state = SMTPServerEngine.ST_HELO
            rv = self.impl.helo(data[5:])
        elif cmd == "RSET":
            rv = self.impl.reset(data[5:])
            self.data_accum = ""
            self.state = SMTPServerEngine.ST_INIT
        elif cmd == "NOOP":
            pass
        elif cmd == "QUIT":
            rv = self.impl.quit(data[5:])
            keep = 0
        elif cmd == "MAIL":
            if self.state != SMTPServerEngine.ST_HELO:
                return ("503 Bad command sequence", 1)
            self.state = SMTPServerEngine.ST_MAIL
            rv = self.impl.mail_from(data[5:])
        elif cmd == "RCPT":
            if (self.state != SMTPServerEngine.ST_MAIL) and \
               (self.state != SMTPServerEngine.ST_RCPT):
                return ("503 Bad command sequence", 1)
            self.state = SMTPServerEngine.ST_RCPT
            rv = self.impl.rcpt_to(data[5:])
        elif cmd == "DATA":
            if self.state != SMTPServerEngine.ST_RCPT:
                return ("503 Bad command sequence", 1)
            self.state = SMTPServerEngine.ST_DATA
            self.data_accum = ""
            return ("354 OK, Enter data, terminated with a \\r\\n.\\r\\n", 1)
        else:
            return ("505 Eh? WTF was that?", 1)

        if rv:
            return (rv, keep)
        else:
            return("250 OK", keep)

    def do_data(self, data):
        """
        Process SMTP Data. Accumulates client DATA until the
        terminator is found.
        """
        self.data_accum = self.data_accum + data
        if len(self.data_accum) > 4 and self.data_accum[-5:] == '\r\n.\r\n':
            self.data_accum = self.data_accum[:-5]
            rv = self.impl.data(self.data_accum)
            self.state = SMTPServerEngine.ST_HELO
            if rv:
                return rv
            else:
                return "250 OK - Data and terminator. found"
        else:
            return None


class SMTPServer:
    """
    A single threaded SMTP Server connection manager. Listens for
    incoming SMTP connections on a given port. For each connection,
    the SMTPServerEngine is chugged, passing the given instance of
    SMTPServerInterface.
    """

    def __init__(self, port):
        self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self._socket.bind(("127.0.0.1", port))
        self._socket_service = None

    def serve(self, impl):
        while ( self._resume ):
            try:
                nsd = self._socket.accept()
            except socket.error:
                return
            self._socket_service = nsd[0]
            engine = SMTPServerEngine(self._socket_service, impl)
            engine.chug()
            self._socket_service = None

    def start(self):
        self._socket.listen(1)
        self._resume = True

    def stop(self):
        self._resume = False

    def terminate(self):
        if self._socket_service:
            # force the blocking socket to stop waiting for data
            try:
                #self._socket_service.shutdown(2)
                self._socket_service.close()
            except AttributeError:
                # the SMTP server may also discard the socket
                pass
            self._socket_service = None
        if self._socket:
            #self._socket.shutdown(2)
            self._socket.close()
            self._socket = None


class SMTPServerStore(SMTPServerInterface):
    """
    Simple store for SMTP data
    """

    def __init__(self):
        self.reset(None)

    def helo(self, args):
        self.reset(None)

    def mail_from(self, args):
        if args.lower().startswith('from:'):
            self.sender = strip_address(args[5:].replace('\r\n','').strip())

    def rcpt_to(self, args):
        if args.lower().startswith('to:'):
            rcpt = args[3:].replace('\r\n','').strip()
            self.recipients.append(strip_address(rcpt))

    def data(self, args):
        self.message = args

    def quit(self, args):
        pass

    def reset(self, args):
        self.sender = None
        self.recipients = []
        self.message = None


class SMTPThreadedServer(threading.Thread):
    """
    Run a SMTP server for a single connection, within a dedicated thread
    """

    def __init__(self, port):
        self.port = port
        self.server = SMTPServer(port)
        self.store  = SMTPServerStore()
        threading.Thread.__init__(self)

    def run(self):
        # run from within the SMTP server thread
        self.server.serve(impl = self.store)

    def start(self):
        # run from the main thread
        self.server.start()
        threading.Thread.start(self)

    def stop(self):
        # run from the main thread
        self.server.stop()
        # send a message to make the SMTP server quit gracefully
        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        try:
            s.connect(('127.0.0.1', self.port))
            r = s.send("QUIT\r\n")
        except socket.error:
            pass
        s.close()
        # wait for the SMTP server to complete (for up to 2 secs)
        self.join(2.0)
        # clean up the SMTP server (and force quit if needed)
        self.server.terminate()

    def get_sender(self):
        return self.store.sender

    def get_recipients(self):
        return self.store.recipients

    def get_message(self):
        return self.store.message

    def cleanup(self):
        self.store.reset(None)


def smtp_address(fulladdr):
    mo = email_re.search(fulladdr)
    if mo:
        return mo.group(0)
    if start >= 0:
        return fulladdr[start+1:-1]
    return fulladdr


def decode_header(header):
    """ Decode a MIME-encoded header value """
    mo = header_re.match(header)
    # header does not seem to be MIME-encoded
    if not mo:
        return header
    # attempts to decode the hedear,
    # following the specified MIME endoding and charset
    try:
        encoding = mo.group('code').lower()
        if encoding  == 'q':
            val = quopri.decodestring(mo.group('value'), header=True)
        elif encoding == 'b':
            val = base64.decodestring(mo.group('value'))
        else:
            raise AssertionError, "unsupported encoding: %s" % encoding
        header = unicode(val, mo.group('charset'))
    except Exception, e:
        raise AssertionError, e
    return header


def parse_smtp_message(msg):
    """ Split a SMTP message into its headers and body.
        Returns a (headers, body) tuple
        We do not use the email/MIME Python facilities here
        as they may accept invalid RFC822 data, or data we do not
        want to support nor generate """
    headers = {}
    lh = None
    body = None
    # last line does not contain the final line ending
    msg += '\r\n'
    for line in msg.splitlines(True):
        if body != None:
            # append current line to the body
            if line[-2] == CR:
                body += line[0:-2]
                body += '\n'
            else:
                raise AssertionError, "body misses CRLF: %s (0x%x)" \
                                      % (line, ord(line[-1]))
        else:
            if line[-2] != CR:
                # RFC822 requires CRLF at end of field line
                raise AssertionError, "header field misses CRLF: %s (0x%x)" \
                                      % (line, ord(line[-1]))
            # discards CR
            line = line[0:-2]
            if line.strip() == '':
                # end of headers, body starts
                body = ''
            else:
                val = None
                if line[0] in ' \t':
                    # continution of the previous line
                    if not lh:
                        # unexpected multiline
                        raise AssertionError, \
                             "unexpected folded line: %s" % line
                    val = decode_header(line.strip(' \t'))
                    # appends the current line to the previous one
                    if not isinstance(headers[lh], tuple):
                        headers[lh] += val
                    else:
                        headers[lh][-1] = headers[lh][-1] + val
                else:
                    # splits header name from value
                    (h, v) = line.split(':', 1)
                    val = decode_header(v.strip())
                    if headers.has_key(h):
                        if isinstance(headers[h], tuple):
                            headers[h] += val
                        else:
                            headers[h] = (headers[h], val)
                    else:
                        headers[h] = val
                    # stores the last header (for multilines headers)
                    lh = h
    # returns the headers and the message body
    return (headers, body)

########NEW FILE########
__FILENAME__ = perm
from trac import perm
from trac.core import *
from trac.test import EnvironmentStub

import unittest


class DefaultPermissionStoreTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(enable=[perm.DefaultPermissionStore,
                                           perm.DefaultPermissionGroupProvider])
        self.store = perm.DefaultPermissionStore(self.env)

    def tearDown(self):
        self.env.reset_db()

    def test_simple_actions(self):
        self.env.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('john', 'WIKI_MODIFY'),
             ('john', 'REPORT_ADMIN'),
             ('kate', 'TICKET_CREATE')])
        self.assertEquals(['REPORT_ADMIN', 'WIKI_MODIFY'],
                          sorted(self.store.get_user_permissions('john')))
        self.assertEquals(['TICKET_CREATE'],
                          self.store.get_user_permissions('kate'))

    def test_simple_group(self):
        self.env.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('dev', 'WIKI_MODIFY'),
             ('dev', 'REPORT_ADMIN'),
             ('john', 'dev')])
        self.assertEquals(['REPORT_ADMIN', 'WIKI_MODIFY'],
                          sorted(self.store.get_user_permissions('john')))

    def test_nested_groups(self):
        self.env.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('dev', 'WIKI_MODIFY'),
             ('dev', 'REPORT_ADMIN'),
             ('admin', 'dev'),
             ('john', 'admin')])
        self.assertEquals(['REPORT_ADMIN', 'WIKI_MODIFY'],
                          sorted(self.store.get_user_permissions('john')))

    def test_mixed_case_group(self):
        self.env.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('Dev', 'WIKI_MODIFY'),
             ('Dev', 'REPORT_ADMIN'),
             ('Admin', 'Dev'),
             ('john', 'Admin')])
        self.assertEquals(['REPORT_ADMIN', 'WIKI_MODIFY'],
                          sorted(self.store.get_user_permissions('john')))

    def test_builtin_groups(self):
        self.env.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('authenticated', 'WIKI_MODIFY'),
             ('authenticated', 'REPORT_ADMIN'),
             ('anonymous', 'TICKET_CREATE')])
        self.assertEquals(['REPORT_ADMIN', 'TICKET_CREATE', 'WIKI_MODIFY'],
                          sorted(self.store.get_user_permissions('john')))
        self.assertEquals(['TICKET_CREATE'],
                          self.store.get_user_permissions('anonymous'))

    def test_get_all_permissions(self):
        self.env.db_transaction.executemany(
            "INSERT INTO permission VALUES (%s,%s)",
            [('dev', 'WIKI_MODIFY'),
             ('dev', 'REPORT_ADMIN'),
             ('john', 'dev')])
        expected = [('dev', 'WIKI_MODIFY'),
                    ('dev', 'REPORT_ADMIN'),
                    ('john', 'dev')]
        for res in self.store.get_all_permissions():
            self.failIf(res not in expected)


class TestPermissionRequestor(Component):
    implements(perm.IPermissionRequestor)

    def get_permission_actions(self):
        return ['TEST_CREATE', 'TEST_DELETE', 'TEST_MODIFY',
                ('TEST_CREATE', []),
                ('TEST_ADMIN', ['TEST_CREATE', 'TEST_DELETE']),
                ('TEST_ADMIN', ['TEST_MODIFY'])]


class PermissionSystemTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(enable=[perm.PermissionSystem,
                                           perm.DefaultPermissionStore,
                                           TestPermissionRequestor])
        self.perm = perm.PermissionSystem(self.env)

    def tearDown(self):
        self.env.reset_db()

    def test_all_permissions(self):
        self.assertEqual({'EMAIL_VIEW': True, 'TRAC_ADMIN': True,
                          'TEST_CREATE': True, 'TEST_DELETE': True,
                          'TEST_MODIFY': True,  'TEST_ADMIN': True},
                         self.perm.get_user_permissions())

    def test_simple_permissions(self):
        self.perm.grant_permission('bob', 'TEST_CREATE')
        self.perm.grant_permission('jane', 'TEST_DELETE')
        self.perm.grant_permission('jane', 'TEST_MODIFY')
        self.assertEqual({'TEST_CREATE': True},
                         self.perm.get_user_permissions('bob'))
        self.assertEqual({'TEST_DELETE': True, 'TEST_MODIFY': True},
                         self.perm.get_user_permissions('jane'))

    def test_meta_permissions(self):
        self.perm.grant_permission('bob', 'TEST_CREATE')
        self.perm.grant_permission('jane', 'TEST_ADMIN')
        self.assertEqual({'TEST_CREATE': True},
                         self.perm.get_user_permissions('bob'))
        self.assertEqual({'TEST_CREATE': True, 'TEST_DELETE': True,
                          'TEST_MODIFY': True,  'TEST_ADMIN': True},
                         self.perm.get_user_permissions('jane'))

    def test_get_all_permissions(self):
        self.perm.grant_permission('bob', 'TEST_CREATE')
        self.perm.grant_permission('jane', 'TEST_ADMIN')
        expected = [('bob', 'TEST_CREATE'),
                    ('jane', 'TEST_ADMIN')]
        for res in self.perm.get_all_permissions():
            self.failIf(res not in expected)

    def test_expand_actions_iter_7467(self):
        # Check that expand_actions works with iterators (#7467)
        perms = set(['EMAIL_VIEW', 'TRAC_ADMIN', 'TEST_DELETE', 'TEST_MODIFY',
                     'TEST_CREATE', 'TEST_ADMIN'])
        self.assertEqual(perms, self.perm.expand_actions(['TRAC_ADMIN']))
        self.assertEqual(perms, self.perm.expand_actions(iter(['TRAC_ADMIN'])))


class PermissionCacheTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(enable=[perm.DefaultPermissionStore,
                                           perm.DefaultPermissionPolicy,
                                           TestPermissionRequestor])
        self.perm_system = perm.PermissionSystem(self.env)
        # by-pass DefaultPermissionPolicy cache:
        perm.DefaultPermissionPolicy.CACHE_EXPIRY = -1
        self.perm_system.grant_permission('testuser', 'TEST_MODIFY')
        self.perm_system.grant_permission('testuser', 'TEST_ADMIN')
        self.perm = perm.PermissionCache(self.env, 'testuser')

    def tearDown(self):
        self.env.reset_db()

    def test_contains(self):
        self.assertEqual(True, 'TEST_MODIFY' in self.perm)
        self.assertEqual(True, 'TEST_ADMIN' in self.perm)
        self.assertEqual(False, 'TRAC_ADMIN' in self.perm)

    def test_has_permission(self):
        self.assertEqual(True, self.perm.has_permission('TEST_MODIFY'))
        self.assertEqual(True, self.perm.has_permission('TEST_ADMIN'))
        self.assertEqual(False, self.perm.has_permission('TRAC_ADMIN'))

    def test_require(self):
        self.perm.require('TEST_MODIFY')
        self.perm.require('TEST_ADMIN')
        self.assertRaises(perm.PermissionError, self.perm.require, 'TRAC_ADMIN')

    def test_assert_permission(self):
        self.perm.assert_permission('TEST_MODIFY')
        self.perm.assert_permission('TEST_ADMIN')
        self.assertRaises(perm.PermissionError,
                          self.perm.assert_permission, 'TRAC_ADMIN')

    def test_cache(self):
        self.perm.assert_permission('TEST_MODIFY')
        self.perm.assert_permission('TEST_ADMIN')
        self.perm_system.revoke_permission('testuser', 'TEST_ADMIN')
        # Using cached GRANT here
        self.perm.assert_permission('TEST_ADMIN')

    def test_cache_shared(self):
        # we need to start with an empty cache here (#7201)
        perm1 = perm.PermissionCache(self.env, 'testcache')
        perm1 = perm1('ticket', 1)
        perm2 = perm1('ticket', 1) # share internal cache
        self.perm_system.grant_permission('testcache', 'TEST_ADMIN')
        perm1.assert_permission('TEST_ADMIN')
        self.perm_system.revoke_permission('testcache', 'TEST_ADMIN')
        # Using cached GRANT here (from shared cache)
        perm2.assert_permission('TEST_ADMIN')


class TestPermissionPolicy(Component):
    implements(perm.IPermissionPolicy)

    def __init__(self):
        self.allowed = {}
        self.results = {}

    def grant(self, username, permissions):
        self.allowed.setdefault(username, set()).update(permissions)

    def revoke(self, username, permissions):
        self.allowed.setdefault(username, set()).difference_update(permissions)

    def check_permission(self, action, username, resource, perm):
        result = action in self.allowed.get(username, set()) or None
        self.results[(username, action)] = result
        return result


class PermissionPolicyTestCase(unittest.TestCase):
    def setUp(self):
        self.env = EnvironmentStub(enable=[perm.DefaultPermissionStore,
                                           perm.DefaultPermissionPolicy,
                                           TestPermissionPolicy,
                                           TestPermissionRequestor])
        self.env.config.set('trac', 'permission_policies', 'TestPermissionPolicy')
        self.policy = TestPermissionPolicy(self.env)
        self.perm = perm.PermissionCache(self.env, 'testuser')

    def tearDown(self):
        self.env.reset_db()

    def test_no_permissions(self):
        self.assertRaises(perm.PermissionError,
                          self.perm.assert_permission, 'TEST_MODIFY')
        self.assertRaises(perm.PermissionError,
                          self.perm.assert_permission, 'TEST_ADMIN')
        self.assertEqual(self.policy.results,
                         {('testuser', 'TEST_MODIFY'): None,
                          ('testuser', 'TEST_ADMIN'): None})

    def test_grant_revoke_permissions(self):
        self.policy.grant('testuser', ['TEST_MODIFY', 'TEST_ADMIN'])
        self.assertEqual('TEST_MODIFY' in self.perm, True)
        self.assertEqual('TEST_ADMIN' in self.perm, True)
        self.assertEqual(self.policy.results,
                         {('testuser', 'TEST_MODIFY'): True,
                          ('testuser', 'TEST_ADMIN'): True})

    def test_policy_chaining(self):
        self.env.config.set('trac', 'permission_policies', 'TestPermissionPolicy,DefaultPermissionPolicy')
        self.policy.grant('testuser', ['TEST_MODIFY'])
        system = perm.PermissionSystem(self.env)
        system.grant_permission('testuser', 'TEST_ADMIN')

        self.assertEqual(list(system.policies),
                         [self.policy,
                          perm.DefaultPermissionPolicy(self.env)])
        self.assertEqual('TEST_MODIFY' in self.perm, True)
        self.assertEqual('TEST_ADMIN' in self.perm, True)
        self.assertEqual(self.policy.results,
                         {('testuser', 'TEST_MODIFY'): True,
                          ('testuser', 'TEST_ADMIN'): None})
def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(DefaultPermissionStoreTestCase, 'test'))
    suite.addTest(unittest.makeSuite(PermissionSystemTestCase, 'test'))
    suite.addTest(unittest.makeSuite(PermissionCacheTestCase, 'test'))
    suite.addTest(unittest.makeSuite(PermissionPolicyTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = resource
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import doctest
import unittest

from trac import resource
from trac.resource import IResourceChangeListener
from trac.core import implements, Component


class ResourceTestCase(unittest.TestCase):

    def test_equals(self):
        # Plain equalities
        self.assertEqual(resource.Resource(), resource.Resource())
        self.assertEqual(resource.Resource(None), resource.Resource())
        self.assertEqual(resource.Resource('wiki'), resource.Resource('wiki'))
        self.assertEqual(resource.Resource('wiki', 'WikiStart'),
                         resource.Resource('wiki', 'WikiStart'))
        self.assertEqual(resource.Resource('wiki', 'WikiStart', 42),
                         resource.Resource('wiki', 'WikiStart', 42))
        # Inequalities
        self.assertNotEqual(resource.Resource('wiki', 'WikiStart', 42),
                            resource.Resource('wiki', 'WikiStart', 43))
        self.assertNotEqual(resource.Resource('wiki', 'WikiStart', 0),
                            resource.Resource('wiki', 'WikiStart', None))
        # Resource hierarchy
        r1 = resource.Resource('attachment', 'file.txt')
        r1.parent = resource.Resource('wiki', 'WikiStart')
        r2 = resource.Resource('attachment', 'file.txt')
        r2.parent = resource.Resource('wiki', 'WikiStart')
        self.assertEqual(r1, r2)
        r2.parent = r2.parent(version=42)
        self.assertNotEqual(r1, r2)


class NeighborhoodTestCase(unittest.TestCase):

    def test_equals(self):
        # Plain equalities
        self.assertEqual(resource.Neighborhood(), resource.Neighborhood())
        self.assertEqual(resource.Neighborhood(None), resource.Neighborhood())
        self.assertEqual(resource.Neighborhood('realm'), 
                         resource.Neighborhood('realm'))
        self.assertEqual(resource.Neighborhood('realm', 'id'),
                         resource.Neighborhood('realm', 'id'))
        # Inequalities
        self.assertNotEqual(resource.Neighborhood('realm', 'id'),
                            resource.Neighborhood('realm', 'id1'))
        self.assertNotEqual(resource.Neighborhood('realm1', 'id'),
                            resource.Neighborhood('realm', 'id'))

    def test_resources_equals(self):
        nbh = resource.Neighborhood('realm', 'id')
        nbh1 = resource.Neighborhood('realm', 'id1')
        # Plain equalities
        self.assertEqual(nbh(resource.Resource()), nbh(resource.Resource()))
        self.assertEqual(nbh(resource.Resource(None)), nbh(resource.Resource()))
        self.assertEqual(nbh(resource.Resource('wiki')), 
                         nbh(resource.Resource('wiki')))
        self.assertEqual(nbh(resource.Resource('wiki', 'WikiStart')),
                         nbh(resource.Resource('wiki', 'WikiStart')))
        self.assertEqual(nbh(resource.Resource('wiki', 'WikiStart', 42)),
                         nbh(resource.Resource('wiki', 'WikiStart', 42)))
        # Inequalities
        self.assertNotEqual(nbh(resource.Resource('wiki', 'WikiStart', 42)),
                            nbh(resource.Resource('wiki', 'WikiStart', 43)))
        self.assertNotEqual(nbh(resource.Resource('wiki', 'WikiStart', 0)),
                            nbh(resource.Resource('wiki', 'WikiStart', None)))
        self.assertNotEqual(nbh1(resource.Resource()), 
                            nbh(resource.Resource()))
        self.assertNotEqual(nbh1(resource.Resource(None)), 
                            nbh(resource.Resource()))
        self.assertNotEqual(nbh1(resource.Resource('wiki')), 
                            nbh(resource.Resource('wiki')))
        self.assertNotEqual(nbh1(resource.Resource('wiki', 'WikiStart')),
                            nbh(resource.Resource('wiki', 'WikiStart')))
        self.assertNotEqual(nbh1(resource.Resource('wiki', 'WikiStart', 42)),
                            nbh(resource.Resource('wiki', 'WikiStart', 42)))
        # Resource hierarchy
        r1 = nbh(resource.Resource('attachment', 'file.txt'))
        r1.parent = nbh(resource.Resource('wiki', 'WikiStart'))
        r2 = nbh(resource.Resource('attachment', 'file.txt'))
        r2.parent = nbh(resource.Resource('wiki', 'WikiStart'))
        self.assertEqual(r1, r2)
        r2.parent = r2.parent(version=42)
        self.assertNotEqual(r1, r2)

    def test_hierarchy_clone(self):
        def enum_parents(r):
            while r is not None:
                yield r
                r = r.parent

        nbh = resource.Neighborhood('realm', 'id')
        nbh1 = resource.Neighborhood('realm', 'id1')

        src = resource.Resource('attachment', 'file.txt')
        src.parent = resource.Resource('wiki', 'WikiStart')
        src.parent.parent = resource.Resource('x', 'y')

        self.assertTrue(all(r.neighborhood is nbh 
                            for r in enum_parents(nbh(src))))
        self.assertTrue(all(r.neighborhood is None 
                            for r in enum_parents(src)))

        src = nbh1(src)
        self.assertTrue(all(r.neighborhood is nbh 
                            for r in enum_parents(nbh(src))))
        self.assertTrue(all(r.neighborhood is nbh1 
                            for r in enum_parents(src)))


class TestResourceChangeListener(Component):
    implements(IResourceChangeListener)

    def __init__(self):
        self.resource_type = None

    def callback(self, action, resource, context, old_values = None):
        pass

    def match_resource(self, resource):
        if self.resource_type is None:
            return False
        return isinstance(resource, self.resource_type)

    def resource_created(self, resource, context):
        self.action = "created"
        self.resource = resource
        self.context = context
        self.callback(self.action, resource, context)

    def resource_changed(self, resource, old_values, context):
        self.action = "changed"
        self.resource = resource
        self.old_values = old_values
        self.context = context
        self.callback(
            self.action, resource, context, old_values=self.old_values)

    def resource_deleted(self, resource, context):
        self.action = "deleted"
        self.resource = resource
        self.context = context
        self.callback(self.action, resource, context)

    def resource_version_deleted(self, resource, context):
        self.action = "version_deleted"
        self.resource = resource
        self.context = context
        self.callback(self.action, resource, context)

def suite():
    suite = unittest.TestSuite()
    suite.addTest(doctest.DocTestSuite(resource))
    suite.addTest(unittest.makeSuite(ResourceTestCase, 'test'))
    suite.addTest(unittest.makeSuite(NeighborhoodTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = wikisyntax
import os
import shutil
import tempfile
import unittest

from trac.attachment import Attachment
from trac.mimeview.api import RenderingContext
from trac.resource import Resource
from trac.search.web_ui import SearchModule
from trac.test import MockPerm
from trac.web.href import Href
from trac.wiki.tests import formatter

SEARCH_TEST_CASES = u"""
============================== search: link resolver
search:foo
search:"foo bar"
[search:bar Bar]
[search:bar]
[search:]
------------------------------
<p>
<a class="search" href="/search?q=foo">search:foo</a>
<a class="search" href="/search?q=foo+bar">search:"foo bar"</a>
<a class="search" href="/search?q=bar">Bar</a>
<a class="search" href="/search?q=bar">bar</a>
<a class="search" href="/search">search</a>
</p>
------------------------------
============================== search: link resolver with query arguments
search:foo?wiki=on
search:?q=foo&wiki=on
search:"foo bar?wiki=on"
search:"?q=foo bar&wiki=on"
[search:bar?ticket=on Bar in Tickets]
[search:?q=bar&ticket=on Bar in Tickets]
------------------------------
<p>
<a class="search" href="/search?q=foo&amp;wiki=on">search:foo?wiki=on</a>
<a class="search" href="/search?q=foo&amp;wiki=on">search:?q=foo&amp;wiki=on</a>
<a class="search" href="/search?q=foo+bar&amp;wiki=on">search:"foo bar?wiki=on"</a>
<a class="search" href="/search?q=foo+bar&amp;wiki=on">search:"?q=foo bar&amp;wiki=on"</a>
<a class="search" href="/search?q=bar&amp;ticket=on">Bar in Tickets</a>
<a class="search" href="/search?q=bar&amp;ticket=on">Bar in Tickets</a>
</p>
------------------------------
"""

ATTACHMENT_TEST_CASES = u"""
============================== attachment: link resolver (deprecated)
attachment:wiki:WikiStart:file.txt (deprecated)
attachment:ticket:123:file.txt (deprecated)
[attachment:wiki:WikiStart:file.txt file.txt] (deprecated)
[attachment:ticket:123:file.txt] (deprecated)
------------------------------
<p>
<a class="attachment" href="/attachment/wiki/WikiStart/file.txt" title="Attachment 'file.txt' in WikiStart">attachment:wiki:WikiStart:file.txt</a><a class="trac-rawlink" href="/raw-attachment/wiki/WikiStart/file.txt" title="Download"></a> (deprecated)
<a class="attachment" href="/attachment/ticket/123/file.txt" title="Attachment 'file.txt' in Ticket #123">attachment:ticket:123:file.txt</a><a class="trac-rawlink" href="/raw-attachment/ticket/123/file.txt" title="Download"></a> (deprecated)
<a class="attachment" href="/attachment/wiki/WikiStart/file.txt" title="Attachment 'file.txt' in WikiStart">file.txt</a><a class="trac-rawlink" href="/raw-attachment/wiki/WikiStart/file.txt" title="Download"></a> (deprecated)
<a class="attachment" href="/attachment/ticket/123/file.txt" title="Attachment 'file.txt' in Ticket #123">ticket:123:file.txt</a><a class="trac-rawlink" href="/raw-attachment/ticket/123/file.txt" title="Download"></a> (deprecated)
</p>
------------------------------
============================== attachment: "foreign" links
attachment:file.txt:wiki:WikiStart
attachment:file.txt:ticket:123
[attachment:file.txt:wiki:WikiStart file.txt]
[attachment:file.txt:ticket:123]
attachment:foo.txt:wiki:SomePage/SubPage
------------------------------
<p>
<a class="attachment" href="/attachment/wiki/WikiStart/file.txt" title="Attachment 'file.txt' in WikiStart">attachment:file.txt:wiki:WikiStart</a><a class="trac-rawlink" href="/raw-attachment/wiki/WikiStart/file.txt" title="Download"></a>
<a class="attachment" href="/attachment/ticket/123/file.txt" title="Attachment 'file.txt' in Ticket #123">attachment:file.txt:ticket:123</a><a class="trac-rawlink" href="/raw-attachment/ticket/123/file.txt" title="Download"></a>
<a class="attachment" href="/attachment/wiki/WikiStart/file.txt" title="Attachment 'file.txt' in WikiStart">file.txt</a><a class="trac-rawlink" href="/raw-attachment/wiki/WikiStart/file.txt" title="Download"></a>
<a class="attachment" href="/attachment/ticket/123/file.txt" title="Attachment 'file.txt' in Ticket #123">file.txt:ticket:123</a><a class="trac-rawlink" href="/raw-attachment/ticket/123/file.txt" title="Download"></a>
<a class="attachment" href="/attachment/wiki/SomePage/SubPage/foo.txt" title="Attachment 'foo.txt' in SomePage/SubPage">attachment:foo.txt:wiki:SomePage/SubPage</a><a class="trac-rawlink" href="/raw-attachment/wiki/SomePage/SubPage/foo.txt" title="Download"></a>
</p>
------------------------------
============================== attachment: "local" links
attachment:file.txt
[attachment:file.txt that file]
------------------------------
<p>
<a class="attachment" href="/attachment/wiki/WikiStart/file.txt" title="Attachment 'file.txt' in WikiStart">attachment:file.txt</a><a class="trac-rawlink" href="/raw-attachment/wiki/WikiStart/file.txt" title="Download"></a>
<a class="attachment" href="/attachment/wiki/WikiStart/file.txt" title="Attachment 'file.txt' in WikiStart">that file</a><a class="trac-rawlink" href="/raw-attachment/wiki/WikiStart/file.txt" title="Download"></a>
</p>
------------------------------
============================== attachment: "missing" links
attachment:foo.txt
[attachment:foo.txt other file]
------------------------------
<p>
<a class="missing attachment">attachment:foo.txt</a>
<a class="missing attachment">other file</a>
</p>
------------------------------
============================== attachment: "raw" links
raw-attachment:file.txt
[raw-attachment:file.txt that file]
------------------------------
<p>
<a class="attachment" href="/raw-attachment/wiki/WikiStart/file.txt" title="Attachment 'file.txt' in WikiStart">raw-attachment:file.txt</a>
<a class="attachment" href="/raw-attachment/wiki/WikiStart/file.txt" title="Attachment 'file.txt' in WikiStart">that file</a>
</p>
------------------------------
============================== attachment: raw format as explicit argument
attachment:file.txt?format=raw
[attachment:file.txt?format=raw that file]
------------------------------
<p>
<a class="attachment" href="/attachment/wiki/WikiStart/file.txt?format=raw" title="Attachment 'file.txt' in WikiStart">attachment:file.txt?format=raw</a><a class="trac-rawlink" href="/raw-attachment/wiki/WikiStart/file.txt?format=raw" title="Download"></a>
<a class="attachment" href="/attachment/wiki/WikiStart/file.txt?format=raw" title="Attachment 'file.txt' in WikiStart">that file</a><a class="trac-rawlink" href="/raw-attachment/wiki/WikiStart/file.txt?format=raw" title="Download"></a>
</p>
------------------------------
""" # "

def attachment_setup(tc):
    import trac.ticket.api
    import trac.wiki.api
    tc.env.path = os.path.join(tempfile.gettempdir(), 'trac-tempenv')
    os.mkdir(tc.env.path)
    attachment = Attachment(tc.env, 'wiki', 'WikiStart')
    attachment.insert('file.txt', tempfile.TemporaryFile(), 0)
    attachment = Attachment(tc.env, 'ticket', 123)
    attachment.insert('file.txt', tempfile.TemporaryFile(), 0)
    attachment = Attachment(tc.env, 'wiki', 'SomePage/SubPage')
    attachment.insert('foo.txt', tempfile.TemporaryFile(), 0)

def attachment_teardown(tc):
    shutil.rmtree(tc.env.path)
    tc.env.reset_db()


EMAIL_TEST_CASE_DEFAULT = u"""
============================== mailto: obfuscated by default, like plain email
user@example.org vs. mailto:user@example.org
and [mailto:user@example.org Joe User]
------------------------------
<p>
user@\u2026 vs. mailto:user@\u2026
and Joe User
</p>
------------------------------
"""

def email_default_context():
    class NoEmailViewPerm(MockPerm):
        def has_permission(self, action, realm_or_resource=None, id=False,
                           version=False):
            return action != 'EMAIL_VIEW'
        __contains__ = has_permission

    context = RenderingContext(Resource('wiki', 'WikiStart'), href=Href('/'),
                               perm=NoEmailViewPerm())
    context.req = None # 1.0 FIXME .req shouldn't be required by formatter
    return context


EMAIL_TEST_CASE_NEVER_OBFUSCATE = u"""
============================== mailto: not obfuscated, unlike plain email
user@example.org vs. mailto:user@example.org
and [mailto:user@example.org Joe User]
------------------------------
<p>
user@\u2026 vs. <a class="mail-link" href="mailto:user@example.org"><span class="icon"></span>mailto:user@example.org</a>
and <a class="mail-link" href="mailto:user@example.org"><span class="icon"></span>Joe User</a>
</p>
------------------------------
"""

def email_never_obfuscate_setup(tc):
    tc.env.config.set('trac', 'never_obfuscate_mailto', True)


def suite():
    suite = unittest.TestSuite()
    suite.addTest(formatter.suite(SEARCH_TEST_CASES, file=__file__))
    suite.addTest(formatter.suite(ATTACHMENT_TEST_CASES, file=__file__,
                                  context=('wiki', 'WikiStart'),
                                  setup=attachment_setup,
                                  teardown=attachment_teardown))
    suite.addTest(formatter.suite(EMAIL_TEST_CASE_DEFAULT, file=__file__,
                                  context=email_default_context()))
    suite.addTest(formatter.suite(EMAIL_TEST_CASE_NEVER_OBFUSCATE,
                                  file=__file__,
                                  context=email_default_context(),
                                  setup=email_never_obfuscate_setup))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')


########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.com/license.html.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/.

from __future__ import with_statement

from datetime import datetime

from trac.admin import *
from trac.core import *
from trac.perm import PermissionSystem
from trac.resource import ResourceNotFound
from trac.ticket import model
from trac.util import getuser
from trac.util.datefmt import utc, parse_date, format_date, format_datetime, \
                              get_datetime_format_hint, user_time
from trac.util.text import print_table, printout, exception_to_unicode
from trac.util.translation import _, N_, gettext
from trac.web.chrome import Chrome, add_notice, add_warning


class TicketAdminPanel(Component):

    implements(IAdminPanelProvider, IAdminCommandProvider)

    abstract = True

    _label = (N_('(Undefined)'), N_('(Undefined)'))

    # i18n note: use gettext() whenever refering to the above as text labels,
    #            and don't use it whenever using them as field names (after
    #            a call to `.lower()`)


    # IAdminPanelProvider methods

    def get_admin_panels(self, req):
        if 'TICKET_ADMIN' in req.perm:
            # in global scope show only products
            # in local scope everything but products
            parent = getattr(self.env, 'parent', None)
            if (parent is None and self._type == 'products') or \
               (parent and self._type != 'products'):
                yield ('ticket', _('Ticket System'), self._type,
                        gettext(self._label[1]))

    def render_admin_panel(self, req, cat, page, version):
        req.perm.require('TICKET_ADMIN')
        # Trap AssertionErrors and convert them to TracErrors
        try:
            return self._render_admin_panel(req, cat, page, version)
        except AssertionError, e:
            raise TracError(e)


def _save_config(config, req, log):
    """Try to save the config, and display either a success notice or a
    failure warning.
    """
    try:
        config.save()
        add_notice(req, _('Your changes have been saved.'))
    except Exception, e:
        log.error('Error writing to trac.ini: %s', exception_to_unicode(e))
        add_warning(req, _('Error writing to trac.ini, make sure it is '
                           'writable by the web server. Your changes have not '
                           'been saved.'))


class ComponentAdminPanel(TicketAdminPanel):

    _type = 'components'
    _label = (N_('Component'), N_('Components'))

    # TicketAdminPanel methods

    def _render_admin_panel(self, req, cat, page, component):
        # Detail view?
        if component:
            comp = model.Component(self.env, component)
            if req.method == 'POST':
                if req.args.get('save'):
                    comp.name = name = req.args.get('name')
                    comp.owner = req.args.get('owner')
                    comp.description = req.args.get('description')
                    try:
                        comp.update()
                    except self.env.db_exc.IntegrityError:
                        raise TracError(_('The component "%(name)s" already '
                                          'exists.', name=name))
                    add_notice(req, _('Your changes have been saved.'))
                    req.redirect(req.href.admin(cat, page))
                elif req.args.get('cancel'):
                    req.redirect(req.href.admin(cat, page))

            Chrome(self.env).add_wiki_toolbars(req)
            data = {'view': 'detail', 'component': comp}

        else:
            default = self.config.get('ticket', 'default_component')
            if req.method == 'POST':
                # Add Component
                if req.args.get('add') and req.args.get('name'):
                    name = req.args.get('name')
                    try:
                        comp = model.Component(self.env, name=name)
                    except ResourceNotFound:
                        comp = model.Component(self.env)
                        comp.name = name
                        if req.args.get('owner'):
                            comp.owner = req.args.get('owner')
                        comp.insert()
                        add_notice(req, _('The component "%(name)s" has been '
                                          'added.', name=name))
                        req.redirect(req.href.admin(cat, page))
                    else:
                        if comp.name is None:
                            raise TracError(_("Invalid component name."))
                        raise TracError(_("Component %(name)s already exists.",
                                          name=name))

                # Remove components
                elif req.args.get('remove'):
                    sel = req.args.get('sel')
                    if not sel:
                        raise TracError(_('No component selected'))
                    if not isinstance(sel, list):
                        sel = [sel]
                    with self.env.db_transaction:
                        for name in sel:
                            model.Component(self.env, name).delete()
                    add_notice(req, _("The selected components have been "
                                      "removed."))
                    req.redirect(req.href.admin(cat, page))

                # Set default component
                elif req.args.get('apply'):
                    name = req.args.get('default')
                    if name and name != default:
                        self.log.info("Setting default component to %s", name)
                        self.config.set('ticket', 'default_component', name)
                        _save_config(self.config, req, self.log)
                        req.redirect(req.href.admin(cat, page))

            data = {'view': 'list',
                    'components': model.Component.select(self.env),
                    'default': default}

        if self.config.getbool('ticket', 'restrict_owner'):
            perm = PermissionSystem(self.env)
            def valid_owner(username):
                return perm.get_user_permissions(username).get('TICKET_MODIFY')
            data['owners'] = [username for username, name, email
                              in self.env.get_known_users()
                              if valid_owner(username)]
            data['owners'].insert(0, '')
            data['owners'].sort()
        else:
            data['owners'] = None

        return 'admin_components.html', data

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('component list', '',
               'Show available components',
               None, self._do_list)
        yield ('component add', '<name> <owner>',
               'Add a new component',
               self._complete_add, self._do_add)
        yield ('component rename', '<name> <newname>',
               'Rename a component',
               self._complete_remove_rename, self._do_rename)
        yield ('component remove', '<name>',
               'Remove/uninstall a component',
               self._complete_remove_rename, self._do_remove)
        yield ('component chown', '<name> <owner>',
               'Change component ownership',
               self._complete_chown, self._do_chown)

    def get_component_list(self):
        return [c.name for c in model.Component.select(self.env)]

    def get_user_list(self):
        return [username for username, in
                self.env.db_query("SELECT DISTINCT username FROM permission")]

    def _complete_add(self, args):
        if len(args) == 2:
            return self.get_user_list()

    def _complete_remove_rename(self, args):
        if len(args) == 1:
            return self.get_component_list()

    def _complete_chown(self, args):
        if len(args) == 1:
            return self.get_component_list()
        elif len(args) == 2:
            return self.get_user_list()

    def _do_list(self):
        print_table([(c.name, c.owner)
                     for c in model.Component.select(self.env)],
                    [_('Name'), _('Owner')])

    def _do_add(self, name, owner):
        component = model.Component(self.env)
        component.name = name
        component.owner = owner
        component.insert()

    def _do_rename(self, name, newname):
        component = model.Component(self.env, name)
        component.name = newname
        component.update()

    def _do_remove(self, name):
        model.Component(self.env, name).delete()

    def _do_chown(self, name, owner):
        component = model.Component(self.env, name)
        component.owner = owner
        component.update()


class MilestoneAdminPanel(TicketAdminPanel):

    _type = 'milestones'
    _label = (N_('Milestone'), N_('Milestones'))

    # IAdminPanelProvider methods

    def get_admin_panels(self, req):
        if 'MILESTONE_VIEW' in req.perm:
            return TicketAdminPanel.get_admin_panels(self, req)
        return iter([])

    # TicketAdminPanel methods

    def _render_admin_panel(self, req, cat, page, milestone):
        req.perm.require('MILESTONE_VIEW')

        # Detail view?
        if milestone:
            mil = model.Milestone(self.env, milestone)
            if req.method == 'POST':
                if req.args.get('save'):
                    req.perm.require('MILESTONE_MODIFY')
                    mil.name = name = req.args.get('name')
                    mil.due = mil.completed = None
                    due = req.args.get('duedate', '')
                    if due:
                        mil.due = user_time(req, parse_date, due,
                                            hint='datetime')
                    if req.args.get('completed', False):
                        completed = req.args.get('completeddate', '')
                        mil.completed = user_time(req, parse_date, completed,
                                                  hint='datetime')
                        if mil.completed > datetime.now(utc):
                            raise TracError(_('Completion date may not be in '
                                              'the future'),
                                            _('Invalid Completion Date'))
                    mil.description = req.args.get('description', '')
                    try:
                        mil.update()
                    except self.env.db_exc.IntegrityError:
                        raise TracError(_('The milestone "%(name)s" already '
                                          'exists.', name=name))
                    add_notice(req, _('Your changes have been saved.'))
                    req.redirect(req.href.admin(cat, page))
                elif req.args.get('cancel'):
                    req.redirect(req.href.admin(cat, page))

            Chrome(self.env).add_wiki_toolbars(req)
            data = {'view': 'detail', 'milestone': mil}

        else:
            default = self.config.get('ticket', 'default_milestone')
            if req.method == 'POST':
                # Add Milestone
                if req.args.get('add') and req.args.get('name'):
                    req.perm.require('MILESTONE_CREATE')
                    name = req.args.get('name')
                    try:
                        mil = model.Milestone(self.env, name=name)
                    except ResourceNotFound:
                        mil = model.Milestone(self.env)
                        mil.name = name
                        if req.args.get('duedate'):
                            mil.due = user_time(req, parse_date,
                                                req.args.get('duedate'),
                                                hint='datetime')
                        mil.insert()
                        add_notice(req, _('The milestone "%(name)s" has been '
                                          'added.', name=name))
                        req.redirect(req.href.admin(cat, page))
                    else:
                        if mil.name is None:
                            raise TracError(_('Invalid milestone name.'))
                        raise TracError(_("Milestone %(name)s already exists.",
                                          name=name))

                # Remove milestone
                elif req.args.get('remove'):
                    req.perm.require('MILESTONE_DELETE')
                    sel = req.args.get('sel')
                    if not sel:
                        raise TracError(_('No milestone selected'))
                    if not isinstance(sel, list):
                        sel = [sel]
                    with self.env.db_transaction:
                        for name in sel:
                            mil = model.Milestone(self.env, name)
                            mil.delete(author=req.authname)
                    add_notice(req, _("The selected milestones have been "
                                      "removed."))
                    req.redirect(req.href.admin(cat, page))

                # Set default milestone
                elif req.args.get('apply'):
                    name = req.args.get('default')
                    if name and name != default:
                        self.log.info("Setting default milestone to %s", name)
                        self.config.set('ticket', 'default_milestone', name)
                        _save_config(self.config, req, self.log)
                        req.redirect(req.href.admin(cat, page))

            # Get ticket count
            milestones = [
                (milestone, self.env.db_query("""
                    SELECT COUNT(*) FROM ticket WHERE milestone=%s
                    """, (milestone.name,))[0][0])
                for milestone in model.Milestone.select(self.env)]

            data = {'view': 'list',
                    'milestones': milestones,
                    'default': default}

        Chrome(self.env).add_jquery_ui(req)

        data.update({
            'datetime_hint': get_datetime_format_hint(req.lc_time),
        })
        return 'admin_milestones.html', data

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('milestone list', '',
               "Show milestones",
               None, self._do_list)
        yield ('milestone add', '<name> [due]',
               "Add milestone",
               None, self._do_add)
        yield ('milestone rename', '<name> <newname>',
               "Rename milestone",
               self._complete_name, self._do_rename)
        yield ('milestone due', '<name> <due>',
               """Set milestone due date

               The <due> date must be specified in the "%s" format.
               Alternatively, "now" can be used to set the due date to the
               current time. To remove the due date from a milestone, specify
               an empty string ("").
               """ % console_date_format_hint,
               self._complete_name, self._do_due)
        yield ('milestone completed', '<name> <completed>',
               """Set milestone complete date

               The <completed> date must be specified in the "%s" format.
               Alternatively, "now" can be used to set the completion date to
               the current time. To remove the completion date from a
               milestone, specify an empty string ("").
               """ % console_date_format_hint,
               self._complete_name, self._do_completed)
        yield ('milestone remove', '<name>',
               "Remove milestone",
               self._complete_name, self._do_remove)

    def get_milestone_list(self):
        return [m.name for m in model.Milestone.select(self.env)]

    def _complete_name(self, args):
        if len(args) == 1:
            return self.get_milestone_list()

    def _do_list(self):
        print_table([(m.name, m.due and
                        format_date(m.due, console_date_format),
                      m.completed and
                        format_datetime(m.completed, console_datetime_format))
                     for m in model.Milestone.select(self.env)],
                    [_("Name"), _("Due"), _("Completed")])

    def _do_add(self, name, due=None):
        milestone = model.Milestone(self.env)
        milestone.name = name
        if due is not None:
            milestone.due = parse_date(due, hint='datetime')
        milestone.insert()

    def _do_rename(self, name, newname):
        milestone = model.Milestone(self.env, name)
        milestone.name = newname
        milestone.update()

    def _do_due(self, name, due):
        milestone = model.Milestone(self.env, name)
        milestone.due = due and parse_date(due, hint='datetime')
        milestone.update()

    def _do_completed(self, name, completed):
        milestone = model.Milestone(self.env, name)
        milestone.completed = completed and parse_date(completed,
                                                       hint='datetime')
        milestone.update()

    def _do_remove(self, name):
        model.Milestone(self.env, name).delete(author=getuser())


class VersionAdminPanel(TicketAdminPanel):

    _type = 'versions'
    _label = (N_('Version'), N_('Versions'))

    # TicketAdminPanel methods

    def _render_admin_panel(self, req, cat, page, version):
        # Detail view?
        if version:
            ver = model.Version(self.env, version)
            if req.method == 'POST':
                if req.args.get('save'):
                    ver.name = name = req.args.get('name')
                    if req.args.get('time'):
                        ver.time = user_time(req, parse_date,
                                             req.args.get('time'),
                                             hint='datetime')
                    else:
                        ver.time = None # unset
                    ver.description = req.args.get('description')
                    try:
                        ver.update()
                    except self.env.db_exc.IntegrityError:
                        raise TracError(_('The version "%(name)s" already '
                                          'exists.', name=name))

                    add_notice(req, _('Your changes have been saved.'))
                    req.redirect(req.href.admin(cat, page))
                elif req.args.get('cancel'):
                    req.redirect(req.href.admin(cat, page))

            Chrome(self.env).add_wiki_toolbars(req)
            data = {'view': 'detail', 'version': ver}

        else:
            default = self.config.get('ticket', 'default_version')
            if req.method == 'POST':
                # Add Version
                if req.args.get('add') and req.args.get('name'):
                    name = req.args.get('name')
                    try:
                        ver = model.Version(self.env, name=name)
                    except ResourceNotFound:
                        ver = model.Version(self.env)
                        ver.name = name
                        if req.args.get('time'):
                            ver.time = user_time(req, parse_date,
                                                 req.args.get('time'),
                                                 hint='datetime')
                        ver.insert()
                        add_notice(req, _('The version "%(name)s" has been '
                                          'added.', name=name))
                        req.redirect(req.href.admin(cat, page))
                    else:
                        if ver.name is None:
                            raise TracError(_("Invalid version name."))
                        raise TracError(_("Version %(name)s already exists.",
                                          name=name))

                # Remove versions
                elif req.args.get('remove'):
                    sel = req.args.get('sel')
                    if not sel:
                        raise TracError(_("No version selected"))
                    if not isinstance(sel, list):
                        sel = [sel]
                    with self.env.db_transaction:
                        for name in sel:
                            ver = model.Version(self.env, name)
                            ver.delete()
                    add_notice(req, _("The selected versions have been "
                                      "removed."))
                    req.redirect(req.href.admin(cat, page))

                # Set default version
                elif req.args.get('apply'):
                    name = req.args.get('default')
                    if name and name != default:
                        self.log.info("Setting default version to %s", name)
                        self.config.set('ticket', 'default_version', name)
                        _save_config(self.config, req, self.log)
                        req.redirect(req.href.admin(cat, page))

            data = {'view': 'list',
                    'versions': model.Version.select(self.env),
                    'default': default}

        Chrome(self.env).add_jquery_ui(req)

        data.update({
            'datetime_hint': get_datetime_format_hint(req.lc_time),
        })
        return 'admin_versions.html', data

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('version list', '',
               "Show versions",
               None, self._do_list)
        yield ('version add', '<name> [time]',
               "Add version",
               None, self._do_add)
        yield ('version rename', '<name> <newname>',
               "Rename version",
               self._complete_name, self._do_rename)
        yield ('version time', '<name> <time>',
               """Set version date

               The <time> must be specified in the "%s" format. Alternatively,
               "now" can be used to set the version date to the current time.
               To remove the date from a version, specify an empty string
               ("").
               """ % console_date_format_hint,
               self._complete_name, self._do_time)
        yield ('version remove', '<name>',
               "Remove version",
               self._complete_name, self._do_remove)

    def get_version_list(self):
        return [v.name for v in model.Version.select(self.env)]

    def _complete_name(self, args):
        if len(args) == 1:
            return self.get_version_list()

    def _do_list(self):
        print_table([(v.name,
                      v.time and format_date(v.time, console_date_format))
                     for v in model.Version.select(self.env)],
                    [_("Name"), _("Time")])

    def _do_add(self, name, time=None):
        version = model.Version(self.env)
        version.name = name
        if time is not None:
            version.time = time and parse_date(time, hint='datetime')
        version.insert()

    def _do_rename(self, name, newname):
        version = model.Version(self.env, name)
        version.name = newname
        version.update()

    def _do_time(self, name, time):
        version = model.Version(self.env, name)
        version.time = time and parse_date(time, hint='datetime')
        version.update()

    def _do_remove(self, name):
        model.Version(self.env, name).delete()


class AbstractEnumAdminPanel(TicketAdminPanel):

    abstract = True

    _type = 'unknown'
    _enum_cls = None

    # TicketAdminPanel methods

    def _render_admin_panel(self, req, cat, page, path_info):
        label = [gettext(each) for each in self._label]
        data = {'label_singular': label[0], 'label_plural': label[1],
                'type': self._type}

        # Detail view?
        if path_info:
            enum = self._enum_cls(self.env, path_info)
            if req.method == 'POST':
                if req.args.get('save'):
                    enum.name = name = req.args.get('name')
                    try:
                        enum.update()
                    except self.env.db_exc.IntegrityError:
                        raise TracError(_('%(type)s value "%(name)s" already '
                                          'exists', type=label[0], name=name))
                    add_notice(req, _("Your changes have been saved."))
                    req.redirect(req.href.admin(cat, page))
                elif req.args.get('cancel'):
                    req.redirect(req.href.admin(cat, page))
            data.update({'view': 'detail', 'enum': enum})

        else:
            default = self.config.get('ticket', 'default_%s' % self._type)
            if req.method == 'POST':
                # Add enum
                if req.args.get('add') and req.args.get('name'):
                    name = req.args.get('name')
                    try:
                        enum = self._enum_cls(self.env, name=name)
                    except ResourceNotFound:
                        enum = self._enum_cls(self.env)
                        enum.name = name
                        enum.insert()
                        add_notice(req, _('The %(field)s value "%(name)s" has '
                                          'been added.',
                                          field=label[0], name=name))
                        req.redirect(req.href.admin(cat, page))
                    else:
                        if enum.name is None:
                            raise TracError(_("Invalid %(type)s value.",
                                              type=label[0]))
                        raise TracError(_('%(type)s value "%(name)s" already '
                                          'exists', type=label[0], name=name))

                # Remove enums
                elif req.args.get('remove'):
                    sel = req.args.get('sel')
                    if not sel:
                        raise TracError(_("No %s selected") % self._type)
                    if not isinstance(sel, list):
                        sel = [sel]
                    with self.env.db_transaction:
                        for name in sel:
                            self._enum_cls(self.env, name).delete()
                    add_notice(req, _("The selected %(field)s values have "
                                      "been removed.", field=label[0]))
                    req.redirect(req.href.admin(cat, page))

                # Apply changes
                elif req.args.get('apply'):
                    changed = False

                    # Set default value
                    name = req.args.get('default')
                    if name and name != default:
                        self.log.info("Setting default %s to %s",
                                      self._type, name)
                        self.config.set('ticket', 'default_%s' % self._type,
                                        name)
                        try:
                            self.config.save()
                            changed = True
                        except Exception, e:
                            self.log.error("Error writing to trac.ini: %s",
                                           exception_to_unicode(e))
                            add_warning(req,
                                        _("Error writing to trac.ini, make "
                                          "sure it is writable by the web "
                                          "server. The default value has not "
                                          "been saved."))

                    # Change enum values
                    order = dict([(str(int(key[6:])),
                                   str(int(req.args.get(key)))) for key
                                  in req.args.keys()
                                  if key.startswith('value_')])
                    values = dict([(val, True) for val in order.values()])
                    if len(order) != len(values):
                        raise TracError(_("Order numbers must be unique"))
                    with self.env.db_transaction:
                        for enum in self._enum_cls.select(self.env):
                            new_value = order[enum.value]
                            if new_value != enum.value:
                                enum.value = new_value
                                enum.update()
                                changed = True

                    if changed:
                        add_notice(req, _("Your changes have been saved."))
                    req.redirect(req.href.admin(cat, page))

            data.update(dict(enums=list(self._enum_cls.select(self.env)),
                             default=default, view='list'))
        return 'admin_enums.html', data

    # IAdminCommandProvider methods

    _command_help = {
        'list': 'Show possible ticket %s',
        'add': 'Add a %s value option',
        'change': 'Change a %s value',
        'remove': 'Remove a %s value',
        'order': 'Move a %s value up or down in the list',
    }

    def get_admin_commands(self):
        enum_type = getattr(self, '_command_type', self._type)
        label = tuple(each.lower() for each in self._label)
        yield ('%s list' % enum_type, '',
               self._command_help['list'] % label[1],
               None, self._do_list)
        yield ('%s add' % enum_type, '<value>',
               self._command_help['add'] % label[0],
               None, self._do_add)
        yield ('%s change' % enum_type, '<value> <newvalue>',
               self._command_help['change'] % label[0],
               self._complete_change_remove, self._do_change)
        yield ('%s remove' % enum_type, '<value>',
               self._command_help['remove'] % label[0],
               self._complete_change_remove, self._do_remove)
        yield ('%s order' % enum_type, '<value> up|down',
               self._command_help['order'] % label[0],
               self._complete_order, self._do_order)

    def get_enum_list(self):
        return [e.name for e in self._enum_cls.select(self.env)]

    def _complete_change_remove(self, args):
        if len(args) == 1:
            return self.get_enum_list()

    def _complete_order(self, args):
        if len(args) == 1:
            return self.get_enum_list()
        elif len(args) == 2:
            return ['up', 'down']

    def _do_list(self):
        print_table([(e.name,) for e in self._enum_cls.select(self.env)],
                    [_('Possible Values')])

    def _do_add(self, name):
        enum = self._enum_cls(self.env)
        enum.name = name
        enum.insert()

    def _do_change(self, name, newname):
        enum = self._enum_cls(self.env, name)
        enum.name = newname
        enum.update()

    def _do_remove(self, value):
        self._enum_cls(self.env, value).delete()

    def _do_order(self, name, up_down):
        if up_down not in ('up', 'down'):
            raise AdminCommandError(_("Invalid up/down value: %(value)s",
                                      value=up_down))
        direction = -1 if up_down == 'up' else 1
        enum1 = self._enum_cls(self.env, name)
        enum1.value = int(float(enum1.value) + direction)
        for enum2 in self._enum_cls.select(self.env):
            if int(float(enum2.value)) == enum1.value:
                enum2.value = int(float(enum2.value) - direction)
                break
        else:
            return
        with self.env.db_transaction:
            enum1.update()
            enum2.update()


class PriorityAdminPanel(AbstractEnumAdminPanel):
    _type = 'priority'
    _enum_cls = model.Priority
    _label = (N_('Priority'), N_('Priorities'))


class ResolutionAdminPanel(AbstractEnumAdminPanel):
    _type = 'resolution'
    _enum_cls = model.Resolution
    _label = (N_('Resolution'), N_('Resolutions'))


class SeverityAdminPanel(AbstractEnumAdminPanel):
    _type = 'severity'
    _enum_cls = model.Severity
    _label = (N_('Severity'), N_('Severities'))


class TicketTypeAdminPanel(AbstractEnumAdminPanel):
    _type = 'type'
    _enum_cls = model.Type
    _label = (N_('Ticket Type'), N_('Ticket Types'))

    _command_type = 'ticket_type'
    _command_help = {
        'list': 'Show possible %s',
        'add': 'Add a %s',
        'change': 'Change a %s',
        'remove': 'Remove a %s',
        'order': 'Move a %s up or down in the list',
    }


class TicketAdmin(Component):
    """trac-admin command provider for ticket administration."""

    implements(IAdminCommandProvider)

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('ticket remove', '<number>',
               'Remove ticket',
               None, self._do_remove)

    def _do_remove(self, number):
        try:
            number = int(number)
        except ValueError:
            raise AdminCommandError(_('<number> must be a number'))
        with self.env.db_transaction:
            model.Ticket(self.env, number).delete()
        printout(_('Ticket #%(num)s and all associated data removed.',
                   num=number))

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>

import copy
import re

from genshi.builder import tag
from genshi.core import Markup, unescape

from trac.cache import cached
from trac.config import *
from trac.core import *
from trac.perm import IPermissionRequestor, PermissionCache, PermissionSystem
from trac.resource import IResourceManager, ResourceSystem
from trac.util import Ranges, as_int
from trac.util.text import shorten_line
from trac.util.translation import _, N_, gettext
from trac.wiki import IWikiSyntaxProvider, WikiParser


class ITicketActionController(Interface):
    """Extension point interface for components willing to participate
    in the ticket workflow.

    This is mainly about controlling the changes to the ticket ''status'',
    though not restricted to it.
    """

    def get_ticket_actions(req, ticket):
        """Return an iterable of `(weight, action)` tuples corresponding to
        the actions that are contributed by this component.
        That list may vary given the current state of the ticket and the
        actual request parameter.

        `action` is a key used to identify that particular action.
        (note that 'history' and 'diff' are reserved and should not be used
        by plugins)

        The actions will be presented on the page in descending order of the
        integer weight. The first action in the list is used as the default
        action.

        When in doubt, use a weight of 0."""

    def get_all_status():
        """Returns an iterable of all the possible values for the ''status''
        field this action controller knows about.

        This will be used to populate the query options and the like.
        It is assumed that the initial status of a ticket is 'new' and
        the terminal status of a ticket is 'closed'.
        """

    def render_ticket_action_control(req, ticket, action):
        """Return a tuple in the form of `(label, control, hint)`

        `label` is a short text that will be used when listing the action,
        `control` is the markup for the action control and `hint` should
        explain what will happen if this action is taken.

        This method will only be called if the controller claimed to handle
        the given `action` in the call to `get_ticket_actions`.

        Note that the radio button for the action has an `id` of
        `"action_%s" % action`.  Any `id`s used in `control` need to be made
        unique.  The method used in the default ITicketActionController is to
        use `"action_%s_something" % action`.
        """

    def get_ticket_changes(req, ticket, action):
        """Return a dictionary of ticket field changes.

        This method must not have any side-effects because it will also
        be called in preview mode (`req.args['preview']` will be set, then).
        See `apply_action_side_effects` for that. If the latter indeed triggers
        some side-effects, it is advised to emit a warning
        (`trac.web.chrome.add_warning(req, reason)`) when this method is called
        in preview mode.

        This method will only be called if the controller claimed to handle
        the given `action` in the call to `get_ticket_actions`.
        """

    def apply_action_side_effects(req, ticket, action):
        """Perform side effects once all changes have been made to the ticket.

        Multiple controllers might be involved, so the apply side-effects
        offers a chance to trigger a side-effect based on the given `action`
        after the new state of the ticket has been saved.

        This method will only be called if the controller claimed to handle
        the given `action` in the call to `get_ticket_actions`.
        """


class ITicketChangeListener(Interface):
    """Extension point interface for components that require notification
    when tickets are created, modified, or deleted."""

    def ticket_created(ticket):
        """Called when a ticket is created."""

    def ticket_changed(ticket, comment, author, old_values):
        """Called when a ticket is modified.

        `old_values` is a dictionary containing the previous values of the
        fields that have changed.
        """

    def ticket_deleted(ticket):
        """Called when a ticket is deleted."""


class ITicketManipulator(Interface):
    """Miscellaneous manipulation of ticket workflow features."""

    def prepare_ticket(req, ticket, fields, actions):
        """Not currently called, but should be provided for future
        compatibility."""

    def validate_ticket(req, ticket):
        """Validate a ticket after it's been populated from user input.

        Must return a list of `(field, message)` tuples, one for each problem
        detected. `field` can be `None` to indicate an overall problem with the
        ticket. Therefore, a return value of `[]` means everything is OK."""


class IMilestoneChangeListener(Interface):
    """Extension point interface for components that require notification
    when milestones are created, modified, or deleted."""

    def milestone_created(milestone):
        """Called when a milestone is created."""

    def milestone_changed(milestone, old_values):
        """Called when a milestone is modified.

        `old_values` is a dictionary containing the previous values of the
        milestone properties that changed. Currently those properties can be
        'name', 'due', 'completed', or 'description'.
        """

    def milestone_deleted(milestone):
        """Called when a milestone is deleted."""

class ITicketFieldProvider(Interface):
    """Extension point interface for components that provide fields for the
    ticket system."""

    def get_select_fields():
        """Returns a list of select fields, each as a tuple of
        (rank, field)
        where field is a dictionary that defines:
            * name: the field name 
            * pk: the primary key of the field table
            * label: the label to display, preferably wrapped with N_()
            * cls: the model describing the field
        the following keys can also usefully be defined:
            * optional: a boolean specifying that the select can be empty
        
        The rank is expected to be an integer to specify the sorting of the
        select and radio fields. This is not intended to allow for the extent
        of configurability of the custom fields but allows a plugin to mix in
        fields as if they are a first class member of the ticket system.
        """

    def get_radio_fields():
        """Returns a list of radio fields, each as a tuple of
        (rank, field)
        See the documentation for get_select_fields for descriptions of rank and
        field.
        Note that in contrast to get_select_fields, radio fields will all be
        specified as optional.
        """

    def get_raw_fields():
        """Returns a list of fields, each represents ticket field
        dictionary. For example:
            * name: field name
            * type: field type
            * label: the label to display, preferably wrapped with N_()
            * format: field format
            * other appropriate field properties
        """

class TicketSystem(Component):
    implements(IPermissionRequestor, IWikiSyntaxProvider, IResourceManager,
               ITicketFieldProvider)

    ticket_field_providers = ExtensionPoint(ITicketFieldProvider)
    change_listeners = ExtensionPoint(ITicketChangeListener)
    milestone_change_listeners = ExtensionPoint(IMilestoneChangeListener)

    ticket_custom_section = ConfigSection('ticket-custom',
        """In this section, you can define additional fields for tickets. See
        TracTicketsCustomFields for more details.""")

    action_controllers = OrderedExtensionsOption('ticket', 'workflow',
        ITicketActionController, default='ConfigurableTicketWorkflow',
        include_missing=False,
        doc="""Ordered list of workflow controllers to use for ticket actions
            (''since 0.11'').""")

    restrict_owner = BoolOption('ticket', 'restrict_owner', 'false',
        """Make the owner field of tickets use a drop-down menu.
        Be sure to understand the performance implications before activating
        this option. See
        [TracTickets#Assign-toasDrop-DownList Assign-to as Drop-Down List].

        Please note that e-mail addresses are '''not''' obfuscated in the
        resulting drop-down menu, so this option should not be used if
        e-mail addresses must remain protected.
        (''since 0.9'')""")

    default_version = Option('ticket', 'default_version', '',
        """Default version for newly created tickets.""")

    default_type = Option('ticket', 'default_type', 'defect',
        """Default type for newly created tickets (''since 0.9'').""")

    default_priority = Option('ticket', 'default_priority', 'major',
        """Default priority for newly created tickets.""")

    default_milestone = Option('ticket', 'default_milestone', '',
        """Default milestone for newly created tickets.""")

    default_component = Option('ticket', 'default_component', '',
        """Default component for newly created tickets.""")

    default_severity = Option('ticket', 'default_severity', '',
        """Default severity for newly created tickets.""")

    default_summary = Option('ticket', 'default_summary', '',
        """Default summary (title) for newly created tickets.""")

    default_description = Option('ticket', 'default_description', '',
        """Default description for newly created tickets.""")

    default_keywords = Option('ticket', 'default_keywords', '',
        """Default keywords for newly created tickets.""")

    default_owner = Option('ticket', 'default_owner', '< default >',
        """Default owner for newly created tickets.""")

    default_cc = Option('ticket', 'default_cc', '',
        """Default cc: list for newly created tickets.""")

    default_resolution = Option('ticket', 'default_resolution', 'fixed',
        """Default resolution for resolving (closing) tickets
        (''since 0.11'').""")

    def __init__(self):
        self.log.debug('action controllers for ticket workflow: %r' %
                [c.__class__.__name__ for c in self.action_controllers])

    # Public API

    def get_available_actions(self, req, ticket):
        """Returns a sorted list of available actions"""
        # The list should not have duplicates.
        actions = {}
        for controller in self.action_controllers:
            weighted_actions = controller.get_ticket_actions(req, ticket) or []
            for weight, action in weighted_actions:
                if action in actions:
                    actions[action] = max(actions[action], weight)
                else:
                    actions[action] = weight
        all_weighted_actions = [(weight, action) for action, weight in
                                actions.items()]
        return [x[1] for x in sorted(all_weighted_actions, reverse=True)]

    def get_all_status(self):
        """Returns a sorted list of all the states all of the action
        controllers know about."""
        valid_states = set()
        for controller in self.action_controllers:
            valid_states.update(controller.get_all_status() or [])
        return sorted(valid_states)

    def get_ticket_field_labels(self):
        """Produce a (name,label) mapping from `get_ticket_fields`."""
        labels = dict((f['name'], f['label'])
                      for f in self.get_ticket_fields())
        labels['attachment'] = _("Attachment")
        return labels

    def get_ticket_fields(self):
        """Returns list of fields available for tickets.

        Each field is a dict with at least the 'name', 'label' (localized)
        and 'type' keys.
        It may in addition contain the 'custom' key, the 'optional' and the
        'options' keys. When present 'custom' and 'optional' are always `True`.
        """
        fields = copy.deepcopy(self.fields)
        label = 'label' # workaround gettext extraction bug
        for f in fields:
            f[label] = gettext(f[label])
        return fields

    def reset_ticket_fields(self):
        """Invalidate ticket field cache."""
        del self.fields

    @cached
    def fields(self, db):
        """Return the list of fields available for tickets."""
        from trac.ticket import model

        fields = []

        # Basic text fields
        fields.append({'name': 'summary', 'type': 'text',
                       'label': N_('Summary')})
        fields.append({'name': 'reporter', 'type': 'text',
                       'label': N_('Reporter')})

        # Owner field, by default text but can be changed dynamically
        # into a drop-down depending on configuration (restrict_owner=true)
        field = {'name': 'owner', 'label': N_('Owner')}
        field['type'] = 'text'
        fields.append(field)

        # Description
        fields.append({'name': 'description', 'type': 'textarea',
                       'label': N_('Description')})

        # Default select and radio fields
        selects = []
        [selects.extend(field_provider.get_select_fields()) 
                    for field_provider in self.ticket_field_providers]
        [select.update({'type': 'select'}) for n, select in selects]
        radios = []
        [radios.extend(field_provider.get_radio_fields()) 
                    for field_provider in self.ticket_field_providers]
        [radio.update({'type': 'radio',
                       'optional': True}) for n, radio in radios]

        selects.extend(radios)
        selects.sort()
        for rank, field in selects:
            cls = field['cls']
            name = field['name']
            pk_field = field.get('pk', 'name')
            options = [getattr(val, pk_field)
                       for val in cls.select(self.env, db=db)]

            if not options:
                # Fields without possible values are treated as if they didn't
                # exist
                continue
            if 'value' not in field:
                field['value'] = getattr(self, 'default_' + name, '')
            field['options'] = options
            fields.append(field)

        # Advanced text fields
        fields.append({'name': 'keywords', 'type': 'text', 'format': 'list',
                       'label': N_('Keywords')})
        fields.append({'name': 'cc', 'type': 'text',  'format': 'list',
                       'label': N_('Cc')})

        # Date/time fields
        fields.append({'name': 'time', 'type': 'time',
                       'label': N_('Created')})
        fields.append({'name': 'changetime', 'type': 'time',
                       'label': N_('Modified')})

        for field in self.get_custom_fields():
            if field['name'] in [f['name'] for f in fields]:
                self.log.warning('Duplicate field name "%s" (ignoring)',
                                 field['name'])
                continue
            if field['name'] in self.reserved_field_names:
                self.log.warning('Field name "%s" is a reserved name '
                                 '(ignoring)', field['name'])
                continue
            if not re.match('^[a-zA-Z][a-zA-Z0-9_]+$', field['name']):
                self.log.warning('Invalid name for custom field: "%s" '
                                 '(ignoring)', field['name'])
                continue
            field['custom'] = True
            fields.append(field)

        #TODO: this is Bloodhound specific patch to the Trac. Contact Trac
        # community about possibility to apply the change to the Trac codebase
        self._add_raw_fields_from_field_providers(fields)

        return fields

    reserved_field_names = ['report', 'order', 'desc', 'group', 'groupdesc',
                            'col', 'row', 'format', 'max', 'page', 'verbose',
                            'comment', 'or']

    def _add_raw_fields_from_field_providers(self, fields):
        for field_provider in self.ticket_field_providers:
            if hasattr(field_provider, 'get_raw_fields'):
                raw_fields = field_provider.get_raw_fields()
                if raw_fields:
                    for raw_field in raw_fields:
                        self._add_raw_field(
                            raw_field, fields)

    def _add_raw_field(self, raw_field, fields):
        if raw_field["name"] in [f['name'] for f in fields]:
            self.log.warning(
                'Duplicate field name "%s" (ignoring)', raw_field["name"])
        else:
            fields.append(raw_field)


    def get_custom_fields(self):
        return copy.deepcopy(self.custom_fields)

    @cached
    def custom_fields(self, db):
        """Return the list of custom ticket fields available for tickets."""
        fields = []
        config = self.ticket_custom_section
        for name in [option for option, value in config.options()
                     if '.' not in option]:
            field = {
                'name': name,
                'type': config.get(name),
                'order': config.getint(name + '.order', 0),
                'label': config.get(name + '.label') or name.capitalize(),
                'value': config.get(name + '.value', '')
            }
            if field['type'] == 'select' or field['type'] == 'radio':
                field['options'] = config.getlist(name + '.options', sep='|')
                if '' in field['options']:
                    field['optional'] = True
                    field['options'].remove('')
            elif field['type'] == 'text':
                field['format'] = config.get(name + '.format', 'plain')
            elif field['type'] == 'textarea':
                field['format'] = config.get(name + '.format', 'plain')
                field['width'] = config.getint(name + '.cols')
                field['height'] = config.getint(name + '.rows')
            fields.append(field)

        fields.sort(lambda x, y: cmp((x['order'], x['name']),
                                     (y['order'], y['name'])))
        return fields

    def get_field_synonyms(self):
        """Return a mapping from field name synonyms to field names.
        The synonyms are supposed to be more intuitive for custom queries."""
        # i18n TODO - translated keys
        return {'created': 'time', 'modified': 'changetime'}

    def eventually_restrict_owner(self, field, ticket=None):
        """Restrict given owner field to be a list of users having
        the TICKET_MODIFY permission (for the given ticket)
        """
        if self.restrict_owner:
            field['type'] = 'select'
            possible_owners = []
            for user in PermissionSystem(self.env) \
                    .get_users_with_permission('TICKET_MODIFY'):
                if not ticket or \
                        'TICKET_MODIFY' in PermissionCache(self.env, user,
                                                           ticket.resource):
                    possible_owners.append(user)
            possible_owners.sort()
            possible_owners.insert(0, '< default >')
            field['options'] = possible_owners
            field['optional'] = True

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['TICKET_APPEND', 'TICKET_CREATE', 'TICKET_CHGPROP',
                'TICKET_VIEW', 'TICKET_EDIT_CC', 'TICKET_EDIT_DESCRIPTION',
                'TICKET_EDIT_COMMENT', 'TICKET_BATCH_MODIFY',
                ('TICKET_MODIFY', ['TICKET_APPEND', 'TICKET_CHGPROP']),
                ('TICKET_ADMIN', ['TICKET_CREATE', 'TICKET_MODIFY',
                                  'TICKET_VIEW', 'TICKET_EDIT_CC',
                                  'TICKET_EDIT_DESCRIPTION',
                                  'TICKET_EDIT_COMMENT',
                                  'TICKET_BATCH_MODIFY'])]

    # IWikiSyntaxProvider methods

    def get_link_resolvers(self):
        return [('bug', self._format_link),
                ('ticket', self._format_link),
                ('comment', self._format_comment_link)]

    def get_wiki_syntax(self):
        yield (
            # matches #... but not &#... (HTML entity)
            r"!?(?<!&)#"
            # optional intertrac shorthand #T... + digits
            r"(?P<it_ticket>%s)%s" % (WikiParser.INTERTRAC_SCHEME,
                                      Ranges.RE_STR),
            lambda x, y, z: self._format_link(x, 'ticket', y[1:], y, z))

    def _format_link(self, formatter, ns, target, label, fullmatch=None):
        intertrac = formatter.shorthand_intertrac_helper(ns, target, label,
                                                         fullmatch)
        if intertrac:
            return intertrac
        try:
            link, params, fragment = formatter.split_link(target)
            r = Ranges(link)
            if len(r) == 1:
                num = r.a
                ticket = formatter.resource('ticket', num)
                from trac.ticket.model import Ticket
                if Ticket.id_is_valid(num) and \
                        'TICKET_VIEW' in formatter.perm(ticket):
                    # TODO: attempt to retrieve ticket view directly,
                    #       something like: t = Ticket.view(num)
                    for type, summary, status, resolution in \
                            self.env.db_query("""
                            SELECT type, summary, status, resolution
                            FROM ticket WHERE id=%s
                            """, (str(num),)):
                        title = self.format_summary(summary, status,
                                                    resolution, type)
                        href = formatter.href.ticket(num) + params + fragment
                        return tag.a(label, title=title, href=href,
                                     class_='%s ticket' % status)
            else:
                ranges = str(r)
                if params:
                    params = '&' + params[1:]
                if isinstance(label, Markup):
                    _label = unescape(label)
                else:
                    _label = label
                label_wrap = _label.replace(',', u',\u200b')
                ranges_wrap = ranges.replace(',', u', ')
                return tag.a(label_wrap,
                             title=_("Tickets %(ranges)s", ranges=ranges_wrap),
                             href=formatter.href.query(id=ranges) + params)
        except ValueError:
            pass
        return tag.a(label, class_='missing ticket')

    def _format_comment_link(self, formatter, ns, target, label):
        resource = None
        if ':' in target:
            elts = target.split(':')
            if len(elts) == 3:
                cnum, realm, id = elts
                if cnum != 'description' and cnum and not cnum[0].isdigit():
                    realm, id, cnum = elts # support old comment: style
                resource = formatter.resource(realm, id)
        else:
            resource = formatter.resource
            cnum = target

        if resource and resource.realm == 'ticket':
            id = as_int(resource.id, None)
            if id is not None:
                href = "%s#comment:%s" % (formatter.href.ticket(resource.id),
                                          cnum)
                title = _("Comment %(cnum)s for Ticket #%(id)s", cnum=cnum,
                          id=resource.id)
                if 'TICKET_VIEW' in formatter.perm(resource):
                    for status, in self.env.db_query(
                            "SELECT status FROM ticket WHERE id=%s", (id,)):
                        return tag.a(label, href=href, title=title,
                                     class_=status)
                return tag.a(label, href=href, title=title)
        return label

    # IResourceManager methods

    def get_resource_realms(self):
        yield 'ticket'

    def get_resource_description(self, resource, format=None, context=None,
                                 **kwargs):
        nbhprefix = ResourceSystem(self.env).neighborhood_prefix(
                resource.neighborhood)
        if format == 'compact':
            return '%s#%s' % (nbhprefix, resource.id)
        elif format == 'summary':
            from trac.ticket.model import Ticket
            ticket = Ticket(self.env, resource.id)
            args = [ticket[f] for f in ('summary', 'status', 'resolution',
                                        'type')]
            return self.format_summary(*args)
        return nbhprefix + _("Ticket #%(shortname)s", shortname=resource.id)

    def format_summary(self, summary, status=None, resolution=None, type=None):
        summary = shorten_line(summary)
        if type:
            summary = type + ': ' + summary
        if status:
            if status == 'closed' and resolution:
                status += ': ' + resolution
            return "%s (%s)" % (summary, status)
        else:
            return summary

    def resource_exists(self, resource):
        """
        >>> from trac.test import EnvironmentStub
        >>> from trac.resource import Resource, resource_exists
        >>> env = EnvironmentStub()

        >>> resource_exists(env, Resource('ticket', 123456))
        False

        >>> from trac.ticket.model import Ticket
        >>> t = Ticket(env)
        >>> int(t.insert())
        1
        >>> resource_exists(env, t.resource)
        True
        """
        if self.env.db_query("SELECT id FROM ticket WHERE id=%s",
                             (resource.id,)):
            if resource.version is None:
                return True
            revcount = self.env.db_query("""
                SELECT count(DISTINCT time) FROM ticket_change WHERE ticket=%s
                """, (resource.id,))
            return revcount[0][0] >= resource.version
        else:
            return False

    # ITicketFieldProvider methods

    def get_select_fields(self):
        """Default select and radio fields"""
        from trac.ticket import model
        selects = [(10, {'name': 'type', 'label': N_('Type'), 
                         'cls': model.Type}),
                   (30, {'name':'priority', 'label': N_('Priority'), 
                         'cls': model.Priority}),
                   (40, {'name': 'milestone', 'label': N_('Milestone'), 
                         'cls': model.Milestone, 'optional': True}),
                   (50, {'name': 'component', 'label': N_('Component'), 
                         'cls': model.Component}),
                   (60, {'name': 'version', 'label': N_('Version'), 
                         'cls': model.Version, 'optional': True}),
                   (70, {'name': 'severity', 'label': N_('Severity'), 
                         'cls': model.Severity})]
        return selects

    def get_radio_fields(self):
        """Default radio fields"""
        from trac.ticket import model
        radios = [(20, {'name': 'status', 'label': N_('Status'),
                        'cls': model.Status}),
                  (80, {'name': 'resolution', 'label': N_('Resolution'), 
                        'cls': model.Resolution})]
        return radios

########NEW FILE########
__FILENAME__ = batch
# -*- coding: utf-8 -*-
#
# Copyright (C) 2010 Brian Meeker
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Brian Meeker <meeker.brian@gmail.com>

from __future__ import with_statement

import re
from datetime import datetime

from genshi.builder import tag

from trac.core import *
from trac.ticket import TicketSystem, Ticket
from trac.ticket.notification import BatchTicketNotifyEmail
from trac.util.datefmt import utc
from trac.util.text import exception_to_unicode, to_unicode
from trac.util.translation import _, tag_
from trac.web import IRequestHandler
from trac.web.chrome import add_warning, add_script_data

class BatchModifyModule(Component):
    """Ticket batch modification module.

    This component allows multiple tickets to be modified in one request from
    the custom query page. For users with the TICKET_BATCH_MODIFY permission
    it will add a [TracBatchModify batch modify] section underneath custom
    query results. Users can choose which tickets and fields they wish to
    modify.
    """

    implements(IRequestHandler)

    list_separator_re =  re.compile(r'[;\s,]+')
    list_connector_string = ', '

    # IRequestHandler methods

    def match_request(self, req):
        return req.path_info == '/batchmodify'

    def process_request(self, req):
        req.perm.assert_permission('TICKET_BATCH_MODIFY')

        comment = req.args.get('batchmod_value_comment', '')
        action = req.args.get('action')

        new_values = self._get_new_ticket_values(req)
        selected_tickets = self._get_selected_tickets(req)

        self._save_ticket_changes(req, selected_tickets,
                                  new_values, comment, action)

        #Always redirect back to the query page we came from.
        req.redirect(req.session['query_href'])

    def _get_new_ticket_values(self, req):
        """Pull all of the new values out of the post data."""
        values = {}

        for field in TicketSystem(self.env).get_ticket_fields():
            name = field['name']
            if name not in ('id', 'resolution', 'status', 'owner', 'time',
                            'changetime', 'summary', 'reporter',
                            'description') and field['type'] != 'textarea':
                value = req.args.get('batchmod_value_' + name)
                if value is not None:
                    values[name] = value
        return values

    def _get_selected_tickets(self, req):
        """The selected tickets will be a comma separated list
        in the request arguments."""
        selected_tickets = req.args.get('selected_tickets')
        if selected_tickets == '':
            return []
        else:
            return selected_tickets.split(',')

    def add_template_data(self, req, data, tickets):
        data['batch_modify'] = True
        data['query_href'] = req.session['query_href'] or req.href.query()
        data['action_controls'] = self._get_action_controls(req, tickets)
        batch_list_modes = [
            {'name': _("add"), 'value': "+"},
            {'name': _("remove"), 'value': "-"},
            {'name': _("add / remove"), 'value': "+-"},
            {'name': _("set to"), 'value': "="},
        ]
        add_script_data(req, batch_list_modes=batch_list_modes,
                             batch_list_properties=self._get_list_fields())

    def _get_list_fields(self):
        return [f['name']
                for f in TicketSystem(self.env).get_ticket_fields()
                if f['type'] == 'text' and f.get('format') == 'list']

    def _get_action_controls(self, req, tickets):
        action_controls = []
        ts = TicketSystem(self.env)
        tickets_by_action = {}
        for t in tickets:
            ticket = Ticket(self.env, t['id'])
            actions = ts.get_available_actions(req, ticket)
            for action in actions:
                tickets_by_action.setdefault(action, []).append(ticket)
        sorted_actions = sorted(set(tickets_by_action.keys()))
        for action in sorted_actions:
            first_label = None
            hints = []
            widgets = []
            ticket = tickets_by_action[action][0]
            for controller in self._get_action_controllers(req, ticket,
                                                           action):
                label, widget, hint = controller.render_ticket_action_control(
                    req, ticket, action)
                if not first_label:
                    first_label = label
                widgets.append(widget)
                hints.append(hint)
            action_controls.append((action, first_label, tag(widgets), hints))
        return action_controls

    def _get_action_controllers(self, req, ticket, action):
        """Generator yielding the controllers handling the given `action`"""
        for controller in TicketSystem(self.env).action_controllers:
            actions = [a for w, a in
                       controller.get_ticket_actions(req, ticket) or []]
            if action in actions:
                yield controller

    def _save_ticket_changes(self, req, selected_tickets,
                             new_values, comment, action):
        """Save all of the changes to tickets."""
        when = datetime.now(utc)
        list_fields = self._get_list_fields()
        with self.env.db_transaction as db:
            for id in selected_tickets:
                t = Ticket(self.env, int(id))
                _values = new_values.copy()
                for field in list_fields:
                    if field in new_values:
                        old = t.values[field] if field in t.values else ''
                        new = new_values[field]
                        mode = req.args.get('batchmod_value_' + field +
                                            '_mode')
                        new2 = req.args.get('batchmod_value_' + field +
                                            '_secondary', '')
                        _values[field] = self._change_list(old, new, new2,
                                                           mode)
                controllers = list(self._get_action_controllers(req, t,
                                                                action))
                for controller in controllers:
                    _values.update(controller.get_ticket_changes(req, t,
                                                                 action))
                t.populate(_values)
                t.save_changes(req.authname, comment, when=when)
                for controller in controllers:
                    controller.apply_action_side_effects(req, t, action)
        try:
            tn = BatchTicketNotifyEmail(self.env)
            tn.notify(selected_tickets, new_values, comment, action,
                      req.authname)
        except Exception, e:
            self.log.error("Failure sending notification on ticket batch"
                    "change: %s", exception_to_unicode(e))
            add_warning(req, tag_("The changes have been saved, but an "
                                  "error occurred while sending "
                                  "notifications: %(message)s",
                                  message=to_unicode(e)))

    def _change_list(self, old_list, new_list, new_list2, mode):
        changed_list = [k.strip()
                        for k in self.list_separator_re.split(old_list)
                        if k]
        new_list = [k.strip()
                    for k in self.list_separator_re.split(new_list)
                    if k]
        new_list2 = [k.strip()
                     for k in self.list_separator_re.split(new_list2)
                     if k]

        if mode == '=':
            changed_list = new_list
        elif mode ==  '+':
            for entry in new_list:
                if entry not in changed_list:
                    changed_list.append(entry)
        elif mode == '-':
            for entry in new_list:
                while entry in changed_list:
                    changed_list.remove(entry)
        elif mode == '+-':
            for entry in new_list:
                if entry not in changed_list:
                    changed_list.append(entry)
            for entry in new_list2:
                while entry in changed_list:
                    changed_list.remove(entry)
        return self.list_connector_string.join(changed_list)

########NEW FILE########
__FILENAME__ = default_workflow
# -*- coding: utf-8 -*-
#
# Copyright (C) 2006-2009 Edgewall Software
# Copyright (C) 2006 Alec Thomas
# Copyright (C) 2007 Eli Carter
# Copyright (C) 2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Eli Carter

import pkg_resources

from ConfigParser import RawConfigParser
from StringIO import StringIO

from genshi.builder import tag

from trac.config import Configuration, ConfigSection
from trac.core import *
from trac.env import IEnvironmentSetupParticipant
from trac.perm import PermissionSystem
from trac.ticket.api import ITicketActionController, TicketSystem
from trac.ticket.model import Resolution
from trac.util.text import obfuscate_email_address
from trac.util.translation import _, tag_, cleandoc_
from trac.web.chrome import Chrome, add_script, add_script_data
from trac.wiki.macros import WikiMacroBase

# -- Utilities for the ConfigurableTicketWorkflow

def parse_workflow_config(rawactions):
    """Given a list of options from [ticket-workflow]"""
    actions = {}
    for option, value in rawactions:
        parts = option.split('.')
        action = parts[0]
        if action not in actions:
            actions[action] = {'oldstates': '', 'newstate': ''}
        if len(parts) == 1:
            # Base name, of the syntax: old,states,here -> newstate
            try:
                oldstates, newstate = [x.strip() for x in value.split('->')]
            except ValueError:
                continue # Syntax error, a warning will be logged later
            actions[action]['newstate'] = newstate
            actions[action]['oldstates'] = oldstates
        else:
            action, attribute = option.split('.')
            actions[action][attribute] = value
    # Fill in the defaults for every action, and normalize them to the desired
    # types
    def as_list(key):
        value = attributes.get(key, '')
        return [item for item in (x.strip() for x in value.split(',')) if item]

    for action, attributes in actions.items():
        # Default the 'name' attribute to the name used in the ini file
        if 'name' not in attributes:
            attributes['name'] = action
        # If not specified, an action is not the default.
        attributes['default'] = int(attributes.get('default', 0))
        # If operations are not specified, that means no operations
        attributes['operations'] = as_list('operations')
        # If no permissions are specified, then no permissions are needed
        attributes['permissions'] = as_list('permissions')
        # Normalize the oldstates
        attributes['oldstates'] = as_list('oldstates')
    return actions

def get_workflow_config(config):
    """Usually passed self.config, this will return the parsed ticket-workflow
    section.
    """
    raw_actions = list(config.options('ticket-workflow'))
    actions = parse_workflow_config(raw_actions)
    return actions

def load_workflow_config_snippet(config, filename):
    """Loads the ticket-workflow section from the given file (expected to be in
    the 'workflows' tree) into the provided config.
    """
    filename = pkg_resources.resource_filename('trac.ticket',
                    'workflows/%s' % filename)
    new_config = Configuration(filename)
    for name, value in new_config.options('ticket-workflow'):
        config.set('ticket-workflow', name, value)


class ConfigurableTicketWorkflow(Component):
    """Ticket action controller which provides actions according to a
    workflow defined in trac.ini.

    The workflow is idefined in the `[ticket-workflow]` section of the
    [wiki:TracIni#ticket-workflow-section trac.ini] configuration file.
    """

    ticket_workflow_section = ConfigSection('ticket-workflow',
        """The workflow for tickets is controlled by plugins. By default,
        there's only a `ConfigurableTicketWorkflow` component in charge.
        That component allows the workflow to be configured via this section
        in the `trac.ini` file. See TracWorkflow for more details.

        (''since 0.11'')""")

    def __init__(self, *args, **kwargs):
        self.actions = get_workflow_config(self.config)
        if not '_reset' in self.actions:
            # Special action that gets enabled if the current status no longer
            # exists, as no other action can then change its state. (#5307)
            self.actions['_reset'] = {
                'default': 0,
                'name': 'reset',
                'newstate': 'new',
                'oldstates': [],  # Will not be invoked unless needed
                'operations': ['reset_workflow'],
                'permissions': []}
        self.log.debug('Workflow actions at initialization: %s\n' %
                       str(self.actions))
        for name, info in self.actions.iteritems():
            if not info['newstate']:
                self.log.warning("Ticket workflow action '%s' doesn't define "
                                 "any transitions", name)

    implements(ITicketActionController, IEnvironmentSetupParticipant)

    # IEnvironmentSetupParticipant methods

    def environment_created(self):
        """When an environment is created, we provide the basic-workflow,
        unless a ticket-workflow section already exists.
        """
        if not 'ticket-workflow' in self.config.sections():
            load_workflow_config_snippet(self.config, 'basic-workflow.ini')
            self.config.save()
            self.actions = get_workflow_config(self.config)

    def environment_needs_upgrade(self, db):
        """The environment needs an upgrade if there is no [ticket-workflow]
        section in the config.
        """
        return not list(self.config.options('ticket-workflow'))

    def upgrade_environment(self, db):
        """Insert a [ticket-workflow] section using the original-workflow"""
        load_workflow_config_snippet(self.config, 'original-workflow.ini')
        self.config.save()
        self.actions = get_workflow_config(self.config)
        info_message = """

==== Upgrade Notice ====

The ticket Workflow is now configurable.

Your environment has been upgraded, but configured to use the original
workflow. It is recommended that you look at changing this configuration to use
basic-workflow.

Read TracWorkflow for more information (don't forget to 'wiki upgrade' as well)

"""
        self.log.info(info_message.replace('\n', ' ').replace('==', ''))
        print info_message

    # ITicketActionController methods

    def get_ticket_actions(self, req, ticket):
        """Returns a list of (weight, action) tuples that are valid for this
        request and this ticket."""
        # Get the list of actions that can be performed

        # Determine the current status of this ticket.  If this ticket is in
        # the process of being modified, we need to base our information on the
        # pre-modified state so that we don't try to do two (or more!) steps at
        # once and get really confused.
        status = ticket._old.get('status', ticket['status']) or 'new'

        ticket_perm = req.perm(ticket.resource)
        allowed_actions = []
        for action_name, action_info in self.actions.items():
            oldstates = action_info['oldstates']
            if oldstates == ['*'] or status in oldstates:
                # This action is valid in this state.  Check permissions.
                required_perms = action_info['permissions']
                if self._is_action_allowed(ticket_perm, required_perms):
                    allowed_actions.append((action_info['default'],
                                            action_name))
        if not (status in ['new', 'closed'] or \
                    status in TicketSystem(self.env).get_all_status()) \
                and 'TICKET_ADMIN' in ticket_perm:
            # State no longer exists - add a 'reset' action if admin.
            allowed_actions.append((0, '_reset'))
        return allowed_actions

    def _is_action_allowed(self, ticket_perm, required_perms):
        if not required_perms:
            return True
        for permission in required_perms:
            if permission in ticket_perm:
                return True
        return False

    def get_all_status(self):
        """Return a list of all states described by the configuration.

        """
        all_status = set()
        for action_name, action_info in self.actions.items():
            all_status.update(action_info['oldstates'])
            all_status.add(action_info['newstate'])
        all_status.discard('*')
        all_status.discard('')
        return all_status

    def render_ticket_action_control(self, req, ticket, action):

        self.log.debug('render_ticket_action_control: action "%s"' % action)

        this_action = self.actions[action]
        status = this_action['newstate']
        operations = this_action['operations']
        current_owner = ticket._old.get('owner', ticket['owner'] or '(none)')
        if not (Chrome(self.env).show_email_addresses
                or 'EMAIL_VIEW' in req.perm(ticket.resource)):
            format_user = obfuscate_email_address
        else:
            format_user = lambda address: address
        current_owner = format_user(current_owner)

        control = [] # default to nothing
        hints = []
        if 'reset_workflow' in operations:
            control.append(tag("from invalid state "))
            hints.append(_("Current state no longer exists"))
        if 'del_owner' in operations:
            hints.append(_("The ticket will be disowned"))
        if 'set_owner' in operations:
            id = 'action_%s_reassign_owner' % action
            selected_owner = req.args.get(id, req.authname)

            if this_action.has_key('set_owner'):
                owners = [x.strip() for x in
                          this_action['set_owner'].split(',')]
            elif self.config.getbool('ticket', 'restrict_owner'):
                perm = PermissionSystem(self.env)
                owners = perm.get_users_with_permission('TICKET_MODIFY')
                owners.sort()
            else:
                owners = None

            if owners == None:
                owner = req.args.get(id, req.authname)
                control.append(tag_('to %(owner)s',
                                    owner=tag.input(type='text', id=id,
                                                    name=id, value=owner)))
                hints.append(_("The owner will be changed from "
                               "%(current_owner)s",
                               current_owner=current_owner))
            elif len(owners) == 1:
                owner = tag.input(type='hidden', id=id, name=id,
                                  value=owners[0])
                formatted_owner = format_user(owners[0])
                control.append(tag_('to %(owner)s ',
                                    owner=tag(formatted_owner, owner)))
                if ticket['owner'] != owners[0]:
                    hints.append(_("The owner will be changed from "
                                   "%(current_owner)s to %(selected_owner)s",
                                   current_owner=current_owner,
                                   selected_owner=formatted_owner))
            else:
                control.append(tag_('to %(owner)s', owner=tag.select(
                    [tag.option(x, value=x,
                                selected=(x == selected_owner or None))
                     for x in owners],
                    id=id, name=id)))
                hints.append(_("The owner will be changed from "
                               "%(current_owner)s to the selected user",
                               current_owner=current_owner))
        elif 'set_owner_to_self' in operations and \
                ticket._old.get('owner', ticket['owner']) != req.authname:
            hints.append(_("The owner will be changed from %(current_owner)s "
                           "to %(authname)s", current_owner=current_owner,
                           authname=req.authname))
        if 'set_resolution' in operations:
            if this_action.has_key('set_resolution'):
                resolutions = [x.strip() for x in
                               this_action['set_resolution'].split(',')]
            else:
                resolutions = [val.name for val in Resolution.select(self.env)]
            if not resolutions:
                raise TracError(_("Your workflow attempts to set a resolution "
                                  "but none is defined (configuration issue, "
                                  "please contact your Trac admin)."))
            id = 'action_%s_resolve_resolution' % action
            if len(resolutions) == 1:
                resolution = tag.input(type='hidden', id=id, name=id,
                                       value=resolutions[0])
                control.append(tag_('as %(resolution)s',
                                    resolution=tag(resolutions[0],
                                                   resolution)))
                hints.append(_("The resolution will be set to %(name)s",
                               name=resolutions[0]))
            else:
                selected_option = req.args.get(id,
                        TicketSystem(self.env).default_resolution)
                control.append(tag_('as %(resolution)s',
                                    resolution=tag.select(
                    [tag.option(x, value=x,
                                selected=(x == selected_option or None))
                     for x in resolutions],
                    id=id, name=id)))
                hints.append(_("The resolution will be set"))
        if 'del_resolution' in operations:
            hints.append(_("The resolution will be deleted"))
        if 'leave_status' in operations:
            control.append(_('as %(status)s ',
                             status= ticket._old.get('status',
                                                     ticket['status'])))
        else:
            if status != '*':
                hints.append(_("Next status will be '%(name)s'", name=status))
        return (this_action['name'], tag(*control), '. '.join(hints) + ".")

    def get_ticket_changes(self, req, ticket, action):
        this_action = self.actions[action]

        # Enforce permissions
        if not self._has_perms_for_action(req, this_action, ticket.resource):
            # The user does not have any of the listed permissions, so we won't
            # do anything.
            return {}

        updated = {}
        # Status changes
        status = this_action['newstate']
        if status != '*':
            updated['status'] = status

        for operation in this_action['operations']:
            if operation == 'reset_workflow':
                updated['status'] = 'new'
            elif operation == 'del_owner':
                updated['owner'] = ''
            elif operation == 'set_owner':
                newowner = req.args.get('action_%s_reassign_owner' % action,
                                    this_action.get('set_owner', '').strip())
                # If there was already an owner, we get a list, [new, old],
                # but if there wasn't we just get new.
                if type(newowner) == list:
                    newowner = newowner[0]
                updated['owner'] = newowner
            elif operation == 'set_owner_to_self':
                updated['owner'] = req.authname
            elif operation == 'del_resolution':
                updated['resolution'] = ''
            elif operation == 'set_resolution':
                newresolution = req.args.get('action_%s_resolve_resolution' % \
                                             action,
                                this_action.get('set_resolution', '').strip())
                updated['resolution'] = newresolution

            # leave_status is just a no-op here, so we don't look for it.
        return updated

    def apply_action_side_effects(self, req, ticket, action):
        pass

    def _has_perms_for_action(self, req, action, resource):
        required_perms = action['permissions']
        if required_perms:
            for permission in required_perms:
                if permission in req.perm(resource):
                    break
            else:
                # The user does not have any of the listed permissions
                return False
        return True

    # Public methods (for other ITicketActionControllers that want to use
    #                 our config file and provide an operation for an action)

    def get_actions_by_operation(self, operation):
        """Return a list of all actions with a given operation
        (for use in the controller's get_all_status())
        """
        actions = [(info['default'], action) for action, info
                   in self.actions.items()
                   if operation in info['operations']]
        return actions

    def get_actions_by_operation_for_req(self, req, ticket, operation):
        """Return list of all actions with a given operation that are valid
        in the given state for the controller's get_ticket_actions().

        If state='*' (the default), all actions with the given operation are
        returned.
        """
        # Be sure to look at the original status.
        status = ticket._old.get('status', ticket['status'])
        actions = [(info['default'], action) for action, info
                   in self.actions.items()
                   if operation in info['operations'] and
                      ('*' in info['oldstates'] or
                       status in info['oldstates']) and
                      self._has_perms_for_action(req, info, ticket.resource)]
        return actions


class WorkflowMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Render a workflow graph.

    This macro accepts a TracWorkflow configuration and renders the states
    and transitions as a directed graph. If no parameters are given, the
    current ticket workflow is rendered. In WikiProcessors mode the `width`
    and `height` arguments can be specified.

    (Defaults: `width = 800` and `heigth = 600`)

    Examples:
    {{{
        [[Workflow()]]

        [[Workflow(go = here -> there; return = there -> here)]]

        {{{
        #!Workflow width=700 height=700
        leave = * -> *
        leave.operations = leave_status
        leave.default = 1

        accept = new,assigned,accepted,reopened -> accepted
        accept.permissions = TICKET_MODIFY
        accept.operations = set_owner_to_self

        resolve = new,assigned,accepted,reopened -> closed
        resolve.permissions = TICKET_MODIFY
        resolve.operations = set_resolution

        reassign = new,assigned,accepted,reopened -> assigned
        reassign.permissions = TICKET_MODIFY
        reassign.operations = set_owner

        reopen = closed -> reopened
        reopen.permissions = TICKET_CREATE
        reopen.operations = del_resolution
        }}}
    }}}
    """)

    def expand_macro(self, formatter, name, text, args):
        if not text:
            raw_actions = self.config.options('ticket-workflow')
        else:
            if args is None:
                text = '\n'.join([line.lstrip() for line in text.split(';')])
            if not '[ticket-workflow]' in text:
                text = '[ticket-workflow]\n' + text
            parser = RawConfigParser()
            parser.readfp(StringIO(text))
            raw_actions = list(parser.items('ticket-workflow'))
        actions = parse_workflow_config(raw_actions)
        states = list(set(
            [state for action in actions.itervalues()
                   for state in action['oldstates']] +
            [action['newstate'] for action in actions.itervalues()]))
        action_names = actions.keys()
        edges = []
        for name, action in actions.items():
            new_index = states.index(action['newstate'])
            name_index = action_names.index(name)
            for old_state in action['oldstates']:
                old_index = states.index(old_state)
                edges.append((old_index, new_index, name_index))

        args = args or {}
        graph = {'nodes': states, 'actions': action_names, 'edges': edges,
                 'width': args.get('width', 800),
                 'height': args.get('height', 600)}
        graph_id = '%012x' % id(graph)
        req = formatter.req
        add_script(req, 'common/js/excanvas.js', ie_if='IE')
        add_script(req, 'common/js/workflow_graph.js')
        add_script_data(req, {'graph_%s' % graph_id: graph})
        return tag.div(_("Enable JavaScript to display the workflow graph."),
                       class_='trac-workflow-graph system-message',
                       id='trac-workflow-graph-%s' % graph_id)

########NEW FILE########
__FILENAME__ = model
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2006 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import re
from datetime import datetime

from trac.attachment import Attachment
from trac import core
from trac.cache import cached
from trac.core import TracError
from trac.resource import Resource, ResourceNotFound, ResourceSystem
from trac.ticket.api import TicketSystem
from trac.util import embedded_numbers, partition
from trac.util.text import empty
from trac.util.datefmt import from_utimestamp, to_utimestamp, utc, utcmax
from trac.util.translation import _

__all__ = ['Ticket', 'Type', 'Status', 'Resolution', 'Priority', 'Severity',
           'Component', 'Milestone', 'Version', 'group_milestones']


def _fixup_cc_list(cc_value):
    """Fix up cc list separators and remove duplicates."""
    cclist = []
    for cc in re.split(r'[;,\s]+', cc_value):
        if cc and cc not in cclist:
            cclist.append(cc)
    return ', '.join(cclist)


class Ticket(object):

    # Fields that must not be modified directly by the user
    protected_fields = ('resolution', 'status', 'time', 'changetime')

    @staticmethod
    def id_is_valid(num):
        return 0 < int(num) <= 1L << 31

    # 0.11 compatibility
    time_created = property(lambda self: self.values.get('time'))
    time_changed = property(lambda self: self.values.get('changetime'))

    def __init__(self, env, tkt_id=None, db=None, version=None):
        """
        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        self.env = env
        if tkt_id is not None:
            tkt_id = int(tkt_id)
        self.resource = Resource('ticket', tkt_id, version)
        self.fields = TicketSystem(self.env).get_ticket_fields()
        self.std_fields, self.custom_fields, self.time_fields = [], [], []
        for f in self.fields:
            if f.get('custom'):
                self.custom_fields.append(f['name'])
            else:
                self.std_fields.append(f['name'])
            if f['type'] == 'time':
                self.time_fields.append(f['name'])
        self.values = {}
        if tkt_id is not None:
            self._fetch_ticket(tkt_id)
        else:
            self._init_defaults()
            self.id = None
        self._old = {}

    exists = property(lambda self: self.id is not None)

    def _init_defaults(self):
        for field in self.fields:
            default = None
            if field['name'] in self.protected_fields:
                # Ignore for new - only change through workflow
                pass
            elif not field.get('custom'):
                default = self.env.config.get('ticket',
                                              'default_' + field['name'])
            else:
                default = field.get('value')
                options = field.get('options')
                if default and options and default not in options:
                    try:
                        default = options[int(default)]
                    except (ValueError, IndexError):
                        self.env.log.warning('Invalid default value "%s" '
                                             'for custom field "%s"'
                                             % (default, field['name']))
            if default:
                self.values.setdefault(field['name'], default)

    def _fetch_ticket(self, tkt_id):
        row = None
        if self.id_is_valid(tkt_id):
            # Fetch the standard ticket fields
            for row in self.env.db_query("SELECT %s FROM ticket WHERE id=%%s" %
                                         ','.join(self.std_fields), (tkt_id,)):
                break
        if not row:
            raise ResourceNotFound(_("Ticket %(id)s does not exist.",
                                     id=tkt_id), _("Invalid ticket number"))

        self.id = tkt_id
        for i, field in enumerate(self.std_fields):
            value = row[i]
            if field in self.time_fields:
                self.values[field] = from_utimestamp(value)
            elif value is None:
                self.values[field] = empty
            else:
                self.values[field] = value

        # Fetch custom fields if available
        for name, value in self.env.db_query("""
                SELECT name, value FROM ticket_custom WHERE ticket=%s
                """, (tkt_id,)):
            if name in self.custom_fields:
                if value is None:
                    self.values[name] = empty
                else:
                    self.values[name] = value

    def __getitem__(self, name):
        return self.values.get(name)

    def __setitem__(self, name, value):
        """Log ticket modifications so the table ticket_change can be updated
        """
        if name in self.values and self.values[name] == value:
            return
        if name not in self._old: # Changed field
            self._old[name] = self.values.get(name)
        elif self._old[name] == value: # Change of field reverted
            del self._old[name]
        if value:
            if isinstance(value, list):
                raise TracError(_("Multi-values fields not supported yet"))
            field = [field for field in self.fields if field['name'] == name]
            if field and field[0].get('type') != 'textarea':
                value = value.strip()
        self.values[name] = value

    def get_value_or_default(self, name):
        """Return the value of a field or the default value if it is undefined
        """
        try:
            value = self.values[name]
            return value if value is not empty else self.get_default(name)
        except KeyError:
            pass

    def get_default(self, name):
        """Return the default value of a field."""
        field = [field for field in self.fields if field['name'] == name]
        if field:
            return field[0].get('value', '')

    def populate(self, values):
        """Populate the ticket with 'suitable' values from a dictionary"""
        field_names = [f['name'] for f in self.fields]
        for name in [name for name in values.keys() if name in field_names]:
            self[name] = values.get(name, '')

        # We have to do an extra trick to catch unchecked checkboxes
        for name in [name for name in values.keys() if name[9:] in field_names
                     and name.startswith('checkbox_')]:
            if name[9:] not in values:
                self[name[9:]] = '0'

    def insert(self, when=None, db=None):
        """Add ticket to database.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert not self.exists, 'Cannot insert an existing ticket'

        if 'cc' in self.values:
            self['cc'] = _fixup_cc_list(self.values['cc'])

        # Add a timestamp
        if when is None:
            when = datetime.now(utc)
        self.values['time'] = self.values['changetime'] = when

        # The owner field defaults to the component owner
        if self.values.get('owner') == '< default >':
            default_to_owner = ''
            if self.values.get('component'):
                try:
                    component = Component(self.env, self['component'])
                    default_to_owner = component.owner # even if it's empty
                except ResourceNotFound:
                    # No such component exists
                    pass
            # If the current owner is "< default >", we need to set it to
            # _something_ else, even if that something else is blank.
            self['owner'] = default_to_owner

        # Perform type conversions
        values = dict(self.values)
        for field in self.time_fields:
            if field in values:
                values[field] = to_utimestamp(values[field])

        # Insert ticket record
        std_fields = []
        custom_fields = []
        for f in self.fields:
            fname = f['name']
            if fname in self.values:
                if f.get('custom'):
                    custom_fields.append(fname)
                else:
                    std_fields.append(fname)
        with self.env.db_transaction as db:
            cursor = db.cursor()
            cursor.execute("INSERT INTO ticket (%s) VALUES (%s)"
                           % (','.join(std_fields),
                              ','.join(['%s'] * len(std_fields))),
                           [values[name] for name in std_fields])
            if getattr(self.env, '_multiproduct_schema_enabled', False):
                tkt_id = db.get_last_id(cursor, 'ticket', 'uid')
                rows = db("""SELECT id FROM ticket WHERE uid=%s""", (tkt_id,))
                if len(rows) != 1:
                    # One row SHOULD always be retrieved, but if it does not
                    # then insertion MUST fail since the cause may be a bug in 
                    # BH SQL translator executing previous INSERT without
                    # product prefix properly setup.
                    # By raising the error the transaction should be rolled back
                    raise AssertionError("No ticket id for uid " + str(tkt_id))
                tkt_id = rows[0][0]
            else:
                tkt_id = db.get_last_id(cursor, 'ticket')

            # Insert custom fields
            if custom_fields:
                db.executemany(
                    """INSERT INTO ticket_custom (ticket, name, value)
                       VALUES (%s, %s, %s)
                    """, [(tkt_id, c, self[c]) for c in custom_fields])

        self.id = tkt_id
        self.resource = self.resource(id=tkt_id)
        self._old = {}

        for listener in TicketSystem(self.env).change_listeners:
            listener.ticket_created(self)
        ResourceSystem(self.env).resource_created(self)

        return self.id

    def save_changes(self, author=None, comment=None, when=None, db=None,
                     cnum='', replyto=None):
        """
        Store ticket changes in the database. The ticket must already exist in
        the database.  Returns False if there were no changes to save, True
        otherwise.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        :since 1.0: the `cnum` parameter is deprecated, and threading should
        be controlled with the `replyto` argument
        """
        assert self.exists, "Cannot update a new ticket"

        if 'cc' in self.values:
            self['cc'] = _fixup_cc_list(self.values['cc'])

        props_unchanged = all(self.values.get(k) == v
                              for k, v in self._old.iteritems())
        if (not comment or not comment.strip()) and props_unchanged:
            return False # Not modified

        if when is None:
            when = datetime.now(utc)
        when_ts = to_utimestamp(when)

        if 'component' in self.values:
            # If the component is changed on a 'new' ticket
            # then owner field is updated accordingly. (#623).
            if self.values.get('status') == 'new' \
                    and 'component' in self._old \
                    and 'owner' not in self._old:
                try:
                    old_comp = Component(self.env, self._old['component'])
                    old_owner = old_comp.owner or ''
                    current_owner = self.values.get('owner') or ''
                    if old_owner == current_owner:
                        new_comp = Component(self.env, self['component'])
                        if new_comp.owner:
                            self['owner'] = new_comp.owner
                except TracError:
                    # If the old component has been removed from the database
                    # we just leave the owner as is.
                    pass

        with self.env.db_transaction as db:
            db("UPDATE ticket SET changetime=%s WHERE id=%s",
               (when_ts, self.id))

            # find cnum if it isn't provided
            if not cnum:
                num = 0
                for ts, old in db("""
                        SELECT DISTINCT tc1.time, COALESCE(tc2.oldvalue,'')
                        FROM ticket_change AS tc1
                        LEFT OUTER JOIN ticket_change AS tc2
                        ON tc2.ticket=%s AND tc2.time=tc1.time
                           AND tc2.field='comment'
                        WHERE tc1.ticket=%s ORDER BY tc1.time DESC
                        """, (self.id, self.id)):
                    # Use oldvalue if available, else count edits
                    try:
                        num += int(old.rsplit('.', 1)[-1])
                        break
                    except ValueError:
                        num += 1
                cnum = str(num + 1)
                if replyto:
                    cnum = '%s.%s' % (replyto, cnum)

            # store fields
            for name in self._old.keys():
                if name in self.custom_fields:
                    for row in db("""SELECT * FROM ticket_custom
                                     WHERE ticket=%s and name=%s
                                     """, (self.id, name)):
                        db("""UPDATE ticket_custom SET value=%s
                              WHERE ticket=%s AND name=%s
                              """, (self[name], self.id, name))
                        break
                    else:
                        db("""INSERT INTO ticket_custom (ticket,name,value)
                              VALUES(%s,%s,%s)
                              """, (self.id, name, self[name]))
                else:
                    db("UPDATE ticket SET %s=%%s WHERE id=%%s"
                       % name, (self[name], self.id))
                db("""INSERT INTO ticket_change
                        (ticket,time,author,field,oldvalue,newvalue)
                      VALUES (%s, %s, %s, %s, %s, %s)
                      """, (self.id, when_ts, author, name, self._old[name],
                            self[name]))

            # always save comment, even if empty
            # (numbering support for timeline)
            db("""INSERT INTO ticket_change
                    (ticket,time,author,field,oldvalue,newvalue)
                  VALUES (%s,%s,%s,'comment',%s,%s)
                  """, (self.id, when_ts, author, cnum, comment))

        old_values = self._old
        self._old = {}
        self.values['changetime'] = when

        for listener in TicketSystem(self.env).change_listeners:
            listener.ticket_changed(self, comment, author, old_values)
        context = dict(comment=comment, author=author)
        ResourceSystem(self.env).resource_changed(self, old_values, context)

        return int(cnum.rsplit('.', 1)[-1])

    def get_changelog(self, when=None, db=None):
        """Return the changelog as a list of tuples of the form
        (time, author, field, oldvalue, newvalue, permanent).

        While the other tuple elements are quite self-explanatory,
        the `permanent` flag is used to distinguish collateral changes
        that are not yet immutable (like attachments, currently).

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        sid = str(self.id)
        when_ts = to_utimestamp(when)
        if when_ts:
            sql = """
                SELECT time, author, field, oldvalue, newvalue, 1 AS permanent
                FROM ticket_change WHERE ticket=%s AND time=%s
                  UNION
                SELECT time, author, 'attachment', null, filename,
                  0 AS permanent
                FROM attachment WHERE type='ticket' AND id=%s AND time=%s
                  UNION
                SELECT time, author, 'comment', null, description,
                  0 AS permanent
                FROM attachment WHERE type='ticket' AND id=%s AND time=%s
                ORDER BY time,permanent,author
                """
            args = (self.id, when_ts, sid, when_ts, sid, when_ts)
        else:
            sql = """
                SELECT time, author, field, oldvalue, newvalue, 1 AS permanent
                FROM ticket_change WHERE ticket=%s
                  UNION
                SELECT time, author, 'attachment', null, filename,
                  0 AS permanent
                FROM attachment WHERE type='ticket' AND id=%s
                  UNION
                SELECT time, author, 'comment', null, description,
                  0 AS permanent
                FROM attachment WHERE type='ticket' AND id=%s
                ORDER BY time,permanent,author
                """
            args = (self.id, sid, sid)
        return [(from_utimestamp(t), author, field, oldvalue or '',
                 newvalue or '', permanent)
                for t, author, field, oldvalue, newvalue, permanent in
                self.env.db_query(sql, args)]

    def delete(self, db=None):
        """Delete the ticket.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        with self.env.db_transaction as db:
            Attachment.delete_all(self.env, 'ticket', self.id, db)
            db("DELETE FROM ticket WHERE id=%s", (self.id,))
            db("DELETE FROM ticket_change WHERE ticket=%s", (self.id,))
            db("DELETE FROM ticket_custom WHERE ticket=%s", (self.id,))

        for listener in TicketSystem(self.env).change_listeners:
            listener.ticket_deleted(self)
        ResourceSystem(self.env).resource_deleted(self)

    def get_change(self, cnum=None, cdate=None, db=None):
        """Return a ticket change by its number or date.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        if cdate is None:
            row = self._find_change(cnum)
            if not row:
                return
            cdate = from_utimestamp(row[0])
        ts = to_utimestamp(cdate)
        fields = {}
        change = {'date': cdate, 'fields': fields}
        for field, author, old, new in self.env.db_query("""
                SELECT field, author, oldvalue, newvalue
                FROM ticket_change WHERE ticket=%s AND time=%s
                """, (self.id, ts)):
            fields[field] = {'author': author, 'old': old, 'new': new}
            if field == 'comment':
                change['author'] = author
            elif not field.startswith('_'):
                change.setdefault('author', author)
        if fields:
            return change

    def delete_change(self, cnum=None, cdate=None, when=None):
        """Delete a ticket change identified by its number or date."""
        if cdate is None:
            row = self._find_change(cnum)
            if not row:
                return
            cdate = from_utimestamp(row[0])
        ts = to_utimestamp(cdate)
        if when is None:
            when = datetime.now(utc)
        when_ts = to_utimestamp(when)

        with self.env.db_transaction as db:
            # Find modified fields and their previous value
            fields = [(field, old, new)
                      for field, old, new in db("""
                        SELECT field, oldvalue, newvalue FROM ticket_change
                        WHERE ticket=%s AND time=%s
                        """, (self.id, ts))
                      if field != 'comment' and not field.startswith('_')]
            for field, oldvalue, newvalue in fields:
                # Find the next change
                for next_ts, in db("""SELECT time FROM ticket_change
                                      WHERE ticket=%s AND time>%s AND field=%s
                                      LIMIT 1
                                      """, (self.id, ts, field)):
                    # Modify the old value of the next change if it is equal
                    # to the new value of the deleted change
                    db("""UPDATE ticket_change SET oldvalue=%s
                          WHERE ticket=%s AND time=%s AND field=%s
                          AND oldvalue=%s
                          """, (oldvalue, self.id, next_ts, field, newvalue))
                    break
                else:
                    # No next change, edit ticket field
                    if field in self.std_fields:
                        db("UPDATE ticket SET %s=%%s WHERE id=%%s"
                           % field, (oldvalue, self.id))
                    else:
                        db("""UPDATE ticket_custom SET value=%s
                              WHERE ticket=%s AND name=%s
                              """, (oldvalue, self.id, field))

            # Delete the change
            db("DELETE FROM ticket_change WHERE ticket=%s AND time=%s",
               (self.id, ts))

            # Update last changed time
            db("UPDATE ticket SET changetime=%s WHERE id=%s",
               (when_ts, self.id))

        self._fetch_ticket(self.id)

    def modify_comment(self, cdate, author, comment, when=None):
        """Modify a ticket comment specified by its date, while keeping a
        history of edits.
        """
        ts = to_utimestamp(cdate)
        if when is None:
            when = datetime.now(utc)
        when_ts = to_utimestamp(when)

        with self.env.db_transaction as db:
            # Find the current value of the comment
            old_comment = False
            for old_comment, in db("""
                    SELECT newvalue FROM ticket_change
                    WHERE ticket=%s AND time=%s AND field='comment'
                    """, (self.id, ts)):
                break
            if comment == (old_comment or ''):
                return

            # Comment history is stored in fields named "_comment%d"
            # Find the next edit number
            fields = db("""SELECT field FROM ticket_change
                           WHERE ticket=%%s AND time=%%s AND field %s
                           """ % db.like(),
                           (self.id, ts, db.like_escape('_comment') + '%'))
            rev = max(int(field[8:]) for field, in fields) + 1 if fields else 0
            db("""INSERT INTO ticket_change
                    (ticket,time,author,field,oldvalue,newvalue)
                  VALUES (%s,%s,%s,%s,%s,%s)
                  """, (self.id, ts, author, '_comment%d' % rev,
                        old_comment or '', str(when_ts)))
            if old_comment is False:
                # There was no comment field, add one, find the
                # original author in one of the other changed fields
                old_author = None
                for old_author, in db("""
                        SELECT author FROM ticket_change
                        WHERE ticket=%%s AND time=%%s AND NOT field %s LIMIT 1
                        """ % db.like(),
                        (self.id, ts, db.like_escape('_') + '%')):
                    db("""INSERT INTO ticket_change
                            (ticket,time,author,field,oldvalue,newvalue)
                          VALUES (%s,%s,%s,'comment','',%s)
                          """, (self.id, ts, old_author, comment))
            else:
                db("""UPDATE ticket_change SET newvalue=%s
                      WHERE ticket=%s AND time=%s AND field='comment'
                      """, (comment, self.id, ts))

            # Update last changed time
            db("UPDATE ticket SET changetime=%s WHERE id=%s",
               (when_ts, self.id))

        self.values['changetime'] = when

    def get_comment_history(self, cnum=None, cdate=None, db=None):
        """Retrieve the edit history of a comment identified by its number or
        date.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        if cdate is None:
            row = self._find_change(cnum)
            if not row:
                return
            ts0, author0, last_comment = row
        else:
            ts0, author0, last_comment = to_utimestamp(cdate), None, None
        with self.env.db_query as db:
            # Get last comment and author if not available
            if last_comment is None:
                last_comment = ''
                for author0, last_comment in db("""
                        SELECT author, newvalue FROM ticket_change
                        WHERE ticket=%s AND time=%s AND field='comment'
                        """, (self.id, ts0)):
                    break
            if author0 is None:
                for author0, last_comment in db("""
                        SELECT author, newvalue FROM ticket_change
                        WHERE ticket=%%s AND time=%%s AND NOT field %s LIMIT 1
                        """ % db.like(),
                        (self.id, ts0, db.like_escape('_') + '%')):
                    break
                else:
                    return

            # Get all fields of the form "_comment%d"
            rows = db("""SELECT field, author, oldvalue, newvalue
                         FROM ticket_change
                         WHERE ticket=%%s AND time=%%s AND field %s
                         """ % db.like(),
                         (self.id, ts0, db.like_escape('_comment') + '%'))
            rows = sorted((int(field[8:]), author, old, new)
                          for field, author, old, new in rows)
            history = []
            for rev, author, comment, ts in rows:
                history.append((rev, from_utimestamp(long(ts0)), author0,
                                comment))
                ts0, author0 = ts, author
            history.sort()
            rev = history[-1][0] + 1 if history else 0
            history.append((rev, from_utimestamp(long(ts0)), author0,
                            last_comment))
            return history

    def _find_change(self, cnum):
        """Find a comment by its number."""
        scnum = str(cnum)
        with self.env.db_query as db:
            for row in db("""
                    SELECT time, author, newvalue FROM ticket_change
                    WHERE ticket=%%s AND field='comment'
                    AND (oldvalue=%%s OR oldvalue %s)
                    """ % db.like(),
                    (self.id, scnum, '%' + db.like_escape('.' + scnum))):
                return row

            # Fallback when comment number is not available in oldvalue
            num = 0
            for ts, old, author, comment in db("""
                    SELECT DISTINCT tc1.time, COALESCE(tc2.oldvalue,''),
                                    tc2.author, COALESCE(tc2.newvalue,'')
                    FROM ticket_change AS tc1
                    LEFT OUTER JOIN ticket_change AS tc2
                    ON tc2.ticket=%s AND tc2.time=tc1.time
                       AND tc2.field='comment'
                    WHERE tc1.ticket=%s ORDER BY tc1.time
                    """, (self.id, self.id)):
                # Use oldvalue if available, else count edits
                try:
                    num = int(old.rsplit('.', 1)[-1])
                except ValueError:
                    num += 1
                if num == cnum:
                    break
            else:
                return

            # Find author if NULL
            if author is None:
                for author, in db("""
                        SELECT author FROM ticket_change
                        WHERE ticket=%%s AND time=%%s AND NOT field %s LIMIT 1
                        """ % db.like(),
                        (self.id, ts, db.like_escape('_') + '%')):
                    break
            return (ts, author, comment)


def simplify_whitespace(name):
    """Strip spaces and remove duplicate spaces within names"""
    if name:
        return ' '.join(name.split())
    return name


class AbstractEnum(object):
    type = None
    ticket_col = None

    def __init__(self, env, name=None, db=None):
        if not self.ticket_col:
            self.ticket_col = self.type
        self.env = env
        if name:
            for value, in self.env.db_query("""
                    SELECT value FROM enum WHERE type=%s AND name=%s
                    """, (self.type, name)):
                self.value = self._old_value = value
                self.name = self._old_name = name
                break
            else:
                raise ResourceNotFound(_("%(type)s %(name)s does not exist.",
                                         type=self.type, name=name))
        else:
            self.value = self._old_value = None
            self.name = self._old_name = None

    exists = property(lambda self: self._old_value is not None)

    def delete(self, db=None):
        """Delete the enum value.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert self.exists, "Cannot delete non-existent %s" % self.type

        with self.env.db_transaction as db:
            self.env.log.info("Deleting %s %s", self.type, self.name)
            db("DELETE FROM enum WHERE type=%s AND value=%s",
               (self.type, self._old_value))
            # Re-order any enums that have higher value than deleted
            # (close gap)
            for enum in self.select(self.env):
                try:
                    if int(enum.value) > int(self._old_value):
                        enum.value = unicode(int(enum.value) - 1)
                        enum.update()
                except ValueError:
                    pass # Ignore cast error for this non-essential operation
            TicketSystem(self.env).reset_ticket_fields()

        ResourceSystem(self.env).resource_deleted(self)
        self.value = self._old_value = None
        self.name = self._old_name = None

    def insert(self, db=None):
        """Add a new enum value.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert not self.exists, "Cannot insert existing %s" % self.type
        self.name = simplify_whitespace(self.name)
        if not self.name:
            raise TracError(_('Invalid %(type)s name.', type=self.type))

        with self.env.db_transaction as db:
            self.env.log.debug("Creating new %s '%s'", self.type, self.name)
            if not self.value:
                row = db("SELECT COALESCE(MAX(%s), 0) FROM enum WHERE type=%%s"
                         % db.cast('value', 'int'),
                         (self.type,))
                self.value = int(float(row[0][0])) + 1 if row else 0
            db("INSERT INTO enum (type, name, value) VALUES (%s, %s, %s)",
               (self.type, self.name, self.value))
            TicketSystem(self.env).reset_ticket_fields()

        self._old_name = self.name
        self._old_value = self.value
        ResourceSystem(self.env).resource_created(self)

    def update(self, db=None):
        """Update the enum value.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert self.exists, "Cannot update non-existent %s" % self.type
        self.name = simplify_whitespace(self.name)
        if not self.name:
            raise TracError(_("Invalid %(type)s name.", type=self.type))

        with self.env.db_transaction as db:
            self.env.log.info("Updating %s '%s'", self.type, self.name)
            db("UPDATE enum SET name=%s,value=%s WHERE type=%s AND name=%s",
               (self.name, self.value, self.type, self._old_name))
            if self.name != self._old_name:
                # Update tickets
                db("UPDATE ticket SET %s=%%s WHERE %s=%%s"
                   % (self.ticket_col, self.ticket_col),
                   (self.name, self._old_name))
            TicketSystem(self.env).reset_ticket_fields()

        old_values = dict()
        if self.name != self._old_name:
            old_values["name"] = self._old_name
        if self.value != self._old_value:
            old_values["value"] = self._old_value
        self._old_name = self.name
        self._old_value = self.value
        ResourceSystem(self.env).resource_changed(self, old_values)

    @classmethod
    def select(cls, env, db=None):
        """
        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        with env.db_query as db:
            for name, value in db("""
                    SELECT name, value FROM enum WHERE type=%s ORDER BY
                    """ + db.cast('value', 'int'),
                    (cls.type,)):
                obj = cls(env)
                obj.name = obj._old_name = name
                obj.value = obj._old_value = value
                yield obj


class Type(AbstractEnum):
    type = 'ticket_type'
    ticket_col = 'type'


class Status(object):
    def __init__(self, env):
        self.env = env

    @classmethod
    def select(cls, env, db=None):
        for state in TicketSystem(env).get_all_status():
            status = cls(env)
            status.name = state
            yield status


class Resolution(AbstractEnum):
    type = 'resolution'


class Priority(AbstractEnum):
    type = 'priority'


class Severity(AbstractEnum):
    type = 'severity'


class Component(object):
    def __init__(self, env, name=None, db=None):
        """
        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        self.env = env
        self.name = self._old_name = self.owner = self.description = None
        if name:
            for owner, description in self.env.db_query("""
                    SELECT owner, description FROM component WHERE name=%s
                    """, (name,)):
                self.name = self._old_name = name
                self.owner = owner or None
                self.description = description or ''
                break
            else:
                raise ResourceNotFound(_("Component %(name)s does not exist.",
                                         name=name))

    exists = property(lambda self: self._old_name is not None)

    def delete(self, db=None):
        """Delete the component.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert self.exists, "Cannot delete non-existent component"

        with self.env.db_transaction as db:
            self.env.log.info("Deleting component %s", self.name)
            db("DELETE FROM component WHERE name=%s", (self.name,))
            TicketSystem(self.env).reset_ticket_fields()

        ResourceSystem(self.env).resource_deleted(self)
        self.name = self._old_name = None

    def insert(self, db=None):
        """Insert a new component.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert not self.exists, "Cannot insert existing component"
        self.name = simplify_whitespace(self.name)
        if not self.name:
            raise TracError(_("Invalid component name."))

        with self.env.db_transaction as db:
            self.env.log.debug("Creating new component '%s'", self.name)
            db("""INSERT INTO component (name,owner,description)
                  VALUES (%s,%s,%s)
                  """, (self.name, self.owner, self.description))
            self._old_name = self.name
            TicketSystem(self.env).reset_ticket_fields()

        ResourceSystem(self.env).resource_created(self)

    def update(self, db=None):
        """Update the component.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert self.exists, "Cannot update non-existent component"
        self.name = simplify_whitespace(self.name)
        if not self.name:
            raise TracError(_("Invalid component name."))

        old_name = self._old_name
        with self.env.db_transaction as db:
            self.env.log.info("Updating component '%s'", self.name)
            db("""UPDATE component SET name=%s,owner=%s, description=%s
                  WHERE name=%s
                  """, (self.name, self.owner, self.description,
                        self._old_name))
            if self.name != self._old_name:
                # Update tickets
                db("UPDATE ticket SET component=%s WHERE component=%s",
                   (self.name, self._old_name))
                self._old_name = self.name
            TicketSystem(self.env).reset_ticket_fields()

        #todo:add support of old_values for owner and description fields
        old_values = dict()
        if self.name != old_name:
            old_values["name"] = old_name
        ResourceSystem(self.env).resource_changed(self, old_values)

    @classmethod
    def select(cls, env, db=None):
        """
        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        for name, owner, description in env.db_query("""
                SELECT name, owner, description FROM component ORDER BY name
            """):
            component = cls(env)
            component.name = component._old_name = name
            component.owner = owner or None
            component.description = description or ''
            yield component


class MilestoneCache(core.Component):
    """Cache for milestone data and factory for 'milestone' resources."""

    @cached
    def milestones(self):
        """Dictionary containing milestone data, indexed by name.

        Milestone data consist of a tuple containing the name, the
        datetime objects for due and completed dates and the
        description.
        """
        milestones = {}
        for name, due, completed, description in self.env.db_query("""
                SELECT name, due, completed, description FROM milestone
                """):
            milestones[name] = (name,
                    from_utimestamp(due) if due else None,
                    from_utimestamp(completed) if completed else None,
                    description or '')
        return milestones

    def fetchone(self, name, milestone=None):
        """Retrieve an existing milestone having the given `name`.

        If `milestone` is specified, fill that instance instead of creating
        a fresh one.

        :return: `None` if no such milestone exists
        """
        data = self.milestones.get(name)
        if data:
            return self.factory(data, milestone)

    def fetchall(self):
        """Iterator on all milestones."""
        for data in self.milestones.itervalues():
            yield self.factory(data)

    def factory(self, (name, due, completed, description), milestone=None):
        """Build a `Milestone` object from milestone data.

        That instance remains *private*, i.e. can't be retrieved by
        name by other processes or even by other threads in the same
        process, until its `~Milestone.insert` method gets called with
        success.
        """
        milestone = milestone or Milestone(self.env)
        milestone.name = name
        milestone.due = due
        milestone.completed = completed
        milestone.description = description
        milestone.checkin(invalidate=False)
        return milestone


class Milestone(object):
    def __init__(self, env, name=None, db=None):
        """Create an undefined milestone or fetch one from the database,
        if `name` is given.

        In the latter case however, raise `~trac.resource.ResourceNotFound`
        if a milestone of that name doesn't exist yet.
        """
        self.env = env
        if name:
            if not self.cache.fetchone(name, self):
                raise ResourceNotFound(
                    _("Milestone %(name)s does not exist.",
                      name=name), _("Invalid milestone name"))
        else:
            self.cache.factory((None, None, None, ''), self)

    @property
    def cache(self):
        return MilestoneCache(self.env)

    @property
    def resource(self):
        return Resource('milestone', self.name) ### .version !!!

    exists = property(lambda self: self._old['name'] is not None)
    is_completed = property(lambda self: self.completed is not None)
    is_late = property(lambda self: self.due and
                                    self.due < datetime.now(utc))

    def checkin(self, invalidate=True):
        self._old = {'name': self.name, 'due': self.due,
                     'completed': self.completed,
                     'description': self.description}
        if invalidate:
            del self.cache.milestones

    _to_old = checkin #: compatibility with hacks < 0.12.5 (remove in 1.1.1)

    def delete(self, retarget_to=None, author=None, db=None):
        """Delete the milestone.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        with self.env.db_transaction as db:
            self.env.log.info("Deleting milestone %s", self.name)
            db("DELETE FROM milestone WHERE name=%s", (self.name,))

            # Retarget/reset tickets associated with this milestone
            now = datetime.now(utc)
            tkt_ids = [int(row[0]) for row in
                       db("SELECT id FROM ticket WHERE milestone=%s",
                          (self.name,))]
            for tkt_id in tkt_ids:
                ticket = Ticket(self.env, tkt_id, db)
                ticket['milestone'] = retarget_to
                comment = "Milestone %s deleted" % self.name # don't translate
                ticket.save_changes(author, comment, now)
            self._old['name'] = None
            del self.cache.milestones
            TicketSystem(self.env).reset_ticket_fields()

        for listener in TicketSystem(self.env).milestone_change_listeners:
            listener.milestone_deleted(self)
        ResourceSystem(self.env).resource_deleted(self)

    def insert(self, db=None):
        """Insert a new milestone.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        self.name = simplify_whitespace(self.name)
        if not self.name:
            raise TracError(_("Invalid milestone name."))

        with self.env.db_transaction as db:
            self.env.log.debug("Creating new milestone '%s'", self.name)
            db("""INSERT INTO milestone (name, due, completed, description)
                  VALUES (%s,%s,%s,%s)
                  """, (self.name, to_utimestamp(self.due),
                        to_utimestamp(self.completed), self.description))
            self.checkin()
            TicketSystem(self.env).reset_ticket_fields()

        for listener in TicketSystem(self.env).milestone_change_listeners:
            listener.milestone_created(self)
        ResourceSystem(self.env).resource_created(self)

    def update(self, db=None):
        """Update the milestone.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        self.name = simplify_whitespace(self.name)
        if not self.name:
            raise TracError(_("Invalid milestone name."))

        old = self._old.copy()
        with self.env.db_transaction as db:
            old_name = old['name']
            self.env.log.info("Updating milestone '%s'", self.name)
            db("""UPDATE milestone
                  SET name=%s, due=%s, completed=%s, description=%s
                  WHERE name=%s
                  """, (self.name, to_utimestamp(self.due),
                        to_utimestamp(self.completed),
                        self.description, old_name))
            self.checkin()

            if self.name != old_name:
                # Update milestone field in tickets
                self.env.log.info("Updating milestone field of all tickets "
                                  "associated with milestone '%s'", self.name)
                db("UPDATE ticket SET milestone=%s WHERE milestone=%s",
                   (self.name, old_name))
                TicketSystem(self.env).reset_ticket_fields()

                # Reparent attachments
                Attachment.reparent_all(self.env, 'milestone', old_name,
                                        'milestone', self.name)

        old_values = dict((k, v) for k, v in old.iteritems()
                          if getattr(self, k) != v)
        for listener in TicketSystem(self.env).milestone_change_listeners:
            listener.milestone_changed(self, old_values)
        ResourceSystem(self.env).resource_changed(self, old_values)

    @classmethod
    def select(cls, env, include_completed=True, db=None):
        """
        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        milestones = MilestoneCache(env).fetchall()
        if not include_completed:
            milestones = [m for m in milestones if m.completed is None]
        def milestone_order(m):
            return (m.completed or utcmax,
                    m.due or utcmax,
                    embedded_numbers(m.name))
        return sorted(milestones, key=milestone_order)


def group_milestones(milestones, include_completed):
    """Group milestones into "open with due date", "open with no due date",
    and possibly "completed". Return a list of (label, milestones) tuples."""
    def category(m):
        return 1 if m.is_completed else 2 if m.due else 3
    open_due_milestones, open_not_due_milestones, \
        closed_milestones = partition([(m, category(m))
            for m in milestones], (2, 3, 1))
    groups = [
        (_('Open (by due date)'), open_due_milestones),
        (_('Open (no due date)'), open_not_due_milestones),
    ]
    if include_completed:
        groups.append((_('Closed'), closed_milestones))
    return groups


class Version(object):
    def __init__(self, env, name=None, db=None):
        self.env = env
        self.name = self._old_name = self.time = self.description = None
        if name:
            for time, description in self.env.db_query("""
                    SELECT time, description FROM version WHERE name=%s
                    """, (name,)):
                self.name = self._old_name = name
                self.time = from_utimestamp(time) if time else None
                self.description = description or ''
                break
            else:
                raise ResourceNotFound(_("Version %(name)s does not exist.",
                                         name=name))

    exists = property(lambda self: self._old_name is not None)

    def delete(self, db=None):
        """Delete the version.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert self.exists, "Cannot delete non-existent version"

        with self.env.db_transaction as db:
            self.env.log.info("Deleting version %s", self.name)
            db("DELETE FROM version WHERE name=%s", (self.name,))
            TicketSystem(self.env).reset_ticket_fields()

        ResourceSystem(self.env).resource_deleted(self)
        self.name = self._old_name = None

    def insert(self, db=None):
        """Insert a new version.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert not self.exists, "Cannot insert existing version"
        self.name = simplify_whitespace(self.name)
        if not self.name:
            raise TracError(_("Invalid version name."))

        with self.env.db_transaction as db:
            self.env.log.debug("Creating new version '%s'", self.name)
            db("INSERT INTO version (name,time,description) VALUES (%s,%s,%s)",
                (self.name, to_utimestamp(self.time), self.description))
            self._old_name = self.name
            TicketSystem(self.env).reset_ticket_fields()

        ResourceSystem(self.env).resource_created(self)

    def update(self, db=None):
        """Update the version.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert self.exists, "Cannot update non-existent version"
        self.name = simplify_whitespace(self.name)
        if not self.name:
            raise TracError(_("Invalid version name."))

        old_name=self._old_name
        with self.env.db_transaction as db:
            self.env.log.info("Updating version '%s'", self.name)
            db("""UPDATE version
                  SET name=%s, time=%s, description=%s WHERE name=%s
                  """, (self.name, to_utimestamp(self.time), self.description,
                        self._old_name))
            if self.name != self._old_name:
                # Update tickets
                db("UPDATE ticket SET version=%s WHERE version=%s",
                   (self.name, self._old_name))
                self._old_name = self.name
            TicketSystem(self.env).reset_ticket_fields()

        #todo: add support of old_values for time and description fields
        old_values = dict()
        if self.name != old_name:
            old_values["name"] = old_name
        ResourceSystem(self.env).resource_changed(self, old_values)

    @classmethod
    def select(cls, env, db=None):
        """
        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        versions = []
        for name, time, description in env.db_query("""
                SELECT name, time, description FROM version"""):
            version = cls(env)
            version.name = version._old_name = name
            version.time = from_utimestamp(time) if time else None
            version.description = description or ''
            versions.append(version)
        def version_order(v):
            return (v.time or utcmax, embedded_numbers(v.name))
        return sorted(versions, key=version_order, reverse=True)

########NEW FILE########
__FILENAME__ = notification
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Daniel Lundin <daniel@edgewall.com>
# Copyright (C) 2005-2006 Emmanuel Blot <emmanuel.blot@free.fr>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>
#

from __future__ import with_statement

from hashlib import md5

from genshi.template.text import NewTextTemplate

from trac.core import *
from trac.config import *
from trac.notification import NotifyEmail
from trac.ticket.api import TicketSystem
from trac.util.datefmt import to_utimestamp
from trac.util.text import obfuscate_email_address, text_width, wrap
from trac.util.translation import deactivate, reactivate


class TicketNotificationSystem(Component):

    always_notify_owner = BoolOption('notification', 'always_notify_owner',
                                     'false',
        """Always send notifications to the ticket owner (''since 0.9'').""")

    always_notify_reporter = BoolOption('notification',
                                        'always_notify_reporter',
                                        'false',
        """Always send notifications to any address in the ''reporter''
        field.""")

    always_notify_updater = BoolOption('notification', 'always_notify_updater',
                                       'true',
        """Always send notifications to the person who causes the ticket
        property change and to any previous updater of that ticket.""")

    ticket_subject_template = Option('notification', 'ticket_subject_template',
                                     '$prefix #$ticket.id: $summary',
        """A Genshi text template snippet used to get the notification subject.

        By default, the subject template is `$prefix #$ticket.id: $summary`.
        `$prefix` being the value of the `smtp_subject_prefix` option.
        ''(since 0.11)''""")

    batch_subject_template = Option('notification', 'batch_subject_template',
                                     '$prefix Batch modify: $tickets_descr',
        """Like ticket_subject_template but for batch modifications.

        By default, the template is `$prefix Batch modify: $tickets_descr`.
        ''(since 1.0)''""")

    ambiguous_char_width = Option('notification', 'ambiguous_char_width',
                                  'single',
        """Which width of ambiguous characters (e.g. 'single' or
        'double') should be used in the table of notification mail.

        If 'single', the same width as characters in US-ASCII. This is
        expected by most users. If 'double', twice the width of
        US-ASCII characters.  This is expected by CJK users. ''(since
        0.12.2)''""")

def get_ticket_notification_recipients(env, config, tktid, prev_cc):
    notify_reporter = config.getbool('notification', 'always_notify_reporter')
    notify_owner = config.getbool('notification', 'always_notify_owner')
    notify_updater = config.getbool('notification', 'always_notify_updater')

    ccrecipients = prev_cc
    torecipients = []
    with env.db_query as db:
        # Harvest email addresses from the cc, reporter, and owner fields
        for row in db("SELECT cc, reporter, owner FROM ticket WHERE id=%s",
                      (tktid,)):
            if row[0]:
                ccrecipients += row[0].replace(',', ' ').split()
            reporter = row[1]
            owner = row[2]
            if notify_reporter:
                torecipients.append(row[1])
            if notify_owner:
                torecipients.append(row[2])
            break

        # Harvest email addresses from the author field of ticket_change(s)
        if notify_updater:
            for author, ticket in db("""
                    SELECT DISTINCT author, ticket FROM ticket_change
                    WHERE ticket=%s
                    """, (tktid,)):
                torecipients.append(author)

        # Suppress the updater from the recipients
        updater = None
        for updater, in db("""
                SELECT author FROM ticket_change WHERE ticket=%s
                ORDER BY time DESC LIMIT 1
                """, (tktid,)):
            break
        else:
            for updater, in db("SELECT reporter FROM ticket WHERE id=%s",
                               (tktid,)):
                break

        if not notify_updater:
            filter_out = True
            if notify_reporter and (updater == reporter):
                filter_out = False
            if notify_owner and (updater == owner):
                filter_out = False
            if filter_out:
                torecipients = [r for r in torecipients
                                if r and r != updater]
        elif updater:
            torecipients.append(updater)

    return (torecipients, ccrecipients, reporter, owner)


class TicketNotifyEmail(NotifyEmail):
    """Notification of ticket changes."""

    template_name = "ticket_notify_email.txt"
    ticket = None
    newticket = None
    modtime = 0
    from_email = 'trac+ticket@localhost'
    COLS = 75

    def __init__(self, env):
        NotifyEmail.__init__(self, env)
        self.prev_cc = []
        ambiguous_char_width = env.config.get('notification',
                                              'ambiguous_char_width',
                                              'single')
        self.ambiwidth = 2 if ambiguous_char_width == 'double' else 1

    def notify(self, ticket, newticket=True, modtime=None):
        """Send ticket change notification e-mail (untranslated)"""
        t = deactivate()
        translated_fields = ticket.fields
        try:
            ticket.fields = TicketSystem(self.env).get_ticket_fields()
            self._notify(ticket, newticket, modtime)
        finally:
            ticket.fields = translated_fields
            reactivate(t)

    def _notify(self, ticket, newticket=True, modtime=None):
        self.ticket = ticket
        self.modtime = modtime
        self.newticket = newticket

        changes_body = ''
        self.reporter = ''
        self.owner = ''
        changes_descr = ''
        change_data = {}
        link = self.env.abs_href.ticket(ticket.id)
        summary = self.ticket['summary']
        author = None

        if not self.newticket and modtime:  # Ticket change
            from trac.ticket.web_ui import TicketModule
            for change in TicketModule(self.env).grouped_changelog_entries(
                                                ticket, when=modtime):
                if not change['permanent']: # attachment with same time...
                    continue
                author = change['author']
                change_data.update({
                    'author': self.obfuscate_email(author),
                    'comment': wrap(change['comment'], self.COLS, ' ', ' ',
                                    '\n', self.ambiwidth)
                    })
                link += '#comment:%s' % str(change.get('cnum', ''))
                for field, values in change['fields'].iteritems():
                    old = values['old']
                    new = values['new']
                    newv = ''
                    if field == 'description':
                        new_descr = wrap(new, self.COLS, ' ', ' ', '\n',
                                         self.ambiwidth)
                        old_descr = wrap(old, self.COLS, '> ', '> ', '\n',
                                         self.ambiwidth)
                        old_descr = old_descr.replace(2 * '\n', '\n' + '>' + \
                                                      '\n')
                        cdescr = '\n'
                        cdescr += 'Old description:' + 2 * '\n' + old_descr + \
                                  2 * '\n'
                        cdescr += 'New description:' + 2 * '\n' + new_descr + \
                                  '\n'
                        changes_descr = cdescr
                    elif field == 'summary':
                        summary = "%s (was: %s)" % (new, old)
                    elif field == 'cc':
                        (addcc, delcc) = self.diff_cc(old, new)
                        chgcc = ''
                        if delcc:
                            chgcc += wrap(" * cc: %s (removed)" %
                                          ', '.join(delcc),
                                          self.COLS, ' ', ' ', '\n',
                                          self.ambiwidth) + '\n'
                        if addcc:
                            chgcc += wrap(" * cc: %s (added)" %
                                          ', '.join(addcc),
                                          self.COLS, ' ', ' ', '\n',
                                          self.ambiwidth) + '\n'
                        if chgcc:
                            changes_body += chgcc
                        self.prev_cc += self.parse_cc(old) if old else []
                    else:
                        if field in ['owner', 'reporter']:
                            old = self.obfuscate_email(old)
                            new = self.obfuscate_email(new)
                        newv = new
                        length = 7 + len(field)
                        spacer_old, spacer_new = ' ', ' '
                        if len(old + new) + length > self.COLS:
                            length = 5
                            if len(old) + length > self.COLS:
                                spacer_old = '\n'
                            if len(new) + length > self.COLS:
                                spacer_new = '\n'
                        chg = '* %s: %s%s%s=>%s%s' % (field, spacer_old, old,
                                                      spacer_old, spacer_new,
                                                      new)
                        chg = chg.replace('\n', '\n' + length * ' ')
                        chg = wrap(chg, self.COLS, '', length * ' ', '\n',
                                   self.ambiwidth)
                        changes_body += ' %s%s' % (chg, '\n')
                    if newv:
                        change_data[field] = {'oldvalue': old, 'newvalue': new}

        if newticket:
            author = ticket['reporter']

        ticket_values = ticket.values.copy()
        ticket_values['id'] = ticket.id
        ticket_values['description'] = wrap(
            ticket_values.get('description', ''), self.COLS,
            initial_indent=' ', subsequent_indent=' ', linesep='\n',
            ambiwidth=self.ambiwidth)
        ticket_values['new'] = self.newticket
        ticket_values['link'] = link

        subject = self.format_subj(summary)
        if not self.newticket:
            subject = 'Re: ' + subject
        self.data.update({
            'ticket_props': self.format_props(),
            'ticket_body_hdr': self.format_hdr(),
            'subject': subject,
            'ticket': ticket_values,
            'changes_body': changes_body,
            'changes_descr': changes_descr,
            'change': change_data
            })
        NotifyEmail.notify(self, ticket.id, subject, author)

    def format_props(self):
        tkt = self.ticket
        fields = [f for f in tkt.fields
                  if f['name'] not in ('summary', 'cc', 'time', 'changetime')]
        width = [0, 0, 0, 0]
        i = 0
        for f in fields:
            if f['type'] == 'textarea':
                continue
            fname = f['name']
            if not fname in tkt.values:
                continue
            fval = tkt[fname] or ''
            if fval.find('\n') != -1:
                continue
            if fname in ['owner', 'reporter']:
                fval = self.obfuscate_email(fval)
            idx = 2 * (i % 2)
            width[idx] = max(self.get_text_width(f['label']), width[idx])
            width[idx + 1] = max(self.get_text_width(fval), width[idx + 1])
            i += 1
        width_l = width[0] + width[1] + 5
        width_r = width[2] + width[3] + 5
        half_cols = (self.COLS - 1) / 2
        if width_l + width_r + 1 > self.COLS:
            if ((width_l > half_cols and width_r > half_cols) or
                    (width[0] > half_cols / 2 or width[2] > half_cols / 2)):
                width_l = half_cols
                width_r = half_cols
            elif width_l > width_r:
                width_l = min((self.COLS - 1) * 2 / 3, width_l)
                width_r = self.COLS - width_l - 1
            else:
                width_r = min((self.COLS - 1) * 2 / 3, width_r)
                width_l = self.COLS - width_r - 1
        sep = width_l * '-' + '+' + width_r * '-'
        txt = sep + '\n'
        cell_tmp = [u'', u'']
        big = []
        i = 0
        width_lr = [width_l, width_r]
        for f in [f for f in fields if f['name'] != 'description']:
            fname = f['name']
            if not tkt.values.has_key(fname):
                continue
            fval = tkt[fname] or ''
            if fname in ['owner', 'reporter']:
                fval = self.obfuscate_email(fval)
            if f['type'] == 'textarea' or '\n' in unicode(fval):
                big.append((f['label'], '\n'.join(fval.splitlines())))
            else:
                # Note: f['label'] is a Babel's LazyObject, make sure its
                # __str__ method won't be called.
                str_tmp = u'%s:  %s' % (f['label'], unicode(fval))
                idx = i % 2
                cell_tmp[idx] += wrap(str_tmp, width_lr[idx] - 2 + 2 * idx,
                                      (width[2 * idx]
                                       - self.get_text_width(f['label'])
                                       + 2 * idx) * ' ',
                                      2 * ' ', '\n', self.ambiwidth)
                cell_tmp[idx] += '\n'
                i += 1
        cell_l = cell_tmp[0].splitlines()
        cell_r = cell_tmp[1].splitlines()
        for i in range(max(len(cell_l), len(cell_r))):
            if i >= len(cell_l):
                cell_l.append(width_l * ' ')
            elif i >= len(cell_r):
                cell_r.append('')
            fmt_width = width_l - self.get_text_width(cell_l[i]) \
                        + len(cell_l[i])
            txt += u'%-*s|%s%s' % (fmt_width, cell_l[i], cell_r[i], '\n')
        if big:
            txt += sep
            for name, value in big:
                txt += '\n'.join(['', name + ':', value, '', ''])
        txt += sep
        return txt

    def parse_cc(self, txt):
        return filter(lambda x: '@' in x, txt.replace(',', ' ').split())

    def diff_cc(self, old, new):
        oldcc = NotifyEmail.addrsep_re.split(old)
        newcc = NotifyEmail.addrsep_re.split(new)
        added = [self.obfuscate_email(x) \
                                for x in newcc if x and x not in oldcc]
        removed = [self.obfuscate_email(x) \
                                for x in oldcc if x and x not in newcc]
        return (added, removed)

    def format_hdr(self):
        return '#%s: %s' % (self.ticket.id, wrap(self.ticket['summary'],
                                                 self.COLS, linesep='\n',
                                                 ambiwidth=self.ambiwidth))

    def format_subj(self, summary):
        template = self.config.get('notification','ticket_subject_template')
        template = NewTextTemplate(template.encode('utf8'))

        prefix = self.config.get('notification', 'smtp_subject_prefix')
        if prefix == '__default__':
            prefix = '[%s]' % self.env.project_name

        data = {
            'prefix': prefix,
            'summary': summary,
            'ticket': self.ticket,
            'env': self.env,
        }

        return template.generate(**data).render('text', encoding=None).strip()

    def get_recipients(self, tktid):
        (torecipients, ccrecipients, reporter, owner) = \
            get_ticket_notification_recipients(self.env, self.config,
                tktid, self.prev_cc)
        self.reporter = reporter
        self.owner = owner
        return (torecipients, ccrecipients)

    def get_message_id(self, rcpt, modtime=None):
        """Generate a predictable, but sufficiently unique message ID."""
        s = '%s.%08d.%d.%s' % (self.env.project_url.encode('utf-8'),
                               int(self.ticket.id), to_utimestamp(modtime),
                               rcpt.encode('ascii', 'ignore'))
        dig = md5(s).hexdigest()
        host = self.from_email[self.from_email.find('@') + 1:]
        msgid = '<%03d.%s@%s>' % (len(s), dig, host)
        return msgid

    def send(self, torcpts, ccrcpts):
        dest = self.reporter or 'anonymous'
        hdrs = {}
        hdrs['Message-ID'] = self.get_message_id(dest, self.modtime)
        hdrs['X-Trac-Ticket-ID'] = str(self.ticket.id)
        hdrs['X-Trac-Ticket-URL'] = self.data['ticket']['link']
        if not self.newticket:
            msgid = self.get_message_id(dest)
            hdrs['In-Reply-To'] = msgid
            hdrs['References'] = msgid
        NotifyEmail.send(self, torcpts, ccrcpts, hdrs)

    def get_text_width(self, text):
        return text_width(text, ambiwidth=self.ambiwidth)

    def obfuscate_email(self, text):
        """ Obfuscate text when `show_email_addresses` is disabled in config.
        Obfuscation happens once per email, regardless of recipients, so
        cannot use permission-based obfuscation.
        """
        if self.env.config.getbool('trac', 'show_email_addresses'):
            return text
        else:
            return obfuscate_email_address(text)

class BatchTicketNotifyEmail(NotifyEmail):
    """Notification of ticket batch modifications."""

    template_name = "batch_ticket_notify_email.txt"

    def __init__(self, env):
        NotifyEmail.__init__(self, env)

    def notify(self, tickets, new_values, comment, action, author):
        """Send batch ticket change notification e-mail (untranslated)"""
        t = deactivate()
        try:
            self._notify(tickets, new_values, comment, action, author)
        finally:
            reactivate(t)

    def _notify(self, tickets, new_values, comment, action, author):
        self.tickets = tickets
        changes_body = ''
        self.reporter = ''
        self.owner = ''
        changes_descr = '\n'.join(['%s to %s' % (prop, val)
                                  for (prop, val) in new_values.iteritems()])
        tickets_descr = ', '.join(['#%s' % t for t in tickets])
        subject = self.format_subj(tickets_descr)
        link = self.env.abs_href.query(id=','.join([str(t) for t in tickets]))
        self.data.update({
            'tickets_descr': tickets_descr,
            'changes_descr': changes_descr,
            'comment': comment,
            'action': action,
            'author': author,
            'subject': subject,
            'ticket_query_link': link,
            })
        NotifyEmail.notify(self, tickets, subject, author)

    def format_subj(self, tickets_descr):
        template = self.config.get('notification','batch_subject_template')
        template = NewTextTemplate(template.encode('utf8'))

        prefix = self.config.get('notification', 'smtp_subject_prefix')
        if prefix == '__default__':
            prefix = '[%s]' % self.env.project_name

        data = {
            'prefix': prefix,
            'tickets_descr': tickets_descr,
            'env': self.env,
        }

        return template.generate(**data).render('text', encoding=None).strip()

    def get_recipients(self, tktids):
        alltorecipients = []
        allccrecipients = []
        for t in tktids:
            (torecipients, ccrecipients, reporter, owner) = \
                get_ticket_notification_recipients(self.env, self.config,
                    t, [])
            alltorecipients.extend(torecipients)
            allccrecipients.extend(ccrecipients)
        return (list(set(alltorecipients)), list(set(allccrecipients)))

########NEW FILE########
__FILENAME__ = query
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import csv
from itertools import groupby
from math import ceil
from datetime import datetime, timedelta
import re
from StringIO import StringIO

from genshi.builder import tag

from trac.config import Option, IntOption
from trac.core import *
from trac.db import get_column_names
from trac.mimeview.api import IContentConverter, Mimeview
from trac.resource import Resource
from trac.ticket.api import TicketSystem
from trac.ticket.model import Milestone, group_milestones, Ticket
from trac.util import Ranges, as_bool
from trac.util.datefmt import format_date, format_datetime, from_utimestamp, \
                              parse_date, to_timestamp, to_utimestamp, utc, \
                              user_time
from trac.util.presentation import Paginator
from trac.util.text import empty, shorten_line, quote_query_string
from trac.util.translation import _, tag_, cleandoc_
from trac.web import arg_list_to_args, parse_arg_list, IRequestHandler
from trac.web.href import Href
from trac.web.chrome import (INavigationContributor, Chrome,
                             add_ctxtnav, add_link, add_script,
                             add_script_data, add_stylesheet, add_warning,
                             web_context)
from trac.wiki.api import IWikiSyntaxProvider
from trac.wiki.macros import WikiMacroBase # TODO: should be moved in .api


class QuerySyntaxError(TracError):
    """Exception raised when a ticket query cannot be parsed from a string."""


class QueryValueError(TracError):
    """Exception raised when a ticket query has bad constraint values."""
    def __init__(self, errors):
        TracError.__init__(self, _('Invalid query constraint value'))
        self.errors = errors


class Query(object):
    substitutions = ['$USER']
    clause_re = re.compile(r'(?P<clause>\d+)_(?P<field>.+)$')

    def __init__(self, env, report=None, constraints=None, cols=None,
                 order=None, desc=0, group=None, groupdesc=0, verbose=0,
                 rows=None, page=None, max=None, format=None):
        self.env = env
        self.id = report # if not None, it's the corresponding saved query
        constraints = constraints or []
        if isinstance(constraints, dict):
            constraints = [constraints]
        self.constraints = constraints
        synonyms = TicketSystem(self.env).get_field_synonyms()
        self.order = synonyms.get(order, order)     # 0.11 compatibility
        self.desc = desc
        self.group = group
        self.groupdesc = groupdesc
        self.format = format
        self.default_page = 1
        self.items_per_page = QueryModule(self.env).items_per_page

        # getting page number (default_page if unspecified)
        if not page:
            page = self.default_page
        try:
            self.page = int(page)
            if self.page < 1:
                raise ValueError()
        except ValueError:
            raise TracError(_('Query page %(page)s is invalid.', page=page))

        # max=0 signifies showing all items on one page
        # max=n will show precisely n items on all pages except the last
        # max<0 is invalid
        if max in ('none', ''):
            max = 0

        if max is None: # meaning unspecified
            max = self.items_per_page
        try:
            self.max = int(max)
            if self.max < 0:
                raise ValueError()
        except ValueError:
            raise TracError(_('Query max %(max)s is invalid.', max=max))

        if self.max == 0:
            self.has_more_pages = False
            self.offset = 0
        else:
            self.has_more_pages = True
            self.offset = self.max * (self.page - 1)

        if rows == None:
            rows = []
        if verbose and 'description' not in rows: # 0.10 compatibility
            rows.append('description')
        self.fields = TicketSystem(self.env).get_ticket_fields()
        self.time_fields = set(f['name'] for f in self.fields
                               if f['type'] == 'time')
        field_names = set(f['name'] for f in self.fields)
        self.cols = [c for c in cols or [] if c in field_names or
                     c == 'id']
        self.rows = [c for c in rows if c in field_names]
        if self.order != 'id' and self.order not in field_names:
            self.order = 'priority'

        if self.group not in field_names:
            self.group = None

        constraint_cols = {}
        for clause in self.constraints:
            for k, v in clause.items():
                if k == 'id' or k in field_names:
                    constraint_cols.setdefault(k, []).append(v)
                else:
                    clause.pop(k)
        self.constraint_cols = constraint_cols

    _clause_splitter = re.compile(r'(?<!\\)&')
    _item_splitter = re.compile(r'(?<!\\)\|')

    @classmethod
    def from_string(cls, env, string, **kw):
        kw_strs = ['order', 'group', 'page', 'max', 'format']
        kw_arys = ['rows']
        kw_bools = ['desc', 'groupdesc', 'verbose']
        kw_synonyms = {'row': 'rows'}
        # i18n TODO - keys will be unicode
        synonyms = TicketSystem(env).get_field_synonyms()
        constraints = [{}]
        cols = []
        report = None
        def as_str(s):
            if isinstance(s, unicode):
                return s.encode('utf-8')
            return s
        for filter_ in cls._clause_splitter.split(string):
            if filter_ == 'or':
                constraints.append({})
                continue
            filter_ = filter_.replace(r'\&', '&').split('=', 1)
            if len(filter_) != 2:
                raise QuerySyntaxError(_('Query filter requires field and '
                                         'constraints separated by a "="'))
            field, values = filter_
            # from last chars of `field`, get the mode of comparison
            mode = ''
            if field and field[-1] in ('~', '^', '$') \
                                and not field in cls.substitutions:
                mode = field[-1]
                field = field[:-1]
            if field and field[-1] == '!':
                mode = '!' + mode
                field = field[:-1]
            if not field:
                raise QuerySyntaxError(_('Query filter requires field name'))
            field = kw_synonyms.get(field, field)
            # add mode of comparison and remove escapes
            processed_values = [mode + val.replace(r'\|', '|')
                                for val in cls._item_splitter.split(values)]
            if field in kw_strs:
                kw[as_str(field)] = processed_values[0]
            elif field in kw_arys:
                kw.setdefault(as_str(field), []).extend(processed_values)
            elif field in kw_bools:
                kw[as_str(field)] = as_bool(processed_values[0])
            elif field == 'col':
                cols.extend(synonyms.get(value, value)
                            for value in processed_values)
            elif field == 'report':
                report = processed_values[0]
            else:
                constraints[-1].setdefault(synonyms.get(field, field),
                                           []).extend(processed_values)
        constraints = filter(None, constraints)
        report = kw.pop('report', report)
        return cls(env, report, constraints=constraints, cols=cols, **kw)

    def get_columns(self):
        if not self.cols:
            self.cols = self.get_default_columns()
        if not 'id' in self.cols:
            # make sure 'id' is always present (needed for permission checks)
            self.cols.insert(0, 'id')
        return self.cols

    def get_all_textareas(self):
        return [f['name'] for f in self.fields if f['type'] == 'textarea']

    def get_all_columns(self):
        # Prepare the default list of columns
        cols = ['id']
        cols += [f['name'] for f in self.fields if f['type'] != 'textarea']
        for col in ('reporter', 'keywords', 'cc'):
            if col in cols:
                cols.remove(col)
                cols.append(col)

        def sort_columns(col1, col2):
            constrained_fields = self.constraint_cols.keys()
            if 'id' in (col1, col2):
                # Ticket ID is always the first column
                return -1 if col1 == 'id' else 1
            elif 'summary' in (col1, col2):
                # Ticket summary is always the second column
                return -1 if col1 == 'summary' else 1
            elif col1 in constrained_fields or col2 in constrained_fields:
                # Constrained columns appear before other columns
                return -1 if col1 in constrained_fields else 1
            return 0
        cols.sort(sort_columns)
        return cols

    def get_default_columns(self):
        cols = self.get_all_columns()

        # Semi-intelligently remove columns that are restricted to a single
        # value by a query constraint.
        for col in [k for k in self.constraint_cols.keys()
                    if k != 'id' and k in cols]:
            constraints = self.constraint_cols[col]
            for constraint in constraints:
                if not (len(constraint) == 1 and constraint[0]
                        and not constraint[0][0] in '!~^$' and col in cols
                        and col not in self.time_fields):
                    break
            else:
                cols.remove(col)
            if col == 'status' and 'resolution' in cols:
                for constraint in constraints:
                    if 'closed' in constraint:
                        break
                else:
                    cols.remove('resolution')
        if self.group in cols:
            cols.remove(self.group)

        # Only display the first seven columns by default
        cols = cols[:7]
        # Make sure the column we order by is visible, if it isn't also
        # the column we group by
        if not self.order in cols and not self.order == self.group:
            cols[-1] = self.order
        return cols

    def count(self, req=None, db=None, cached_ids=None, authname=None,
              tzinfo=None, locale=None):
        """Get the number of matching tickets for the present query.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        sql, args = self.get_sql(req, cached_ids, authname, tzinfo, locale)
        return self._count(sql, args)

    def _count(self, sql, args):
        cnt = self.env.db_query("SELECT COUNT(*) FROM (%s) AS x"
                                % sql, args)[0][0]
        # "AS x" is needed for MySQL ("Subqueries in the FROM Clause")
        self.env.log.debug("Count results in Query: %d", cnt)
        return cnt

    def execute(self, req=None, db=None, cached_ids=None, authname=None,
                tzinfo=None, href=None, locale=None):
        """Retrieve the list of matching tickets.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        if req is not None:
            href = req.href
        with self.env.db_query as db:
            cursor = db.cursor()

            self.num_items = 0
            sql, args = self.get_sql(req, cached_ids, authname, tzinfo, locale)
            self.num_items = self._count(sql, args)

            if self.num_items <= self.max:
                self.has_more_pages = False

            if self.has_more_pages:
                max = self.max
                if self.group:
                    max += 1
                sql = sql + " LIMIT %d OFFSET %d" % (max, self.offset)
                if (self.page > int(ceil(float(self.num_items) / self.max)) and
                    self.num_items != 0):
                    raise TracError(_("Page %(page)s is beyond the number of "
                                      "pages in the query", page=self.page))

            # self.env.log.debug("SQL: " + sql % tuple([repr(a) for a in args]))
            cursor.execute(sql, args)
            columns = get_column_names(cursor)
            fields = []
            for column in columns:
                fields += [f for f in self.fields if f['name'] == column] or \
                          [None]
            results = []

            column_indices = range(len(columns))
            for row in cursor:
                result = {}
                for i in column_indices:
                    name, field, val = columns[i], fields[i], row[i]
                    if name == 'reporter':
                        val = val or 'anonymous'
                    elif name == 'id':
                        val = int(val)
                        if href is not None:
                            result['href'] = href.ticket(val)
                    elif name in self.time_fields:
                        val = from_utimestamp(val)
                    elif field and field['type'] == 'checkbox':
                        try:
                            val = bool(int(val))
                        except (TypeError, ValueError):
                            val = False
                    elif val is None:
                        val = ''
                    result[name] = val
                results.append(result)
            cursor.close()
            return results

    def get_href(self, href, id=None, order=None, desc=None, format=None,
                 max=None, page=None):
        """Create a link corresponding to this query.

        :param href: the `Href` object used to build the URL
        :param id: optionally set or override the report `id`
        :param order: optionally override the order parameter of the query
        :param desc: optionally override the desc parameter
        :param format: optionally override the format of the query
        :param max: optionally override the max items per page
        :param page: optionally specify which page of results (defaults to
                     the first)

        Note: `get_resource_url` of a 'query' resource?
        """
        if not isinstance(href, Href):
            href = href.href # compatibility with the `req` of the 0.10 API

        if format is None:
            format = self.format
        if format == 'rss':
            max = self.items_per_page
            page = self.default_page

        if id is None:
            id = self.id
        if desc is None:
            desc = self.desc
        if order is None:
            order = self.order
        if max is None:
            max = self.max
        if page is None:
            page = self.page

        cols = self.get_columns()
        # don't specify the columns in the href if they correspond to
        # the default columns, page and max in the same order. That keeps the
        # query url shorter in the common case where we just want the default
        # columns.
        if cols == self.get_default_columns():
            cols = None
        if page == self.default_page:
            page = None
        if max == self.items_per_page:
            max = None

        constraints = []
        for clause in self.constraints:
            constraints.extend(clause.iteritems())
            constraints.append(("or", empty))
        del constraints[-1:]

        return href.query(constraints,
                          report=id,
                          order=order, desc=1 if desc else None,
                          group=self.group or None,
                          groupdesc=1 if self.groupdesc else None,
                          col=cols,
                          row=self.rows,
                          max=max,
                          page=page,
                          format=format)

    def to_string(self):
        """Return a user readable and editable representation of the query.

        Note: for now, this is an "exploded" query href, but ideally should be
        expressed in TracQuery language.
        """
        query_string = self.get_href(Href(''))
        query_string = query_string.split('?', 1)[-1]
        return 'query:?' + query_string.replace('&', '\n&\n')

    def get_sql(self, req=None, cached_ids=None, authname=None, tzinfo=None,
                locale=None):
        """Return a (sql, params) tuple for the query."""
        if req is not None:
            authname = req.authname
            tzinfo = req.tz
            locale = req.locale
        self.get_columns()
        db = self.env.get_read_db()

        enum_columns = ('resolution', 'priority', 'severity')
        # Build the list of actual columns to query
        cols = self.cols[:]
        def add_cols(*args):
            for col in args:
                if not col in cols:
                    cols.append(col)
        if self.group and not self.group in cols:
            add_cols(self.group)
        if self.rows:
            add_cols('reporter', *self.rows)
        add_cols('status', 'priority', 'time', 'changetime', self.order)
        cols.extend([c for c in self.constraint_cols if not c in cols])

        custom_fields = [f['name'] for f in self.fields if f.get('custom')]
        list_fields = [f['name'] for f in self.fields
                                 if f['type'] == 'text' and
                                    f.get('format') == 'list']

        sql = []
        sql.append("SELECT " + ",".join(['t.%s AS %s' % (c, c) for c in cols
                                         if c not in custom_fields]))
        sql.append(",priority.value AS priority_value")
        for k in [db.quote(k) for k in cols if k in custom_fields]:
            sql.append(",%s.value AS %s" % (k, k))
        sql.append("\nFROM ticket AS t")

        # Join with ticket_custom table as necessary
        for k in [k for k in cols if k in custom_fields]:
            qk = db.quote(k)
            sql.append("\n  LEFT OUTER JOIN ticket_custom AS %s ON " \
                       "(id=%s.ticket AND %s.name='%s')" % (qk, qk, qk, k))

        # Join with the enum table for proper sorting
        for col in [c for c in enum_columns
                    if c == self.order or c == self.group or c == 'priority']:
            sql.append("\n  LEFT OUTER JOIN enum AS %s ON "
                       "(%s.type='%s' AND %s.name=%s)"
                       % (col, col, col, col, col))

        # Join with the version/milestone tables for proper sorting
        for col in [c for c in ['milestone', 'version']
                    if c == self.order or c == self.group]:
            sql.append("\n  LEFT OUTER JOIN %s ON (%s.name=%s)"
                       % (col, col, col))

        def get_timestamp(date):
            if date:
                try:
                    return to_utimestamp(user_time(req, parse_date, date))
                except TracError, e:
                    errors.append(unicode(e))
            return None

        def get_constraint_sql(name, value, mode, neg):
            if name not in custom_fields:
                col = 't.' + name
            else:
                col = '%s.value' % db.quote(name)
            value = value[len(mode) + neg:]

            if name in self.time_fields:
                if '..' in value:
                    (start, end) = [each.strip() for each in
                                    value.split('..', 1)]
                else:
                    (start, end) = (value.strip(), '')
                col_cast = db.cast(col, 'int64')
                start = get_timestamp(start)
                end = get_timestamp(end)
                if start is not None and end is not None:
                    return ("%s(%s>=%%s AND %s<%%s)" % ('NOT ' if neg else '',
                                                        col_cast, col_cast),
                            (start, end))
                elif start is not None:
                    return ("%s%s>=%%s" % ('NOT ' if neg else '', col_cast),
                            (start, ))
                elif end is not None:
                    return ("%s%s<%%s" % ('NOT ' if neg else '', col_cast),
                            (end, ))
                else:
                    return None

            if mode == '~' and name in list_fields:
                words = value.split()
                clauses, args = [], []
                for word in words:
                    cneg = ''
                    if word.startswith('-'):
                        cneg = 'NOT '
                        word = word[1:]
                        if not word:
                            continue
                    clauses.append("COALESCE(%s,'') %s%s" % (col, cneg,
                                                             db.like()))
                    args.append('%' + db.like_escape(word) + '%')
                if not clauses:
                    return None
                return (('NOT ' if neg else '')
                        + '(' + ' AND '.join(clauses) + ')', args)

            if mode == '':
                return ("COALESCE(%s,'')%s=%%s" % (col, '!' if neg else ''),
                        (value, ))

            if not value:
                return None
            value = db.like_escape(value)
            if mode == '~':
                value = '%' + value + '%'
            elif mode == '^':
                value = value + '%'
            elif mode == '$':
                value = '%' + value
            return ("COALESCE(%s,'') %s%s" % (col, 'NOT ' if neg else '',
                                              db.like()),
                    (value, ))

        def get_clause_sql(constraints):
            db = self.env.get_read_db()
            clauses = []
            for k, v in constraints.iteritems():
                if authname is not None:
                    v = [val.replace('$USER', authname) for val in v]
                # Determine the match mode of the constraint (contains,
                # starts-with, negation, etc.)
                neg = v[0].startswith('!')
                mode = ''
                if len(v[0]) > neg and v[0][neg] in ('~', '^', '$'):
                    mode = v[0][neg]

                # Special case id ranges
                if k == 'id':
                    ranges = Ranges()
                    for r in v:
                        r = r.replace('!', '')
                        try:
                            ranges.appendrange(r)
                        except Exception:
                            errors.append(_('Invalid ticket id list: '
                                            '%(value)s', value=r))
                    ids = []
                    id_clauses = []
                    for a, b in ranges.pairs:
                        if a == b:
                            ids.append(str(a))
                        else:
                            id_clauses.append('id BETWEEN %s AND %s')
                            args.append(a)
                            args.append(b)
                    if ids:
                        id_clauses.append('id IN (%s)' % (','.join(ids)))
                    if id_clauses:
                        clauses.append('%s(%s)' % ('NOT 'if neg else '',
                                                   ' OR '.join(id_clauses)))
                # Special case for exact matches on multiple values
                elif not mode and len(v) > 1 and k not in self.time_fields:
                    if k not in custom_fields:
                        col = 't.' + k
                    else:
                        col = '%s.value' % db.quote(k)
                    clauses.append("COALESCE(%s,'') %sIN (%s)"
                                   % (col, 'NOT ' if neg else '',
                                      ','.join(['%s' for val in v])))
                    args.extend([val[neg:] for val in v])
                elif v:
                    constraint_sql = [get_constraint_sql(k, val, mode, neg)
                                      for val in v]
                    constraint_sql = filter(None, constraint_sql)
                    if not constraint_sql:
                        continue
                    if neg:
                        clauses.append("(" + " AND ".join(
                            [item[0] for item in constraint_sql]) + ")")
                    else:
                        clauses.append("(" + " OR ".join(
                            [item[0] for item in constraint_sql]) + ")")
                    for item in constraint_sql:
                        args.extend(item[1])
            return " AND ".join(clauses)

        args = []
        errors = []
        clauses = filter(None, (get_clause_sql(c) for c in self.constraints))
        if clauses:
            sql.append("\nWHERE ")
            sql.append(" OR ".join('(%s)' % c for c in clauses))
            if cached_ids:
                sql.append(" OR ")
                sql.append("id in (%s)" %
                           (','.join([str(id) for id in cached_ids])))

        sql.append("\nORDER BY ")
        order_cols = [(self.order, self.desc)]
        if self.group and self.group != self.order:
            order_cols.insert(0, (self.group, self.groupdesc))

        for name, desc in order_cols:
            if name in enum_columns:
                col = name + '.value'
            elif name in custom_fields:
                col = '%s.value' % db.quote(name)
            else:
                col = 't.' + name
            desc = ' DESC' if desc else ''
            # FIXME: This is a somewhat ugly hack.  Can we also have the
            #        column type for this?  If it's an integer, we do first
            #        one, if text, we do 'else'
            if name == 'id' or name in self.time_fields:
                sql.append("COALESCE(%s,0)=0%s," % (col, desc))
            else:
                sql.append("COALESCE(%s,'')=''%s," % (col, desc))
            if name in enum_columns:
                # These values must be compared as ints, not as strings
                sql.append(db.cast(col, 'int') + desc)
            elif name == 'milestone':
                sql.append("COALESCE(milestone.completed,0)=0%s,"
                           "milestone.completed%s,"
                           "COALESCE(milestone.due,0)=0%s,milestone.due%s,"
                           "%s%s" % (desc, desc, desc, desc, col, desc))
            elif name == 'version':
                sql.append("COALESCE(version.time,0)=0%s,version.time%s,%s%s"
                           % (desc, desc, col, desc))
            else:
                sql.append("%s%s" % (col, desc))
            if name == self.group and not name == self.order:
                sql.append(",")
        if self.order != 'id':
            sql.append(",t.id")

        if errors:
            raise QueryValueError(errors)
        return "".join(sql), args

    @staticmethod
    def get_modes():
        modes = {}
        modes['text'] = [
            {'name': _("contains"), 'value': "~"},
            {'name': _("doesn't contain"), 'value': "!~"},
            {'name': _("begins with"), 'value': "^"},
            {'name': _("ends with"), 'value': "$"},
            {'name': _("is"), 'value': ""},
            {'name': _("is not"), 'value': "!"},
        ]
        modes['textarea'] = [
            {'name': _("contains"), 'value': "~"},
            {'name': _("doesn't contain"), 'value': "!~"},
        ]
        modes['select'] = [
            {'name': _("is"), 'value': ""},
            {'name': _("is not"), 'value': "!"},
        ]
        modes['id'] = [
            {'name': _("is"), 'value': ""},
            {'name': _("is not"), 'value': "!"},
        ]
        return modes

    def template_data(self, context, tickets, orig_list=None, orig_time=None,
                      req=None):
        clauses = []
        for clause in self.constraints:
            constraints = {}
            for k, v in clause.items():
                constraint = {'values': [], 'mode': ''}
                for val in v:
                    neg = val.startswith('!')
                    if neg:
                        val = val[1:]
                    mode = ''
                    if val[:1] in ('~', '^', '$') \
                                        and not val in self.substitutions:
                        mode, val = val[:1], val[1:]
                    if req:
                        val = val.replace('$USER', req.authname)
                    constraint['mode'] = ('!' if neg else '') + mode
                    constraint['values'].append(val)
                constraints[k] = constraint
            clauses.append(constraints)

        cols = self.get_columns()
        labels = TicketSystem(self.env).get_ticket_field_labels()
        wikify = set(f['name'] for f in self.fields
                     if f['type'] == 'text' and f.get('format') == 'wiki')

        headers = [{
            'name': col, 'label': labels.get(col, _('Ticket')),
            'wikify': col in wikify,
            'href': self.get_href(context.href, order=col,
                                  desc=(col == self.order and not self.desc))
        } for col in cols]

        fields = {'id': {'type': 'id', 'label': _("Ticket")}}
        for field in self.fields:
            name = field['name']
            if name == 'owner' and field['type'] == 'select':
                # Make $USER work when restrict_owner = true
                field = field.copy()
                field['options'].insert(0, '$USER')
            if name == 'milestone':
                milestones = [Milestone(self.env, opt)
                              for opt in field['options']]
                milestones = [m for m in milestones
                              if 'MILESTONE_VIEW' in context.perm(m.resource)]
                groups = group_milestones(milestones, True)
                field['options'] = []
                field['optgroups'] = [
                    {'label': label, 'options': [m.name for m in milestones]}
                    for (label, milestones) in groups]
            fields[name] = field

        groups = {}
        groupsequence = []
        for ticket in tickets:
            if orig_list:
                # Mark tickets added or changed since the query was first
                # executed
                if ticket['time'] > orig_time:
                    ticket['added'] = True
                elif ticket['changetime'] > orig_time:
                    ticket['changed'] = True
            if self.group:
                group_key = ticket[self.group]
                # If grouping by datetime field use days (Bloodhound #68)
                if self.group in ('changetime', 'time'):
                    group_key = format_date(group_key)
                groups.setdefault(group_key, []).append(ticket)
                if not groupsequence or group_key not in groupsequence:
                    groupsequence.append(group_key)
        groupsequence = [(value, groups[value]) for value in groupsequence]

        # detect whether the last group continues on the next page,
        # by checking if the extra (max+1)th ticket is in the last group
        last_group_is_partial = False
        if groupsequence and self.max and len(tickets) == self.max + 1:
            del tickets[-1]
            if len(groupsequence[-1][1]) == 1:
                # additional ticket started a new group
                del groupsequence[-1] # remove that additional group
            else:
                # additional ticket stayed in the group
                last_group_is_partial = True
                del groupsequence[-1][1][-1] # remove the additional ticket

        results = Paginator(tickets,
                            self.page - 1,
                            self.max,
                            self.num_items)

        if req:
            if results.has_next_page:
                next_href = self.get_href(req.href, max=self.max,
                                          page=self.page + 1)
                add_link(req, 'next', next_href, _('Next Page'))

            if results.has_previous_page:
                prev_href = self.get_href(req.href, max=self.max,
                                          page=self.page - 1)
                add_link(req, 'prev', prev_href, _('Previous Page'))
        else:
            results.show_index = False

        pagedata = []
        shown_pages = results.get_shown_pages(21)
        for page in shown_pages:
            pagedata.append([self.get_href(context.href, page=page), None,
                             str(page), _('Page %(num)d', num=page)])

        results.shown_pages = [dict(zip(['href', 'class', 'string', 'title'],
                                        p)) for p in pagedata]
        results.current_page = {'href': None, 'class': 'current',
                                'string': str(results.page + 1),
                                'title':None}

        return {'query': self,
                'context': context,
                'col': cols,
                'row': self.rows,
                'clauses': clauses,
                'headers': headers,
                'fields': fields,
                'modes': self.get_modes(),
                'tickets': tickets,
                'groups': groupsequence or [(None, tickets)],
                'last_group_is_partial': last_group_is_partial,
                'paginator': results}

class QueryModule(Component):

    implements(IRequestHandler, INavigationContributor, IWikiSyntaxProvider,
               IContentConverter)

    default_query = Option('query', 'default_query',
        default='status!=closed&owner=$USER',
        doc="""The default query for authenticated users. The query is either
            in [TracQuery#QueryLanguage query language] syntax, or a URL query
            string starting with `?` as used in `query:`
            [TracQuery#UsingTracLinks Trac links].
            (''since 0.11.2'')""")

    default_anonymous_query = Option('query', 'default_anonymous_query',
        default='status!=closed&cc~=$USER',
        doc="""The default query for anonymous users. The query is either
            in [TracQuery#QueryLanguage query language] syntax, or a URL query
            string starting with `?` as used in `query:`
            [TracQuery#UsingTracLinks Trac links].
            (''since 0.11.2'')""")

    items_per_page = IntOption('query', 'items_per_page', 100,
        """Number of tickets displayed per page in ticket queries,
        by default (''since 0.11'')""")

    # IContentConverter methods

    def get_supported_conversions(self):
        yield ('rss', _('RSS Feed'), 'xml',
               'trac.ticket.Query', 'application/rss+xml', 8)
        yield ('csv', _('Comma-delimited Text'), 'csv',
               'trac.ticket.Query', 'text/csv', 8)
        yield ('tab', _('Tab-delimited Text'), 'tsv',
               'trac.ticket.Query', 'text/tab-separated-values', 8)

    def convert_content(self, req, mimetype, query, key):
        if key == 'rss':
            return self.export_rss(req, query)
        elif key == 'csv':
            return self.export_csv(req, query, mimetype='text/csv')
        elif key == 'tab':
            return self.export_csv(req, query, '\t',
                                   mimetype='text/tab-separated-values')

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'tickets'

    def get_navigation_items(self, req):
        from trac.ticket.report import ReportModule
        if 'TICKET_VIEW' in req.perm and \
                not self.env.is_component_enabled(ReportModule):
            yield ('mainnav', 'tickets',
                   tag.a(_('View Tickets'), href=req.href.query()))

    # IRequestHandler methods

    def match_request(self, req):
        return req.path_info == '/query'

    def process_request(self, req):
        req.perm.assert_permission('TICKET_VIEW')

        constraints = self._get_constraints(req)
        args = req.args
        if not constraints and not 'order' in req.args:
            # If no constraints are given in the URL, use the default ones.
            if req.authname and req.authname != 'anonymous':
                qstring = self.default_query
                user = req.authname
            else:
                email = req.session.get('email')
                name = req.session.get('name')
                qstring = self.default_anonymous_query
                user = email or name or None

            self.log.debug('QueryModule: Using default query: %s', str(qstring))
            if qstring.startswith('?'):
                arg_list = parse_arg_list(qstring[1:])
                args = arg_list_to_args(arg_list)
                constraints = self._get_constraints(arg_list=arg_list)
            else:
                query = Query.from_string(self.env, qstring)
                args = {'order': query.order, 'group': query.group,
                        'col': query.cols, 'max': query.max}
                if query.desc:
                    args['desc'] = '1'
                if query.groupdesc:
                    args['groupdesc'] = '1'
                constraints = query.constraints

            # Substitute $USER, or ensure no field constraints that depend
            # on $USER are used if we have no username.
            for clause in constraints:
                for field, vals in clause.items():
                    for (i, val) in enumerate(vals):
                        if user:
                            vals[i] = val.replace('$USER', user)
                        elif val.endswith('$USER'):
                            del clause[field]
                            break

        cols = args.get('col')
        if isinstance(cols, basestring):
            cols = [cols]
        # Since we don't show 'id' as an option to the user,
        # we need to re-insert it here.
        if cols and 'id' not in cols:
            cols.insert(0, 'id')
        rows = args.get('row', [])
        if isinstance(rows, basestring):
            rows = [rows]
        format = req.args.get('format')
        max = args.get('max')
        if max is None and format in ('csv', 'tab'):
            max = 0 # unlimited unless specified explicitly
        query = Query(self.env, req.args.get('report'),
                      constraints, cols, args.get('order'),
                      'desc' in args, args.get('group'),
                      'groupdesc' in args, 'verbose' in args,
                      rows,
                      args.get('page'),
                      max)

        if 'update' in req.args:
            # Reset session vars
            for var in ('query_constraints', 'query_time', 'query_tickets'):
                if var in req.session:
                    del req.session[var]
            req.redirect(query.get_href(req.href))

        # Add registered converters
        for conversion in Mimeview(self.env).get_supported_conversions(
                                             'trac.ticket.Query'):
            add_link(req, 'alternate',
                     query.get_href(req.href, format=conversion[0]),
                     conversion[1], conversion[4], conversion[0])

        if format:
            filename = 'query' if format != 'rss' else None
            Mimeview(self.env).send_converted(req, 'trac.ticket.Query', query,
                                              format, filename=filename)

        return self.display_html(req, query)

    # Internal methods

    remove_re = re.compile(r'rm_filter_\d+_(.+)_(\d+)$')
    add_re = re.compile(r'add_(\d+)$')

    def _get_constraints(self, req=None, arg_list=[]):
        fields = TicketSystem(self.env).get_ticket_fields()
        synonyms = TicketSystem(self.env).get_field_synonyms()
        fields = dict((f['name'], f) for f in fields)
        fields['id'] = {'type': 'id'}
        fields.update((k, fields[v]) for k, v in synonyms.iteritems())

        clauses = []
        if req is not None:
            # For clients without JavaScript, we remove constraints here if
            # requested
            remove_constraints = {}
            for k in req.args:
                match = self.remove_re.match(k)
                if match:
                    field = match.group(1)
                    if fields[field]['type'] == 'radio':
                        index = -1
                    else:
                        index = int(match.group(2))
                    remove_constraints[k[10:match.end(1)]] = index

            # Get constraints from form fields, and add a constraint if
            # requested for clients without JavaScript
            add_num = None
            constraints = {}
            for k, vals in req.args.iteritems():
                match = self.add_re.match(k)
                if match:
                    add_num = match.group(1)
                    continue
                match = Query.clause_re.match(k)
                if not match:
                    continue
                field = match.group('field')
                clause_num = int(match.group('clause'))
                if field not in fields:
                    continue
                if not isinstance(vals, (list, tuple)):
                    vals = [vals]
                if vals:
                    mode = req.args.get(k + '_mode')
                    if mode:
                        vals = [mode + x for x in vals]
                    if fields[field]['type'] == 'time':
                        ends = req.args.getlist(k + '_end')
                        if ends:
                            vals = [start + '..' + end
                                    for (start, end) in zip(vals, ends)]
                    if k in remove_constraints:
                        idx = remove_constraints[k]
                        if idx >= 0:
                            del vals[idx]
                            if not vals:
                                continue
                        else:
                            continue
                    field = synonyms.get(field, field)
                    clause = constraints.setdefault(clause_num, {})
                    clause.setdefault(field, []).extend(vals)
            if add_num is not None:
                field = req.args.get('add_filter_' + add_num,
                                     req.args.get('add_clause_' + add_num))
                if field:
                    clause = constraints.setdefault(int(add_num), {})
                    modes = Query.get_modes().get(fields[field]['type'])
                    mode = modes[0]['value'] if modes else ''
                    clause.setdefault(field, []).append(mode)
            clauses.extend(each[1] for each in sorted(constraints.iteritems()))

        # Get constraints from query string
        clauses.append({})
        for field, val in arg_list or req.arg_list:
            if field == "or":
                clauses.append({})
            elif field in fields:
                clauses[-1].setdefault(field, []).append(val)
        clauses = filter(None, clauses)

        return clauses

    def display_html(self, req, query):
        # The most recent query is stored in the user session;
        orig_list = None
        orig_time = datetime.now(utc)
        query_time = int(req.session.get('query_time', 0))
        query_time = datetime.fromtimestamp(query_time, utc)
        query_constraints = unicode(query.constraints)
        try:
            if query_constraints != req.session.get('query_constraints') \
                    or query_time < orig_time - timedelta(hours=1):
                tickets = query.execute(req)
                # New or outdated query, (re-)initialize session vars
                req.session['query_constraints'] = query_constraints
                req.session['query_tickets'] = ' '.join([str(t['id'])
                                                         for t in tickets])
            else:
                orig_list = [int(id) for id
                             in req.session.get('query_tickets', '').split()]
                tickets = query.execute(req, cached_ids=orig_list)
                orig_time = query_time
        except QueryValueError, e:
            tickets = []
            for error in e.errors:
                add_warning(req, error)

        context = web_context(req, 'query')
        owner_field = [f for f in query.fields if f['name'] == 'owner']
        if owner_field:
            TicketSystem(self.env).eventually_restrict_owner(owner_field[0])
        data = query.template_data(context, tickets, orig_list, orig_time, req)

        req.session['query_href'] = query.get_href(context.href)
        req.session['query_time'] = to_timestamp(orig_time)
        req.session['query_tickets'] = ' '.join([str(t['id'])
                                                 for t in tickets])
        title = _('Custom Query')

        # Only interact with the report module if it is actually enabled.
        #
        # Note that with saved custom queries, there will be some convergence
        # between the report module and the query module.
        from trac.ticket.report import ReportModule
        if 'REPORT_VIEW' in req.perm and \
               self.env.is_component_enabled(ReportModule):
            data['report_href'] = req.href.report()
            add_ctxtnav(req, _('Available Reports'), req.href.report())
            add_ctxtnav(req, _('Custom Query'), req.href.query())
            if query.id:
                for title, description in self.env.db_query("""
                        SELECT title, description FROM report WHERE id=%s
                        """, (query.id,)):
                    data['report_resource'] = Resource('report', query.id)
                    data['description'] = description
        else:
            data['report_href'] = None

        # Only interact with the batch modify module it it is enabled
        from trac.ticket.batch import BatchModifyModule
        if 'TICKET_BATCH_MODIFY' in req.perm and \
                self.env.is_component_enabled(BatchModifyModule):
            self.env[BatchModifyModule].add_template_data(req, data, tickets)

        data.setdefault('report', None)
        data.setdefault('description', None)
        data['title'] = title

        data['all_columns'] = query.get_all_columns()
        # Don't allow the user to remove the id column
        data['all_columns'].remove('id')
        data['all_textareas'] = query.get_all_textareas()

        properties = dict((name, dict((key, field[key])
                                      for key in ('type', 'label', 'options',
                                                  'optgroups')
                                      if key in field))
                          for name, field in data['fields'].iteritems())
        add_script_data(req, properties=properties, modes=data['modes'])

        add_stylesheet(req, 'common/css/report.css')
        Chrome(self.env).add_jquery_ui(req)
        add_script(req, 'common/js/query.js')

        return 'query.html', data, None

    def export_csv(self, req, query, sep=',', mimetype='text/plain'):
        content = StringIO()
        content.write('\xef\xbb\xbf')   # BOM
        cols = query.get_columns()
        writer = csv.writer(content, delimiter=sep, quoting=csv.QUOTE_MINIMAL)
        writer.writerow([unicode(c).encode('utf-8') for c in cols])

        context = web_context(req)
        results = query.execute(req)
        for result in results:
            ticket = Resource('ticket', result['id'])
            if 'TICKET_VIEW' in req.perm(ticket):
                values = []
                for col in cols:
                    value = result[col]
                    if col in ('cc', 'reporter'):
                        value = Chrome(self.env).format_emails(
                                    context.child(ticket), value)
                    elif col in query.time_fields:
                        value = format_datetime(value, '%Y-%m-%d %H:%M:%S',
                                                tzinfo=req.tz)
                    values.append(unicode(value).encode('utf-8'))
                writer.writerow(values)
        return (content.getvalue(), '%s;charset=utf-8' % mimetype)

    def export_rss(self, req, query):
        context = web_context(req, 'query', absurls=True)
        query_href = query.get_href(context.href)
        if 'description' not in query.rows:
            query.rows.append('description')
        results = query.execute(req)
        data = {
            'context': context,
            'results': results,
            'query_href': query_href
        }
        output = Chrome(self.env).render_template(req, 'query.rss', data,
                                                  'application/rss+xml')
        return output, 'application/rss+xml'

    # IWikiSyntaxProvider methods

    def get_wiki_syntax(self):
        return []

    def get_link_resolvers(self):
        yield ('query', self._format_link)

    def _format_link(self, formatter, ns, query, label):
        if query.startswith('?'):
            query = quote_query_string(query)
            return tag.a(label, class_='query',
                         href=formatter.href.query() + query)
        else:
            try:
                query = Query.from_string(self.env, query)
                return tag.a(label,
                             href=query.get_href(formatter.context.href),
                             class_='query')
            except QuerySyntaxError, e:
                return tag.em(_('[Error: %(error)s]', error=unicode(e)),
                              class_='error')


class TicketQueryMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Wiki macro listing tickets that match certain criteria.

    This macro accepts a comma-separated list of keyed parameters,
    in the form "key=value".

    If the key is the name of a field, the value must use the syntax
    of a filter specifier as defined in TracQuery#QueryLanguage.
    Note that this is ''not'' the same as the simplified URL syntax
    used for `query:` links starting with a `?` character. Commas (`,`)
    can be included in field values by escaping them with a backslash (`\`).

    Groups of field constraints to be OR-ed together can be separated by a
    litteral `or` argument.

    In addition to filters, several other named parameters can be used
    to control how the results are presented. All of them are optional.

    The `format` parameter determines how the list of tickets is
    presented:
     - '''list''' -- the default presentation is to list the ticket ID next
       to the summary, with each ticket on a separate line.
     - '''compact''' -- the tickets are presented as a comma-separated
       list of ticket IDs.
     - '''count''' -- only the count of matching tickets is displayed
     - '''table'''  -- a view similar to the custom query view (but without
       the controls)
     - '''progress''' -- a view similar to the milestone progress bars

    The `max` parameter can be used to limit the number of tickets shown
    (defaults to '''0''', i.e. no maximum).

    The `order` parameter sets the field used for ordering tickets
    (defaults to '''id''').

    The `desc` parameter indicates whether the order of the tickets
    should be reversed (defaults to '''false''').

    The `group` parameter sets the field used for grouping tickets
    (defaults to not being set).

    The `groupdesc` parameter indicates whether the natural display
    order of the groups should be reversed (defaults to '''false''').

    The `verbose` parameter can be set to a true value in order to
    get the description for the listed tickets. For '''table''' format only.
    ''deprecated in favor of the `rows` parameter''

    The `rows` parameter can be used to specify which field(s) should
    be viewed as a row, e.g. `rows=description|summary`

    For compatibility with Trac 0.10, if there's a last positional parameter
    given to the macro, it will be used to specify the `format`.
    Also, using "&" as a field separator still works (except for `order`)
    but is deprecated.
    """)

    _comma_splitter = re.compile(r'(?<!\\),')

    @staticmethod
    def parse_args(content):
        """Parse macro arguments and translate them to a query string."""
        clauses = [{}]
        argv = []
        kwargs = {}
        for arg in TicketQueryMacro._comma_splitter.split(content):
            arg = arg.replace(r'\,', ',')
            m = re.match(r'\s*[^=]+=', arg)
            if m:
                kw = arg[:m.end() - 1].strip()
                value = arg[m.end():]
                if kw in ('order', 'max', 'format', 'col'):
                    kwargs[kw] = value
                else:
                    clauses[-1][kw] = value
            elif arg.strip() == 'or':
                clauses.append({})
            else:
                argv.append(arg)
        clauses = filter(None, clauses)

        if len(argv) > 0 and not 'format' in kwargs: # 0.10 compatibility hack
            kwargs['format'] = argv[0]
        if 'order' not in kwargs:
            kwargs['order'] = 'id'
        if 'max' not in kwargs:
            kwargs['max'] = '0' # unlimited by default

        format = kwargs.pop('format', 'list').strip().lower()
        if format in ('list', 'compact'): # we need 'status' and 'summary'
            if 'col' in kwargs:
                kwargs['col'] = 'status|summary|' + kwargs['col']
            else:
                kwargs['col'] = 'status|summary'

        query_string = '&or&'.join('&'.join('%s=%s' % item
                                            for item in clause.iteritems())
                                   for clause in clauses)
        return query_string, kwargs, format

    def expand_macro(self, formatter, name, content):
        req = formatter.req
        query_string, kwargs, format = self.parse_args(content)
        if query_string:
            query_string += '&'
        query_string += '&'.join('%s=%s' % item
                                 for item in kwargs.iteritems())
        query = Query.from_string(self.env, query_string)

        if format == 'count':
            cnt = query.count(req)
            return tag.span(cnt, title='%d tickets for which %s' %
                            (cnt, query_string), class_='query_count')

        tickets = query.execute(req)

        if format == 'table':
            data = query.template_data(formatter.context, tickets,
                                       req=formatter.context.req)

            add_stylesheet(req, 'common/css/report.css')

            return Chrome(self.env).render_template(
                req, 'query_results.html', data, None, fragment=True)

        if format == 'progress':
            from trac.ticket.roadmap import (RoadmapModule,
                                             apply_ticket_permissions,
                                             get_ticket_stats,
                                             grouped_stats_data)

            add_stylesheet(req, 'common/css/roadmap.css')

            def query_href(extra_args, group_value = None):
                q = Query.from_string(self.env, query_string)
                if q.group:
                    extra_args[q.group] = group_value
                    q.group = None
                for constraint in q.constraints:
                    constraint.update(extra_args)
                if not q.constraints:
                    q.constraints.append(extra_args)
                return q.get_href(formatter.context)
            chrome = Chrome(self.env)
            tickets = apply_ticket_permissions(self.env, req, tickets)
            stats_provider = RoadmapModule(self.env).stats_provider
            by = query.group
            if not by:
                stat = get_ticket_stats(stats_provider, tickets)
                data = {
                    'stats': stat,
                    'stats_href': query_href(stat.qry_args),
                    'interval_hrefs': [query_href(interval['qry_args'])
                                       for interval in stat.intervals],
                    'legend': True,
                }
                return tag.div(
                    chrome.render_template(req, 'progress_bar.html', data,
                                           None, fragment=True),
                    class_='trac-progress')

            def per_group_stats_data(gstat, group_name):
                return {
                    'stats': gstat,
                    'stats_href': query_href(gstat.qry_args,  group_name),
                    'interval_hrefs': [query_href(interval['qry_args'],
                                                  group_name)
                                       for interval in gstat.intervals],
                    'percent': '%d / %d' % (gstat.done_count,
                                            gstat.count),
                    'legend': False,
                }

            groups = grouped_stats_data(self.env, stats_provider, tickets, by,
                                        per_group_stats_data)
            data = {
                'groups': groups, 'grouped_by': by,
                'summary': _("Ticket completion status for each %(group)s",
                             group=by),
            }
            return tag.div(
                chrome.render_template(req, 'progress_bar_grouped.html', data,
                                       None, fragment=True),
                class_='trac-groupprogress')

        # Formats above had their own permission checks, here we need to
        # do it explicitly:

        tickets = [t for t in tickets
                   if 'TICKET_VIEW' in req.perm('ticket', t['id'])]

        if not tickets:
            return tag.span(_("No results"), class_='query_no_results')

        def ticket_anchor(ticket):
            return tag.a('#%s' % ticket['id'],
                         class_=ticket['status'],
                         href=req.href.ticket(int(ticket['id'])),
                         title=shorten_line(ticket['summary']))

        def ticket_groups():
            groups = []
            for v, g in groupby(tickets, lambda t: t[query.group]):
                q = Query.from_string(self.env, query_string)
                # produce the hint for the group
                q.group = q.groupdesc = None
                order = q.order
                q.order = None
                title = _("%(groupvalue)s %(groupname)s tickets matching "
                          "%(query)s", groupvalue=v, groupname=query.group,
                          query=q.to_string())
                # produce the href for the query corresponding to the group
                for constraint in q.constraints:
                    constraint[str(query.group)] = v
                q.order = order
                href = q.get_href(formatter.context)
                groups.append((v, [t for t in g], href, title))
            return groups

        if format == 'compact':
            if query.group:
                groups = [(v, ' ',
                           tag.a('#%s' % u',\u200b'.join(str(t['id'])
                                                         for t in g),
                                 href=href, class_='query', title=title))
                          for v, g, href, title in ticket_groups()]
                return tag(groups[0], [(', ', g) for g in groups[1:]])
            else:
                alist = [ticket_anchor(ticket) for ticket in tickets]
                return tag.span(alist[0], *[(', ', a) for a in alist[1:]])
        else:
            if query.group:
                return tag.div(
                    [(tag.p(tag_('%(groupvalue)s %(groupname)s tickets:',
                                 groupvalue=tag.a(v, href=href, class_='query',
                                                  title=title),
                                 groupname=query.group)),
                      tag.dl([(tag.dt(ticket_anchor(t)),
                               tag.dd(t['summary'])) for t in g],
                             class_='wiki compact'))
                     for v, g, href, title in ticket_groups()])
            else:
                return tag.div(tag.dl([(tag.dt(ticket_anchor(ticket)),
                                        tag.dd(ticket['summary']))
                                       for ticket in tickets],
                                      class_='wiki compact'))

    def is_inline(self, content):
        query_string, kwargs, format = self.parse_args(content)
        return format in ('count', 'compact')

########NEW FILE########
__FILENAME__ = report
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2004 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2006 Christian Boos <cboos@edgewall.org>
# Copyright (C) 2006 Matthew Good <trac@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>

from __future__ import with_statement

import csv
import re
from StringIO import StringIO

from genshi.builder import tag

from trac.config import IntOption
from trac.core import *
from trac.db import get_column_names
from trac.perm import IPermissionRequestor
from trac.resource import Resource, ResourceNotFound
from trac.ticket.api import TicketSystem
from trac.util import as_int, content_disposition
from trac.util.datefmt import format_datetime, format_time, from_utimestamp
from trac.util.presentation import Paginator
from trac.util.text import exception_to_unicode, to_unicode, quote_query_string
from trac.util.translation import _, tag_
from trac.web.api import IRequestHandler, RequestDone
from trac.web.chrome import (INavigationContributor, Chrome,
                             add_ctxtnav, add_link, add_notice, add_script,
                             add_stylesheet, add_warning, auth_link,
                             web_context)
from trac.wiki import IWikiSyntaxProvider, WikiParser



SORT_COLUMN = '@SORT_COLUMN@'
LIMIT_OFFSET = '@LIMIT_OFFSET@'


def cell_value(v):
    """Normalize a cell value for display.
    >>> (cell_value(None), cell_value(0), cell_value(1), cell_value('v'))
    ('', '0', u'1', u'v')
    """
    return '0' if v is 0 else unicode(v) if v else ''


_sql_re = re.compile(r'''
      --.*$                        # single line "--" comment
    | /\*([^*/]|\*[^/]|/[^*])*\*/  # C style comment
    | '(\\.|[^'\\])*'              # literal string
    | \([^()]+\)                   # parenthesis group
''', re.MULTILINE | re.VERBOSE)

def _expand_with_space(m):
    return ' ' * len(m.group(0))

def sql_skeleton(sql):
    """Strip an SQL query to leave only its toplevel structure.

    This is probably not 100% robust but should be enough for most
    needs.

    >>> re.sub('\s+', lambda m: '<%d>' % len(m.group(0)), sql_skeleton(''' \\n\
        SELECT a FROM (SELECT x FROM z ORDER BY COALESCE(u, ')/*(')) ORDER \\n\
          /* SELECT a FROM (SELECT x /* FROM z                             \\n\
                        ORDER BY */ COALESCE(u, '\)X(')) ORDER */          \\n\
          BY c, (SELECT s FROM f WHERE v in ('ORDER BY', '(\\')')          \\n\
                 ORDER BY (1), '') -- LIMIT                                \\n\
         '''))
    '<10>SELECT<1>a<1>FROM<48>ORDER<164>BY<1>c,<144>'
    """
    old = None
    while sql != old:
        old = sql
        sql = _sql_re.sub(_expand_with_space, old)
    return old

_order_by_re = re.compile(r'ORDER\s+BY', re.MULTILINE)

def split_sql(sql, clause_re, skel=None):
    """Split an SQL query according to a toplevel clause regexp.

    We assume there's only one such clause present in the outer query.

    >>> split_sql('''SELECT a FROM x  ORDER \
            BY u, v''', _order_by_re)
    ('SELECT a FROM x  ', ' u, v')
    """
    if skel is None:
        skel = sql_skeleton(sql)
    blocks = clause_re.split(skel.upper())
    if len(blocks) == 2:
        return sql[:len(blocks[0])], sql[-len(blocks[1]):] # (before, after)
    else:
        return sql, '' # no single clause separator



class ReportModule(Component):

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
               IWikiSyntaxProvider)

    items_per_page = IntOption('report', 'items_per_page', 100,
        """Number of tickets displayed per page in ticket reports,
        by default (''since 0.11'')""")

    items_per_page_rss = IntOption('report', 'items_per_page_rss', 0,
        """Number of tickets displayed in the rss feeds for reports
        (''since 0.11'')""")

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'tickets'

    def get_navigation_items(self, req):
        if 'REPORT_VIEW' in req.perm:
            yield ('mainnav', 'tickets', tag.a(_('View Tickets'),
                                               href=req.href.report()))

    # IPermissionRequestor methods

    def get_permission_actions(self):
        actions = ['REPORT_CREATE', 'REPORT_DELETE', 'REPORT_MODIFY',
                   'REPORT_SQL_VIEW', 'REPORT_VIEW']
        return actions + [('REPORT_ADMIN', actions)]

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/report(?:/(?:([0-9]+)|-1))?$', req.path_info)
        if match:
            if match.group(1):
                req.args['id'] = match.group(1)
            return True

    def process_request(self, req):
        req.perm.require('REPORT_VIEW')

        # did the user ask for any special report?
        id = int(req.args.get('id', -1))
        action = req.args.get('action', 'view')

        data = {}
        if req.method == 'POST':
            if action == 'new':
                self._do_create(req)
            elif action == 'delete':
                self._do_delete(req, id)
            elif action == 'edit':
                self._do_save(req, id)
        elif action in ('copy', 'edit', 'new'):
            template = 'report_edit.html'
            data = self._render_editor(req, id, action=='copy')
            Chrome(self.env).add_wiki_toolbars(req)
        elif action == 'delete':
            template = 'report_delete.html'
            data = self._render_confirm_delete(req, id)
        elif id == -1:
            template, data, content_type = self._render_list(req)
            if content_type: # i.e. alternate format
                return template, data, content_type
            if action == 'clear':
                if 'query_href' in req.session:
                    del req.session['query_href']
                if 'query_tickets' in req.session:
                    del req.session['query_tickets']
        else:
            template, data, content_type = self._render_view(req, id)
            if content_type: # i.e. alternate format
                return template, data, content_type

        if id != -1 or action == 'new':
            add_ctxtnav(req, _('Available Reports'), href=req.href.report())
            add_link(req, 'up', req.href.report(), _('Available Reports'))
        else:
            add_ctxtnav(req, _('Available Reports'))

        # Kludge: only show link to custom query if the query module
        # is actually enabled
        from trac.ticket.query import QueryModule
        if 'TICKET_VIEW' in req.perm and \
                self.env.is_component_enabled(QueryModule):
            add_ctxtnav(req, _('Custom Query'), href=req.href.query())
            data['query_href'] = req.href.query()
            data['saved_query_href'] = req.session.get('query_href')
        else:
            data['query_href'] = None

        add_stylesheet(req, 'common/css/report.css')
        return template, data, None

    # Internal methods

    def _do_create(self, req):
        req.perm.require('REPORT_CREATE')

        if 'cancel' in req.args:
            req.redirect(req.href.report())

        title = req.args.get('title', '')
        query = req.args.get('query', '')
        description = req.args.get('description', '')
        with self.env.db_transaction as db:
            cursor = db.cursor()
            cursor.execute("""
                INSERT INTO report (title,query,description) VALUES (%s,%s,%s)
                """, (title, query, description))
            report_id = db.get_last_id(cursor, 'report')
        add_notice(req, _("The report has been created."))
        req.redirect(req.href.report(report_id))

    def _do_delete(self, req, id):
        req.perm.require('REPORT_DELETE')

        if 'cancel' in req.args:
            req.redirect(req.href.report(id))

        self.env.db_transaction("DELETE FROM report WHERE id=%s", (id,))
        add_notice(req, _("The report {%(id)d} has been deleted.", id=id))
        req.redirect(req.href.report())

    def _do_save(self, req, id):
        """Save report changes to the database"""
        req.perm.require('REPORT_MODIFY')

        if 'cancel' not in req.args:
            title = req.args.get('title', '')
            query = req.args.get('query', '')
            description = req.args.get('description', '')
            self.env.db_transaction("""
                UPDATE report SET title=%s, query=%s, description=%s
                WHERE id=%s
                """, (title, query, description, id))
            add_notice(req, _("Your changes have been saved."))
        req.redirect(req.href.report(id))

    def _render_confirm_delete(self, req, id):
        req.perm.require('REPORT_DELETE')

        for title, in self.env.db_query("""
                SELECT title FROM report WHERE id=%s
                """, (id,)):
            return {'title': _("Delete Report {%(num)s} %(title)s", num=id,
                               title=title),
                    'action': 'delete',
                    'report': {'id': id, 'title': title}}
        else:
            raise TracError(_("Report {%(num)s} does not exist.", num=id),
                            _("Invalid Report Number"))

    def _render_editor(self, req, id, copy):
        if id != -1:
            req.perm.require('REPORT_MODIFY')
            for title, description, query in self.env.db_query(
                    "SELECT title, description, query FROM report WHERE id=%s",
                    (id,)):
                break
            else:
                raise TracError(_("Report {%(num)s} does not exist.", num=id),
                                _("Invalid Report Number"))
        else:
            req.perm.require('REPORT_CREATE')
            title = description = query = ''

        # an explicitly given 'query' parameter will override the saved query
        query = req.args.get('query', query)

        if copy:
            title += ' (copy)'

        if copy or id == -1:
            data = {'title': _('Create New Report'),
                    'action': 'new',
                    'error': None}
        else:
            data = {'title': _('Edit Report {%(num)d} %(title)s', num=id,
                               title=title),
                    'action': 'edit',
                    'error': req.args.get('error')}

        data['report'] = {'id': id, 'title': title,
                          'sql': query, 'description': description}
        return data

    def _render_list(self, req):
        """Render the list of available reports."""
        sort = req.args.get('sort', 'report')
        asc = bool(int(req.args.get('asc', 1)))
        format = req.args.get('format')

        rows = self.env.db_query("""
                SELECT id, title, description FROM report ORDER BY %s %s
                """ % ('title' if sort == 'title' else 'id',
                       '' if asc else 'DESC'))

        if format == 'rss':
            data = {'rows': rows}
            return 'report_list.rss', data, 'application/rss+xml'
        elif format == 'csv':
            self._send_csv(req, ['report', 'title', 'description'],
                           rows, mimetype='text/csv',
                           filename='reports.csv')
        elif format == 'tab':
            self._send_csv(req, ['report', 'title', 'description'],
                           rows, '\t', mimetype='text/tab-separated-values',
                           filename='reports.tsv')

        def report_href(**kwargs):
            return req.href.report(sort=req.args.get('sort'),
                                   asc='1' if asc else '0', **kwargs)

        add_link(req, 'alternate',
                 auth_link(req, report_href(format='rss')),
                 _('RSS Feed'), 'application/rss+xml', 'rss')
        add_link(req, 'alternate', report_href(format='csv'),
                 _('Comma-delimited Text'), 'text/plain')
        add_link(req, 'alternate', report_href(format='tab'),
                 _('Tab-delimited Text'), 'text/plain')

        reports = [(id, title, description,
                    'REPORT_MODIFY' in req.perm('report', id),
                    'REPORT_DELETE' in req.perm('report', id))
                   for id, title, description in rows]
        data = {'reports': reports, 'sort': sort, 'asc': asc}

        return 'report_list.html', data, None

    _html_cols = set(['__class__', '__style__', '__color__', '__fgcolor__',
                      '__bgcolor__', '__grouplink__'])

    def _render_view(self, req, id):
        """Retrieve the report results and pre-process them for rendering."""
        for title, sql, description in self.env.db_query("""
                SELECT title, query, description from report WHERE id=%s
                """, (id,)):
            break
        else:
            raise ResourceNotFound(_("Report {%(num)s} does not exist.",
                                     num=id), _("Invalid Report Number"))
        try:
            args = self.get_var_args(req)
        except ValueError, e:
            raise TracError(_("Report failed: %(error)s", error=e))

        # If this is a saved custom query, redirect to the query module
        #
        # A saved query is either an URL query (?... or query:?...),
        # or a query language expression (query:...).
        #
        # It may eventually contain newlines, for increased clarity.
        #
        query = ''.join([line.strip() for line in sql.splitlines()])
        if query and (query[0] == '?' or query.startswith('query:?')):
            query = query if query[0] == '?' else query[6:]
            report_id = 'report=%s' % id
            if 'report=' in query:
                if not report_id in query:
                    err = _('When specified, the report number should be '
                            '"%(num)s".', num=id)
                    req.redirect(req.href.report(id, action='edit', error=err))
            else:
                if query[-1] != '?':
                    query += '&'
                query += report_id
            req.redirect(req.href.query() + quote_query_string(query))
        elif query.startswith('query:'):
            try:
                from trac.ticket.query import Query, QuerySyntaxError
                query = Query.from_string(self.env, query[6:], report=id)
                req.redirect(query.get_href(req))
            except QuerySyntaxError, e:
                req.redirect(req.href.report(id, action='edit',
                                             error=to_unicode(e)))

        format = req.args.get('format')
        if format == 'sql':
            self._send_sql(req, id, title, description, sql)

        title = '{%i} %s' % (id, title)

        report_resource = Resource('report', id)
        req.perm.require('REPORT_VIEW', report_resource)
        context = web_context(req, report_resource)

        page = int(req.args.get('page', '1'))
        default_max = {'rss': self.items_per_page_rss,
                       'csv': 0, 'tab': 0}.get(format, self.items_per_page)
        max = req.args.get('max')
        limit = as_int(max, default_max, min=0) # explict max takes precedence
        offset = (page - 1) * limit

        sort_col = req.args.get('sort', '')
        asc = req.args.get('asc', 1)
        asc = bool(int(asc)) # string '0' or '1' to int/boolean

        def report_href(**kwargs):
            """Generate links to this report preserving user variables,
            and sorting and paging variables.
            """
            params = args.copy()
            if sort_col:
                params['sort'] = sort_col
            params['page'] = page
            if max:
                params['max'] = max
            params.update(kwargs)
            params['asc'] = '1' if params.get('asc', asc) else '0'
            return req.href.report(id, params)

        data = {'action': 'view',
                'report': {'id': id, 'resource': report_resource},
                'context': context,
                'title': title, 'description': description,
                'max': limit, 'args': args, 'show_args_form': False,
                'message': None, 'paginator': None,
                'report_href': report_href,
                }

        res = None
        with self.env.db_query as db:
            res = self.execute_paginated_report(req, db, id, sql, args, limit,
                                                offset)

        if len(res) == 2:
             e, sql = res
             data['message'] = \
                 tag_("Report execution failed: %(error)s %(sql)s",
                      error=tag.pre(exception_to_unicode(e)),
                      sql=tag(tag.hr(),
                              tag.pre(sql, style="white-space: pre")))
             return 'report_view.html', data, None

        cols, results, num_items, missing_args, limit_offset = res
        need_paginator = limit > 0 and limit_offset
        need_reorder = limit_offset is None
        results = [list(row) for row in results]
        numrows = len(results)

        paginator = None
        if need_paginator:
            paginator = Paginator(results, page - 1, limit, num_items)
            data['paginator'] = paginator
            if paginator.has_next_page:
                add_link(req, 'next', report_href(page=page + 1),
                         _('Next Page'))
            if paginator.has_previous_page:
                add_link(req, 'prev', report_href(page=page - 1),
                         _('Previous Page'))

            pagedata = []
            shown_pages = paginator.get_shown_pages(21)
            for p in shown_pages:
                pagedata.append([report_href(page=p), None, str(p),
                                 _('Page %(num)d', num=p)])
            fields = ['href', 'class', 'string', 'title']
            paginator.shown_pages = [dict(zip(fields, p)) for p in pagedata]
            paginator.current_page = {'href': None, 'class': 'current',
                                    'string': str(paginator.page + 1),
                                    'title': None}
            numrows = paginator.num_items

        # Place retrieved columns in groups, according to naming conventions
        #  * _col_ means fullrow, i.e. a group with one header
        #  * col_ means finish the current group and start a new one

        field_labels = TicketSystem(self.env).get_ticket_field_labels()

        header_groups = [[]]
        for idx, col in enumerate(cols):
            if col in field_labels:
                title = field_labels[col]
            else:
                title = col.strip('_').capitalize()
            header = {
                'col': col,
                'title': title,
                'hidden': False,
                'asc': None,
            }

            if col == sort_col:
                header['asc'] = asc
                if not paginator and need_reorder:
                    # this dict will have enum values for sorting
                    # and will be used in sortkey(), if non-empty:
                    sort_values = {}
                    if sort_col in ('status', 'resolution', 'priority',
                                    'severity'):
                        # must fetch sort values for that columns
                        # instead of comparing them as strings
                        with self.env.db_query as db:
                            for name, value in db(
                                    "SELECT name, %s FROM enum WHERE type=%%s"
                                    % db.cast('value', 'int'),
                                    (sort_col,)):
                                sort_values[name] = value

                    def sortkey(row):
                        val = row[idx]
                        # check if we have sort_values, then use them as keys.
                        if sort_values:
                            return sort_values.get(val)
                        # otherwise, continue with string comparison:
                        if isinstance(val, basestring):
                            val = val.lower()
                        return val
                    results = sorted(results, key=sortkey, reverse=(not asc))

            header_group = header_groups[-1]

            if col.startswith('__') and col.endswith('__'): # __col__
                header['hidden'] = True
            elif col[0] == '_' and col[-1] == '_':          # _col_
                header_group = []
                header_groups.append(header_group)
                header_groups.append([])
            elif col[0] == '_':                             # _col
                header['hidden'] = True
            elif col[-1] == '_':                            # col_
                header_groups.append([])
            header_group.append(header)

        # Structure the rows and cells:
        #  - group rows according to __group__ value, if defined
        #  - group cells the same way headers are grouped
        chrome = Chrome(self.env)
        row_groups = []
        authorized_results = []
        prev_group_value = None
        for row_idx, result in enumerate(results):
            col_idx = 0
            cell_groups = []
            row = {'cell_groups': cell_groups}
            realm = 'ticket'
            parent_realm = ''
            parent_id = ''
            email_cells = []
            for header_group in header_groups:
                cell_group = []
                for header in header_group:
                    value = cell_value(result[col_idx])
                    cell = {'value': value, 'header': header, 'index': col_idx}
                    col = header['col']
                    col_idx += 1
                    # Detect and create new group
                    if col == '__group__' and value != prev_group_value:
                        prev_group_value = value
                        # Brute force handling of email in group by header
                        row_groups.append(
                            (value and chrome.format_author(req, value), []))
                    # Other row properties
                    row['__idx__'] = row_idx
                    if col in self._html_cols:
                        row[col] = value
                    if col in ('report', 'ticket', 'id', '_id'):
                        row['id'] = value
                    # Special casing based on column name
                    col = col.strip('_')
                    if col in ('reporter', 'cc', 'owner'):
                        email_cells.append(cell)
                    elif col == 'realm':
                        realm = value
                    elif col == 'parent_realm':
                        parent_realm = value
                    elif col == 'parent_id':
                        parent_id = value
                    cell_group.append(cell)
                cell_groups.append(cell_group)
            if parent_realm:
                resource = Resource(realm, row.get('id'),
                                    parent=Resource(parent_realm, parent_id))
            else:
                resource = Resource(realm, row.get('id'))
            # FIXME: for now, we still need to hardcode the realm in the action
            if resource.realm.upper()+'_VIEW' not in req.perm(resource):
                continue
            authorized_results.append(result)
            if email_cells:
                for cell in email_cells:
                    emails = chrome.format_emails(context.child(resource),
                                                  cell['value'])
                    result[cell['index']] = cell['value'] = emails
            row['resource'] = resource
            if row_groups:
                row_group = row_groups[-1][1]
            else:
                row_group = []
                row_groups = [(None, row_group)]
            row_group.append(row)

        data.update({'header_groups': header_groups,
                     'row_groups': row_groups,
                     'numrows': numrows})

        if format == 'rss':
            data['email_map'] = chrome.get_email_map()
            data['context'] = web_context(req, report_resource,
                                                   absurls=True)
            return 'report.rss', data, 'application/rss+xml'
        elif format == 'csv':
            filename = 'report_%s.csv' % id if id else 'report.csv'
            self._send_csv(req, cols, authorized_results, mimetype='text/csv',
                           filename=filename)
        elif format == 'tab':
            filename = 'report_%s.tsv' % id if id else 'report.tsv'
            self._send_csv(req, cols, authorized_results, '\t',
                           mimetype='text/tab-separated-values',
                           filename=filename)
        else:
            p = page if max is not None else None
            add_link(req, 'alternate',
                     auth_link(req, report_href(format='rss', page=None)),
                     _('RSS Feed'), 'application/rss+xml', 'rss')
            add_link(req, 'alternate', report_href(format='csv', page=p),
                     _('Comma-delimited Text'), 'text/plain')
            add_link(req, 'alternate', report_href(format='tab', page=p),
                     _('Tab-delimited Text'), 'text/plain')
            if 'REPORT_SQL_VIEW' in req.perm:
                add_link(req, 'alternate',
                         req.href.report(id=id, format='sql'),
                         _('SQL Query'), 'text/plain')

            # reuse the session vars of the query module so that
            # the query navigation links on the ticket can be used to
            # navigate report results as well
            try:
                req.session['query_tickets'] = \
                    ' '.join([str(int(row['id']))
                              for rg in row_groups for row in rg[1]])
                req.session['query_href'] = \
                    req.session['query_href'] = report_href()
                # Kludge: we have to clear the other query session
                # variables, but only if the above succeeded
                for var in ('query_constraints', 'query_time'):
                    if var in req.session:
                        del req.session[var]
            except (ValueError, KeyError):
                pass
            if set(data['args']) - set(['USER']):
                data['show_args_form'] = True
                add_script(req, 'common/js/folding.js')
            if missing_args:
                add_warning(req, _(
                    'The following arguments are missing: %(args)s',
                    args=", ".join(missing_args)))
            return 'report_view.html', data, None

    def execute_report(self, req, db, id, sql, args):
        """Execute given sql report (0.10 backward compatibility method)

        :see: ``execute_paginated_report``
        """
        res = self.execute_paginated_report(req, db, id, sql, args)
        if len(res) == 2:
            raise res[0]
        return res[:5]

    def execute_paginated_report(self, req, db, id, sql, args,
                                 limit=0, offset=0):
        sql, args, missing_args = self.sql_sub_vars(sql, args, db)
        if not sql:
            raise TracError(_("Report {%(num)s} has no SQL query.", num=id))
        self.log.debug('Report {%d} with SQL "%s"', id, sql)
        self.log.debug('Request args: %r', req.args)

        cursor = db.cursor()

        num_items = 0
        order_by = []
        limit_offset = None
        base_sql = sql.replace(SORT_COLUMN, '1').replace(LIMIT_OFFSET, '')
        if id == -1 or limit == 0:
            sql = base_sql
        else:
            # The number of tickets is obtained
            count_sql = 'SELECT COUNT(*) FROM (\n%s\n) AS tab' % base_sql
            self.log.debug("Report {%d} SQL (count): %s", id, count_sql)
            try:
                cursor.execute(count_sql, args)
            except Exception, e:
                return e, count_sql
            num_items = cursor.fetchone()[0]

            # The column names are obtained
            colnames_sql = 'SELECT * FROM (\n%s\n) AS tab LIMIT 1' % base_sql
            self.log.debug("Report {%d} SQL (col names): %s", id, colnames_sql)
            try:
                cursor.execute(colnames_sql, args)
            except Exception, e:
                return e, colnames_sql
            cols = get_column_names(cursor)

            # The ORDER BY columns are inserted
            sort_col = req.args.get('sort', '')
            asc = req.args.get('asc', '1')
            self.log.debug("%r %s (%s)", cols, sort_col, asc and '^' or 'v')
            order_cols = []
            if sort_col and sort_col not in cols:
                raise TracError(_('Query parameter "sort=%(sort_col)s" '
                                  ' is invalid', sort_col=sort_col))
            skel = None
            if '__group__' in cols:
                order_cols.append('__group__')
            if sort_col:
                sort_col = '%s %s' % (db.quote(sort_col),
                                      asc == '1' and 'ASC' or 'DESC')

            if SORT_COLUMN in sql:
                # Method 1: insert sort_col at specified position
                sql = sql.replace(SORT_COLUMN, sort_col or '1')
            elif sort_col:
                # Method 2: automagically insert sort_col (and __group__
                # before it, if __group__ was specified) as first criterions
                if '__group__' in cols:
                    order_by.append('__group__ ASC')
                order_by.append(sort_col)
                # is there already an ORDER BY in the original sql?
                skel = sql_skeleton(sql)
                before, after = split_sql(sql, _order_by_re, skel)
                if after: # there were some other criterions, keep them
                    order_by.append(after)
                sql = ' '.join([before, 'ORDER BY', ', '.join(order_by)])

            # Add LIMIT/OFFSET if pagination needed
            limit_offset = ''
            if num_items > limit:
                limit_offset = ' '.join(['LIMIT', str(limit),
                                         'OFFSET', str(offset)])
            if LIMIT_OFFSET in sql:
                # Method 1: insert LIMIT/OFFSET at specified position
                sql = sql.replace(LIMIT_OFFSET, limit_offset)
            else:
                # Method 2: limit/offset is added unless already present
                skel = skel or sql_skeleton(sql)
                if 'LIMIT' not in skel.upper():
                    sql = ' '.join([sql, limit_offset])
            self.log.debug("Report {%d} SQL (order + limit): %s", id, sql)
        try:
            cursor.execute(sql, args)
        except Exception, e:
            if order_by or limit_offset:
                add_notice(req, _("Hint: if the report failed due to automatic"
                                  " modification of the ORDER BY clause or the"
                                  " addition of LIMIT/OFFSET, please look up"
                                  " %(sort_column)s and %(limit_offset)s in"
                                  " TracReports to see how to gain complete"
                                  " control over report rewriting.",
                                  sort_column=SORT_COLUMN,
                                  limit_offset=LIMIT_OFFSET))
            return e, sql
        rows = cursor.fetchall() or []
        cols = get_column_names(cursor)
        return cols, rows, num_items, missing_args, limit_offset

    def get_var_args(self, req):
        # reuse somehow for #9574 (wiki vars)
        report_args = {}
        for arg in req.args.keys():
            if not arg.isupper():
                continue
            report_args[arg] = to_unicode(req.args.get(arg))

        # Set some default dynamic variables
        if 'USER' not in report_args:
            report_args['USER'] = req.authname

        return report_args

    def sql_sub_vars(self, sql, args, db=None):
        """Extract $XYZ-style variables from the `sql` query.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        names = set()
        values = []
        missing_args = []
        def add_value(aname):
            names.add(aname)
            try:
                arg = args[aname]
            except KeyError:
                arg = args[str(aname)] = ''
                missing_args.append(aname)
            values.append(arg)

        var_re = re.compile("[$]([A-Z_][A-Z0-9_]*)")

        # simple parameter substitution outside literal
        def repl(match):
            add_value(match.group(1))
            return '%s'

        # inside a literal break it and concatenate with the parameter
        def repl_literal(expr):
            parts = var_re.split(expr[1:-1])
            if len(parts) == 1:
                return expr
            params = parts[1::2]
            parts = ["'%s'" % p for p in parts]
            parts[1::2] = ['%s'] * len(params)
            for param in params:
                add_value(param)
            return self.env.get_read_db().concat(*parts)

        sql_io = StringIO()

        # break SQL into literals and non-literals to handle replacing
        # variables within them with query parameters
        for expr in re.split("('(?:[^']|(?:''))*')", sql):
            if expr.startswith("'"):
                sql_io.write(repl_literal(expr))
            else:
                sql_io.write(var_re.sub(repl, expr))

        # Remove arguments that don't appear in the SQL query
        for name in set(args) - names:
            del args[name]
        return sql_io.getvalue(), values, missing_args

    def _send_csv(self, req, cols, rows, sep=',', mimetype='text/plain',
                  filename=None):
        def iso_time(t):
            return format_time(from_utimestamp(t), 'iso8601')

        def iso_datetime(dt):
            return format_datetime(from_utimestamp(dt), 'iso8601')

        col_conversions = {
            'time': iso_time,
            'datetime': iso_datetime,
            'changetime': iso_datetime,
            'date': iso_datetime,
            'created': iso_datetime,
            'modified': iso_datetime,
        }

        converters = [col_conversions.get(c.strip('_'), cell_value)
                      for c in cols]

        out = StringIO()
        out.write('\xef\xbb\xbf')       # BOM
        writer = csv.writer(out, delimiter=sep)
        writer.writerow([unicode(c).encode('utf-8') for c in cols
                         if c not in self._html_cols])
        for row in rows:
            writer.writerow([converters[i](cell).encode('utf-8')
                             for i, cell in enumerate(row)
                             if cols[i] not in self._html_cols])
        data = out.getvalue()

        req.send_response(200)
        req.send_header('Content-Type', mimetype + ';charset=utf-8')
        req.send_header('Content-Length', len(data))
        if filename:
            req.send_header('Content-Disposition',
                            content_disposition('attachment', filename))
        req.end_headers()
        req.write(data)
        raise RequestDone

    def _send_sql(self, req, id, title, description, sql):
        req.perm.require('REPORT_SQL_VIEW')

        out = StringIO()
        out.write('-- ## %s: %s ## --\n\n' % (id, title.encode('utf-8')))
        if description:
            lines = description.encode('utf-8').splitlines()
            out.write('-- %s\n\n' % '\n-- '.join(lines))
        out.write(sql.encode('utf-8'))
        data = out.getvalue()

        req.send_response(200)
        req.send_header('Content-Type', 'text/plain;charset=utf-8')
        req.send_header('Content-Length', len(data))
        if id:
            req.send_header('Content-Disposition',
                            content_disposition('attachment',
                                                'report_%s.sql' % id))
        req.end_headers()
        req.write(data)
        raise RequestDone

    # IWikiSyntaxProvider methods

    def get_link_resolvers(self):
        yield ('report', self._format_link)

    def get_wiki_syntax(self):
        yield (r"!?\{(?P<it_report>%s\s*)[0-9]+\}" % \
                                                WikiParser.INTERTRAC_SCHEME,
               lambda x, y, z: self._format_link(x, 'report', y[1:-1], y, z))

    def _format_link(self, formatter, ns, target, label, fullmatch=None):
        intertrac = formatter.shorthand_intertrac_helper(ns, target, label,
                                                         fullmatch)
        if intertrac:
            return intertrac
        report, args, fragment = formatter.split_link(target)
        return tag.a(label, href=formatter.href.report(report) + args,
                     class_='report')

########NEW FILE########
__FILENAME__ = roadmap
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2006-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

from StringIO import StringIO
from datetime import datetime, timedelta
import re

from genshi.builder import tag

from trac import __version__
from trac.attachment import AttachmentModule
from trac.config import ConfigSection, ExtensionOption
from trac.core import *
from trac.perm import IPermissionRequestor
from trac.resource import *
from trac.search import ISearchSource, search_to_regexps, shorten_result
from trac.util import as_bool
from trac.util.datefmt import parse_date, utc, to_utimestamp, to_datetime, \
                              get_datetime_format_hint, format_date, \
                              format_datetime, from_utimestamp, user_time
from trac.util.text import CRLF
from trac.util.translation import _, tag_
from trac.ticket.api import TicketSystem
from trac.ticket.model import Milestone, MilestoneCache, Ticket, \
                              group_milestones
from trac.timeline.api import ITimelineEventProvider
from trac.web import IRequestHandler, RequestDone
from trac.web.chrome import (Chrome, INavigationContributor,
                             add_link, add_notice, add_script, add_stylesheet,
                             add_warning, auth_link, prevnext_nav, web_context)
from trac.wiki.api import IWikiSyntaxProvider
from trac.wiki.formatter import format_to


class ITicketGroupStatsProvider(Interface):
    def get_ticket_group_stats(ticket_ids):
        """ Gather statistics on a group of tickets.

        This method returns a valid `TicketGroupStats` object.
        """

class TicketGroupStats(object):
    """Encapsulates statistics on a group of tickets."""

    def __init__(self, title, unit):
        """
        :param title: the display name of this group of stats (e.g.
                      ``'ticket status'``)
        :param unit: is the units for these stats in plural form,
                     e.g. ``_('hours'``)
        """
        self.title = title
        self.unit = unit
        self.count = 0
        self.qry_args = {}
        self.intervals = []
        self.done_percent = 0
        self.done_count = 0

    def add_interval(self, title, count, qry_args, css_class,
                     overall_completion=None):
        """Adds a division to this stats' group's progress bar.

        :param title: the display name (e.g. ``'closed'``, ``'spent
                      effort'``) of this interval that will be
                      displayed in front of the unit name
        :param count: the number of units in the interval
        :param qry_args: a dict of extra params that will yield the
                         subset of tickets in this interval on a query.
        :param css_class: is the css class that will be used to
                          display the division
        :param overall_completion: can be set to true to make this
                                   interval count towards overall
                                   completion of this group of
                                   tickets.

        .. versionchanged :: 0.12
           deprecated `countsToProg` argument was removed, use
           `overall_completion` instead
        """
        self.intervals.append({
            'title': title,
            'count': count,
            'qry_args': qry_args,
            'css_class': css_class,
            'percent': None,
            'overall_completion': overall_completion,
        })
        self.count = self.count + count

    def refresh_calcs(self):
        if self.count < 1:
            return
        total_percent = 0
        self.done_percent = 0
        self.done_count = 0
        for interval in self.intervals:
            interval['percent'] = round(float(interval['count'] /
                                        float(self.count) * 100))
            total_percent = total_percent + interval['percent']
            if interval['overall_completion']:
                self.done_percent += interval['percent']
                self.done_count += interval['count']

        # We want the percentages to add up to 100%. To do that, we fudge one
        # of the intervals. If we're <100%, we add to the smallest non-zero
        # interval. If we're >100%, we subtract from the largest interval.
        # The interval is adjusted by enough to make the intervals sum to 100%.
        if self.done_count and total_percent != 100:
            fudge_amt = 100 - total_percent
            fudge_int = [i for i in sorted(self.intervals,
                                           key=lambda k: k['percent'],
                                           reverse=(fudge_amt < 0))
                         if i['percent']][0]
            fudge_int['percent'] += fudge_amt
            self.done_percent += fudge_amt


class DefaultTicketGroupStatsProvider(Component):
    """Configurable ticket group statistics provider.

    See :teo:`TracIni#milestone-groups-section` for a detailed
    example configuration.
    """

    implements(ITicketGroupStatsProvider)

    milestone_groups_section = ConfigSection('milestone-groups',
        """As the workflow for tickets is now configurable, there can
        be many ticket states, and simply displaying closed tickets
        vs. all the others is maybe not appropriate in all cases. This
        section enables one to easily create ''groups'' of states that
        will be shown in different colors in the milestone progress
        bar.

        Note that the groups can only be based on the ticket
        //status//, nothing else. In particular, it's not possible to
        distinguish between different closed tickets based on the
        //resolution//.

        Example configuration with three groups, //closed//, //new//
        and //active// (the default only has closed and active):
        {{{
        # the 'closed' group correspond to the 'closed' tickets
        closed = closed

        # .order: sequence number in the progress bar
        closed.order = 0

        # .query_args: optional parameters for the corresponding
        #              query.  In this example, the changes from the
        #              default are two additional columns ('created' and
        #              'modified'), and sorting is done on 'created'.
        closed.query_args = group=resolution,order=time,col=id,col=summary,col=owner,col=type,col=priority,col=component,col=severity,col=time,col=changetime

        # .overall_completion: indicates groups that count for overall
        #                      completion percentage
        closed.overall_completion = true

        new = new
        new.order = 1
        new.css_class = new
        new.label = new

        # Note: one catch-all group for other statuses is allowed
        active = *
        active.order = 2

        # .css_class: CSS class for this interval
        active.css_class = open

        # .label: displayed label for this group
        active.label = in progress
        }}}

        The definition consists in a comma-separated list of accepted
        status.  Also, '*' means any status and could be used to
        associate all remaining states to one catch-all group.

        The CSS class can be one of: new (yellow), open (no color) or
        closed (green). Other styles can easily be added using custom
        CSS rule: `table.progress td.<class> { background: <color> }`
        to a [TracInterfaceCustomization#SiteAppearance site/style.css] file
        for example.

        (''since 0.11'')""")

    default_milestone_groups =  [
        {'name': 'closed', 'status': 'closed',
         'query_args': 'group=resolution', 'overall_completion': 'true'},
        {'name': 'active', 'status': '*', 'css_class': 'open'}
        ]

    def _get_ticket_groups(self):
        """Returns a list of dict describing the ticket groups
        in the expected order of appearance in the milestone progress bars.
        """
        if 'milestone-groups' in self.config:
            groups = {}
            order = 0
            for groupname, value in self.milestone_groups_section.options():
                qualifier = 'status'
                if '.' in groupname:
                    groupname, qualifier = groupname.split('.', 1)
                group = groups.setdefault(groupname, {'name': groupname,
                                                      'order': order})
                group[qualifier] = value
                order = max(order, int(group['order'])) + 1
            return [group for group in sorted(groups.values(),
                                              key=lambda g: int(g['order']))]
        else:
            return self.default_milestone_groups

    def get_ticket_group_stats(self, ticket_ids):
        total_cnt = len(ticket_ids)
        all_statuses = set(TicketSystem(self.env).get_all_status())
        status_cnt = {}
        for s in all_statuses:
            status_cnt[s] = 0
        if total_cnt:
            for status, count in self.env.db_query("""
                    SELECT status, count(status) FROM ticket
                    WHERE id IN (%s) GROUP BY status
                    """ % ",".join(str(x) for x in sorted(ticket_ids))):
                status_cnt[status] = count

        stat = TicketGroupStats(_('ticket status'), _('tickets'))
        remaining_statuses = set(all_statuses)
        groups =  self._get_ticket_groups()
        catch_all_group = None
        # we need to go through the groups twice, so that the catch up group
        # doesn't need to be the last one in the sequence
        for group in groups:
            status_str = group['status'].strip()
            if status_str == '*':
                if catch_all_group:
                    raise TracError(_(
                        "'%(group1)s' and '%(group2)s' milestone groups "
                        "both are declared to be \"catch-all\" groups. "
                        "Please check your configuration.",
                        group1=group['name'], group2=catch_all_group['name']))
                catch_all_group = group
            else:
                group_statuses = set([s.strip()
                                      for s in status_str.split(',')]) \
                                      & all_statuses
                if group_statuses - remaining_statuses:
                    raise TracError(_(
                        "'%(groupname)s' milestone group reused status "
                        "'%(status)s' already taken by other groups. "
                        "Please check your configuration.",
                        groupname=group['name'],
                        status=', '.join(group_statuses - remaining_statuses)))
                else:
                    remaining_statuses -= group_statuses
                group['statuses'] = group_statuses
        if catch_all_group:
            catch_all_group['statuses'] = remaining_statuses
        for group in groups:
            group_cnt = 0
            query_args = {}
            for s, cnt in status_cnt.iteritems():
                if s in group['statuses']:
                    group_cnt += cnt
                    query_args.setdefault('status', []).append(s)
            for arg in [kv for kv in group.get('query_args', '').split(',')
                        if '=' in kv]:
                k, v = [a.strip() for a in arg.split('=', 1)]
                query_args.setdefault(k, []).append(v)
            stat.add_interval(group.get('label', group['name']),
                              group_cnt, query_args,
                              group.get('css_class', group['name']),
                              as_bool(group.get('overall_completion')))
        stat.refresh_calcs()
        return stat


def get_ticket_stats(provider, tickets):
    return provider.get_ticket_group_stats([t['id'] for t in tickets])

def get_tickets_for_milestone(env, db=None, milestone=None, field='component'):
    """Retrieve all tickets associated with the given `milestone`.

    .. versionchanged :: 1.0
       the `db` parameter is no longer needed and will be removed in
       version 1.1.1
    """
    with env.db_query as db:
        fields = TicketSystem(env).get_ticket_fields()
        if field in [f['name'] for f in fields if not f.get('custom')]:
            sql = """SELECT id, status, %s FROM ticket WHERE milestone=%%s
                     ORDER BY %s""" % (field, field)
            args = (milestone,)
        else:
            sql = """SELECT id, status, value FROM ticket
                       LEFT OUTER JOIN ticket_custom ON (id=ticket AND name=%s)
                      WHERE milestone=%s ORDER BY value"""
            args = (field, milestone)
        return [{'id': tkt_id, 'status': status, field: fieldval}
                for tkt_id, status, fieldval in env.db_query(sql, args)]

def apply_ticket_permissions(env, req, tickets):
    """Apply permissions to a set of milestone tickets as returned by
    `get_tickets_for_milestone()`."""
    return [t for t in tickets
            if 'TICKET_VIEW' in req.perm('ticket', t['id'])]

def milestone_stats_data(env, req, stat, name, grouped_by='component',
                         group=None):
    from trac.ticket.query import QueryModule
    has_query = env[QueryModule] is not None
    def query_href(extra_args):
        if not has_query:
            return None
        args = {'milestone': name, grouped_by: group, 'group': 'status'}
        args.update(extra_args)
        return req.href.query(args)
    return {'stats': stat,
            'stats_href': query_href(stat.qry_args),
            'interval_hrefs': [query_href(interval['qry_args'])
                               for interval in stat.intervals]}

def grouped_stats_data(env, stats_provider, tickets, by, per_group_stats_data):
    """Get the `tickets` stats data grouped by ticket field `by`.

    `per_group_stats_data(gstat, group_name)` should return a data dict to
    include for the group with field value `group_name`.
    """
    group_names = []
    for field in TicketSystem(env).get_ticket_fields():
        if field['name'] == by:
            if 'options' in field:
                group_names = field['options']
                if field.get('optional'):
                    group_names.insert(0, '')
            else:
                group_names = [name for name, in env.db_query("""
                    SELECT DISTINCT COALESCE(%s, '') FROM ticket
                    ORDER BY COALESCE(%s, '')
                    """ % (by, by))]
    max_count = 0
    data = []

    for name in group_names:
        values = (name,) if name else (None, name)
        group_tickets = [t for t in tickets if t[by] in values]
        if not group_tickets:
            continue

        gstat = get_ticket_stats(stats_provider, group_tickets)
        if gstat.count > max_count:
            max_count = gstat.count

        gs_dict = {'name': name}
        gs_dict.update(per_group_stats_data(gstat, name))
        data.append(gs_dict)

    for gs_dict in data:
        percent = 1.0
        if max_count:
            gstat = gs_dict['stats']
            percent = float(gstat.count) / float(max_count) * 100
        gs_dict['percent_of_max_total'] = percent
    return data


class RoadmapModule(Component):
    """Give an overview over all the milestones."""

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler)

    stats_provider = ExtensionOption('roadmap', 'stats_provider',
                                     ITicketGroupStatsProvider,
                                     'DefaultTicketGroupStatsProvider',
        """Name of the component implementing `ITicketGroupStatsProvider`,
        which is used to collect statistics on groups of tickets for display
        in the roadmap views.""")

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'roadmap'

    def get_navigation_items(self, req):
        if 'ROADMAP_VIEW' in req.perm:
            yield ('mainnav', 'roadmap',
                   tag.a(_('Roadmap'), href=req.href.roadmap(), accesskey=3))

    # IPermissionRequestor methods

    def get_permission_actions(self):
        actions = ['MILESTONE_CREATE', 'MILESTONE_DELETE', 'MILESTONE_MODIFY',
                   'MILESTONE_VIEW', 'ROADMAP_VIEW']
        return ['ROADMAP_VIEW'] + [('ROADMAP_ADMIN', actions)]

    # IRequestHandler methods

    def match_request(self, req):
        return req.path_info == '/roadmap'

    def process_request(self, req):
        req.perm.require('MILESTONE_VIEW')

        show = req.args.getlist('show')
        if 'all' in show:
            show = ['completed']

        milestones = Milestone.select(self.env, 'completed' in show)
        if 'noduedate' in show:
            milestones = [m for m in milestones
                          if m.due is not None or m.completed]
        milestones = [m for m in milestones
                      if 'MILESTONE_VIEW' in req.perm(m.resource)]

        stats = []
        queries = []

        for milestone in milestones:
            tickets = get_tickets_for_milestone(
                    self.env, milestone=milestone.name, field='owner')
            tickets = apply_ticket_permissions(self.env, req, tickets)
            stat = get_ticket_stats(self.stats_provider, tickets)
            stats.append(milestone_stats_data(self.env, req, stat,
                                              milestone.name))
            #milestone['tickets'] = tickets # for the iCalendar view

        if req.args.get('format') == 'ics':
            self._render_ics(req, milestones)
            return

        # FIXME should use the 'webcal:' scheme, probably
        username = None
        if req.authname and req.authname != 'anonymous':
            username = req.authname
        icshref = req.href.roadmap(show=show, user=username, format='ics')
        add_link(req, 'alternate', auth_link(req, icshref), _('iCalendar'),
                 'text/calendar', 'ics')

        data = {
            'milestones': milestones,
            'milestone_stats': stats,
            'queries': queries,
            'show': show,
        }
        add_stylesheet(req, 'common/css/roadmap.css')
        return 'roadmap.html', data, None

    # Internal methods

    def _render_ics(self, req, milestones):
        req.send_response(200)
        req.send_header('Content-Type', 'text/calendar;charset=utf-8')
        buf = StringIO()

        from trac.ticket import Priority
        priorities = {}
        for priority in Priority.select(self.env):
            priorities[priority.name] = float(priority.value)
        def get_priority(ticket):
            value = priorities.get(ticket['priority'])
            if value:
                return int((len(priorities) + 8 * value - 9) /
                       (len(priorities) - 1))

        def get_status(ticket):
            status = ticket['status']
            if status == 'new' or status == 'reopened' and not ticket['owner']:
                return 'NEEDS-ACTION'
            elif status == 'assigned' or status == 'reopened':
                return 'IN-PROCESS'
            elif status == 'closed':
                if ticket['resolution'] == 'fixed':
                    return 'COMPLETED'
                else:
                    return 'CANCELLED'
            else: return ''

        def escape_value(text):
            s = ''.join(map(lambda c: '\\' + c if c in ';,\\' else c, text))
            return '\\n'.join(re.split(r'[\r\n]+', s))

        def write_prop(name, value, params={}):
            text = ';'.join([name] + [k + '=' + v for k, v in params.items()]) \
                 + ':' + escape_value(value)
            firstline = 1
            while text:
                if not firstline:
                    text = ' ' + text
                else:
                    firstline = 0
                buf.write(text[:75] + CRLF)
                text = text[75:]

        def write_date(name, value, params={}):
            params['VALUE'] = 'DATE'
            write_prop(name, format_date(value, '%Y%m%d', req.tz), params)

        def write_utctime(name, value, params={}):
            write_prop(name, format_datetime(value, '%Y%m%dT%H%M%SZ', utc),
                       params)

        host = req.base_url[req.base_url.find('://') + 3:]
        user = req.args.get('user', 'anonymous')

        write_prop('BEGIN', 'VCALENDAR')
        write_prop('VERSION', '2.0')
        write_prop('PRODID', '-//Edgewall Software//NONSGML Trac %s//EN'
                   % __version__)
        write_prop('METHOD', 'PUBLISH')
        write_prop('X-WR-CALNAME',
                   self.env.project_name + ' - ' + _('Roadmap'))
        write_prop('X-WR-CALDESC', self.env.project_description)
        write_prop('X-WR-TIMEZONE', str(req.tz))

        for milestone in milestones:
            uid = '<%s/milestone/%s@%s>' % (req.base_path, milestone.name,
                                            host)
            if milestone.due:
                write_prop('BEGIN', 'VEVENT')
                write_prop('UID', uid)
                write_utctime('DTSTAMP', milestone.due)
                write_date('DTSTART', milestone.due)
                write_prop('SUMMARY', _('Milestone %(name)s',
                                        name=milestone.name))
                write_prop('URL', req.abs_href.milestone(milestone.name))
                if milestone.description:
                    write_prop('DESCRIPTION', milestone.description)
                write_prop('END', 'VEVENT')
            tickets = get_tickets_for_milestone(
                    self.env, milestone=milestone.name, field='owner')
            tickets = apply_ticket_permissions(self.env, req, tickets)
            for tkt_id in [ticket['id'] for ticket in tickets
                           if ticket['owner'] == user]:
                ticket = Ticket(self.env, tkt_id)
                write_prop('BEGIN', 'VTODO')
                write_prop('UID', '<%s/ticket/%s@%s>' % (req.base_path,
                                                         tkt_id, host))
                if milestone.due:
                    write_prop('RELATED-TO', uid)
                    write_date('DUE', milestone.due)
                write_prop('SUMMARY', _('Ticket #%(num)s: %(summary)s',
                                        num=ticket.id,
                                        summary=ticket['summary']))
                write_prop('URL', req.abs_href.ticket(ticket.id))
                write_prop('DESCRIPTION', ticket['description'])
                priority = get_priority(ticket)
                if priority:
                    write_prop('PRIORITY', unicode(priority))
                write_prop('STATUS', get_status(ticket))
                if ticket['status'] == 'closed':
                    for time, in self.env.db_query("""
                            SELECT time FROM ticket_change
                            WHERE ticket=%s AND field='status'
                            ORDER BY time desc LIMIT 1
                            """, (ticket.id,)):
                        write_utctime('COMPLETED', from_utimestamp(time))
                write_prop('END', 'VTODO')
        write_prop('END', 'VCALENDAR')

        ics_str = buf.getvalue().encode('utf-8')
        req.send_header('Content-Length', len(ics_str))
        req.end_headers()
        req.write(ics_str)
        raise RequestDone


class MilestoneModule(Component):
    """View and edit individual milestones."""

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
               ITimelineEventProvider, IWikiSyntaxProvider, IResourceManager,
               ISearchSource)

    stats_provider = ExtensionOption('milestone', 'stats_provider',
                                     ITicketGroupStatsProvider,
                                     'DefaultTicketGroupStatsProvider',
        """Name of the component implementing `ITicketGroupStatsProvider`,
        which is used to collect statistics on groups of tickets for display
        in the milestone views.""")


    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'roadmap'

    def get_navigation_items(self, req):
        return []

    # IPermissionRequestor methods

    def get_permission_actions(self):
        actions = ['MILESTONE_CREATE', 'MILESTONE_DELETE', 'MILESTONE_MODIFY',
                   'MILESTONE_VIEW']
        return actions + [('MILESTONE_ADMIN', actions)]

    # ITimelineEventProvider methods

    def get_timeline_filters(self, req):
        if 'MILESTONE_VIEW' in req.perm:
            yield ('milestone', _('Milestones reached'))

    def get_timeline_events(self, req, start, stop, filters):
        if 'milestone' in filters:
            milestone_realm = Resource('milestone')
            for name, due, completed, description \
                    in MilestoneCache(self.env).milestones.itervalues():
                if completed and start <= completed <= stop:
                    # TODO: creation and (later) modifications should also be
                    #       reported
                    milestone = milestone_realm(id=name)
                    if 'MILESTONE_VIEW' in req.perm(milestone):
                        yield ('milestone', completed, '', # FIXME: author?
                               (milestone, description))

            # Attachments
            for event in AttachmentModule(self.env).get_timeline_events(
                req, milestone_realm, start, stop):
                yield event

    def render_timeline_event(self, context, field, event):
        milestone, description = event[3]
        if field == 'url':
            return context.href.milestone(milestone.id)
        elif field == 'title':
            return tag_('Milestone %(name)s completed',
                        name=tag.em(milestone.id))
        elif field == 'description':
            return format_to(self.env, None, context.child(resource=milestone),
                             description)

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/milestone(?:/(.+))?$', req.path_info)
        if match:
            if match.group(1):
                req.args['id'] = match.group(1)
            return True

    def process_request(self, req):
        milestone_id = req.args.get('id')
        req.perm('milestone', milestone_id).require('MILESTONE_VIEW')

        add_link(req, 'up', req.href.roadmap(), _('Roadmap'))

        action = req.args.get('action', 'view')
        try:
            milestone = Milestone(self.env, milestone_id)
        except ResourceNotFound:
            if 'MILESTONE_CREATE' not in req.perm('milestone', milestone_id):
                raise
            milestone = Milestone(self.env, None)
            milestone.name = milestone_id
            action = 'edit' # rather than 'new' so that it works for POST/save

        if req.method == 'POST':
            if req.args.has_key('cancel'):
                if milestone.exists:
                    req.redirect(req.href.milestone(milestone.name))
                else:
                    req.redirect(req.href.roadmap())
            elif action == 'edit':
                return self._do_save(req, milestone)
            elif action == 'delete':
                self._do_delete(req, milestone)
        elif action in ('new', 'edit'):
            return self._render_editor(req, milestone)
        elif action == 'delete':
            return self._render_confirm(req, milestone)

        if not milestone.name:
            req.redirect(req.href.roadmap())

        return self._render_view(req, milestone)

    # Internal methods

    def _do_delete(self, req, milestone):
        req.perm(milestone.resource).require('MILESTONE_DELETE')

        retarget_to = None
        if req.args.has_key('retarget'):
            retarget_to = req.args.get('target') or None
        milestone.delete(retarget_to, req.authname)
        add_notice(req, _('The milestone "%(name)s" has been deleted.',
                          name=milestone.name))
        req.redirect(req.href.roadmap())

    def _do_save(self, req, milestone):
        if milestone.exists:
            req.perm(milestone.resource).require('MILESTONE_MODIFY')
        else:
            req.perm(milestone.resource).require('MILESTONE_CREATE')

        old_name = milestone.name
        new_name = req.args.get('name')

        milestone.description = req.args.get('description', '')

        if 'due' in req.args:
            due = req.args.get('duedate', '')
            milestone.due = user_time(req, parse_date, due, hint='datetime') \
                            if due else None
        else:
            milestone.due = None

        completed = req.args.get('completeddate', '')
        retarget_to = req.args.get('target')

        # Instead of raising one single error, check all the constraints and
        # let the user fix them by going back to edit mode showing the warnings
        warnings = []
        def warn(msg):
            add_warning(req, msg)
            warnings.append(msg)

        # -- check the name
        # If the name has changed, check that the milestone doesn't already
        # exist
        # FIXME: the whole .exists business needs to be clarified
        #        (#4130) and should behave like a WikiPage does in
        #        this respect.
        try:
            new_milestone = Milestone(self.env, new_name)
            if new_milestone.name == old_name:
                pass        # Creation or no name change
            elif new_milestone.name:
                warn(_('Milestone "%(name)s" already exists, please '
                       'choose another name.', name=new_milestone.name))
            else:
                warn(_('You must provide a name for the milestone.'))
        except ResourceNotFound:
            milestone.name = new_name

        # -- check completed date
        if 'completed' in req.args:
            completed = user_time(req, parse_date, completed,
                                  hint='datetime') if completed else None
            if completed and completed > datetime.now(utc):
                warn(_('Completion date may not be in the future'))
        else:
            completed = None
        milestone.completed = completed

        if warnings:
            return self._render_editor(req, milestone)

        # -- actually save changes
        if milestone.exists:
            milestone.update()
            # eventually retarget opened tickets associated with the milestone
            if 'retarget' in req.args and completed:
                self.env.db_transaction("""
                    UPDATE ticket SET milestone=%s
                    WHERE milestone=%s and status != 'closed'
                    """, (retarget_to, old_name))
                self.log.info("Tickets associated with milestone %s "
                              "retargeted to %s" % (old_name, retarget_to))
        else:
            milestone.insert()

        add_notice(req, _("Your changes have been saved."))
        req.redirect(req.href.milestone(milestone.name))

    def _render_confirm(self, req, milestone):
        req.perm(milestone.resource).require('MILESTONE_DELETE')

        milestones = [m for m in Milestone.select(self.env)
                      if m.name != milestone.name
                      and 'MILESTONE_VIEW' in req.perm(m.resource)]
        data = {
            'milestone': milestone,
            'milestone_groups': group_milestones(milestones,
                'TICKET_ADMIN' in req.perm)
        }
        return 'milestone_delete.html', data, None

    def _render_editor(self, req, milestone):
        # Suggest a default due time of 18:00 in the user's timezone
        now = datetime.now(req.tz)
        default_due = datetime(now.year, now.month, now.day, 18)
        if now.hour > 18:
            default_due += timedelta(days=1)
        default_due = to_datetime(default_due, req.tz)

        data = {
            'milestone': milestone,
            'datetime_hint': get_datetime_format_hint(req.lc_time),
            'default_due': default_due,
            'milestone_groups': [],
        }

        if milestone.exists:
            req.perm(milestone.resource).require('MILESTONE_MODIFY')
            milestones = [m for m in Milestone.select(self.env)
                          if m.name != milestone.name
                          and 'MILESTONE_VIEW' in req.perm(m.resource)]
            data['milestone_groups'] = group_milestones(milestones,
                'TICKET_ADMIN' in req.perm)
        else:
            req.perm(milestone.resource).require('MILESTONE_CREATE')

        chrome = Chrome(self.env)
        chrome.add_jquery_ui(req)
        chrome.add_wiki_toolbars(req)
        return 'milestone_edit.html', data, None

    def _render_view(self, req, milestone):
        milestone_groups = []
        available_groups = []
        component_group_available = False
        ticket_fields = TicketSystem(self.env).get_ticket_fields()

        # collect fields that can be used for grouping
        for field in ticket_fields:
            if field['type'] == 'select' and field['name'] != 'milestone' \
                    or field['name'] in ('owner', 'reporter'):
                available_groups.append({'name': field['name'],
                                         'label': field['label']})
                if field['name'] == 'component':
                    component_group_available = True

        # determine the field currently used for grouping
        by = None
        if component_group_available:
            by = 'component'
        elif available_groups:
            by = available_groups[0]['name']
        by = req.args.get('by', by)

        tickets = get_tickets_for_milestone(self.env, milestone=milestone.name,
                                            field=by)
        tickets = apply_ticket_permissions(self.env, req, tickets)
        stat = get_ticket_stats(self.stats_provider, tickets)

        context = web_context(req, milestone.resource)
        data = {
            'context': context,
            'milestone': milestone,
            'attachments': AttachmentModule(self.env).attachment_data(context),
            'available_groups': available_groups,
            'grouped_by': by,
            'groups': milestone_groups
            }
        data.update(milestone_stats_data(self.env, req, stat, milestone.name))

        if by:
            def per_group_stats_data(gstat, group_name):
                return milestone_stats_data(self.env, req, gstat,
                                            milestone.name, by, group_name)
            milestone_groups.extend(
                grouped_stats_data(self.env, self.stats_provider, tickets, by,
                                   per_group_stats_data))

        add_stylesheet(req, 'common/css/roadmap.css')
        add_script(req, 'common/js/folding.js')

        def add_milestone_link(rel, milestone):
            href = req.href.milestone(milestone.name, by=req.args.get('by'))
            add_link(req, rel, href, _('Milestone "%(name)s"',
                                       name=milestone.name))

        milestones = [m for m in Milestone.select(self.env)
                      if 'MILESTONE_VIEW' in req.perm(m.resource)]
        idx = [i for i, m in enumerate(milestones) if m.name == milestone.name]
        if idx:
            idx = idx[0]
            if idx > 0:
                add_milestone_link('first', milestones[0])
                add_milestone_link('prev', milestones[idx - 1])
            if idx < len(milestones) - 1:
                add_milestone_link('next', milestones[idx + 1])
                add_milestone_link('last', milestones[-1])
        roadmap_back = self.env[RoadmapModule] and _('Back to Roadmap') or None
        prevnext_nav(req, _('Previous Milestone'), _('Next Milestone'),
                         roadmap_back)

        return 'milestone_view.html', data, None

    # IWikiSyntaxProvider methods

    def get_wiki_syntax(self):
        return []

    def get_link_resolvers(self):
        yield ('milestone', self._format_link)

    def _format_link(self, formatter, ns, name, label):
        name, query, fragment = formatter.split_link(name)
        return self._render_link(formatter.context, name, label,
                                 query + fragment)

    def _render_link(self, context, name, label, extra=''):
        try:
            milestone = Milestone(self.env, name)
        except TracError:
            milestone = None
        # Note: the above should really not be needed, `Milestone.exists`
        # should simply be false if the milestone doesn't exist in the db
        # (related to #4130)
        href = context.href.milestone(name)
        if milestone and milestone.exists:
            if 'MILESTONE_VIEW' in context.perm(milestone.resource):
                closed = 'closed ' if milestone.is_completed else ''
                return tag.a(label, class_='%smilestone' % closed,
                             href=href + extra)
        elif 'MILESTONE_CREATE' in context.perm('milestone', name):
            return tag.a(label, class_='missing milestone', href=href + extra,
                         rel='nofollow')
        return tag.a(label, class_='missing milestone')

    # IResourceManager methods

    def get_resource_realms(self):
        yield 'milestone'

    def get_resource_description(self, resource, format=None, context=None,
                                 **kwargs):
        nbhprefix = ResourceSystem(self.env).neighborhood_prefix(
                resource.neighborhood)
        desc = resource.id
        if format != 'compact':
            desc =  nbhprefix + _('Milestone %(name)s', name=resource.id)
        if context:
            return self._render_link(context, resource.id, desc)
        else:
            return desc

    def resource_exists(self, resource):
        """
        >>> from trac.test import EnvironmentStub
        >>> env = EnvironmentStub()

        >>> m1 = Milestone(env)
        >>> m1.name = 'M1'
        >>> m1.insert()

        >>> MilestoneModule(env).resource_exists(Resource('milestone', 'M1'))
        True
        >>> MilestoneModule(env).resource_exists(Resource('milestone', 'M2'))
        False
        """
        return resource.id in MilestoneCache(self.env).milestones

    # ISearchSource methods

    def get_search_filters(self, req):
        if 'MILESTONE_VIEW' in req.perm:
            yield ('milestone', _('Milestones'))

    def get_search_results(self, req, terms, filters):
        if not 'milestone' in filters:
            return
        term_regexps = search_to_regexps(terms)
        milestone_realm = Resource('milestone')
        for name, due, completed, description \
                in MilestoneCache(self.env).milestones.itervalues():
            if any(r.search(description) or r.search(name)
                   for r in term_regexps):
                milestone = milestone_realm(id=name)
                if 'MILESTONE_VIEW' in req.perm(milestone):
                    dt = (completed if completed else
                          due if due else datetime.now(utc))
                    yield (get_resource_url(self.env, milestone, req.href),
                           get_resource_name(self.env, milestone), dt,
                           '', shorten_result(description, terms))

        # Attachments
        for result in AttachmentModule(self.env).get_search_results(
                req, milestone_realm, terms):
            yield result

########NEW FILE########
__FILENAME__ = api
from trac.perm import PermissionCache, PermissionSystem
from trac.ticket.api import TicketSystem, ITicketFieldProvider
from trac.ticket.model import Ticket
from trac.test import EnvironmentStub, Mock
from trac.core import implements, Component

import unittest

class TestFieldProvider(Component):
    implements(ITicketFieldProvider)

    def __init__(self):
        self.raw_fields = []

    def get_select_fields(self):
        return []

    def get_radio_fields(self):
        return []

    def get_raw_fields(self):
        return self.raw_fields


class TicketSystemTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        self.perm = PermissionSystem(self.env)
        self.ticket_system = TicketSystem(self.env)
        self.req = Mock()

    def tearDown(self):
        self.env.reset_db()

    def _get_actions(self, ticket_dict):
        ts = TicketSystem(self.env)
        ticket = Ticket(self.env)
        ticket.populate(ticket_dict)
        id = ticket.insert()
        return ts.get_available_actions(self.req, Ticket(self.env, id))

    def test_custom_field_text(self):
        self.env.config.set('ticket-custom', 'test', 'text')
        self.env.config.set('ticket-custom', 'test.label', 'Test')
        self.env.config.set('ticket-custom', 'test.value', 'Foo bar')
        self.env.config.set('ticket-custom', 'test.format', 'wiki')
        fields = TicketSystem(self.env).get_custom_fields()
        self.assertEqual({'name': 'test', 'type': 'text', 'label': 'Test',
                          'value': 'Foo bar', 'order': 0, 'format': 'wiki'},
                         fields[0])

    def test_custom_field_select(self):
        self.env.config.set('ticket-custom', 'test', 'select')
        self.env.config.set('ticket-custom', 'test.label', 'Test')
        self.env.config.set('ticket-custom', 'test.value', '1')
        self.env.config.set('ticket-custom', 'test.options', 'option1|option2')
        fields = TicketSystem(self.env).get_custom_fields()
        self.assertEqual({'name': 'test', 'type': 'select', 'label': 'Test',
                          'value': '1', 'options': ['option1', 'option2'],
                          'order': 0},
                         fields[0])

    def test_custom_field_optional_select(self):
        self.env.config.set('ticket-custom', 'test', 'select')
        self.env.config.set('ticket-custom', 'test.label', 'Test')
        self.env.config.set('ticket-custom', 'test.value', '1')
        self.env.config.set('ticket-custom', 'test.options', '|option1|option2')
        fields = TicketSystem(self.env).get_custom_fields()
        self.assertEqual({'name': 'test', 'type': 'select', 'label': 'Test',
                          'value': '1', 'options': ['option1', 'option2'],
                          'order': 0, 'optional': True},
                         fields[0])

    def test_custom_field_textarea(self):
        self.env.config.set('ticket-custom', 'test', 'textarea')
        self.env.config.set('ticket-custom', 'test.label', 'Test')
        self.env.config.set('ticket-custom', 'test.value', 'Foo bar')
        self.env.config.set('ticket-custom', 'test.cols', '60')
        self.env.config.set('ticket-custom', 'test.rows', '4')
        self.env.config.set('ticket-custom', 'test.format', 'wiki')
        fields = TicketSystem(self.env).get_custom_fields()
        self.assertEqual({'name': 'test', 'type': 'textarea', 'label': 'Test',
                          'value': 'Foo bar', 'width': 60, 'height': 4,
                          'order': 0, 'format': 'wiki'},
                         fields[0])

    def test_custom_field_order(self):
        self.env.config.set('ticket-custom', 'test1', 'text')
        self.env.config.set('ticket-custom', 'test1.order', '2')
        self.env.config.set('ticket-custom', 'test2', 'text')
        self.env.config.set('ticket-custom', 'test2.order', '1')
        fields = TicketSystem(self.env).get_custom_fields()
        self.assertEqual('test2', fields[0]['name'])
        self.assertEqual('test1', fields[1]['name'])

    def test_available_actions_full_perms(self):
        self.perm.grant_permission('anonymous', 'TICKET_CREATE')
        self.perm.grant_permission('anonymous', 'TICKET_MODIFY')
        self.req.perm = PermissionCache(self.env)
        self.assertEqual(['leave', 'resolve', 'reassign', 'accept'],
                         self._get_actions({'status': 'new'}))
        self.assertEqual(['leave', 'resolve', 'reassign', 'accept'],
                         self._get_actions({'status': 'assigned'}))
        self.assertEqual(['leave', 'resolve', 'reassign', 'accept'],
                         self._get_actions({'status': 'accepted'}))
        self.assertEqual(['leave', 'resolve', 'reassign', 'accept'],
                         self._get_actions({'status': 'reopened'}))
        self.assertEqual(['leave', 'reopen'],
                         self._get_actions({'status': 'closed'}))

    def test_available_actions_no_perms(self):
        self.req.perm = PermissionCache(self.env)
        self.assertEqual(['leave'], self._get_actions({'status': 'new'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'assigned'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'accepted'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'reopened'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'closed'}))

    def test_available_actions_create_only(self):
        self.perm.grant_permission('anonymous', 'TICKET_CREATE')
        self.req.perm = PermissionCache(self.env)
        self.assertEqual(['leave'], self._get_actions({'status': 'new'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'assigned'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'accepted'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'reopened'}))
        self.assertEqual(['leave', 'reopen'],
                         self._get_actions({'status': 'closed'}))

    def test_available_actions_chgprop_only(self):
        # CHGPROP is not enough for changing a ticket's state (#3289)
        self.perm.grant_permission('anonymous', 'TICKET_CHGPROP')
        self.req.perm = PermissionCache(self.env)
        self.assertEqual(['leave'], self._get_actions({'status': 'new'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'assigned'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'accepted'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'reopened'}))
        self.assertEqual(['leave'], self._get_actions({'status': 'closed'}))

    def test_can_add_raw_fields_from_field_providers(self):
        testFieldProvider = self.env[TestFieldProvider]
        self.assertIsNotNone(testFieldProvider)
        testFieldProvider.raw_fields = [
            {
                'name': "test_name",
                'type': 'some_type',
                'label': "some_label",
            },
        ]
        fields = TicketSystem(self.env).get_ticket_fields()
        row_added_fields = [
            field for field in fields if field["name"] == "test_name"]
        self.assertEqual(1, len(row_added_fields))

    def test_does_not_add_duplicated_raw_fields_from_field_providers(self):
        testFieldProvider = self.env[TestFieldProvider]
        self.assertIsNotNone(testFieldProvider)
        testFieldProvider.raw_fields = [
            {
                'name': "test_name",
                'type': 'some_type1',
                'label': "some_label1",
            },
            {
                'name': "test_name",
                'type': 'some_type2',
                'label': "some_label2",
            },
        ]
        fields = TicketSystem(self.env).get_ticket_fields()
        row_added_fields = [
            field for field in fields if field["name"] == "test_name"]
        self.assertEqual(1, len(row_added_fields))


def suite():
    return unittest.makeSuite(TicketSystemTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = batch
from trac.perm import PermissionCache
from trac.test import Mock, EnvironmentStub
from trac.ticket import api, default_workflow, web_ui
from trac.ticket.batch import BatchModifyModule
from trac.ticket.model import Ticket
from trac.util.datefmt import utc

import unittest


class BatchModifyTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True,
            enable=[default_workflow.ConfigurableTicketWorkflow,
                    web_ui.TicketModule, 
                    api.TicketSystem])
        self.req = Mock(href=self.env.href, authname='anonymous', tz=utc)
        self.req.session = {}
        self.req.perm = PermissionCache(self.env)

    def assertCommentAdded(self, ticket_id, comment):
        ticket = Ticket(self.env, int(ticket_id))
        changes = ticket.get_changelog()
        comment_change = [c for c in changes if c[2] == 'comment'][0]
        self.assertEqual(comment_change[2], comment)

    def assertFieldChanged(self, ticket_id, field, new_value):
        ticket = Ticket(self.env, int(ticket_id))
        changes = ticket.get_changelog()
        field_change = [c for c in changes if c[2] == field][0]
        self.assertEqual(field_change[4], new_value)

    def _change_list_test_helper(self, original, new, new2, mode):
        batch = BatchModifyModule(self.env)
        return batch._change_list(original, new, new2, mode)

    def _add_list_test_helper(self, original, to_add):
        return self._change_list_test_helper(original, to_add, '', '+')

    def _remove_list_test_helper(self, original, to_remove):
        return self._change_list_test_helper(original, to_remove, '', '-')

    def _add_remove_list_test_helper(self, original, to_add, to_remove):
        return self._change_list_test_helper(original, to_add, to_remove,
                                             '+-')

    def _assign_list_test_helper(self, original, new):
        return self._change_list_test_helper(original, new, '', '=')

    def _insert_ticket(self, summary, **kw):
        """Helper for inserting a ticket into the database"""
        ticket = Ticket(self.env)
        for k, v in kw.items():
            ticket[k] = v
        return ticket.insert()

    def test_ignore_summary_reporter_and_description(self):
        """These cannot be added through the UI, but if somebody tries
        to build their own POST data they will be ignored."""
        batch = BatchModifyModule(self.env)
        self.req.args = {}
        self.req.args['batchmod_value_summary'] = 'test ticket'
        self.req.args['batchmod_value_reporter'] = 'anonymous'
        self.req.args['batchmod_value_description'] = 'synergize the widgets'
        values = batch._get_new_ticket_values(self.req)
        self.assertEqual(len(values), 0)

    def test_add_batchmod_value_data_from_request(self):
        batch = BatchModifyModule(self.env)
        self.req.args = {}
        self.req.args['batchmod_value_milestone'] = 'milestone1'
        values = batch._get_new_ticket_values(self.req)
        self.assertEqual(values['milestone'], 'milestone1')

    def test_selected_tickets(self):
        self.req.args = { 'selected_tickets' : '1,2,3' }
        batch = BatchModifyModule(self.env)
        selected_tickets = batch._get_selected_tickets(self.req)
        self.assertEqual(selected_tickets, ['1', '2', '3'])

    def test_no_selected_tickets(self):
        """If nothing is selected, the return value is the empty list."""
        self.req.args = { 'selected_tickets' : '' }
        batch = BatchModifyModule(self.env)
        selected_tickets = batch._get_selected_tickets(self.req)
        self.assertEqual(selected_tickets, [])

    # Assign list items

    def test_change_list_replace_empty_with_single(self):
        """Replace emtpy field with single item."""
        changed = self._assign_list_test_helper('', 'alice')
        self.assertEqual(changed, 'alice')

    def test_change_list_replace_empty_with_items(self):
        """Replace emtpy field with items."""
        changed = self._assign_list_test_helper('', 'alice, bob')
        self.assertEqual(changed, 'alice, bob')

    def test_change_list_replace_item(self):
        """Replace item with a different item."""
        changed = self._assign_list_test_helper('alice', 'bob')
        self.assertEqual(changed, 'bob')

    def test_change_list_replace_item_with_items(self):
        """Replace item with different items."""
        changed = self._assign_list_test_helper('alice', 'bob, carol')
        self.assertEqual(changed, 'bob, carol')

    def test_change_list_replace_items_with_item(self):
        """Replace items with a different item."""
        changed = self._assign_list_test_helper('alice, bob', 'carol')
        self.assertEqual(changed, 'carol')

    def test_change_list_replace_items(self):
        """Replace items with different items."""
        changed = self._assign_list_test_helper('alice, bob', 'carol, dave')
        self.assertEqual(changed, 'carol, dave')

    def test_change_list_replace_items_partial(self):
        """Replace items with different (or not) items."""
        changed = self._assign_list_test_helper('alice, bob', 'bob, dave')
        self.assertEqual(changed, 'bob, dave')

    def test_change_list_clear(self):
        """Clear field."""
        changed = self._assign_list_test_helper('alice bob', '')
        self.assertEqual(changed, '')

    # Add / remove list items

    def test_change_list_add_item(self):
        """Append additional item."""
        changed = self._add_list_test_helper('alice', 'bob')
        self.assertEqual(changed, 'alice, bob')

    def test_change_list_add_items(self):
        """Append additional items."""
        changed = self._add_list_test_helper('alice, bob', 'carol, dave')
        self.assertEqual(changed, 'alice, bob, carol, dave')

    def test_change_list_remove_item(self):
        """Remove existing item."""
        changed = self._remove_list_test_helper('alice, bob', 'bob')
        self.assertEqual(changed, 'alice')

    def test_change_list_remove_items(self):
        """Remove existing items."""
        changed = self._remove_list_test_helper('alice, bob, carol',
                                                'alice, carol')
        self.assertEqual(changed, 'bob')

    def test_change_list_remove_idempotent(self):
        """Ignore missing item to be removed."""
        changed = self._remove_list_test_helper('alice', 'bob')
        self.assertEqual(changed, 'alice')

    def test_change_list_remove_mixed(self):
        """Ignore only missing item to be removed."""
        changed = self._remove_list_test_helper('alice, bob', 'bob, carol')
        self.assertEqual(changed, 'alice')

    def test_change_list_add_remove(self):
        """Remove existing item and append additional item."""
        changed = self._add_remove_list_test_helper('alice, bob', 'carol',
                                                'alice')
        self.assertEqual(changed, 'bob, carol')

    def test_change_list_add_no_duplicates(self):
        """Existing items are not duplicated."""
        changed = self._add_list_test_helper('alice, bob', 'bob, carol')
        self.assertEqual(changed, 'alice, bob, carol')

    def test_change_list_remove_all_duplicates(self):
        """Remove all duplicates."""
        changed = self._remove_list_test_helper('alice, bob, alice', 'alice')
        self.assertEqual(changed, 'bob')

    # Save

    def test_save_comment(self):
        """Comments are saved to all selected tickets."""
        first_ticket_id = self._insert_ticket('Test 1', reporter='joe')
        second_ticket_id = self._insert_ticket('Test 2', reporter='joe')
        selected_tickets = [first_ticket_id, second_ticket_id]

        batch = BatchModifyModule(self.env)
        batch._save_ticket_changes(self.req, selected_tickets, {}, 'comment',
                                   'leave')

        self.assertCommentAdded(first_ticket_id, 'comment')
        self.assertCommentAdded(second_ticket_id, 'comment')

    def test_save_values(self):
        """Changed values are saved to all tickets."""
        first_ticket_id = self._insert_ticket('Test 1', reporter='joe',
                                              component='foo')
        second_ticket_id = self._insert_ticket('Test 2', reporter='joe')
        selected_tickets = [first_ticket_id, second_ticket_id]
        new_values = { 'component' : 'bar' }

        batch = BatchModifyModule(self.env)
        batch._save_ticket_changes(self.req, selected_tickets, new_values, '',
                                   'leave')

        self.assertFieldChanged(first_ticket_id, 'component', 'bar')
        self.assertFieldChanged(second_ticket_id, 'component', 'bar')

    def test_action_with_state_change(self):
        """Actions can have change status."""
        self.env.config.set('ticket-workflow', 'embiggen', '* -> big')

        first_ticket_id = self._insert_ticket('Test 1', reporter='joe',
                                              status='small')
        second_ticket_id = self._insert_ticket('Test 2', reporter='joe')
        selected_tickets = [first_ticket_id, second_ticket_id]

        batch = BatchModifyModule(self.env)
        batch._save_ticket_changes(self.req, selected_tickets, {}, '',
                                   'embiggen')

        ticket = Ticket(self.env, int(first_ticket_id))
        changes = ticket.get_changelog()
        self.assertFieldChanged(first_ticket_id, 'status', 'big')
        self.assertFieldChanged(second_ticket_id, 'status', 'big')

    def test_action_with_side_effects(self):
        """Actions can have operations with side effects."""
        self.env.config.set('ticket-workflow', 'buckify', '* -> *')
        self.env.config.set('ticket-workflow', 'buckify.operations',
                                               'set_owner')
        self.req.args = {}
        self.req.args['action_buckify_reassign_owner'] = 'buck'

        first_ticket_id = self._insert_ticket('Test 1', reporter='joe',
                                              owner='foo')
        second_ticket_id = self._insert_ticket('Test 2', reporter='joe')
        selected_tickets = [first_ticket_id, second_ticket_id]

        batch = BatchModifyModule(self.env)
        batch._save_ticket_changes(self.req, selected_tickets, {}, '',
                                   'buckify')

        ticket = Ticket(self.env, int(first_ticket_id))
        changes = ticket.get_changelog()
        self.assertFieldChanged(first_ticket_id, 'owner', 'buck')
        self.assertFieldChanged(second_ticket_id, 'owner', 'buck')


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(BatchModifyTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = conversion
import os
import unittest

from trac import __version__ as TRAC_VERSION
from trac.test import EnvironmentStub, Mock
from trac.ticket.model import Ticket
from trac.ticket.web_ui import TicketModule
from trac.mimeview.api import Mimeview
from trac.web.href import Href


class TicketConversionTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        self.env.config.set('trac', 'templates_dir',
                            os.path.join(os.path.dirname(self.env.path),
                                         'templates'))
        self.ticket_module = TicketModule(self.env)
        self.mimeview = Mimeview(self.env)
        self.req = Mock(base_path='/trac.cgi', path_info='',
                        href=Href('/trac.cgi'), chrome={'logo': {}},
                        abs_href=Href('http://example.org/trac.cgi'),
                        environ={}, perm=[], authname='-', args={}, tz=None,
                        locale='', session=None, form_token=None)

    def tearDown(self):
        self.env.reset_db()

    def _create_a_ticket(self):
        # 1. Creating ticket
        ticket = Ticket(self.env)
        ticket['reporter'] = 'santa'
        ticket['summary'] = 'Foo'
        ticket['description'] = 'Bar'
        ticket['foo'] = 'This is a custom field'
        ticket.insert()
        return ticket

    def test_conversions(self):
        conversions = self.mimeview.get_supported_conversions(
            'trac.ticket.Ticket')
        expected = sorted([('csv', 'Comma-delimited Text', 'csv',
                           'trac.ticket.Ticket', 'text/csv', 8,
                           self.ticket_module),
                          ('tab', 'Tab-delimited Text', 'tsv',
                           'trac.ticket.Ticket', 'text/tab-separated-values', 8,
                           self.ticket_module),
                           ('rss', 'RSS Feed', 'xml',
                            'trac.ticket.Ticket', 'application/rss+xml', 8,
                            self.ticket_module)],
                          key=lambda i: i[-1], reverse=True)
        self.assertEqual(expected, conversions)

    def test_csv_conversion(self):
        ticket = self._create_a_ticket()
        csv = self.mimeview.convert_content(self.req, 'trac.ticket.Ticket',
                                            ticket, 'csv')
        self.assertEqual(('\xef\xbb\xbf'
                          'id,summary,reporter,owner,description,status,'
                          'keywords,cc\r\n1,Foo,santa,,Bar,,,\r\n',
                          'text/csv;charset=utf-8', 'csv'), csv)


    def test_tab_conversion(self):
        ticket = self._create_a_ticket()
        csv = self.mimeview.convert_content(self.req, 'trac.ticket.Ticket',
                                            ticket, 'tab')
        self.assertEqual(('\xef\xbb\xbf'
                          'id\tsummary\treporter\towner\tdescription\tstatus\t'
                          'keywords\tcc\r\n1\tFoo\tsanta\t\tBar\t\t\t\r\n',
                          'text/tab-separated-values;charset=utf-8', 'tsv'),
                         csv)

    def test_rss_conversion(self):
        ticket = self._create_a_ticket()
        content, mimetype, ext = self.mimeview.convert_content(
            self.req, 'trac.ticket.Ticket', ticket, 'rss')
        self.assertEqual(("""<?xml version="1.0"?>
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0">
  <channel>
    <title>My Project: Ticket #1: Foo</title>
    <link>http://example.org/trac.cgi/ticket/1</link>
    <description>&lt;p&gt;
Bar
&lt;/p&gt;
</description>
    <language>en-us</language>
    <generator>Trac %s</generator>
 </channel>
</rss>""" % (TRAC_VERSION),
                          'application/rss+xml', 'xml'),
                         (content.replace('\r', ''), mimetype, ext))


def suite():
    return unittest.makeSuite(TicketConversionTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = functional
#!/usr/bin/python
# -*- coding: utf-8 -*-
import os
import re

from datetime import datetime, timedelta

from trac.test import locale_en
from trac.tests.functional import *
from trac.util.datefmt import utc, localtz, format_date, format_datetime


class TestTickets(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Create a ticket, comment on it, and attach a file"""
        # TODO: this should be split into multiple tests
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.create_ticket()
        self._tester.add_comment(ticketid)
        self._tester.attach_file_to_ticket(ticketid)


class TestTicketPreview(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Preview ticket creation"""
        self._tester.go_to_front()
        tc.follow('New Ticket')
        summary = random_sentence(5)
        desc = random_sentence(5)
        tc.formvalue('propertyform', 'field-summary', summary)
        tc.formvalue('propertyform', 'field-description', desc)
        tc.submit('preview')
        tc.url(self._tester.url + '/newticket$')
        tc.find('ticket not yet created')
        tc.find(summary)
        tc.find(desc)


class TestTicketNoSummary(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Creating a ticket without summary should fail"""
        self._tester.go_to_front()
        tc.follow('New Ticket')
        desc = random_sentence(5)
        tc.formvalue('propertyform', 'field-description', desc)
        tc.submit('submit')
        tc.find(desc)
        tc.find('Tickets must contain a summary.')
        tc.find('Create New Ticket')
        tc.find('ticket not yet created')


class TestTicketAltFormats(FunctionalTestCaseSetup):
    def runTest(self):
        """Download ticket in alternative formats"""
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.go_to_ticket(ticketid)
        for format in ['Comma-delimited Text', 'Tab-delimited Text',
                       'RSS Feed']:
            tc.follow(format)
            content = b.get_html()
            if content.find(summary) < 0:
                raise AssertionError('Summary missing from %s format' % format)
            tc.back()


class TestTicketCSVFormat(FunctionalTestCaseSetup):
    def runTest(self):
        """Download ticket in CSV format"""
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.go_to_ticket(ticketid)
        tc.follow('Comma-delimited Text')
        csv = b.get_html()
        if not csv.startswith('\xef\xbb\xbfid,summary,'): # BOM
            raise AssertionError('Bad CSV format')


class TestTicketTabFormat(FunctionalTestCaseSetup):
    def runTest(self):
        """Download ticket in Tab-delimitted format"""
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.go_to_ticket(ticketid)
        tc.follow('Tab-delimited Text')
        tab = b.get_html()
        if not tab.startswith('\xef\xbb\xbfid\tsummary\t'): # BOM
            raise AssertionError('Bad tab delimitted format')


class TestTicketRSSFormat(FunctionalTestCaseSetup):
    def runTest(self):
        """Download ticket in RSS format"""
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.go_to_ticket(ticketid)
        # Make a number of changes to exercise all of the RSS feed code
        self._tester.go_to_ticket(ticketid)
        tc.formvalue('propertyform', 'comment', random_sentence(3))
        tc.formvalue('propertyform', 'field-type', 'task')
        tc.formvalue('propertyform', 'description', summary + '\n\n' +
                                                    random_sentence(8))
        tc.formvalue('propertyform', 'field-keywords', 'key')
        tc.submit('submit')
        time.sleep(1) # Have to wait a second
        tc.formvalue('propertyform', 'field-keywords', '')
        tc.submit('submit')

        tc.find('RSS Feed')
        tc.follow('RSS Feed')
        rss = b.get_html()
        if not rss.startswith('<?xml version="1.0"?>'):
            raise AssertionError('RSS Feed not valid feed')


class TestTicketSearch(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test ticket search"""
        summary = random_sentence(4)
        ticketid = self._tester.create_ticket(summary)
        self._tester.go_to_front()
        tc.follow('Search')
        tc.formvalue('fullsearch', 'ticket', True)
        tc.formvalue('fullsearch', 'q', summary)
        tc.submit('Search')
        tc.find('class="searchable">.*' + summary)
        tc.notfind('No matches found')


class TestNonTicketSearch(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test non-ticket search"""
        # Create a summary containing only unique words
        summary = ' '.join([random_word() + '_TestNonTicketSearch'
                            for i in range(5)])
        ticketid = self._tester.create_ticket(summary)
        self._tester.go_to_front()
        tc.follow('Search')
        tc.formvalue('fullsearch', 'ticket', False)
        tc.formvalue('fullsearch', 'q', summary)
        tc.submit('Search')
        tc.notfind('class="searchable">' + summary)
        tc.find('No matches found')


class TestTicketHistory(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test ticket history"""
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        comment = random_sentence(5)
        self._tester.add_comment(ticketid, comment=comment)
        self._tester.go_to_ticket(ticketid)
        url = b.get_url()
        tc.go(url + '?version=0')
        tc.find('at <[^>]*>*Initial Version')
        tc.find(summary)
        tc.notfind(comment)
        tc.go(url + '?version=1')
        tc.find('at <[^>]*>*Version 1')
        tc.find(summary)
        tc.find(comment)


class TestTicketHistoryDiff(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test ticket history (diff)"""
        name = 'TestTicketHistoryDiff'
        ticketid = self._tester.create_ticket(name)
        self._tester.go_to_ticket(ticketid)
        tc.formvalue('propertyform', 'description', random_sentence(6))
        tc.submit('submit')
        tc.find('Description<[^>]*>\\s*modified \\(<[^>]*>diff', 's')
        tc.follow('diff')
        tc.find('Changes\\s*between\\s*<[^>]*>Initial Version<[^>]*>\\s*and' \
                '\\s*<[^>]*>Version 1<[^>]*>\\s*of\\s*<[^>]*>Ticket #' , 's')


class TestTicketQueryLinks(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test ticket query links"""
        count = 3
        ticket_ids = [self._tester.create_ticket(
                        summary='TestTicketQueryLinks%s' % i)
                      for i in range(count)]
        self._tester.go_to_query()
        # We don't have the luxury of javascript, so this is a multi-step
        # process
        tc.formvalue('query', 'add_filter_0', 'summary')
        tc.submit('add_0')
        tc.formvalue('query', '0_owner', 'nothing')
        tc.submit('rm_filter_0_owner_0')
        tc.formvalue('query', '0_summary', 'TestTicketQueryLinks')
        tc.submit('update')
        query_url = b.get_url()
        tc.find(r'\(%d matches\)' % count)
        for i in range(count):
            tc.find('TestTicketQueryLinks%s' % i)

        tc.follow('TestTicketQueryLinks0')
        tc.find('class="missing">&larr; Previous Ticket')
        tc.find('title="Ticket #%s">Next Ticket' % ticket_ids[1])
        tc.follow('Back to Query')
        tc.url(re.escape(query_url))

        tc.follow('TestTicketQueryLinks1')
        tc.find('title="Ticket #%s">Previous Ticket' % ticket_ids[0])
        tc.find('title="Ticket #%s">Next Ticket' % ticket_ids[2])
        tc.follow('Next Ticket')

        tc.find('title="Ticket #%s">Previous Ticket' % ticket_ids[1])
        tc.find('class="missing">Next Ticket &rarr;')


class TestTicketQueryOrClause(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test ticket query with an or clauses"""
        count = 3
        ticket_ids = [self._tester.create_ticket(
                        summary='TestTicketQueryOrClause%s' % i,
                        info={'keywords': str(i)})
                      for i in range(count)]
        self._tester.go_to_query()
        tc.formvalue('query', '0_owner', '')
        tc.submit('rm_filter_0_owner_0')
        tc.formvalue('query', 'add_filter_0', 'summary')
        tc.submit('add_0')
        tc.formvalue('query', '0_summary', 'TestTicketQueryOrClause1')
        tc.formvalue('query', 'add_clause_1', 'keywords')
        tc.submit('add_1')
        tc.formvalue('query', '1_keywords', '2')
        tc.submit('update')
        tc.notfind('TestTicketQueryOrClause0')
        for i in [1, 2]:
            tc.find('TestTicketQueryOrClause%s' % i)


class TestTicketCustomFieldTextNoFormat(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test custom text field with no format explicitly specified.
        Its contents should be rendered as plain text.
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', '')
        env.config.save()

        self._testenv.restart()
        val = "%s %s" % (random_unique_camel(), random_word())
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        tc.find('<td headers="h_newfield"[^>]*>\s*%s\s*</td>' % val)


class TestTicketCustomFieldTextAreaNoFormat(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test custom textarea field with no format explicitly specified,
        its contents should be rendered as plain text.
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'textarea')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', '')
        env.config.save()

        self._testenv.restart()
        val = "%s %s" % (random_unique_camel(), random_word())
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        tc.find('<td headers="h_newfield"[^>]*>\s*%s\s*</td>' % val)


class TestTicketCustomFieldTextWikiFormat(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test custom text field with `wiki` format.
        Its contents should through the wiki engine, wiki-links and all.
        Feature added in http://trac.edgewall.org/ticket/1791
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'wiki')
        env.config.save()

        self._testenv.restart()
        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        wiki = '<a [^>]*>%s\??</a> %s' % (word1, word2)
        tc.find('<td headers="h_newfield"[^>]*>\s*%s\s*</td>' % wiki)


class TestTicketCustomFieldTextAreaWikiFormat(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test custom textarea field with no format explicitly specified,
        its contents should be rendered as plain text.
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'textarea')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'wiki')
        env.config.save()

        self._testenv.restart()
        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        wiki = '<p>\s*<a [^>]*>%s\??</a> %s<br />\s*</p>' % (word1, word2)
        tc.find('<td headers="h_newfield"[^>]*>\s*%s\s*</td>' % wiki)


class TestTicketCustomFieldTextReferenceFormat(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test custom text field with `reference` format.
        Its contents are treated as a single value
        and are rendered as an auto-query link.
        Feature added in http://trac.edgewall.org/ticket/10643
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'reference')
        env.config.save()

        self._testenv.restart()
        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        query = 'status=!closed&amp;newfield=%s\+%s' % (word1, word2)
        querylink = '<a href="/query\?%s">%s</a>' % (query, val)
        tc.find('<td headers="h_newfield"[^>]*>\s*%s\s*</td>' % querylink)


class TestTicketCustomFieldTextListFormat(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test custom text field with `list` format.
        Its contents are treated as a space-separated list of values
        and are rendered as separate auto-query links per word.
        Feature added in http://trac.edgewall.org/ticket/10643
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'list')
        env.config.save()

        self._testenv.restart()
        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        ticketid = self._tester.create_ticket(summary=random_sentence(3),
                                              info={'newfield': val})
        self._tester.go_to_ticket(ticketid)
        query1 = 'status=!closed&amp;newfield=~%s' % word1
        query2 = 'status=!closed&amp;newfield=~%s' % word2
        querylink1 = '<a href="/query\?%s">%s</a>' % (query1, word1)
        querylink2 = '<a href="/query\?%s">%s</a>' % (query2, word2)
        querylinks = '%s %s' % (querylink1, querylink2)
        tc.find('<td headers="h_newfield"[^>]*>\s*%s\s*</td>' % querylinks)


class RegressionTestTicket10828(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/10828
        Rendered property changes should be described as lists of added and
        removed items, even in the presence of comma and semicolon separators.
        """
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'A Custom Field')
        env.config.set('ticket-custom', 'newfield.format', 'list')
        env.config.save()

        self._testenv.restart()
        ticketid = self._tester.create_ticket(summary=random_sentence(3))
        self._tester.go_to_ticket(ticketid)

        word1 = random_unique_camel()
        word2 = random_word()
        val = "%s %s" % (word1, word2)
        tc.formvalue('propertyform', 'field-newfield', val)
        tc.submit('submit')
        tc.find('<em>%s</em> <em>%s</em> added' % (word1, word2))

        word3 = random_unique_camel()
        word4 = random_unique_camel()
        val = "%s,  %s; %s" % (word2, word3, word4)
        tc.formvalue('propertyform', 'field-newfield', val)
        tc.submit('submit')
        tc.find('<em>%s</em> <em>%s</em> added; <em>%s</em> removed'
                % (word3, word4, word1))

        tc.formvalue('propertyform', 'field-newfield', '')
        tc.submit('submit')
        tc.find('<em>%s</em> <em>%s</em> <em>%s</em> removed'
                % (word2, word3, word4))

        val = "%s %s,%s" % (word1, word2, word3)
        tc.formvalue('propertyform', 'field-newfield', val)
        tc.submit('submit')
        tc.find('<em>%s</em> <em>%s</em> <em>%s</em> added'
                % (word1, word2, word3))
        query1 = 'status=!closed&amp;newfield=~%s' % word1
        query2 = 'status=!closed&amp;newfield=~%s' % word2
        query3 = 'status=!closed&amp;newfield=~%s' % word3
        querylink1 = '<a href="/query\?%s">%s</a>' % (query1, word1)
        querylink2 = '<a href="/query\?%s">%s</a>' % (query2, word2)
        querylink3 = '<a href="/query\?%s">%s</a>' % (query3, word3)
        querylinks = '%s %s, %s' % (querylink1, querylink2, querylink3)
        tc.find('<td headers="h_newfield"[^>]*>\s*%s\s*</td>' % querylinks)


class TestTimelineTicketDetails(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test ticket details on timeline"""
        env = self._testenv.get_trac_environment()
        env.config.set('timeline', 'ticket_show_details', 'yes')
        env.config.save()
        summary = random_sentence(5)
        ticketid = self._tester.create_ticket(summary)
        self._tester.go_to_ticket(ticketid)
        self._tester.add_comment(ticketid)
        self._tester.go_to_timeline()
        tc.formvalue('prefs', 'ticket_details', True)
        tc.submit()
        htmltags = '(<[^>]*>)*'
        tc.find('Ticket ' + htmltags + '#' + str(ticketid) + htmltags + ' \\(' +
                summary + '\\) updated\\s+by\\s+' + htmltags + 'admin', 's')


class TestAdminComponent(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create component"""
        self._tester.create_component()


class TestAdminComponentDuplicates(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create duplicate component"""
        name = "DuplicateMilestone"
        self._tester.create_component(name)
        component_url = self._tester.url + "/admin/ticket/components"
        tc.go(component_url)
        tc.formvalue('addcomponent', 'name', name)
        tc.submit()
        tc.notfind(internal_error)
        tc.find('Component .* already exists')


class TestAdminComponentRemoval(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove component"""
        name = "RemovalComponent"
        self._tester.create_component(name)
        component_url = self._tester.url + "/admin/ticket/components"
        tc.go(component_url)
        tc.formvalue('component_table', 'sel', name)
        tc.submit('remove')
        tc.notfind(name)


class TestAdminComponentNonRemoval(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove no selected component"""
        component_url = self._tester.url + "/admin/ticket/components"
        tc.go(component_url)
        tc.submit('remove', formname='component_table')
        tc.find('No component selected')


class TestAdminComponentDefault(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin set default component"""
        name = "DefaultComponent"
        self._tester.create_component(name)
        component_url = self._tester.url + "/admin/ticket/components"
        tc.go(component_url)
        tc.formvalue('component_table', 'default', name)
        tc.submit('apply')
        tc.find('type="radio" name="default" value="%s" checked="checked"' % \
                name)
        tc.go(self._tester.url + '/newticket')
        tc.find('<option selected="selected" value="%s">%s</option>'
                % (name, name))


class TestAdminComponentDetail(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin component detail"""
        name = "DetailComponent"
        self._tester.create_component(name)
        component_url = self._tester.url + "/admin/ticket/components"
        tc.go(component_url)
        tc.follow(name)
        desc = 'Some component description'
        tc.formvalue('modcomp', 'description', desc)
        tc.submit('cancel')
        tc.url(component_url + '$')
        tc.follow(name)
        tc.notfind(desc)


class TestAdminMilestone(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create milestone"""
        self._tester.create_milestone()


class TestAdminMilestoneSpace(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create milestone with a space"""
        self._tester.create_milestone('Milestone 1')


class TestAdminMilestoneDuplicates(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create duplicate milestone"""
        name = "DuplicateMilestone"
        self._tester.create_milestone(name)
        milestone_url = self._tester.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.url(milestone_url)
        tc.formvalue('addmilestone', 'name', name)
        tc.submit()
        tc.notfind(internal_error)
        tc.find('Milestone %s already exists' % name)
        tc.notfind('%s')


class TestAdminMilestoneDetail(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin modify milestone details"""
        name = "DetailMilestone"
        # Create a milestone
        self._tester.create_milestone(name)

        # Modify the details of the milestone
        milestone_url = self._tester.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.url(milestone_url)
        tc.follow(name)
        tc.url(milestone_url + '/' + name)
        tc.formvalue('modifymilestone', 'description', 'Some description.')
        tc.submit('save')
        tc.url(milestone_url)

        # Make sure the milestone isn't closed
        self._tester.go_to_roadmap()
        tc.find(name)

        # Cancel more modifications
        tc.go(milestone_url)
        tc.url(milestone_url)
        tc.follow(name)
        tc.formvalue('modifymilestone', 'description',
                     '~~Some other description.~~')
        tc.submit('cancel')
        tc.url(milestone_url)

        # Verify the correct modifications show up
        self._tester.go_to_roadmap()
        tc.find('Some description.')
        tc.follow(name)
        tc.find('Some description.')


class TestAdminMilestoneDue(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin milestone duedate"""
        name = "DueMilestone"
        duedate = datetime.now(tz=utc)
        duedate_string = format_datetime(duedate, tzinfo=utc, locale=locale_en)
        self._tester.create_milestone(name, due=duedate_string)
        tc.find(duedate_string)


class TestAdminMilestoneDetailDue(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin modify milestone duedate on detail page"""
        name = "DetailDueMilestone"
        # Create a milestone
        self._tester.create_milestone(name)

        # Modify the details of the milestone
        milestone_url = self._tester.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.url(milestone_url)
        tc.follow(name)
        tc.url(milestone_url + '/' + name)
        duedate = datetime.now(tz=utc)
        duedate_string = format_datetime(duedate, tzinfo=utc, locale=locale_en)
        tc.formvalue('modifymilestone', 'due', duedate_string)
        tc.submit('save')
        tc.url(milestone_url + '$')
        tc.find(name + '(<[^>]*>|\\s)*'+ duedate_string, 's')


class TestAdminMilestoneCompleted(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin milestone completed"""
        name = "CompletedMilestone"
        self._tester.create_milestone(name)
        milestone_url = self._tester.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.url(milestone_url)
        tc.follow(name)
        tc.url(milestone_url + '/' + name)
        tc.formvalue('modifymilestone', 'completed', True)
        tc.submit('save')
        tc.url(milestone_url + "$")


class TestAdminMilestoneCompletedFuture(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin milestone completed in the future"""
        name = "CompletedFutureMilestone"
        self._tester.create_milestone(name)
        milestone_url = self._tester.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.url(milestone_url)
        tc.follow(name)
        tc.url(milestone_url + '/' + name)
        tc.formvalue('modifymilestone', 'completed', True)
        cdate = datetime.now(tz=utc) + timedelta(days=1)
        cdate_string = format_date(cdate, tzinfo=localtz, locale=locale_en)
        tc.formvalue('modifymilestone', 'completeddate', cdate_string)
        tc.submit('save')
        tc.find('Completion date may not be in the future')
        # And make sure it wasn't marked as completed.
        self._tester.go_to_roadmap()
        tc.find(name)


class TestAdminMilestoneRemove(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove milestone"""
        name = "MilestoneRemove"
        self._tester.create_milestone(name)
        milestone_url = self._tester.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.formvalue('milestone_table', 'sel', name)
        tc.submit('remove')
        tc.url(milestone_url + '$')
        tc.notfind(name)


class TestAdminMilestoneRemoveMulti(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove multiple milestones"""
        name = "MultiRemoveMilestone"
        count = 3
        for i in range(count):
            self._tester.create_milestone("%s%s" % (name, i))
        milestone_url = self._tester.url + '/admin/ticket/milestones'
        tc.go(milestone_url)
        tc.url(milestone_url + '$')
        for i in range(count):
            tc.find("%s%s" % (name, i))
        for i in range(count):
            tc.formvalue('milestone_table', 'sel', "%s%s" % (name, i))
        tc.submit('remove')
        tc.url(milestone_url + '$')
        for i in range(count):
            tc.notfind("%s%s" % (name, i))


class TestAdminMilestoneNonRemoval(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove no selected milestone"""
        milestone_url = self._tester.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.submit('remove', formname='milestone_table')
        tc.find('No milestone selected')


class TestAdminMilestoneDefault(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin set default milestone"""
        name = "DefaultMilestone"
        self._tester.create_milestone(name)
        milestone_url = self._tester.url + "/admin/ticket/milestones"
        tc.go(milestone_url)
        tc.formvalue('milestone_table', 'default', name)
        tc.submit('apply')
        tc.find('type="radio" name="default" value="%s" checked="checked"' % \
                name)
        # verify it is the default on the newticket page.
        tc.go(self._tester.url + '/newticket')
        tc.find('<option selected="selected" value="%s">%s</option>'
                % (name, name))


class TestAdminPriority(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create priority"""
        self._tester.create_priority()


class TestAdminPriorityDuplicates(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create duplicate priority"""
        name = "DuplicatePriority"
        self._tester.create_priority(name)
        self._tester.create_priority(name)
        tc.find('Priority %s already exists' % name)


class TestAdminPriorityModify(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin modify priority"""
        name = "ModifyPriority"
        self._tester.create_priority(name)
        priority_url = self._tester.url + '/admin/ticket/priority'
        tc.go(priority_url)
        tc.url(priority_url + '$')
        tc.find(name)
        tc.follow(name)
        tc.formvalue('modenum', 'name', name * 2)
        tc.submit('save')
        tc.url(priority_url + '$')
        tc.find(name * 2)


class TestAdminPriorityRemove(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove priority"""
        name = "RemovePriority"
        self._tester.create_priority(name)
        priority_url = self._tester.url + '/admin/ticket/priority'
        tc.go(priority_url)
        tc.url(priority_url + '$')
        tc.find(name)
        tc.formvalue('enumtable', 'sel', name)
        tc.submit('remove')
        tc.url(priority_url + '$')
        tc.notfind(name)


class TestAdminPriorityRemoveMulti(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove multiple priorities"""
        name = "MultiRemovePriority"
        count = 3
        for i in range(count):
            self._tester.create_priority("%s%s" % (name, i))
        priority_url = self._tester.url + '/admin/ticket/priority'
        tc.go(priority_url)
        tc.url(priority_url + '$')
        for i in range(count):
            tc.find("%s%s" % (name, i))
        for i in range(count):
            tc.formvalue('enumtable', 'sel', "%s%s" % (name, i))
        tc.submit('remove')
        tc.url(priority_url + '$')
        for i in range(count):
            tc.notfind("%s%s" % (name, i))


class TestAdminPriorityNonRemoval(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove no selected priority"""
        priority_url = self._tester.url + "/admin/ticket/priority"
        tc.go(priority_url)
        tc.submit('remove', formname='enumtable')
        tc.find('No priority selected')


class TestAdminPriorityDefault(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin default priority"""
        name = "DefaultPriority"
        self._tester.create_priority(name)
        priority_url = self._tester.url + '/admin/ticket/priority'
        tc.go(priority_url)
        tc.url(priority_url + '$')
        tc.find(name)
        tc.formvalue('enumtable', 'default', name)
        tc.submit('apply')
        tc.url(priority_url + '$')
        tc.find('radio.*"%s"\\schecked="checked"' % name)


class TestAdminPriorityDetail(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin modify priority details"""
        name = "DetailPriority"
        # Create a priority
        self._tester.create_priority(name + '1')

        # Modify the details of the priority
        priority_url = self._tester.url + "/admin/ticket/priority"
        tc.go(priority_url)
        tc.url(priority_url + '$')
        tc.follow(name + '1')
        tc.url(priority_url + '/' + name + '1')
        tc.formvalue('modenum', 'name', name + '2')
        tc.submit('save')
        tc.url(priority_url + '$')

        # Cancel more modifications
        tc.go(priority_url)
        tc.follow(name)
        tc.formvalue('modenum', 'name', name + '3')
        tc.submit('cancel')
        tc.url(priority_url + '$')

        # Verify that only the correct modifications show up
        tc.notfind(name + '1')
        tc.find(name + '2')
        tc.notfind(name + '3')


class TestAdminPriorityRenumber(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin renumber priorities"""
        valuesRE = re.compile('<select name="value_([0-9]+)">', re.M)
        html = b.get_html()
        max_priority = max([int(x) for x in valuesRE.findall(html)])

        name = "RenumberPriority"
        self._tester.create_priority(name + '1')
        self._tester.create_priority(name + '2')
        priority_url = self._tester.url + '/admin/ticket/priority'
        tc.go(priority_url)
        tc.url(priority_url + '$')
        tc.find(name + '1')
        tc.find(name + '2')
        tc.formvalue('enumtable', 'value_%s' % (max_priority + 1), str(max_priority + 2))
        tc.formvalue('enumtable', 'value_%s' % (max_priority + 2), str(max_priority + 1))
        tc.submit('apply')
        tc.url(priority_url + '$')
        # Verify that their order has changed.
        tc.find(name + '2.*' + name + '1', 's')

class TestAdminPriorityRenumberDup(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin badly renumber priorities"""
        # Make the first priority the 2nd priority, and leave the 2nd priority
        # as the 2nd priority.
        priority_url = self._tester.url + '/admin/ticket/priority'
        tc.go(priority_url)
        tc.url(priority_url + '$')
        tc.formvalue('enumtable', 'value_1', '2')
        tc.submit('apply')
        tc.url(priority_url + '$')
        tc.find('Order numbers must be unique')


class TestAdminResolution(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create resolution"""
        self._tester.create_resolution()


class TestAdminResolutionDuplicates(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create duplicate resolution"""
        name = "DuplicateResolution"
        self._tester.create_resolution(name)
        self._tester.create_resolution(name)
        tc.find('Resolution value "%s" already exists' % name)


class TestAdminSeverity(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create severity"""
        self._tester.create_severity()


class TestAdminSeverityDuplicates(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create duplicate severity"""
        name = "DuplicateSeverity"
        self._tester.create_severity(name)
        self._tester.create_severity(name)
        tc.find('Severity value "%s" already exists' % name)


class TestAdminType(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create type"""
        self._tester.create_type()


class TestAdminTypeDuplicates(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create duplicate type"""
        name = "DuplicateType"
        self._tester.create_type(name)
        self._tester.create_type(name)
        tc.find('Type value "%s" already exists' % name)


class TestAdminVersion(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create version"""
        self._tester.create_version()


class TestAdminVersionDuplicates(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create duplicate version"""
        name = "DuplicateVersion"
        self._tester.create_version(name)
        version_admin = self._tester.url + "/admin/ticket/versions"
        tc.go(version_admin)
        tc.url(version_admin)
        tc.formvalue('addversion', 'name', name)
        tc.submit()
        tc.notfind(internal_error)
        tc.find("Version %s already exists." % name)


class TestAdminVersionDetail(FunctionalTwillTestCaseSetup):
    # This is somewhat pointless... the only place to find the version
    # description is on the version details page.
    def runTest(self):
        """Admin version details"""
        name = "DetailVersion"
        self._tester.create_version(name)
        version_admin = self._tester.url + "/admin/ticket/versions"
        tc.go(version_admin)
        tc.url(version_admin)
        tc.follow(name)

        desc = 'Some version description.'
        tc.formvalue('modifyversion', 'description', desc)
        tc.submit('save')
        tc.url(version_admin)
        tc.follow(name)
        tc.find(desc)


class TestAdminVersionDetailTime(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin version detail set time"""
        name = "DetailTimeVersion"
        self._tester.create_version(name)
        version_admin = self._tester.url + "/admin/ticket/versions"
        tc.go(version_admin)
        tc.url(version_admin)
        tc.follow(name)

        tc.formvalue('modifyversion', 'time', '')
        tc.submit('save')
        tc.url(version_admin + '$')
        tc.find(name + '(<[^>]*>|\\s)*<[^>]* name="default" value="%s"' % name, 's')


class TestAdminVersionDetailCancel(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin version details"""
        name = "DetailVersion"
        self._tester.create_version(name)
        version_admin = self._tester.url + "/admin/ticket/versions"
        tc.go(version_admin)
        tc.url(version_admin)
        tc.follow(name)

        desc = 'Some other version description.'
        tc.formvalue('modifyversion', 'description', desc)
        tc.submit('cancel')
        tc.url(version_admin)
        tc.follow(name)
        tc.notfind(desc)


class TestAdminVersionRemove(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove version"""
        name = "VersionRemove"
        self._tester.create_version(name)
        version_url = self._tester.url + "/admin/ticket/versions"
        tc.go(version_url)
        tc.formvalue('version_table', 'sel', name)
        tc.submit('remove')
        tc.url(version_url + '$')
        tc.notfind(name)


class TestAdminVersionRemoveMulti(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove multiple versions"""
        name = "MultiRemoveVersion"
        count = 3
        for i in range(count):
            self._tester.create_version("%s%s" % (name, i))
        version_url = self._tester.url + '/admin/ticket/versions'
        tc.go(version_url)
        tc.url(version_url + '$')
        for i in range(count):
            tc.find("%s%s" % (name, i))
        for i in range(count):
            tc.formvalue('version_table', 'sel', "%s%s" % (name, i))
        tc.submit('remove')
        tc.url(version_url + '$')
        for i in range(count):
            tc.notfind("%s%s" % (name, i))


class TestAdminVersionNonRemoval(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin remove no selected version"""
        version_url = self._tester.url + "/admin/ticket/versions"
        tc.go(version_url)
        tc.submit('remove', formname='version_table')
        tc.find('No version selected')


class TestAdminVersionDefault(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin set default version"""
        name = "DefaultVersion"
        self._tester.create_version(name)
        version_url = self._tester.url + "/admin/ticket/versions"
        tc.go(version_url)
        tc.formvalue('version_table', 'default', name)
        tc.submit('apply')
        tc.find('type="radio" name="default" value="%s" checked="checked"' % \
                name)
        # verify it is the default on the newticket page.
        tc.go(self._tester.url + '/newticket')
        tc.find('<option selected="selected" value="%s">%s</option>'
                % (name, name))


class TestNewReport(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Create a new report"""
        self._tester.create_report(
            'Closed tickets, modified in the past 7 days by owner.', """
              SELECT DISTINCT p.value AS __color__,
               id AS ticket,
               summary, component, milestone, t.type AS type,
               reporter, time AS created,
               changetime AS modified, description AS _description,
               priority,
               round(julianday('now') -
                     julianday(changetime, 'unixepoch')) as days,
               resolution,
               owner as __group__
              FROM ticket t
              LEFT JOIN enum p ON p.name = t.priority AND
                                  p.type = 'priority'
              WHERE ((julianday('now') -
                      julianday(changetime, 'unixepoch')) < 7)
               AND status = 'closed'
              ORDER BY __group__, changetime, p.value
            """,
            'List of all tickets that are closed, and have been modified in'
            ' the past 7 days, grouped by owner.\n\n(So they have probably'
            ' been closed this week.)')


class TestReportRealmDecoration(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Realm/id decoration in report"""
        self._tester.create_report(
            'Realm/id decoration',
            """\
SELECT NULL AS _realm, NULL AS id, NULL AS _parent_realm, NULL AS _parent_id
UNION ALL SELECT 'ticket', '42', NULL, NULL
UNION ALL SELECT 'report', '42', NULL, NULL
UNION ALL SELECT 'milestone', '42', NULL, NULL
UNION ALL SELECT 'wiki', 'WikiStart', NULL, NULL
UNION ALL SELECT 'changeset', '42/trunk', NULL, NULL
UNION ALL SELECT 'changeset', '42/trunk', 'repository', 'repo'
UNION ALL SELECT 'changeset', '43/tags', 'repository', ''
UNION ALL SELECT 'attachment', 'file.ext', 'ticket', '42'
UNION ALL SELECT 'attachment', 'file.ext', 'milestone', '42'
UNION ALL SELECT 'attachment', 'file.ext', 'wiki', 'WikiStart'
""", '')
        tc.find('<a title="View ticket" href="[^"]*?/ticket/42">#42</a>')
        tc.find('<a title="View report" href="[^"]*?/report/42">report:42</a>')
        tc.find('<a title="View milestone" href="[^"]*?/milestone/42">42</a>')
        tc.find('<a title="View wiki" href="[^"]*?/wiki/WikiStart">'
                'WikiStart</a>')
        tc.find('<a title="View changeset" href="[^"]*?/changeset/42/trunk">'
                'Changeset 42/trunk</a>')
        tc.find('<a title="View changeset" '
                'href="[^"]*?/changeset/42/trunk/repo">'
                'Changeset 42/trunk in repo</a>')
        tc.find('<a title="View changeset" href="[^"]*?/changeset/43/tags">'
                'Changeset 43/tags</a>')
        tc.find('<a title="View attachment" '
                'href="[^"]*?/attachment/ticket/42/file[.]ext">'
                'file[.]ext [(]Ticket #42[)]</a>')
        tc.find('<a title="View attachment" '
                'href="[^"]*?/attachment/milestone/42/file[.]ext">'
                'file[.]ext [(]Milestone 42[)]</a>')
        tc.find('<a title="View attachment" '
                'href="[^"]*?/attachment/wiki/WikiStart/file[.]ext">'
                'file[.]ext [(]WikiStart[)]</a>')


class RegressionTestRev5665(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Admin create version without release time (r5665)"""
        self._tester.create_version(releasetime='')


class RegressionTestRev5994(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of the column label fix in r5994"""
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'custfield', 'text')
        env.config.set('ticket-custom', 'custfield.label', 'Custom Field')
        env.config.save()
        try:
            self._testenv.restart()
            self._tester.go_to_query()
            tc.find('<label>( |\\n)*<input[^<]*value="custfield"'
                    '[^<]*/>( |\\n)*Custom Field( |\\n)*</label>', 's')
        finally:
            pass
            #env.config.set('ticket', 'restrict_owner', 'no')
            #env.config.save()
            #self._testenv.restart()


class RegressionTestTicket4447(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/4447"""
        ticketid = self._tester.create_ticket(summary="Hello World")

        env = self._testenv.get_trac_environment()
        env.config.set('ticket-custom', 'newfield', 'text')
        env.config.set('ticket-custom', 'newfield.label',
                       'Another Custom Field')
        env.config.save()
        self._testenv.restart()
        self._tester.go_to_ticket(ticketid)
        self._tester.add_comment(ticketid)
        tc.notfind('deleted')
        tc.notfind('set to')


class RegressionTestTicket4630a(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/4630 a"""
        env = self._testenv.get_trac_environment()
        env.config.set('ticket', 'restrict_owner', 'yes')
        env.config.save()
        try:
            self._testenv.restart()
            # Make sure 'user' has logged in.
            self._tester.go_to_front()
            self._tester.logout()
            self._tester.login('user')
            self._tester.logout()
            self._tester.login('admin')
            ticket_id = self._tester.create_ticket()
            self._tester.go_to_ticket(ticket_id)
            tc.formvalue('propertyform', 'action', 'reassign')
            tc.find('reassign_reassign_owner')
            tc.formvalue('propertyform', 'action_reassign_reassign_owner', 'user')
            tc.submit('submit')
        finally:
            # Undo the config change for now since this (failing)
            # regression test causes problems for later tests.
            env.config.set('ticket', 'restrict_owner', 'no')
            env.config.save()
            self._testenv.restart()


class RegressionTestTicket4630b(FunctionalTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/4630 b"""
        # NOTE: this must be run after RegressionTestTicket4630 (user must
        # have logged in)
        from trac.perm import PermissionSystem
        env = self._testenv.get_trac_environment()
        perm = PermissionSystem(env)
        users = perm.get_users_with_permission('TRAC_ADMIN')
        self.assertEqual(users, ['admin'])
        users = perm.get_users_with_permission('TICKET_MODIFY')
        self.assertEqual(users, ['admin', 'user'])


class RegressionTestTicket5022(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5022
        """
        summary = 'RegressionTestTicket5022'
        ticket_id = self._tester.create_ticket(summary=summary)
        tc.go(self._tester.url + '/newticket?id=%s' % ticket_id)
        tc.notfind(summary)


class RegressionTestTicket5394a(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5394 a
        Order user list alphabetically in (re)assign action
        """
        # set restrict_owner config
        env = self._testenv.get_trac_environment()
        env.config.set('ticket', 'restrict_owner', 'yes')
        env.config.save()
        self._testenv.restart()

        self._tester.go_to_front()
        self._tester.logout()

        test_users = ['alice', 'bob', 'jane', 'john', 'charlie', 'alan',
                      'zorro']
        # Apprently it takes a sec for the new user to be recognized by the
        # environment.  So we add all the users, then log in as the users
        # in a second loop.  This should be faster than adding a sleep(1)
        # between the .adduser and .login steps.
        for user in test_users:
            self._testenv.adduser(user)
        for user in test_users:
            self._tester.login(user)
            self._tester.logout()

        self._tester.login('admin')

        ticketid = self._tester.create_ticket("regression test 5394a")
        self._tester.go_to_ticket(ticketid)

        options = 'id="action_reassign_reassign_owner">' + \
            ''.join(['<option[^>]*>%s</option>' % user for user in
                     sorted(test_users + ['admin', 'user'])])
        tc.find(options, 's')
        # We don't have a good way to fully delete a user from the Trac db.
        # Once we do, we may want to cleanup our list of users here.


class RegressionTestTicket5394b(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5394 b
        Order user list alphabetically on new ticket page
        """
        # Must run after RegressionTestTicket5394a
        self._tester.go_to_front()
        tc.follow('New Ticket')
        tc.find('Create New Ticket')

        test_users = ['alice', 'bob', 'jane', 'john', 'charlie', 'alan',
                      'zorro']
        options = 'id="field-owner"[^>]*>[[:space:]]*<option/>.*' + \
            '.*'.join(['<option[^>]*>%s</option>' % user for user in
                     sorted(test_users + ['admin', 'user'])])
        options = '.*'.join(sorted(test_users + ['admin', 'user']))
        tc.find(options, 's')


# TODO: this should probably be changed to be a testsuite derived from
# TestSetup
class RegressionTestTicket5497prep(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 prep
        When the component is changed, the owner should update to the
        default owner of the component.
        If component is changed and the owner is changed (reassigned action
        for open tickets in the basic workflow), the owner should be the
        specified owner, not the owner of the component.
        """
        # The default owner for the component we're using for this testcase
        # is 'user', and we'll manually assign to 'admin'.
        self._tester.create_component('regression5497', 'user')

class RegressionTestTicket5497a(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 a
        Open ticket, component changed, owner not changed"""
        ticketid = self._tester.create_ticket("regression test 5497a")
        self._tester.go_to_ticket(ticketid)
        tc.formvalue('propertyform', 'field-component', 'regression5497')
        tc.submit('submit')
        tc.find(regex_owned_by('user'))

class RegressionTestTicket5497b(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 b
        Open ticket, component changed, owner changed"""
        ticketid = self._tester.create_ticket("regression test 5497b")
        self._tester.go_to_ticket(ticketid)
        tc.formvalue('propertyform', 'field-component', 'regression5497')
        tc.formvalue('propertyform', 'action', 'reassign')
        tc.formvalue('propertyform', 'action_reassign_reassign_owner', 'admin')
        tc.submit('submit')
        tc.notfind(regex_owned_by('user'))
        tc.find(regex_owned_by('admin'))

class RegressionTestTicket5497c(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 c
        New ticket, component changed, owner not changed"""
        ticketid = self._tester.create_ticket("regression test 5497c",
            {'component':'regression5497'})
        self._tester.go_to_ticket(ticketid)
        tc.find(regex_owned_by('user'))

class RegressionTestTicket5497d(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5497 d
        New ticket, component changed, owner changed"""
        ticketid = self._tester.create_ticket("regression test 5497d",
            {'component':'regression5497', 'owner':'admin'})
        self._tester.go_to_ticket(ticketid)
        tc.find(regex_owned_by('admin'))


class RegressionTestTicket5602(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5602"""
        # Create a set of tickets, and assign them all to a milestone
        milestone = self._tester.create_milestone()
        ids = [self._tester.create_ticket() for x in range(5)]
        [self._tester.ticket_set_milestone(x, milestone) for x in ids]
        # Need a ticket in each state: new, assigned, accepted, closed,
        # reopened
        # leave ids[0] as new
        # make ids[1] be assigned
        self._tester.go_to_ticket(ids[1])
        tc.formvalue('propertyform', 'action', 'reassign')
        tc.formvalue('propertyform', 'action_reassign_reassign_owner', 'admin')
        tc.submit('submit')
        # make ids[2] be accepted
        self._tester.go_to_ticket(ids[2])
        tc.formvalue('propertyform', 'action', 'accept')
        tc.submit('submit')
        # make ids[3] be closed
        self._tester.go_to_ticket(ids[3])
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.formvalue('propertyform', 'action_resolve_resolve_resolution', 'fixed')
        tc.submit('submit')
        # make ids[4] be reopened
        self._tester.go_to_ticket(ids[4])
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.formvalue('propertyform', 'action_resolve_resolve_resolution', 'fixed')
        tc.submit('submit')
        # FIXME: we have to wait a second to avoid "IntegrityError: columns
        # ticket, time, field are not unique"
        time.sleep(1)
        tc.formvalue('propertyform', 'action', 'reopen')
        tc.submit('submit')
        tc.show()
        tc.notfind("Python Traceback")

        # Go to the milestone and follow the links to the closed and active
        # tickets.
        tc.go(self._tester.url + "/roadmap")
        tc.follow(milestone)

        tc.follow("closed:")
        tc.find("Resolution:[ \t\n]+fixed")

        tc.back()
        tc.follow("active:")
        tc.find("Status:[ \t\n]+new")
        tc.find("Status:[ \t\n]+assigned")
        tc.find("Status:[ \t\n]+accepted")
        tc.notfind("Status:[ \t\n]+closed")
        tc.find("Status:[ \t\n]+reopened")


class RegressionTestTicket5687(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5687"""
        self._tester.logout()
        self._tester.login('user')
        ticketid = self._tester.create_ticket()
        self._tester.logout()
        self._tester.login('admin')


class RegressionTestTicket5930(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5930
        TypeError: from_string() takes exactly 3 non-keyword arguments (4
        given)
        Caused by a saved query
        """
        self._tester.create_report('Saved Query', 'query:version=1.0', '')
        tc.notfind(internal_error)
        # TODO: Add a testcase for the following:
        # Can you also throw in addition of a 1.0 ticket and a 2.0 ticket
        # as part of the demo env, then see that only the correct one shows
        # up in the report?


class RegressionTestTicket6048(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6048"""
        # Setup the DeleteTicket plugin
        plugin = open(os.path.join(self._testenv.command_cwd, 'sample-plugins',
                                   'workflow', 'DeleteTicket.py')).read()
        open(os.path.join(self._testenv.tracdir, 'plugins', 'DeleteTicket.py'),
             'w').write(plugin)
        env = self._testenv.get_trac_environment()
        prevconfig = env.config.get('ticket', 'workflow')
        env.config.set('ticket', 'workflow',
                       prevconfig + ',DeleteTicketActionController')
        env.config.save()
        env = self._testenv.get_trac_environment() # reload environment

        # Create a ticket and delete it
        ticket_id = self._tester.create_ticket(
            summary='RegressionTestTicket6048')
        # (Create a second ticket so that the ticket id does not get reused
        # and confuse the tester object.)
        self._tester.create_ticket(summary='RegressionTestTicket6048b')
        self._tester.go_to_ticket(ticket_id)
        tc.find('delete ticket')
        tc.formvalue('propertyform', 'action', 'delete')
        tc.submit('submit')

        self._tester.go_to_ticket(ticket_id)
        tc.find('Error: Invalid ticket number')
        tc.find('Ticket %s does not exist.' % ticket_id)

        # Remove the DeleteTicket plugin
        env.config.set('ticket', 'workflow', prevconfig)
        env.config.save()
        env = self._testenv.get_trac_environment() # reload environment
        for ext in ('py', 'pyc', 'pyo'):
            filename = os.path.join(self._testenv.tracdir, 'plugins',
                                    'DeleteTicket.%s' % ext)
            if os.path.exists(filename):
                os.unlink(filename)


class RegressionTestTicket6747(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6747"""
        env = self._testenv.get_trac_environment()
        env.config.set('ticket-workflow', 'resolve.operations',
                       'set_resolution,set_owner')
        env.config.set('ticket-workflow', 'resolve.set_owner',
                       'a_specified_owner')
        env.config.save()

        try:
            self._testenv.restart()

            ticket_id = self._tester.create_ticket("RegressionTestTicket6747")
            self._tester.go_to_ticket(ticket_id)
            tc.find("a_specified_owner")
            tc.notfind("a_specified_owneras")

        finally:
            # Undo the config change to avoid causing problems for later
            # tests.
            env.config.set('ticket-workflow', 'resolve.operations',
                           'set_resolution')
            env.config.remove('ticket-workflow', 'resolve.set_owner')
            env.config.save()
            self._testenv.restart()


class RegressionTestTicket6879a(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6879 a

        Make sure that previewing a close does not make the available actions
        be those for the close status.
        """
        # create a ticket, then preview resolving the ticket twice
        ticket_id = self._tester.create_ticket("RegressionTestTicket6879 a")
        self._tester.go_to_ticket(ticket_id)
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.formvalue('propertyform', 'action_resolve_resolve_resolution', 'fixed')
        tc.submit('preview')
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.submit('preview')


class RegressionTestTicket6879b(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6879 a

        Make sure that previewing a close does not make the available actions
        be those for the close status.
        """
        # create a ticket, then preview resolving the ticket twice
        ticket_id = self._tester.create_ticket("RegressionTestTicket6879 b")
        self._tester.go_to_ticket(ticket_id)
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.formvalue('propertyform', 'action_resolve_resolve_resolution', 'fixed')
        tc.submit('preview')
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.submit('submit')


class RegressionTestTicket6912a(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6912 a"""
        try:
            self._tester.create_component(name='RegressionTestTicket6912a',
                                          user='')
        except twill.utils.ClientForm.ItemNotFoundError, e:
            raise twill.errors.TwillAssertionError(e)


class RegressionTestTicket6912b(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/6912 b"""
        self._tester.create_component(name='RegressionTestTicket6912b',
                                      user='admin')
        tc.follow('RegressionTestTicket6912b')
        try:
            tc.formvalue('modcomp', 'owner', '')
        except twill.utils.ClientForm.ItemNotFoundError, e:
            raise twill.errors.TwillAssertionError(e)
        tc.submit('save', formname='modcomp')
        tc.find('RegressionTestTicket6912b</a>[ \n\t]*</td>[ \n\t]*'
                '<td class="owner"></td>', 's')


class RegressionTestTicket7821group(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/7821 group"""
        env = self._testenv.get_trac_environment()
        saved_default_query = env.config.get('query', 'default_query')
        default_query = 'status!=closed&order=status&group=status&max=42' \
                        '&desc=1&groupdesc=1&col=summary|status|cc' \
                        '&cc~=$USER'
        env.config.set('query', 'default_query', default_query)
        env.config.save()
        try:
            self._testenv.restart()
            self._tester.create_ticket('RegressionTestTicket7821 group')
            self._tester.go_to_query()
            # $USER
            tc.find('<input type="text" name="0_cc" value="admin"'
                    ' size="[0-9]+" />')
            # col
            tc.find('<input type="checkbox" name="col" value="summary"'
                    ' checked="checked" />')
            tc.find('<input type="checkbox" name="col" value="owner" />')
            tc.find('<input type="checkbox" name="col" value="status"'
                    ' checked="checked" />')
            tc.find('<input type="checkbox" name="col" value="cc"'
                    ' checked="checked" />')
            # group
            tc.find('<option selected="selected" value="status">Status'
                    '</option>')
            # groupdesc
            tc.find('<input type="checkbox" name="groupdesc" id="groupdesc"'
                    ' checked="checked" />')
            # max
            tc.find('<input type="text" name="max" id="max" size="[0-9]*?"'
                    ' value="42" />')
            # col in results
            tc.find('<a title="Sort by Ticket [(]ascending[)]" ')
            tc.find('<a title="Sort by Summary [(]ascending[)]" ')
            tc.find('<a title="Sort by Status [(]ascending[)]" ')
            tc.find('<a title="Sort by Cc [(]ascending[)]" ')
            tc.notfind('<a title="Sort by Owner "')
        finally:
            env.config.set('query', 'default_query', saved_default_query)
            env.config.save()
            self._testenv.restart()


class RegressionTestTicket7821var(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/7821 var"""
        env = self._testenv.get_trac_environment()
        saved_default_query = env.config.get('query', 'default_query')
        saved_restrict_owner = env.config.get('ticket', 'restrict_owner')
        default_query = '?status=!closed&cc=~$USER&owner=$USER'
        env.config.set('query', 'default_query', default_query)
        env.config.set('ticket', 'restrict_owner', 'no')
        env.config.save()
        try:
            self._testenv.restart()
            self._tester.create_ticket('RegressionTestTicket7821 var')
            self._tester.go_to_query()
            # $USER in default_query
            tc.find('<input type="text" name="0_owner" value="admin"'
                    ' size="[0-9]+" />')
            tc.find('<input type="text" name="0_cc" value="admin"'
                    ' size="[0-9]+" />')
            # query:owner=$USER&or&cc~=$USER
            tc.go(self._tester.url + \
                  '/intertrac/query:owner=$USER&or&cc~=$USER')
            tc.find('<input type="text" name="0_owner" value="admin"'
                    ' size="[0-9]+" />')
            tc.find('<input type="text" name="1_cc" value="admin"'
                    ' size="[0-9]+" />')
        finally:
            env.config.set('query', 'default_query', saved_default_query)
            env.config.set('ticket', 'restrict_owner', saved_restrict_owner)
            env.config.save()
            self._testenv.restart()


class RegressionTestTicket8247(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/8247
        Author field of ticket comment corresponding to the milestone removal
        was always 'anonymous'."""
        name = "MilestoneRemove"
        self._tester.create_milestone(name)
        id = self._tester.create_ticket(info={'milestone': name})
        ticket_url = self._tester.url + "/ticket/%d" % id
        tc.go(ticket_url)
        tc.find(name)
        tc.go(self._tester.url + "/admin/ticket/milestones")
        tc.formvalue('milestone_table', 'sel', name)
        tc.submit('remove')
        tc.go(ticket_url)
        tc.find('<strong class="trac-field-milestone">Milestone</strong>'
                '[ \n\t]*<em>%s</em> deleted' % name)
        tc.find('Changed <a.* ago</a> by admin')
        tc.notfind('anonymous')


class RegressionTestTicket8861(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/8816
        When creating a milestone with an already existing name, you get
        a warning. After changing the name you will find that the original
        milestone with that name is renamed instead of a new one being
        created."""
        name = "8861Milestone"
        self._tester.create_milestone(name)
        tc.go(self._tester.url + "/milestone?action=new")
        tc.formvalue('edit', 'name', name)
        tc.submit('Add milestone')
        tc.find('Milestone "%s" already exists' % name)
        tc.formvalue('edit', 'name', name + '__')
        tc.submit('Add milestone')
        tc.go(self._tester.url + "/roadmap")
        tc.find('Milestone: <em>%s</em>' % name)
        tc.find('Milestone: <em>%s</em>' % (name + '__'))


class RegressionTestTicket9084(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/9084"""
        ticketid = self._tester.create_ticket()
        self._tester.add_comment(ticketid)
        self._tester.go_to_ticket(ticketid)
        tc.submit('2', formname='reply-to-comment-1') # '1' hidden, '2' submit
        tc.formvalue('propertyform', 'comment', random_sentence(3))
        tc.submit('Submit changes')
        tc.notfind('AssertionError')


class RegressionTestTicket9981(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/9981"""
        ticketid = self._tester.create_ticket()
        self._tester.add_comment(ticketid)
        tc.formvalue('propertyform', 'action', 'resolve')
        tc.submit('submit')
        comment = '[ticket:%s#comment:1]' % ticketid
        self._tester.add_comment(ticketid, comment=comment)
        self._tester.go_to_ticket(ticketid)
        tc.find('class="closed ticket".*ticket/%s#comment:1"' % ticketid)


def functionalSuite(suite=None):
    if not suite:
        import trac.tests.functional.testcases
        suite = trac.tests.functional.testcases.functionalSuite()
    suite.addTest(TestTickets())
    suite.addTest(TestTicketPreview())
    suite.addTest(TestTicketNoSummary())
    suite.addTest(TestTicketAltFormats())
    suite.addTest(TestTicketCSVFormat())
    suite.addTest(TestTicketTabFormat())
    suite.addTest(TestTicketRSSFormat())
    suite.addTest(TestTicketSearch())
    suite.addTest(TestNonTicketSearch())
    suite.addTest(TestTicketHistory())
    suite.addTest(TestTicketHistoryDiff())
    suite.addTest(TestTicketQueryLinks())
    suite.addTest(TestTicketQueryOrClause())
    suite.addTest(TestTicketCustomFieldTextNoFormat())
    suite.addTest(TestTicketCustomFieldTextWikiFormat())
    suite.addTest(TestTicketCustomFieldTextAreaNoFormat())
    suite.addTest(TestTicketCustomFieldTextAreaWikiFormat())
    suite.addTest(TestTicketCustomFieldTextReferenceFormat())
    suite.addTest(TestTicketCustomFieldTextListFormat())
    suite.addTest(RegressionTestTicket10828())
    suite.addTest(TestTimelineTicketDetails())
    suite.addTest(TestAdminComponent())
    suite.addTest(TestAdminComponentDuplicates())
    suite.addTest(TestAdminComponentRemoval())
    suite.addTest(TestAdminComponentNonRemoval())
    suite.addTest(TestAdminComponentDefault())
    suite.addTest(TestAdminComponentDetail())
    suite.addTest(TestAdminMilestone())
    suite.addTest(TestAdminMilestoneSpace())
    suite.addTest(TestAdminMilestoneDuplicates())
    suite.addTest(TestAdminMilestoneDetail())
    suite.addTest(TestAdminMilestoneDue())
    suite.addTest(TestAdminMilestoneDetailDue())
    suite.addTest(TestAdminMilestoneCompleted())
    suite.addTest(TestAdminMilestoneCompletedFuture())
    suite.addTest(TestAdminMilestoneRemove())
    suite.addTest(TestAdminMilestoneRemoveMulti())
    suite.addTest(TestAdminMilestoneNonRemoval())
    suite.addTest(TestAdminMilestoneDefault())
    suite.addTest(TestAdminPriority())
    suite.addTest(TestAdminPriorityModify())
    suite.addTest(TestAdminPriorityRemove())
    suite.addTest(TestAdminPriorityRemoveMulti())
    suite.addTest(TestAdminPriorityNonRemoval())
    suite.addTest(TestAdminPriorityDefault())
    suite.addTest(TestAdminPriorityDetail())
    suite.addTest(TestAdminPriorityRenumber())
    suite.addTest(TestAdminPriorityRenumberDup())
    suite.addTest(TestAdminResolution())
    suite.addTest(TestAdminResolutionDuplicates())
    suite.addTest(TestAdminSeverity())
    suite.addTest(TestAdminSeverityDuplicates())
    suite.addTest(TestAdminType())
    suite.addTest(TestAdminTypeDuplicates())
    suite.addTest(TestAdminVersion())
    suite.addTest(TestAdminVersionDuplicates())
    suite.addTest(TestAdminVersionDetail())
    suite.addTest(TestAdminVersionDetailTime())
    suite.addTest(TestAdminVersionDetailCancel())
    suite.addTest(TestAdminVersionRemove())
    suite.addTest(TestAdminVersionRemoveMulti())
    suite.addTest(TestAdminVersionNonRemoval())
    suite.addTest(TestAdminVersionDefault())
    suite.addTest(TestNewReport())
    suite.addTest(TestReportRealmDecoration())
    suite.addTest(RegressionTestRev5665())
    suite.addTest(RegressionTestRev5994())

    suite.addTest(RegressionTestTicket4447())
    suite.addTest(RegressionTestTicket4630a())
    suite.addTest(RegressionTestTicket4630b())
    suite.addTest(RegressionTestTicket5022())
    suite.addTest(RegressionTestTicket5394a())
    suite.addTest(RegressionTestTicket5394b())
    suite.addTest(RegressionTestTicket5497prep())
    suite.addTest(RegressionTestTicket5497a())
    suite.addTest(RegressionTestTicket5497b())
    suite.addTest(RegressionTestTicket5497c())
    suite.addTest(RegressionTestTicket5497d())
    suite.addTest(RegressionTestTicket5602())
    suite.addTest(RegressionTestTicket5687())
    suite.addTest(RegressionTestTicket5930())
    suite.addTest(RegressionTestTicket6048())
    suite.addTest(RegressionTestTicket6747())
    suite.addTest(RegressionTestTicket6879a())
    suite.addTest(RegressionTestTicket6879b())
    suite.addTest(RegressionTestTicket6912a())
    suite.addTest(RegressionTestTicket6912b())
    suite.addTest(RegressionTestTicket7821group())
    suite.addTest(RegressionTestTicket7821var())
    suite.addTest(RegressionTestTicket8247())
    suite.addTest(RegressionTestTicket8861())
    suite.addTest(RegressionTestTicket9084())
    suite.addTest(RegressionTestTicket9981())

    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = model
from __future__ import with_statement

from datetime import datetime, timedelta
import os.path
from StringIO import StringIO
import tempfile
import shutil
import unittest

from trac import core
from trac.attachment import Attachment
from trac.core import TracError, implements
from trac.resource import ResourceNotFound
from trac.ticket.model import (
    Ticket, Component, Milestone, Priority, Type, Version
)
from trac.ticket.api import (
    IMilestoneChangeListener, ITicketChangeListener, TicketSystem
)
from trac.test import EnvironmentStub
from trac.tests.resource import TestResourceChangeListener
from trac.util.datefmt import from_utimestamp, to_utimestamp, utc


class TestTicketChangeListener(core.Component):
    implements(ITicketChangeListener)

    def ticket_created(self, ticket):
        self.action = 'created'
        self.ticket = ticket
        self.resource = ticket.resource

    def ticket_changed(self, ticket, comment, author, old_values):
        self.action = 'changed'
        self.ticket = ticket
        self.comment = comment
        self.author = author
        self.old_values = old_values

    def ticket_deleted(self, ticket):
        self.action = 'deleted'
        self.ticket = ticket


class TicketTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.env.config.set('ticket-custom', 'foo', 'text')
        self.env.config.set('ticket-custom', 'cbon', 'checkbox')
        self.env.config.set('ticket-custom', 'cboff', 'checkbox')

    def tearDown(self):
        self.env.reset_db()

    def _insert_ticket(self, summary, **kw):
        """Helper for inserting a ticket into the database"""
        ticket = Ticket(self.env)
        for k, v in kw.items():
            ticket[k] = v
        return ticket.insert()

    def _create_a_ticket(self):
        # 1. Creating ticket
        ticket = Ticket(self.env)
        ticket['reporter'] = 'santa'
        ticket['summary'] = 'Foo'
        ticket['foo'] = 'This is a custom field'
        return ticket

    def test_invalid_ticket_id(self):
        self.assertEqual(Ticket.id_is_valid(-1), False)
        self.assertEqual(Ticket.id_is_valid(0), False)
        self.assertEqual(Ticket.id_is_valid(1), True)
        self.assertEqual(Ticket.id_is_valid(1L << 31), True)
        self.assertEqual(Ticket.id_is_valid(1L << 32), False)
        self.assertRaises(ResourceNotFound, Ticket, self.env, -1)
        self.assertRaises(ResourceNotFound, Ticket, self.env, 1L << 32)

    def test_create_ticket_1(self):
        ticket = self._create_a_ticket()
        self.assertEqual('santa', ticket['reporter'])
        self.assertEqual('Foo', ticket['summary'])
        self.assertEqual('This is a custom field', ticket['foo'])
        ticket.insert()

    def test_create_ticket_2(self):
        ticket = self._create_a_ticket()
        ticket.insert()
        self.assertEqual(1, ticket.id)
        # Retrieving ticket
        ticket2 = Ticket(self.env, 1)
        self.assertEqual(1, ticket2.id)
        self.assertEqual('santa', ticket2['reporter'])
        self.assertEqual('Foo', ticket2['summary'])
        self.assertEqual('This is a custom field', ticket2['foo'])

    def _modify_a_ticket(self):
        ticket2 = self._create_a_ticket()
        ticket2.insert()
        ticket2['summary'] = 'Bar'
        ticket2['foo'] = 'New value'
        ticket2.save_changes('santa', 'this is my comment')
        return ticket2

    def test_create_ticket_3(self):
        self._modify_a_ticket()
        # Retrieving ticket
        ticket3 = Ticket(self.env, 1)
        self.assertEqual(1, ticket3.id)
        self.assertEqual(ticket3['reporter'], 'santa')
        self.assertEqual(ticket3['summary'], 'Bar')
        self.assertEqual(ticket3['foo'], 'New value')

    def test_create_ticket_4(self):
        ticket3 = self._modify_a_ticket()
        # Testing get_changelog()
        log = ticket3.get_changelog()
        self.assertEqual(len(log), 3)
        ok_vals = ['foo', 'summary', 'comment']
        self.failUnless(log[0][2] in ok_vals)
        self.failUnless(log[1][2] in ok_vals)
        self.failUnless(log[2][2] in ok_vals)

    def test_create_ticket_5(self):
        ticket3 = self._modify_a_ticket()
        # Testing delete()
        ticket3.delete()
        log = ticket3.get_changelog()
        self.assertEqual(len(log), 0)
        self.assertRaises(TracError, Ticket, self.env, 1)

    def test_ticket_id_is_always_int(self):
        ticket_id = self._insert_ticket('Foo')
        self.assertEqual(ticket_id, int(ticket_id))
        ticket = Ticket(self.env, str(ticket_id))
        self.assertEqual(ticket_id, ticket.id)
        self.assertEqual(ticket.resource.id, ticket_id)

    def test_can_save_ticket_without_explicit_comment(self):
        ticket = Ticket(self.env)
        ticket.insert()

        ticket['summary'] = 'another summary'
        ticket.save_changes('foo')

        changes = ticket.get_changelog()
        comment_change = [c for c in changes if c[2] == 'comment'][0]
        self.assertEqual('1', comment_change[3])
        self.assertEqual('', comment_change[4])

    def test_can_save_ticket_without_explicit_username(self):
        ticket = Ticket(self.env)
        ticket.insert()

        ticket['summary'] = 'another summary'
        ticket.save_changes()

        for change in ticket.get_changelog():
            self.assertEqual(None, change[1])

    def test_comment_with_whitespace_only_is_not_saved(self):
        ticket = Ticket(self.env)
        ticket.insert()

        ticket.save_changes(comment='\n \n ')
        self.assertEqual(0, len(ticket.get_changelog()))

    def test_prop_whitespace_change_is_not_saved(self):
        ticket = Ticket(self.env)
        ticket.populate({'summary': 'ticket summary'})
        ticket.insert()

        ticket['summary'] = ' ticket summary '
        ticket.save_changes()
        self.assertEqual(0, len(ticket.get_changelog()))

    def test_ticket_default_values(self):
        """
        Verify that a ticket uses default values specified in the configuration
        when created.
        """
        # Set defaults for some standard fields
        self.env.config.set('ticket', 'default_type', 'defect')
        self.env.config.set('ticket', 'default_component', 'component1')

        # Add a custom field of type 'text' with a default value
        self.env.config.set('ticket-custom', 'foo', 'text')
        self.env.config.set('ticket-custom', 'foo.value', 'Something')

        # Add a custom field of type 'select' with a default value specified as
        # the value itself
        self.env.config.set('ticket-custom', 'bar', 'select')
        self.env.config.set('ticket-custom', 'bar.options', 'one|two|three')
        self.env.config.set('ticket-custom', 'bar.value', 'two')

        # Add a custom field of type 'select' with a default value specified as
        # index into the options list
        self.env.config.set('ticket-custom', 'baz', 'select')
        self.env.config.set('ticket-custom', 'baz.options', 'one|two|three')
        self.env.config.set('ticket-custom', 'baz.value', '2')

        ticket = Ticket(self.env)
        self.assertEqual('defect', ticket['type'])
        self.assertEqual('component1', ticket['component'])
        self.assertEqual('Something', ticket['foo'])
        self.assertEqual('two', ticket['bar'])
        self.assertEqual('three', ticket['baz'])

    def test_set_field_stripped(self):
        """
        Verify that whitespace around ticket fields is stripped, except for
        textarea fields.
        """
        ticket = Ticket(self.env)
        ticket['component'] = '  foo  '
        ticket['description'] = '  bar  '
        self.assertEqual('foo', ticket['component'])
        self.assertEqual('  bar  ', ticket['description'])

    def test_set_field_multi(self):
        """
        Ticket fields can't yet be multi-valued
        """
        ticket = Ticket(self.env)
        def set_multi_valued():
            ticket['component'] = ['  foo  ',  '  bar  ']
        self.assertRaises(TracError, set_multi_valued)

    def test_owner_from_component(self):
        """
        Verify that the owner of a new ticket is set to the owner of the
        component.
        """
        component = Component(self.env)
        component.name = 'test'
        component.owner = 'joe'
        component.insert()

        ticket = Ticket(self.env)
        ticket['reporter'] = 'santa'
        ticket['summary'] = 'Foo'
        ticket['component'] = 'test'
        ticket.insert()
        self.assertEqual('joe', ticket['owner'])

    def test_owner_from_changed_component(self):
        """
        Verify that the owner of a new ticket is updated when the component is
        changed.
        """
        component1 = Component(self.env)
        component1.name = 'test1'
        component1.owner = 'joe'
        component1.insert()

        component2 = Component(self.env)
        component2.name = 'test2'
        component2.owner = 'kate'
        component2.insert()

        ticket = Ticket(self.env)
        ticket['reporter'] = 'santa'
        ticket['summary'] = 'Foo'
        ticket['component'] = 'test1'
        ticket['status'] = 'new'
        tktid = ticket.insert()

        ticket = Ticket(self.env, tktid)
        ticket['component'] = 'test2'
        ticket.save_changes('jane', 'Testing')
        self.assertEqual('kate', ticket['owner'])

    def test_no_disown_from_changed_component(self):
        """
        Verify that a ticket is not disowned when the component is changed to
        a non-assigned component.
        """
        component1 = Component(self.env)
        component1.name = 'test1'
        component1.owner = 'joe'
        component1.insert()

        component2 = Component(self.env)
        component2.name = 'test2'
        component2.owner = ''
        component2.insert()

        ticket = Ticket(self.env)
        ticket['reporter'] = 'santa'
        ticket['summary'] = 'Foo'
        ticket['component'] = 'test1'
        ticket['status'] = 'new'
        tktid = ticket.insert()

        ticket = Ticket(self.env, tktid)
        ticket['component'] = 'test2'
        ticket.save_changes('jane', 'Testing')
        self.assertEqual('joe', ticket['owner'])

    def test_populate_ticket(self):
        data = {'summary': 'Hello world', 'reporter': 'john',
                'foo': 'bar', 'checkbox_cbon': '', 'cbon': 'on',
                'checkbox_cboff': ''}
        ticket = Ticket(self.env)
        ticket.populate(data)

        # Standard fields
        self.assertEqual('Hello world', ticket['summary'])
        self.assertEqual('john', ticket['reporter'])

        # An unknown field
        assert ticket['bar'] is None

        # Custom field
        self.assertEqual('bar', ticket['foo'])

        # Custom field of type 'checkbox'
        self.assertEqual('on', ticket['cbon'])
        self.assertEqual('0', ticket['cboff'])

    def test_changelog(self):
        tkt_id = self._insert_ticket('Test', reporter='joe', component='foo',
                                     milestone='bar')
        ticket = Ticket(self.env, tkt_id)
        ticket['component'] = 'bar'
        ticket['milestone'] = 'foo'
        now = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        ticket.save_changes('jane', 'Testing', now)
        changelog = sorted(ticket.get_changelog())
        self.assertEqual([(now, 'jane', 'comment', '1', 'Testing', True),
                          (now, 'jane', 'component', 'foo', 'bar', True),
                          (now, 'jane', 'milestone', 'bar', 'foo', True)],
                         changelog)

    def test_changelog_with_attachment(self):
        """Verify ordering of attachments and comments in the changelog."""
        tkt_id = self._insert_ticket('Test', reporter='joe', component='foo')
        ticket = Ticket(self.env, tkt_id)
        t1 = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        ticket.save_changes('jane', 'Testing', t1)
        t2 = datetime(2001, 1, 1, 1, 1, 2, 0, utc)
        self.env.db_transaction("""
            INSERT INTO attachment (type, id, filename, size, time,
                                    description, author, ipnr)
            VALUES ('ticket',%s,'file.txt',1234,%s, 'My file','mark','')
            """, (str(tkt_id), to_utimestamp(t2)))
        t3 = datetime(2001, 1, 1, 1, 1, 3, 0, utc)
        ticket.save_changes('jim', 'Other', t3)
        log = ticket.get_changelog()
        self.assertEqual(4, len(log))
        self.assertEqual((t1, 'jane', 'comment', '1', 'Testing', True), log[0])
        self.assertEqual([(t2, 'mark', 'attachment', '', 'file.txt', False),
                          (t2, 'mark', 'comment', '', 'My file', False)],
                          sorted(log[1:3]))
        self.assertEqual((t3, 'jim', 'comment', '2', 'Other', True), log[3])

    def test_subsecond_change(self):
        """Perform two ticket changes within a second."""
        tkt_id = self._insert_ticket('Test', reporter='joe', component='foo')
        ticket = Ticket(self.env, tkt_id)
        t1 = datetime(2001, 1, 1, 1, 1, 1, 123456, utc)
        ticket.save_changes('jane', 'Testing', t1)
        t2 = datetime(2001, 1, 1, 1, 1, 1, 123789, utc)
        ticket.save_changes('jim', 'Other', t2)
        log = ticket.get_changelog()
        self.assertEqual(2, len(log))
        self.assertEqual((t1, 'jane', 'comment', '1', 'Testing', True), log[0])
        self.assertEqual((t2, 'jim', 'comment', '2', 'Other', True), log[1])

    def test_changelog_with_reverted_change(self):
        tkt_id = self._insert_ticket('Test', reporter='joe', component='foo')
        ticket = Ticket(self.env, tkt_id)
        ticket['component'] = 'bar'
        ticket['component'] = 'foo'
        now = datetime(2001, 1, 1,  1, 1, 1, 0, utc)
        ticket.save_changes('jane', 'Testing', now)
        self.assertEqual([(now, 'jane', 'comment', '1', 'Testing', True)],
                         list(ticket.get_changelog()))

    def test_change_listener_created(self):
        listener = TestTicketChangeListener(self.env)
        ticket = self._create_a_ticket()
        ticket.insert()
        self.assertEqual('created', listener.action)
        self.assertEqual(ticket, listener.ticket)
        self.assertEqual(ticket.id, ticket.resource.id)

    def test_change_listener_changed(self):
        listener = TestTicketChangeListener(self.env)
        data = {'component': 'foo', 'milestone': 'bar'}
        tkt_id = self._insert_ticket('Hello World', reporter='john', **data)

        ticket = Ticket(self.env, tkt_id)
        ticket['component'] = 'new component'
        ticket['milestone'] = 'new milestone'

        comment = 'changing ticket'
        ticket.save_changes('author', comment)

        self.assertEqual('changed', listener.action)
        self.assertEqual(comment, listener.comment)
        self.assertEqual('author', listener.author)
        for key, value in data.iteritems():
            self.assertEqual(value, listener.old_values[key])

    def test_change_listener_deleted(self):
        listener = TestTicketChangeListener(self.env)
        ticket = self._create_a_ticket()
        ticket.insert()
        ticket.delete()
        self.assertEqual('deleted', listener.action)
        self.assertEqual(ticket, listener.ticket)


class TicketCommentTestCase(unittest.TestCase):

    def _insert_ticket(self, summary, when, **kwargs):
        ticket = Ticket(self.env)
        for k, v in kwargs.iteritems():
            ticket[k] = v
        self.id = ticket.insert(when)

    def _modify_ticket(self, author, comment, when, cnum, **kwargs):
        ticket = Ticket(self.env, self.id)
        for k, v in kwargs.iteritems():
            ticket[k] = v
        ticket.save_changes(author, comment, when, cnum=cnum)

    def _find_change(self, ticket, cnum):
        (ts, author, comment) = ticket._find_change(cnum)
        return from_utimestamp(ts)

    def assertChange(self, ticket, cnum, date, author, **fields):
        change = ticket.get_change(cnum=cnum)
        self.assertEqual(dict(date=date, author=author, fields=fields), change)


class TicketCommentEditTestCase(TicketCommentTestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.created = datetime(2001, 1, 1, 1, 0, 0, 0, utc)
        self._insert_ticket('Test ticket', self.created,
                            owner='john', keywords='a, b, c')
        self.t1 = self.created + timedelta(seconds=1)
        self._modify_ticket('jack', 'Comment 1', self.t1, '1')
        self.t2 = self.created + timedelta(seconds=2)
        self._modify_ticket('john', 'Comment 2', self.t2, '1.2',
                            owner='jack')
        self.t3 = self.created + timedelta(seconds=3)
        self._modify_ticket('jim', 'Comment 3', self.t3, '3',
                            keywords='a, b')

    def tearDown(self):
        self.env.reset_db()

    def test_modify_comment(self):
        """Check modification of a "standalone" comment"""
        ticket = Ticket(self.env, self.id)
        self.assertChange(ticket, 1, self.t1, 'jack',
            comment=dict(author='jack', old='1', new='Comment 1'))
        self.assertChange(ticket, 2, self.t2, 'john',
            owner=dict(author='john', old='john', new='jack'),
            comment=dict(author='john', old='1.2', new='Comment 2'))
        self.assertChange(ticket, 3, self.t3, 'jim',
            keywords=dict(author='jim', old='a, b, c', new='a, b'),
            comment=dict(author='jim', old='3', new='Comment 3'))

        t = self.created + timedelta(seconds=10)
        ticket.modify_comment(self._find_change(ticket, 1),
                              'joe', 'New comment 1', t)
        self.assertChange(ticket, 1, self.t1, 'jack',
            comment=dict(author='jack', old='1', new='New comment 1'),
            _comment0=dict(author='joe', old='Comment 1',
                           new=str(to_utimestamp(t))))
        self.assertEqual(t, Ticket(self.env, self.id)['changetime'])

    def test_threading(self):
        """Check modification of a "threaded" comment"""
        ticket = Ticket(self.env, self.id)
        t = self.created + timedelta(seconds=20)
        ticket.modify_comment(self._find_change(ticket, 2),
                              'joe', 'New comment 2', t)
        self.assertChange(ticket, 2, self.t2, 'john',
            owner=dict(author='john', old='john', new='jack'),
            comment=dict(author='john', old='1.2', new='New comment 2'),
            _comment0=dict(author='joe', old='Comment 2',
                           new=str(to_utimestamp(t))))

    def test_modify_missing_cnum(self):
        """Editing a comment with no cnum in oldvalue"""
        self.env.db_transaction(
            "UPDATE ticket_change SET oldvalue='' WHERE oldvalue='3'")
        ticket = Ticket(self.env, self.id)
        t = self.created + timedelta(seconds=30)
        ticket.modify_comment(self._find_change(ticket, 3),
                              'joe', 'New comment 3', t)
        self.assertChange(ticket, 3, self.t3, 'jim',
            keywords=dict(author='jim', old='a, b, c', new='a, b'),
            comment=dict(author='jim', old='', new='New comment 3'),
            _comment0=dict(author='joe', old='Comment 3',
                           new=str(to_utimestamp(t))))

    def test_modify_missing_comment(self):
        """Editing a comment where the comment field is missing"""
        self.env.db_transaction("""
            DELETE FROM ticket_change WHERE field='comment' AND oldvalue='1.2'
            """)
        ticket = Ticket(self.env, self.id)
        t = self.created + timedelta(seconds=40)
        ticket.modify_comment(self._find_change(ticket, 2),
                              'joe', 'New comment 2', t)
        self.assertChange(ticket, 2, self.t2, 'john',
            owner=dict(author='john', old='john', new='jack'),
            comment=dict(author='john', old='', new='New comment 2'),
            _comment0=dict(author='joe', old='',
                           new=str(to_utimestamp(t))))

    def test_modify_missing_cnums_and_comment(self):
        """Editing a comment when all cnums are missing and one comment
        field is missing
        """
        with self.env.db_transaction as db:
            db("UPDATE ticket_change SET oldvalue='' WHERE oldvalue='1'")
            db("""DELETE FROM ticket_change
                  WHERE field='comment' AND oldvalue='1.2'""")
            db("UPDATE ticket_change SET oldvalue='' WHERE oldvalue='3'")

        # Modify after missing comment
        ticket = Ticket(self.env, self.id)
        t = self.created + timedelta(seconds=50)
        ticket.modify_comment(self._find_change(ticket, 3),
                              'joe', 'New comment 3', t)
        self.assertChange(ticket, 3, self.t3, 'jim',
            keywords=dict(author='jim', old='a, b, c', new='a, b'),
            comment=dict(author='jim', old='', new='New comment 3'),
            _comment0=dict(author='joe', old='Comment 3',
                           new=str(to_utimestamp(t))))

        # Modify missing comment
        t = self.created + timedelta(seconds=60)
        ticket.modify_comment(self._find_change(ticket, 2),
                              'joe', 'New comment 2', t)
        self.assertChange(ticket, 2, self.t2, 'john',
            owner=dict(author='john', old='john', new='jack'),
            comment=dict(author='john', old='', new='New comment 2'),
            _comment0=dict(author='joe', old='',
                           new=str(to_utimestamp(t))))

    def test_missing_comment_edit(self):
        """Modify a comment where one edit is missing"""
        ticket = Ticket(self.env, self.id)
        t1 = self.created + timedelta(seconds=70)
        ticket.modify_comment(self._find_change(ticket, 1),
                              'joe', 'New comment 1', t1)
        t2 = self.created + timedelta(seconds=80)
        ticket.modify_comment(self._find_change(ticket, 1),
                              'joe', 'Other comment 1', t2)

        self.assertChange(ticket, 1, self.t1, 'jack',
            comment=dict(author='jack', old='1', new='Other comment 1'),
            _comment0=dict(author='joe', old='Comment 1',
                           new=str(to_utimestamp(t1))),
            _comment1=dict(author='joe', old='New comment 1',
                           new=str(to_utimestamp(t2))))

        self.env.db_transaction(
            "DELETE FROM ticket_change WHERE field='_comment0'")

        t3 = self.created + timedelta(seconds=90)
        ticket.modify_comment(self._find_change(ticket, 1),
                              'joe', 'Newest comment 1', t3)

        self.assertChange(ticket, 1, self.t1, 'jack',
            comment=dict(author='jack', old='1', new='Newest comment 1'),
            _comment1=dict(author='joe', old='New comment 1',
                           new=str(to_utimestamp(t2))),
            _comment2=dict(author='joe', old='Other comment 1',
                           new=str(to_utimestamp(t3))))

    def test_comment_history(self):
        """Check the generation of the comment history"""
        ticket = Ticket(self.env, self.id)
        t = [self.t1]
        for i in range(1, 32):
            t.append(self.created + timedelta(minutes=i))
            ticket.modify_comment(self._find_change(ticket, 1),
                                  'joe (%d)' % i,
                                  'Comment 1 (%d)' % i, t[-1])
        history = ticket.get_comment_history(cnum=1)
        self.assertEqual((0, t[0], 'jack', 'Comment 1'), history[0])
        for i in range(1, len(history)):
            self.assertEqual((i, t[i], 'joe (%d)' % i,
                             'Comment 1 (%d)' % i), history[i])
        history = ticket.get_comment_history(cdate=self.t1)
        self.assertEqual((0, t[0], 'jack', 'Comment 1'), history[0])
        for i in range(1, len(history)):
            self.assertEqual((i, t[i], 'joe (%d)' % i,
                             'Comment 1 (%d)' % i), history[i])


class TicketCommentDeleteTestCase(TicketCommentTestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.env.config.set('ticket-custom', 'foo', 'text')
        self.created = datetime(2001, 1, 1, 1, 0, 0, 0, utc)
        self._insert_ticket('Test ticket', self.created,
                            owner='john', keywords='a, b, c', foo='initial')
        self.t1 = self.created + timedelta(seconds=1)
        self._modify_ticket('jack', 'Comment 1', self.t1, '1',
                            foo='change 1')
        self.t2 = self.created + timedelta(seconds=2)
        self._modify_ticket('john', 'Comment 2', self.t2, '1.2',
                            owner='jack', foo='change2')
        self.t3 = self.created + timedelta(seconds=3)
        self._modify_ticket('jim', 'Comment 3', self.t3, '3',
                            keywords='a, b', foo='change3')
        self.t4 = self.created + timedelta(seconds=4)
        self._modify_ticket('joe', 'Comment 4', self.t4, '4',
                            keywords='a', foo='change4')

    def tearDown(self):
        self.env.reset_db()

    def test_delete_last_comment(self):
        ticket = Ticket(self.env, self.id)
        self.assertEqual('a', ticket['keywords'])
        self.assertEqual('change4', ticket['foo'])
        t = datetime.now(utc)
        ticket.delete_change(cnum=4, when=t)
        self.assertEqual('a, b', ticket['keywords'])
        self.assertEqual('change3', ticket['foo'])
        self.assertEqual(None, ticket.get_change(cnum=4))
        self.assertNotEqual(None, ticket.get_change(cnum=3))
        self.assertEqual(t, ticket.time_changed)

    def test_delete_last_comment_when_custom_field_gone(self):
        """Regression test for http://trac.edgewall.org/ticket/10858"""
        ticket = Ticket(self.env, self.id)
        self.assertEqual('a', ticket['keywords'])
        self.assertEqual('change4', ticket['foo'])
        # we simulate the removal of the definition of the 'foo' custom field
        self.env.config.remove('ticket-custom', 'foo')
        del TicketSystem(self.env).fields
        del TicketSystem(self.env).custom_fields
        ticket = Ticket(self.env, self.id)
        #
        t = datetime.now(utc)
        ticket.delete_change(cnum=4, when=t)
        self.assertEqual('a, b', ticket['keywords'])
        # 'foo' is no longer defined for the ticket
        self.assertEqual(None, ticket['foo'])
        # however, 'foo=change3' is still in the database
        self.assertEqual([('change3',)], self.env.db_query("""
            SELECT value FROM ticket_custom WHERE ticket=%s AND name='foo'
            """, (self.id,)))
        self.assertEqual(None, ticket.get_change(cnum=4))
        self.assertNotEqual(None, ticket.get_change(cnum=3))
        self.assertEqual(t, ticket.time_changed)

    def test_delete_last_comment_by_date(self):
        ticket = Ticket(self.env, self.id)
        self.assertEqual('a', ticket['keywords'])
        self.assertEqual('change4', ticket['foo'])
        t = datetime.now(utc)
        ticket.delete_change(cdate=self.t4, when=t)
        self.assertEqual('a, b', ticket['keywords'])
        self.assertEqual('change3', ticket['foo'])
        self.assertEqual(None, ticket.get_change(cdate=self.t4))
        self.assertNotEqual(None, ticket.get_change(cdate=self.t3))
        self.assertEqual(t, ticket.time_changed)

    def test_delete_mid_comment(self):
        ticket = Ticket(self.env, self.id)
        self.assertChange(ticket, 4, self.t4, 'joe',
            comment=dict(author='joe', old='4', new='Comment 4'),
            keywords=dict(author='joe', old='a, b', new='a'),
            foo=dict(author='joe', old='change3', new='change4'))
        t = datetime.now(utc)
        ticket.delete_change(cnum=3, when=t)
        self.assertEqual(None, ticket.get_change(cnum=3))
        self.assertEqual('a', ticket['keywords'])
        self.assertChange(ticket, 4, self.t4, 'joe',
            comment=dict(author='joe', old='4', new='Comment 4'),
            keywords=dict(author='joe', old='a, b, c', new='a'),
            foo=dict(author='joe', old='change2', new='change4'))
        self.assertEqual(t, ticket.time_changed)

    def test_delete_mid_comment_by_date(self):
        ticket = Ticket(self.env, self.id)
        self.assertChange(ticket, 4, self.t4, 'joe',
            comment=dict(author='joe', old='4', new='Comment 4'),
            keywords=dict(author='joe', old='a, b', new='a'),
            foo=dict(author='joe', old='change3', new='change4'))
        t = datetime.now(utc)
        ticket.delete_change(cdate=self.t3, when=t)
        self.assertEqual(None, ticket.get_change(cdate=self.t3))
        self.assertEqual('a', ticket['keywords'])
        self.assertChange(ticket, 4, self.t4, 'joe',
            comment=dict(author='joe', old='4', new='Comment 4'),
            keywords=dict(author='joe', old='a, b, c', new='a'),
            foo=dict(author='joe', old='change2', new='change4'))
        self.assertEqual(t, ticket.time_changed)

    def test_delete_mid_comment_inconsistent(self):
        # Make oldvalue on keywords for change 4 inconsistent. This should
        # result in no change in oldvalue when deleting change 3. The
        # oldvalue of foo should change normally.
        self.env.db_transaction("""
            UPDATE ticket_change SET oldvalue='1, 2'
            WHERE field='keywords' AND oldvalue='a, b'
            """)
        ticket = Ticket(self.env, self.id)
        self.assertChange(ticket, 4, self.t4, 'joe',
            comment=dict(author='joe', old='4', new='Comment 4'),
            keywords=dict(author='joe', old='1, 2', new='a'),
            foo=dict(author='joe', old='change3', new='change4'))
        ticket.delete_change(3)
        self.assertEqual(None, ticket.get_change(3))
        self.assertEqual('a', ticket['keywords'])
        self.assertChange(ticket, 4, self.t4, 'joe',
            comment=dict(author='joe', old='4', new='Comment 4'),
            keywords=dict(author='joe', old='1, 2', new='a'),
            foo=dict(author='joe', old='change2', new='change4'))

    def test_delete_all_comments(self):
        ticket = Ticket(self.env, self.id)
        ticket.delete_change(4)
        ticket.delete_change(3)
        ticket.delete_change(2)
        t = datetime.now(utc)
        ticket.delete_change(1, when=t)
        self.assertEqual(t, ticket.time_changed)


class EnumTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)

    def tearDown(self):
        self.env.reset_db()

    def test_priority_fetch(self):
        prio = Priority(self.env, 'major')
        self.assertEqual(prio.name, 'major')
        self.assertEqual(prio.value, '3')

    def test_priority_insert(self):
        prio = Priority(self.env)
        prio.name = 'foo'
        prio.insert()
        self.assertEqual(True, prio.exists)

    def test_priority_insert_with_value(self):
        prio = Priority(self.env)
        prio.name = 'bar'
        prio.value = 100
        prio.insert()
        self.assertEqual(True, prio.exists)

    def test_priority_update(self):
        prio = Priority(self.env, 'major')
        prio.name = 'foo'
        prio.update()
        Priority(self.env, 'foo')
        self.assertRaises(TracError, Priority, self.env, 'major')

    def test_priority_delete(self):
        prio = Priority(self.env, 'major')
        self.assertEqual('3', prio.value)
        prio.delete()
        self.assertEqual(False, prio.exists)
        self.assertRaises(TracError, Priority, self.env, 'major')
        prio = Priority(self.env, 'minor')
        self.assertEqual('3', prio.value)

    def test_ticket_type_update(self):
        tkttype = Type(self.env, 'task')
        self.assertEqual(tkttype.name, 'task')
        self.assertEqual(tkttype.value, '3')
        tkttype.name = 'foo'
        tkttype.update()
        Type(self.env, 'foo')


class TestMilestoneChangeListener(core.Component):
    implements(IMilestoneChangeListener)

    def milestone_created(self, milestone):
        self.action = 'created'
        self.milestone = milestone

    def milestone_changed(self, milestone, old_values):
        self.action = 'changed'
        self.milestone = milestone
        self.old_values = old_values

    def milestone_deleted(self, milestone):
        self.action = 'deleted'
        self.milestone = milestone


class MilestoneTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.env.path = os.path.join(tempfile.gettempdir(), 'trac-tempenv')
        os.mkdir(self.env.path)

    def tearDown(self):
        shutil.rmtree(self.env.path)
        self.env.reset_db()

    def _create_milestone(self, **values):
        milestone = Milestone(self.env)
        for k, v in values.iteritems():
            setattr(milestone, k, v)
        return milestone

    def test_new_milestone(self):
        milestone = Milestone(self.env)
        self.assertEqual(False, milestone.exists)
        self.assertEqual(None, milestone.name)
        self.assertEqual(None, milestone.due)
        self.assertEqual(None, milestone.completed)
        self.assertEqual('', milestone.description)

    def test_new_milestone_empty_name(self):
        """
        Verifies that specifying an empty milestone name results in the
        milestone being correctly detected as non-existent.
        """
        milestone = Milestone(self.env, '')
        self.assertEqual(False, milestone.exists)
        self.assertEqual(None, milestone.name)
        self.assertEqual(None, milestone.due)
        self.assertEqual(None, milestone.completed)
        self.assertEqual('', milestone.description)

    def test_existing_milestone(self):
        self.env.db_transaction("INSERT INTO milestone (name) VALUES ('Test')")

        milestone = Milestone(self.env, 'Test')
        self.assertEqual(True, milestone.exists)
        self.assertEqual('Test', milestone.name)
        self.assertEqual(None, milestone.due)
        self.assertEqual(None, milestone.completed)
        self.assertEqual('', milestone.description)

    def test_create_and_update_milestone(self):
        milestone = Milestone(self.env)
        milestone.name = 'Test'
        milestone.insert()

        self.assertEqual([('Test', 0, 0, '')], self.env.db_query("""
            SELECT name, due, completed, description FROM milestone
            WHERE name='Test'
            """))

        # Use the same model object to update the milestone
        milestone.description = 'Some text'
        milestone.update()
        self.assertEqual([('Test', 0, 0, 'Some text')], self.env.db_query("""
            SELECT name, due, completed, description FROM milestone
            WHERE name='Test'
            """))

    def test_create_milestone_without_name(self):
        milestone = Milestone(self.env)
        self.assertRaises(TracError, milestone.insert)

    def test_delete_milestone(self):
        self.env.db_transaction("INSERT INTO milestone (name) VALUES ('Test')")

        milestone = Milestone(self.env, 'Test')
        milestone.delete()
        self.assertEqual(False, milestone.exists)
        self.assertEqual([],
            self.env.db_query("SELECT * FROM milestone WHERE name='Test'"))

    def test_delete_milestone_retarget_tickets(self):
        self.env.db_transaction("INSERT INTO milestone (name) VALUES ('Test')")

        tkt1 = Ticket(self.env)
        tkt1.populate({'summary': 'Foo', 'milestone': 'Test'})
        tkt1.insert()
        tkt2 = Ticket(self.env)
        tkt2.populate({'summary': 'Bar', 'milestone': 'Test'})
        tkt2.insert()

        milestone = Milestone(self.env, 'Test')
        milestone.delete(retarget_to='Other')
        self.assertEqual(False, milestone.exists)

        self.assertEqual('Other', Ticket(self.env, tkt1.id)['milestone'])
        self.assertEqual('Other', Ticket(self.env, tkt2.id)['milestone'])

    def test_update_milestone(self):
        self.env.db_transaction("INSERT INTO milestone (name) VALUES ('Test')")

        milestone = Milestone(self.env, 'Test')
        t1 = datetime(2001, 01, 01, tzinfo=utc)
        t2 = datetime(2002, 02, 02, tzinfo=utc)
        milestone.due = t1
        milestone.completed = t2
        milestone.description = 'Foo bar'
        milestone.update()

        self.assertEqual(
            [('Test', to_utimestamp(t1), to_utimestamp(t2), 'Foo bar')],
            self.env.db_query("SELECT * FROM milestone WHERE name='Test'"))

    def test_update_milestone_without_name(self):
        self.env.db_transaction("INSERT INTO milestone (name) VALUES ('Test')")

        milestone = Milestone(self.env, 'Test')
        milestone.name = None
        self.assertRaises(TracError, milestone.update)

    def test_update_milestone_update_tickets(self):
        self.env.db_transaction("INSERT INTO milestone (name) VALUES ('Test')")

        tkt1 = Ticket(self.env)
        tkt1.populate({'summary': 'Foo', 'milestone': 'Test'})
        tkt1.insert()
        tkt2 = Ticket(self.env)
        tkt2.populate({'summary': 'Bar', 'milestone': 'Test'})
        tkt2.insert()

        milestone = Milestone(self.env, 'Test')
        milestone.name = 'Testing'
        milestone.update()

        self.assertEqual('Testing', Ticket(self.env, tkt1.id)['milestone'])
        self.assertEqual('Testing', Ticket(self.env, tkt2.id)['milestone'])

    def test_rename_milestone(self):
        milestone = Milestone(self.env)
        milestone.name = 'OldName'
        milestone.insert()

        attachment = Attachment(self.env, 'milestone', 'OldName')
        attachment.insert('foo.txt', StringIO(), 0, 1)

        milestone = Milestone(self.env, 'OldName')
        milestone.name = 'NewName'
        milestone.update()

        self.assertRaises(ResourceNotFound, Milestone, self.env, 'OldName')
        self.assertEqual('NewName', Milestone(self.env, 'NewName').name)

        attachments = Attachment.select(self.env, 'milestone', 'OldName')
        self.assertRaises(StopIteration, attachments.next)
        attachments = Attachment.select(self.env, 'milestone', 'NewName')
        self.assertEqual('foo.txt', attachments.next().filename)
        self.assertRaises(StopIteration, attachments.next)

    def test_select_milestones(self):
        self.env.db_transaction.executemany(
            "INSERT INTO milestone (name) VALUES (%s)",
            [('1.0',), ('2.0',)])

        milestones = list(Milestone.select(self.env))
        self.assertEqual('1.0', milestones[0].name)
        assert milestones[0].exists
        self.assertEqual('2.0', milestones[1].name)
        assert milestones[1].exists

    def test_change_listener_created(self):
        listener = TestMilestoneChangeListener(self.env)
        milestone = self._create_milestone(name='Milestone 1')
        milestone.insert()
        self.assertEqual('created', listener.action)
        self.assertEqual(milestone, listener.milestone)

    def test_change_listener_changed(self):
        listener = TestMilestoneChangeListener(self.env)
        milestone = self._create_milestone(
            name='Milestone 1',
            due=datetime(2001, 01, 01, tzinfo=utc),
            description='The milestone description')
        milestone.insert()

        milestone.name = 'Milestone 2'
        milestone.completed = datetime(2001, 02, 03, tzinfo=utc)
        milestone.description = 'The changed description'
        milestone.update()

        self.assertEqual('changed', listener.action)
        self.assertEqual(milestone, listener.milestone)
        self.assertEqual({'name': 'Milestone 1', 'completed': None,
                          'description': 'The milestone description'},
                         listener.old_values)

    def test_change_listener_deleted(self):
        listener = TestMilestoneChangeListener(self.env)
        milestone = self._create_milestone(name='Milestone 1')
        milestone.insert()
        self.assertEqual(True, milestone.exists)
        milestone.delete()
        self.assertEqual('Milestone 1', milestone.name)
        self.assertEqual(False, milestone.exists)
        self.assertEqual('deleted', listener.action)
        self.assertEqual(milestone, listener.milestone)


class ComponentTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)

    def tearDown(self):
        self.env.reset_db()

    def test_exists_negative(self):
        def get_fake_component():
            return Component(self.env, "Shrubbery")
        self.assertRaises(TracError, get_fake_component)

    def test_exists(self):
        """
        http://trac.edgewall.org/ticket/4247
        """
        for c in Component.select(self.env):
            self.assertEqual(c.exists, True)

    def test_create_and_update(self):
        component = Component(self.env)
        component.name = 'Test'
        component.insert()

        self.assertEqual([('Test', None, None)], self.env.db_query("""
            SELECT name, owner, description FROM component
            WHERE name='Test'"""))

        # Use the same model object to update the component
        component.owner = 'joe'
        component.update()
        self.assertEqual([('Test', 'joe', None)], self.env.db_query(
            "SELECT name, owner, description FROM component WHERE name='Test'"))

class VersionTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)

    def tearDown(self):
        self.env.reset_db()

    def test_exists_negative(self):
        def get_fake_version():
            return Version(self.env, "-1")
        self.assertRaises(TracError, get_fake_version)

    def test_exists(self):
        """
        http://trac.edgewall.org/ticket/4247
        """
        for v in Version.select(self.env):
            self.assertEqual(v.exists, True)

    def test_create_and_update(self):
        version = Version(self.env)
        version.name = 'Test'
        version.insert()

        self.assertEqual([('Test', 0, None)], self.env.db_query(
            "SELECT name, time, description FROM version WHERE name='Test'"))

        # Use the same model object to update the version
        version.description = 'Some text'
        version.update()
        self.assertEqual([('Test', 0, 'Some text')], self.env.db_query(
            "SELECT name, time, description FROM version WHERE name='Test'"))

class BaseResourceChangeListenerTestCase(unittest.TestCase):
    DUMMY_RESOURCE_NAME = "Resource 1"
    resource_type = None
    name_field = "name"

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.listener = TestResourceChangeListener(self.env)
        self.listener.resource_type = self.resource_type
        self.listener.callback = self.listener_callback

    def tearDown(self):
        self.env.reset_db()

    def test_change_listener_created(self):
        self._create_resource(self.DUMMY_RESOURCE_NAME)
        self.assertEqual('created', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, self.resource_type))
        self.assertEqual(
            self.DUMMY_RESOURCE_NAME,
            self.resource_name)

    def test_change_listener_changed(self):
        resource = self._create_resource(self.DUMMY_RESOURCE_NAME)
        self._rename_resource(resource, "UpdatedName")
        self.assertEqual('changed', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, self.resource_type))
        self.assertEqual("UpdatedName", self.resource_name)
        self.assertEqual(
            self.DUMMY_RESOURCE_NAME,
            self.listener.old_values[self.name_field])

    def test_change_listener_deleted(self):
        resource = self._create_resource(self.DUMMY_RESOURCE_NAME)
        resource.delete()
        self.assertEqual('deleted', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, self.resource_type))
        self.assertEqual(self.DUMMY_RESOURCE_NAME, self.resource_name)

    def _create_resource(self, name):
        resource = self.resource_type(self.env)
        resource.name = name
        resource.insert()
        return resource

    def _rename_resource(self, resource, new_name):
        resource.name = new_name
        resource.update()
        return resource

    def _get_resource_name(self, resource):
        return resource.name

    def listener_callback(self, action, resource, context, old_values = None):
        self.resource_name = self._get_resource_name(resource)

class ComponentResourceChangeListenerTestCase(
    BaseResourceChangeListenerTestCase):
    resource_type = Component

class VersionResourceChangeListenerTestCase(
    BaseResourceChangeListenerTestCase):
    resource_type = Version

class PriorityResourceChangeListenerTestCase(
    BaseResourceChangeListenerTestCase):
    resource_type = Priority

class MilestoneResourceChangeListenerTestCase(
    BaseResourceChangeListenerTestCase):
    resource_type = Milestone

class TicketResourceChangeListenerTestCase(
    BaseResourceChangeListenerTestCase):
    resource_type = Ticket
    name_field = "summary"
    dummy_author = "anAuthor"
    dummy_comment = "some comment"

    def test_change_listener_changed(self):
        super(
            TicketResourceChangeListenerTestCase,
            self).test_change_listener_changed()

        self.assertEqual(self.dummy_author, self.listener.context["author"])
        self.assertEqual(self.dummy_comment, self.listener.context["comment"])


    def _create_resource(self, name):
        ticket = Ticket(self.env)
        ticket["summary"] = name
        ticket.insert()
        return ticket

    def _rename_resource(self, resource, new_name):
        resource["summary"] = new_name
        resource.save_changes(self.dummy_author, self.dummy_comment)
        return resource

    def _get_resource_name(self, resource):
        return resource["summary"]

def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(TicketTestCase, 'test'))
    suite.addTest(unittest.makeSuite(TicketCommentEditTestCase, 'test'))
    suite.addTest(unittest.makeSuite(TicketCommentDeleteTestCase, 'test'))
    suite.addTest(unittest.makeSuite(EnumTestCase, 'test'))
    suite.addTest(unittest.makeSuite(MilestoneTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ComponentTestCase, 'test'))
    suite.addTest(unittest.makeSuite(VersionTestCase, 'test'))
    suite.addTest(unittest.makeSuite(
        ComponentResourceChangeListenerTestCase, 'test'))
    suite.addTest(unittest.makeSuite(
        VersionResourceChangeListenerTestCase, 'test'))
    suite.addTest(unittest.makeSuite(
        PriorityResourceChangeListenerTestCase, 'test'))
    suite.addTest(unittest.makeSuite(
        MilestoneResourceChangeListenerTestCase, 'test'))
    suite.addTest(unittest.makeSuite(
        TicketResourceChangeListenerTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = notification
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2006 Emmanuel Blot <emmanuel.blot@free.fr>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Include a basic SMTP server, based on L. Smithson
# (lsmithson@open-networks.co.uk) extensible Python SMTP Server
#

from trac.util.datefmt import utc
from trac.ticket.model import Ticket
from trac.ticket.notification import TicketNotifyEmail
from trac.test import EnvironmentStub, Mock, MockPerm
from trac.tests.notification import SMTPThreadedServer, parse_smtp_message, \
                                    smtp_address

import base64
from datetime import datetime
import os
import quopri
import re
import unittest

SMTP_TEST_PORT = 7000 + os.getpid() % 1000
MAXBODYWIDTH = 76
notifysuite = None


class NotificationTestCase(unittest.TestCase):
    """Notification test cases that send email over SMTP"""

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.env.config.set('project', 'name', 'TracTest')
        self.env.config.set('notification', 'smtp_enabled', 'true')
        self.env.config.set('notification', 'always_notify_owner', 'true')
        self.env.config.set('notification', 'always_notify_reporter', 'true')
        self.env.config.set('notification', 'smtp_always_cc',
                            'joe.user@example.net, joe.bar@example.net')
        self.env.config.set('notification', 'use_public_cc', 'true')
        self.env.config.set('notification', 'smtp_port', str(SMTP_TEST_PORT))
        self.env.config.set('notification', 'smtp_server','localhost')
        self.req = Mock(href=self.env.href, abs_href=self.env.abs_href, tz=utc,
                        perm=MockPerm())

    def tearDown(self):
        """Signal the notification test suite that a test is over"""
        notifysuite.tear_down()
        self.env.reset_db()

    def test_recipients(self):
        """To/Cc recipients"""
        ticket = Ticket(self.env)
        ticket['reporter'] = '"Joe User" < joe.user@example.org >'
        ticket['owner']    = 'joe.user@example.net'
        ticket['cc']       = 'joe.user@example.com, joe.bar@example.org, ' \
                             'joe.bar@example.net'
        ticket['summary'] = 'Foo'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        recipients = notifysuite.smtpd.get_recipients()
        # checks there is no duplicate in the recipient list
        rcpts = []
        for r in recipients:
            self.failIf(r in rcpts)
            rcpts.append(r)
        # checks that all cc recipients have been notified
        cc_list = self.env.config.get('notification', 'smtp_always_cc')
        cc_list = "%s, %s" % (cc_list, ticket['cc'])
        for r in cc_list.replace(',', ' ').split():
            self.failIf(r not in recipients)
        # checks that owner has been notified
        self.failIf(smtp_address(ticket['owner']) not in recipients)
        # checks that reporter has been notified
        self.failIf(smtp_address(ticket['reporter']) not in recipients)

    def test_no_recipient(self):
        """No recipient case"""
        self.env.config.set('notification', 'smtp_always_cc', '')
        ticket = Ticket(self.env)
        ticket['reporter'] = 'anonymous'
        ticket['summary'] = 'Foo'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        sender = notifysuite.smtpd.get_sender()
        recipients = notifysuite.smtpd.get_recipients()
        message = notifysuite.smtpd.get_message()
        # checks that no message has been sent
        self.failIf(recipients)
        self.failIf(sender)
        self.failIf(message)

    def test_cc_only(self):
        """Notification w/o explicit recipients but Cc: (#3101)"""
        ticket = Ticket(self.env)
        ticket['summary'] = 'Foo'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        recipients = notifysuite.smtpd.get_recipients()
        # checks that all cc recipients have been notified
        cc_list = self.env.config.get('notification', 'smtp_always_cc')
        for r in cc_list.replace(',', ' ').split():
            self.failIf(r not in recipients)

    def test_structure(self):
        """Basic SMTP message structure (headers, body)"""
        ticket = Ticket(self.env)
        ticket['reporter'] = '"Joe User" <joe.user@example.org>'
        ticket['owner']    = 'joe.user@example.net'
        ticket['cc']       = 'joe.user@example.com, joe.bar@example.org, ' \
                             'joe.bar@example.net'
        ticket['summary'] = 'This is a summary'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        # checks for header existence
        self.failIf(not headers)
        # checks for body existance
        self.failIf(not body)
        # checks for expected headers
        self.failIf('Date' not in headers)
        self.failIf('Subject' not in headers)
        self.failIf('Message-ID' not in headers)
        self.failIf('From' not in headers)

    def test_date(self):
        """Date format compliance (RFC822)
           we do not support 'military' format"""
        date_str = r"^((?P<day>\w{3}),\s*)*(?P<dm>\d{2})\s+" \
                   r"(?P<month>\w{3})\s+(?P<year>\d{4})\s+" \
                   r"(?P<hour>\d{2}):(?P<min>[0-5][0-9])" \
                   r"(:(?P<sec>[0-5][0-9]))*\s" \
                   r"((?P<tz>\w{2,3})|(?P<offset>[+\-]\d{4}))$"
        date_re = re.compile(date_str)
        # python time module does not detect incorrect time values
        days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
        months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \
                  'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
        tz = ['UT', 'GMT', 'EST', 'EDT', 'CST', 'CDT', 'MST', 'MDT',
              'PST', 'PDT']
        ticket = Ticket(self.env)
        ticket['reporter'] = '"Joe User" <joe.user@example.org>'
        ticket['summary'] = 'This is a summary'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.failIf('Date' not in headers)
        mo = date_re.match(headers['Date'])
        self.failIf(not mo)
        if mo.group('day'):
            self.failIf(mo.group('day') not in days)
        self.failIf(int(mo.group('dm')) not in range(1, 32))
        self.failIf(mo.group('month') not in months)
        self.failIf(int(mo.group('hour')) not in range(0, 24))
        if mo.group('tz'):
            self.failIf(mo.group('tz') not in tz)

    def test_bcc_privacy(self):
        """Visibility of recipients"""
        def run_bcc_feature(public):
            # CC list should be private
            self.env.config.set('notification', 'use_public_cc',
                                'true' if public else 'false')
            self.env.config.set('notification', 'smtp_always_bcc',
                                'joe.foobar@example.net')
            ticket = Ticket(self.env)
            ticket['reporter'] = '"Joe User" <joe.user@example.org>'
            ticket['summary'] = 'This is a summary'
            ticket.insert()
            tn = TicketNotifyEmail(self.env)
            tn.notify(ticket, newticket=True)
            message = notifysuite.smtpd.get_message()
            (headers, body) = parse_smtp_message(message)
            if public:
                # Msg should have a To list
                self.failIf('To' not in headers)
                # Extract the list of 'To' recipients from the message
                to = [rcpt.strip() for rcpt in headers['To'].split(',')]
            else:
                # Msg should not have a To list
                self.failIf('To' in headers)
                # Extract the list of 'To' recipients from the message
                to = []
            # Extract the list of 'Cc' recipients from the message
            cc = [rcpt.strip() for rcpt in headers['Cc'].split(',')]
            # Extract the list of the actual SMTP recipients
            rcptlist = notifysuite.smtpd.get_recipients()
            # Build the list of the expected 'Cc' recipients
            ccrcpt = self.env.config.get('notification', 'smtp_always_cc')
            cclist = [ccr.strip() for ccr in ccrcpt.split(',')]
            for rcpt in cclist:
                # Each recipient of the 'Cc' list should appear
                # in the 'Cc' header
                self.failIf(rcpt not in cc)
                # Check the message has actually been sent to the recipients
                self.failIf(rcpt not in rcptlist)
            # Build the list of the expected 'Bcc' recipients
            bccrcpt = self.env.config.get('notification', 'smtp_always_bcc')
            bcclist = [bccr.strip() for bccr in bccrcpt.split(',')]
            for rcpt in bcclist:
                # Check none of the 'Bcc' recipients appears
                # in the 'To' header
                self.failIf(rcpt in to)
                # Check the message has actually been sent to the recipients
                self.failIf(rcpt not in rcptlist)
        run_bcc_feature(True)
        run_bcc_feature(False)

    def test_short_login(self):
        """Email addresses without a FQDN"""
        def _test_short_login(enabled):
            ticket = Ticket(self.env)
            ticket['reporter'] = 'joeuser'
            ticket['summary'] = 'This is a summary'
            ticket.insert()
            # Be sure that at least one email address is valid, so that we
            # send a notification even if other addresses are not valid
            self.env.config.set('notification', 'smtp_always_cc',
                                'joe.bar@example.net')
            if enabled:
                self.env.config.set('notification', 'use_short_addr', 'true')
            tn = TicketNotifyEmail(self.env)
            tn.notify(ticket, newticket=True)
            message = notifysuite.smtpd.get_message()
            (headers, body) = parse_smtp_message(message)
            # Msg should not have a 'To' header
            if not enabled:
                self.failIf('To' in headers)
            else:
                tolist = [addr.strip() for addr in headers['To'].split(',')]
            # Msg should have a 'Cc' field
            self.failIf('Cc' not in headers)
            cclist = [addr.strip() for addr in headers['Cc'].split(',')]
            if enabled:
                # Msg should be delivered to the reporter
                self.failIf(ticket['reporter'] not in tolist)
            else:
                # Msg should not be delivered to joeuser
                self.failIf(ticket['reporter'] in cclist)
            # Msg should still be delivered to the always_cc list
            self.failIf(self.env.config.get('notification',
                        'smtp_always_cc') not in cclist)
        # Validate with and without the short addr option enabled
        for enable in [False, True]:
            _test_short_login(enable)

    def test_default_domain(self):
        """Default domain name"""
        def _test_default_domain(enabled):
            self.env.config.set('notification', 'always_notify_owner',
                                'false')
            self.env.config.set('notification', 'always_notify_reporter',
                                'false')
            self.env.config.set('notification', 'smtp_always_cc', '')
            ticket = Ticket(self.env)
            ticket['cc'] = 'joenodom, joewithdom@example.com'
            ticket['summary'] = 'This is a summary'
            ticket.insert()
            # Be sure that at least one email address is valid, so that we
            # send a notification even if other addresses are not valid
            self.env.config.set('notification', 'smtp_always_cc',
                                'joe.bar@example.net')
            if enabled:
                self.env.config.set('notification', 'smtp_default_domain',
                                    'example.org')
            tn = TicketNotifyEmail(self.env)
            tn.notify(ticket, newticket=True)
            message = notifysuite.smtpd.get_message()
            (headers, body) = parse_smtp_message(message)
            # Msg should always have a 'Cc' field
            self.failIf('Cc' not in headers)
            cclist = [addr.strip() for addr in headers['Cc'].split(',')]
            self.failIf('joewithdom@example.com' not in cclist)
            self.failIf('joe.bar@example.net' not in cclist)
            if not enabled:
                self.failIf(len(cclist) != 2)
                self.failIf('joenodom' in cclist)
            else:
                self.failIf(len(cclist) != 3)
                self.failIf('joenodom@example.org' not in cclist)

        # Validate with and without a default domain
        for enable in [False, True]:
            _test_default_domain(enable)

    def test_email_map(self):
        """Login-to-email mapping"""
        self.env.config.set('notification', 'always_notify_owner', 'true')
        self.env.config.set('notification', 'always_notify_reporter', 'true')
        self.env.config.set('notification', 'smtp_always_cc',
                            'joe@example.com')
        self.env.known_users = [('joeuser', 'Joe User',
                                 'user-joe@example.com'),
                                ('jim@domain', 'Jim User',
                                 'user-jim@example.com')]
        ticket = Ticket(self.env)
        ticket['reporter'] = 'joeuser'
        ticket['owner'] = 'jim@domain'
        ticket['summary'] = 'This is a summary'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        # Msg should always have a 'To' field
        self.failIf('To' not in headers)
        tolist = [addr.strip() for addr in headers['To'].split(',')]
        # 'To' list should have been resolved to the real email address
        self.failIf('user-joe@example.com' not in tolist)
        self.failIf('user-jim@example.com' not in tolist)
        self.failIf('joeuser' in tolist)
        self.failIf('jim@domain' in tolist)

    def test_from_author(self):
        """Using the reporter or change author as the notification sender"""
        self.env.config.set('notification', 'smtp_from', 'trac@example.com')
        self.env.config.set('notification', 'smtp_from_name', 'My Trac')
        self.env.config.set('notification', 'smtp_from_author', 'true')
        self.env.known_users = [('joeuser', 'Joe User',
                                 'user-joe@example.com'),
                                ('jim@domain', 'Jim User',
                                 'user-jim@example.com'),
                                ('noemail', 'No e-mail', ''),
                                ('noname', '', 'user-noname@example.com')]
        # Ticket creation uses the reporter
        ticket = Ticket(self.env)
        ticket['reporter'] = 'joeuser'
        ticket['summary'] = 'This is a summary'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.assertEqual('"Joe User" <user-joe@example.com>', headers['From'])
        # Ticket change uses the change author
        ticket['summary'] = 'Modified summary'
        ticket.save_changes('jim@domain', 'Made some changes')
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=False, modtime=ticket['changetime'])
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.assertEqual('"Jim User" <user-jim@example.com>', headers['From'])
        # Known author without name uses e-mail address only
        ticket['summary'] = 'Final summary'
        ticket.save_changes('noname', 'Final changes')
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=False, modtime=ticket['changetime'])
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.assertEqual('user-noname@example.com', headers['From'])
        # Known author without e-mail uses smtp_from and smtp_from_name
        ticket['summary'] = 'Other summary'
        ticket.save_changes('noemail', 'More changes')
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=False, modtime=ticket['changetime'])
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.assertEqual('"My Trac" <trac@example.com>', headers['From'])
        # Unknown author with name and e-mail address
        ticket['summary'] = 'Some summary'
        ticket.save_changes('Test User <test@example.com>', 'Some changes')
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=False, modtime=ticket['changetime'])
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.assertEqual('"Test User" <test@example.com>', headers['From'])
        # Unknown author with e-mail address only
        ticket['summary'] = 'Some summary'
        ticket.save_changes('test@example.com', 'Some changes')
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=False, modtime=ticket['changetime'])
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.assertEqual('test@example.com', headers['From'])
        # Unknown author uses smtp_from and smtp_from_name
        ticket['summary'] = 'Better summary'
        ticket.save_changes('unknown', 'Made more changes')
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=False, modtime=ticket['changetime'])
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.assertEqual('"My Trac" <trac@example.com>', headers['From'])

    def test_ignore_domains(self):
        """Non-SMTP domain exclusion"""
        self.env.config.set('notification', 'ignore_domains',
                            'example.com, example.org')
        self.env.known_users = \
            [('kerberos@example.com', 'No Email', ''),
             ('kerberos@example.org', 'With Email', 'kerb@example.net')]
        ticket = Ticket(self.env)
        ticket['reporter'] = 'kerberos@example.com'
        ticket['owner'] = 'kerberos@example.org'
        ticket['summary'] = 'This is a summary'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        # Msg should always have a 'To' field
        self.failIf('To' not in headers)
        tolist = [addr.strip() for addr in headers['To'].split(',')]
        # 'To' list should not contain addresses with non-SMTP domains
        self.failIf('kerberos@example.com' in tolist)
        self.failIf('kerberos@example.org' in tolist)
        # 'To' list should have been resolved to the actual email address
        self.failIf('kerb@example.net' not in tolist)
        self.failIf(len(tolist) != 1)

    def test_admit_domains(self):
        """SMTP domain inclusion"""
        self.env.config.set('notification', 'admit_domains',
                            'localdomain, server')
        ticket = Ticket(self.env)
        ticket['reporter'] = 'joeuser@example.com'
        ticket['summary'] = 'This is a summary'
        ticket['cc'] = 'joe.user@localdomain, joe.user@unknown, ' \
                       'joe.user@server'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        # Msg should always have a 'To' field
        self.failIf('Cc' not in headers)
        cclist = [addr.strip() for addr in headers['Cc'].split(',')]
        # 'Cc' list should contain addresses with SMTP included domains
        self.failIf('joe.user@localdomain' not in cclist)
        self.failIf('joe.user@server' not in cclist)
        # 'Cc' list should not contain non-FQDN domains
        self.failIf('joe.user@unknown' in cclist)
        self.failIf(len(cclist) != 2+2)

    def test_multiline_header(self):
        """Encoded headers split into multiple lines"""
        self.env.config.set('notification', 'mime_encoding', 'qp')
        ticket = Ticket(self.env)
        ticket['reporter'] = 'joe.user@example.org'
        # Forces non-ascii characters
        ticket['summary'] = u'A_very %s smmry' % u' '.join(['long'] * 20)
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        # Discards the project name & ticket number
        subject = headers['Subject']
        summary = subject[subject.find(':')+2:]
        self.failIf(ticket['summary'] != summary)

    def test_mimebody_b64(self):
        """MIME Base64/utf-8 encoding"""
        self.env.config.set('notification', 'mime_encoding', 'base64')
        ticket = Ticket(self.env)
        ticket['reporter'] = 'joe.user@example.org'
        ticket['summary'] = u'This is a long enough summary to cause Trac ' \
                            u'to generate a multi-line (2 lines) smmry'
        ticket.insert()
        self._validate_mimebody((base64, 'base64', 'utf-8'), \
                                ticket, True)

    def test_mimebody_qp(self):
        """MIME QP/utf-8 encoding"""
        self.env.config.set('notification', 'mime_encoding', 'qp')
        ticket = Ticket(self.env)
        ticket['reporter'] = 'joe.user@example.org'
        ticket['summary'] = u'This is a long enough summary to cause Trac ' \
                            u'to generate a multi-line (2 lines) smmry'
        ticket.insert()
        self._validate_mimebody((quopri, 'quoted-printable', 'utf-8'),
                                ticket, True)

    def test_mimebody_none_7bit(self):
        """MIME None encoding resulting in 7bit"""
        self.env.config.set('notification', 'mime_encoding', 'none')
        ticket = Ticket(self.env)
        ticket['reporter'] = 'joe.user'
        ticket['summary'] = u'This is a summary'
        ticket.insert()
        self._validate_mimebody((None, '7bit', 'utf-8'), \
                                ticket, True)

    def test_mimebody_none_8bit(self):
        """MIME None encoding resulting in 8bit"""
        self.env.config.set('notification', 'mime_encoding', 'none')
        ticket = Ticket(self.env)
        ticket['reporter'] = 'joe.user'
        ticket['summary'] = u'This is a summary for Je Usr'
        ticket.insert()
        self._validate_mimebody((None, '8bit', 'utf-8'), \
                                ticket, True)

    def test_md5_digest(self):
        """MD5 digest w/ non-ASCII recipient address (#3491)"""
        self.env.config.set('notification', 'always_notify_owner', 'false')
        self.env.config.set('notification', 'always_notify_reporter', 'true')
        self.env.config.set('notification', 'smtp_always_cc', '')
        ticket = Ticket(self.env)
        ticket['reporter'] = u'"Je Usr" <joe.user@example.org>'
        ticket['summary'] = u'This is a summary'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)

    def test_updater(self):
        """No-self-notification option"""
        def _test_updater(disable):
            if disable:
                self.env.config.set('notification', 'always_notify_updater',
                                    'false')
            ticket = Ticket(self.env)
            ticket['reporter'] = 'joe.user@example.org'
            ticket['summary'] = u'This is a smmry'
            ticket['cc'] = 'joe.bar@example.com'
            ticket.insert()
            ticket['component'] = 'dummy'
            now = datetime.now(utc)
            ticket.save_changes('joe.bar2@example.com', 'This is a change',
                                when=now)
            tn = TicketNotifyEmail(self.env)
            tn.notify(ticket, newticket=False, modtime=now)
            message = notifysuite.smtpd.get_message()
            (headers, body) = parse_smtp_message(message)
            # checks for header existence
            self.failIf(not headers)
            # checks for updater in the 'To' recipient list
            self.failIf('To' not in headers)
            tolist = [addr.strip() for addr in headers['To'].split(',')]
            if disable:
                self.failIf('joe.bar2@example.com' in tolist)
            else:
                self.failIf('joe.bar2@example.com' not in tolist)

        # Validate with and without a default domain
        for disable in [False, True]:
            _test_updater(disable)

    def test_updater_only(self):
        """Notification w/ updater, w/o any other recipient (#4188)"""
        self.env.config.set('notification', 'always_notify_owner', 'false')
        self.env.config.set('notification', 'always_notify_reporter', 'false')
        self.env.config.set('notification', 'always_notify_updater', 'true')
        self.env.config.set('notification', 'smtp_always_cc', '')
        self.env.config.set('notification', 'smtp_always_bcc', '')
        self.env.config.set('notification', 'use_public_cc', 'false')
        self.env.config.set('notification', 'use_short_addr', 'false')
        self.env.config.set('notification', 'smtp_replyto',
                            'joeuser@example.net')
        ticket = Ticket(self.env)
        ticket['summary'] = 'Foo'
        ticket.insert()
        ticket['summary'] = 'Bar'
        ticket['component'] = 'New value'
        ticket.save_changes('joe@example.com', 'this is my comment')
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        recipients = notifysuite.smtpd.get_recipients()
        self.failIf(recipients is None)
        self.failIf(len(recipients) != 1)
        self.failIf(recipients[0] != 'joe@example.com')

    def test_updater_is_reporter(self):
        """Notification to reporter w/ updater option disabled (#3780)"""
        self.env.config.set('notification', 'always_notify_owner', 'false')
        self.env.config.set('notification', 'always_notify_reporter', 'true')
        self.env.config.set('notification', 'always_notify_updater', 'false')
        self.env.config.set('notification', 'smtp_always_cc', '')
        self.env.config.set('notification', 'smtp_always_bcc', '')
        self.env.config.set('notification', 'use_public_cc', 'false')
        self.env.config.set('notification', 'use_short_addr', 'false')
        self.env.config.set('notification', 'smtp_replyto',
                            'joeuser@example.net')
        ticket = Ticket(self.env)
        ticket['summary'] = 'Foo'
        ticket['reporter'] = u'joe@example.org'
        ticket.insert()
        ticket['summary'] = 'Bar'
        ticket['component'] = 'New value'
        ticket.save_changes('joe@example.org', 'this is my comment')
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        recipients = notifysuite.smtpd.get_recipients()
        self.failIf(recipients is None)
        self.failIf(len(recipients) != 1)
        self.failIf(recipients[0] != 'joe@example.org')

    def _validate_mimebody(self, mime, ticket, newtk):
        """Body of a ticket notification message"""
        (mime_decoder, mime_name, mime_charset) = mime
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=newtk)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        self.failIf('MIME-Version' not in headers)
        self.failIf('Content-Type' not in headers)
        self.failIf('Content-Transfer-Encoding' not in headers)
        self.failIf(not re.compile(r"1.\d").match(headers['MIME-Version']))
        type_re = re.compile(r'^text/plain;\scharset="([\w\-\d]+)"$')
        charset = type_re.match(headers['Content-Type'])
        self.failIf(not charset)
        charset = charset.group(1)
        self.assertEqual(charset, mime_charset)
        self.assertEqual(headers['Content-Transfer-Encoding'], mime_name)
        # checks the width of each body line
        for line in body.splitlines():
            self.failIf(len(line) > MAXBODYWIDTH)
        # attempts to decode the body, following the specified MIME endoding
        # and charset
        try:
            if mime_decoder:
                body = mime_decoder.decodestring(body)
            body = unicode(body, charset)
        except Exception, e:
            raise AssertionError, e
        # now processes each line of the body
        bodylines = body.splitlines()
        # body starts with one of more summary lines, first line is prefixed
        # with the ticket number such as #<n>: summary
        # finds the banner after the summary
        banner_delim_re = re.compile(r'^\-+\+\-+$')
        bodyheader = []
        while ( not banner_delim_re.match(bodylines[0]) ):
            bodyheader.append(bodylines.pop(0))
        # summary should be present
        self.failIf(not bodyheader)
        # banner should not be empty
        self.failIf(not bodylines)
        # extracts the ticket ID from the first line
        (tknum, bodyheader[0]) = bodyheader[0].split(' ', 1)
        self.assertEqual(tknum[0], '#')
        try:
            tkid = int(tknum[1:-1])
            self.assertEqual(tkid, 1)
        except ValueError:
            raise AssertionError, "invalid ticket number"
        self.assertEqual(tknum[-1], ':')
        summary = ' '.join(bodyheader)
        self.assertEqual(summary, ticket['summary'])
        # now checks the banner contents
        self.failIf(not banner_delim_re.match(bodylines[0]))
        banner = True
        footer = None
        props = {}
        for line in bodylines[1:]:
            # detect end of banner
            if banner_delim_re.match(line):
                banner = False
                continue
            if banner:
                # parse banner and fill in a property dict
                properties = line.split('|')
                self.assertEqual(len(properties), 2)
                for prop in properties:
                    if prop.strip() == '':
                        continue
                    (k, v) = prop.split(':')
                    props[k.strip().lower()] = v.strip()
            # detect footer marker (weak detection)
            if not footer:
                if line.strip() == '--':
                    footer = 0
                    continue
            # check footer
            if footer != None:
                footer += 1
                # invalid footer detection
                self.failIf(footer > 3)
                # check ticket link
                if line[:11] == 'Ticket URL:':
                    ticket_link = self.env.abs_href.ticket(ticket.id)
                    self.assertEqual(line[12:].strip(), "<%s>" % ticket_link)
                # note project title / URL are not validated yet

        # ticket properties which are not expected in the banner
        xlist = ['summary', 'description', 'comment', 'time', 'changetime']
        # check banner content (field exists, msg value matches ticket value)
        for p in [prop for prop in ticket.values.keys() if prop not in xlist]:
            self.failIf(not props.has_key(p))
            # Email addresses might be obfuscated
            if '@' in ticket[p] and '@' in props[p]:
                self.failIf(props[p].split('@')[0] != ticket[p].split('@')[0])
            else:
                self.failIf(props[p] != ticket[p])

    def test_props_format_ambiwidth_single(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        self.env.config.set('notification', 'ambiguous_char_width', '')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'nonymos'
        ticket['status'] = u'new'
        ticket['owner'] = u'sombody'
        ticket['type'] = u'(dfct)'
        ticket['priority'] = u'(mjor)'
        ticket['milestone'] = u'1'
        ticket['component'] = u'1'
        ticket['version'] = u'2.0 lph'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  nonymos        |      Owner:  sombody
      Type:  (dfct)     |     Status:  new
  Priority:  (mjor)  |  Milestone:  1
 Component:  1  |    Version:  2.0 lph
Resolution:  fixed            |   Keywords:"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_ambiwidth_double(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        self.env.config.set('notification', 'ambiguous_char_width', 'double')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'nonymos'
        ticket['status'] = u'new'
        ticket['owner'] = u'sombody'
        ticket['type'] = u'(dfct)'
        ticket['priority'] = u'(mjor)'
        ticket['milestone'] = u'1'
        ticket['component'] = u'1'
        ticket['version'] = u'2.0 lph'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  nonymos       |      Owner:  sombody
      Type:  (dfct)    |     Status:  new
  Priority:  (mjor)  |  Milestone:  1
 Component:  1   |    Version:  2.0 lph
Resolution:  fixed             |   Keywords:"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_obfuscated_email(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'joe@foobar.foo.bar.example.org'
        ticket['status'] = u'new'
        ticket['owner'] = u'joe.bar@foobar.foo.bar.example.org'
        ticket['type'] = u'defect'
        ticket['priority'] = u'major'
        ticket['milestone'] = u'milestone1'
        ticket['component'] = u'component1'
        ticket['version'] = u'2.0'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  joe@       |      Owner:  joe.bar@
      Type:  defect      |     Status:  new
  Priority:  major       |  Milestone:  milestone1
 Component:  component1  |    Version:  2.0
Resolution:  fixed       |   Keywords:"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_obfuscated_email_disabled(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        self.env.config.set('trac', 'show_email_addresses', 'true')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'joe@foobar.foo.bar.example.org'
        ticket['status'] = u'new'
        ticket['owner'] = u'joe.bar@foobar.foo.bar.example.org'
        ticket['type'] = u'defect'
        ticket['priority'] = u'major'
        ticket['milestone'] = u'milestone1'
        ticket['component'] = u'component1'
        ticket['version'] = u'2.0'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:                          |      Owner:
  joe@foobar.foo.bar.example.org     |  joe.bar@foobar.foo.bar.example.org
      Type:  defect                  |     Status:  new
  Priority:  major                   |  Milestone:  milestone1
 Component:  component1              |    Version:  2.0
Resolution:  fixed                   |   Keywords:"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_wrap_leftside(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'anonymous'
        ticket['status'] = u'new'
        ticket['owner'] = u'somebody'
        ticket['type'] = u'defect'
        ticket['priority'] = u'major'
        ticket['milestone'] = u'milestone1'
        ticket['component'] = u'Lorem ipsum dolor sit amet, consectetur ' \
                              u'adipisicing elit, sed do eiusmod tempor ' \
                              u'incididunt ut labore et dolore magna ' \
                              u'aliqua. Ut enim ad minim veniam, quis ' \
                              u'nostrud exercitation ullamco laboris nisi ' \
                              u'ut aliquip ex ea commodo consequat. Duis ' \
                              u'aute irure dolor in reprehenderit in ' \
                              u'voluptate velit esse cillum dolore eu ' \
                              u'fugiat nulla pariatur. Excepteur sint ' \
                              u'occaecat cupidatat non proident, sunt in ' \
                              u'culpa qui officia deserunt mollit anim id ' \
                              u'est laborum.'
        ticket['version'] = u'2.0'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  anonymous                           |      Owner:  somebody
      Type:  defect                              |     Status:  new
  Priority:  major                               |  Milestone:  milestone1
 Component:  Lorem ipsum dolor sit amet,         |    Version:  2.0
  consectetur adipisicing elit, sed do eiusmod   |   Keywords:
  tempor incididunt ut labore et dolore magna    |
  aliqua. Ut enim ad minim veniam, quis nostrud  |
  exercitation ullamco laboris nisi ut aliquip   |
  ex ea commodo consequat. Duis aute irure       |
  dolor in reprehenderit in voluptate velit      |
  esse cillum dolore eu fugiat nulla pariatur.   |
  Excepteur sint occaecat cupidatat non          |
  proident, sunt in culpa qui officia deserunt   |
  mollit anim id est laborum.                    |
Resolution:  fixed                               |"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_wrap_leftside_unicode(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'anonymous'
        ticket['status'] = u'new'
        ticket['owner'] = u'somebody'
        ticket['type'] = u'defect'
        ticket['priority'] = u'major'
        ticket['milestone'] = u'milestone1'
        ticket['component'] = u'Trac  BSD ' \
                              u'[1:]' \
                              u'' \
                              u' [3:COPYING] ' \
                              u'[2:]' \
                              u''
        ticket['version'] = u'2.0'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  anonymous                           |      Owner:  somebody
      Type:  defect                              |     Status:  new
  Priority:  major                               |  Milestone:  milestone1
 Component:  Trac  BSD   |    Version:  2.0
  [1:]   |   Keywords:
   [3:COPYING]   |
  [2:]     |
Resolution:  fixed                               |"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_wrap_rightside(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'anonymous'
        ticket['status'] = u'new'
        ticket['owner'] = u'somebody'
        ticket['type'] = u'defect'
        ticket['priority'] = u'major'
        ticket['milestone'] = u'Lorem ipsum dolor sit amet, consectetur ' \
                              u'adipisicing elit, sed do eiusmod tempor ' \
                              u'incididunt ut labore et dolore magna ' \
                              u'aliqua. Ut enim ad minim veniam, quis ' \
                              u'nostrud exercitation ullamco laboris nisi ' \
                              u'ut aliquip ex ea commodo consequat. Duis ' \
                              u'aute irure dolor in reprehenderit in ' \
                              u'voluptate velit esse cillum dolore eu ' \
                              u'fugiat nulla pariatur. Excepteur sint ' \
                              u'occaecat cupidatat non proident, sunt in ' \
                              u'culpa qui officia deserunt mollit anim id ' \
                              u'est laborum.'
        ticket['component'] = u'component1'
        ticket['version'] = u'2.0'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  anonymous   |      Owner:  somebody
      Type:  defect      |     Status:  new
  Priority:  major       |  Milestone:  Lorem ipsum dolor sit amet,
 Component:  component1  |  consectetur adipisicing elit, sed do eiusmod
Resolution:  fixed       |  tempor incididunt ut labore et dolore magna
                         |  aliqua. Ut enim ad minim veniam, quis nostrud
                         |  exercitation ullamco laboris nisi ut aliquip ex
                         |  ea commodo consequat. Duis aute irure dolor in
                         |  reprehenderit in voluptate velit esse cillum
                         |  dolore eu fugiat nulla pariatur. Excepteur sint
                         |  occaecat cupidatat non proident, sunt in culpa
                         |  qui officia deserunt mollit anim id est
                         |  laborum.
                         |    Version:  2.0
                         |   Keywords:"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_wrap_rightside_unicode(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'anonymous'
        ticket['status'] = u'new'
        ticket['owner'] = u'somebody'
        ticket['type'] = u'defect'
        ticket['priority'] = u'major'
        ticket['milestone'] = u'Trac BSD' \
                              u'[1:][2:' \
                              u'] [3:COPYING] ' \
                              u''
        ticket['component'] = u'component1'
        ticket['version'] = u'2.0'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  anonymous   |      Owner:  somebody
      Type:  defect      |     Status:  new
  Priority:  major       |  Milestone:  Trac BSD
 Component:  component1  |  [1:][2:]
Resolution:  fixed       |   [3:COPYING] 
                         |    Version:  2.0
                         |   Keywords:"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_wrap_bothsides(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'anonymous'
        ticket['status'] = u'new'
        ticket['owner'] = u'somebody'
        ticket['type'] = u'defect'
        ticket['priority'] = u'major'
        ticket['milestone'] = u'Lorem ipsum dolor sit amet, consectetur ' \
                              u'adipisicing elit, sed do eiusmod tempor ' \
                              u'incididunt ut labore et dolore magna ' \
                              u'aliqua. Ut enim ad minim veniam, quis ' \
                              u'nostrud exercitation ullamco laboris nisi ' \
                              u'ut aliquip ex ea commodo consequat. Duis ' \
                              u'aute irure dolor in reprehenderit in ' \
                              u'voluptate velit esse cillum dolore eu ' \
                              u'fugiat nulla pariatur. Excepteur sint ' \
                              u'occaecat cupidatat non proident, sunt in ' \
                              u'culpa qui officia deserunt mollit anim id ' \
                              u'est laborum.'
        ticket['component'] = ticket['milestone']
        ticket['version'] = u'2.0'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  anonymous               |      Owner:  somebody
      Type:  defect                  |     Status:  new
  Priority:  major                   |  Milestone:  Lorem ipsum dolor sit
 Component:  Lorem ipsum dolor sit   |  amet, consectetur adipisicing elit,
  amet, consectetur adipisicing      |  sed do eiusmod tempor incididunt ut
  elit, sed do eiusmod tempor        |  labore et dolore magna aliqua. Ut
  incididunt ut labore et dolore     |  enim ad minim veniam, quis nostrud
  magna aliqua. Ut enim ad minim     |  exercitation ullamco laboris nisi
  veniam, quis nostrud exercitation  |  ut aliquip ex ea commodo consequat.
  ullamco laboris nisi ut aliquip    |  Duis aute irure dolor in
  ex ea commodo consequat. Duis      |  reprehenderit in voluptate velit
  aute irure dolor in reprehenderit  |  esse cillum dolore eu fugiat nulla
  in voluptate velit esse cillum     |  pariatur. Excepteur sint occaecat
  dolore eu fugiat nulla pariatur.   |  cupidatat non proident, sunt in
  Excepteur sint occaecat cupidatat  |  culpa qui officia deserunt mollit
  non proident, sunt in culpa qui    |  anim id est laborum.
  officia deserunt mollit anim id    |    Version:  2.0
  est laborum.                       |   Keywords:
Resolution:  fixed                   |"""
        self._validate_props_format(formatted, ticket)

    def test_props_format_wrap_bothsides_unicode(self):
        self.env.config.set('notification', 'mime_encoding', 'none')
        self.env.config.set('notification', 'ambiguous_char_width', 'double')
        ticket = Ticket(self.env)
        ticket['summary'] = u'This is a summary'
        ticket['reporter'] = u'anonymous'
        ticket['status'] = u'new'
        ticket['owner'] = u'somebody'
        ticket['type'] = u'defect'
        ticket['priority'] = u'major'
        ticket['milestone'] = u'Trac BSD' \
                              u'[1:][2:' \
                              u'] [3:COPYING] ' \
                              u''
        ticket['component'] = u'Trac  BSD ' \
                              u'[1:]' \
                              u'' \
                              u'[3:CPYING]' \
                              u'[2:]' \
                              u''
        ticket['version'] = u'2.0'
        ticket['resolution'] = u'fixed'
        ticket['keywords'] = u''
        ticket.insert()
        formatted = """\
  Reporter:  anonymous               |      Owner:  somebody
      Type:  defect                  |     Status:  new
  Priority:  major                   |  Milestone:  Trac BSD
 Component:  Trac  BSD   |  [1:][2:
  [1:]   |  ] [3:COPYING]
     |  
  [3:CPYING]   |    Version:  2.0
  [2:]   |   Keywords:
                     |
Resolution:  fixed                   |"""
        self._validate_props_format(formatted, ticket)

    def _validate_props_format(self, expected, ticket):
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        message = notifysuite.smtpd.get_message()
        (headers, body) = parse_smtp_message(message)
        bodylines = body.splitlines()
        # Extract ticket properties
        delim_re = re.compile(r'^\-+\+\-+$')
        while not delim_re.match(bodylines[0]):
            bodylines.pop(0)
        lines = []
        for line in bodylines[1:]:
            if delim_re.match(line):
                break
            lines.append(line)
        self.assertEqual(expected, '\n'.join(lines))

    def test_notification_does_not_alter_ticket_instance(self):
        ticket = Ticket(self.env)
        ticket['summary'] = 'My Summary'
        ticket['description'] = 'Some description'
        ticket.insert()
        tn = TicketNotifyEmail(self.env)
        tn.notify(ticket, newticket=True)
        self.assertNotEqual(None, notifysuite.smtpd.get_message())
        self.assertEqual('My Summary', ticket['summary'])
        self.assertEqual('Some description', ticket['description'])
        valid_fieldnames = set([f['name'] for f in ticket.fields])
        current_fieldnames = set(ticket.values.keys())
        self.assertEqual(set(), current_fieldnames - valid_fieldnames)

    def test_notification_get_message_id_unicode(self):
        ticket = Ticket(self.env)
        ticket['summary'] = 'My Summary'
        ticket['description'] = 'Some description'
        ticket.insert()
        self.env.config.set('project', 'url', u" Mller ")
        tn = TicketNotifyEmail(self.env)
        tn.ticket = ticket
        tn.get_message_id('foo')



class NotificationTestSuite(unittest.TestSuite):
    """Thin test suite wrapper to start and stop the SMTP test server"""

    def __init__(self):
        """Start the local SMTP test server"""
        unittest.TestSuite.__init__(self)
        self.smtpd = SMTPThreadedServer(SMTP_TEST_PORT)
        self.smtpd.start()
        self.addTest(unittest.makeSuite(NotificationTestCase, 'test'))
        self.remaining = self.countTestCases()

    def tear_down(self):
        """Reset the local SMTP test server"""
        self.smtpd.cleanup()
        self.remaining = self.remaining-1
        if self.remaining > 0:
            return
        # stop the SMTP test server when all tests have been completed
        self.smtpd.stop()

def suite():
    global notifysuite
    if not notifysuite:
        notifysuite = NotificationTestSuite()
    return notifysuite

if __name__ == '__main__':
    unittest.TextTestRunner(verbosity=2).run(suite())

########NEW FILE########
__FILENAME__ = query
from trac.test import Mock, EnvironmentStub, MockPerm, locale_en
from trac.ticket.query import Query, QueryModule, TicketQueryMacro
from trac.util.datefmt import utc
from trac.web.chrome import web_context
from trac.web.href import Href
from trac.wiki.formatter import LinkFormatter

import unittest
import difflib

# Note: we don't want to replicate 1:1 all the SQL dialect abstraction
#       methods from the trac.db layer here.

class QueryTestCase(unittest.TestCase):

    def prettifySQL(self, sql):
        """Returns a prettified version of the SQL as a list of lines to help
        in creating a useful diff between two SQL statements."""
        pretty = []
        for line in sql.split('\n'):
            pretty.extend([ "%s,\n" % x for x in line.split(',')])
        return pretty

    def assertEqualSQL(self, sql, correct_sql):
        sql_split = self.prettifySQL(sql)
        correct_sql_split = self.prettifySQL(correct_sql)
        sql_diff = ''.join(list(
            difflib.unified_diff(correct_sql_split, sql_split)
        ))
        failure_message = "%r != %r\n" % (sql, correct_sql) + sql_diff
        self.assertEqual(sql, correct_sql, failure_message)

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.req = Mock(href=self.env.href, authname='anonymous', tz=utc,
                        locale=locale_en, lc_time=locale_en)

    def tearDown(self):
        self.env.reset_db()

    def test_all_ordered_by_id(self):
        query = Query(self.env, order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_id_desc(self):
        query = Query(self.env, order='id', desc=1)
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0 DESC,t.id DESC""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_id_verbose(self):
        query = Query(self.env, order='id', verbose=1)
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.reporter AS reporter,t.description AS description,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_id_from_unicode(self):
        query = Query.from_string(self.env, u'order=id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_priority(self):
        query = Query(self.env) # priority is default order
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(priority.value,'')='',%(cast_priority)s,t.id""" % {
          'cast_priority': self.env.get_read_db().cast('priority.value', 'int')})
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_priority_desc(self):
        query = Query(self.env, desc=1) # priority is default order
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(priority.value,'')='' DESC,%(cast_priority)s DESC,t.id""" % {
          'cast_priority': self.env.get_read_db().cast('priority.value', 'int')})
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_version(self):
        query = Query(self.env, order='version')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.version AS version,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
  LEFT OUTER JOIN version ON (version.name=version)
ORDER BY COALESCE(t.version,'')='',COALESCE(version.time,0)=0,version.time,t.version,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_ordered_by_version_desc(self):
        query = Query(self.env, order='version', desc=1)
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.version AS version,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
  LEFT OUTER JOIN version ON (version.name=version)
ORDER BY COALESCE(t.version,'')='' DESC,COALESCE(version.time,0)=0 DESC,version.time DESC,t.version DESC,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_milestone(self):
        query = Query.from_string(self.env, 'milestone=milestone1', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.component AS component,t.time AS time,t.changetime AS changetime,t.milestone AS milestone,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.milestone,'')=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['milestone1'], args)
        tickets = query.execute(self.req)

    def test_all_grouped_by_milestone(self):
        query = Query(self.env, order='id', group='milestone')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.component AS component,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
  LEFT OUTER JOIN milestone ON (milestone.name=milestone)
ORDER BY COALESCE(t.milestone,'')='',COALESCE(milestone.completed,0)=0,milestone.completed,COALESCE(milestone.due,0)=0,milestone.due,t.milestone,COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_all_grouped_by_milestone_desc(self):
        query = Query(self.env, order='id', group='milestone', groupdesc=1)
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.component AS component,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
  LEFT OUTER JOIN milestone ON (milestone.name=milestone)
ORDER BY COALESCE(t.milestone,'')='' DESC,COALESCE(milestone.completed,0)=0 DESC,milestone.completed DESC,COALESCE(milestone.due,0)=0 DESC,milestone.due DESC,t.milestone DESC,COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_grouped_by_priority(self):
        query = Query(self.env, group='priority')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.milestone AS milestone,t.component AS component,t.priority AS priority,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(priority.value,'')='',%(cast_priority)s,t.id""" % {
          'cast_priority': self.env.get_read_db().cast('priority.value', 'int')})
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_milestone_not(self):
        query = Query.from_string(self.env, 'milestone!=milestone1', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.milestone AS milestone,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.milestone,'')!=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['milestone1'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_status(self):
        query = Query.from_string(self.env, 'status=new|assigned|reopened',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.status AS status,t.owner AS owner,t.type AS type,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (COALESCE(t.status,'') IN (%s,%s,%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['new', 'assigned', 'reopened'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_owner_containing(self):
        query = Query.from_string(self.env, 'owner~=someone', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['%someone%'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_owner_not_containing(self):
        query = Query.from_string(self.env, 'owner!~=someone', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') NOT %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['%someone%'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_owner_beginswith(self):
        query = Query.from_string(self.env, 'owner^=someone', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['someone%'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_owner_endswith(self):
        query = Query.from_string(self.env, 'owner$=someone', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['%someone'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_custom_field(self):
        self.env.config.set('ticket-custom', 'foo', 'text')
        query = Query.from_string(self.env, 'foo=something', order='id')
        sql, args = query.get_sql()
        foo = self.env.get_read_db().quote('foo')
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value,%s.value AS %s
FROM ticket AS t
  LEFT OUTER JOIN ticket_custom AS %s ON (id=%s.ticket AND %s.name='foo')
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(%s.value,'')=%%s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % ((foo,) * 6))
        self.assertEqual(['something'], args)
        tickets = query.execute(self.req)

    def test_grouped_by_custom_field(self):
        self.env.config.set('ticket-custom', 'foo', 'text')
        query = Query(self.env, group='foo', order='id')
        sql, args = query.get_sql()
        foo = self.env.get_read_db().quote('foo')
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value,%s.value AS %s
FROM ticket AS t
  LEFT OUTER JOIN ticket_custom AS %s ON (id=%s.ticket AND %s.name='foo')
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(%s.value,'')='',%s.value,COALESCE(t.id,0)=0,t.id""" %
        ((foo,) * 7))
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_multiple_owners(self):
        query = Query.from_string(self.env, 'owner=someone|someone_else',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (COALESCE(t.owner,'') IN (%s,%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['someone', 'someone_else'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_multiple_owners_not(self):
        query = Query.from_string(self.env, 'owner!=someone|someone_else',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (COALESCE(t.owner,'') NOT IN (%s,%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['someone', 'someone_else'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_multiple_owners_contain(self):
        query = Query.from_string(self.env, 'owner~=someone|someone_else',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqual(['%someone%', '%someone/_else%'], args)
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'') %(like)s OR COALESCE(t.owner,'') %(like)s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        tickets = query.execute(self.req)

    def test_constrained_by_empty_value_contains(self):
        query = Query.from_string(self.env, 'owner~=|', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_empty_value_startswith(self):
        query = Query.from_string(self.env, 'owner^=|', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_empty_value_endswith(self):
        query = Query.from_string(self.env, 'owner$=|', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual([], args)
        tickets = query.execute(self.req)

    def test_constrained_by_time_range(self):
        query = Query.from_string(self.env, 'created=2008-08-01..2008-09-01', order='id')
        sql, args = query.get_sql(self.req)
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.time AS time,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (((%(cast_time)s>=%%s AND %(cast_time)s<%%s)))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {
          'cast_time': self.env.get_read_db().cast('t.time', 'int64')})
        self.assertEqual([1217548800000000L, 1220227200000000L], args)
        tickets = query.execute(self.req)

    def test_constrained_by_time_range_exclusion(self):
        query = Query.from_string(self.env, 'created!=2008-08-01..2008-09-01', order='id')
        sql, args = query.get_sql(self.req)
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.time AS time,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((NOT (%(cast_time)s>=%%s AND %(cast_time)s<%%s)))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {
          'cast_time': self.env.get_read_db().cast('t.time', 'int64')})
        self.assertEqual([1217548800000000L, 1220227200000000L], args)
        tickets = query.execute(self.req)

    def test_constrained_by_time_range_open_right(self):
        query = Query.from_string(self.env, 'created=2008-08-01..', order='id')
        sql, args = query.get_sql(self.req)
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.time AS time,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((%(cast_time)s>=%%s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {
          'cast_time': self.env.get_read_db().cast('t.time', 'int64')})
        self.assertEqual([1217548800000000L], args)
        tickets = query.execute(self.req)

    def test_constrained_by_time_range_open_left(self):
        query = Query.from_string(self.env, 'created=..2008-09-01', order='id')
        sql, args = query.get_sql(self.req)
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.time AS time,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((%(cast_time)s<%%s))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {
          'cast_time': self.env.get_read_db().cast('t.time', 'int64')})
        self.assertEqual([1220227200000000L], args)
        tickets = query.execute(self.req)

    def test_constrained_by_time_range_modified(self):
        query = Query.from_string(self.env, 'modified=2008-08-01..2008-09-01', order='id')
        sql, args = query.get_sql(self.req)
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.changetime AS changetime,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.time AS time,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (((%(cast_changetime)s>=%%s AND %(cast_changetime)s<%%s)))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {
          'cast_changetime': self.env.get_read_db().cast('t.changetime', 'int64')})
        self.assertEqual([1217548800000000L, 1220227200000000L], args)
        tickets = query.execute(self.req)

    def test_constrained_by_keywords(self):
        query = Query.from_string(self.env, 'keywords~=foo -bar baz',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.product AS product,t.id AS id,t.summary AS summary,t.keywords AS keywords,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (((COALESCE(t.keywords,'') %(like)s AND COALESCE(t.keywords,'') NOT %(like)s AND COALESCE(t.keywords,'') %(like)s)))
ORDER BY COALESCE(t.id,0)=0,t.id""" % {'like': self.env.get_read_db().like()})
        self.assertEqual(['%foo%', '%bar%', '%baz%'], args)
        tickets = query.execute(self.req)

    def test_constrained_by_milestone_or_version(self):
        query = Query.from_string(self.env, 'milestone=milestone1&or&version=version1', order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.component AS component,t.time AS time,t.changetime AS changetime,t.version AS version,t.milestone AS milestone,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.milestone,'')=%s)) OR ((COALESCE(t.version,'')=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['milestone1', 'version1'], args)
        tickets = query.execute(self.req)

    def test_equal_in_value(self):
        query = Query.from_string(self.env, r'status=this=that&version=version1',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.priority AS priority,t.milestone AS milestone,t.component AS component,t.status AS status,t.time AS time,t.changetime AS changetime,t.version AS version,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.status,'')=%s) AND (COALESCE(t.version,'')=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['this=that', 'version1'], args)
        tickets = query.execute(self.req)

    def test_special_character_escape(self):
        query = Query.from_string(self.env, r'status=here\&now|maybe\|later|back\slash',
                                  order='id')
        sql, args = query.get_sql()
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.status AS status,t.owner AS owner,t.type AS type,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE (COALESCE(t.status,'') IN (%s,%s,%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['here&now', 'maybe|later', 'back\\slash'], args)
        tickets = query.execute(self.req)

    def test_repeated_constraint_field(self):
        like_query = Query.from_string(self.env, 'owner!=someone|someone_else',
                                       order='id')
        query = Query.from_string(self.env, 'owner!=someone&owner!=someone_else',
                                  order='id')
        like_sql, like_args = like_query.get_sql()
        sql, args = query.get_sql()
        self.assertEqualSQL(sql, like_sql)
        self.assertEqual(args, like_args)
        tickets = query.execute(self.req)

    def test_user_var(self):
        query = Query.from_string(self.env, 'owner=$USER&order=id')
        sql, args = query.get_sql(req=self.req)
        self.assertEqualSQL(sql,
"""SELECT t.id AS id,t.summary AS summary,t.owner AS owner,t.type AS type,t.status AS status,t.priority AS priority,t.milestone AS milestone,t.time AS time,t.changetime AS changetime,priority.value AS priority_value
FROM ticket AS t
  LEFT OUTER JOIN enum AS priority ON (priority.type='priority' AND priority.name=priority)
WHERE ((COALESCE(t.owner,'')=%s))
ORDER BY COALESCE(t.id,0)=0,t.id""")
        self.assertEqual(['anonymous'], args)
        tickets = query.execute(self.req)

    def test_csv_escape(self):
        query = Mock(get_columns=lambda: ['col1'],
                     execute=lambda r: [{'id': 1,
                                         'col1': 'value, needs escaped'}],
                     time_fields=['time', 'changetime'])
        content, mimetype = QueryModule(self.env).export_csv(
                                Mock(href=self.env.href, perm=MockPerm()),
                                query)
        self.assertEqual('\xef\xbb\xbfcol1\r\n"value, needs escaped"\r\n',
                         content)

    def test_template_data(self):
        req = Mock(href=self.env.href, perm=MockPerm(), authname='anonymous',
                   tz=None, locale=None)
        context = web_context(req, 'query')

        query = Query.from_string(self.env, 'owner=$USER&order=id')
        tickets = query.execute(req)
        data = query.template_data(context, tickets, req=req)
        self.assertEqual(['anonymous'], data['clauses'][0]['owner']['values'])

        query = Query.from_string(self.env, 'owner=$USER&order=id')
        tickets = query.execute(req)
        data = query.template_data(context, tickets)
        self.assertEqual(['$USER'], data['clauses'][0]['owner']['values'])


class QueryLinksTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.query_module = QueryModule(self.env)
        req = Mock(perm=MockPerm(), args={}, href=Href('/'))
        self.formatter = LinkFormatter(self.env, web_context(req))

    def tearDown(self):
        self.env.reset_db()

    def _format_link(self, query, label):
        return str(self.query_module._format_link(self.formatter, 'query',
                                                  query, label))

    def test_empty_query(self):
        self.assertEqual(self._format_link('', 'label'),
                         '<em class="error">[Error: Query filter requires '
                         'field and constraints separated by a "="]</em>')


class TicketQueryMacroTestCase(unittest.TestCase):

    def assertQueryIs(self, content, query, kwargs, format):
        qs, kw, f = TicketQueryMacro.parse_args(content)
        self.assertEqual(query, qs)
        self.assertEqual(kwargs, kw)
        self.assertEqual(format, f)

    def test_owner_and_milestone(self):
        self.assertQueryIs('owner=joe, milestone=milestone1',
                           'owner=joe&milestone=milestone1',
                           dict(col='status|summary', max='0', order='id'),
                           'list')

    def test_owner_or_milestone(self):
        self.assertQueryIs('owner=joe, or, milestone=milestone1',
                           'owner=joe&or&milestone=milestone1',
                           dict(col='status|summary', max='0', order='id'),
                           'list')

    def test_format_arguments(self):
        self.assertQueryIs('owner=joe, milestone=milestone1, col=component|severity, max=15, order=component, format=compact',
                           'owner=joe&milestone=milestone1',
                           dict(col='status|summary|component|severity', max='15', order='component'),
                           'compact')
        self.assertQueryIs('owner=joe, milestone=milestone1, col=id|summary|component, max=30, order=component, format=table',
                           'owner=joe&milestone=milestone1',
                           dict(col='id|summary|component', max='30', order='component'),
                           'table')

    def test_special_char_escaping(self):
        self.assertQueryIs(r'owner=joe|jack, milestone=this\&that\|here\,now',
                           r'owner=joe|jack&milestone=this\&that\|here,now',
                           dict(col='status|summary', max='0', order='id'),
                           'list')


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(QueryTestCase, 'test'))
    suite.addTest(unittest.makeSuite(QueryLinksTestCase, 'test'))
    suite.addTest(unittest.makeSuite(TicketQueryMacroTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = report
# -*- coding: utf-8 -*-

import doctest

from trac.db.mysql_backend import MySQLConnection
from trac.ticket.report import ReportModule
from trac.test import EnvironmentStub, Mock
from trac.web.api import Request, RequestDone
import trac

import unittest
from StringIO import StringIO

class MockMySQLConnection(MySQLConnection):
    def __init__(self):
        pass


class ReportTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        self.report_module = ReportModule(self.env)

    def tearDown(self):
        self.env.reset_db()

    def _make_environ(self, scheme='http', server_name='example.org',
                      server_port=80, method='GET', script_name='/trac',
                      **kwargs):
        environ = {'wsgi.url_scheme': scheme, 'wsgi.input': StringIO(''),
                   'REQUEST_METHOD': method, 'SERVER_NAME': server_name,
                   'SERVER_PORT': server_port, 'SCRIPT_NAME': script_name}
        environ.update(kwargs)
        return environ

    def test_sub_var_no_quotes(self):
        sql, values, missing_args = self.report_module.sql_sub_vars(
            "$VAR", {'VAR': 'value'})
        self.assertEqual("%s", sql)
        self.assertEqual(['value'], values)
        self.assertEqual([], missing_args)

    def test_sub_var_digits_underscore(self):
        sql, values, missing_args = self.report_module.sql_sub_vars(
            "$_VAR, $VAR2, $2VAR", {'_VAR': 'value1', 'VAR2': 'value2'})
        self.assertEqual("%s, %s, $2VAR", sql)
        self.assertEqual(['value1', 'value2'], values)
        self.assertEqual([], missing_args)

    def test_sub_var_quotes(self):
        sql, values, missing_args = self.report_module.sql_sub_vars(
            "'$VAR'", {'VAR': 'value'})
        self.assertEqual(self.env.get_read_db().concat("''", '%s', "''"), sql)
        self.assertEqual(['value'], values)
        self.assertEqual([], missing_args)

    def test_sub_var_missing_args(self):
        sql, values, missing_args = self.report_module.sql_sub_vars(
            "$VAR, $PARAM, $MISSING", {'VAR': 'value'})
        self.assertEqual("%s, %s, %s", sql)
        self.assertEqual(['value', '', ''], values)
        self.assertEqual(['PARAM', 'MISSING'], missing_args)

    def test_csv_escape(self):
        buf = StringIO()
        def start_response(status, headers):
            return buf.write
        environ = self._make_environ()
        req = Request(environ, start_response)
        cols = ['TEST_COL', 'TEST_ZERO']
        rows = [('value, needs escaped', 0)]
        try:
            self.report_module._send_csv(req, cols, rows)
        except RequestDone:
            pass
        self.assertEqual('\xef\xbb\xbfTEST_COL,TEST_ZERO\r\n"value, needs escaped",0\r\n',
                         buf.getvalue())

    def test_saved_custom_query_redirect(self):
        query = u'query:?type=rsum'
        db = self.env.get_db_cnx()
        cursor = db.cursor()
        cursor.execute("INSERT INTO report (title,query,description) "
                       "VALUES (%s,%s,%s)", ('redirect', query, ''))
        id = db.get_last_id(cursor, 'report')
        db.commit()

        headers_sent = {}
        def start_response(status, headers):
            headers_sent.update(dict(headers))
        environ = self._make_environ()
        req = Request(environ, start_response)
        req.authname = 'anonymous'
        req.session = Mock(save=lambda: None)
        self.assertRaises(RequestDone,
                          self.report_module._render_view, req, id)
        self.assertEqual('http://example.org/trac/query?' + \
                         'type=r%C3%A9sum%C3%A9&report=' + str(id),
                         headers_sent['Location'])


def suite():
    suite = unittest.TestSuite()
    suite.addTest(doctest.DocTestSuite(trac.ticket.report))
    suite.addTest(unittest.makeSuite(ReportTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = roadmap
from trac.test import EnvironmentStub
from trac.ticket.roadmap import *
from trac.core import ComponentManager

import unittest

class TicketGroupStatsTestCase(unittest.TestCase):

    def setUp(self):
        self.stats = TicketGroupStats('title', 'units')

    def test_init(self):
        self.assertEquals('title', self.stats.title, 'title incorrect')
        self.assertEquals('units', self.stats.unit, 'unit incorrect')
        self.assertEquals(0, self.stats.count, 'count not zero')
        self.assertEquals(0, len(self.stats.intervals), 'intervals not empty')

    def test_add_iterval(self):
        self.stats.add_interval('intTitle', 3, {'k1': 'v1'}, 'css', 0)
        self.stats.refresh_calcs()
        self.assertEquals(3, self.stats.count, 'count not incremented')
        int = self.stats.intervals[0]
        self.assertEquals('intTitle', int['title'], 'title incorrect')
        self.assertEquals(3, int['count'], 'count incorrect')
        self.assertEquals({'k1': 'v1'}, int['qry_args'], 'query args incorrect')
        self.assertEquals('css', int['css_class'], 'css class incorrect')
        self.assertEquals(100, int['percent'], 'percent incorrect')
        self.stats.add_interval('intTitle', 3, {'k1': 'v1'}, 'css', 0)
        self.stats.refresh_calcs()
        self.assertEquals(50, int['percent'], 'percent not being updated')

    def test_add_interval_no_prog(self):
        self.stats.add_interval('intTitle', 3, {'k1': 'v1'}, 'css', 0)
        self.stats.add_interval('intTitle', 5, {'k1': 'v1'}, 'css', 0)
        self.stats.refresh_calcs()
        interval = self.stats.intervals[1]
        self.assertEquals(0, self.stats.done_count, 'count added for no prog')
        self.assertEquals(0, self.stats.done_percent, 'percent incremented')

    def test_add_interval_prog(self):
        self.stats.add_interval('intTitle', 3, {'k1': 'v1'}, 'css', 0)
        self.stats.add_interval('intTitle', 1, {'k1': 'v1'}, 'css', 1)
        self.stats.refresh_calcs()
        self.assertEquals(4, self.stats.count, 'count not incremented')
        self.assertEquals(1, self.stats.done_count, 'count not added to prog')
        self.assertEquals(25, self.stats.done_percent, 'done percent not incr')

    def test_add_interval_fudging(self):
        self.stats.add_interval('intTitle', 3, {'k1': 'v1'}, 'css', 0)
        self.stats.add_interval('intTitle', 5, {'k1': 'v1'}, 'css', 1)
        self.stats.refresh_calcs()
        self.assertEquals(8, self.stats.count, 'count not incremented')
        self.assertEquals(5, self.stats.done_count, 'count not added to prog')
        self.assertEquals(62, self.stats.done_percent,
                          'done percnt not fudged downward')
        self.assertEquals(62, self.stats.intervals[1]['percent'],
                          'interval percent not fudged downward')
        self.assertEquals(38, self.stats.intervals[0]['percent'],
                          'interval percent not fudged upward')


class DefaultTicketGroupStatsProviderTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)

        self.milestone1 = Milestone(self.env)
        self.milestone1.name = 'Test'
        self.milestone1.insert()
        self.milestone2 = Milestone(self.env)
        self.milestone2.name = 'Test2'
        self.milestone2.insert()

        tkt1 = Ticket(self.env)
        tkt1.populate({'summary': 'Foo', 'milestone': 'Test', 'owner': 'foman',
                        'status': 'new'})
        tkt1.insert()
        tkt2 = Ticket(self.env)
        tkt2.populate({'summary': 'Bar', 'milestone': 'Test',
                        'status': 'closed', 'owner': 'barman'})
        tkt2.insert()
        tkt3 = Ticket(self.env)
        tkt3.populate({'summary': 'Sum', 'milestone': 'Test', 'owner': 'suman',
                        'status': 'reopened'})
        tkt3.insert()
        self.tkt1 = tkt1
        self.tkt2 = tkt2
        self.tkt3 = tkt3

        prov = DefaultTicketGroupStatsProvider(ComponentManager())
        prov.env = self.env
        prov.config = self.env.config
        self.stats = prov.get_ticket_group_stats([tkt1.id, tkt2.id, tkt3.id])

    def tearDown(self):
        self.env.reset_db()

    def test_stats(self):
        self.assertEquals(self.stats.title, 'ticket status', 'title incorrect')
        self.assertEquals(self.stats.unit, 'tickets', 'unit incorrect')
        self.assertEquals(2, len(self.stats.intervals), 'more than 2 intervals')

    def test_closed_interval(self):
        closed = self.stats.intervals[0]
        self.assertEquals('closed', closed['title'], 'closed title incorrect')
        self.assertEquals('closed', closed['css_class'], 'closed class incorrect')
        self.assertEquals(True, closed['overall_completion'],
                          'closed should contribute to overall completion')
        self.assertEquals({'status': ['closed'], 'group': ['resolution']},
                          closed['qry_args'], 'qry_args incorrect')
        self.assertEquals(1, closed['count'], 'closed count incorrect')
        self.assertEquals(33, closed['percent'], 'closed percent incorrect')

    def test_open_interval(self):
        open = self.stats.intervals[1]
        self.assertEquals('active', open['title'], 'open title incorrect')
        self.assertEquals('open', open['css_class'], 'open class incorrect')
        self.assertEquals(False, open['overall_completion'],
                          "open shouldn't contribute to overall completion")
        self.assertEquals({'status':
                           [u'assigned', u'new', u'accepted', u'reopened']},
                          open['qry_args'], 'qry_args incorrect')
        self.assertEquals(2, open['count'], 'open count incorrect')
        self.assertEquals(67, open['percent'], 'open percent incorrect')


def in_tlist(ticket, list):
    return len([t for t in list if t['id'] == ticket.id]) > 0

def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(TicketGroupStatsTestCase, 'test'))
    suite.addTest(unittest.makeSuite(DefaultTicketGroupStatsProviderTestCase,
                                      'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = wikisyntax
# -*- coding: utf-8 -*-

import unittest

from trac.ticket.model import Ticket
from trac.ticket.roadmap import Milestone
from trac.wiki.tests import formatter

TICKET_TEST_CASES = u"""
============================== ticket: link resolver
ticket:1
ticket:12
ticket:abc
------------------------------
<p>
<a class="new ticket" href="/ticket/1" title="This is the summary (new)">ticket:1</a>
<a class="missing ticket">ticket:12</a>
<a class="missing ticket">ticket:abc</a>
</p>
------------------------------
============================== ticket: link resolver + arguments
ticket:1?format=csv
ticket:1#comment:3
------------------------------
<p>
<a class="new ticket" href="/ticket/1?format=csv" title="This is the summary (new)">ticket:1?format=csv</a>
<a class="new ticket" href="/ticket/1#comment:3" title="This is the summary (new)">ticket:1#comment:3</a>
</p>
------------------------------
============================== ticket: link resolver with ranges
ticket:12-14,33
ticket:12,33?order=created
------------------------------
<p>
<a href="/query?id=12-14%2C33" title="Tickets 12-14, 33">ticket:12-14,33</a>
<a href="/query?id=12%2C33&amp;order=created" title="Tickets 12, 33">ticket:12,33?order=created</a>
</p>
------------------------------
============================== ticket link shorthand form
#1, #2
#12, #abc
------------------------------
<p>
<a class="new ticket" href="/ticket/1" title="This is the summary (new)">#1</a>, <a class="missing ticket">#2</a>
<a class="missing ticket">#12</a>, #abc
</p>
------------------------------
============================== ticket link shorthand form with ranges
#1-5,42
#1,3,5,7
------------------------------
<p>
<a href="/query?id=1-5%2C42" title="Tickets 1-5, 42">#1-5,42</a>
<a href="/query?id=1%2C3%2C5%2C7" title="Tickets 1, 3, 5, 7">#1,3,5,7</a>
</p>
------------------------------
============================== ticket link shorthand form with long ranges (#10111 regression)
#1-123456789012345678901234
------------------------------
<p>
<a href="/query?id=1-123456789012345678901234" title="Tickets 1-123456789012345678901234">#1-123456789012345678901234</a>
</p>
------------------------------
============================== escaping the above
!#1
------------------------------
<p>
#1
</p>
------------------------------
#1
============================== InterTrac for tickets
trac:ticket:2041
[trac:ticket:2041 Trac #2041]
#T2041
#trac2041
------------------------------
<p>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/ticket%3A2041" title="ticket:2041 in Trac's Trac"><span class="icon"></span>trac:ticket:2041</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/ticket%3A2041" title="ticket:2041 in Trac's Trac"><span class="icon"></span>Trac #2041</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/ticket%3A2041" title="ticket:2041 in Trac's Trac"><span class="icon"></span>#T2041</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/ticket%3A2041" title="ticket:2041 in Trac's Trac"><span class="icon"></span>#trac2041</a>
</p>
------------------------------
============================== Ticket InterTrac shorthands
T:#2041
trac:#2041
------------------------------
<p>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/%232041" title="#2041 in Trac's Trac"><span class="icon"></span>T:#2041</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/%232041" title="#2041 in Trac's Trac"><span class="icon"></span>trac:#2041</a>
</p>
------------------------------
============================== ticket syntax with unicode digits
#
#1-,42
#1,,5,7
#T
#trac
------------------------------
<p>
#
<a class="new ticket" href="/ticket/1" title="This is the summary (new)">#1</a>-,42
<a class="new ticket" href="/ticket/1" title="This is the summary (new)">#1</a>,,5,7
#T
#trac
</p>
------------------------------
""" # "

def ticket_setup(tc):
    ticket = Ticket(tc.env)
    ticket.values.update({'reporter': 'santa',
                          'summary': 'This is the summary',
                          'status': 'new'})
    ticket.insert()

def ticket_teardown(tc):
    tc.env.reset_db()



REPORT_TEST_CASES = u"""
============================== report link shorthand form
{1}, {2}
{12}, {abc}
------------------------------
<p>
<a class="report" href="/report/1">{1}</a>, <a class="report" href="/report/2">{2}</a>
<a class="report" href="/report/12">{12}</a>, {abc}
</p>
------------------------------
============================== escaping the above
!{1}
------------------------------
<p>
{1}
</p>
------------------------------
{1}
============================== ticket shorthands, not numerical HTML entities
&#1; &#23;
------------------------------
<p>
&amp;#1; &amp;#23;
</p>
------------------------------
&amp;#1; &amp;#23;
============================== InterTrac for reports
trac:report:1
[trac:report:1 Trac r1]
{T1}
{trac1}
{trac 1}
------------------------------
<p>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/report%3A1" title="report:1 in Trac's Trac"><span class="icon"></span>trac:report:1</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/report%3A1" title="report:1 in Trac's Trac"><span class="icon"></span>Trac r1</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/report%3A1" title="report:1 in Trac's Trac"><span class="icon"></span>{T1}</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/report%3A1" title="report:1 in Trac's Trac"><span class="icon"></span>{trac1}</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/report%3A1" title="report:1 in Trac's Trac"><span class="icon"></span>{trac 1}</a>
</p>
------------------------------
============================== report syntax with unicode digits
{} !{}
{T}
{trac}
------------------------------
<p>
{} !{}
{T}
{trac}
</p>
------------------------------
""" # '

def report_setup(tc):
    pass # TBD


MILESTONE_TEST_CASES = u"""
============================== milestone: link resolver
milestone:foo
[milestone:boo Milestone Boo]
[milestone:roo Milestone Roo]
------------------------------
<p>
<a class="missing milestone" href="/milestone/foo" rel="nofollow">milestone:foo</a>
<a class="milestone" href="/milestone/boo">Milestone Boo</a>
<a class="closed milestone" href="/milestone/roo">Milestone Roo</a>
</p>
------------------------------
============================== milestone: link resolver + arguments
milestone:?action=new
[milestone:boo#KnownIssues Known Issues for 1.0]
------------------------------
<p>
<a class="missing milestone" href="/milestone/?action=new" rel="nofollow">milestone:?action=new</a>
<a class="milestone" href="/milestone/boo#KnownIssues">Known Issues for 1.0</a>
</p>
------------------------------
""" #"

def milestone_setup(tc):
    from datetime import datetime
    from trac.util.datefmt import utc
    boo = Milestone(tc.env)
    boo.name = 'boo'
    boo.completed = boo.due = None
    boo.insert()
    roo = Milestone(tc.env)
    roo.name = 'roo'
    roo.completed = datetime.now(utc)
    roo.due = None
    roo.insert()

def milestone_teardown(tc):
    tc.env.reset_db()



QUERY_TEST_CASES = u"""
============================== query: link resolver
query:?order=priority

query:?order=priority&owner=me

query:?type=rsum

query:status=new|reopened

query:reporter!=

query:reporter=joe|jack&owner=me

query:group=owner

query:verbose=1

query:summary=rsum
------------------------------
<p>
<a class="query" href="/query?order=priority">query:?order=priority</a>
</p>
<p>
<a class="query" href="/query?order=priority&amp;owner=me">query:?order=priority&amp;owner=me</a>
</p>
<p>
<a class="query" href="/query?type=r%C3%A9sum%C3%A9">query:?type=rsum</a>
</p>
<p>
<a class="query" href="/query?status=new&amp;status=reopened&amp;order=priority">query:status=new|reopened</a>
</p>
<p>
<a class="query" href="/query?reporter=!&amp;order=priority">query:reporter!=</a>
</p>
<p>
<a class="query" href="/query?owner=me&amp;reporter=joe&amp;reporter=jack&amp;order=priority">query:reporter=joe|jack&amp;owner=me</a>
</p>
<p>
<a class="query" href="/query?group=owner&amp;order=priority">query:group=owner</a>
</p>
<p>
<a class="query" href="/query?row=description&amp;order=priority">query:verbose=1</a>
</p>
<p>
<a class="query" href="/query?summary=r%C3%A9sum%C3%A9&amp;order=priority">query:summary=rsum</a>
</p>
------------------------------
============================== TicketQuery macro: no results, list form
Reopened tickets: [[TicketQuery(status=reopened)]]
------------------------------
<p>
Reopened tickets: <span class="query_no_results">No results</span>
</p>
------------------------------
============================== TicketQuery macro: no results, count 0
Reopened tickets: [[TicketQuery(status=reopened, format=count)]]
------------------------------
<p>
Reopened tickets: <span class="query_count" title="0 tickets for which status=reopened&amp;max=0&amp;order=id">0</span>
</p>
------------------------------
============================== TicketQuery macro: no results, compact form
Reopened tickets: [[TicketQuery(status=reopened, format=compact)]]
------------------------------
<p>
Reopened tickets: <span class="query_no_results">No results</span>
</p>
------------------------------
============================== TicketQuery macro: one result, list form
New tickets: [[TicketQuery(status=new)]]
------------------------------
<p>
New tickets: </p><div><dl class="wiki compact"><dt><a class="new" href="/ticket/1" title="This is the summary">#1</a></dt><dd>This is the summary</dd></dl></div><p>
</p>
------------------------------
============================== TicketQuery macro: one result, count 1
New tickets: [[TicketQuery(status=new, format=count)]]
------------------------------
<p>
New tickets: <span class="query_count" title="1 tickets for which status=new&amp;max=0&amp;order=id">1</span>
</p>
------------------------------
============================== TicketQuery macro: one result, compact form
New tickets: [[TicketQuery(status=new, format=compact)]]
------------------------------
<p>
New tickets: <span><a class="new" href="/ticket/1" title="This is the summary">#1</a></span>
</p>
------------------------------
"""

QUERY2_TEST_CASES = u"""
============================== TicketQuery macro: two results, list form
New tickets: [[TicketQuery(status=new, order=reporter)]]
------------------------------
<p>
New tickets: </p><div><dl class="wiki compact"><dt><a class="new" href="/ticket/2" title="This is another summary">#2</a></dt><dd>This is another summary</dd><dt><a class="new" href="/ticket/1" title="This is the summary">#1</a></dt><dd>This is the summary</dd></dl></div><p>
</p>
------------------------------
============================== TicketQuery macro: two results, count 2
New tickets: [[TicketQuery(status=new, order=reporter, format=count)]]
------------------------------
<p>
New tickets: <span class="query_count" title="2 tickets for which status=new&amp;max=0&amp;order=reporter">2</span>
</p>
------------------------------
============================== TicketQuery macro: two results, compact form
New tickets: [[TicketQuery(status=new, order=reporter, format=compact)]]
------------------------------
<p>
New tickets: <span><a class="new" href="/ticket/2" title="This is another summary">#2</a>, <a class="new" href="/ticket/1" title="This is the summary">#1</a></span>
</p>
------------------------------
"""

def query2_setup(tc):
    ticket = Ticket(tc.env)
    ticket.values.update({'reporter': 'santa',
                          'summary': 'This is the summary',
                          'status': 'new'})
    ticket.insert()
    ticket = Ticket(tc.env)
    ticket.values.update({'reporter': 'claus',
                          'summary': 'This is another summary',
                          'status': 'new'})
    ticket.insert()

def query2_teardown(tc):
    tc.env.reset_db()


COMMENT_TEST_CASES = u"""
============================== comment: link resolver (deprecated)
comment:ticket:123:2 (deprecated)
[comment:ticket:123:2 see above] (deprecated)
[comment:ticket:123:description see descr] (deprecated)
------------------------------
<p>
<a href="/ticket/123#comment:2" title="Comment 2 for Ticket #123">comment:ticket:123:2</a> (deprecated)
<a href="/ticket/123#comment:2" title="Comment 2 for Ticket #123">see above</a> (deprecated)
<a href="/ticket/123#comment:description" title="Comment description for Ticket #123">see descr</a> (deprecated)
</p>
------------------------------
============================== comment: link resolver
comment:2:ticket:123
[comment:2:ticket:123 see above]
[comment:description:ticket:123 see descr]
------------------------------
<p>
<a href="/ticket/123#comment:2" title="Comment 2 for Ticket #123">comment:2:ticket:123</a>
<a href="/ticket/123#comment:2" title="Comment 2 for Ticket #123">see above</a>
<a href="/ticket/123#comment:description" title="Comment description for Ticket #123">see descr</a>
</p>
------------------------------
""" # "

# NOTE: the following test cases:
#
#  comment:2
#  [comment:2 see above]
#
# would trigger an error in the workaround code ../api.py, line 235
# As it's a problem with a temp workaround, I think there's no need
# to fix it for now.

def suite():
    suite = unittest.TestSuite()
    suite.addTest(formatter.suite(TICKET_TEST_CASES, ticket_setup, __file__,
                                  ticket_teardown))
    suite.addTest(formatter.suite(REPORT_TEST_CASES, report_setup, __file__))
    suite.addTest(formatter.suite(MILESTONE_TEST_CASES, milestone_setup,
                                  __file__, milestone_teardown))
    suite.addTest(formatter.suite(QUERY_TEST_CASES, ticket_setup, __file__,
                                  ticket_teardown))
    suite.addTest(formatter.suite(QUERY2_TEST_CASES, query2_setup, __file__,
                                  query2_teardown))
    suite.addTest(formatter.suite(COMMENT_TEST_CASES, file=__file__))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')


########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>

from __future__ import with_statement

import csv
from datetime import datetime
import pkg_resources
import re
from StringIO import StringIO

from genshi.core import Markup
from genshi.builder import tag

from trac.attachment import AttachmentModule
from trac.config import BoolOption, Option, IntOption
from trac.core import *
from trac.mimeview.api import Mimeview, IContentConverter
from trac.resource import (
    Resource, ResourceNotFound, get_resource_url, render_resource_link,
    get_resource_shortname
)
from trac.search import ISearchSource, search_to_sql, shorten_result
from trac.ticket.api import TicketSystem, ITicketManipulator
from trac.ticket.model import Milestone, Ticket, group_milestones
from trac.ticket.notification import TicketNotifyEmail
from trac.timeline.api import ITimelineEventProvider
from trac.util import as_bool, as_int, get_reporter_id
from trac.util.datefmt import (
    format_datetime, from_utimestamp, to_utimestamp, utc
)
from trac.util.text import (
    exception_to_unicode, empty, obfuscate_email_address, shorten_line,
    to_unicode
)
from trac.util.presentation import separated
from trac.util.translation import _, tag_, tagn_, N_, gettext, ngettext
from trac.versioncontrol.diff import get_diff_options, diff_blocks
from trac.web import (
    IRequestHandler, RequestDone, arg_list_to_args, parse_arg_list
)
from trac.web.chrome import (
    Chrome, INavigationContributor, ITemplateProvider,
    add_ctxtnav, add_link, add_notice, add_script, add_script_data,
    add_stylesheet, add_warning, auth_link, prevnext_nav, web_context
)
from trac.wiki.formatter import format_to, format_to_html, format_to_oneliner


class InvalidTicket(TracError):
    """Exception raised when a ticket fails validation."""
    title = N_("Invalid Ticket")


class TicketModule(Component):

    implements(IContentConverter, INavigationContributor, IRequestHandler,
               ISearchSource, ITemplateProvider, ITimelineEventProvider)

    ticket_manipulators = ExtensionPoint(ITicketManipulator)

    timeline_details = BoolOption('timeline', 'ticket_show_details', 'false',
        """Enable the display of all ticket changes in the timeline, not only
        open / close operations (''since 0.9'').""")

    max_description_size = IntOption('ticket', 'max_description_size', 262144,
        """Don't accept tickets with a too big description.
        (''since 0.11'').""")

    max_comment_size = IntOption('ticket', 'max_comment_size', 262144,
        """Don't accept tickets with a too big comment.
        (''since 0.11.2'')""")

    timeline_newticket_formatter = Option('timeline', 'newticket_formatter',
                                          'oneliner',
        """Which formatter flavor (e.g. 'html' or 'oneliner') should be
        used when presenting the description for new tickets.
        If 'oneliner', the [timeline] abbreviated_messages option applies.
        (''since 0.11'').""")

    preserve_newlines = Option('ticket', 'preserve_newlines', 'default',
        """Whether Wiki formatter should respect the new lines present
        in the Wiki text.
        If set to 'default', this is equivalent to 'yes' for new environments
        but keeps the old behavior for upgraded environments (i.e. 'no').
        (''since 0.11'').""")

    ticketlink_query = Option('query', 'ticketlink_query',
        default='?status=!closed',
        doc="""The base query to be used when linkifying values of ticket
            fields. The query is a URL query
            string starting with `?` as used in `query:`
            [TracQuery#UsingTracLinks Trac links].
            (''since 0.12'')""")

    def __init__(self):
        self._warn_for_default_attr = set()

    def __getattr__(self, name):
        """Delegate access to ticket default Options which were move to
        TicketSystem.

        .. todo:: remove in 1.0
        """
        if name.startswith('default_'):
            if name not in self._warn_for_default_attr:
                self.log.warning("%s option should be accessed via "
                                 "TicketSystem component", name)
                self._warn_for_default_attr.add(name)
            return getattr(TicketSystem(self.env), name)
        raise AttributeError("TicketModule has no attribute '%s'" % name)

    @property
    def must_preserve_newlines(self):
        preserve_newlines = self.preserve_newlines
        if preserve_newlines == 'default':
            preserve_newlines = self.env.get_version(initial=True) >= 21 # 0.11
        return as_bool(preserve_newlines)

    # IContentConverter methods

    def get_supported_conversions(self):
        yield ('csv', _("Comma-delimited Text"), 'csv',
               'trac.ticket.Ticket', 'text/csv', 8)
        yield ('tab', _("Tab-delimited Text"), 'tsv',
               'trac.ticket.Ticket', 'text/tab-separated-values', 8)
        yield ('rss', _("RSS Feed"), 'xml',
               'trac.ticket.Ticket', 'application/rss+xml', 8)

    def convert_content(self, req, mimetype, ticket, key):
        if key == 'csv':
            return self.export_csv(req, ticket, mimetype='text/csv')
        elif key == 'tab':
            return self.export_csv(req, ticket, sep='\t',
                                   mimetype='text/tab-separated-values')
        elif key == 'rss':
            return self.export_rss(req, ticket)

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        if re.match(r'/newticket/?', req.path_info):
            return 'newticket'
        return 'tickets'

    def get_navigation_items(self, req):
        if 'TICKET_CREATE' in req.perm:
            yield ('mainnav', 'newticket',
                   tag.a(_("New Ticket"), href=req.href.newticket(),
                         accesskey=7))

    # IRequestHandler methods

    def match_request(self, req):
        if req.path_info == "/newticket":
            return True
        match = re.match(r'/ticket/([0-9]+)$', req.path_info)
        if match:
            req.args['id'] = match.group(1)
            return True

    def process_request(self, req):
        if 'id' in req.args:
            if req.path_info == '/newticket':
                raise TracError(_("id can't be set for a new ticket request."))
            return self._process_ticket_request(req)
        return self._process_newticket_request(req)

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        return [pkg_resources.resource_filename('trac.ticket', 'templates')]

    # ISearchSource methods

    def get_search_filters(self, req):
        if 'TICKET_VIEW' in req.perm:
            yield ('ticket', _("Tickets"))

    def get_search_results(self, req, terms, filters):
        if not 'ticket' in filters:
            return
        ticket_realm = Resource('ticket')
        with self.env.db_query as db:
            sql, args = search_to_sql(db, ['summary', 'keywords',
                                           'description', 'reporter', 'cc',
                                           db.cast('id', 'text')], terms)
            sql2, args2 = search_to_sql(db, ['newvalue'], terms)
            sql3, args3 = search_to_sql(db, ['value'], terms)
            ticketsystem = TicketSystem(self.env)
            for summary, desc, author, type, tid, ts, status, resolution in \
                    db("""SELECT summary, description, reporter, type, id,
                                 time, status, resolution
                          FROM ticket
                          WHERE id IN (
                              SELECT id FROM ticket WHERE %s
                            UNION
                              SELECT ticket FROM ticket_change
                              WHERE field='comment' AND %s
                            UNION
                              SELECT ticket FROM ticket_custom WHERE %s
                          )
                          """ % (sql, sql2, sql3),
                          args + args2 + args3):
                t = ticket_realm(id=tid)
                if 'TICKET_VIEW' in req.perm(t):
                    yield (req.href.ticket(tid),
                           tag_("%(title)s: %(message)s",
                                title=tag.span(
                                    get_resource_shortname(self.env, t),
                                    class_=status),
                                message=ticketsystem.format_summary(
                                    summary, status, resolution, type)),
                           from_utimestamp(ts), author,
                           shorten_result(desc, terms))

        # Attachments
        for result in AttachmentModule(self.env).get_search_results(
            req, ticket_realm, terms):
            yield result

    # ITimelineEventProvider methods

    def get_timeline_filters(self, req):
        if 'TICKET_VIEW' in req.perm:
            yield ('ticket', _("Tickets opened and closed"))
            if self.timeline_details:
                yield ('ticket_details', _("Ticket updates"), False)

    def get_timeline_events(self, req, start, stop, filters):
        ts_start = to_utimestamp(start)
        ts_stop = to_utimestamp(stop)

        status_map = {'new': ('newticket', 'created'),
                      'reopened': ('reopenedticket', 'reopened'),
                      'closed': ('closedticket', 'closed'),
                      'edit': ('editedticket', 'updated')}

        ticket_realm = Resource('ticket')

        field_labels = TicketSystem(self.env).get_ticket_field_labels()

        def produce_event((id, ts, author, type, summary, description),
                          status, fields, comment, cid):
            ticket = ticket_realm(id=id)
            if 'TICKET_VIEW' not in req.perm(ticket):
                return None
            resolution = fields.get('resolution')
            info = ''
            if status == 'edit':
                if 'ticket_details' in filters:
                    if len(fields) > 0:
                        labels = [tag.i(field_labels.get(k, k.capitalize()))
                                  for k in fields.keys()]
                        info = tagn_("%(labels)s changed",
                                     "%(labels)s changed", len(labels),
                                     labels=separated(labels, ', ')) + tag.br()
                else:
                    return None
            elif 'ticket' in filters:
                if status == 'closed' and resolution:
                    if resolution and comment:
                        info = _("%(title)s: %(message)s", title=resolution,
                                 message='') # typographical translation (fr)
                    else:
                        info = resolution
            else:
                return None
            kind, verb = status_map[status]
            return (kind, from_utimestamp(ts), author,
                    (ticket, verb, info, summary, status, resolution, type,
                     description, comment, cid))

        def produce_ticket_change_events(db):
            data = None
            for id, t, author, type, summary, field, oldvalue, newvalue \
                    in db("""
                    SELECT t.id, tc.time, tc.author, t.type, t.summary,
                           tc.field, tc.oldvalue, tc.newvalue
                    FROM ticket_change tc
                        INNER JOIN ticket t ON t.id = tc.ticket
                            AND tc.time>=%s AND tc.time<=%s
                    ORDER BY tc.time
                    """ % (ts_start, ts_stop)):
                if not (oldvalue or newvalue):
                    # ignore empty change corresponding to custom field
                    # created (None -> '') or deleted ('' -> None)
                    continue
                if not data or (id, t) != data[:2]:
                    if data:
                        ev = produce_event(data, status, fields, comment,
                                           cid)
                        if ev:
                             yield (ev, data[1])
                    status, fields, comment, cid = 'edit', {}, '', None
                    data = (id, t, author, type, summary, None)
                if field == 'comment':
                    comment = newvalue
                    cid = oldvalue and oldvalue.split('.')[-1]
                    # Always use the author from the comment field
                    data = data[:2] + (author,) + data[3:]
                elif field == 'status' and \
                        newvalue in ('reopened', 'closed'):
                    status = newvalue
                elif field[0] != '_':
                    # properties like _comment{n} are hidden
                    fields[field] = newvalue
            if data:
                ev = produce_event(data, status, fields, comment, cid)
                if ev:
                    yield (ev, data[1])

        # Ticket changes
        with self.env.db_query as db:
            if 'ticket' in filters or 'ticket_details' in filters:
                prev_t = None
                prev_ev = None
                batch_ev = None
                for (ev, t) in produce_ticket_change_events(db):
                    if batch_ev:
                        if prev_t == t:
                            ticket = ev[3][0]
                            batch_ev[3][0].append(ticket.id)
                        else:
                            yield batch_ev
                            prev_ev = ev
                            prev_t = t
                            batch_ev = None
                    elif prev_t and prev_t == t:
                        prev_ticket = prev_ev[3][0]
                        ticket = ev[3][0]
                        tickets = [prev_ticket.id, ticket.id]
                        batch_data = (tickets,) + ev[3][1:]
                        batch_ev = ('batchmodify', ev[1], ev[2], batch_data)
                    else:
                        if prev_ev:
                            yield prev_ev
                        prev_ev = ev
                        prev_t = t
                if batch_ev:
                    yield batch_ev
                elif prev_ev:
                    yield prev_ev

                # New tickets
                if 'ticket' in filters:
                    for row in db("""SELECT id, time, reporter, type, summary,
                                            description
                                     FROM ticket WHERE time>=%s AND time<=%s
                                     """, (ts_start, ts_stop)):
                        ev = produce_event(row, 'new', {}, None, None)
                        if ev:
                            yield ev

            # Attachments
            if 'ticket_details' in filters:
                for event in AttachmentModule(self.env).get_timeline_events(
                    req, ticket_realm, start, stop):
                    yield event

    def render_timeline_event(self, context, field, event):
        kind = event[0]
        if kind == 'batchmodify':
            return self._render_batched_timeline_event(context, field, event)
        ticket, verb, info, summary, status, resolution, type, \
                description, comment, cid = event[3]
        if field == 'url':
            href = context.href.ticket(ticket.id)
            if cid:
                href += '#comment:' + cid
            return href
        elif field == 'title':
            title = TicketSystem(self.env).format_summary(summary, status,
                                                          resolution, type)
            message = {
                'created': N_("Ticket %(ticketref)s (%(summary)s) created"),
                'reopened': N_("Ticket %(ticketref)s (%(summary)s) reopened"),
                'closed': N_("Ticket %(ticketref)s (%(summary)s) closed"),
                'updated': N_("Ticket %(ticketref)s (%(summary)s) updated"),
            }[verb]
            return tag_(message,
                        ticketref=tag.em('#', ticket.id, title=title),
                        summary=shorten_line(summary))
        elif field == 'description':
            descr = message = ''
            if status == 'new':
                message = description
            else:
                descr = info
                message = comment
            t_context = context.child(resource=ticket)
            t_context.set_hints(preserve_newlines=self.must_preserve_newlines)
            if status == 'new' and \
                    context.get_hint('wiki_flavor') == 'oneliner':
                flavor = self.timeline_newticket_formatter
                t_context.set_hints(wiki_flavor=flavor,
                                    shorten_lines=flavor == 'oneliner')
            return descr + format_to(self.env, None, t_context, message)

    def _render_batched_timeline_event(self, context, field, event):
        tickets, verb, info, summary, status, resolution, type, \
                description, comment, cid = event[3]
        tickets = sorted(tickets)
        if field == 'url':
            return context.href.query(id=','.join(str(t) for t in tickets))
        elif field == 'title':
            ticketids = u',\u200b'.join(str(t) for t in tickets)
            title = _("Tickets %(ticketids)s", ticketids=ticketids)
            return tag_("Tickets %(ticketlist)s batch updated",
                        ticketlist=tag.em('#', ticketids, title=title))
        elif field == 'description':
            t_context = context()
            t_context.set_hints(preserve_newlines=self.must_preserve_newlines)
            return info + format_to(self.env, None, t_context, comment)

    # Internal methods

    def _get_action_controllers(self, req, ticket, action):
        """Generator yielding the controllers handling the given `action`"""
        for controller in TicketSystem(self.env).action_controllers:
            actions = [a for w, a in
                       controller.get_ticket_actions(req, ticket) or []]
            if action in actions:
                yield controller

    def _process_newticket_request(self, req):
        req.perm.require('TICKET_CREATE')
        ticket = Ticket(self.env)

        plain_fields = True # support for /newticket?version=0.11 GETs
        field_reporter = 'reporter'

        if req.method == 'POST':
            plain_fields = False
            field_reporter = 'field_reporter'
            if 'field_owner' in req.args and 'TICKET_MODIFY' not in req.perm:
                del req.args['field_owner']

        self._populate(req, ticket, plain_fields)
        ticket.values['status'] = 'new'     # Force initial status
        reporter_id = req.args.get(field_reporter) or \
                      get_reporter_id(req, 'author')
        ticket.values['reporter'] = reporter_id

        valid = None
        if req.method == 'POST' and not 'preview' in req.args:
            valid = self._validate_ticket(req, ticket)
            if valid:
                self._do_create(req, ticket) # (redirected if successful)
            # else fall through in a preview
            req.args['preview'] = True

        # don't validate for new tickets and don't validate twice
        if valid is None and 'preview' in req.args:
            valid = self._validate_ticket(req, ticket)

        # Preview a new ticket
        data = self._prepare_data(req, ticket)
        data.update({
            'author_id': reporter_id,
            'actions': [],
            'version': None,
            'description_change': None,
            'valid': valid
        })

        fields = self._prepare_fields(req, ticket)

        # position 'owner' immediately before 'cc',
        # if not already positioned after (?)

        field_names = [field['name'] for field in ticket.fields
                       if not field.get('custom')]
        if 'owner' in field_names:
            curr_idx = field_names.index('owner')
            if 'cc' in field_names:
                insert_idx = field_names.index('cc')
            else:
                insert_idx = len(field_names)
            if curr_idx < insert_idx:
                ticket.fields.insert(insert_idx, ticket.fields[curr_idx])
                del ticket.fields[curr_idx]

        data['fields'] = fields
        data['fields_map'] = dict((field['name'], i)
                                  for i, field in enumerate(fields))

        if req.get_header('X-Requested-With') == 'XMLHttpRequest':
            data['preview_mode'] = True
            return 'ticket_box.html', data, None

        add_stylesheet(req, 'common/css/ticket.css')
        add_script(req, 'common/js/folding.js')
        Chrome(self.env).add_wiki_toolbars(req)
        Chrome(self.env).add_auto_preview(req)
        return 'ticket.html', data, None

    def _process_ticket_request(self, req):
        id = int(req.args.get('id'))
        version = as_int(req.args.get('version'), None)
        xhr = req.get_header('X-Requested-With') == 'XMLHttpRequest'

        if xhr and 'preview_comment' in req.args:
            context = web_context(req, 'ticket', id, version)
            escape_newlines = self.must_preserve_newlines
            rendered = format_to_html(self.env, context,
                                      req.args.get('edited_comment', ''),
                                      escape_newlines=escape_newlines)
            req.send(rendered.encode('utf-8'))

        req.perm('ticket', id, version).require('TICKET_VIEW')
        ticket = Ticket(self.env, id, version=version)
        action = req.args.get('action', ('history' in req.args and 'history' or
                                         'view'))

        data = self._prepare_data(req, ticket)

        if action in ('history', 'diff'):
            field = req.args.get('field')
            if field:
                text_fields = [field]
            else:
                text_fields = [field['name'] for field in ticket.fields if
                               field['type'] == 'textarea']
            if action == 'history':
                return self._render_history(req, ticket, data, text_fields)
            elif action == 'diff':
                return self._render_diff(req, ticket, data, text_fields)
        elif action == 'comment-history':
            cnum = int(req.args['cnum'])
            return self._render_comment_history(req, ticket, data, cnum)
        elif action == 'comment-diff':
            cnum = int(req.args['cnum'])
            return self._render_comment_diff(req, ticket, data, cnum)
        elif 'preview_comment' in req.args:
            field_changes = {}
            data.update({'action': None,
                         'reassign_owner': req.authname,
                         'resolve_resolution': None,
                         'start_time': ticket['changetime']})
        elif req.method == 'POST':
            if 'cancel_comment' in req.args:
                req.redirect(req.href.ticket(ticket.id))
            elif 'edit_comment' in req.args:
                comment = req.args.get('edited_comment', '')
                cnum = int(req.args['cnum_edit'])
                change = ticket.get_change(cnum)
                if not (req.authname and req.authname != 'anonymous'
                        and change and change['author'] == req.authname):
                    req.perm(ticket.resource).require('TICKET_EDIT_COMMENT')
                ticket.modify_comment(change['date'], req.authname, comment)
                req.redirect(req.href.ticket(ticket.id) + '#comment:%d' % cnum)

            valid = True

            # Do any action on the ticket?
            actions = TicketSystem(self.env).get_available_actions(req, ticket)
            if action not in actions:
                valid = False
                add_warning(req, _('The action "%(name)s" is not available.',
                                   name=action))

            # We have a bit of a problem.  There are two sources of changes to
            # the ticket: the user, and the workflow.  We need to show all the
            # changes that are proposed, but we need to be able to drop the
            # workflow changes if the user changes the action they want to do
            # from one preview to the next.
            #
            # the _populate() call pulls all the changes from the webpage; but
            # the webpage includes both changes by the user and changes by the
            # workflow... so we aren't able to differentiate them clearly.

            self._populate(req, ticket) # Apply changes made by the user
            field_changes, problems = self.get_ticket_changes(req, ticket,
                                                              action)
            if problems:
                valid = False
                for problem in problems:
                    add_warning(req, problem)
                add_warning(req,
                            tag_("Please review your configuration, "
                                 "probably starting with %(section)s "
                                 "in your %(tracini)s.",
                                 section=tag.pre('[ticket]', tag.br(),
                                                 'workflow = ...'),
                                 tracini=tag.tt('trac.ini')))

            # Apply changes made by the workflow
            self._apply_ticket_changes(ticket, field_changes)
            # Unconditionally run the validation so that the user gets
            # information any and all problems.  But it's only valid if it
            # validates and there were no problems with the workflow side of
            # things.
            valid = self._validate_ticket(req, ticket, not valid) and valid
            if 'submit' in req.args:
                if valid:
                    # redirected if successful
                    self._do_save(req, ticket, action)
                # else fall through in a preview
                req.args['preview'] = True

            # Preview an existing ticket (after a Preview or a failed Save)
            start_time = from_utimestamp(long(req.args.get('start_time', 0)))
            data.update({
                'action': action, 'start_time': start_time,
                'reassign_owner': (req.args.get('reassign_choice')
                                   or req.authname),
                'resolve_resolution': req.args.get('resolve_choice'),
                'valid': valid
                })
        else: # simply 'View'ing the ticket
            field_changes = {}
            data.update({'action': None,
                         'reassign_owner': req.authname,
                         'resolve_resolution': None,
                         # Store a timestamp for detecting "mid air collisions"
                         'start_time': ticket['changetime']})

        data.update({'comment': req.args.get('comment'),
                     'cnum_edit': req.args.get('cnum_edit'),
                     'edited_comment': req.args.get('edited_comment'),
                     'cnum_hist': req.args.get('cnum_hist'),
                     'cversion': req.args.get('cversion')})

        self._insert_ticket_data(req, ticket, data,
                                 get_reporter_id(req, 'author'), field_changes)

        if xhr:
            data['preview_mode'] = bool(data['change_preview']['fields'])
            return 'ticket_preview.html', data, None

        mime = Mimeview(self.env)
        format = req.args.get('format')
        if format:
            # FIXME: mime.send_converted(context, ticket, 'ticket_x') (#3332)
            filename = 't%d' % ticket.id if format != 'rss' else None
            mime.send_converted(req, 'trac.ticket.Ticket', ticket,
                                format, filename=filename)

        def add_ticket_link(css_class, id):
            t = ticket.resource(id=id, version=None)
            if t:
                add_link(req, css_class, req.href.ticket(id),
                         _("Ticket #%(id)s", id=id))

        global_sequence = True
        # If the ticket is being shown in the context of a query, add
        # links to help navigate in the query result set
        if 'query_tickets' in req.session:
            tickets = req.session['query_tickets'].split()
            if str(ticket.id) in tickets:
                idx = tickets.index(str(ticket.id))
                if idx > 0:
                    add_ticket_link('first', tickets[0])
                    add_ticket_link('prev', tickets[idx - 1])
                if idx < len(tickets) - 1:
                    add_ticket_link('next', tickets[idx + 1])
                    add_ticket_link('last', tickets[-1])
                add_link(req, 'up', req.session['query_href'])
                global_sequence = False
        if global_sequence:
            with self.env.db_query as db:
                for min_id, max_id in db(
                        "SELECT min(id), max(id) FROM ticket"):
                    min_id = int(min_id)
                    max_id = int(max_id)
                    if min_id < ticket.id:
                        add_ticket_link('first', min_id)
                        for prev_id, in db(
                                "SELECT max(id) FROM ticket WHERE id < %s",
                                (ticket.id,)):
                            add_ticket_link('prev', int(prev_id))
                    if ticket.id < max_id:
                        add_ticket_link('last', max_id)
                        for next_id, in db(
                                "SELECT min(id) FROM ticket WHERE %s < id",
                                (ticket.id,)):
                            add_ticket_link('next', int(next_id))
                    break

        add_script_data(req, {'comments_prefs': self._get_prefs(req)})
        add_stylesheet(req, 'common/css/ticket.css')
        add_script(req, 'common/js/folding.js')
        Chrome(self.env).add_wiki_toolbars(req)
        Chrome(self.env).add_auto_preview(req)

        # Add registered converters
        for conversion in mime.get_supported_conversions('trac.ticket.Ticket'):
            format = conversion[0]
            conversion_href = get_resource_url(self.env, ticket.resource,
                                               req.href, format=format)
            if format == 'rss':
                conversion_href = auth_link(req, conversion_href)
            add_link(req, 'alternate', conversion_href, conversion[1],
                     conversion[4], format)

        prevnext_nav(req, _("Previous Ticket"), _("Next Ticket"),
                     _("Back to Query"))

        return 'ticket.html', data, None

    def _get_prefs(self, req):
        return {'comments_order': req.session.get('ticket_comments_order',
                                                  'oldest'),
                'comments_only': req.session.get('ticket_comments_only',
                                                 'false')}

    def _prepare_data(self, req, ticket, absurls=False):
        return {'ticket': ticket, 'to_utimestamp': to_utimestamp,
                'context': web_context(req, ticket.resource, absurls=absurls),
                'preserve_newlines': self.must_preserve_newlines,
                'emtpy': empty}

    def _cc_list(self, cc):
        return Chrome(self.env).cc_list(cc)

    def _toggle_cc(self, req, cc):
        """Return an (action, recipient) tuple corresponding to a change
        of CC status for this user relative to the current `cc_list`."""
        entries = []
        email = req.session.get('email', '').strip()
        if email:
            entries.append(email)
        if req.authname != 'anonymous':
            entries.append(req.authname)
        else:
            author = get_reporter_id(req, 'author').strip()
            if author and author != 'anonymous':
                email = author.split()[-1]
                if (email[0], email[-1]) == ('<', '>'):
                    email = email[1:-1]
                entries.append(email)
        add = []
        remove = []
        cc_list = self._cc_list(cc)
        for entry in entries:
            if entry in cc_list:
                remove.append(entry)
            else:
                add.append(entry)
        action = entry = ''
        if remove:
            action, entry = ('remove', remove[0])
        elif add:
            action, entry = ('add', add[0])
        return (action, entry, cc_list)

    def _populate(self, req, ticket, plain_fields=False):
        if not plain_fields:
            fields = dict((k[6:], v) for k, v in req.args.iteritems()
                          if k.startswith('field_')
                             and not 'revert_' + k[6:] in req.args)
            # Handle revert of checkboxes (in particular, revert to 1)
            for k in list(fields):
                if k.startswith('checkbox_'):
                    k = k[9:]
                    if 'revert_' + k in req.args:
                        fields[k] = ticket[k]
        else:
            fields = req.args.copy()
        # Prevent direct changes to protected fields (status and resolution are
        # set in the workflow, in get_ticket_changes())
        for each in Ticket.protected_fields:
            fields.pop(each, None)
            fields.pop('checkbox_' + each, None)    # See Ticket.populate()
        ticket.populate(fields)
        # special case for updating the Cc: field
        if 'cc_update' in req.args and 'revert_cc' not in req.args:
            cc_action, cc_entry, cc_list = self._toggle_cc(req, ticket['cc'])
            if cc_action == 'remove':
                cc_list.remove(cc_entry)
            elif cc_action == 'add':
                cc_list.append(cc_entry)
            ticket['cc'] = ', '.join(cc_list)

    def _get_history(self, req, ticket):
        history = []
        for change in self.rendered_changelog_entries(req, ticket):
            if change['permanent']:
                change['version'] = change['cnum']
                history.append(change)
        return history

    def _render_history(self, req, ticket, data, text_fields):
        """Extract the history for a ticket description."""
        req.perm(ticket.resource).require('TICKET_VIEW')

        history = self._get_history(req, ticket)
        history.reverse()
        history = [c for c in history if any(f in text_fields
                                             for f in c['fields'])]
        history.append({'version': 0, 'comment': "''Initial version''",
                        'date': ticket['time'],
                        'author': ticket['reporter'] # not 100% accurate...
                        })
        data.update({'title': _("Ticket History"),
                     'resource': ticket.resource,
                     'history': history})

        add_ctxtnav(req, _("Back to Ticket #%(num)s", num=ticket.id),
                           req.href.ticket(ticket.id))
        return 'history_view.html', data, None

    def _render_diff(self, req, ticket, data, text_fields):
        """Show differences between two versions of a ticket description.

        `text_fields` is optionally a list of fields of interest, that are
        considered for jumping to the next change.
        """
        new_version = int(req.args.get('version', 1))
        old_version = int(req.args.get('old_version', new_version))
        if old_version > new_version:
            old_version, new_version = new_version, old_version

        # get the list of versions having a description change
        history = self._get_history(req, ticket)
        changes = {}
        descriptions = []
        old_idx = new_idx = -1 # indexes in descriptions
        for change in history:
            version = change['version']
            changes[version] = change
            if any(f in text_fields for f in change['fields']):
                if old_version and version <= old_version:
                    old_idx = len(descriptions)
                if new_idx == -1 and new_version and version >= new_version:
                    new_idx = len(descriptions)
                descriptions.append((version, change))

        # determine precisely old and new versions
        if old_version == new_version:
            if new_idx >= 0:
                old_idx = new_idx - 1
        if old_idx >= 0:
            old_version, old_change = descriptions[old_idx]
        else:
            old_version, old_change = 0, None
        num_changes = new_idx - old_idx
        if new_idx >= 0:
            new_version, new_change = descriptions[new_idx]
        else:
            raise TracError(_("No differences to show"))

        tnew = ticket.resource(version=new_version)
        told = ticket.resource(version=old_version)

        req.perm(tnew).require('TICKET_VIEW')
        req.perm(told).require('TICKET_VIEW')

        # determine prev and next versions
        prev_version = old_version
        next_version = None
        if new_idx < len(descriptions) - 1:
            next_version = descriptions[new_idx+1][0]

        # -- old properties (old_ticket) and new properties (new_ticket)

        # assume a linear sequence of change numbers, starting at 1, with gaps
        def replay_changes(values, old_values, from_version, to_version):
            for version in range(from_version, to_version+1):
                if version in changes:
                    for k, v in changes[version]['fields'].iteritems():
                        values[k] = v['new']
                        if old_values is not None and k not in old_values:
                            old_values[k] = v['old']

        old_ticket = {}
        if old_version:
            replay_changes(old_ticket, None, 1, old_version)

        new_ticket = dict(old_ticket)
        replay_changes(new_ticket, old_ticket, old_version+1, new_version)

        field_labels = TicketSystem(self.env).get_ticket_field_labels()

        changes = []

        def version_info(t, field=None):
            path = _("Ticket #%(id)s", id=ticket.id)
            # TODO: field info should probably be part of the Resource as well
            if field:
                path = tag(path, Markup(' &ndash; '),
                           field_labels.get(field, field.capitalize()))
            if t.version:
                rev = _("Version %(num)s", num=t.version)
                shortrev = 'v%d' % t.version
            else:
                rev, shortrev = _("Initial Version"), _("initial")
            return {'path':  path, 'rev': rev, 'shortrev': shortrev,
                    'href': get_resource_url(self.env, t, req.href)}

        # -- prop changes
        props = []
        for k, v in new_ticket.iteritems():
            if k not in text_fields:
                old, new = old_ticket[k], new_ticket[k]
                if old != new:
                    label = field_labels.get(k, k.capitalize())
                    prop = {'name': label, 'field': k,
                            'old': {'name': label, 'value': old},
                            'new': {'name': label, 'value': new}}
                    rendered = self._render_property_diff(req, ticket, k,
                                                          old, new, tnew)
                    if rendered:
                        prop['diff'] = tag.li(
                            tag_("Property %(label)s %(rendered)s",
                                 label=tag.strong(label), rendered=rendered))
                    props.append(prop)
        changes.append({'props': props, 'diffs': [],
                        'new': version_info(tnew),
                        'old': version_info(told)})

        # -- text diffs
        diff_style, diff_options, diff_data = get_diff_options(req)
        diff_context = 3
        for option in diff_options:
            if option.startswith('-U'):
                diff_context = int(option[2:])
                break
        if diff_context < 0:
            diff_context = None

        for field in text_fields:
            old_text = old_ticket.get(field)
            old_text = old_text.splitlines() if old_text else []
            new_text = new_ticket.get(field)
            new_text = new_text.splitlines() if new_text else []
            diffs = diff_blocks(old_text, new_text, context=diff_context,
                                ignore_blank_lines='-B' in diff_options,
                                ignore_case='-i' in diff_options,
                                ignore_space_changes='-b' in diff_options)

            changes.append({'diffs': diffs, 'props': [], 'field': field,
                            'new': version_info(tnew, field),
                            'old': version_info(told, field)})

        # -- prev/up/next links
        if prev_version:
            add_link(req, 'prev', get_resource_url(self.env, ticket.resource,
                                                   req.href, action='diff',
                                                   version=prev_version),
                     _("Version %(num)s", num=prev_version))
        add_link(req, 'up', get_resource_url(self.env, ticket.resource,
                                             req.href, action='history'),
                 _("Ticket History"))
        if next_version:
            add_link(req, 'next', get_resource_url(self.env, ticket.resource,
                                                   req.href, action='diff',
                                                   version=next_version),
                     _("Version %(num)s", num=next_version))

        prevnext_nav(req, _("Previous Change"), _("Next Change"),
                     _("Ticket History"))
        add_stylesheet(req, 'common/css/diff.css')
        add_script(req, 'common/js/diff.js')

        data.update({
            'title': _("Ticket Diff"),
            'resource': ticket.resource,
            'old_version': old_version, 'new_version': new_version,
            'changes': changes, 'diff': diff_data,
            'num_changes': num_changes, 'change': new_change,
            'old_ticket': old_ticket, 'new_ticket': new_ticket,
            'longcol': '', 'shortcol': ''
        })

        return 'diff_view.html', data, None

    def _make_comment_url(self, req, ticket, cnum, version=None):
        return req.href.ticket(ticket.id,
                               cnum_hist=cnum if version is not None else None,
                               cversion=version) + '#comment:%d' % cnum

    def _get_comment_history(self, req, ticket, cnum):
        history = []
        for version, date, author, comment in ticket.get_comment_history(cnum):
            history.append({
                'version': version, 'date': date, 'author': author,
                'comment': _("''Initial version''") if version == 0 else '',
                'value': comment,
                'url': self._make_comment_url(req, ticket, cnum, version)
            })
        return history

    def _render_comment_history(self, req, ticket, data, cnum):
        """Extract the history for a ticket comment."""
        req.perm(ticket.resource).require('TICKET_VIEW')
        history = self._get_comment_history(req, ticket, cnum)
        history.reverse()
        url = self._make_comment_url(req, ticket, cnum)
        data.update({
            'title': _("Ticket Comment History"),
            'resource': ticket.resource,
            'name': _("Ticket #%(num)s, comment %(cnum)d",
                      num=ticket.id, cnum=cnum),
            'url': url,
            'diff_action': 'comment-diff', 'diff_args': [('cnum', cnum)],
            'history': history,
        })
        add_ctxtnav(req, _("Back to Ticket #%(num)s", num=ticket.id), url)
        return 'history_view.html', data, None

    def _render_comment_diff(self, req, ticket, data, cnum):
        """Show differences between two versions of a ticket comment."""
        req.perm(ticket.resource).require('TICKET_VIEW')
        new_version = int(req.args.get('version', 1))
        old_version = int(req.args.get('old_version', new_version))
        if old_version > new_version:
            old_version, new_version = new_version, old_version
        elif old_version == new_version:
            old_version = new_version - 1

        history = {}
        for change in self._get_comment_history(req, ticket, cnum):
            history[change['version']] = change

        def version_info(version):
            path = _("Ticket #%(num)s, comment %(cnum)d",
                     num=ticket.id, cnum=cnum)
            if version:
                rev = _("Version %(num)s", num=version)
                shortrev = 'v%d' % version
            else:
                rev, shortrev = _("Initial Version"), _("initial")
            return {'path':  path, 'rev': rev, 'shortrev': shortrev}

        diff_style, diff_options, diff_data = get_diff_options(req)
        diff_context = 3
        for option in diff_options:
            if option.startswith('-U'):
                diff_context = int(option[2:])
                break
        if diff_context < 0:
            diff_context = None

        def get_text(version):
            try:
                text = history[version]['value']
                return text.splitlines() if text else []
            except KeyError:
                raise ResourceNotFound(_("No version %(version)d for comment "
                                         "%(cnum)d on ticket #%(ticket)s",
                                         version=version, cnum=cnum,
                                         ticket=ticket.id))

        old_text = get_text(old_version)
        new_text = get_text(new_version)
        diffs = diff_blocks(old_text, new_text, context=diff_context,
                            ignore_blank_lines='-B' in diff_options,
                            ignore_case='-i' in diff_options,
                            ignore_space_changes='-b' in diff_options)

        changes = [{'diffs': diffs, 'props': [],
                    'new': version_info(new_version),
                    'old': version_info(old_version)}]

        # -- prev/up/next links
        prev_version = old_version
        next_version = None
        if new_version < len(history) - 1:
            next_version = new_version + 1

        if prev_version:
            url = req.href.ticket(ticket.id, cnum=cnum, action='comment-diff',
                                  version=prev_version)
            add_link(req, 'prev', url, _("Version %(num)s", num=prev_version))
        add_link(req, 'up', req.href.ticket(ticket.id, cnum=cnum,
                                            action='comment-history'),
                 _("Ticket Comment History"))
        if next_version:
            url = req.href.ticket(ticket.id, cnum=cnum, action='comment-diff',
                                  version=next_version)
            add_link(req, 'next', url, _("Version %(num)s", num=next_version))

        prevnext_nav(req, _("Previous Change"), _("Next Change"),
                     _("Ticket Comment History"))
        add_stylesheet(req, 'common/css/diff.css')
        add_script(req, 'common/js/diff.js')

        data.update({
            'title': _("Ticket Comment Diff"),
            'resource': ticket.resource,
            'name': _("Ticket #%(num)s, comment %(cnum)d",
                      num=ticket.id, cnum=cnum),
            'url': self._make_comment_url(req, ticket, cnum),
            'old_url': self._make_comment_url(req, ticket, cnum, old_version),
            'new_url': self._make_comment_url(req, ticket, cnum, new_version),
            'diff_url': req.href.ticket(ticket.id, cnum=cnum,
                                        action='comment-diff',
                                        version=new_version),
            'diff_action': 'comment-diff', 'diff_args': [('cnum', cnum)],
            'old_version': old_version, 'new_version': new_version,
            'changes': changes, 'diff': diff_data,
            'num_changes': new_version - old_version,
            'change': history[new_version],
            'ticket': ticket, 'cnum': cnum,
            'longcol': '', 'shortcol': ''
        })

        return 'diff_view.html', data, None

    def export_csv(self, req, ticket, sep=',', mimetype='text/plain'):
        # FIXME: consider dumping history of changes here as well
        #        as one row of output doesn't seem to be terribly useful...
        fields = [f for f in ticket.fields
                  if f['name'] not in ('time', 'changetime')]
        content = StringIO()
        content.write('\xef\xbb\xbf')   # BOM
        writer = csv.writer(content, delimiter=sep, quoting=csv.QUOTE_MINIMAL)
        writer.writerow(['id'] + [unicode(f['name']) for f in fields])

        context = web_context(req, ticket.resource)
        cols = [unicode(ticket.id)]
        for f in fields:
            name = f['name']
            value = ticket.values.get(name, '')
            if name in ('cc', 'reporter'):
                value = Chrome(self.env).format_emails(context, value, ' ')
            elif name in ticket.time_fields:
                value = format_datetime(value, '%Y-%m-%d %H:%M:%S',
                                        tzinfo=req.tz)
            cols.append(value.encode('utf-8'))
        writer.writerow(cols)
        return (content.getvalue(), '%s;charset=utf-8' % mimetype)

    def export_rss(self, req, ticket):
        changes = []
        change_summary = {}

        for change in self.rendered_changelog_entries(req, ticket):
            changes.append(change)
            # compute a change summary
            change_summary = {}
            # wikify comment
            if 'comment' in change:
                change_summary['added'] = ['comment']
            for field, values in change['fields'].iteritems():
                if field == 'description':
                    change_summary.setdefault('changed', []).append(field)
                else:
                    chg = 'changed'
                    if not values['old']:
                        chg = 'set'
                    elif not values['new']:
                        chg = 'deleted'
                    change_summary.setdefault(chg, []).append(field)
            c = change_summary.get('changed')
            if c:
                c = ngettext("%(labels)s changed", "%(labels)s changed",
                             len(c), labels=', '.join(c))
            s = change_summary.get('set')
            if s:
                s = ngettext("%(labels)s set", "%(labels)s set",
                             len(s), labels=', '.join(s))
            d = change_summary.get('deleted')
            if d:
                d = ngettext("%(labels)s deleted", "%(labels)s deleted",
                             len(d), labels=', '.join(d))
            change['title'] = _("; ").join(g for g in [c, s, d] if g)

        data = self._prepare_data(req, ticket, absurls=True)
        data['changes'] = changes
        output = Chrome(self.env).render_template(req, 'ticket.rss', data,
                                                  'application/rss+xml')
        return output, 'application/rss+xml'

    # Ticket validation and changes

    def _validate_ticket(self, req, ticket, force_collision_check=False):
        valid = True
        resource = ticket.resource

        # If the ticket has been changed, check the proper permissions
        if ticket.exists and ticket._old:
            # Status and resolution can be modified by the workflow even
            # without having TICKET_CHGPROP
            changed = set(ticket._old) - set(['status', 'resolution'])
            if 'description' in changed \
                    and 'TICKET_EDIT_DESCRIPTION' not in req.perm(resource):
                add_warning(req, _("No permission to edit the ticket "
                                   "description."))
                valid = False
            changed.discard('description')
            if 'reporter' in changed \
                    and 'TICKET_ADMIN' not in req.perm(resource):
                add_warning(req, _("No permission to change the ticket "
                                   "reporter."))
                valid = False
            changed.discard('reporter')
            if changed and 'TICKET_CHGPROP' not in req.perm(resource):
                add_warning(req, _("No permission to change ticket fields."))
                valid = False
            if not valid:
                ticket.values.update(ticket._old)

        comment = req.args.get('comment')
        if comment:
            if not ('TICKET_CHGPROP' in req.perm(resource) or \
                    'TICKET_APPEND' in req.perm(resource)):
                add_warning(req, _("No permissions to add a comment."))
                valid = False

        # Mid air collision?
        if ticket.exists and (ticket._old or comment or force_collision_check):
            changetime = ticket['changetime']
            if req.args.get('view_time') != str(to_utimestamp(changetime)):
                add_warning(req, _("Sorry, can not save your changes. "
                              "This ticket has been modified by someone else "
                              "since you started"))
                valid = False

        # Always require a summary
        if not ticket['summary']:
            add_warning(req, _("Tickets must contain a summary."))
            valid = False

        # Always validate for known values
        for field in ticket.fields:
            if 'options' not in field:
                continue
            if field['name'] == 'status':
                continue
            name = field['name']
            if name in ticket.values and name in ticket._old:
                value = ticket[name]
                if value:
                    if value not in field['options']:
                        add_warning(req, '"%s" is not a valid value for '
                                    'the %s field.' % (value, name))
                        valid = False
                elif not field.get('optional', False):
                    add_warning(req, _("field %(name)s must be set",
                                       name=name))
                    valid = False

        # Validate description length
        if len(ticket['description'] or '') > self.max_description_size:
            add_warning(req, _("Ticket description is too long (must be less "
                               "than %(num)s characters)",
                               num=self.max_description_size))
            valid = False

        # Validate comment length
        if len(comment or '') > self.max_comment_size:
            add_warning(req, _("Ticket comment is too long (must be less "
                               "than %(num)s characters)",
                               num=self.max_comment_size))
            valid = False

        # Validate comment numbering
        try:
            # replyto must be 'description' or a number
            replyto = req.args.get('replyto')
            if replyto != 'description':
                int(replyto or 0)
        except ValueError:
            # Shouldn't happen in "normal" circumstances, hence not a warning
            raise InvalidTicket(_("Invalid comment threading identifier"))

        # Custom validation rules
        for manipulator in self.ticket_manipulators:
            for field, message in manipulator.validate_ticket(req, ticket):
                valid = False
                if field:
                    add_warning(req, _("The ticket field '%(field)s' is "
                                       "invalid: %(message)s",
                                       field=field, message=message))
                else:
                    add_warning(req, message)
        return valid

    def _do_create(self, req, ticket):
        ticket.insert()

        # Notify
        try:
            tn = TicketNotifyEmail(self.env)
            tn.notify(ticket, newticket=True)
        except Exception, e:
            self.log.error("Failure sending notification on creation of "
                    "ticket #%s: %s", ticket.id, exception_to_unicode(e))
            add_warning(req, _("The ticket has been created, but an error "
                               "occurred while sending notifications: "
                               "%(message)s", message=to_unicode(e)))

        # Redirect the user to the newly created ticket or add attachment
        ticketref=tag.a('#', ticket.id, href=req.href.ticket(ticket.id))
        if 'attachment' in req.args:
            add_notice(req, tag_("The ticket %(ticketref)s has been created. "
                                 "You can now attach the desired files.",
                                 ticketref=ticketref))
            req.redirect(req.href.attachment('ticket', ticket.id,
                                             action='new'))
        if 'TICKET_VIEW' not in req.perm('ticket', ticket.id):
            add_notice(req, tag_("The ticket %(ticketref)s has been created, "
                                 "but you don't have permission to view it.",
                                 ticketref=ticketref))
            req.redirect(req.href.newticket())
        req.redirect(req.href.ticket(ticket.id))

    def _do_save(self, req, ticket, action):
        # Save the action controllers we need to call side-effects for before
        # we save the changes to the ticket.
        controllers = list(self._get_action_controllers(req, ticket, action))

        # -- Save changes

        fragment = ''
        now = datetime.now(utc)
        cnum = ticket.save_changes(get_reporter_id(req, 'author'),
                                   req.args.get('comment'), when=now,
                                   replyto=req.args.get('replyto'))
        if cnum:
            fragment = '#comment:%d' % cnum
            try:
                tn = TicketNotifyEmail(self.env)
                tn.notify(ticket, newticket=False, modtime=now)
            except Exception, e:
                self.log.error("Failure sending notification on change to "
                        "ticket #%s: %s", ticket.id, exception_to_unicode(e))
                # TRANSLATOR: The 'change' has been saved... (link)
                change = _('change')
                if fragment:
                    change = tag.a(change, href=fragment)
                add_warning(req, tag_("The %(change)s has been saved, but an "
                                      "error occurred while sending "
                                      "notifications: %(message)s",
                                      change=change, message=to_unicode(e)))
                fragment = ''

        # After saving the changes, apply the side-effects.
        for controller in controllers:
            self.log.debug("Side effect for %s" %
                           controller.__class__.__name__)
            controller.apply_action_side_effects(req, ticket, action)

        req.redirect(req.href.ticket(ticket.id) + fragment)

    def get_ticket_changes(self, req, ticket, selected_action):
        """Returns a dictionary of field changes.

        The field changes are represented as:
        `{field: {'old': oldvalue, 'new': newvalue, 'by': what}, ...}`
        """
        field_labels = TicketSystem(self.env).get_ticket_field_labels()
        field_changes = {}
        def store_change(field, old, new, author):
            field_changes[field] = {'old': old, 'new': new, 'by': author,
                                    'label': field_labels.get(field, field)}
        # Start with user changes
        for field, value in ticket._old.iteritems():
            store_change(field, value or '', ticket[field], 'user')

        # Apply controller changes corresponding to the selected action
        problems = []
        for controller in self._get_action_controllers(req, ticket,
                                                       selected_action):
            cname = controller.__class__.__name__
            action_changes = controller.get_ticket_changes(req, ticket,
                                                           selected_action)
            for key in action_changes.keys():
                old = ticket[key]
                new = action_changes[key]
                # Check for conflicting changes between controllers
                if key in field_changes:
                    last_new = field_changes[key]['new']
                    last_by = field_changes[key]['by']
                    if last_new != new and last_by:
                        problems.append('%s changed "%s" to "%s", '
                                        'but %s changed it to "%s".' %
                                        (cname, key, new, last_by, last_new))
                store_change(key, old, new, cname)

        # Detect non-changes
        for key, item in field_changes.items():
            if item['old'] == item['new']:
                del field_changes[key]
        return field_changes, problems

    def _apply_ticket_changes(self, ticket, field_changes):
        """Apply the changes obtained from `get_ticket_changes` to the ticket
        """
        for key in field_changes:
            ticket[key] = field_changes[key]['new']

    def _query_link(self, req, name, value, text=None):
        """Return a link to /query with the appropriate name and value"""
        default_query = self.ticketlink_query.lstrip('?')
        args = arg_list_to_args(parse_arg_list(default_query))
        args[name] = value
        if name == 'resolution':
            args['status'] = 'closed'
        return tag.a(text or value, href=req.href.query(args))

    def _query_link_words(self, context, name, value):
        """Splits a list of words and makes a query link to each separately"""
        if not isinstance(value, basestring): # None or other non-splitable
            return value
        default_query = self.ticketlink_query.startswith('?') and \
                        self.ticketlink_query[1:] or self.ticketlink_query
        args = arg_list_to_args(parse_arg_list(default_query))
        items = []
        for i, word in enumerate(re.split(r'([;,\s]+)', value)):
            if i % 2:
                items.append(word.strip() + ' ')
            elif word:
                rendered = name != 'cc' and word \
                           or Chrome(self.env).format_emails(context, word)
                if rendered == word:
                    word_args = args.copy()
                    word_args[name] = '~' + word
                    items.append(tag.a(word,
                                       href=context.href.query(word_args)))
                else:
                    items.append(rendered)
        return tag(items)

    def _prepare_fields(self, req, ticket, field_changes=None):
        context = web_context(req, ticket.resource)
        fields = []
        owner_field = None
        for field in ticket.fields:
            name = field['name']
            type_ = field['type']

            # enable a link to custom query for all choice fields
            if type_ not in ['text', 'textarea']:
                field['rendered'] = self._query_link(req, name, ticket[name])

            # per field settings
            if name in ('summary', 'reporter', 'description', 'status',
                        'resolution', 'time', 'changetime'):
                field['skip'] = True
            elif name == 'owner':
                TicketSystem(self.env).eventually_restrict_owner(field, ticket)
                type_ = field['type']
                field['skip'] = True
                if not ticket.exists:
                    field['label'] = _("Owner")
                    if 'TICKET_MODIFY' in req.perm(ticket.resource):
                        field['skip'] = False
                        owner_field = field
            elif name == 'milestone':
                milestones = [Milestone(self.env, opt)
                              for opt in field['options']]
                milestones = [m for m in milestones
                              if 'MILESTONE_VIEW' in req.perm(m.resource)]
                groups = group_milestones(milestones, ticket.exists
                    and 'TICKET_ADMIN' in req.perm(ticket.resource))
                field['options'] = []
                field['optgroups'] = [
                    {'label': label, 'options': [m.name for m in milestones]}
                    for (label, milestones) in groups]
                milestone = Resource('milestone', ticket[name])
                field['rendered'] = render_resource_link(self.env, context,
                                                         milestone, 'compact')
            elif name == 'cc':
                cc_changed = field_changes is not None and 'cc' in field_changes
                if ticket.exists and \
                        'TICKET_EDIT_CC' not in req.perm(ticket.resource):
                    cc = ticket._old.get('cc', ticket['cc'])
                    cc_action, cc_entry, cc_list = self._toggle_cc(req, cc)
                    cc_update = 'cc_update' in req.args \
                                and 'revert_cc' not in req.args
                    field['edit_label'] = {
                            'add': _("Add to Cc"),
                            'remove': _("Remove from Cc"),
                            '': _("Add/Remove from Cc")}[cc_action]
                    field['cc_entry'] = cc_entry or _("<Author field>")
                    field['cc_update'] = cc_update or None
                    if cc_changed:
                        field_changes['cc']['cc_update'] = cc_update
                if cc_changed:
                    # normalize the new CC: list; also remove the
                    # change altogether if there's no real change
                    old_cc_list = self._cc_list(field_changes['cc']['old'])
                    new_cc_list = self._cc_list(field_changes['cc']['new']
                                                .replace(' ', ','))
                    if new_cc_list == old_cc_list:
                        del field_changes['cc']
                    else:
                        field_changes['cc']['new'] = ','.join(new_cc_list)

            # per type settings
            if type_ in ('radio', 'select'):
                if ticket.exists:
                    value = ticket.values.get(name)
                    options = field['options']
                    optgroups = []
                    for x in field.get('optgroups', []):
                        optgroups.extend(x['options'])
                    if value and \
                        (not value in options and \
                         not value in optgroups):
                        # Current ticket value must be visible,
                        # even if it's not among the possible values
                        options.append(value)
            elif type_ == 'checkbox':
                value = ticket.values.get(name)
                if value in ('1', '0'):
                    field['rendered'] = self._query_link(req, name, value,
                                _("yes") if value == '1' else _("no"))
            elif type_ == 'text':
                if field.get('format') == 'wiki':
                    field['rendered'] = format_to_oneliner(self.env, context,
                                                           ticket[name])
                elif field.get('format') == 'reference':
                    field['rendered'] = self._query_link(req, name,
                                                         ticket[name])
                elif field.get('format') == 'list':
                    field['rendered'] = self._query_link_words(context, name,
                                                               ticket[name])
            elif type_ == 'textarea':
                if field.get('format') == 'wiki':
                    field['rendered'] = \
                        format_to_html(self.env, context, ticket[name],
                                escape_newlines=self.must_preserve_newlines)

            # ensure sane defaults
            field.setdefault('optional', False)
            field.setdefault('options', [])
            field.setdefault('skip', False)
            fields.append(field)

        # Move owner field to end when shown
        if owner_field is not None:
            fields.remove(owner_field)
            fields.append(owner_field)
        return fields

    def _insert_ticket_data(self, req, ticket, data, author_id, field_changes):
        """Insert ticket data into the template `data`"""
        replyto = req.args.get('replyto')
        data['replyto'] = replyto
        data['version'] = ticket.resource.version
        data['description_change'] = None

        data['author_id'] = author_id

        # -- Ticket fields

        fields = self._prepare_fields(req, ticket, field_changes)
        fields_map = dict((field['name'], i) for i, field in enumerate(fields))

        # -- Ticket Change History

        def quote_original(author, original, link):
            if 'comment' not in req.args: # i.e. the comment was not yet edited
                data['comment'] = '\n'.join(
                    ["Replying to [%s %s]:" % (link,
                                        obfuscate_email_address(author))] +
                    ["> %s" % line for line in original.splitlines()] + [''])

        if replyto == 'description':
            quote_original(ticket['reporter'], ticket['description'],
                           'ticket:%d' % ticket.id)
        values = {}
        replies = {}
        changes = []
        cnum = 0
        skip = False
        start_time = data.get('start_time', ticket['changetime'])
        conflicts = set()
        for change in self.rendered_changelog_entries(req, ticket):
            # change['permanent'] is false for attachment changes; true for
            # other changes.
            if change['permanent']:
                cnum = change['cnum']
                if ticket.resource.version is not None and \
                       cnum > ticket.resource.version:
                    # Retrieve initial ticket values from later changes
                    for k, v in change['fields'].iteritems():
                        if k not in values:
                            values[k] = v['old']
                    skip = True
                else:
                    # keep track of replies threading
                    if 'replyto' in change:
                        replies.setdefault(change['replyto'], []).append(cnum)
                    # eventually cite the replied to comment
                    if replyto == str(cnum):
                        quote_original(change['author'], change['comment'],
                                       'comment:%s' % replyto)
                    if ticket.resource.version:
                        # Override ticket value by current changes
                        for k, v in change['fields'].iteritems():
                            values[k] = v['new']
                    if 'description' in change['fields']:
                        data['description_change'] = change
                if change['date'] > start_time:
                    conflicts.update(change['fields'])
            if not skip:
                changes.append(change)

        if ticket.resource.version is not None:
            ticket.values.update(values)

        # -- Workflow support

        selected_action = req.args.get('action')

        # retrieve close time from changes
        closetime = None
        for c in changes:
            s = c['fields'].get('status')
            if s:
                closetime = c['date'] if s['new'] == 'closed' else None

        # action_controls is an ordered list of "renders" tuples, where
        # renders is a list of (action_key, label, widgets, hints) representing
        # the user interface for each action
        action_controls = []
        sorted_actions = TicketSystem(self.env).get_available_actions(req,
                                                                      ticket)
        for action in sorted_actions:
            first_label = None
            hints = []
            widgets = []
            for controller in self._get_action_controllers(req, ticket,
                                                           action):
                label, widget, hint = controller.render_ticket_action_control(
                    req, ticket, action)
                if not first_label:
                    first_label = label
                widgets.append(widget)
                hints.append(hint)
            action_controls.append((action, first_label, tag(widgets), hints))

        # The default action is the first in the action_controls list.
        if not selected_action:
            if action_controls:
                selected_action = action_controls[0][0]

        # Insert change preview
        change_preview = {
            'author': author_id, 'fields': field_changes, 'preview': True,
            'comment': req.args.get('comment', data.get('comment')),
            'comment_history': {},
        }
        replyto = req.args.get('replyto')
        if replyto:
            change_preview['replyto'] = replyto
        if req.method == 'POST':
            self._apply_ticket_changes(ticket, field_changes)
            self._render_property_changes(req, ticket, field_changes)

        if ticket.resource.version is not None: ### FIXME
            ticket.values.update(values)

        context = web_context(req, ticket.resource)

        # Display the owner and reporter links when not obfuscated
        chrome = Chrome(self.env)
        for user in 'reporter', 'owner':
            if chrome.format_author(req, ticket[user]) == ticket[user]:
                data['%s_link' % user] = self._query_link(req, user,
                                                          ticket[user])
        data.update({
            'context': context, 'conflicts': conflicts,
            'fields': fields, 'fields_map': fields_map,
            'changes': changes, 'replies': replies,
            'attachments': AttachmentModule(self.env).attachment_data(context),
            'action_controls': action_controls, 'action': selected_action,
            'change_preview': change_preview, 'closetime': closetime,
        })

    def rendered_changelog_entries(self, req, ticket, when=None):
        """Iterate on changelog entries, consolidating related changes
        in a `dict` object.
        """
        attachment_realm = ticket.resource.child('attachment')
        for group in self.grouped_changelog_entries(ticket, when=when):
            t = ticket.resource(version=group.get('cnum', None))
            if 'TICKET_VIEW' in req.perm(t):
                self._render_property_changes(req, ticket, group['fields'], t)
                if 'attachment' in group['fields']:
                    filename = group['fields']['attachment']['new']
                    attachment = attachment_realm(id=filename)
                    if 'ATTACHMENT_VIEW' not in req.perm(attachment):
                        del group['fields']['attachment']
                        if not group['fields']:
                            continue
                yield group

    def _render_property_changes(self, req, ticket, fields, resource_new=None):
        for field, changes in fields.iteritems():
            new, old = changes['new'], changes['old']
            rendered = self._render_property_diff(req, ticket, field, old, new,
                                                  resource_new)
            if rendered:
                changes['rendered'] = rendered

    def _render_property_diff(self, req, ticket, field, old, new,
                              resource_new=None):
        rendered = None
        old_list, new_list = None, None
        render_elt = lambda x: x
        sep = ', '

        # per type special rendering of diffs
        field_info = {}
        for f in ticket.fields:
            if f['name'] == field:
                field_info = f
                break
        type_ = field_info.get('type')
        if type_ == 'checkbox':
            rendered = _("set") if new == '1' else _("unset")
        elif type_ == 'textarea':
            if not resource_new:
                rendered = _("modified")
            else:
                href = get_resource_url(self.env, resource_new, req.href,
                                        action='diff')
                # TRANSLATOR: modified ('diff') (link)
                diff = tag.a(_("diff"), href=href)
                rendered = tag_("modified (%(diff)s)", diff=diff)
        elif type_ == 'text' and field_info.get('format') == 'list':
            old_list = re.split(r'[;,\s]+', old) if old else []
            new_list = re.split(r'[;,\s]+', new) if new else []
            sep = ' '

        # per name special rendering of diffs
        if field == 'cc':
            old_list, new_list = self._cc_list(old), self._cc_list(new)
            if not (Chrome(self.env).show_email_addresses or
                    'EMAIL_VIEW' in req.perm(resource_new or ticket.resource)):
                render_elt = obfuscate_email_address
        if (old_list, new_list) != (None, None):
            added = [tag.em(render_elt(x)) for x in new_list
                     if x not in old_list]
            remvd = [tag.em(render_elt(x)) for x in old_list
                     if x not in new_list]
            added = added and tagn_("%(items)s added", "%(items)s added",
                                    len(added), items=separated(added, sep))
            remvd = remvd and tagn_("%(items)s removed", "%(items)s removed",
                                    len(remvd), items=separated(remvd, sep))
            if added or remvd:
                rendered = tag(added, added and remvd and _("; "), remvd)
        if field in ('reporter', 'owner'):
            if not (Chrome(self.env).show_email_addresses or
                    'EMAIL_VIEW' in req.perm(resource_new or ticket.resource)):
                old = obfuscate_email_address(old)
                new = obfuscate_email_address(new)
            if old and not new:
                rendered = tag_("%(value)s deleted", value=tag.em(old))
            elif new and not old:
                rendered = tag_("set to %(value)s", value=tag.em(new))
            elif old and new:
                rendered = tag_("changed from %(old)s to %(new)s",
                                old=tag.em(old), new=tag.em(new))
        return rendered

    def grouped_changelog_entries(self, ticket, db=None, when=None):
        """Iterate on changelog entries, consolidating related changes
        in a `dict` object.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        field_labels = TicketSystem(self.env).get_ticket_field_labels()
        changelog = ticket.get_changelog(when=when)
        autonum = 0 # used for "root" numbers
        last_uid = current = None
        for date, author, field, old, new, permanent in changelog:
            uid = (date,) if permanent else (date, author)
            if uid != last_uid:
                if current:
                    last_comment = comment_history[max(comment_history)]
                    last_comment['comment'] = current['comment']
                    yield current
                last_uid = uid
                comment_history = {0: {'date': date}}
                current = {'date': date, 'fields': {},
                           'permanent': permanent, 'comment': '',
                           'comment_history': comment_history}
                if permanent and not when:
                    autonum += 1
                    current['cnum'] = autonum
            # some common processing for fields
            if not field.startswith('_'):
                current.setdefault('author', author)
                comment_history[0].setdefault('author', author)
            if field == 'comment':
                current['comment'] = new
                # Always take the author from the comment field if available
                current['author'] = comment_history[0]['author'] = author
                if old:
                    if '.' in old: # retrieve parent.child relationship
                        parent_num, this_num = old.split('.', 1)
                        current['replyto'] = parent_num
                    else:
                        this_num = old
                    current['cnum'] = autonum = int(this_num)
            elif field.startswith('_comment'):      # Comment edits
                rev = int(field[8:])
                comment_history.setdefault(rev, {}).update({'comment': old})
                comment_history.setdefault(rev + 1, {}).update(
                        {'author': author, 'date': from_utimestamp(long(new))})
            elif (old or new) and old != new:
                current['fields'][field] = {
                    'old': old, 'new': new,
                    'label': field_labels.get(field, field)}
        if current:
            last_comment = comment_history[max(comment_history)]
            last_comment['comment'] = current['comment']
            yield current

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005-2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from trac.core import *


class ITimelineEventProvider(Interface):
    """Extension point interface for adding sources for timed events to the
    timeline.
    """

    def get_timeline_filters(req):
        """Return a list of filters that this event provider supports.

        Each filter must be a (name, label) tuple, where `name` is the internal
        name, and `label` is a human-readable name for display.

        Optionally, the tuple can contain a third element, `checked`.
        If `checked` is omitted or True, the filter is active by default,
        otherwise it will be inactive.
        """

    def get_timeline_events(req, start, stop, filters):
        """Return a list of events in the time range given by the `start` and
        `stop` parameters.

        The `filters` parameters is a list of the enabled filters, each item
        being the name of the tuples returned by `get_timeline_filters`.

        Since 0.11, the events are `(kind, date, author, data)` tuples,
        where `kind` is a string used for categorizing the event, `date`
        is a `datetime` object, `author` is a string and `data` is some
        private data that the component will reuse when rendering the event.

        When the event has been created indirectly by another module,
        like this happens when calling `AttachmentModule.get_timeline_events()`
        the tuple can also specify explicitly the provider by returning tuples
        of the following form: `(kind, date, author, data, provider)`.

        Before version 0.11,  the events returned by this function used to
        be tuples of the form `(kind, href, title, date, author, markup)`.
        This is still supported but less flexible, as `href`, `title` and
        `markup` are not context dependent.
        """

    def render_timeline_event(context, field, event):
        """Display the title of the event in the given context.

        :param context: the `RenderingContext` object that can be used for
                        rendering
        :param field: what specific part information from the event should
                      be rendered: can be the 'title', the 'description' or
                      the 'url'
        :param event: the event tuple, as returned by `get_timeline_events`
        """



########NEW FILE########
__FILENAME__ = functional
#!/usr/bin/python
from trac.tests.functional import *


class RegressionTestRev5883(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of the timeline fix in r5883
        From Tim:
        the issue was that event.markup was never being output anywhere, so
        you actually have to render the template with a wiki modification
        and see if '(diff)' shows up as the text in a link
        also note that (diff) should _not_ show up for a wiki creation
        """
        pagename = random_unique_camel()
        self._tester.create_wiki_page(pagename)
        self._tester.go_to_timeline()
        tc.find(pagename)
        tc.notfind(pagename + '.*diff</a>\\)')
        self._tester.go_to_wiki(pagename)
        tc.formvalue('modifypage', 'action', 'edit')
        tc.submit()
        tc.find('Editing ' + pagename)
        tc.formvalue('edit', 'text', random_page())
        tc.formvalue('edit', 'comment', random_sentence())
        tc.submit('save')
        self._tester.go_to_timeline()
        tc.find(pagename + '.*diff</a>\\)')


def functionalSuite(suite=None):
    if not suite:
        import trac.tests.functional.testcases
        suite = trac.tests.functional.testcases.functionalSuite()
    suite.addTest(RegressionTestRev5883())
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005-2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from datetime import datetime, timedelta
import pkg_resources
import re

from genshi.builder import tag

from trac.config import IntOption, BoolOption
from trac.core import *
from trac.perm import IPermissionRequestor
from trac.timeline.api import ITimelineEventProvider
from trac.util import as_int
from trac.util.datefmt import format_date, format_datetime, format_time, \
                              parse_date, to_utimestamp, to_datetime, utc, \
                              pretty_timedelta, user_time
from trac.util.text import exception_to_unicode, to_unicode
from trac.util.translation import _, tag_
from trac.web import IRequestHandler, IRequestFilter
from trac.web.chrome import (Chrome, INavigationContributor, ITemplateProvider,
                             add_link, add_stylesheet, auth_link, prevnext_nav,
                             web_context)
from trac.wiki.api import IWikiSyntaxProvider
from trac.wiki.formatter import concat_path_query_fragment, \
                                split_url_into_path_query_fragment


class TimelineModule(Component):

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
               IRequestFilter, ITemplateProvider, IWikiSyntaxProvider)

    event_providers = ExtensionPoint(ITimelineEventProvider)

    default_daysback = IntOption('timeline', 'default_daysback', 30,
        """Default number of days displayed in the Timeline, in days.
        (''since 0.9.'')""")

    max_daysback = IntOption('timeline', 'max_daysback', 90,
        """Maximum number of days (-1 for unlimited) displayable in the
        Timeline. (''since 0.11'')""")

    abbreviated_messages = BoolOption('timeline', 'abbreviated_messages',
                                      True,
        """Whether wiki-formatted event messages should be truncated or not.

        This only affects the default rendering, and can be overriden by
        specific event providers, see their own documentation.
        (''Since 0.11'')""")

    _authors_pattern = re.compile(r'(-)?(?:"([^"]*)"|\'([^\']*)\'|([^\s]+))')

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'timeline'

    def get_navigation_items(self, req):
        if 'TIMELINE_VIEW' in req.perm:
            yield ('mainnav', 'timeline',
                   tag.a(_("Timeline"), href=req.href.timeline(), accesskey=2))

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['TIMELINE_VIEW']

    # IRequestHandler methods

    def match_request(self, req):
        return req.path_info == '/timeline'

    def process_request(self, req):
        req.perm.assert_permission('TIMELINE_VIEW')

        format = req.args.get('format')
        maxrows = int(req.args.get('max', 50 if format == 'rss' else 0))
        lastvisit = int(req.session.get('timeline.lastvisit', '0'))

        # indication of new events is unchanged when form is updated by user
        revisit = any(a in req.args for a in ['update', 'from', 'daysback',
                                              'author'])
        if revisit:
            lastvisit = int(req.session.get('timeline.nextlastvisit',
                                            lastvisit))

        # Parse the from date and adjust the timestamp to the last second of
        # the day
        fromdate = today = datetime.now(req.tz)
        yesterday = to_datetime(today.replace(tzinfo=None) - timedelta(days=1),
                                req.tz)
        precisedate = precision = None
        if 'from' in req.args:
            # Acquire from date only from non-blank input
            reqfromdate = req.args['from'].strip()
            if reqfromdate:
                precisedate = user_time(req, parse_date, reqfromdate)
                fromdate = precisedate.astimezone(req.tz)
            precision = req.args.get('precision', '')
            if precision.startswith('second'):
                precision = timedelta(seconds=1)
            elif precision.startswith('minute'):
                precision = timedelta(minutes=1)
            elif precision.startswith('hour'):
                precision = timedelta(hours=1)
            else:
                precision = None
        fromdate = to_datetime(datetime(fromdate.year, fromdate.month,
                                        fromdate.day, 23, 59, 59, 999999),
                               req.tz)

        daysback = as_int(req.args.get('daysback'),
                          90 if format == 'rss' else None)
        if daysback is None:
            daysback = as_int(req.session.get('timeline.daysback'), None)
        if daysback is None:
            daysback = self.default_daysback
        daysback = max(0, daysback)
        if self.max_daysback >= 0:
            daysback = min(self.max_daysback, daysback)

        authors = req.args.get('authors')
        if authors is None and format != 'rss':
            authors = req.session.get('timeline.authors')
        authors = (authors or '').strip()

        data = {'fromdate': fromdate, 'daysback': daysback,
                'authors': authors,
                'today': user_time(req, format_date, today),
                'yesterday': user_time(req, format_date, yesterday),
                'precisedate': precisedate, 'precision': precision,
                'events': [], 'filters': [],
                'abbreviated_messages': self.abbreviated_messages,
                'lastvisit': lastvisit}

        available_filters = []
        for event_provider in self.event_providers:
            available_filters += event_provider.get_timeline_filters(req) or []

        # check the request or session for enabled filters, or use default
        filters = [f[0] for f in available_filters if f[0] in req.args]
        if not filters and format != 'rss':
            filters = [f[0] for f in available_filters
                       if req.session.get('timeline.filter.' + f[0]) == '1']
        if not filters:
            filters = [f[0] for f in available_filters if len(f) == 2 or f[2]]

        # save the results of submitting the timeline form to the session
        if 'update' in req.args:
            for filter in available_filters:
                key = 'timeline.filter.%s' % filter[0]
                if filter[0] in req.args:
                    req.session[key] = '1'
                elif key in req.session:
                    del req.session[key]

        stop = fromdate
        start = to_datetime(stop.replace(tzinfo=None) - \
                                timedelta(days=daysback + 1),
                            req.tz)

        # create author include and exclude sets
        include = set()
        exclude = set()
        for match in self._authors_pattern.finditer(authors):
            name = (match.group(2) or match.group(3) or match.group(4)).lower()
            if match.group(1):
                exclude.add(name)
            else:
                include.add(name)

        # gather all events for the given period of time
        events = []
        for provider in self.event_providers:
            try:
                for event in provider.get_timeline_events(req, start, stop,
                                                          filters) or []:
                    # Check for 0.10 events
                    author = (event[2 if len(event) < 6 else 4] or '').lower()
                    if (not include or author in include) \
                       and not author in exclude:
                        events.append(self._event_data(provider, event))
            except Exception, e: # cope with a failure of that provider
                self._provider_failure(e, req, provider, filters,
                                       [f[0] for f in available_filters])

        # prepare sorted global list
        events = sorted(events, key=lambda e: e['date'], reverse=True)
        if maxrows:
            events = events[:maxrows]

        data['events'] = events

        if format == 'rss':
            data['email_map'] = Chrome(self.env).get_email_map()
            rss_context = web_context(req, absurls=True)
            rss_context.set_hints(wiki_flavor='html', shorten_lines=False)
            data['context'] = rss_context
            return 'timeline.rss', data, 'application/rss+xml'
        else:
            req.session.set('timeline.daysback', daysback,
                            self.default_daysback)
            req.session.set('timeline.authors', authors, '')
            # store lastvisit
            if events and not revisit:
                lastviewed = to_utimestamp(events[0]['date'])
                req.session['timeline.lastvisit'] = max(lastvisit, lastviewed)
                req.session['timeline.nextlastvisit'] = lastvisit
            html_context = web_context(req)
            html_context.set_hints(wiki_flavor='oneliner',
                                   shorten_lines=self.abbreviated_messages)
            data['context'] = html_context

        add_stylesheet(req, 'common/css/timeline.css')
        rss_href = req.href.timeline([(f, 'on') for f in filters],
                                     daysback=90, max=50, authors=authors,
                                     format='rss')
        add_link(req, 'alternate', auth_link(req, rss_href), _('RSS Feed'),
                 'application/rss+xml', 'rss')
        Chrome(self.env).add_jquery_ui(req)

        for filter_ in available_filters:
            data['filters'].append({'name': filter_[0], 'label': filter_[1],
                                    'enabled': filter_[0] in filters})

        # Navigation to the previous/next period of 'daysback' days
        previous_start = fromdate.replace(tzinfo=None) - \
                            timedelta(days=daysback + 1)
        previous_start = format_date(to_datetime(previous_start, req.tz),
                                     format='%Y-%m-%d', tzinfo=req.tz)
        add_link(req, 'prev', req.href.timeline(from_=previous_start,
                                                authors=authors,
                                                daysback=daysback),
                 _('Previous Period'))
        if today - fromdate > timedelta(days=0):
            next_start = fromdate.replace(tzinfo=None) + \
                            timedelta(days=daysback + 1)
            next_start = format_date(to_datetime(next_start, req.tz),
                                     format='%Y-%m-%d', tzinfo=req.tz)
            add_link(req, 'next', req.href.timeline(from_=next_start,
                                                    authors=authors,
                                                    daysback=daysback),
                     _('Next Period'))
        prevnext_nav(req, _('Previous Period'), _('Next Period'))

        return 'timeline.html', data, None

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        return [pkg_resources.resource_filename('trac.timeline', 'templates')]

    # IRequestFilter methods

    def pre_process_request(self, req, handler):
        return handler

    def post_process_request(self, req, template, data, content_type):
        if data:
            def pretty_dateinfo(date, format=None, dateonly=False):
                absolute = user_time(req, format_datetime, date)
                relative = pretty_timedelta(date)
                if not format:
                    format = req.session.get('dateinfo',
                                 Chrome(self.env).default_dateinfo_format)
                if format == 'absolute':
                    if dateonly:
                        label = absolute
                    elif req.lc_time == 'iso8601':
                        label = _("at %(iso8601)s", iso8601=absolute)
                    else:
                        label = _("on %(date)s at %(time)s",
                                  date=user_time(req, format_date, date),
                                  time=user_time(req, format_time, date))
                    title = _("See timeline %(relativetime)s ago",
                              relativetime=relative)
                else:
                    label = _("%(relativetime)s ago", relativetime=relative) \
                            if not dateonly else relative
                    title = _("See timeline at %(absolutetime)s",
                              absolutetime=absolute)
                return self.get_timeline_link(req, date, label,
                                              precision='second', title=title)
            def dateinfo(date):
                return pretty_dateinfo(date, format='relative', dateonly=True)
            data['pretty_dateinfo'] = pretty_dateinfo
            data['dateinfo'] = dateinfo
        return template, data, content_type

    # IWikiSyntaxProvider methods

    def get_wiki_syntax(self):
        return []

    def get_link_resolvers(self):
        def link_resolver(formatter, ns, target, label):
            path, query, fragment = split_url_into_path_query_fragment(target)
            precision = None
            time = path.split("T", 1)
            if len(time) > 1:
                time = time[1].split("Z")[0]
                if len(time) >= 6:
                    precision = 'seconds'
                elif len(time) >= 4:
                    precision = 'minutes'
                elif len(time) >= 2:
                    precision = 'hours'
            try:
                return self.get_timeline_link(formatter.req,
                                              parse_date(path, utc),
                                              label, precision, query, fragment)
            except TracError, e:
                return tag.a(label, title=to_unicode(e.message),
                             class_='timeline missing')
        yield ('timeline', link_resolver)

    # Public methods

    def get_timeline_link(self, req, date, label=None, precision='hours',
                          query=None, fragment=None, title=None):
        iso_date = format_datetime(date, 'iso8601', req.tz)
        href = req.href.timeline(from_=iso_date, precision=precision)
        return tag.a(label or iso_date, class_='timeline',
                     title=title or _("See timeline at %(absolutetime)s",
                                      absolutetime=iso_date),
                     href=concat_path_query_fragment(href, query, fragment))

    # Internal methods

    def _event_data(self, provider, event):
        """Compose the timeline event date from the event tuple and prepared
        provider methods"""
        if len(event) == 6: # 0.10 events
            kind, url, title, date, author, markup = event
            data = {'url': url, 'title': title, 'description': markup}
            render = lambda field, context: data.get(field)
        else: # 0.11 events
            if len(event) == 5: # with special provider
                kind, date, author, data, provider = event
            else:
                kind, date, author, data = event
            render = lambda field, context: \
                    provider.render_timeline_event(context, field, event)
        if not isinstance(date, datetime):
            date = datetime.fromtimestamp(date, utc)
        dateuid = to_utimestamp(date)
        return {'kind': kind, 'author': author, 'date': date,
                'dateuid': dateuid, 'render': render, 'event': event,
                'data': data, 'provider': provider}

    def _provider_failure(self, exc, req, ep, current_filters, all_filters):
        """Raise a TracError exception explaining the failure of a provider.

        At the same time, the message will contain a link to the timeline
        without the filters corresponding to the guilty event provider `ep`.
        """
        self.log.error('Timeline event provider failed: %s',
                       exception_to_unicode(exc, traceback=True))

        ep_kinds = dict((f[0], f[1])
                        for f in ep.get_timeline_filters(req) or [])
        ep_filters = set(ep_kinds.keys())
        current_filters = set(current_filters)
        other_filters = set(current_filters) - ep_filters
        if not other_filters:
            other_filters = set(all_filters) -  ep_filters
        args = [(a, req.args.get(a)) for a in ('from', 'format', 'max',
                                               'daysback')]
        href = req.href.timeline(args + [(f, 'on') for f in other_filters])
        # TRANSLATOR: ...want to see the 'other kinds of events' from... (link)
        other_events = tag.a(_('other kinds of events'), href=href)
        raise TracError(tag(
            tag.p(tag_("Event provider %(name)s failed for filters "
                       "%(kinds)s: ",
                       name=tag.tt(ep.__class__.__name__),
                       kinds=', '.join('"%s"' % ep_kinds[f] for f in
                                       current_filters & ep_filters)),
                  tag.b(exception_to_unicode(exc)), class_='message'),
            tag.p(tag_("You may want to see the %(other_events)s from the "
                       "Timeline or notify your Trac administrator about the "
                       "error (detailed information was written to the log).",
                       other_events=other_events))))

########NEW FILE########
__FILENAME__ = db10
sql = [
#-- Make the node_change table contain more information, and force a resync
"""DROP TABLE revision;""",
"""DROP TABLE node_change;""",
"""CREATE TABLE revision (
    rev             text PRIMARY KEY,
    time            integer,
    author          text,
    message         text
);""",
"""CREATE TABLE node_change (
    rev             text,
    path            text,
    kind            char(1), -- 'D' for directory, 'F' for file
    change          char(1),
    base_path       text,
    base_rev        text,
    UNIQUE(rev, path, change)
);"""
]

def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)
    print 'Please perform a "resync" after this upgrade.'

########NEW FILE########
__FILENAME__ = db11
sql = [
#-- Remove empty values from the milestone list
"""DELETE FROM milestone WHERE COALESCE(name,'')='';""",
#-- Add a description column to the version table, and remove unnamed versions
"""CREATE TEMPORARY TABLE version_old AS SELECT * FROM version;""",
"""DROP TABLE version;""",
"""CREATE TABLE version (
        name            text PRIMARY KEY,
        time            integer,
        description     text
);""",
"""INSERT INTO version(name,time,description)
    SELECT name,time,'' FROM version_old WHERE COALESCE(name,'')<>'';""",
#-- Add a description column to the component table, and remove unnamed components
"""CREATE TEMPORARY TABLE component_old AS SELECT * FROM component;""",
"""DROP TABLE component;""",
"""CREATE TABLE component (
        name            text PRIMARY KEY,
        owner           text,
        description     text
);""",
"""INSERT INTO component(name,owner,description)
    SELECT name,owner,'' FROM component_old WHERE COALESCE(name,'')<>'';""",
"""DROP TABLE version_old;""",
"""DROP TABLE component_old;"""
]

def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)

########NEW FILE########
__FILENAME__ = db12
sql = [
#-- Some anonymous session might have been left over
"""DELETE FROM session WHERE username='anonymous';""",
#-- Schema change: use an authenticated flag instead of separate sid/username
#-- columns
"""CREATE TEMPORARY TABLE session_old AS SELECT * FROM session;""",
"""DROP TABLE session;""",
"""CREATE TABLE session (
        sid             text,
        authenticated   int,
        var_name        text,
        var_value       text,
        UNIQUE(sid, var_name)
);""",
"""INSERT INTO session(sid,authenticated,var_name,var_value)
    SELECT DISTINCT sid,0,var_name,var_value FROM session_old
    WHERE sid IS NULL;""",
"""INSERT INTO session(sid,authenticated,var_name,var_value)
    SELECT DISTINCT username,1,var_name,var_value FROM session_old
    WHERE sid IS NULL;""",
"""DROP TABLE session_old;"""
]

def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)

########NEW FILE########
__FILENAME__ = db13
sql = [
#-- Add ticket_type to 'ticket', remove the unused 'url' column
"""CREATE TEMPORARY TABLE ticket_old AS SELECT * FROM ticket;""",
"""DROP TABLE ticket;""",
"""CREATE TABLE ticket (
        id              integer PRIMARY KEY,
        type            text,           -- the nature of the ticket
        time            integer,        -- the time it was created
        changetime      integer,
        component       text,
        severity        text,
        priority        text,
        owner           text,           -- who is this ticket assigned to
        reporter        text,
        cc              text,           -- email addresses to notify
        version         text,           --
        milestone       text,           --
        status          text,
        resolution      text,
        summary         text,           -- one-line summary
        description     text,           -- problem description (long)
        keywords        text
);""",
"""INSERT INTO ticket(id, type, time, changetime, component, severity, priority,
                   owner, reporter, cc, version, milestone, status, resolution,
                   summary, description, keywords)
  SELECT id, 'defect', time, changetime, component, severity, priority, owner,
         reporter, cc, version, milestone, status, resolution, summary,
         description, keywords FROM ticket_old
  WHERE COALESCE(severity,'') <> 'enhancement';""",
"""INSERT INTO ticket(id, type, time, changetime, component, severity, priority,
                   owner, reporter, cc, version, milestone, status, resolution,
                   summary, description, keywords)
  SELECT id, 'enhancement', time, changetime, component, 'normal', priority,
         owner, reporter, cc, version, milestone, status, resolution, summary,
         description, keywords FROM ticket_old
  WHERE severity = 'enhancement';""",
"""INSERT INTO enum (type, name, value) VALUES ('ticket_type', 'defect', '1');""",
"""INSERT INTO enum (type, name, value) VALUES ('ticket_type', 'enhancement', '2');""",
"""INSERT INTO enum (type, name, value) VALUES ('ticket_type', 'task', '3');""",
"""DELETE FROM enum WHERE type = 'severity' AND name = 'enhancement';""",
"""DROP TABLE ticket_old;""",
]

def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)

    # -- upgrade reports (involve a rename)
    cursor.execute("SELECT id,sql FROM report")
    reports = {}
    for id, rsql in cursor:
        reports[id] = rsql
    for id, rsql in reports.items():
        parts = rsql.split('ORDER BY', 1)
        ending = len(parts)>1 and 'ORDER BY'+parts[1] or ''
        cursor.execute("UPDATE report SET sql=%s WHERE id=%s",
                       (parts[0].replace('severity,',
                                         't.type AS type, severity,') + ending,
                        id))

########NEW FILE########
__FILENAME__ = db14
sql = [
"""CREATE TEMPORARY TABLE node_change_old AS SELECT * FROM node_change;""",
"""DROP TABLE node_change;""",
"""CREATE TABLE node_change (
    rev             text,
    path            text,
    kind            char(1),
    change          char(1),
    base_path       text,
    base_rev        text,
    UNIQUE(rev, path, change)
);""",
"""INSERT INTO node_change (rev,path,kind,change,base_path,base_rev)
    SELECT rev,path,kind,change,base_path,base_rev FROM node_change_old;""",
"""DROP TABLE node_change_old;"""
]

def do_upgrade(env, ver, cursor):
    # Wiki pages were accidentially created with the version number starting at
    # 0 instead of 1; This should fix that
    cursor.execute("SELECT name, version FROM wiki WHERE name IN "
                   "(SELECT name FROM wiki WHERE version=0) ORDER BY name,"
                   "version DESC")
    result = cursor.fetchall()
    if result:
        cursor.executemany("UPDATE wiki SET version=version+1 WHERE name=%s "
                           "and version=%s",
                           [tuple(row) for row in result])

    # Correct difference between db_default.py and upgrades/db10.py: The
    # 'change' was missing from the uniqueness constraint
    for s in sql:
        cursor.execute(s)

########NEW FILE########
__FILENAME__ = db15
from trac.db import Table, Column, Index, DatabaseManager

def do_upgrade(env, ver, cursor):
    cursor.execute("""
        CREATE TEMPORARY TABLE session_old AS SELECT * FROM session
        """)
    cursor.execute("DROP TABLE session")

    session_table = Table('session', key=('sid', 'authenticated', 'var_name'))[
        Column('sid'),
        Column('authenticated', type='int'),
        Column('var_name'),
        Column('var_value')]
    db_backend, _ = DatabaseManager(env).get_connector()
    for stmt in db_backend.to_sql(session_table):
        cursor.execute(stmt)

    cursor.execute("""
        INSERT INTO session (sid,authenticated,var_name,var_value)
        SELECT sid,authenticated,var_name,var_value FROM session_old
        """)
    cursor.execute("DROP TABLE session_old")

########NEW FILE########
__FILENAME__ = db16
from trac.db import Table, Column, Index

def do_upgrade(env, ver, cursor):
    # Add a few new indices to speed things up
    cursor.execute("CREATE INDEX wiki_time_idx ON wiki (time)")
    cursor.execute("CREATE INDEX revision_time_idx ON revision (time)")
    cursor.execute("CREATE INDEX ticket_status_idx ON ticket (status)")
    cursor.execute("CREATE INDEX ticket_time_idx ON ticket (time)")

    # Fix missing single column primary key constraints
    if env.config.get('trac', 'database').startswith('postgres'):
        cursor.execute("ALTER TABLE system ADD CONSTRAINT system_pkey PRIMARY KEY (name)")
        cursor.execute("ALTER TABLE revision ADD CONSTRAINT revision_pkey PRIMARY KEY (rev)")
        cursor.execute("ALTER TABLE ticket ADD CONSTRAINT ticket_pkey PRIMARY KEY (id)")
        cursor.execute("ALTER TABLE component ADD CONSTRAINT component_pkey PRIMARY KEY (name)")
        cursor.execute("ALTER TABLE milestone ADD CONSTRAINT milestone_pkey PRIMARY KEY (name)")
        cursor.execute("ALTER TABLE version ADD CONSTRAINT version_pkey PRIMARY KEY (name)")
        cursor.execute("ALTER TABLE report ADD CONSTRAINT report_pkey PRIMARY KEY (id)")

########NEW FILE########
__FILENAME__ = db17
from trac.db import Table, Column, Index, DatabaseManager

def do_upgrade(env, ver, cursor):
    """Rename the columns `kind` and `change` in the `node_change` table for
    compatibity with MySQL.
    """
    cursor.execute("CREATE TEMPORARY TABLE nc_old AS SELECT * FROM node_change")
    cursor.execute("DROP TABLE node_change")

    table = Table('node_change', key=('rev', 'path', 'change_type'))[
        Column('rev'),
        Column('path'),
        Column('node_type', size=1),
        Column('change_type', size=1),
        Column('base_path'),
        Column('base_rev'),
        Index(['rev'])
    ]
    db_connector, _ = DatabaseManager(env).get_connector()
    for stmt in db_connector.to_sql(table):
        cursor.execute(stmt)

    cursor.execute("INSERT INTO node_change (rev,path,node_type,change_type,"
                   "base_path,base_rev) SELECT rev,path,kind,change,"
                   "base_path,base_rev FROM nc_old")
    cursor.execute("DROP TABLE nc_old")

########NEW FILE########
__FILENAME__ = db18
from trac.db import Table, Column, Index, DatabaseManager

def do_upgrade(env, ver, cursor):
    cursor.execute("CREATE TEMPORARY TABLE session_old AS SELECT * FROM session")
    cursor.execute("DROP TABLE session")
    cursor.execute("CREATE TEMPORARY TABLE ticket_change_old AS SELECT * FROM ticket_change")
    cursor.execute("DROP TABLE ticket_change")

    # A more normalized session schema where the attributes are stored in
    # a separate table
    tables = [Table('session', key=('sid', 'authenticated'))[
                Column('sid'),
                Column('authenticated', type='int'),
                Column('last_visit', type='int'),
                Index(['last_visit']),
                Index(['authenticated'])],
              Table('session_attribute', key=('sid', 'authenticated', 'name'))[
                Column('sid'),
                Column('authenticated', type='int'),
                Column('name'),
                Column('value')],
              Table('ticket_change', key=('ticket', 'time', 'field'))[
                Column('ticket', type='int'),
                Column('time', type='int'),
                Column('author'),
                Column('field'),
                Column('oldvalue'),
                Column('newvalue'),
                Index(['ticket']),
                Index(['time'])]]

    db_connector, _ = DatabaseManager(env).get_connector()
    for table in tables:
        for stmt in db_connector.to_sql(table):
            cursor.execute(stmt)

    # Add an index to the temporary table to speed up the conversion
    cursor.execute("CREATE INDEX session_old_sid_idx ON session_old(sid)")
    # Insert the sessions into the new table
    cursor.execute("""
        INSERT INTO session (sid, last_visit, authenticated)
        SELECT distinct s.sid,COALESCE(%s,0),s.authenticated
        FROM session_old AS s LEFT JOIN session_old AS s2
        ON (s.sid=s2.sid AND s2.var_name='last_visit')
        WHERE s.sid IS NOT NULL
        """ % env.get_read_db().cast('s2.var_value', 'int'))
    cursor.execute("""
        INSERT INTO session_attribute (sid, authenticated, name, value)
        SELECT s.sid, s.authenticated, s.var_name, s.var_value
        FROM session_old s
        WHERE s.var_name <> 'last_visit' AND s.sid IS NOT NULL
        """)

    # Insert ticket change data into the new table
    cursor.execute("""
        INSERT INTO ticket_change (ticket, time, author, field, oldvalue,
                                   newvalue)
        SELECT ticket, time, author, field, oldvalue, newvalue
        FROM ticket_change_old
        """)

    cursor.execute("DROP TABLE session_old")
    cursor.execute("DROP TABLE ticket_change_old")


########NEW FILE########
__FILENAME__ = db19
from trac.db import Table, Column, Index, DatabaseManager

def do_upgrade(env, ver, cursor):
    """Rename the column `sql` in the `report` table for compatibity with MySQL.
    """
    cursor.execute("CREATE TEMPORARY TABLE report_old AS SELECT * FROM report")
    cursor.execute("DROP TABLE report")

    table = Table('report', key='id')[
        Column('id', auto_increment=True),
        Column('author'),
        Column('title'),
        Column('query'),
        Column('description')
    ]
    db_connector, _ = DatabaseManager(env).get_connector()
    for stmt in db_connector.to_sql(table):
        cursor.execute(stmt)

    cursor.execute("INSERT INTO report (id,author,title,query,description) "
                   "SELECT id,author,title,sql,description FROM report_old")
    cursor.execute("DROP TABLE report_old")

########NEW FILE########
__FILENAME__ = db20
from trac.versioncontrol.cache import CACHE_YOUNGEST_REV

def do_upgrade(env, ver, cursor):
    """Modify the repository cache scheme (if needed)

    Now we use the 'youngest_rev' entry in the system table
    to explicitly store the youngest rev in the cache.
    """
    youngest = ''
    cursor.execute("SELECT value FROM system WHERE name='repository_dir'")
    for repository_dir, in cursor:
        if repository_dir.startswith('svn:'):
            cursor.execute("SELECT rev FROM revision "
                           "ORDER BY -LENGTH(rev), rev DESC LIMIT 1")
            row = cursor.fetchone()
            youngest = row and row[0] or ''
        else:
            print 'Please perform a "repository resync" after this upgrade.'

    # deleting first, for the 0.11dev and 0.10.4dev users
    cursor.execute("DELETE FROM system WHERE name=%s",
                   (CACHE_YOUNGEST_REV,))
    cursor.execute("INSERT INTO system (name, value) VALUES (%s, %s)",
                   (CACHE_YOUNGEST_REV, youngest))

########NEW FILE########
__FILENAME__ = db21

def do_upgrade(env, ver, cursor):
    """Upgrade the reports to better handle the new workflow capabilities"""
    owner = env.get_read_db().concat('owner', "' *'")
    cursor.execute('SELECT id, query, description FROM report')
    reports = cursor.fetchall()
    for report, query, description in reports:
        q, d = query, description
        if query:
            # All states other than 'closed' are "active".
            q = q.replace("IN ('new', 'assigned', 'reopened')", "<> 'closed'")
            # Add a status column instead of adding an '*' to the owner's name
            # for the 'assigned' state.
            q = q.replace("(CASE status WHEN 'assigned' THEN %s "
                          "ELSE owner END) AS owner" % owner, "owner, status")
        if description:
            d = d.replace(" * If a ticket has been accepted, a '*' is"
                          " appended after the owner's name\n", '')
        if q != query or d != description:
            cursor.execute("""
                UPDATE report SET query=%s, description=%s WHERE id=%s
                """, (q, d, report))

########NEW FILE########
__FILENAME__ = db22
from trac.db import Table, Column, DatabaseManager

def do_upgrade(env, ver, cursor):
    """Add the cache table."""
    table = Table('cache', key='id')[
        Column('id'),
        Column('generation', type='int')
    ]
    db_connector, _ = DatabaseManager(env).get_connector()
    for stmt in db_connector.to_sql(table):
        cursor.execute(stmt)

########NEW FILE########
__FILENAME__ = db23
from trac.db import Table, Column, Index, DatabaseManager

def do_upgrade(env, ver, cursor):
    # Make changeset cache multi-repository aware
    cursor.execute("CREATE TEMPORARY TABLE rev_old "
                   "AS SELECT * FROM revision")
    cursor.execute("DROP TABLE revision")
    cursor.execute("CREATE TEMPORARY TABLE nc_old "
                   "AS SELECT * FROM node_change")
    cursor.execute("DROP TABLE node_change")

    tables = [Table('repository', key=('id', 'name'))[
                Column('id'),
                Column('name'),
                Column('value')],
              Table('revision', key=('repos', 'rev'))[
                Column('repos'),
                Column('rev', key_size=20),
                Column('time', type='int'),
                Column('author'),
                Column('message'),
                Index(['repos', 'time'])],
              Table('node_change', key=('repos', 'rev', 'path', 'change_type'))[
                Column('repos', key_size=56),
                Column('rev', key_size=20),
                Column('path', key_size=255),
                Column('node_type', size=1),
                Column('change_type', size=1, key_size=2),
                Column('base_path'),
                Column('base_rev'),
                Index(['repos', 'rev'])]]

    db_connector, _ = DatabaseManager(env)._get_connector()
    for table in tables:
        for stmt in db_connector.to_sql(table):
            cursor.execute(stmt)

    cursor.execute("INSERT INTO revision (repos,rev,time,author,message) "
                   "SELECT '',rev,time,author,message FROM rev_old")
    cursor.execute("DROP TABLE rev_old")
    cursor.execute("INSERT INTO node_change (repos,rev,path,node_type,"
                   "change_type,base_path,base_rev) "
                   "SELECT '',rev,path,node_type,change_type,base_path,"
                   "base_rev FROM nc_old")
    cursor.execute("DROP TABLE nc_old")

    cursor.execute("INSERT INTO repository (id,name,value) "
                   "SELECT '',name,value FROM system "
                   "WHERE name IN ('repository_dir', 'youngest_rev')")
    cursor.execute("DELETE FROM system "
                   "WHERE name IN ('repository_dir', 'youngest_rev')")

########NEW FILE########
__FILENAME__ = db24
from trac.db import Table, Column, Index, DatabaseManager

def do_upgrade(env, ver, cursor):
    # Change repository key from reponame to a surrogate id
    cursor.execute("SELECT id FROM repository "
                   "UNION SELECT repos AS id FROM revision "
                   "UNION SELECT repos AS id FROM node_change "
                   "ORDER BY id")
    id_name_list = [(i + 1, name) for i, (name,) in enumerate(cursor)]

    cursor.execute("CREATE TEMPORARY TABLE repo_old "
                   "AS SELECT * FROM repository")
    cursor.execute("DROP TABLE repository")
    cursor.execute("CREATE TEMPORARY TABLE rev_old "
                   "AS SELECT * FROM revision")
    cursor.execute("DROP TABLE revision")
    cursor.execute("CREATE TEMPORARY TABLE nc_old "
                   "AS SELECT * FROM node_change")
    cursor.execute("DROP TABLE node_change")

    tables = [Table('repository', key=('id', 'name'))[
                  Column('id', type='int'),
                  Column('name'),
                  Column('value')],
              Table('revision', key=('repos', 'rev'))[
                  Column('repos', type='int'),
                  Column('rev', key_size=20),
                  Column('time', type='int'),
                  Column('author'),
                  Column('message'),
                  Index(['repos', 'time'])],
              Table('node_change', key=('repos', 'rev', 'path', 'change_type'))[
                  Column('repos', type='int'),
                  Column('rev', key_size=20),
                  Column('path', key_size=255),
                  Column('node_type', size=1),
                  Column('change_type', size=1, key_size=2),
                  Column('base_path'),
                  Column('base_rev'),
                  Index(['repos', 'rev'])]]

    db_connector, _ = DatabaseManager(env)._get_connector()
    for table in tables:
        for stmt in db_connector.to_sql(table):
            cursor.execute(stmt)

    cursor.executemany("INSERT INTO repository (id,name,value) "
                       "VALUES (%s,'name',%s)", id_name_list)
    cursor.executemany("INSERT INTO repository (id,name,value) "
                       "SELECT %s,name,value FROM repo_old WHERE id=%s",
                       id_name_list)
    cursor.execute("DROP TABLE repo_old")
    cursor.executemany("INSERT INTO revision (repos,rev,time,author,message) "
                       "SELECT %s,rev,time,author,message FROM rev_old "
                       "WHERE repos=%s", id_name_list)
    cursor.execute("DROP TABLE rev_old")
    cursor.executemany("INSERT INTO node_change (repos,rev,path,node_type,"
                       "  change_type,base_path,base_rev) "
                       "SELECT %s,rev,path,node_type,change_type,base_path,"
                       "  base_rev FROM nc_old WHERE repos=%s", id_name_list)
    cursor.execute("DROP TABLE nc_old")

########NEW FILE########
__FILENAME__ = db25
from trac.db import DatabaseManager


def do_upgrade(env, ver, cursor):
    """Convert time values from integer seconds to integer microseconds."""
    tables = [
        ('attachment', {'time': ('int', 'int64')}),
        ('wiki', {'time': ('int', 'int64')}),
        ('revision', {'time': ('int', 'int64')}),
        ('ticket', {'time': ('int', 'int64'),
                    'changetime': ('int', 'int64')}),
        ('ticket_change', {'time': ('int', 'int64')}),
        ('milestone', {'due': ('int', 'int64'),
                       'completed': ('int', 'int64')}),
        ('version', {'time': ('int', 'int64')}),
    ]

    db_connector, _ = DatabaseManager(env).get_connector()
    for table, columns in tables:
        # Alter column types
        for sql in db_connector.alter_column_types(table, columns):
            cursor.execute(sql)

        # Convert timestamps to microseconds
        cursor.execute("UPDATE %s SET %s" % (table,
                        ', '.join("%s=%s*1000000" % (column, column)
                                  for column in columns)))

    # Convert comment edit timestamps to microseconds
    db = env.get_read_db()
    cursor.execute("""
        UPDATE ticket_change SET newvalue=%s*1000000
        WHERE field %s""" % (db.cast('newvalue', 'int64'), db.like()),
        ('_comment%',))

########NEW FILE########
__FILENAME__ = db26

def do_upgrade(env, ver, cursor):
    """Zero-pad Subversion revision numbers in the cache."""
    cursor.execute("""
        SELECT id, value FROM repository WHERE name='repository_dir'
        """)
    for id in [id for id, dir in cursor if dir.startswith('svn:')]:
        cursor.execute("SELECT DISTINCT rev FROM revision WHERE repos=%s",
                       (id,))
        for rev in set(row[0] for row in cursor):
            cursor.execute("""
                UPDATE revision SET rev=%s WHERE repos=%s AND rev=%s
                """, ('%010d' % int(rev), id, rev))

        cursor.execute("SELECT DISTINCT rev FROM node_change WHERE repos=%s",
                       (id,))
        for rev in set(row[0] for row in cursor):
            cursor.execute("""
                UPDATE node_change SET rev=%s WHERE repos=%s AND rev=%s
                """, ('%010d' % int(rev), id, rev))

########NEW FILE########
__FILENAME__ = db27
from trac.db import Table, Column, DatabaseManager

def do_upgrade(env, ver, cursor):
    """Modify the cache table to use an integer id."""
    # No need to keep the previous content
    cursor.execute("DROP TABLE cache")

    table = Table('cache', key='id')[
        Column('id', type='int'),
        Column('generation', type='int'),
        Column('key'),
    ]
    db_connector, _ = DatabaseManager(env).get_connector()
    for stmt in db_connector.to_sql(table):
        cursor.execute(stmt)

########NEW FILE########
__FILENAME__ = db28
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.com/license.html.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/.

import os.path

from trac.attachment import Attachment
from trac.util.text import exception_to_unicode, printerr, unicode_quote
from trac.util.translation import _


def do_upgrade(env, version, cursor):
    """Move attachments from the `attachments` directory into `files`, hashing
    the filenames in the process."""
    path = env.path
    old_dir = os.path.join(path, 'attachments')
    if not os.path.exists(old_dir):
        return
    old_stat = os.stat(old_dir)
    new_dir = os.path.join(path, 'files', 'attachments')
    if not os.path.exists(new_dir):
        os.makedirs(new_dir)

    cursor.execute("""
        SELECT type, id, filename FROM attachment ORDER BY type, id
        """)
    for row in cursor:
        move_attachment_file(env, *row)

    # Try to preserve permissions and ownerships of the attachments
    # directory for $ENV/files
    for dir, dirs, files in os.walk(os.path.join(path, 'files')):
        try:
            if hasattr(os, 'chmod'):
                os.chmod(dir, old_stat.st_mode)
            if hasattr(os, 'chflags') and hasattr(old_stat, 'st_flags'):
                os.chflags(dir, old_stat.st_flags)
            if hasattr(os, 'chown'):
                os.chown(dir, old_stat.st_uid, old_stat.st_gid)
        except OSError:
            pass

    # Remove empty directory hierarchy
    try:
        for dir, dirs, files in os.walk(old_dir, topdown=False):
            os.rmdir(dir)
    except OSError, e:
        env.log.warning("Can't delete old attachments directory %s: %s",
                         old_dir, exception_to_unicode(e))
        # TRANSLATOR: Wrap message to 80 columns
        printerr(_("""\
The upgrade of attachments was successful, but the old attachments directory:

  %(src_dir)s

couldn't be removed, possibly due to the presence of files that weren't
referenced in the database. The error was:

  %(exception)s

This error can be ignored, but for keeping your environment clean you should
backup any remaining files in that directory and remove it manually.
""", src_dir=old_dir, exception=exception_to_unicode(e)))


def move_attachment_file(env, parent_realm, parent_id, filename):
    old_path = os.path.join(env.path, 'attachments', parent_realm,
                            unicode_quote(parent_id))
    if filename:
        old_path = os.path.join(old_path, unicode_quote(filename))
    old_path = os.path.normpath(old_path)
    if os.path.isfile(old_path):
        new_path = Attachment._get_path(env.path, parent_realm, parent_id,
                                        filename)
        try:
            os.renames(old_path, new_path)
        except OSError:
            printerr(_("Unable to move attachment from:\n\n"
                       "  %(old_path)s\n\nto:\n\n  %(new_path)s\n",
                       old_path=old_path, new_path=new_path))
            raise
    else:
        env.log.warning("Can't find file for 'attachment:%s:%s:%s', ignoring",
                        filename, parent_realm, parent_id)

########NEW FILE########
__FILENAME__ = db29
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.com/license.html.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/.

import shutil

from trac.util import create_unique_file
from trac.util.text import exception_to_unicode


_svn_components = [
    'svn_fs.SubversionConnector',
    'svn_prop.SubversionMergePropertyDiffRenderer',
    'svn_prop.SubversionMergePropertyRenderer',
    'svn_prop.SubversionPropertyRenderer',
]
_old_path = 'trac.versioncontrol.'
_new_path = 'tracopt.versioncontrol.svn.'


def do_upgrade(env, version, cursor):
    """Automatically enable tracopt.versioncontrol.svn.* components,
    unless they were explicitly disabled or the new svn components are
    already enabled.
    """
    enable = [c for c in _svn_components
              if env.is_component_enabled(_old_path + c) and
              not env.is_component_enabled(_new_path + c)]
    if not enable:
        return
    try:
        backup, f = create_unique_file(env.config.filename
                                       + '.tracopt-svn.bak')
        f.close()
        shutil.copyfile(env.config.filename, backup)
        env.log.info("Saved backup of configuration file in %s", backup)
    except IOError, e:
        env.log.warn("Couldn't save backup of configuration file (%s)",
                     exception_to_unicode(e))
    for c in enable:
        env.config.set('components', _new_path + c, 'enabled')
    env.config.save()
    env.log.info("Enabled components %r to cope with the move from %s to %s.",
                 enable,
                 _old_path.replace('.', '/'), _new_path.replace('.', '/'))

########NEW FILE########
__FILENAME__ = db3
sql = """
CREATE TABLE attachment (
         type            text,
         id              text,
         filename        text,
         size            integer,
         time            integer,
         description     text,
         author          text,
         ipnr            text,
         UNIQUE(type,id,filename)
);
"""

def do_upgrade(env, ver, cursor):
    cursor.execute(sql)
    env.config.set('attachment', 'max_size', '262144')
    env.config.save()

########NEW FILE########
__FILENAME__ = db4
sql = [
"""CREATE TABLE session (
         sid             text,
         username        text,
         var_name        text,
         var_value       text,
         UNIQUE(sid,var_name)
);""",
"""CREATE INDEX session_idx ON session(sid,var_name);"""
]

def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)

########NEW FILE########
__FILENAME__ = db5
sql = [
#-- Add unique id, descr to 'milestone'
"""CREATE TEMPORARY TABLE milestone_old AS SELECT * FROM milestone;""",
"""DROP TABLE milestone;""",
"""CREATE TABLE milestone (
         id              integer PRIMARY KEY,
         name            text,
         time            integer,
         descr           text,
         UNIQUE(name)
);""",
"""
INSERT INTO milestone(name,time, descr) SELECT name,time,'' FROM milestone_old;""",
"""DROP TABLE milestone_old;""",
]
def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)

########NEW FILE########
__FILENAME__ = db6
sql = """
CREATE TABLE ticket_custom (
       ticket               integer,
       name             text,
       value            text,
       UNIQUE(ticket,name)
);
"""

def do_upgrade(env, ver, cursor):
    cursor.execute(sql)


########NEW FILE########
__FILENAME__ = db7
sql = [
#-- Add readonly flag to 'wiki'
"""CREATE TEMPORARY TABLE wiki_old AS SELECT * FROM wiki;""",
"""DROP TABLE wiki;""",
"""CREATE TABLE wiki (
         name            text,
         version         integer,
         time            integer,
         author          text,
         ipnr            text,
         text            text,
         comment         text,
         readonly        integer,
         UNIQUE(name,version)
);""",
"""INSERT INTO wiki(name,version,time,author,ipnr,text,comment,readonly) SELECT name,version,time,author,ipnr,text,comment,0 FROM wiki_old;"""
]

def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)

########NEW FILE########
__FILENAME__ = db8
import time

d = {'now':time.time()}
sql = [
#-- Separate between due and completed time for milestones.
"""CREATE TEMPORARY TABLE milestone_old AS SELECT * FROM milestone;""",
"""DROP TABLE milestone;""",
"""CREATE TABLE milestone (
         name            text PRIMARY KEY,
         due             integer, -- Due date/time
         completed       integer, -- Completed date/time
         description     text
);""",
"""INSERT INTO milestone(name,due,completed,description)
SELECT name,time,time,descr FROM milestone_old WHERE time <= %(now)s;""" % d,
"""INSERT INTO milestone(name,due,description)
SELECT name,time,descr FROM milestone_old WHERE time > %(now)s;""" % d
]

def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)

########NEW FILE########
__FILENAME__ = db9
import time

sql = [
#-- Remove the unused lock table
"""DROP TABLE lock;""",
#-- Separate anonymous from authenticated sessions.
"""CREATE TEMPORARY TABLE session_old AS SELECT * FROM session;""",
"""DELETE FROM session;""",
"""INSERT INTO session (username,var_name,var_value)
  SELECT username,var_name,var_value FROM session_old
  WHERE sid IN (SELECT DISTINCT sid FROM session_old
    WHERE username!='anonymous' AND var_name='last_visit'
    GROUP BY username ORDER BY var_value DESC);""",
"""INSERT INTO session (sid,username,var_name,var_value)
  SELECT sid,username,var_name,var_value FROM session_old
  WHERE username='anonymous';""",
"""DROP TABLE session_old;"""
]

def do_upgrade(env, ver, cursor):
    for s in sql:
        cursor.execute(s)

########NEW FILE########
__FILENAME__ = autoreload
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os
import sys
import threading
import time
import traceback

_SLEEP_TIME = 1

def _reloader_thread(modification_callback, loop_callback):
    """When this function is run from the main thread, it will force other
    threads to exit when any modules currently loaded change.

    @param modification_callback: a function taking a single argument, the
        modified file, which is called every time a modification is detected
    @param loop_callback: a function taking no arguments, which is called
        after every modification check
    """
    mtimes = {}
    while True:
        for filename in filter(None, [getattr(module, '__file__', None)
                                      for module in sys.modules.values()]):
            while not os.path.isfile(filename): # Probably in an egg or zip file
                filename = os.path.dirname(filename)
                if not filename:
                    break
            if not filename: # Couldn't map to physical file, so just ignore
                continue

            if filename.endswith(('.pyc', '.pyo')):
                filename = filename[:-1]

            if not os.path.isfile(filename):
                # Compiled file for non-existant source
                continue

            mtime = os.stat(filename).st_mtime
            if filename not in mtimes:
                mtimes[filename] = mtime
                continue
            if mtime > mtimes[filename]:
                modification_callback(filename)
                sys.exit(3)
        loop_callback()
        time.sleep(_SLEEP_TIME)

def _restart_with_reloader():
    while True:
        args = [sys.executable] + sys.argv
        if sys.platform == 'win32':
            args = ['"%s"' % arg for arg in args]
        new_environ = os.environ.copy()
        new_environ['RUN_MAIN'] = 'true'

        # This call reinvokes ourself and goes into the other branch of main as
        # a new process.
        exit_code = os.spawnve(os.P_WAIT, sys.executable,
                               args, new_environ)
        if exit_code != 3:
            return exit_code

def main(func, modification_callback, *args, **kwargs):
    """Run the given function and restart any time modules are changed."""
    if os.environ.get('RUN_MAIN'):
        exit_code = []
        def main_thread():
            try:
                func(*args, **kwargs)
                exit_code.append(None)
            except SystemExit, e:
                exit_code.append(e.code)
            except:
                traceback.print_exception(*sys.exc_info())
                exit_code.append(1)
        def check_exit():
            if exit_code:
                sys.exit(exit_code[0])
        # Lanch the actual program as a child thread
        thread = threading.Thread(target=main_thread, name='Main thread')
        thread.setDaemon(True)
        thread.start()
        try:
            # Now wait for a file modification and quit
            _reloader_thread(modification_callback, check_exit)
        except KeyboardInterrupt:
            pass
    else:
        # Initial invocation just waits around restarting this executable
        try:
            sys.exit(_restart_with_reloader())
        except KeyboardInterrupt:
            pass

########NEW FILE########
__FILENAME__ = compat
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# Copyright (C) 2006 Matthew Good <trac@matt-good.net>
# Copyright (C) 2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

"""Various classes and functions to provide some backwards-compatibility with
previous versions of Python from 2.5 onward.
"""

import os

# Import symbols previously defined here, kept around so that plugins importing
# them don't suddenly stop working
all = all
any = any
frozenset = frozenset
reversed = reversed
set = set
sorted = sorted
from functools import partial
from hashlib import md5, sha1
from itertools import groupby, tee

class py_groupby(object):
    def __init__(self, iterable, key=None):
        if key is None:
            key = lambda x: x
        self.keyfunc = key
        self.it = iter(iterable)
        self.tgtkey = self.currkey = self.currvalue = xrange(0)
    def __iter__(self):
        return self
    def next(self):
        while self.currkey == self.tgtkey:
            self.currvalue = self.it.next() # Exit on StopIteration
            self.currkey = self.keyfunc(self.currvalue)
        self.tgtkey = self.currkey
        return (self.currkey, self._grouper(self.tgtkey))
    def _grouper(self, tgtkey):
        while self.currkey == tgtkey:
            yield self.currvalue
            self.currvalue = self.it.next() # Exit on StopIteration
            self.currkey = self.keyfunc(self.currvalue)

def rpartition(s, sep):
    return s.rpartition(sep)

# An error is raised by subprocess if we ever pass close_fds=True on Windows.
# We want it to be True on all other platforms to not leak file descriptors.
close_fds = os.name != 'nt'

# inspect.cleandoc() was introduced in 2.6
try:
    from inspect import cleandoc
except ImportError:
    import sys

    # Taken from Python 2.6
    def cleandoc(doc):
        """De-indent a multi-line text.

        Any whitespace that can be uniformly removed from the second line
        onwards is removed."""
        try:
            lines = doc.expandtabs().split('\n')
        except UnicodeError:
            return None
        else:
            # Find minimum indentation of any non-blank lines after first line
            margin = sys.maxint
            for line in lines[1:]:
                content = len(line.lstrip())
                if content:
                    indent = len(line) - content
                    margin = min(margin, indent)
            # Remove indentation
            if lines:
                lines[0] = lines[0].lstrip()
            if margin < sys.maxint:
                for i in range(1, len(lines)):
                    lines[i] = lines[i][margin:]
            # Remove any trailing or leading blank lines
            while lines and not lines[-1]:
                lines.pop()
            while lines and not lines[0]:
                lines.pop(0)
            return '\n'.join(lines)

########NEW FILE########
__FILENAME__ = concurrency
# -*- coding: utf-8 -*-
#
# Copyright (C) 2010 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

try:
    import threading
except ImportError:
    import dummy_threading as threading
    threading._get_ident = lambda: 0


class ThreadLocal(threading.local):
    """A thread-local storage allowing to set default values on construction.
    """
    def __init__(self, **kwargs):
        threading.local.__init__(self)
        self.__dict__.update(kwargs)

def get_thread_id():
    return threading._get_ident()

########NEW FILE########
__FILENAME__ = daemon
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from __future__ import with_statement

import atexit
import errno
import os
import signal
import sys

def daemonize(pidfile=None, progname=None, stdin='/dev/null',
              stdout='/dev/null', stderr='/dev/null', umask=022):
    """Fork a daemon process."""
    if pidfile:
        # Check whether the pid file already exists and refers to a still
        # process running
        pidfile = os.path.abspath(pidfile)
        if os.path.exists(pidfile):
            with open(pidfile) as fileobj:
                try:
                    pid = int(fileobj.read())
                except ValueError:
                    sys.exit('Invalid pid in file %s\nPlease remove it to '
                             'proceed' % pidfile)

            try: # signal the process to see if it is still running
                os.kill(pid, 0)
                if not progname:
                    progname = os.path.basename(sys.argv[0])
                sys.exit('%s is already running with pid %s' % (progname, pid))
            except OSError, e:
                if e.errno != errno.ESRCH:
                    raise

        # The pid file must be writable
        try:
            fileobj = open(pidfile, 'a+')
            fileobj.close()
        except IOError, e:
            from trac.util.text import exception_to_unicode
            sys.exit('Error writing to pid file: %s' % exception_to_unicode(e))

    # Perform first fork
    pid = os.fork()
    if pid > 0:
        sys.exit(0) # exit first parent

    # Decouple from parent environment
    os.chdir('/')
    os.umask(umask)
    os.setsid()

    # Perform second fork
    pid = os.fork()
    if pid > 0:
        sys.exit(0) # exit second parent

    # The process is now daemonized, redirect standard file descriptors
    for stream in sys.stdout, sys.stderr:
        stream.flush()
    stdin = open(stdin, 'r')
    stdout = open(stdout, 'a+')
    stderr = open(stderr, 'a+', 0)
    os.dup2(stdin.fileno(), sys.stdin.fileno())
    os.dup2(stdout.fileno(), sys.stdout.fileno())
    os.dup2(stderr.fileno(), sys.stderr.fileno())

    if pidfile:
        # Register signal handlers to ensure atexit hooks are called on exit
        for signum in [signal.SIGTERM, signal.SIGHUP]:
            signal.signal(signum, handle_signal)

        # Create/update the pid file, and register a hook to remove it when the
        # process exits
        def remove_pidfile():
            if os.path.exists(pidfile):
                os.remove(pidfile)
        atexit.register(remove_pidfile)
        with open(pidfile, 'w') as fileobj:
            fileobj.write(str(os.getpid()))


def handle_signal(signum, frame):
    """Handle signals sent to the daemonized process."""
    sys.exit()

########NEW FILE########
__FILENAME__ = datefmt
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2006 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2006 Matthew Good <trac@matt-good.net>
# Copyright (C) 2005-2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Matthew Good <trac@matt-good.net>

import math
import re
import sys
import time
from datetime import tzinfo, timedelta, datetime, date
from locale import getlocale, LC_TIME

try:
    import babel
    from babel import Locale
    from babel.core import LOCALE_ALIASES
    from babel.dates import (
        format_datetime as babel_format_datetime,
        format_date as babel_format_date,
        format_time as babel_format_time,
        get_datetime_format, get_date_format,
        get_time_format, get_month_names,
        get_period_names, get_day_names
    )
except ImportError:
    babel = None

from trac.core import TracError
from trac.util.text import to_unicode, getpreferredencoding
from trac.util.translation import _, ngettext, get_available_locales

# Date/time utilities

# -- conversion

def to_datetime(t, tzinfo=None):
    """Convert ``t`` into a `datetime` object in the ``tzinfo`` timezone.

    If no ``tzinfo`` is given, the local timezone `localtz` will be used.

    ``t`` is converted using the following rules:

     - If ``t`` is already a `datetime` object,
       - if it is timezone-"naive", it is localized to ``tzinfo``
       - if it is already timezone-aware, ``t`` is mapped to the given
         timezone (`datetime.datetime.astimezone`)
     - If ``t`` is None, the current time will be used.
     - If ``t`` is a number, it is interpreted as a timestamp.

    Any other input will trigger a `TypeError`.

    All returned datetime instances are timezone aware and normalized.
    """
    tz = tzinfo or localtz
    if t is None:
        dt = datetime.now(tz)
    elif isinstance(t, datetime):
        if t.tzinfo:
            dt = t.astimezone(tz)
        else:
            dt = tz.localize(t)
    elif isinstance(t, date):
        dt = tz.localize(datetime(t.year, t.month, t.day))
    elif isinstance(t, (int, long, float)):
        if not (_min_ts <= t <= _max_ts):
            # Handle microsecond timestamps for 0.11 compatibility
            t *= 0.000001
        if t < 0 and isinstance(t, float):
            # Work around negative fractional times bug in Python 2.4
            # http://bugs.python.org/issue1646728
            frac, integer = math.modf(t)
            dt = datetime.fromtimestamp(integer - 1, tz) + \
                    timedelta(seconds=frac + 1)
        else:
            dt = datetime.fromtimestamp(t, tz)
    if dt:
        return tz.normalize(dt)
    raise TypeError('expecting datetime, int, long, float, or None; got %s' %
                    type(t))

def to_timestamp(dt):
    """Return the corresponding POSIX timestamp"""
    if dt:
        diff = dt - _epoc
        return diff.days * 86400 + diff.seconds
    else:
        return 0

def to_utimestamp(dt):
    """Return a microsecond POSIX timestamp for the given `datetime`."""
    if not dt:
        return 0
    diff = dt - _epoc
    return (diff.days * 86400000000L + diff.seconds * 1000000
            + diff.microseconds)

def from_utimestamp(ts):
    """Return the `datetime` for the given microsecond POSIX timestamp."""
    return _epoc + timedelta(microseconds=ts or 0)

# -- formatting

_units = (
    (3600*24*365, lambda r: ngettext('%(num)d year', '%(num)d years', r)),
    (3600*24*30,  lambda r: ngettext('%(num)d month', '%(num)d months', r)),
    (3600*24*7,   lambda r: ngettext('%(num)d week', '%(num)d weeks', r)),
    (3600*24,     lambda r: ngettext('%(num)d day', '%(num)d days', r)),
    (3600,        lambda r: ngettext('%(num)d hour', '%(num)d hours', r)),
    (60,          lambda r: ngettext('%(num)d minute', '%(num)d minutes', r)))

def pretty_timedelta(time1, time2=None, resolution=None):
    """Calculate time delta between two `datetime` objects.
    (the result is somewhat imprecise, only use for prettyprinting).

    If either `time1` or `time2` is None, the current time will be used
    instead.
    """
    time1 = to_datetime(time1)
    time2 = to_datetime(time2)
    if time1 > time2:
        time2, time1 = time1, time2

    diff = time2 - time1
    age_s = int(diff.days * 86400 + diff.seconds)
    if resolution and age_s < resolution:
        return ''
    if age_s <= 60 * 1.9:
        return ngettext('%(num)i second', '%(num)i seconds', age_s)
    for u, format_units in _units:
        r = float(age_s) / float(u)
        if r >= 1.9:
            r = int(round(r))
            return format_units(r)
    return ''


_BABEL_FORMATS = {
    'datetime': {'short': '%x %H:%M', 'medium': '%x %X', 'long': '%x %X',
                 'full': '%x %X'},
    'date': {'short': '%x', 'medium': '%x', 'long': '%x', 'full': '%x'},
    'time': {'short': '%H:%M', 'medium': '%X', 'long': '%X', 'full': '%X'},
}
_ISO8601_FORMATS = {
    'datetime': {
        '%x %X': 'iso8601', '%x': 'iso8601date', '%X': 'iso8601time',
        'short': '%Y-%m-%dT%H:%M', 'medium': '%Y-%m-%dT%H:%M:%S',
        'long': 'iso8601', 'full': 'iso8601',
        'iso8601': 'iso8601', None: 'iso8601'},
    'date': {
        '%x %X': 'iso8601', '%x': 'iso8601date', '%X': 'iso8601time',
        'short': 'iso8601date', 'medium': 'iso8601date',
        'long': 'iso8601date', 'full': 'iso8601date',
        'iso8601': 'iso8601date', None: 'iso8601date'},
    'time': {
        '%x %X': 'iso8601', '%x': 'iso8601date', '%X': 'iso8601time',
        'short': '%H:%M', 'medium': '%H:%M:%S',
        'long': 'iso8601time', 'full': 'iso8601time',
        'iso8601': 'iso8601time', None: 'iso8601time'},
}
_STRFTIME_HINTS = {'%x %X': 'datetime', '%x': 'date', '%X': 'time'}

def _format_datetime_without_babel(t, format):
    normalize_Z = False
    if format.lower().startswith('iso8601'):
        if 'date' in format:
            format = '%Y-%m-%d'
        elif 'time' in format:
            format = '%H:%M:%S%z'
            normalize_Z = True
        else:
            format = '%Y-%m-%dT%H:%M:%S%z'
            normalize_Z = True
    text = t.strftime(str(format))
    if normalize_Z:
        text = text.replace('+0000', 'Z')
        if not text.endswith('Z'):
            text = text[:-2] + ":" + text[-2:]
    encoding = getlocale(LC_TIME)[1] or getpreferredencoding() \
               or sys.getdefaultencoding()
    return unicode(text, encoding, 'replace')

def _format_datetime(t, format, tzinfo, locale, hint):
    t = to_datetime(t, tzinfo or localtz)

    if (format in ('iso8601', 'iso8601date', 'iso8601time') or
        locale == 'iso8601'):
        format = _ISO8601_FORMATS[hint].get(format, format)
        return _format_datetime_without_babel(t, format)

    if babel and locale:
        if format is None:
            format = 'medium'
        elif format in _STRFTIME_HINTS:
            hint = _STRFTIME_HINTS[format]
            format = 'medium'
        if format in ('short', 'medium', 'long', 'full'):
            if hint == 'datetime':
                return babel_format_datetime(t, format, None, locale)
            if hint == 'date':
                return babel_format_date(t, format, locale)
            if hint == 'time':
                return babel_format_time(t, format, None, locale)

    format = _BABEL_FORMATS[hint].get(format, format)
    return _format_datetime_without_babel(t, format)

def format_datetime(t=None, format='%x %X', tzinfo=None, locale=None):
    """Format the `datetime` object `t` into an `unicode` string

    If `t` is None, the current time will be used.

    The formatting will be done using the given `format`, which consist
    of conventional `strftime` keys. In addition the format can be 'iso8601'
    to specify the international date format (compliant with RFC 3339).

    `tzinfo` will default to the local timezone if left to `None`.
    """
    return _format_datetime(t, format, tzinfo, locale, 'datetime')

def format_date(t=None, format='%x', tzinfo=None, locale=None):
    """Convenience method for formatting the date part of a `datetime` object.
    See `format_datetime` for more details.
    """
    return _format_datetime(t, format, tzinfo, locale, 'date')

def format_time(t=None, format='%X', tzinfo=None, locale=None):
    """Convenience method for formatting the time part of a `datetime` object.
    See `format_datetime` for more details.
    """
    return _format_datetime(t, format, tzinfo, locale, 'time')

def get_date_format_hint(locale=None):
    """Present the default format used by `format_date` in a human readable
    form.
    This is a format that will be recognized by `parse_date` when reading a
    date.
    """
    if locale == 'iso8601':
        return 'YYYY-MM-DD'
    if babel and locale:
        format = get_date_format('medium', locale=locale)
        return format.pattern

    t = datetime(1999, 10, 29, tzinfo=utc)
    tmpl = format_date(t, tzinfo=utc)
    return tmpl.replace('1999', 'YYYY', 1).replace('99', 'YY', 1) \
               .replace('10', 'MM', 1).replace('29', 'DD', 1)

def get_datetime_format_hint(locale=None):
    """Present the default format used by `format_datetime` in a human readable
    form.
    This is a format that will be recognized by `parse_date` when reading a
    date.
    """
    if locale == 'iso8601':
        return u'YYYY-MM-DDThh:mm:sshh:mm'
    if babel and locale:
        date_pattern = get_date_format('medium', locale=locale).pattern
        time_pattern = get_time_format('medium', locale=locale).pattern
        format = get_datetime_format('medium', locale=locale)
        return format.replace('{0}', time_pattern) \
                     .replace('{1}', date_pattern)

    t = datetime(1999, 10, 29, 23, 59, 58, tzinfo=utc)
    tmpl = format_datetime(t, tzinfo=utc)
    ampm = format_time(t, '%p', tzinfo=utc)
    if ampm:
        tmpl = tmpl.replace(ampm, 'a', 1)
    return tmpl.replace('1999', 'YYYY', 1).replace('99', 'YY', 1) \
               .replace('10', 'MM', 1).replace('29', 'DD', 1) \
               .replace('23', 'hh', 1).replace('11', 'hh', 1) \
               .replace('59', 'mm', 1).replace('58', 'ss', 1)

def get_month_names_jquery_ui(req):
    """Get the month names for the jQuery UI datepicker library"""
    locale = req.lc_time
    if locale == 'iso8601':
        locale = req.locale
    if babel and locale:
        month_names = {}
        for width in ('wide', 'abbreviated'):
            names = get_month_names(width, locale=locale)
            month_names[width] = [names[i + 1] for i in xrange(12)]
        return month_names

    return {
        'wide': (
            'January', 'February', 'March', 'April', 'May', 'June', 'July',
            'August', 'September', 'October', 'November', 'December'),
        'abbreviated': (
            'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',
            'Oct', 'Nov', 'Dec'),
    }

def get_day_names_jquery_ui(req):
    """Get the day names for the jQuery UI datepicker library"""
    locale = req.lc_time
    if locale == 'iso8601':
        locale = req.locale
    if babel and locale:
        day_names = {}
        for width in ('wide', 'abbreviated', 'narrow'):
            names = get_day_names(width, locale=locale)
            day_names[width] = [names[(i + 6) % 7] for i in xrange(7)]
        return day_names

    return {
        'wide': ('Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday',
                 'Friday', 'Saturday'),
        'abbreviated': ('Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'),
        'narrow': ('Su', 'Mo', 'Tu', 'We', 'Th', 'Fr', 'Sa'),
    }

def get_date_format_jquery_ui(locale):
    """Get the date format for the jQuery UI datepicker library."""
    if locale == 'iso8601':
        return 'yy-mm-dd'
    if babel and locale:
        values = {'yyyy': 'yy', 'y': 'yy', 'M': 'm', 'MM': 'mm', 'MMM': 'M',
                  'd': 'd', 'dd': 'dd'}
        return get_date_format('medium', locale=locale).format % values

    t = datetime(1999, 10, 29, tzinfo=utc)
    tmpl = format_date(t, tzinfo=utc)
    return tmpl.replace('1999', 'yy', 1).replace('99', 'y', 1) \
               .replace('10', 'mm', 1).replace('29', 'dd', 1)

def get_time_format_jquery_ui(locale):
    """Get the time format for the jQuery UI timepicker addon."""
    if locale == 'iso8601':
        return 'hh:mm:ssz'  # XXX timepicker doesn't support 'ISO_8601'
    if babel and locale:
        values = {'h': 'h', 'hh': 'hh', 'H': 'h', 'HH': 'hh',
                  'm': 'm', 'mm': 'mm', 's': 's', 'ss': 'ss',
                  'a': 'TT'}
        return get_time_format('medium', locale=locale).format % values

    t = datetime(1999, 10, 29, 23, 59, 58, tzinfo=utc)
    tmpl = format_time(t, tzinfo=utc)
    ampm = format_time(t, '%p', tzinfo=utc)
    if ampm:
        tmpl = tmpl.replace(ampm, 'TT', 1)
    return tmpl.replace('23', 'hh', 1).replace('11', 'hh', 1) \
               .replace('59', 'mm', 1).replace('58', 'ss', 1)

def get_timezone_list_jquery_ui(t=None):
    """Get timezone list for jQuery timepicker addon"""
    t = datetime.now(utc) if t is None else utc.localize(t)
    zones = set(t.astimezone(get_timezone(tz)).strftime('%z')
                for tz in all_timezones)
    return [{'value': 'Z', 'label': '+00:00'} \
            if zone == '+0000' else zone[:-2] + ':' + zone[-2:]
            for zone in sorted(zones, key=lambda tz: int(tz))]

def get_first_week_day_jquery_ui(req):
    """Get first week day for jQuery date picker"""
    locale = req.lc_time
    if locale == 'iso8601':
        return 1 # Monday
    if babel and locale:
        if not locale.territory and locale.language in LOCALE_ALIASES:
            locale = Locale.parse(LOCALE_ALIASES[locale.language])
        return (locale.first_week_day + 1) % 7
    return 0 # Sunday

def is_24_hours(locale):
    """Returns `True` for 24 hour time formats."""
    if locale == 'iso8601':
        return True
    t = datetime(1999, 10, 29, 23, tzinfo=utc)
    tmpl = format_datetime(t, tzinfo=utc, locale=locale)
    return '23' in tmpl

def http_date(t=None):
    """Format `datetime` object `t` as a rfc822 timestamp"""
    t = to_datetime(t, utc)
    weekdays = ('Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun')
    months = ('Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',
              'Oct', 'Nov', 'Dec')
    return '%s, %02d %s %04d %02d:%02d:%02d GMT' % (
        weekdays[t.weekday()], t.day, months[t.month - 1], t.year,
        t.hour, t.minute, t.second)


# -- parsing

_ISO_8601_RE = re.compile(r'''
    (\d\d\d\d)(?:-?(\d\d)(?:-?(\d\d))?)?    # date
    (?:
        [T ]
        (\d\d)(?::?(\d\d)(?::?(\d\d)        # time
        (?:[,.](\d{1,6}))?)?)?              # microseconds
    )?
    (Z?(?:([-+])?(\d\d):?(\d\d)?)?)?$       # timezone
    ''', re.VERBOSE)

def _parse_date_iso8601(text, tzinfo):
    match = _ISO_8601_RE.match(text)
    if match:
        try:
            g = match.groups()
            years = g[0]
            months = g[1] or '01'
            days = g[2] or '01'
            hours, minutes, seconds, useconds = [x or '00' for x in g[3:7]]
            useconds = (useconds + '000000')[:6]
            z, tzsign, tzhours, tzminutes = g[7:11]
            if z:
                tz = timedelta(hours=int(tzhours or '0'),
                               minutes=int(tzminutes or '0')).seconds / 60
                if tz == 0:
                    tzinfo = utc
                else:
                    tzinfo = FixedOffset(-tz if tzsign == '-' else tz,
                                         '%s%s:%s' %
                                         (tzsign, tzhours, tzminutes))
            tm = [int(x) for x in (years, months, days,
                                   hours, minutes, seconds, useconds)]
            t = tzinfo.localize(datetime(*tm))
            return tzinfo.normalize(t)
        except ValueError:
            pass

    return None

def parse_date(text, tzinfo=None, locale=None, hint='date'):
    tzinfo = tzinfo or localtz
    text = text.strip()

    dt = _parse_date_iso8601(text, tzinfo)
    if dt is None and locale != 'iso8601':
        if babel and locale:
            dt = _i18n_parse_date(text, tzinfo, locale)
        else:
            for format in ['%x %X', '%x, %X', '%X %x', '%X, %x', '%x', '%c',
                           '%b %d, %Y']:
                try:
                    tm = time.strptime(text, format)
                    dt = tzinfo.localize(datetime(*tm[0:6]))
                    dt = tzinfo.normalize(dt)
                    break
                except ValueError:
                    continue
    if dt is None:
        dt = _parse_relative_time(text, tzinfo)
    if dt is None:
        hint = {'datetime': get_datetime_format_hint,
                'date': get_date_format_hint
               }.get(hint, lambda(l): hint)(locale)
        raise TracError(_('"%(date)s" is an invalid date, or the date format '
                          'is not known. Try "%(hint)s" instead.',
                          date=text, hint=hint), _('Invalid Date'))
    # Make sure we can convert it to a timestamp and back - fromtimestamp()
    # may raise ValueError if larger than platform C localtime() or gmtime()
    try:
        datetime.utcfromtimestamp(to_timestamp(dt))
    except ValueError:
        raise TracError(_('The date "%(date)s" is outside valid range. '
                          'Try a date closer to present time.', date=text),
                          _('Invalid Date'))
    return dt

def _i18n_parse_date_pattern(locale):
    format_keys = {
        'y': ('y', 'Y'),
        'M': ('M',),
        'd': ('d',),
        'h': ('h', 'H'),
        'm': ('m',),
        's': ('s',),
    }
    regexp = [r'[0-9]+']

    date_format = get_date_format('medium', locale=locale)
    time_format = get_time_format('medium', locale=locale)
    datetime_format = get_datetime_format('medium', locale=locale)
    formats = (
        datetime_format.replace('{0}', time_format.format) \
                       .replace('{1}', date_format.format),
        date_format.format)

    orders = []
    for format in formats:
        order = []
        for key, chars in format_keys.iteritems():
            for char in chars:
                idx = format.find('%(' + char)
                if idx != -1:
                    order.append((idx, key))
                    break
        order.sort()
        order = dict((key, idx) for idx, (_, key) in enumerate(order))
        orders.append(order)

    month_names = {
        'jan': 1, 'feb': 2, 'mar': 3, 'apr': 4, 'may': 5, 'jun': 6,
        'jul': 7, 'aug': 8, 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12,
    }
    if formats[0].find('%(MMM)s') != -1:
        for width in ('wide', 'abbreviated'):
            names = get_month_names(width, locale=locale)
            for num, name in names.iteritems():
                name = name.lower()
                month_names[name] = num
    regexp.extend(month_names.iterkeys())

    period_names = {'am': 'am', 'pm': 'pm'}
    if formats[0].find('%(a)s') != -1:
        names = get_period_names(locale=locale)
        for period, name in names.iteritems():
            name = name.lower()
            period_names[name] = period
    regexp.extend(period_names.iterkeys())

    return {
        'orders': orders,
        'regexp': re.compile('(%s)' % '|'.join(regexp),
                             re.IGNORECASE | re.UNICODE),
        'month_names': month_names,
        'period_names': period_names,
    }

_I18N_PARSE_DATE_PATTERNS = dict(map(lambda l: (l, False),
                                     get_available_locales()))

def _i18n_parse_date(text, tzinfo, locale):
    locale = Locale.parse(locale)
    key = str(locale)
    pattern = _I18N_PARSE_DATE_PATTERNS.get(key)
    if pattern is False:
        pattern = _i18n_parse_date_pattern(locale)
        _I18N_PARSE_DATE_PATTERNS[key] = pattern
    if pattern is None:
        return None

    regexp = pattern['regexp']
    period_names = pattern['period_names']
    month_names = pattern['month_names']
    text = text.lower()
    for order in pattern['orders']:
        try:
            return _i18n_parse_date_0(text, order, regexp, period_names,
                                      month_names, tzinfo)
        except ValueError:
            continue

    return None

def _i18n_parse_date_0(text, order, regexp, period_names, month_names, tzinfo):
    matches = regexp.findall(text)
    if not matches:
        return None

    # remove am/pm markers on ahead
    period = None
    for idx, match in enumerate(matches):
        period = period_names.get(match)
        if period is not None:
            del matches[idx]
            break

    # for date+time, use 0 seconds if seconds are missing
    if 's' in order and len(matches) == 5:
        matches.insert(order['s'], 0)

    values = {}
    for key, idx in order.iteritems():
        if idx < len(matches):
            value = matches[idx]
            if key == 'y':
                if len(value) == 2 and value.isdigit():
                    value = '20' + value
            values[key] = value

    if 'y' not in values or 'M' not in values or 'd' not in values:
        raise ValueError

    for key in ('y', 'M', 'd'):
        value = values[key]
        value = month_names.get(value)
        if value is not None:
            if key == 'M':
                values[key] = value
            else:
                values[key], values['M'] = values['M'], value
            break

    values = dict((key, int(value)) for key, value in values.iteritems())
    values.setdefault('h', 0)
    values.setdefault('m', 0)
    values.setdefault('s', 0)

    if period and values['h'] <= 12:
        if period == 'am':
            values['h'] %= 12
        elif period == 'pm':
            values['h'] = values['h'] % 12 + 12

    t = tzinfo.localize(datetime(*(values[k] for k in 'yMdhms')))
    return tzinfo.normalize(t)

_REL_TIME_RE = re.compile(
    r'(\d+\.?\d*)\s*'
    r'(second|minute|hour|day|week|month|year|[hdwmy])s?\s*'
    r'(?:ago)?$')
_time_intervals = dict(
    second=lambda v: timedelta(seconds=v),
    minute=lambda v: timedelta(minutes=v),
    hour=lambda v: timedelta(hours=v),
    day=lambda v: timedelta(days=v),
    week=lambda v: timedelta(weeks=v),
    month=lambda v: timedelta(days=30 * v),
    year=lambda v: timedelta(days=365 * v),
    h=lambda v: timedelta(hours=v),
    d=lambda v: timedelta(days=v),
    w=lambda v: timedelta(weeks=v),
    m=lambda v: timedelta(days=30 * v),
    y=lambda v: timedelta(days=365 * v),
)
_TIME_START_RE = re.compile(r'(this|last)\s*'
                            r'(second|minute|hour|day|week|month|year)$')
_time_starts = dict(
    second=lambda now: datetime(now.year, now.month, now.day, now.hour,
                                now.minute, now.second),
    minute=lambda now: datetime(now.year, now.month, now.day, now.hour,
                                now.minute),
    hour=lambda now: datetime(now.year, now.month, now.day, now.hour),
    day=lambda now: datetime(now.year, now.month, now.day),
    week=lambda now: datetime(now.year, now.month, now.day) \
                     - timedelta(days=now.weekday()),
    month=lambda now: datetime(now.year, now.month, 1),
    year=lambda now: datetime(now.year, 1, 1),
)

def _parse_relative_time(text, tzinfo, now=None):
    if now is None:     # now argument for unit tests
        now = datetime.now(tzinfo)
    if text == 'now':
        return now

    dt = None
    if text == 'today':
        dt = _time_starts['day'](now)
    elif text == 'yesterday':
        dt = _time_starts['day'](now) - timedelta(days=1)
    if dt is None:
        match = _REL_TIME_RE.match(text)
        if match:
            (value, interval) = match.groups()
            dt = now - _time_intervals[interval](float(value))
    if dt is None:
        match = _TIME_START_RE.match(text)
        if match:
            (which, start) = match.groups()
            dt = _time_starts[start](now)
            if which == 'last':
                if start == 'month':
                    if dt.month > 1:
                        dt = dt.replace(month=dt.month - 1)
                    else:
                        dt = dt.replace(year=dt.year - 1, month=12)
                elif start == 'year':
                    dt = dt.replace(year=dt.year - 1)
                else:
                    dt -= _time_intervals[start](1)

    if dt is None:
        return None
    if not dt.tzinfo:
        dt = tzinfo.localize(dt)
    return tzinfo.normalize(dt)

# -- formatting/parsing helper functions

def user_time(req, func, *args, **kwargs):
    """A helper function which passes to `tzinfo` and `locale` keyword
    arguments of `func` using `req` parameter. It is expected to be used with
    `format_*` and `parse_date` methods in `trac.util.datefmt` package.

    :param req: a instance of `Request`
    :param func: a function which must accept `tzinfo` and `locale` keyword
                 arguments
    :param args: arguments which pass to `func` function
    :param kwargs: keyword arguments which pass to `func` function
    """
    if 'tzinfo' not in kwargs:
        kwargs['tzinfo'] = getattr(req, 'tz', None)
    if 'locale' not in kwargs:
        kwargs['locale'] = getattr(req, 'lc_time', None)
    return func(*args, **kwargs)

# -- timezone utilities

class FixedOffset(tzinfo):
    """Fixed offset in minutes east from UTC."""

    def __init__(self, offset, name):
        self._offset = timedelta(minutes=offset)
        self.zone = name

    def __str__(self):
        return self.zone

    def __repr__(self):
        return '<FixedOffset "%s" %s>' % (self.zone, self._offset)

    def utcoffset(self, dt):
        return self._offset

    def tzname(self, dt):
        return self.zone

    def dst(self, dt):
        return _zero

    def localize(self, dt, is_dst=False):
        if dt.tzinfo is not None:
            raise ValueError('Not naive datetime (tzinfo is already set)')
        return dt.replace(tzinfo=self)

    def normalize(self, dt, is_dst=False):
        if dt.tzinfo is None:
            raise ValueError('Naive time (no tzinfo set)')
        return dt


class LocalTimezone(tzinfo):
    """A 'local' time zone implementation"""

    _std_offset = None
    _dst_offset = None
    _dst_diff = None
    _std_tz = None
    _dst_tz = None

    @classmethod
    def _initialize(cls):
        cls._std_tz = cls(False)
        cls._std_offset = timedelta(seconds=-time.timezone)
        if time.daylight:
            cls._dst_tz = cls(True)
            cls._dst_offset = timedelta(seconds=-time.altzone)
        else:
            cls._dst_tz = cls._std_tz
            cls._dst_offset = cls._std_offset
        cls._dst_diff = cls._dst_offset - cls._std_offset

    def __init__(self, is_dst=None):
        self.is_dst = is_dst

    def __str__(self):
        offset = self.utcoffset(datetime.now())
        secs = offset.days * 3600 * 24 + offset.seconds
        hours, rem = divmod(abs(secs), 3600)
        return 'UTC%c%02d:%02d' % ('-' if secs < 0 else '+', hours, rem / 60)

    def __repr__(self):
        if self.is_dst is None:
            return '<LocalTimezone "%s" %s "%s" %s>' % \
                   (time.tzname[False], self._std_offset,
                    time.tzname[True], self._dst_offset)
        if self.is_dst:
            offset = self._dst_offset
        else:
            offset = self._std_offset
        return '<LocalTimezone "%s" %s>' % (time.tzname[self.is_dst], offset)

    def _is_dst(self, dt, is_dst=False):
        if self.is_dst is not None:
            return self.is_dst

        tt = (dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second,
              dt.weekday(), 0)
        try:
            std_tt = time.localtime(time.mktime(tt + (0,)))
            dst_tt = time.localtime(time.mktime(tt + (1,)))
        except (ValueError, OverflowError):
            return False

        std_correct = std_tt.tm_isdst == 0
        dst_correct = dst_tt.tm_isdst == 1
        if std_correct is dst_correct:
            if is_dst is None:
                if std_correct is True:
                    raise ValueError('Ambiguous time "%s"' % dt)
                if std_correct is False:
                    raise ValueError('Non existent time "%s"' % dt)
            return is_dst
        if std_correct:
            return False
        if dst_correct:
            return True

    def utcoffset(self, dt):
        if self._is_dst(dt):
            return self._dst_offset
        else:
            return self._std_offset

    def dst(self, dt):
        if self._is_dst(dt):
            return self._dst_diff
        else:
            return _zero

    def tzname(self, dt):
        return time.tzname[self._is_dst(dt)]

    def localize(self, dt, is_dst=False):
        if dt.tzinfo is not None:
            raise ValueError('Not naive datetime (tzinfo is already set)')
        if self._is_dst(dt, is_dst):
            tz = self._dst_tz
        else:
            tz = self._std_tz
        return dt.replace(tzinfo=tz)

    def normalize(self, dt, is_dst=False):
        if dt.tzinfo is None:
            raise ValueError('Naive time (no tzinfo set)')
        if dt.tzinfo is localtz: # if not localized, returns without changes
            return dt
        return self.fromutc(dt.replace(tzinfo=self) - dt.utcoffset())

    def fromutc(self, dt):
        if dt.tzinfo is None or dt.tzinfo is not self:
            raise ValueError('fromutc: dt.tzinfo is not self')
        tt = time.localtime(to_timestamp(dt.replace(tzinfo=utc)))
        if tt.tm_isdst > 0:
            tz = self._dst_tz
        else:
            tz = self._std_tz
        return datetime(microsecond=dt.microsecond, tzinfo=tz, *tt[0:6])


utc = FixedOffset(0, 'UTC')
utcmin = datetime.min.replace(tzinfo=utc)
utcmax = datetime.max.replace(tzinfo=utc)
_epoc = datetime(1970, 1, 1, tzinfo=utc)
_zero = timedelta(0)
_min_ts = -(1 << 31)
_max_ts = (1 << 31) - 1

LocalTimezone._initialize()
localtz = LocalTimezone()

STDOFFSET = LocalTimezone._std_offset
DSTOFFSET = LocalTimezone._dst_offset
DSTDIFF = LocalTimezone._dst_diff


# Use a makeshift timezone implementation if pytz is not available.
# This implementation only supports fixed offset time zones.
#
_timezones = [
    FixedOffset(0, 'UTC'),
    FixedOffset(-720, 'GMT -12:00'), FixedOffset(-660, 'GMT -11:00'),
    FixedOffset(-600, 'GMT -10:00'), FixedOffset(-540, 'GMT -9:00'),
    FixedOffset(-480, 'GMT -8:00'),  FixedOffset(-420, 'GMT -7:00'),
    FixedOffset(-360, 'GMT -6:00'),  FixedOffset(-300, 'GMT -5:00'),
    FixedOffset(-240, 'GMT -4:00'),  FixedOffset(-180, 'GMT -3:00'),
    FixedOffset(-120, 'GMT -2:00'),  FixedOffset(-60, 'GMT -1:00'),
    FixedOffset(0, 'GMT'),           FixedOffset(60, 'GMT +1:00'),
    FixedOffset(120, 'GMT +2:00'),   FixedOffset(180, 'GMT +3:00'),
    FixedOffset(240, 'GMT +4:00'),   FixedOffset(300, 'GMT +5:00'),
    FixedOffset(360, 'GMT +6:00'),   FixedOffset(420, 'GMT +7:00'),
    FixedOffset(480, 'GMT +8:00'),   FixedOffset(540, 'GMT +9:00'),
    FixedOffset(600, 'GMT +10:00'),  FixedOffset(660, 'GMT +11:00'),
    FixedOffset(720, 'GMT +12:00'),  FixedOffset(780, 'GMT +13:00')]
_tzmap = dict([(z.zone, z) for z in _timezones])

all_timezones = [z.zone for z in _timezones]

try:
    import pytz

    _tzoffsetmap = dict([(tz.utcoffset(None), tz) for tz in _timezones
                         if tz.zone != 'UTC'])

    def timezone(tzname):
        """Fetch timezone instance by name or raise `KeyError`"""
        tz = get_timezone(tzname)
        if not tz:
            raise KeyError(tzname)
        return tz

    def get_timezone(tzname):
        """Fetch timezone instance by name or return `None`"""
        try:
            # if given unicode parameter, pytz.timezone fails with:
            # "type() argument 1 must be string, not unicode"
            tz = pytz.timezone(to_unicode(tzname).encode('ascii', 'replace'))
        except (KeyError, IOError):
            tz = _tzmap.get(tzname)
        if tz and tzname.startswith('Etc/'):
            tz = _tzoffsetmap.get(tz.utcoffset(None))
        return tz

    _pytz_zones = [tzname for tzname in pytz.common_timezones
                   if not tzname.startswith('Etc/') and
                      not tzname.startswith('GMT')]
    # insert just the GMT timezones into the pytz zones at the right location
    # the pytz zones already include UTC so skip it
    from bisect import bisect
    _gmt_index = bisect(_pytz_zones, 'GMT')
    all_timezones = _pytz_zones[:_gmt_index] + all_timezones[1:] + \
                    _pytz_zones[_gmt_index:]

except ImportError:
    pytz = None

    def timezone(tzname):
        """Fetch timezone instance by name or raise `KeyError`"""
        return _tzmap[tzname]

    def get_timezone(tzname):
        """Fetch timezone instance by name or return `None`"""
        return _tzmap.get(tzname)

########NEW FILE########
__FILENAME__ = dist
# -*- coding: utf-8 -*-
#
# Copyright (C) 2010 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

# Imports for backward compatibility
from trac.dist import get_l10n_cmdclass, get_l10n_js_cmdclass
try:
    from trac.dist import extract_javascript_script
except ImportError:
    pass


########NEW FILE########
__FILENAME__ = html
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from HTMLParser import HTMLParser
import re

from genshi import Markup, HTML, escape, unescape
from genshi.core import stripentities, striptags, START, END
from genshi.builder import Element, ElementFactory, Fragment
from genshi.filters.html import HTMLSanitizer
from genshi.input import ParseError

__all__ = ['escape', 'unescape', 'html', 'plaintext', 'find_element',
           'TracHTMLSanitizer', 'Deuglifier', 'FormTokenInjector']


class TracHTMLSanitizer(HTMLSanitizer):
    """Sanitize HTML constructions which are potentially vector of
    phishing or XSS attacks, in user-supplied HTML.

    See also `genshi.HTMLSanitizer`_.

    .. _genshi.HTMLSanitizer:
       http://genshi.edgewall.org/wiki/Documentation/filters.html#html-sanitizer
    """

    SAFE_CSS = frozenset([
        # CSS 3 properties <http://www.w3.org/TR/CSS/#properties>
        'background', 'background-attachment', 'background-color',
        'background-image', 'background-position', 'background-repeat',
        'border', 'border-bottom', 'border-bottom-color',
        'border-bottom-style', 'border-bottom-width', 'border-collapse',
        'border-color', 'border-left', 'border-left-color',
        'border-left-style', 'border-left-width', 'border-right',
        'border-right-color', 'border-right-style', 'border-right-width',
        'border-spacing', 'border-style', 'border-top', 'border-top-color',
        'border-top-style', 'border-top-width', 'border-width', 'bottom',
        'caption-side', 'clear', 'clip', 'color', 'content',
        'counter-increment', 'counter-reset', 'cursor', 'direction', 'display',
        'empty-cells', 'float', 'font', 'font-family', 'font-size',
        'font-style', 'font-variant', 'font-weight', 'height', 'left',
        'letter-spacing', 'line-height', 'list-style', 'list-style-image',
        'list-style-position', 'list-style-type', 'margin', 'margin-bottom',
        'margin-left', 'margin-right', 'margin-top', 'max-height', 'max-width',
        'min-height', 'min-width', 'opacity', 'orphans', 'outline',
        'outline-color', 'outline-style', 'outline-width', 'overflow',
        'padding', 'padding-bottom', 'padding-left', 'padding-right',
        'padding-top', 'page-break-after', 'page-break-before',
        'page-break-inside', 'position', 'quotes', 'right', 'table-layout',
        'text-align', 'text-decoration', 'text-indent', 'text-transform',
        'top', 'unicode-bidi', 'vertical-align', 'visibility', 'white-space',
        'widows', 'width', 'word-spacing', 'z-index',
    ])

    def __init__(self, safe_schemes=HTMLSanitizer.SAFE_SCHEMES,
                 safe_css=SAFE_CSS):
        safe_attrs = HTMLSanitizer.SAFE_ATTRS | frozenset(['style'])
        safe_schemes = frozenset(safe_schemes)
        super(TracHTMLSanitizer, self).__init__(safe_attrs=safe_attrs,
                                                safe_schemes=safe_schemes)
        self.safe_css = frozenset(safe_css)

    # IE6 <http://heideri.ch/jso/#80>
    _EXPRESSION_SEARCH = re.compile(
        u'[eE\uFF25\uFF45]'         # FULLWIDTH LATIN CAPITAL LETTER E
                                    # FULLWIDTH LATIN SMALL LETTER E
        u'[xX\uFF38\uFF58]'         # FULLWIDTH LATIN CAPITAL LETTER X
                                    # FULLWIDTH LATIN SMALL LETTER X
        u'[pP\uFF30\uFF50]'         # FULLWIDTH LATIN CAPITAL LETTER P
                                    # FULLWIDTH LATIN SMALL LETTER P
        u'[rR\u0280\uFF32\uFF52]'   # LATIN LETTER SMALL CAPITAL R
                                    # FULLWIDTH LATIN CAPITAL LETTER R
                                    # FULLWIDTH LATIN SMALL LETTER R
        u'[eE\uFF25\uFF45]'         # FULLWIDTH LATIN CAPITAL LETTER E
                                    # FULLWIDTH LATIN SMALL LETTER E
        u'[sS\uFF33\uFF53]{2}'      # FULLWIDTH LATIN CAPITAL LETTER S
                                    # FULLWIDTH LATIN SMALL LETTER S
        u'[iI\u026A\uFF29\uFF49]'   # LATIN LETTER SMALL CAPITAL I
                                    # FULLWIDTH LATIN CAPITAL LETTER I
                                    # FULLWIDTH LATIN SMALL LETTER I
        u'[oO\uFF2F\uFF4F]'         # FULLWIDTH LATIN CAPITAL LETTER O
                                    # FULLWIDTH LATIN SMALL LETTER O
        u'[nN\u0274\uFF2E\uFF4E]'   # LATIN LETTER SMALL CAPITAL N
                                    # FULLWIDTH LATIN CAPITAL LETTER N
                                    # FULLWIDTH LATIN SMALL LETTER N
    ).search

    # IE6 <http://openmya.hacker.jp/hasegawa/security/expression.txt>
    #     7) Particular bit of Unicode characters
    _URL_FINDITER = re.compile(
        u'[Uu][Rr\u0280][Ll\u029F]\s*\(([^)]+)').finditer

    def sanitize_css(self, text):
        decls = []
        text = self._strip_css_comments(self._replace_unicode_escapes(text))
        for decl in filter(None, text.split(';')):
            decl = decl.strip()
            if not decl:
                continue
            try:
                prop, value = decl.split(':', 1)
            except ValueError:
                continue
            if not self.is_safe_css(prop.strip().lower(), value.strip()):
                continue
            is_evil = False
            if self._EXPRESSION_SEARCH(decl):
                is_evil = True
            for match in self._URL_FINDITER(decl):
                if not self.is_safe_uri(match.group(1)):
                    is_evil = True
                    break
            if not is_evil:
                decls.append(decl.strip())
        return decls

    def __call__(self, stream):
        """Remove input type="password" elements from the stream
        """
        suppress = False
        for kind, data, pos in super(TracHTMLSanitizer, self).__call__(stream):
            if kind is START:
                tag, attrs = data
                if (tag == 'input' and
                    attrs.get('type', '').lower() == 'password'):
                    suppress = True
                else:
                    yield kind, data, pos
            elif kind is END:
                if not suppress:
                    yield kind, data, pos
                suppress = False
            else:
                yield kind, data, pos

    def is_safe_css(self, prop, value):
        """Determine whether the given css property declaration is to be
        considered safe for inclusion in the output.
        """
        if prop not in self.safe_css:
            return False
        # Position can be used for phishing, 'static' excepted
        if prop == 'position':
            return value.lower() == 'static'
        # Negative margins can be used for phishing
        if prop.startswith('margin'):
            return '-' not in value
        return True

    _NORMALIZE_NEWLINES = re.compile(r'\r\n').sub
    _UNICODE_ESCAPE = re.compile(
        r"""\\([0-9a-fA-F]{1,6})\s?|\\([^\r\n\f0-9a-fA-F'"{};:()#*])""",
        re.UNICODE).sub

    def _replace_unicode_escapes(self, text):
        def _repl(match):
            t = match.group(1)
            if t:
                code = int(t, 16)
                chr = unichr(code)
                if code <= 0x1f:
                    # replace space character because IE ignores control
                    # characters
                    chr = ' '
                elif chr == '\\':
                    chr = r'\\'
                return chr
            t = match.group(2)
            if t == '\\':
                return r'\\'
            else:
                return t
        return self._UNICODE_ESCAPE(_repl,
                                    self._NORMALIZE_NEWLINES('\n', text))

    _CSS_COMMENTS = re.compile(r'/\*.*?\*/').sub

    def _strip_css_comments(self, text):
        """Replace comments with space character instead of superclass which
        removes comments to avoid problems when nested comments.
        """
        return self._CSS_COMMENTS(' ', text)


class Deuglifier(object):
    """Help base class used for cleaning up HTML riddled with ``<FONT
    COLOR=...>`` tags and replace them with appropriate ``<span
    class="...">``.

    The subclass must define a `rules()` static method returning a
    list of regular expression fragments, each defining a capture
    group in which the name will be reused for the span's class. Two
    special group names, ``font`` and ``endfont`` are used to emit
    ``<span>`` and ``</span>``, respectively.
    """
    def __new__(cls):
        self = object.__new__(cls)
        if not hasattr(cls, '_compiled_rules'):
            cls._compiled_rules = re.compile('(?:%s)' % '|'.join(cls.rules()))
        self._compiled_rules = cls._compiled_rules
        return self

    def format(self, indata):
        return re.sub(self._compiled_rules, self.replace, indata)

    def replace(self, fullmatch):
        for mtype, match in fullmatch.groupdict().items():
            if match:
                if mtype == 'font':
                    return '<span>'
                elif mtype == 'endfont':
                    return '</span>'
                return '<span class="code-%s">' % mtype


class FormTokenInjector(HTMLParser):
    """Identify and protect forms from CSRF attacks.

    This filter works by adding a input type=hidden field to POST forms.
    """
    def __init__(self, form_token, out):
        HTMLParser.__init__(self)
        self.out = out
        self.token = form_token

    def handle_starttag(self, tag, attrs):
        self.out.write(self.get_starttag_text())
        if tag.lower() == 'form':
            for name, value in attrs:
                if name.lower() == 'method' and value.lower() == 'post':
                    self.out.write('<input type="hidden" name="__FORM_TOKEN"'
                                   ' value="%s"/>' % self.token)
                    break

    def handle_startendtag(self, tag, attrs):
        self.out.write(self.get_starttag_text())

    def handle_charref(self, name):
        self.out.write('&#%s;' % name)

    def handle_entityref(self, name):
        self.out.write('&%s;' % name)

    def handle_comment(self, data):
        self.out.write('<!--%s-->' % data)

    def handle_decl(self, data):
        self.out.write('<!%s>' % data)

    def handle_pi(self, data):
        self.out.write('<?%s?>' % data)

    def handle_data(self, data):
        self.out.write(data)

    def handle_endtag(self, tag):
        self.out.write('</' + tag + '>')


class TransposingElementFactory(ElementFactory):
    """A `genshi.builder.ElementFactory` which applies `func` to the
    named attributes before creating a `genshi.builder.Element`.
    """

    def __init__(self, func, namespace=None):
        ElementFactory.__init__(self, namespace=namespace)
        self.func = func

    def __getattr__(self, name):
        return ElementFactory.__getattr__(self, self.func(name))

html = TransposingElementFactory(str.lower)


def plaintext(text, keeplinebreaks=True):
    """Extract the text elements from (X)HTML content

    :param text: `unicode` or `genshi.builder.Fragment`
    :param keeplinebreaks: optionally keep linebreaks
    """
    if isinstance(text, Fragment):
        text = text.generate().render('text', encoding=None)
    else:
        text = stripentities(striptags(text))
    if not keeplinebreaks:
        text = text.replace(u'\n', u' ')
    return text


def find_element(frag, attr=None, cls=None):
    """Return the first element in the fragment having the given attribute or
    class, using a preorder depth-first search.
    """
    if isinstance(frag, Element):
        if attr is not None and attr in frag.attrib:
            return frag
        if cls is not None and cls in frag.attrib.get('class', '').split():
            return frag
    if isinstance(frag, Fragment):
        for child in frag.children:
            elt = find_element(child, attr, cls)
            if elt is not None:
                return elt


def expand_markup(stream, ctxt=None):
    """A Genshi stream filter for expanding `genshi.Markup` events.

    Note: Expansion may not be possible if the fragment is badly
    formed, or partial.
    """
    for event in stream:
        if isinstance(event[1], Markup):
            try:
                for subevent in HTML(event[1]):
                    yield subevent
            except ParseError:
                yield event
        else:
            yield event

########NEW FILE########
__FILENAME__ = presentation
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# Copyright (C) 2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

"""Various utility functions and classes that support common presentation
tasks such as grouping or pagination.
"""

from math import ceil
import re

__all__ = ['captioned_button', 'classes', 'first_last', 'group', 'istext',
           'prepared_paginate', 'paginate', 'Paginator']
__no_apidoc__ = 'prepared_paginate'

def captioned_button(req, symbol, text):
    """Return symbol and text or only symbol, according to user preferences."""
    return symbol if req.session.get('ui.use_symbols') \
        else u'%s %s' % (symbol, text)

def classes(*args, **kwargs):
    """Helper function for dynamically assembling a list of CSS class names
    in templates.

    Any positional arguments are added to the list of class names. All
    positional arguments must be strings:

    >>> classes('foo', 'bar')
    u'foo bar'

    In addition, the names of any supplied keyword arguments are added if they
    have a truth value:

    >>> classes('foo', bar=True)
    u'foo bar'
    >>> classes('foo', bar=False)
    u'foo'

    If none of the arguments are added to the list, this function returns
    `None`:

    >>> classes(bar=False)
    """
    classes = list(filter(None, args)) + [k for k, v in kwargs.items() if v]
    if not classes:
        return None
    return u' '.join(classes)

def first_last(idx, seq):
    """Generate ``first`` or ``last`` or both, according to the
    position `idx` in sequence `seq`.
    """
    return classes(first=idx == 0, last=idx == len(seq) - 1)


def group(iterable, num, predicate=None):
    """Combines the elements produced by the given iterable so that every `n`
    items are returned as a tuple.

    >>> items = [1, 2, 3, 4]
    >>> for item in group(items, 2):
    ...     print item
    (1, 2)
    (3, 4)

    The last tuple is padded with `None` values if its' length is smaller than
    `num`.

    >>> items = [1, 2, 3, 4, 5]
    >>> for item in group(items, 2):
    ...     print item
    (1, 2)
    (3, 4)
    (5, None)

    The optional `predicate` parameter can be used to flag elements that should
    not be packed together with other items. Only those elements where the
    predicate function returns True are grouped with other elements, otherwise
    they are returned as a tuple of length 1:

    >>> items = [1, 2, 3, 4]
    >>> for item in group(items, 2, lambda x: x != 3):
    ...     print item
    (1, 2)
    (3,)
    (4, None)
    """
    buf = []
    for item in iterable:
        flush = predicate and not predicate(item)
        if buf and flush:
            buf += [None] * (num - len(buf))
            yield tuple(buf)
            del buf[:]
        buf.append(item)
        if flush or len(buf) == num:
            yield tuple(buf)
            del buf[:]
    if buf:
        buf += [None] * (num - len(buf))
        yield tuple(buf)


def istext(text):
    """`True` for text (`unicode` and `str`), but `False` for `Markup`."""
    from genshi.core import Markup
    return isinstance(text, basestring) and not isinstance(text, Markup)

def prepared_paginate(items, num_items, max_per_page):
    if max_per_page == 0:
        num_pages = 1
    else:
        num_pages = int(ceil(float(num_items) / max_per_page))
    return items, num_items, num_pages

def paginate(items, page=0, max_per_page=10):
    """Simple generic pagination.

    Given an iterable, this function returns:
     * the slice of objects on the requested page,
     * the total number of items, and
     * the total number of pages.

    The `items` parameter can be a list, tuple, or iterator:

    >>> items = range(12)
    >>> items
    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
    >>> paginate(items)
    ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 12, 2)
    >>> paginate(items, page=1)
    ([10, 11], 12, 2)
    >>> paginate(iter(items))
    ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 12, 2)
    >>> paginate(iter(items), page=1)
    ([10, 11], 12, 2)

    This function also works with generators:

    >>> def generate():
    ...     for idx in range(12):
    ...         yield idx
    >>> paginate(generate())
    ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], 12, 2)
    >>> paginate(generate(), page=1)
    ([10, 11], 12, 2)

    The `max_per_page` parameter can be used to set the number of items that
    should be displayed per page:

    >>> items = range(12)
    >>> paginate(items, page=0, max_per_page=6)
    ([0, 1, 2, 3, 4, 5], 12, 2)
    >>> paginate(items, page=1, max_per_page=6)
    ([6, 7, 8, 9, 10, 11], 12, 2)
    """
    if not page:
        page = 0
    start = page * max_per_page
    stop = start + max_per_page

    count = None
    if hasattr(items, '__len__'):
        count = len(items)
        if count:
            assert start < count, 'Page %d out of range' % page

    try: # Try slicing first for better performance
        retval = items[start:stop]
    except TypeError: # Slicing not supported, so iterate through the whole list
        retval = []
        idx = -1 # Needed if items = []
        for idx, item in enumerate(items):
            if start <= idx < stop:
                retval.append(item)
            # If we already obtained the total number of items via `len()`,
            # we can break out of the loop as soon as we've got the last item
            # for the requested page
            if count is not None and idx >= stop:
                break
        if count is None:
            count = idx + 1

    return retval, count, int(ceil(float(count) / max_per_page))


class Paginator(object):
    """Pagination controller"""

    def __init__(self, items, page=0, max_per_page=10, num_items=None):
        if not page:
            page = 0

        if num_items is None:
            items, num_items, num_pages = paginate(items, page, max_per_page)
        else:
            items, num_items, num_pages = prepared_paginate(items, num_items,
                                                            max_per_page)
        offset = page * max_per_page
        self.page = page
        self.max_per_page = max_per_page
        self.items = items
        self.num_items = num_items
        self.num_pages = num_pages
        self.span = offset, offset + len(items)
        self.show_index = True

    def __iter__(self):
        return iter(self.items)

    def __len__(self):
        return len(self.items)

    def __nonzero__(self):
        return len(self.items) > 0

    def __setitem__(self, idx, value):
        self.items[idx] = value

    @property
    def has_more_pages(self):
        return self.num_pages > 1

    @property
    def has_next_page(self):
        return self.page + 1 < self.num_pages

    @property
    def has_previous_page(self):
        return self.page > 0

    def get_shown_pages(self, page_index_count = 11):
        if self.has_more_pages == False:
            return range(1, 2)

        min_page = 1
        max_page = int(ceil(float(self.num_items) / self.max_per_page))
        current_page = self.page + 1
        start_page = current_page - page_index_count / 2
        end_page = current_page + page_index_count / 2 + \
                   (page_index_count % 2 - 1)

        if start_page < min_page:
            start_page = min_page
        if end_page > max_page:
            end_page = max_page

        return range(start_page, end_page + 1)

    def displayed_items(self):
        from trac.util.translation import _
        start, stop = self.span
        total = self.num_items
        if start + 1 == stop:
            return _("%(last)d of %(total)d", last=stop, total=total)
        else:
            return _("%(start)d - %(stop)d of %(total)d",
                    start=self.span[0] + 1, stop=self.span[1], total=total)


def separated(items, sep=','):
    """Yield `(item, sep)` tuples, one for each element in `items`.

    `sep` will be `None` for the last item.

    >>> list(separated([1, 2]))
    [(1, ','), (2, None)]

    >>> list(separated([1]))
    [(1, None)]

    >>> list(separated("abc", ':'))
    [('a', ':'), ('b', ':'), ('c', None)]
    """
    items = iter(items)
    last = items.next()
    for i in items:
        yield last, sep
        last = i
    yield last, None


try:
    from json import dumps

    _js_quote = dict((c, '\\u%04x' % ord(c)) for c in '&<>')
    _js_quote_re = re.compile('[' + ''.join(_js_quote) + ']')

    def to_json(value):
        """Encode `value` to JSON."""
        def replace(match):
            return _js_quote[match.group(0)]
        text = dumps(value, sort_keys=True, separators=(',', ':'))
        return _js_quote_re.sub(replace, text)

except ImportError:
    from trac.util.text import to_js_string

    def to_json(value):
        """Encode `value` to JSON."""
        if isinstance(value, basestring):
            return to_js_string(value)
        elif value is None:
            return 'null'
        elif value is False:
            return 'false'
        elif value is True:
            return 'true'
        elif isinstance(value, (int, long)):
            return str(value)
        elif isinstance(value, float):
            return repr(value)
        elif isinstance(value, (list, tuple)):
            return '[%s]' % ','.join(to_json(each) for each in value)
        elif isinstance(value, dict):
            return '{%s}' % ','.join('%s:%s' % (to_json(k), to_json(v))
                                     for k, v in sorted(value.iteritems()))
        else:
            raise TypeError('Cannot encode type %s' % value.__class__.__name__)

########NEW FILE########
__FILENAME__ = concurrency
# -*- coding: utf-8 -*-
#
# Copyright (C) 2010 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import threading
import unittest

from trac.util.concurrency import ThreadLocal


class ThreadLocalTestCase(unittest.TestCase):

    def test_thread_local(self):
        local = ThreadLocal(a=1, b=2)
        local.b = 3
        local.c = 4
        local_dict = [local.__dict__.copy()]
        def f():
            local.b = 5
            local.d = 6
            local_dict.append(local.__dict__.copy())
        thread = threading.Thread(target=f)
        thread.start()
        thread.join()
        self.assertEqual(dict(a=1, b=3, c=4), local_dict[0])
        self.assertEqual(dict(a=1, b=5, d=6), local_dict[1])


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(ThreadLocalTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = datefmt
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2009 Edgewall Software
# Copyright (C) 2007 Matt Good <trac@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Matt Good <trac@matt-good.net>

import datetime
import os
import time
import unittest

from trac.core import TracError
from trac.util import datefmt, translation

try:
    import pytz
except ImportError:
    pytz = None
try:
    from babel import Locale
except ImportError:
    Locale = None

if pytz is None:
    PytzTestCase = None
else:
    class PytzTestCase(unittest.TestCase):
        def test_pytz_conversion(self):
            tz = datefmt.get_timezone('GMT +3:00')
            self.assertEqual(datetime.timedelta(hours=3),
                             tz.utcoffset(None))

        def test_posix_conversion(self):
            tz = datefmt.get_timezone('Etc/GMT-4')
            self.assertEqual(datetime.timedelta(hours=4),
                             tz.utcoffset(None))
            self.assertEqual('GMT +4:00', tz.zone)

        def test_unicode_input(self):
            tz = datefmt.get_timezone(u'Etc/GMT-4')
            self.assertEqual(datetime.timedelta(hours=4),
                             tz.utcoffset(None))
            self.assertEqual('GMT +4:00', tz.zone)

        def test_parse_date(self):
            tz = datefmt.get_timezone('Europe/Zurich')
            t_utc = datetime.datetime(2009, 12, 1, 11, 0, 0, 0, datefmt.utc)
            self.assertEqual(t_utc,
                    datefmt.parse_date('2009-12-01T12:00:00', tz))
            self.assertEqual(t_utc,
                    datefmt.parse_date('2009-12-01 12:00:00', tz))

        def test_parse_date_dst(self):
            tz = datefmt.get_timezone('Europe/Zurich')
            t_utc = datetime.datetime(2009, 8, 1, 10, 0, 0, 0, datefmt.utc)
            self.assertEqual(t_utc,
                    datefmt.parse_date('2009-08-01T12:00:00', tz))
            self.assertEqual(t_utc,
                    datefmt.parse_date('2009-08-01 12:00:00', tz))

        def test_parse_date_across_dst_boundary(self):
            tz = datefmt.get_timezone('Europe/Zurich')
            # DST start - 31 March, 02:00
            format = '%Y-%m-%d %H:%M:%S %Z%z'
            expected = '2002-03-31 03:30:00 CEST+0200'
            # iso8601
            t = datefmt.parse_date('2002-03-31T02:30:00', tz)
            self.assertEqual(expected, t.strftime(format))
            # strptime
            t = datetime.datetime(2002, 3, 31, 2, 30)
            t = datefmt.parse_date(t.strftime('%x %X'), tz)
            self.assertEqual(expected, t.strftime(format))
            # i18n datetime
            if Locale:
                en_US = Locale.parse('en_US')
                t = datefmt.parse_date('Mar 31, 2002 02:30', tz, en_US)
                self.assertEqual(expected, t.strftime(format))

        def test_to_datetime_pytz_normalize(self):
            tz = datefmt.get_timezone('Europe/Zurich')
            date = datefmt.to_datetime(datetime.date(2002, 3, 31), tz)
            format = '%Y-%m-%d %H:%M:%S %Z%z'
            expected = '2002-03-31 00:00:00 CET+0100'
            self.assertEqual(expected, date.strftime(format))

        def test_to_datetime_normalized(self):
            tz = datefmt.get_timezone('Europe/Paris')
            t = datetime.datetime(2012, 3, 25, 2, 15)
            dt = datefmt.to_datetime(t, tz)
            self.assertEqual(datetime.timedelta(0, 7200), dt.utcoffset())

        def test_parse_date_across_dst_boundary(self):
            tz = datefmt.get_timezone('Europe/Zurich')
            # DST start - 31 March, 02:00
            format = '%Y-%m-%d %H:%M:%S %Z%z'
            expected = '2002-03-31 03:30:00 CEST+0200'
            # iso8601
            t = datefmt.parse_date('2002-03-31T02:30:00', tz)
            self.assertEqual(expected, t.strftime(format))
            # strptime
            t = datetime.datetime(2002, 3, 31, 2, 30)
            t = datefmt.parse_date(t.strftime('%x %X'), tz)
            self.assertEqual(expected, t.strftime(format))

        def test_to_datetime_astimezone(self):
            tz = datefmt.get_timezone('Europe/Paris')
            t = datetime.datetime(2012, 3, 25, 2, 15, tzinfo=datefmt.utc)
            dt = datefmt.to_datetime(t, tz)
            self.assertEqual(datetime.timedelta(0, 7200), dt.utcoffset())

        def test_to_datetime_tz_from_naive_datetime_is_localtz(self):
            t = datetime.datetime(2012, 3, 25, 2, 15)
            dt = datefmt.to_datetime(t)
            self.assert_(isinstance(dt.tzinfo, datefmt.LocalTimezone))

        def test_to_datetime_tz_from_now_is_localtz(self):
            dt = datefmt.to_datetime(None)
            self.assert_(isinstance(dt.tzinfo, datefmt.LocalTimezone))


class ParseISO8601TestCase(unittest.TestCase):

    def test_iso8601_second(self):
        t = datetime.datetime(2012, 10, 11, 2, 40, 57, 0, datefmt.utc)
        self.assertEqual(t, datefmt.parse_date('2012-10-11T02:40:57Z'))
        self.assertEqual(t, datefmt.parse_date('2012-10-10T14:40:57-12:00'))
        self.assertEqual(t, datefmt.parse_date('2012-10-11T02:40:57+00:00'))
        self.assertEqual(t, datefmt.parse_date('2012-10-11T02:40:57-00:00'))
        self.assertEqual(t, datefmt.parse_date('2012-10-11T08:25:57+05:45'))
        self.assertEqual(t, datefmt.parse_date('2012-10-11T16:40:57+14:00'))
        self.assertEqual(t, datefmt.parse_date('20121011T024057Z'))
        self.assertEqual(t, datefmt.parse_date('20121010T144057-1200'))
        self.assertEqual(t, datefmt.parse_date('20121011T024057+0000'))
        self.assertEqual(t, datefmt.parse_date('20121011T024057-0000'))
        self.assertEqual(t, datefmt.parse_date('20121011T082557+0545'))
        self.assertEqual(t, datefmt.parse_date('20121011T164057+1400'))

    def test_iso8601_minute(self):
        t = datetime.datetime(2012, 10, 11, 2, 40, 0, 0, datefmt.utc)
        self.assertEqual(t, datefmt.parse_date('2012-10-11T02:40Z'))
        self.assertEqual(t, datefmt.parse_date('2012-10-10T14:40-12:00'))
        self.assertEqual(t, datefmt.parse_date('2012-10-11T16:40+14:00'))
        self.assertEqual(t, datefmt.parse_date('20121011T0240Z'))
        self.assertEqual(t, datefmt.parse_date('20121010T1440-1200'))
        self.assertEqual(t, datefmt.parse_date('20121011T1640+1400'))

    def test_iso8601_hour(self):
        t = datetime.datetime(2012, 10, 11, 2, 0, 0, 0, datefmt.utc)
        self.assertEqual(t, datefmt.parse_date('2012-10-11T02Z'))
        self.assertEqual(t, datefmt.parse_date('2012-10-10T14-12'))
        self.assertEqual(t, datefmt.parse_date('2012-10-10T14-12:00'))
        self.assertEqual(t, datefmt.parse_date('2012-10-11T16+14'))
        self.assertEqual(t, datefmt.parse_date('2012-10-11T16+14:00'))
        self.assertEqual(t, datefmt.parse_date('20121011T02Z'))
        self.assertEqual(t, datefmt.parse_date('20121010T14-12'))
        self.assertEqual(t, datefmt.parse_date('20121010T14-1200'))
        self.assertEqual(t, datefmt.parse_date('20121011T16+1400'))
        self.assertEqual(t, datefmt.parse_date('20121011T16+14'))

    def test_iso8601_day(self):
        t = datetime.datetime(2012, 10, 11, 0, 0, 0, 0, datefmt.localtz)
        self.assertEqual(t, datefmt.parse_date('2012-10-11'))
        self.assertEqual(t, datefmt.parse_date('20121011'))

    def test_iso8601_month(self):
        t = datetime.datetime(2012, 10, 1, 0, 0, 0, 0, datefmt.localtz)
        self.assertEqual(t, datefmt.parse_date('2012-10'))
        self.assertEqual(t, datefmt.parse_date('201210'))

    def test_iso8601_year(self):
        t = datetime.datetime(2012, 1, 1, 0, 0, 0, 0, datefmt.localtz)
        self.assertEqual(t, datefmt.parse_date('2012'))

    def test_iso8601_tz(self):
        self.assertEqual(
            datetime.timedelta(),
            datefmt.parse_date('2012-10-11T02:40:57Z').utcoffset())
        self.assertEqual(
            datetime.timedelta(hours=-12),
            datefmt.parse_date('2012-10-10T14:40:57-12').utcoffset())
        self.assertEqual(
            datetime.timedelta(hours=-9, minutes=-30),
            datefmt.parse_date('2012-10-10T17:10:57-09:30').utcoffset())
        self.assertEqual(
            datetime.timedelta(),
            datefmt.parse_date('2012-10-11T02:40:57+00:00').utcoffset())
        self.assertEqual(
            datetime.timedelta(),
            datefmt.parse_date('2012-10-11T02:40:57-00:00').utcoffset())
        self.assertEqual(
            datetime.timedelta(hours=5, minutes=45),
            datefmt.parse_date('2012-10-11T08:25:57+05:45').utcoffset())

    def test_iso8601_naive_tz_is_localtz(self):
        t = datetime.datetime(2012, 10, 11, 2, 40, 57, 0, datefmt.localtz)
        dt = datefmt.parse_date('2012-10-11T02:40:57')
        self.assertEqual(t, dt)
        self.assert_(isinstance(dt.tzinfo, datefmt.LocalTimezone))

    def test_iso8601_naive_tz_used_tzinfo_arg(self):
        tz = datefmt.timezone('GMT +1:00')
        t = datetime.datetime(2012, 10, 11, 2, 40, 57, 0, tz)
        dt = datefmt.parse_date('2012-10-11T02:40:57', tz)
        self.assertEqual(t, dt)
        self.assertEqual(tz, dt.tzinfo)
        self.assertEqual(datetime.timedelta(hours=1), dt.utcoffset())

    def test_iso8601_tz_not_used_tzinfo_arg(self):
        tz = datefmt.timezone('GMT +1:00')
        dt = datefmt.parse_date('2012-10-10T17:10:57-09:30', tz)
        self.assertEqual(datetime.timedelta(hours=-9, minutes=-30),
                         dt.utcoffset())

    if pytz:
        def test_iso8601_naive_tz_normalize_non_existent_time(self):
            t = datetime.datetime(2012, 3, 25, 1, 15, 57, 0, datefmt.utc)
            tz = datefmt.timezone('Europe/Paris')
            dt = datefmt.parse_date('2012-03-25T02:15:57', tz)
            self.assertEqual(t, dt)
            self.assertEqual(3, dt.hour)
            self.assertEqual(datetime.timedelta(hours=2), dt.utcoffset())

        def test_iso8601_naive_tz_normalize_ambiguous_time(self):
            t = datetime.datetime(2011, 10, 31, 1, 15, 57, 0, datefmt.utc)
            tz = datefmt.timezone('Europe/Paris')
            dt = datefmt.parse_date('2011-10-31T02:15:57', tz)
            self.assertEqual(t, dt)
            self.assertEqual(2, dt.hour)
            self.assertEqual(datetime.timedelta(hours=1), dt.utcoffset())


class ParseRelativeDateTestCase(unittest.TestCase):

    def test_time_interval_seconds(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        past_42s = datetime.datetime(2012, 3, 25, 3, 14, 39, 987654, tzinfo=tz)

        self.assertEqual(
            past_42s,
            datefmt._parse_relative_time('42second ago', tz, now))
        self.assertEqual(
            past_42s,
            datefmt._parse_relative_time('42 secondsago', tz, now))
        self.assertEqual(
            past_42s,
            datefmt._parse_relative_time('42 second', tz, now))
        self.assertEqual(
            past_42s,
            datefmt._parse_relative_time('42seconds', tz, now))
        self.assertEqual(
            None,
            datefmt._parse_relative_time('42s ago', tz, now))
        self.assertEqual(
            None,
            datefmt._parse_relative_time('42s', tz, now))

    def test_time_interval_minutes(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)

        self.assertEqual(
            datetime.datetime(2012, 3, 25, 2, 54, 21, 987654, tzinfo=tz),
            datefmt._parse_relative_time('21minute', tz, now))
        self.assertEqual(
            datetime.datetime(2012, 3, 25, 2, 54, 6, 987654, tzinfo=tz),
            datefmt._parse_relative_time('21.25 minutes', tz, now))

    def test_time_interval_hours(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        past_42h = datetime.datetime(2012, 3, 23, 9, 15, 21, 987654, tzinfo=tz)

        self.assertEqual(
            past_42h,
            datefmt._parse_relative_time('42 hours', tz, now))
        self.assertEqual(
            past_42h,
            datefmt._parse_relative_time('42h ago', tz, now))

    def test_time_interval_days(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        past_24d = datetime.datetime(2012, 3, 1, 3, 15, 21, 987654, tzinfo=tz)

        self.assertEqual(
            past_24d,
            datefmt._parse_relative_time('24day', tz, now))
        self.assertEqual(
            past_24d,
            datefmt._parse_relative_time('24ds', tz, now))

    def test_time_interval_weeks(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        past_3w = datetime.datetime(2012, 3, 4, 3, 15, 21, 987654, tzinfo=tz)

        self.assertEqual(past_3w,
                         datefmt._parse_relative_time('3 weeks', tz, now))
        self.assertEqual(past_3w,
                         datefmt._parse_relative_time('3w', tz, now))

    def test_time_interval_months(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 1, 1, 3, 15, 21, 987654, tzinfo=tz)
        past_12m = datetime.datetime(2011, 1, 6, 3, 15, 21, 987654, tzinfo=tz)

        self.assertEqual(
            past_12m,
            datefmt._parse_relative_time('12 months', tz, now))
        self.assertEqual(
            past_12m,
            datefmt._parse_relative_time('12 ms ago', tz, now))

    def test_time_interval_years(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        past_2y = datetime.datetime(2010, 3, 26, 3, 15, 21, 987654, tzinfo=tz)

        self.assertEqual(past_2y,
                         datefmt._parse_relative_time('2 years', tz, now))
        self.assertEqual(past_2y, datefmt._parse_relative_time('2y', tz, now))

    def test_time_start_now(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        self.assertEqual(now, datefmt._parse_relative_time('now', tz, now))

    def test_time_start_today(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        today = datefmt.to_datetime(datetime.datetime(2012, 3, 25), tzinfo=tz)
        self.assertEqual(today,
                         datefmt._parse_relative_time('today', tz, now))
        self.assertEqual(today,
                         datefmt._parse_relative_time('this day', tz, now))

    def test_time_start_yesterday(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        yesterday = datefmt.to_datetime(datetime.datetime(2012, 3, 24), tz)
        self.assertEqual(yesterday,
                         datefmt._parse_relative_time('yesterday', tz, now))
        self.assertEqual(yesterday,
                         datefmt._parse_relative_time('last day', tz, now))

    def test_time_start_year(self):
        tz = datefmt.timezone('GMT +1:00')

        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        self.assertEqual(datetime.datetime(2012, 1, 1, tzinfo=tz),
                         datefmt._parse_relative_time('this year', tz, now))
        self.assertEqual(datetime.datetime(2011, 1, 1, tzinfo=tz),
                         datefmt._parse_relative_time('last year', tz, now))

        now = datetime.datetime(2009, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        self.assertEqual(datetime.datetime(2009, 1, 1, tzinfo=tz),
                         datefmt._parse_relative_time('this year', tz, now))
        self.assertEqual(datetime.datetime(2008, 1, 1, tzinfo=tz),
                         datefmt._parse_relative_time('last year', tz, now))

    def test_time_start_month(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 1, 23, 3, 15, 42, 987654, tzinfo=tz)
        self.assertEqual(datetime.datetime(2012, 1, 1, tzinfo=tz),
                         datefmt._parse_relative_time('this month', tz, now))
        self.assertEqual(datetime.datetime(2011, 12, 1, tzinfo=tz),
                         datefmt._parse_relative_time('last month', tz, now))

    def test_time_start_week(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 21, 987654, tzinfo=tz)
        self.assertEqual(datetime.datetime(2012, 3, 19, tzinfo=tz),
                         datefmt._parse_relative_time('this week', tz, now))
        self.assertEqual(datetime.datetime(2012, 3, 12, tzinfo=tz),
                         datefmt._parse_relative_time('last week', tz, now))

    def test_time_start_day(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 1, 3, 15, 21, 987654, tzinfo=tz)
        self.assertEqual(datetime.datetime(2012, 3, 1, tzinfo=tz),
                         datefmt._parse_relative_time('this day', tz, now))
        self.assertEqual(datetime.datetime(2012, 2, 29, tzinfo=tz),
                         datefmt._parse_relative_time('last day', tz, now))

    def test_time_start_hour(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 0, 15, 21, 987654, tzinfo=tz)
        self.assertEqual(datetime.datetime(2012, 3, 25, 0, tzinfo=tz),
                         datefmt._parse_relative_time('this hour', tz, now))
        self.assertEqual(datetime.datetime(2012, 3, 24, 23, tzinfo=tz),
                         datefmt._parse_relative_time('last hour', tz, now))

    def test_time_start_minute(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 0, 21, 987654, tzinfo=tz)
        self.assertEqual(datetime.datetime(2012, 3, 25, 3, 0, tzinfo=tz),
                         datefmt._parse_relative_time('this minute', tz, now))
        self.assertEqual(datetime.datetime(2012, 3, 25, 2, 59, tzinfo=tz),
                         datefmt._parse_relative_time('last minute', tz, now))

    def test_time_start_second(self):
        tz = datefmt.timezone('GMT +1:00')
        now = datetime.datetime(2012, 3, 25, 3, 15, 0, 987654, tzinfo=tz)
        self.assertEqual(datetime.datetime(2012, 3, 25, 3, 15, 0, tzinfo=tz),
                         datefmt._parse_relative_time('this second', tz, now))
        self.assertEqual(datetime.datetime(2012, 3, 25, 3, 14, 59, tzinfo=tz),
                         datefmt._parse_relative_time('last second', tz, now))

    if pytz:
        def test_time_interval_across_dst(self):
            tz = datefmt.timezone('Europe/Paris')
            now = datefmt.to_datetime(datetime.datetime(2012, 3, 25, 3, 0, 41),
                                      tz)
            dt = datefmt._parse_relative_time('41 seconds', tz, now)
            self.assertEqual('2012-03-25T03:00:00+02:00', dt.isoformat())
            dt = datefmt._parse_relative_time('42 seconds', tz, now)
            self.assertEqual('2012-03-25T01:59:59+01:00', dt.isoformat())

        def test_this_time_start_across_dst(self):
            tz = datefmt.timezone('Europe/Paris')
            now = datefmt.to_datetime(
                datetime.datetime(2012, 3, 25, 3, 15, 21, 987654), tz)
            dt = datefmt._parse_relative_time('this hour', tz, now)
            self.assertEqual('2012-03-25T03:00:00+02:00', dt.isoformat())
            dt = datefmt._parse_relative_time('today', tz, now)
            self.assertEqual('2012-03-25T00:00:00+01:00', dt.isoformat())
            dt = datefmt._parse_relative_time('this day', tz, now)
            self.assertEqual('2012-03-25T00:00:00+01:00', dt.isoformat())

        def test_last_time_start_across_dst(self):
            tz = datefmt.timezone('Europe/Paris')
            now = datefmt.to_datetime(datetime.datetime(2012, 3, 26, 3, 0, 41),
                                      tz)
            dt = datefmt._parse_relative_time('this day', tz, now)
            self.assertEqual('2012-03-26T00:00:00+02:00', dt.isoformat())
            dt = datefmt._parse_relative_time('yesterday', tz, now)
            self.assertEqual('2012-03-25T00:00:00+01:00', dt.isoformat())
            dt = datefmt._parse_relative_time('last day', tz, now)
            self.assertEqual('2012-03-25T00:00:00+01:00', dt.isoformat())


class ParseDateValidRangeTestCase(unittest.TestCase):

    def test_max_timestamp(self):
        # At least all platforms support maximal signed 32 bits integer,
        # 2**31 - 1, INT32_MAX.
        datefmt.parse_date('2038-01-19T03:14:07Z')
        try:
            datefmt.parse_date('9999-12-31T23:59:59-12:00')
            raise AssertionError('TracError not raised')
        except TracError, e:
            self.assert_('is outside valid range' in unicode(e))

    def test_min_timestamp(self):
        if os.name != 'nt':
            # At least all Unix support minimal signed 32 bits integer,
            # -(2**31), INT32_MIN
            datefmt.parse_date('1901-12-13T20:45:52Z')
        else:
            # At least All VC run-times support 0 as time_t
            datefmt.parse_date('1970-01-01T00:00:00Z')
        try:
            datefmt.parse_date('0001-01-01T00:00:00+14:00')
            raise AssertionError('TracError not raised')
        except TracError, e:
            self.assert_('is outside valid range' in unicode(e))


class DateFormatTestCase(unittest.TestCase):

    def test_to_datetime(self):
        expected = datetime.datetime.fromtimestamp(23, datefmt.localtz)
        self.assertEqual(datefmt.to_datetime(23), expected)
        self.assertEqual(datefmt.to_datetime(23L), expected)
        self.assertEqual(datefmt.to_datetime(23.0), expected)

    def test_to_datetime_microsecond_timestamps(self):
        expected = datetime.datetime.fromtimestamp(2345.678912,
                                                   datefmt.localtz)
        self.assertEqual(datefmt.to_datetime(2345678912), expected)
        self.assertEqual(datefmt.to_datetime(2345678912L), expected)
        self.assertEqual(datefmt.to_datetime(2345678912.0), expected)

    def test_to_datetime_microsecond_negative_timestamps(self):
        # Work around issue1646728 in Python 2.4
        expected = datetime.datetime.fromtimestamp(-2345, datefmt.localtz) \
                   - datetime.timedelta(seconds=.678912)

        self.assertEqual(datefmt.to_datetime(-2345678912).microsecond,
                         321088) # 1000000 - 678912
        self.assertEqual(datefmt.to_datetime(-2345678912), expected)
        self.assertEqual(datefmt.to_datetime(-2345678912L), expected)
        self.assertEqual(datefmt.to_datetime(-2345678912.0), expected)
    if os.name == 'nt':
        del test_to_datetime_microsecond_negative_timestamps
        # negative timestamps not supported on Windows:
        # ValueError: timestamp out of range for platform localtime()/gmtime()

    def test_to_datetime_can_convert_dates(self):
        expected = datetime.datetime(2009, 5, 2, tzinfo=datefmt.localtz)
        self.assertEqual(datefmt.to_datetime(expected.date()), expected)

    def test_to_datetime_tz(self):
        tz = datefmt.timezone('GMT +1:00')
        expected = datetime.datetime(1970, 1, 1, 1, 0, 23, 0, tz)
        self.assertEqual(datefmt.to_datetime(23, tz), expected)
        self.assertEqual(datefmt.to_datetime(23L, tz), expected)
        self.assertEqual(datefmt.to_datetime(23.0, tz), expected)
        tz = datefmt.timezone('GMT +4:00')
        expected = datetime.datetime(1970, 1, 1, 4, 0, 23, 0, tz)
        self.assertEqual(datefmt.to_datetime(23, tz), expected)
        self.assertEqual(datefmt.to_datetime(23L, tz), expected)
        self.assertEqual(datefmt.to_datetime(23.0, tz), expected)

    def test_format_datetime_utc(self):
        t = datetime.datetime(1970, 1, 1, 1, 0, 23, 0, datefmt.utc)
        expected = '1970-01-01T01:00:23Z'
        self.assertEqual(datefmt.format_datetime(t, '%Y-%m-%dT%H:%M:%SZ',
                                                 datefmt.utc), expected)
        self.assertEqual(datefmt.format_datetime(t, 'iso8601',
                                                 datefmt.utc), expected)
        self.assertEqual(datefmt.format_datetime(t, 'iso8601date',
                                                 datefmt.utc),
                                                 expected.split('T')[0])
        self.assertEqual(datefmt.format_datetime(t, 'iso8601time',
                                                 datefmt.utc),
                                                 expected.split('T')[1])
        self.assertEqual(datefmt.format_date(t, 'iso8601', datefmt.utc),
                         expected.split('T')[0])
        self.assertEqual(datefmt.format_time(t, 'iso8601', datefmt.utc),
                         expected.split('T')[1])

    def test_format_datetime_gmt01(self):
        gmt01 = datefmt.FixedOffset(60, 'GMT +1:00')
        t = datetime.datetime(1970, 1, 1, 1, 0, 23, 0, gmt01)
        self.assertEqual('1970-01-01T01:00:23+0100',
                         datefmt.format_datetime(t, '%Y-%m-%dT%H:%M:%S%z',
                                                 gmt01))
        expected = '1970-01-01T01:00:23+01:00'
        self.assertEqual(datefmt.format_datetime(t, 'iso8601',
                                                 gmt01), expected)
        self.assertEqual(datefmt.format_datetime(t, 'iso8601date', gmt01),
                                                 expected.split('T')[0])
        self.assertEqual(datefmt.format_datetime(t, 'iso8601time', gmt01),
                                                 expected.split('T')[1])
        self.assertEqual(datefmt.format_date(t, 'iso8601', gmt01),
                         expected.split('T')[0])
        self.assertEqual(datefmt.format_time(t, 'iso8601', gmt01),
                         expected.split('T')[1])

    def test_format_date_accepts_date_instances(self):
        a_date = datetime.date(2009, 8, 20)
        self.assertEqual('2009-08-20',
                         datefmt.format_date(a_date, format='%Y-%m-%d'))

    def test_format_compatibility(self):
        tz = datefmt.timezone('GMT +2:00')
        t = datetime.datetime(2010, 8, 28, 11, 45, 56, 123456, datefmt.utc)
        tz_t = datetime.datetime(2010, 8, 28, 13, 45, 56, 123456, tz)

        # Converting babel's format to strftime format
        self.assertEqual(tz_t.strftime('%x %H:%M').decode('utf-8'),
                         datefmt.format_datetime(t, 'short', tz))
        self.assertEqual(tz_t.strftime('%x').decode('utf-8'),
                         datefmt.format_date(t, 'short', tz))
        self.assertEqual(tz_t.strftime('%H:%M').decode('utf-8'),
                         datefmt.format_time(t, 'short', tz))
        for f in ('medium', 'long', 'full'):
            self.assertEqual(tz_t.strftime('%x %X').decode('utf-8'),
                             datefmt.format_datetime(t, f, tz))
            self.assertEqual(tz_t.strftime('%x').decode('utf-8'),
                             datefmt.format_date(t, f, tz))
            self.assertEqual(tz_t.strftime('%X').decode('utf-8'),
                             datefmt.format_time(t, f, tz))


class UTimestampTestCase(unittest.TestCase):

    def test_sub_second(self):
        t = datetime.datetime(2001, 2, 3, 4, 5, 6, 123456, datefmt.utc)
        ts = datefmt.to_utimestamp(t)
        self.assertEqual(981173106123456L, ts)
        self.assertEqual(t, datefmt.from_utimestamp(ts))


class ISO8601TestCase(unittest.TestCase):
    def test_default(self):
        tz = datefmt.timezone('GMT +2:00')
        t = datetime.datetime(2010, 8, 28, 11, 45, 56, 123456, tz)
        self.assertEqual('2010-08-28',
                         datefmt.format_date(t, tzinfo=tz, locale='iso8601'))
        self.assertEqual('11:45:56+02:00',
                         datefmt.format_time(t, tzinfo=tz, locale='iso8601'))
        self.assertEqual('2010-08-28T11:45:56+02:00',
                         datefmt.format_datetime(t, tzinfo=tz,
                                                 locale='iso8601'))

    def test_with_iso8601(self):
        tz = datefmt.timezone('GMT +2:00')
        t = datetime.datetime(2010, 8, 28, 11, 45, 56, 123456, tz)
        self.assertEqual('2010-08-28',
                         datefmt.format_date(t, 'iso8601', tz, 'iso8601'))
        self.assertEqual('11:45:56+02:00',
                         datefmt.format_time(t, 'iso8601', tz, 'iso8601'))
        self.assertEqual('2010-08-28T11:45:56+02:00',
                         datefmt.format_datetime(t, 'iso8601', tz, 'iso8601'))

    def test_parse_date_offset(self):
        t_utc = datetime.datetime(2009, 12, 1, 11, 0, 0, 0, datefmt.utc)
        self.assertEqual(t_utc,
                         datefmt.parse_date('2009-12-01T11:00:00Z'))
        self.assertEqual(t_utc,
                         datefmt.parse_date('2009-12-01T11:00:00+00:00'))
        self.assertEqual(t_utc,
                         datefmt.parse_date('2009-12-01T11:00:00-00:00'))
        self.assertEqual(t_utc,
                         datefmt.parse_date('2009-12-01T09:00:00-02:00'))
        self.assertEqual(t_utc,
                         datefmt.parse_date('2009-12-01T11:30:00+00:30'))

    def test_parse_date_usec(self):
        tz = datefmt.get_timezone('GMT +1:00')
        t_utc = datetime.datetime(2009, 12, 1, 11, 0, 0, 98765, datefmt.utc)
        self.assertEqual(t_utc,
                         datefmt.parse_date('2009-12-01T12:00:00.098765', tz))
        self.assertEqual(t_utc,
                         datefmt.parse_date('2009-12-01T12:00:00,098765', tz))
        self.assertEqual(datetime.datetime(2009, 12, 1, 11, 0, 0, 98700,
                                           datefmt.utc),
                         datefmt.parse_date('2009-12-01T12:00:00.0987', tz))
        self.assertEqual(datetime.datetime(2009, 12, 1, 11, 0, 0, 90000,
                                           datefmt.utc),
                         datefmt.parse_date('2009-12-01T12:00:00.09', tz))
        self.assertEqual(datetime.datetime(2009, 12, 1, 11, 0, 0, 0,
                                           datefmt.utc),
                         datefmt.parse_date('2009-12-01T12:00:00.0', tz))

    def test_with_babel_format(self):
        tz = datefmt.timezone('GMT +2:00')
        t = datetime.datetime(2010, 8, 28, 11, 45, 56, 123456, tz)
        for f in ('short', 'medium', 'long', 'full'):
            self.assertEqual('2010-08-28',
                             datefmt.format_date(t, f, tz, 'iso8601'))
        self.assertEqual('11:45',
                         datefmt.format_time(t, 'short', tz, 'iso8601'))
        self.assertEqual('2010-08-28T11:45',
                         datefmt.format_datetime(t, 'short', tz, 'iso8601'))
        self.assertEqual('11:45:56',
                         datefmt.format_time(t, 'medium', tz, 'iso8601'))
        self.assertEqual('2010-08-28T11:45:56',
                         datefmt.format_datetime(t, 'medium', tz, 'iso8601'))
        for f in ('long', 'full'):
            self.assertEqual('11:45:56+02:00',
                             datefmt.format_time(t, f, tz, 'iso8601'))
            self.assertEqual('2010-08-28T11:45:56+02:00',
                             datefmt.format_datetime(t, f, tz, 'iso8601'))

    def test_hint(self):
        try:
            datefmt.parse_date('***', locale='iso8601', hint='date')
        except TracError, e:
            self.assert_('"YYYY-MM-DD"' in unicode(e))
        try:
            datefmt.parse_date('***', locale='iso8601', hint='datetime')
        except TracError, e:
            self.assert_(u'"YYYY-MM-DDThh:mm:sshh:mm"' in unicode(e))
        try:
            datefmt.parse_date('***', locale='iso8601', hint='foobar')
        except TracError, e:
            self.assert_('"foobar"' in unicode(e))


if Locale is None:
    I18nDateFormatTestCase = None
else:
    class I18nDateFormatTestCase(unittest.TestCase):
        def test_i18n_format_datetime(self):
            tz = datefmt.timezone('GMT +2:00')
            t = datetime.datetime(2010, 8, 28, 11, 45, 56, 123456, datefmt.utc)
            en_US = Locale.parse('en_US')
            self.assertEqual('Aug 28, 2010 1:45:56 PM',
                             datefmt.format_datetime(t, tzinfo=tz,
                                                     locale=en_US))
            en_GB = Locale.parse('en_GB')
            self.assertEqual('28 Aug 2010 13:45:56',
                             datefmt.format_datetime(t, tzinfo=tz,
                                                     locale=en_GB))
            fr = Locale.parse('fr')
            self.assertEqual(u'28 aot 2010 13:45:56',
                             datefmt.format_datetime(t, tzinfo=tz, locale=fr))
            ja = Locale.parse('ja')
            self.assertEqual(u'2010/08/28 13:45:56',
                             datefmt.format_datetime(t, tzinfo=tz, locale=ja))
            vi = Locale.parse('vi')
            self.assertEqual(u'13:45:56 28-08-2010',
                             datefmt.format_datetime(t, tzinfo=tz, locale=vi))
            zh_CN = Locale.parse('zh_CN')
            self.assertEqual(u'2010-8-28 01:45:56',
                             datefmt.format_datetime(t, tzinfo=tz,
                                                     locale=zh_CN))

        def test_i18n_format_date(self):
            tz = datefmt.timezone('GMT +2:00')
            t = datetime.datetime(2010, 8, 7, 11, 45, 56, 123456, datefmt.utc)
            en_US = Locale.parse('en_US')
            self.assertEqual('Aug 7, 2010',
                             datefmt.format_date(t, tzinfo=tz, locale=en_US))
            en_GB = Locale.parse('en_GB')
            self.assertEqual('7 Aug 2010',
                             datefmt.format_date(t, tzinfo=tz, locale=en_GB))
            fr = Locale.parse('fr')
            self.assertEqual(u'7 aot 2010',
                             datefmt.format_date(t, tzinfo=tz, locale=fr))
            ja = Locale.parse('ja')
            self.assertEqual(u'2010/08/07',
                             datefmt.format_date(t, tzinfo=tz, locale=ja))
            vi = Locale.parse('vi')
            self.assertEqual(u'07-08-2010',
                             datefmt.format_date(t, tzinfo=tz, locale=vi))
            zh_CN = Locale.parse('zh_CN')
            self.assertEqual(u'2010-8-7',
                             datefmt.format_date(t, tzinfo=tz, locale=zh_CN))

        def test_i18n_format_time(self):
            tz = datefmt.timezone('GMT +2:00')
            t = datetime.datetime(2010, 8, 28, 11, 45, 56, 123456, datefmt.utc)
            en_US = Locale.parse('en_US')
            en_GB = Locale.parse('en_GB')
            fr = Locale.parse('fr')
            ja = Locale.parse('ja')
            vi = Locale.parse('vi')
            zh_CN = Locale.parse('zh_CN')

            self.assertEqual('1:45:56 PM',
                             datefmt.format_time(t, tzinfo=tz, locale=en_US))
            self.assertEqual('13:45:56',
                             datefmt.format_time(t, tzinfo=tz, locale=en_GB))
            self.assertEqual('13:45:56',
                             datefmt.format_time(t, tzinfo=tz, locale=fr))
            self.assertEqual('13:45:56',
                             datefmt.format_time(t, tzinfo=tz, locale=ja))
            self.assertEqual('13:45:56',
                             datefmt.format_time(t, tzinfo=tz, locale=vi))
            self.assertEqual(u'01:45:56',
                             datefmt.format_time(t, tzinfo=tz, locale=zh_CN))

        def test_i18n_datetime_hint(self):
            en_US = Locale.parse('en_US')
            en_GB = Locale.parse('en_GB')
            fr = Locale.parse('fr')
            ja = Locale.parse('ja')
            vi = Locale.parse('vi')
            zh_CN = Locale.parse('zh_CN')

            self.assert_(datefmt.get_datetime_format_hint(en_US)
                         in ('MMM d, yyyy h:mm:ss a', 'MMM d, y h:mm:ss a'))
            self.assert_(datefmt.get_datetime_format_hint(en_GB)
                         in ('d MMM yyyy HH:mm:ss', 'd MMM y HH:mm:ss'))
            self.assert_(datefmt.get_datetime_format_hint(fr)
                         in ('d MMM yyyy HH:mm:ss', 'd MMM y HH:mm:ss'))
            self.assertEqual('yyyy/MM/dd H:mm:ss',
                             datefmt.get_datetime_format_hint(ja))
            self.assertEqual('HH:mm:ss dd-MM-yyyy',
                             datefmt.get_datetime_format_hint(vi))
            self.assertEqual('yyyy-M-d ahh:mm:ss',
                             datefmt.get_datetime_format_hint(zh_CN))

        def test_i18n_date_hint(self):
            en_US = Locale.parse('en_US')
            en_GB = Locale.parse('en_GB')
            fr = Locale.parse('fr')
            ja = Locale.parse('ja')
            vi = Locale.parse('vi')
            zh_CN = Locale.parse('zh_CN')

            self.assert_(datefmt.get_date_format_hint(en_US)
                         in ('MMM d, yyyy', 'MMM d, y'))
            self.assert_(datefmt.get_date_format_hint(en_GB)
                         in ('d MMM yyyy', 'd MMM y'))
            self.assert_(datefmt.get_date_format_hint(fr)
                         in ('d MMM yyyy', 'd MMM y'))
            self.assertEqual('yyyy/MM/dd',
                             datefmt.get_date_format_hint(ja))
            self.assertEqual('dd-MM-yyyy',
                             datefmt.get_date_format_hint(vi))
            self.assertEqual('yyyy-M-d',
                             datefmt.get_date_format_hint(zh_CN))

        def test_i18n_parse_date_iso8609(self):
            tz = datefmt.timezone('GMT +2:00')
            dt = datetime.datetime(2010, 8, 28, 13, 45, 56, 0, tz)
            d = datetime.datetime(2010, 8, 28, 0, 0, 0, 0, tz)
            en_US = Locale.parse('en_US')
            vi = Locale.parse('vi')

            def iso8601(expected, text, tz, locale):
                self.assertEqual(expected,
                                 datefmt.parse_date(text, tz, locale))

            iso8601(dt, '2010-08-28T15:45:56+0400', tz, en_US)
            iso8601(dt, '2010-08-28T11:45:56+0000', tz, vi)
            iso8601(dt, '2010-08-28T11:45:56Z', tz, vi)
            iso8601(dt, '20100828T144556+0300', tz, en_US)
            iso8601(dt, '20100828T114556Z', tz, vi)

            iso8601(d, '2010-08-28+0200', tz, en_US)
            # iso8601(d, '2010-08-28+0000', tz, vi)
            # iso8601(d, '2010-08-28Z', tz, en_US)
            iso8601(d, '2010-08-28', tz, vi)
            iso8601(d, '20100828+0200', tz, en_US)
            # iso8601(d, '20100828Z', tz, vi)

        def test_i18n_parse_date_datetime(self):
            tz = datefmt.timezone('GMT +2:00')
            expected = datetime.datetime(2010, 8, 28, 13, 45, 56, 0, tz)
            expected_minute = datetime.datetime(2010, 8, 28, 13, 45, 0, 0, tz)
            en_US = Locale.parse('en_US')
            en_GB = Locale.parse('en_GB')
            fr = Locale.parse('fr')
            ja = Locale.parse('ja')
            vi = Locale.parse('vi')
            zh_CN = Locale.parse('zh_CN')

            self.assertEqual(expected,
                             datefmt.parse_date('Aug 28, 2010 1:45:56 PM', tz,
                                                en_US))
            self.assertEqual(expected,
                             datefmt.parse_date('8 28, 2010 1:45:56 PM', tz,
                                                en_US))
            self.assertEqual(expected,
                             datefmt.parse_date('28 Aug 2010 1:45:56 PM', tz,
                                                en_US))
            self.assertEqual(expected,
                             datefmt.parse_date('28 Aug 2010 PM 1:45:56', tz,
                                                en_US))
            self.assertEqual(expected,
                             datefmt.parse_date('28 Aug 2010 13:45:56', tz,
                                                en_US))
            self.assertEqual(expected_minute,
                             datefmt.parse_date('28 Aug 2010 PM 1:45', tz,
                                                en_US))

            self.assertEqual(expected,
                             datefmt.parse_date('28 Aug 2010 13:45:56', tz,
                                                en_GB))

            self.assertEqual(expected,
                             datefmt.parse_date(u'28 aot 2010 13:45:56', tz,
                                                fr))
            self.assertEqual(expected,
                             datefmt.parse_date(u'aot 28 2010 13:45:56', tz,
                                                fr))
            self.assertEqual(expected_minute,
                             datefmt.parse_date(u'aot 28 2010 13:45', tz,
                                                fr))

            self.assertEqual(expected,
                             datefmt.parse_date('2010/08/28 13:45:56', tz, ja))
            self.assertEqual(expected_minute,
                             datefmt.parse_date('2010/08/28 13:45', tz, ja))

            self.assertEqual(expected,
                             datefmt.parse_date('13:45:56 28-08-2010', tz, vi))
            self.assertEqual(expected_minute,
                             datefmt.parse_date('13:45 28-08-2010', tz, vi))

            self.assertEqual(expected,
                             datefmt.parse_date(u'2010-8-28 01:45:56',
                                                tz, zh_CN))
            self.assertEqual(expected,
                             datefmt.parse_date(u'2010-8-28 01:45:56',
                                                tz, zh_CN))
            self.assertEqual(expected_minute,
                             datefmt.parse_date(u'2010-8-28 01:45', tz,
                                                zh_CN))
            self.assertEqual(expected_minute,
                             datefmt.parse_date(u'2010-8-28 01:45', tz,
                                                zh_CN))

        def test_i18n_parse_date_datetime_meridiem(self):
            tz = datefmt.timezone('GMT +2:00')
            expected_am = datetime.datetime(2011, 2, 22, 0, 45, 56, 0, tz)
            expected_pm = datetime.datetime(2011, 2, 22, 12, 45, 56, 0, tz)
            en_US = Locale.parse('en_US')
            zh_CN = Locale.parse('zh_CN')

            self.assertEqual(expected_am,
                             datefmt.parse_date('Feb 22, 2011 0:45:56 AM', tz,
                                                en_US))
            self.assertEqual(expected_am,
                             datefmt.parse_date('Feb 22, 2011 12:45:56 AM', tz,
                                                en_US))
            self.assertEqual(expected_am,
                             datefmt.parse_date(u'2011-2-22 0:45:56', tz,
                                                zh_CN))
            self.assertEqual(expected_am,
                             datefmt.parse_date(u'2011-2-22 12:45:56', tz,
                                                zh_CN))

            self.assertEqual(expected_pm,
                             datefmt.parse_date('Feb 22, 2011 0:45:56 PM', tz,
                                                en_US))
            self.assertEqual(expected_pm,
                             datefmt.parse_date('Feb 22, 2011 12:45:56 PM', tz,
                                                en_US))
            self.assertEqual(expected_pm,
                             datefmt.parse_date(u'2011-2-22 0:45:56', tz,
                                                zh_CN))
            self.assertEqual(expected_pm,
                             datefmt.parse_date(u'2011-2-22 12:45:56', tz,
                                                zh_CN))

        def test_i18n_parse_date_date(self):
            tz = datefmt.timezone('GMT +2:00')
            expected = datetime.datetime(2010, 8, 28, 0, 0, 0, 0, tz)
            en_US = Locale.parse('en_US')
            en_GB = Locale.parse('en_GB')
            fr = Locale.parse('fr')
            ja = Locale.parse('ja')
            vi = Locale.parse('vi')
            zh_CN = Locale.parse('zh_CN')

            self.assertEqual(expected,
                             datefmt.parse_date('Aug 28, 2010', tz, en_US))
            self.assertEqual(expected,
                             datefmt.parse_date('28 Aug 2010', tz, en_GB))
            self.assertEqual(expected,
                             datefmt.parse_date(u'28 aot 2010', tz, fr))
            self.assertEqual(expected,
                             datefmt.parse_date('2010/08/28', tz, ja))
            self.assertEqual(expected,
                             datefmt.parse_date('28-08-2010', tz, vi))
            self.assertEqual(expected,
                             datefmt.parse_date(u'2010-8-28', tz, zh_CN))

        def test_i18n_parse_date_roundtrip(self):
            tz = datefmt.timezone('GMT +2:00')
            t = datetime.datetime(2010, 8, 28, 11, 45, 56, 123456, datefmt.utc)
            expected = datetime.datetime(2010, 8, 28, 13, 45, 56, 0, tz)

            for locale in translation.get_available_locales():
                locale = Locale.parse(locale)
                formatted = datefmt.format_datetime(t, tzinfo=tz,
                                                    locale=locale)

                actual = datefmt.parse_date(formatted, tz, locale)
                self.assertEqual(expected, actual,
                                 '%r != %r (%r)' % (expected, actual, locale))

                actual = datefmt.format_datetime(expected, tzinfo=tz,
                                                 locale=locale)
                self.assertEqual(formatted, actual,
                                 '%r != %r (%r)' % (formatted, actual, locale))

        def test_format_compatibility(self):
            tz = datefmt.timezone('GMT +2:00')
            t = datetime.datetime(2010, 8, 28, 11, 45, 56, 123456, datefmt.utc)
            tz_t = datetime.datetime(2010, 8, 28, 13, 45, 56, 123456, tz)
            en_US = Locale.parse('en_US')

            # Converting default format to babel's format
            self.assertEqual('Aug 28, 2010 1:45:56 PM',
                             datefmt.format_datetime(t, '%x %X', tz, en_US))
            self.assertEqual('Aug 28, 2010',
                             datefmt.format_datetime(t, '%x', tz, en_US))
            self.assertEqual('1:45:56 PM',
                             datefmt.format_datetime(t, '%X', tz, en_US))
            self.assertEqual('Aug 28, 2010',
                             datefmt.format_date(t, '%x', tz, en_US))
            self.assertEqual('1:45:56 PM',
                             datefmt.format_time(t, '%X', tz, en_US))

        def test_parse_invalid_date(self):
            tz = datefmt.timezone('GMT +2:00')
            en_US = Locale.parse('en_US')

            self.assertRaises(TracError, datefmt.parse_date,
                              '',
                              tzinfo=tz, locale=en_US, hint='date')
            self.assertRaises(TracError, datefmt.parse_date,
                              '2011 Apr Mar',
                              tzinfo=tz, locale=en_US, hint='date')
            self.assertRaises(TracError, datefmt.parse_date,
                              '29 Feb',
                              tzinfo=tz, locale=en_US, hint='date')
            self.assertRaises(TracError, datefmt.parse_date,
                              'Feb 2011',
                              tzinfo=tz, locale=en_US, hint='date')
            self.assertRaises(TracError, datefmt.parse_date,
                              '29 Feb 2010',
                              tzinfo=tz, locale=en_US, hint='date')
            self.assertRaises(TracError, datefmt.parse_date,
                              '29 Xxx 2012',
                              tzinfo=tz, locale=en_US, hint='date')
            self.assertRaises(TracError, datefmt.parse_date,
                              '29 Xxx 2012 4:00:00 AM',
                              tzinfo=tz, locale=en_US, hint='datetime')
            self.assertRaises(TracError, datefmt.parse_date,
                              '29 2012 4:01:02 AM Feb',
                              tzinfo=tz, locale=en_US, hint='datetime')
            self.assertRaises(TracError, datefmt.parse_date,
                              '29 2012 4:00 Feb',
                              tzinfo=tz, locale=en_US, hint='datetime')


class HttpDateTestCase(unittest.TestCase):

    def test_http_date(self):
        t = datetime.datetime(2001, 2, 3, 4, 5, 6, 123456, datefmt.utc)
        self.assertEqual('Sat, 03 Feb 2001 04:05:06 GMT', datefmt.http_date(t))


class LocalTimezoneTestCase(unittest.TestCase):

    def setUp(self):
        self.env_tz = os.environ.get('TZ')

    def tearDown(self):
        self._tzset(self.env_tz)

    def _tzset(self, tz):
        if tz is not None:
            os.environ['TZ'] = tz
        elif 'TZ' in os.environ:
            del os.environ['TZ']
        time.tzset()
        datefmt.LocalTimezone._initialize()

    def test_gmt01(self):
        self._tzset('GMT-1')
        self.assertEqual(datetime.timedelta(hours=1),
                         datefmt.LocalTimezone._std_offset)
        self.assertEqual(datetime.timedelta(hours=1),
                         datefmt.LocalTimezone._dst_offset)
        self.assertEqual(datetime.timedelta(0),
                         datefmt.LocalTimezone._dst_diff)

    def test_europe_paris(self):
        self._tzset('Europe/Paris')
        self.assertEqual(datetime.timedelta(hours=1),
                         datefmt.LocalTimezone._std_offset)
        self.assertEqual(datetime.timedelta(hours=2),
                         datefmt.LocalTimezone._dst_offset)
        self.assertEqual(datetime.timedelta(hours=1),
                         datefmt.LocalTimezone._dst_diff)

    def test_utcoffset_not_localized(self):
        self._tzset('Europe/Paris')
        self.assertEqual(datetime.timedelta(hours=1),
                         datetime.datetime(2012, 3, 25, 1, 15, 42, 123456,
                                           datefmt.localtz).utcoffset())
        self.assertEqual(datetime.timedelta(hours=2),
                         datetime.datetime(2012, 3, 25, 3, 15, 42, 123456,
                                           datefmt.localtz).utcoffset())
        # non existent time
        self.assertEqual(datetime.timedelta(hours=1),
                         datetime.datetime(2012, 3, 25, 2, 15, 42, 123456,
                                           datefmt.localtz).utcoffset())
        # ambiguous time
        self.assertEqual(datetime.timedelta(hours=1),
                         datetime.datetime(2011, 10, 30, 2, 45, 42, 123456,
                                           datefmt.localtz).utcoffset())

    def test_localized_non_existent_time(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2012, 3, 25, 2, 15, 42, 123456)
        self.assertEqual('2012-03-25T02:15:42.123456+01:00',
                         datefmt.localtz.localize(dt).isoformat())
        try:
            datefmt.localtz.localize(dt, is_dst=None)
            raise AssertionError('ValueError not raised')
        except ValueError, e:
            self.assertEqual('Non existent time "2012-03-25 02:15:42.123456"',
                             unicode(e))

    def test_localized_ambiguous_time(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2011, 10, 30, 2, 45, 42, 123456)
        self.assertEqual('2011-10-30T02:45:42.123456+01:00',
                         datefmt.localtz.localize(dt).isoformat())
        try:
            datefmt.localtz.localize(dt, is_dst=None)
            raise AssertionError('ValueError not raised')
        except ValueError, e:
            self.assertEqual('Ambiguous time "2011-10-30 02:45:42.123456"',
                             unicode(e))

    def test_normalized_non_existent_time(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2012, 3, 25, 2, 15, 42, 123456)
        dt = datefmt.localtz.normalize(datefmt.localtz.localize(dt))
        self.assertEqual('2012-03-25T03:15:42.123456+02:00', dt.isoformat())

    def test_normalized_ambiguous_time(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2011, 10, 30, 2, 45, 42, 123456)
        dt = datefmt.localtz.normalize(datefmt.localtz.localize(dt))
        self.assertEqual('2011-10-30T02:45:42.123456+01:00', dt.isoformat())

    def test_normalized_not_localized_non_existent_time(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2012, 3, 25, 2, 15, 42, 123456, datefmt.localtz)
        self.assertEqual('2012-03-25T02:15:42.123456+01:00', dt.isoformat())
        dt = datefmt.localtz.normalize(dt)
        self.assertEqual(datefmt.localtz, dt.tzinfo)
        self.assertEqual('2012-03-25T02:15:42.123456+01:00', dt.isoformat())

    def test_normalized_not_localized_ambiguous_time(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2011, 10, 30, 2, 45, 42, 123456, datefmt.localtz)
        self.assertEqual('2011-10-30T02:45:42.123456+01:00', dt.isoformat())
        dt = datefmt.localtz.normalize(dt)
        self.assertEqual(datefmt.localtz, dt.tzinfo)
        self.assertEqual('2011-10-30T02:45:42.123456+01:00', dt.isoformat())

    def test_astimezone_utc(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2012, 1, 23, 23, 32, 42, 123456, datefmt.utc)
        self.assertEqual('2012-01-24T00:32:42.123456+01:00',
                         dt.astimezone(datefmt.localtz).isoformat())
        dt = datetime.datetime(2011, 7, 15, 23, 57, 42, 123456, datefmt.utc)
        self.assertEqual('2011-07-16T01:57:42.123456+02:00',
                         dt.astimezone(datefmt.localtz).isoformat())

    def test_astimezone_non_utc(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2012, 1, 23, 16, 32, 42, 123456,
                               datefmt.timezone('GMT -7:00'))
        self.assertEqual('2012-01-24T00:32:42.123456+01:00',
                         dt.astimezone(datefmt.localtz).isoformat())
        dt = datetime.datetime(2011, 7, 16, 10, 57, 42, 123456,
                               datefmt.timezone('GMT +11:00'))
        self.assertEqual('2011-07-16T01:57:42.123456+02:00',
                         dt.astimezone(datefmt.localtz).isoformat())

    def test_astimezone_non_existent_time(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2012, 3, 25, 0, 15, 42, 123456, datefmt.utc)
        self.assertEqual('2012-03-25T01:15:42.123456+01:00',
                         dt.astimezone(datefmt.localtz).isoformat())
        dt = datetime.datetime(2012, 3, 25, 1, 15, 42, 123456, datefmt.utc)
        self.assertEqual('2012-03-25T03:15:42.123456+02:00',
                         dt.astimezone(datefmt.localtz).isoformat())

    def test_astimezone_ambiguous_time(self):
        self._tzset('Europe/Paris')
        dt = datetime.datetime(2011, 10, 30, 0, 45, 42, 123456, datefmt.utc)
        self.assertEqual('2011-10-30T02:45:42.123456+02:00',
                         dt.astimezone(datefmt.localtz).isoformat())
        dt = datetime.datetime(2011, 10, 30, 1, 45, 42, 123456, datefmt.utc)
        self.assertEqual('2011-10-30T02:45:42.123456+01:00',
                         dt.astimezone(datefmt.localtz).isoformat())

    def test_arithmetic_localized_non_existent_time(self):
        self._tzset('Europe/Paris')
        t = datetime.datetime(2012, 3, 25, 1, 15, 42, 123456)
        t_utc = t.replace(tzinfo=datefmt.utc)
        t1 = datefmt.localtz.localize(t)
        self.assertEqual('2012-03-25T01:15:42.123456+01:00', t1.isoformat())
        t2 = t1 + datetime.timedelta(hours=1)
        self.assertEqual('2012-03-25T02:15:42.123456+01:00', t2.isoformat())
        t3 = t1 + datetime.timedelta(hours=2)
        self.assertEqual('2012-03-25T03:15:42.123456+01:00', t3.isoformat())
        self.assertEqual(datetime.timedelta(hours=1),
                         (t2 - t_utc) - (t1 - t_utc))
        self.assertEqual(datetime.timedelta(hours=2),
                         (t3 - t_utc) - (t1 - t_utc))

    def test_arithmetic_localized_ambiguous_time(self):
        self._tzset('Europe/Paris')
        t = datetime.datetime(2011, 10, 30, 1, 45, 42, 123456)
        t_utc = t.replace(tzinfo=datefmt.utc)
        t1 = datefmt.localtz.localize(t)
        self.assertEqual('2011-10-30T01:45:42.123456+02:00', t1.isoformat())
        t2 = t1 + datetime.timedelta(hours=1)
        self.assertEqual('2011-10-30T02:45:42.123456+02:00', t2.isoformat())
        t3 = t1 + datetime.timedelta(hours=2)
        self.assertEqual('2011-10-30T03:45:42.123456+02:00', t3.isoformat())
        self.assertEqual(datetime.timedelta(hours=1),
                         (t2 - t_utc) - (t1 - t_utc))
        self.assertEqual(datetime.timedelta(hours=1),
                         (t3 - t_utc) - (t2 - t_utc))

    def test_arithmetic_normalized_non_existent_time(self):
        self._tzset('Europe/Paris')
        t = datetime.datetime(2012, 3, 25, 1, 15, 42, 123456)
        t_utc = t.replace(tzinfo=datefmt.utc)
        t1 = datefmt.localtz.normalize(datefmt.localtz.localize(t))
        self.assertEqual('2012-03-25T01:15:42.123456+01:00', t1.isoformat())
        t2 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=1))
        self.assertEqual('2012-03-25T03:15:42.123456+02:00', t2.isoformat())
        t3 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=2))
        self.assertEqual('2012-03-25T04:15:42.123456+02:00', t3.isoformat())

        self.assertEqual(datetime.timedelta(hours=1),
                         (t2 - t_utc) - (t1 - t_utc))
        self.assertEqual(datetime.timedelta(hours=1),
                         (t3 - t_utc) - (t2 - t_utc))

    def test_arithmetic_normalized_ambiguous_time(self):
        self._tzset('Europe/Paris')
        t = datetime.datetime(2011, 10, 30, 1, 45, 42, 123456)
        t_utc = t.replace(tzinfo=datefmt.utc)
        t1 = datefmt.localtz.normalize(datefmt.localtz.localize(t))
        self.assertEqual('2011-10-30T01:45:42.123456+02:00', t1.isoformat())
        t2 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=1))
        self.assertEqual('2011-10-30T02:45:42.123456+02:00', t2.isoformat())
        t3 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=2))
        self.assertEqual('2011-10-30T02:45:42.123456+01:00', t3.isoformat())
        t4 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=3))
        self.assertEqual('2011-10-30T03:45:42.123456+01:00', t4.isoformat())

        self.assertEqual(datetime.timedelta(hours=1),
                         (t2 - t_utc) - (t1 - t_utc))
        self.assertEqual(datetime.timedelta(hours=1),
                         (t3 - t_utc) - (t2 - t_utc))
        self.assertEqual(datetime.timedelta(hours=1),
                         (t4 - t_utc) - (t3 - t_utc))

    def test_arithmetic_not_localized_normalized_non_existent_time(self):
        self._tzset('Europe/Paris')
        t = datetime.datetime(2012, 3, 25, 1, 15, 42, 123456, datefmt.localtz)
        t_utc = t.replace(tzinfo=datefmt.utc)
        t1 = t
        self.assertEqual('2012-03-25T01:15:42.123456+01:00', t1.isoformat())
        t2 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=1))
        self.assertEqual('2012-03-25T02:15:42.123456+01:00', t2.isoformat())
        t3 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=2))
        self.assertEqual('2012-03-25T03:15:42.123456+02:00', t3.isoformat())

        self.assertEqual(datetime.timedelta(hours=1), t2 - t1)
        self.assertEqual(datetime.timedelta(hours=1), t3 - t2)

    def test_arithmetic_not_localized_normalized_ambiguous_time(self):
        self._tzset('Europe/Paris')
        t = datetime.datetime(2011, 10, 30, 1, 45, 42, 123456, datefmt.localtz)
        t_utc = t.replace(tzinfo=datefmt.utc)
        t1 = t
        self.assertEqual('2011-10-30T01:45:42.123456+02:00', t1.isoformat())
        t2 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=1))
        self.assertEqual('2011-10-30T02:45:42.123456+01:00', t2.isoformat())
        t3 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=2))
        self.assertEqual('2011-10-30T03:45:42.123456+01:00', t3.isoformat())
        t4 = datefmt.localtz.normalize(t1 + datetime.timedelta(hours=3))
        self.assertEqual('2011-10-30T04:45:42.123456+01:00', t4.isoformat())

        self.assertEqual(datetime.timedelta(hours=1), t2 - t1)
        self.assertEqual(datetime.timedelta(hours=1), t3 - t2)
        self.assertEqual(datetime.timedelta(hours=1), t4 - t3)


class LocalTimezoneStrTestCase(unittest.TestCase):

    def test_localtz_str(self):
        class FixedLocalTz(datefmt.LocalTimezone):
            def __init__(self, hours, minutes):
                self._offset = datetime.timedelta(hours=hours,
                                                  seconds=minutes * 60)
            def utcoffset(self, dt):
                return self._offset

        self.assertEqual("UTC+02:03", str(FixedLocalTz(02, 03)))
        self.assertEqual("UTC+01:00", str(FixedLocalTz(01, 00)))
        self.assertEqual("UTC+00:23", str(FixedLocalTz(00, 23)))
        self.assertEqual("UTC+00:00", str(FixedLocalTz(00, 00)))
        self.assertEqual("UTC-00:23", str(FixedLocalTz(-00, -23)))
        self.assertEqual("UTC-01:00", str(FixedLocalTz(-01, -00)))
        self.assertEqual("UTC-02:03", str(FixedLocalTz(-02, -03)))


def suite():
    suite = unittest.TestSuite()
    if PytzTestCase:
        suite.addTest(unittest.makeSuite(PytzTestCase, 'test'))
    else:
        print "SKIP: utils/tests/datefmt.py (no pytz installed)"
    suite.addTest(unittest.makeSuite(DateFormatTestCase))
    suite.addTest(unittest.makeSuite(UTimestampTestCase))
    suite.addTest(unittest.makeSuite(ISO8601TestCase))
    if I18nDateFormatTestCase:
        suite.addTest(unittest.makeSuite(I18nDateFormatTestCase, 'test'))
    else:
        print "SKIP: utils/tests/datefmt.py (no babel installed)"
    suite.addTest(unittest.makeSuite(ParseISO8601TestCase))
    suite.addTest(unittest.makeSuite(ParseRelativeDateTestCase))
    suite.addTest(unittest.makeSuite(ParseDateValidRangeTestCase))
    suite.addTest(unittest.makeSuite(HttpDateTestCase))
    if hasattr(time, 'tzset'):
        suite.addTest(unittest.makeSuite(LocalTimezoneTestCase))
    suite.addTest(unittest.makeSuite(LocalTimezoneStrTestCase))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = html
# -*- coding: utf-8 -*-

import unittest
from genshi.input import HTML

from trac.util.html import TracHTMLSanitizer


class TracHTMLSanitizerTestCase(unittest.TestCase):
    def test_expression(self):
        html = HTML('<div style="top:expression(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

    def test_capital_expression(self):
        html = HTML('<div style="top:EXPRESSION(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

    def test_expression_with_comments(self):
        html = HTML(r'<div style="top:exp/**/ression(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div style="top:exp ression(alert())">XSS</div>',
                         unicode(html | TracHTMLSanitizer()))
        html = HTML(r'<div style="top:exp//**/**/ression(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual(
            '<div style="top:exp/ **/ression(alert())">XSS</div>',
            unicode(html | TracHTMLSanitizer()))
        html = HTML(r'<div style="top:ex/*p*/ression(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div style="top:ex ression(alert())">XSS</div>',
                         unicode(html | TracHTMLSanitizer()))

    def test_url_with_javascript(self):
        html = HTML('<div style="background-image:url(javascript:alert())">'
                    'XSS</div>', encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

    def test_capital_url_with_javascript(self):
        html = HTML('<div style="background-image:URL(javascript:alert())">'
                    'XSS</div>', encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

    def test_unicode_escapes(self):
        html = HTML(r'<div style="top:exp\72 ess\000069 on(alert())">'
                    r'XSS</div>', encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))
        # escaped backslash
        html = HTML(r'<div style="top:exp\5c ression(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual(r'<div style="top:exp\\ression(alert())">XSS</div>',
                         unicode(html | TracHTMLSanitizer()))
        html = HTML(r'<div style="top:exp\5c 72 ession(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual(r'<div style="top:exp\\72 ession(alert())">XSS</div>',
                         unicode(html | TracHTMLSanitizer()))
        # escaped control characters
        html = HTML(r'<div style="top:exp\000000res\1f sion(alert())">'
                    r'XSS</div>', encoding='utf-8')
        self.assertEqual('<div style="top:exp res sion(alert())">XSS</div>',
                         unicode(html | TracHTMLSanitizer()))

    def test_backslash_without_hex(self):
        html = HTML(r'<div style="top:e\xp\ression(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))
        html = HTML(r'<div style="top:e\\xp\\ression(alert())">XSS</div>',
                    encoding='utf-8')
        self.assertEqual(r'<div style="top:e\\xp\\ression(alert())">'
                         'XSS</div>',
                         unicode(html | TracHTMLSanitizer()))

    def test_unsafe_props(self):
        html = HTML('<div style="POSITION:RELATIVE">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))
        html = HTML('<div style="position:STATIC">safe</div>',
                    encoding='utf-8')
        self.assertEqual('<div style="position:STATIC">safe</div>',
                         unicode(html | TracHTMLSanitizer()))

        html = HTML('<div style="behavior:url(test.htc)">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

        html = HTML('<div style="-ms-behavior:url(test.htc) url(#obj)">'
                    'XSS</div>', encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

        html = HTML("""<div style="-o-link:'javascript:alert(1)';"""
                    """-o-link-source:current">XSS</div>""", encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

        html = HTML("""<div style="-moz-binding:url(xss.xbl)">XSS</div>""",
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

    def test_nagative_margin(self):
        html = HTML('<div style="margin-top:-9999px">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))
        html = HTML('<div style="margin:0 -9999px">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

    def test_css_hack(self):
        html = HTML('<div style="*position:static">XSS</div>',
                    encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

        html = HTML('<div style="_margin:-10px">XSS</div>', encoding='utf-8')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

    def test_property_name(self):
        html = HTML('<div style="display:none;border-left-color:red;'
                    'user_defined:1;-moz-user-selct:-moz-all">prop</div>',
                    encoding='utf-8')
        self.assertEqual('<div style="display:none; border-left-color:red'
                         '">prop</div>',
                         unicode(html | TracHTMLSanitizer()))

    def test_unicode_expression(self):
        # Fullwidth small letters
        html = HTML(u'<div style="top:(alert())">'
                    u'XSS</div>')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))
        # Fullwidth capital letters
        html = HTML(u'<div style="top:(alert())">'
                    u'XSS</div>')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))
        # IPA extensions
        html = HTML(u'<div style="top:expesso(alert())">'
                    u'XSS</div>')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))

    def test_unicode_url(self):
        # IPA extensions
        html = HTML(u'<div style="background-image:u(javascript:alert())">'
                    u'XSS</div>')
        self.assertEqual('<div>XSS</div>', unicode(html | TracHTMLSanitizer()))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(TracHTMLSanitizerTestCase, 'test'))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = presentation
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# Copyright (C) 2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import doctest
import unittest

from trac.util import presentation


class ToJsonTestCase(unittest.TestCase):

    def test_simple_types(self):
        self.assertEqual('42', presentation.to_json(42))
        self.assertEqual('123.456', presentation.to_json(123.456))
        self.assertEqual('true', presentation.to_json(True))
        self.assertEqual('false', presentation.to_json(False))
        self.assertEqual('null', presentation.to_json(None))
        self.assertEqual('"String"', presentation.to_json('String'))
        self.assertEqual(r'"a \" quote"', presentation.to_json('a " quote'))
        self.assertEqual('''"a ' single quote"''',
                         presentation.to_json("a ' single quote"))
        self.assertEqual(r'"\u003cb\u003e\u0026\u003c/b\u003e"',
                         presentation.to_json('<b>&</b>'))

    def test_compound_types(self):
        self.assertEqual('[1,2,[true,false]]',
                         presentation.to_json([1, 2, [True, False]]))
        self.assertEqual(r'{"one":1,"other":[null,0],'
                         r'''"three":[3,"\u0026\u003c\u003e'"],'''
                         r'"two":2}',
                         presentation.to_json({"one": 1, "two": 2,
                                               "other": [None, 0],
                                               "three": [3, "&<>'"]}))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(doctest.DocTestSuite(presentation))
    suite.addTest(unittest.makeSuite(ToJsonTestCase))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = text
# -*- coding: utf-8 -*-

import unittest
from StringIO import StringIO

from trac.util.text import empty, expandtabs, fix_eol, javascript_quote, \
                           to_js_string, normalize_whitespace, to_unicode, \
                           text_width, print_table, unicode_quote, \
                           unicode_quote_plus, unicode_unquote, \
                           unicode_urlencode, wrap, quote_query_string, \
                           unicode_to_base64, unicode_from_base64, \
                           strip_line_ws, stripws, levenshtein_distance


class ToUnicodeTestCase(unittest.TestCase):
    def test_explicit_charset(self):
        uc = to_unicode('\xc3\xa7', 'utf-8')
        assert isinstance(uc, unicode)
        self.assertEquals(u'\xe7', uc)

    def test_explicit_charset_with_replace(self):
        uc = to_unicode('\xc3', 'utf-8')
        assert isinstance(uc, unicode)
        self.assertEquals(u'\xc3', uc)

    def test_implicit_charset(self):
        uc = to_unicode('\xc3\xa7')
        assert isinstance(uc, unicode)
        self.assertEquals(u'\xe7', uc)

    def test_from_exception_using_unicode_args(self):
        u = u'\uB144'
        try:
            raise ValueError, '%s is not a number.' % u
        except ValueError, e:
            self.assertEquals(u'\uB144 is not a number.', to_unicode(e))

    def test_from_exception_using_str_args(self):
        u = u'Das Ger\xe4t oder die Ressource ist belegt'
        try:
            raise ValueError, u.encode('utf-8')
        except ValueError, e:
            self.assertEquals(u, to_unicode(e))


class ExpandtabsTestCase(unittest.TestCase):
    def test_empty(self):
        x = expandtabs('', ignoring='\0')
        self.assertEquals('', x)
    def test_ingoring(self):
        x = expandtabs('\0\t', ignoring='\0')
        self.assertEquals('\0        ', x)
    def test_tabstops(self):
        self.assertEquals('        ', expandtabs('       \t'))
        self.assertEquals('                ', expandtabs('\t\t'))


class JavascriptQuoteTestCase(unittest.TestCase):
    def test_quoting(self):
        self.assertEqual(r'Quote \" in text',
                         javascript_quote('Quote " in text'))
        self.assertEqual(r'\\\"\b\f\n\r\t\'',
                         javascript_quote('\\"\b\f\n\r\t\''))
        self.assertEqual(r'\u0002\u001e',
                         javascript_quote('\x02\x1e'))
        self.assertEqual(r'\u0026\u003c\u003e',
                         javascript_quote('&<>'))


class ToJsStringTestCase(unittest.TestCase):
    def test_(self):
        self.assertEqual(r'"Quote \" in text"',
                         to_js_string('Quote " in text'))
        self.assertEqual(r'''"\\\"\b\f\n\r\t'"''',
                         to_js_string('\\"\b\f\n\r\t\''))
        self.assertEqual(r'"\u0002\u001e"',
                         to_js_string('\x02\x1e'))
        self.assertEqual(r'"\u0026\u003c\u003e"',
                         to_js_string('&<>'))
        self.assertEqual('""',
                         to_js_string(''))
        self.assertEqual('""',
                         to_js_string(None))


class UnicodeQuoteTestCase(unittest.TestCase):
    def test_unicode_quote(self):
        self.assertEqual(u'the%20%C3%9C%20thing',
                         unicode_quote(u'the  thing'))
        self.assertEqual(u'%2520%C3%9C%20%2520',
                         unicode_quote(u'%20 %20'))

    def test_unicode_quote_plus(self):
        self.assertEqual(u'the+%C3%9C+thing',
                         unicode_quote_plus(u'the  thing'))
        self.assertEqual(u'%2520%C3%9C+%2520',
                         unicode_quote_plus(u'%20 %20'))

    def test_unicode_unquote(self):
        u = u'the  thing'
        up = u'%20 %20'
        self.assertEqual(u, unicode_unquote(unicode_quote(u)))
        self.assertEqual(up, unicode_unquote(unicode_quote(up)))

    def test_unicode_urlencode(self):
        self.assertEqual('thing=%C3%9C&%C3%9C=thing&%C3%9Cthing',
                         unicode_urlencode({u'': 'thing',
                                            'thing': u'',
                                            u'thing': empty}))


class QuoteQueryStringTestCase(unittest.TestCase):
    def test_quote(self):
        text = u'type=the  thing&component=comp\x7fonent'
        self.assertEqual('type=the+%C3%9C+thing&component=comp%7Fonent',
                         quote_query_string(text))


class WhitespaceTestCase(unittest.TestCase):
    def test_default(self):
        self.assertEqual(u'This is text ',
            normalize_whitespace(u'Th\u200bis\u00a0is te\u200bxt\u00a0'))
        self.assertEqual(u'Some other text',
            normalize_whitespace(u'Some\tother\ntext\r', to_space='\t\n',
                                 remove='\r'))


class TextWidthTestCase(unittest.TestCase):
    def test_single(self):
        def tw1(text):
            return text_width(text, ambiwidth=1)
        self.assertEqual(8, tw1(u'Alphabet'))
        self.assertEqual(16, tw1('east asian width'))
        self.assertEqual(16, tw1(u''))
        self.assertEqual(21, tw1(u''))

    def test_double(self):
        def tw2(text):
            return text_width(text, ambiwidth=2)
        self.assertEqual(8, tw2(u'Alphabet'))
        self.assertEqual(16, tw2('east asian width'))
        self.assertEqual(16, tw2(u''))
        self.assertEqual(22, tw2(u''))


class PrintTableTestCase(unittest.TestCase):
    def test_single_bytes(self):
        data = (
            ('Trac 0.12', '2010-06-13', 'Babel'),
            ('Trac 0.11', '2008-06-22', 'Genshi'),
            ('Trac 0.10', '2006-09-28', 'Zengia'),
            ('Trac 0.9',  '2005-10-31', 'Vodun'),
            ('Trac 0.8',  '2004-11-15', 'Qualia'),
            ('Trac 0.7',  '2004-05-18', 'Fulci'),
            ('Trac 0.6',  '2004-03-23', 'Solanum'),
            ('Trac 0.5',  '2004-02-23', 'Incognito'),
        )
        headers = ('Version', 'Date', 'Name')
        expected = """\

Version     Date         Name
----------------------------------
Trac 0.12 | 2010-06-13 | Babel
Trac 0.11 | 2008-06-22 | Genshi
Trac 0.10 | 2006-09-28 | Zengia
Trac 0.9  | 2005-10-31 | Vodun
Trac 0.8  | 2004-11-15 | Qualia
Trac 0.7  | 2004-05-18 | Fulci
Trac 0.6  | 2004-03-23 | Solanum
Trac 0.5  | 2004-02-23 | Incognito

"""
        self._validate_print_table(expected, data, headers=headers, sep=' | ',
                                   ambiwidth=1)

    def test_various_types(self):
        data = (
            ('NoneType', 'None',  None),
            ('bool',     'True',  True),
            ('bool',     'False', False),
            ('int',      '0',     0),
            ('float',    '0.0',   0.0),
        )
        expected = u"""\

NoneType | None  |
bool     | True  | True
bool     | False | False
int      | 0     | 0
float    | 0.0   | 0.0

"""
        self._validate_print_table(expected, data, sep=' | ', ambiwidth=1)

    def test_ambiwidth_1(self):
        data = (
            ('foo@localhost', 'foo@localhost'),
            (u'bar@.com', 'bar@example.com'),
        )
        headers = ('Obfuscated', 'Email')
        expected = u"""\

Obfuscated      Email
-------------------------------
foo@localhost | foo@localhost
bar@.com     | bar@example.com

"""
        self._validate_print_table(expected, data, headers=headers, sep=' | ',
                                   ambiwidth=1)

    def test_ambiwidth_2(self):
        data = (
            ('foo@localhost', 'foo@localhost'),
            (u'bar@.com', 'bar@example.com'),
        )
        headers = ('Obfuscated', 'Email')
        expected = u"""\

Obfuscated      Email
-------------------------------
foo@localhost | foo@localhost
bar@.com    | bar@example.com

"""
        self._validate_print_table(expected, data, headers=headers, sep=' | ',
                                   ambiwidth=2)

    def _validate_print_table(self, expected, data, **kwargs):
        out = StringIO()
        kwargs['out'] = out
        print_table(data, **kwargs)
        self.assertEqual(expected.encode('utf-8'),
                         strip_line_ws(out.getvalue(), leading=False))


class WrapTestCase(unittest.TestCase):
    def test_wrap_ambiwidth_single(self):
        text = u'Lorem ipsum dolor sit amet, consectetur adipisicing ' + \
               u'elit, sed do eiusmod tempor incididunt ut labore et ' + \
               u'dolore magna aliqua. Ut enim ad minim veniam, quis ' + \
               u'nostrud exercitation ullamco laboris nisi ut aliquip ex ' + \
               u'ea commodo consequat. Duis aute irure dolor in ' + \
               u'reprehenderit in voluptate velit esse cillum dolore eu ' + \
               u'fugiat nulla pariatur. Excepteur sint occaecat ' + \
               u'cupidatat non proident, sunt in culpa qui officia ' + \
               u'deserunt mollit anim id est laborum.'
        wrapped = u"""\
> Lorem ipsum dolor sit amet, consectetur adipisicing elit,
| sed do eiusmod tempor incididunt ut labore et dolore
| magna aliqua. Ut enim ad minim veniam, quis nostrud
| exercitation ullamco laboris nisi ut aliquip ex ea
| commodo consequat. Duis aute irure dolor in reprehenderit
| in voluptate velit esse cillum dolore eu fugiat nulla
| pariatur. Excepteur sint occaecat cupidatat non proident,
| sunt in culpa qui officia deserunt mollit anim id est
| laborum."""
        self.assertEqual(wrapped, wrap(text, 59, '> ', '| ', '\n'))

    def test_wrap_ambiwidth_double(self):
        text = u'Trac  BSD ' + \
               u'[1:]' + \
               u'[3:CPYING]' + \
               u'[2:]' \
               u''
        wrapped = u"""\
> Trac  BSD [1:]
| 
| [3:CPYING][2:]
| """
        self.assertEqual(wrapped, wrap(text, 59, '> ', '| ', '\n',
                                       ambiwidth=2))


class FixEolTestCase(unittest.TestCase):
    def test_mixed_eol(self):
        text = u'\nLine 2\rLine 3\r\nLine 4\n\r'
        self.assertEqual(u'\nLine 2\nLine 3\nLine 4\n\n',
                         fix_eol(text, '\n'))
        self.assertEqual(u'\rLine 2\rLine 3\rLine 4\r\r',
                         fix_eol(text, '\r'))
        self.assertEqual(u'\r\nLine 2\r\nLine 3\r\nLine 4\r\n\r\n',
                         fix_eol(text, '\r\n'))


class UnicodeBase64TestCase(unittest.TestCase):
    def test_to_and_from_base64_unicode(self):
        text = u'Trac  '
        text_base64 = unicode_to_base64(text)
        self.assertEqual('VHJhYyDjga8gw5jDhsOF', text_base64)
        self.assertEqual(text, unicode_from_base64(text_base64))

    def test_to_and_from_base64_whitespace(self):
        # test that removing whitespace does not affect conversion
        text = 'a space: '
        text_base64 = unicode_to_base64(text)
        self.assertEqual('YSBzcGFjZTog', text_base64)
        self.assertEqual(text, unicode_from_base64(text_base64))
        text = 'two newlines: \n\n'
        text_base64 = unicode_to_base64(text)
        self.assertEqual('dHdvIG5ld2xpbmVzOiAKCg==', text_base64)
        self.assertEqual(text, unicode_from_base64(text_base64))
        text = 'a test string ' * 10000
        text_base64_strip = unicode_to_base64(text)
        text_base64_no_strip = unicode_to_base64(text, strip_newlines=False)
        self.assertNotEqual(text_base64_strip, text_base64_no_strip)
        self.assertEqual(text, unicode_from_base64(text_base64_strip))
        self.assertEqual(text, unicode_from_base64(text_base64_no_strip))


class StripwsTestCase(unittest.TestCase):
    def test_stripws(self):
        self.assertEquals(u'stripws',
                          stripws(u' \u200b\t\u3000stripws \u200b\t\u2008'))
        self.assertEquals(u'stripws \u3000\t',
                          stripws(u'\u200b\t\u2008 stripws \u3000\t',
                                  trailing=False))
        self.assertEquals(u' \t\u3000stripws',
                          stripws(u' \t\u3000stripws \u200b\t\u2008',
                                  leading=False))
        self.assertEquals(u' \t\u3000stripws \u200b\t\u2008',
                          stripws(u' \t\u3000stripws \u200b\t\u2008',
                                  leading=False, trailing=False))



class LevenshteinDistanceTestCase(unittest.TestCase):
    def test_distance(self):
        self.assertEqual(5, levenshtein_distance('kitten', 'sitting'))
        self.assertEqual(1, levenshtein_distance('wii', 'wiki'))
        self.assertEqual(2, levenshtein_distance('comfig', 'config'))
        self.assertEqual(5, levenshtein_distance('update', 'upgrade'))
        self.assertEqual(0, levenshtein_distance('milestone', 'milestone'))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(ToUnicodeTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ExpandtabsTestCase, 'test'))
    suite.addTest(unittest.makeSuite(UnicodeQuoteTestCase, 'test'))
    suite.addTest(unittest.makeSuite(JavascriptQuoteTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ToJsStringTestCase, 'test'))
    suite.addTest(unittest.makeSuite(QuoteQueryStringTestCase, 'test'))
    suite.addTest(unittest.makeSuite(WhitespaceTestCase, 'test'))
    suite.addTest(unittest.makeSuite(TextWidthTestCase, 'test'))
    suite.addTest(unittest.makeSuite(PrintTableTestCase, 'test'))
    suite.addTest(unittest.makeSuite(WrapTestCase, 'test'))
    suite.addTest(unittest.makeSuite(FixEolTestCase, 'test'))
    suite.addTest(unittest.makeSuite(UnicodeBase64TestCase, 'test'))
    suite.addTest(unittest.makeSuite(StripwsTestCase, 'test'))
    suite.addTest(unittest.makeSuite(LevenshteinDistanceTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = text
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2004 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2006 Matthew Good <trac@matt-good.net>
# Copyright (C) 2005-2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Matthew Good <trac@matt-good.net>
#         Christian Boos <cboos@edgewall.org>

import __builtin__
import locale
import os
import re
import sys
import textwrap
from urllib import quote, quote_plus, unquote
from unicodedata import east_asian_width

from trac.util.translation import _


CRLF = '\r\n'

class Empty(unicode):
    """A special tag object evaluating to the empty string"""
    __slots__ = []

empty = Empty()

del Empty # shouldn't be used outside of Trac core


# -- Unicode

def to_unicode(text, charset=None):
    """Convert input to an `unicode` object.

    For a `str` object, we'll first try to decode the bytes using the given
    `charset` encoding (or UTF-8 if none is specified), then we fall back to
    the latin1 encoding which might be correct or not, but at least preserves
    the original byte sequence by mapping each byte to the corresponding
    unicode code point in the range U+0000 to U+00FF.

    For anything else, a simple `unicode()` conversion is attempted,
    with special care taken with `Exception` objects.
    """
    if isinstance(text, str):
        try:
            return unicode(text, charset or 'utf-8')
        except UnicodeDecodeError:
            return unicode(text, 'latin1')
    elif isinstance(text, Exception):
        # two possibilities for storing unicode strings in exception data:
        try:
            # custom __str__ method on the exception (e.g. PermissionError)
            return unicode(text)
        except UnicodeError:
            # unicode arguments given to the exception (e.g. parse_date)
            return ' '.join([to_unicode(arg) for arg in text.args])
    return unicode(text)


def exception_to_unicode(e, traceback=False):
    """Convert an `Exception` to an `unicode` object.

    In addition to `to_unicode`, this representation of the exception
    also contains the class name and optionally the traceback.
    """
    message = '%s: %s' % (e.__class__.__name__, to_unicode(e))
    if traceback:
        from trac.util import get_last_traceback
        traceback_only = get_last_traceback().split('\n')[:-2]
        message = '\n%s\n%s' % (to_unicode('\n'.join(traceback_only)), message)
    return message


def path_to_unicode(path):
    """Convert a filesystem path to unicode, using the filesystem encoding."""
    if isinstance(path, str):
        try:
            return unicode(path, sys.getfilesystemencoding())
        except UnicodeDecodeError:
            return unicode(path, 'latin1')
    return unicode(path)


_ws_leading_re = re.compile(ur'\A[\s\u200b]+', re.UNICODE)
_ws_trailing_re = re.compile(ur'[\s\u200b]+\Z', re.UNICODE)

def stripws(text, leading=True, trailing=True):
    """Strips unicode white-spaces and ZWSPs from ``text``.

    :param leading: strips leading spaces from ``text`` unless ``leading`` is
                    `False`.
    :param trailing: strips trailing spaces from ``text`` unless ``trailing``
                     is `False`.
    """
    if leading:
        text = _ws_leading_re.sub('', text)
    if trailing:
        text = _ws_trailing_re.sub('', text)
    return text


def strip_line_ws(text, leading=True, trailing=True):
    """Strips unicode white-spaces and ZWSPs from each line of ``text``.

    :param leading: strips leading spaces from ``text`` unless ``leading`` is
                    `False`.
    :param trailing: strips trailing spaces from ``text`` unless ``trailing``
                     is `False`.
    """
    lines = re.compile(r'(\n|\r\n|\r)').split(text)
    if leading:
        lines[::2] = (_ws_leading_re.sub('', line) for line in lines[::2])
    if trailing:
        lines[::2] = (_ws_trailing_re.sub('', line) for line in lines[::2])
    return ''.join(lines)


_js_quote = {'\\': '\\\\', '"': '\\"', '\b': '\\b', '\f': '\\f',
             '\n': '\\n', '\r': '\\r', '\t': '\\t', "'": "\\'"}
for i in range(0x20) + [ord(c) for c in '&<>']:
    _js_quote.setdefault(chr(i), '\\u%04x' % i)
_js_quote_re = re.compile(r'[\x00-\x1f\\"\b\f\n\r\t\'&<>]')
_js_string_re = re.compile(r'[\x00-\x1f\\"\b\f\n\r\t&<>]')


def javascript_quote(text):
    """Quote strings for inclusion in single or double quote delimited
    Javascript strings
    """
    if not text:
        return ''
    def replace(match):
        return _js_quote[match.group(0)]
    return _js_quote_re.sub(replace, text)


def to_js_string(text):
    """Embed the given string in a double quote delimited Javascript string
    (conform to the JSON spec)
    """
    if not text:
        return '""'
    def replace(match):
        return _js_quote[match.group(0)]
    return '"%s"' % _js_string_re.sub(replace, text)


def unicode_quote(value, safe='/'):
    """A unicode aware version of `urllib.quote`

    :param value: anything that converts to a `str`. If `unicode`
                  input is given, it will be UTF-8 encoded.
    :param safe: as in `quote`, the characters that would otherwise be
                 quoted but shouldn't here (defaults to '/')
    """
    return quote(value.encode('utf-8') if isinstance(value, unicode)
                 else str(value), safe)


def unicode_quote_plus(value, safe=''):
    """A unicode aware version of `urllib.quote_plus`.

    :param value: anything that converts to a `str`. If `unicode`
                  input is given, it will be UTF-8 encoded.
    :param safe: as in `quote_plus`, the characters that would
                 otherwise be quoted but shouldn't here (defaults to
                 '/')
    """
    return quote_plus(value.encode('utf-8') if isinstance(value, unicode)
                      else str(value), safe)


def unicode_unquote(value):
    """A unicode aware version of `urllib.unquote`.

    :param str: UTF-8 encoded `str` value (for example, as obtained by
                `unicode_quote`).
    :rtype: `unicode`
    """
    return unquote(value).decode('utf-8')


def unicode_urlencode(params, safe=''):
    """A unicode aware version of `urllib.urlencode`.

    Values set to `empty` are converted to the key alone, without the
    equal sign.
    """
    if isinstance(params, dict):
        params = params.iteritems()
    l = []
    for k, v in params:
        if v is empty:
            l.append(unicode_quote_plus(k, safe))
        else:
            l.append(unicode_quote_plus(k, safe) + '=' +
                     unicode_quote_plus(v, safe))
    return '&'.join(l)


_qs_quote_safe = ''.join(chr(c) for c in xrange(0x21, 0x7f))

def quote_query_string(text):
    """Quote strings for query string
    """
    return unicode_quote_plus(text, _qs_quote_safe)


def to_utf8(text, charset='latin1'):
    """Convert a string to UTF-8, assuming the encoding is either UTF-8, ISO
    Latin-1, or as specified by the optional `charset` parameter.

    .. deprecated :: 0.10
       You should use `unicode` strings only.
    """
    try:
        # Do nothing if it's already utf-8
        u = unicode(text, 'utf-8')
        return text
    except UnicodeError:
        try:
            # Use the user supplied charset if possible
            u = unicode(text, charset)
        except UnicodeError:
            # This should always work
            u = unicode(text, 'latin1')
        return u.encode('utf-8')


class unicode_passwd(unicode):
    """Conceal the actual content of the string when `repr` is called."""
    def __repr__(self):
        return '*******'


def stream_encoding(stream):
    """Return the appropriate encoding for the given stream."""
    encoding = getattr(stream, 'encoding', None)
    # Windows returns 'cp0' to indicate no encoding
    return encoding if encoding not in (None, 'cp0') else 'utf-8'


def console_print(out, *args, **kwargs):
    """Output the given arguments to the console, encoding the output
    as appropriate.

    :param kwargs: ``newline`` controls whether a newline will be appended
                   (defaults to `True`)
    """
    cons_charset = stream_encoding(out)
    out.write(' '.join([to_unicode(a).encode(cons_charset, 'replace')
                        for a in args]))
    if kwargs.get('newline', True):
        out.write('\n')


def printout(*args, **kwargs):
    """Do a `console_print` on `sys.stdout`."""
    console_print(sys.stdout, *args, **kwargs)


def printerr(*args, **kwargs):
    """Do a `console_print` on `sys.stderr`."""
    console_print(sys.stderr, *args, **kwargs)


def raw_input(prompt):
    """Input one line from the console and converts it to unicode as
    appropriate.
    """
    printout(prompt, newline=False)
    return to_unicode(__builtin__.raw_input(), sys.stdin.encoding)


_preferredencoding = locale.getpreferredencoding()

def getpreferredencoding():
    """Return the encoding, which is retrieved on ahead, according to user
    preference.

    We should use this instead of `locale.getpreferredencoding()` which
    is not thread-safe."""
    return _preferredencoding


# -- Plain text formatting

def text_width(text, ambiwidth=1):
    """Determine the column width of `text` in Unicode characters.

    The characters in the East Asian Fullwidth (F) or East Asian Wide (W)
    have a column width of 2. The other characters in the East Asian
    Halfwidth (H) or East Asian Narrow (Na) have a column width of 1.

    That `ambiwidth` parameter is used for the column width of the East
    Asian Ambiguous (A). If `1`, the same width as characters in US-ASCII.
    This is expected by most users. If `2`, twice the width of US-ASCII
    characters. This is expected by CJK users.

    cf. http://www.unicode.org/reports/tr11/.
    """
    twice = 'FWA' if ambiwidth == 2 else 'FW'
    return sum([2 if east_asian_width(chr) in twice else 1
                for chr in to_unicode(text)])

_default_ambiwidth = 1  # Default width of East Asian Ambiguous (A)
if os.name == 'nt':
    try:
        # `ctypes` is available since Python 2.5
        import ctypes
        codepage = ctypes.windll.kernel32.GetConsoleOutputCP()
    except ImportError:
        # Try to retrieve the codepage from stderr and stdout
        codepage = (sys.stderr.encoding or sys.stdout.encoding or '')[2:]
        codepage = codepage.isdigit() and int(codepage) or 0

    if codepage in (932,  # Japanese (Shift-JIS)
                    936,  # Chinese Simplified (GB2312)
                    949,  # Korean (Unified Hangul Code)
                    950): # Chinese Traditional (Big5)
        _default_ambiwidth = 2
    del codepage
else:
    if re.match(r'zh|ja|kr', os.environ.get('LANG') or '', re.IGNORECASE):
        _default_ambiwidth = 2


def print_table(data, headers=None, sep='  ', out=None, ambiwidth=None):
    """Print data according to a tabular layout.

    :param data: a sequence of rows; assume all rows are of equal length.
    :param headers: an optional row containing column headers; must be of
                    the same length as each row in `data`.
    :param sep: column separator
    :param out: output file descriptor (`None` means use `sys.stdout`)
    :param ambiwidth: column width of the East Asian Ambiguous (A). If None,
                      detect ambiwidth with the locale settings. If others,
                      pass to the `ambiwidth` parameter of `text_width`.
    """
    if out is None:
        out = sys.stdout
    charset = getattr(out, 'encoding', None) or 'utf-8'
    if ambiwidth is None:
        ambiwidth = _default_ambiwidth
    data = list(data)
    if headers:
        data.insert(0, headers)
    elif not data:
        return

    # Convert to an unicode object with `to_unicode`. If None, convert to a
    # empty string.
    def to_text(val):
        if val is None:
            return u''
        return to_unicode(val)

    def tw(text):
        return text_width(text, ambiwidth=ambiwidth)

    # Convert each cell to an unicode object
    data = [[to_text(cell) for cell in row] for row in data]

    num_cols = len(data[0])
    col_width = [max(tw(row[idx]) for row in data)
                 for idx in xrange(num_cols)]

    out.write('\n')
    for ridx, row in enumerate(data):
        for cidx, cell in enumerate(row):
            if headers and ridx == 0:
                sp = '%*s' % (tw(sep), ' ') # No separator in header
            else:
                sp = sep
            if cidx + 1 == num_cols:
                sp = '' # No separator after last column

            line = u'%-*s%s' % (col_width[cidx] - tw(cell) + len(cell),
                                cell, sp)
            line = line.encode(charset, 'replace')
            out.write(line)

        out.write('\n')
        if ridx == 0 and headers:
            out.write('-' * (tw(sep) * cidx + sum(col_width)))
            out.write('\n')
    out.write('\n')


def shorten_line(text, maxlen=75):
    """Truncates content to at most `maxlen` characters.

    This tries to be (a bit) clever and attempts to find a proper word
    boundary for doing so.
    """
    if len(text or '') < maxlen:
        return text
    cut = max(text.rfind(' ', 0, maxlen), text.rfind('\n', 0, maxlen))
    if cut < 0:
        cut = maxlen
    return text[:cut] + ' ...'


class UnicodeTextWrapper(textwrap.TextWrapper):
    breakable_char_ranges = [
        (0x1100, 0x11FF),   # Hangul Jamo
        (0x2E80, 0x2EFF),   # CJK Radicals Supplement
        (0x3000, 0x303F),   # CJK Symbols and Punctuation
        (0x3040, 0x309F),   # Hiragana
        (0x30A0, 0x30FF),   # Katakana
        (0x3130, 0x318F),   # Hangul Compatibility Jamo
        (0x3190, 0x319F),   # Kanbun
        (0x31C0, 0x31EF),   # CJK Strokes
        (0x3200, 0x32FF),   # Enclosed CJK Letters and Months
        (0x3300, 0x33FF),   # CJK Compatibility
        (0x3400, 0x4DBF),   # CJK Unified Ideographs Extension A
        (0x4E00, 0x9FFF),   # CJK Unified Ideographs
        (0xA960, 0xA97F),   # Hangul Jamo Extended-A
        (0xAC00, 0xD7AF),   # Hangul Syllables
        (0xD7B0, 0xD7FF),   # Hangul Jamo Extended-B
        (0xF900, 0xFAFF),   # CJK Compatibility Ideographs
        (0xFE30, 0xFE4F),   # CJK Compatibility Forms
        (0xFF00, 0xFFEF),   # Halfwidth and Fullwidth Forms
        (0x20000, 0x2FFFF, u'[\uD840-\uD87F][\uDC00-\uDFFF]'), # Plane 2
        (0x30000, 0x3FFFF, u'[\uD880-\uD8BF][\uDC00-\uDFFF]'), # Plane 3
    ]

    split_re = None
    breakable_re = None

    @classmethod
    def _init_patterns(cls):
        char_ranges = []
        surrogate_pairs = []
        for val in cls.breakable_char_ranges:
            try:
                high = unichr(val[0])
                low = unichr(val[1])
                char_ranges.append(u'%s-%s' % (high, low))
            except ValueError:
                # Narrow build, `re` cannot use characters >= 0x10000
                surrogate_pairs.append(val[2])
        char_ranges = u''.join(char_ranges)
        if surrogate_pairs:
            pattern = u'(?:[%s]|%s)+' % (char_ranges,
                                         u'|'.join(surrogate_pairs))
        else:
            pattern = u'[%s]+' % char_ranges

        cls.split_re = re.compile(
            ur'(\s+|' +                                 # any whitespace
            pattern + u'|' +                            # breakable text
            ur'[^\s\w]*\w+[^0-9\W]-(?=\w+[^0-9\W])|' +  # hyphenated words
            ur'(?<=[\w\!\"\'\&\.\,\?])-{2,}(?=\w))',    # em-dash
            re.UNICODE)
        cls.breakable_re = re.compile(ur'\A' + pattern, re.UNICODE)

    def __init__(self, cols, replace_whitespace=0, break_long_words=0,
                 initial_indent='', subsequent_indent='', ambiwidth=1):
        textwrap.TextWrapper.__init__(
                self, cols, replace_whitespace=0, break_long_words=0,
                initial_indent=initial_indent,
                subsequent_indent=subsequent_indent)
        self.ambiwidth = ambiwidth
        if self.split_re is None:
            self._init_patterns()

    def _split(self, text):
        chunks = self.split_re.split(to_unicode(text))
        chunks = filter(None, chunks)
        return chunks

    def _text_width(self, text):
        return text_width(text, ambiwidth=self.ambiwidth)

    def _wrap_chunks(self, chunks):
        lines = []
        chunks.reverse()
        text_width = self._text_width

        while chunks:
            cur_line = []
            cur_width = 0

            if lines:
                indent = self.subsequent_indent
            else:
                indent = self.initial_indent
            width = self.width - text_width(indent)

            if chunks[-1].strip() == '' and lines:
                del chunks[-1]

            while chunks:
                chunk = chunks[-1]
                w = text_width(chunk)
                if cur_width + w <= width:
                    cur_line.append(chunks.pop())
                    cur_width += w
                elif self.breakable_re.match(chunk):
                    left_space = width - cur_width
                    for i in xrange(len(chunk)):
                        w = text_width(chunk[i])
                        if left_space < w:
                            break
                        left_space -= w
                    if i > 0:
                        cur_line.append(chunk[:i])
                        chunk = chunk[i:]
                        chunks[-1] = chunk
                    w = text_width(chunk)
                    break
                else:
                    break

            if chunks and w > width:
                self._handle_long_word(chunks, cur_line, cur_width, width)

            if cur_line and cur_line[-1].strip() == '':
                del cur_line[-1]

            if cur_line:
                lines.append(indent + ''.join(cur_line))

        return lines


def wrap(t, cols=75, initial_indent='', subsequent_indent='',
         linesep=os.linesep, ambiwidth=1):
    """Wraps the single paragraph in `t`, which contains unicode characters.
    The every line is at most `cols` characters long.

    That `ambiwidth` parameter is used for the column width of the East
    Asian Ambiguous (A). If `1`, the same width as characters in US-ASCII.
    This is expected by most users. If `2`, twice the width of US-ASCII
    characters. This is expected by CJK users.
    """
    t = t.strip().replace('\r\n', '\n').replace('\r', '\n')
    wrapper = UnicodeTextWrapper(cols, replace_whitespace=0,
                                 break_long_words=0,
                                 initial_indent=initial_indent,
                                 subsequent_indent=subsequent_indent,
                                 ambiwidth=ambiwidth)
    wrappedLines = []
    for line in t.split('\n'):
        wrappedLines += wrapper.wrap(line.rstrip()) or ['']
    return linesep.join(wrappedLines)


def obfuscate_email_address(address):
    """Replace anything looking like an e-mail address (``'@something'``)
    with a trailing ellipsis (``'@'``)
    """
    if address:
        at = address.find('@')
        if at != -1:
            return address[:at] + u'@\u2026' + \
                   ('>' if address[-1] == '>' else '')
    return address


def breakable_path(path):
    """Make a path breakable after path separators, and conversely, avoid
    breaking at spaces.
    """
    if not path:
        return path
    prefix = ''
    if path.startswith('/'):    # Avoid breaking after a leading /
        prefix = '/'
        path = path[1:]
    return prefix + path.replace('/', u'/\u200b').replace('\\', u'\\\u200b') \
                        .replace(' ', u'\u00a0')


def normalize_whitespace(text, to_space=u'\u00a0', remove=u'\u200b'):
    """Normalize whitespace in a string, by replacing special spaces by normal
    spaces and removing zero-width spaces."""
    if not text:
        return text
    for each in to_space:
        text = text.replace(each, ' ')
    for each in remove:
        text = text.replace(each, '')
    return text

def unquote_label(txt):
    """Remove (one level of) enclosing single or double quotes.

    .. versionadded :: 1.0
    """
    return txt[1:-1] if txt and txt[0] in "'\"" and txt[0] == txt[-1] else txt

# -- Conversion

def pretty_size(size, format='%.1f'):
    """Pretty print content size information with appropriate unit.

    :param size: number of bytes
    :param format: can be used to adjust the precision shown
    """
    if size is None:
        return ''

    jump = 1024
    if size < jump:
        return _('%(size)s bytes', size=size)

    units = ['KB', 'MB', 'GB', 'TB']
    i = 0
    while size >= jump and i < len(units):
        i += 1
        size /= 1024.

    return (format + ' %s') % (size, units[i - 1])


def expandtabs(s, tabstop=8, ignoring=None):
    """Expand tab characters `'\\\\t'` into spaces.

    :param tabstop: number of space characters per tab
                    (defaults to the canonical 8)

    :param ignoring: if not `None`, the expansion will be "smart" and
                     go from one tabstop to the next. In addition,
                     this parameter lists characters which can be
                     ignored when computing the indent.
    """
    if '\t' not in s:
        return s
    if ignoring is None:
        return s.expandtabs(tabstop)

    outlines = []
    for line in s.split('\n'):
        if '\t' not in line:
            outlines.append(line)
            continue
        p = 0
        s = []
        for c in line:
            if c == '\t':
                n = tabstop - p % tabstop
                s.append(' ' * n)
                p += n
            elif not ignoring or c not in ignoring:
                p += 1
                s.append(c)
            else:
                s.append(c)
        outlines.append(''.join(s))
    return '\n'.join(outlines)


def fix_eol(text, eol):
    """Fix end-of-lines in a text."""
    lines = text.splitlines()
    lines.append('')
    return eol.join(lines)

def unicode_to_base64(text, strip_newlines=True):
    """Safe conversion of ``text`` to base64 representation using
    utf-8 bytes.

    Strips newlines from output unless ``strip_newlines`` is `False`.
    """
    text = to_unicode(text)
    if strip_newlines:
        return text.encode('utf-8').encode('base64').replace('\n', '')
    return text.encode('utf-8').encode('base64')

def unicode_from_base64(text):
    """Safe conversion of ``text`` to unicode based on utf-8 bytes."""
    return text.decode('base64').decode('utf-8')


def levenshtein_distance(lhs, rhs):
    """Return the Levenshtein distance between two strings."""
    if len(lhs) > len(rhs):
        rhs, lhs = lhs, rhs
    if not lhs:
        return len(rhs)

    prev = range(len(rhs) + 1)
    for lidx, lch in enumerate(lhs):
        curr = [lidx + 1]
        for ridx, rch in enumerate(rhs):
            cost = (lch != rch) * 2
            curr.append(min(prev[ridx + 1] + 1, # deletion
                            curr[ridx] + 1,     # insertion
                            prev[ridx] + cost)) # substitution
        prev = curr
    return prev[-1]

########NEW FILE########
__FILENAME__ = translation
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

"""Utilities for text translation with gettext."""

from __future__ import with_statement

import pkg_resources
import re

from genshi.builder import tag

from trac.util.concurrency import ThreadLocal, threading
from trac.util.compat import cleandoc


__all__ = ['gettext', 'ngettext', 'gettext_noop', 'ngettext_noop',
           'tgettext', 'tgettext_noop', 'tngettext', 'tngettext_noop']

def safefmt(string, kwargs):
    if kwargs:
        try:
            return string % kwargs
        except KeyError:
            pass
    return string


def gettext_noop(string, **kwargs):
    return safefmt(string, kwargs)

def dgettext_noop(domain, string, **kwargs):
    return gettext_noop(string, **kwargs)

N_ = _noop = lambda string: string
cleandoc_ = cleandoc

def ngettext_noop(singular, plural, num, **kwargs):
    string = singular if num == 1 else plural
    kwargs.setdefault('num', num)
    return safefmt(string, kwargs)

def dngettext_noop(domain, singular, plural, num, **kwargs):
    return ngettext_noop(singular, plural, num, **kwargs)

_param_re = re.compile(r"%\((\w+)\)(?:s|[\d]*d|\d*.?\d*[fg])")
def _tag_kwargs(trans, kwargs):
    trans_elts = _param_re.split(trans)
    for i in xrange(1, len(trans_elts), 2):
        trans_elts[i] = kwargs.get(trans_elts[i], '???')
    return tag(*trans_elts)

def tgettext_noop(string, **kwargs):
    return _tag_kwargs(string, kwargs) if kwargs else string

def dtgettext_noop(domain, string, **kwargs):
    return tgettext_noop(string, **kwargs)

def tngettext_noop(singular, plural, num, **kwargs):
    string = singular if num == 1 else plural
    kwargs.setdefault('num', num)
    return _tag_kwargs(string, kwargs)

def dtngettext_noop(domain, singular, plural, num, **kwargs):
    return tngettext_noop(singular, plural, num, **kwargs)

def add_domain(domain, env_path, locale_dir):
    pass

def domain_functions(domain, *symbols):
    if symbols and not isinstance(symbols[0], basestring):
        symbols = symbols[0]
    _functions = {
      'gettext': gettext_noop,
      '_': gettext_noop,
      'N_': _noop,
      'ngettext': ngettext_noop,
      'tgettext': tgettext_noop,
      'tag_': tgettext_noop,
      'tngettext': tngettext_noop,
      'tagn_': tngettext_noop,
      'add_domain': lambda env_path, locale_dir: None,
      }
    return [_functions[s] for s in symbols]


from gettext import NullTranslations

class NullTranslationsBabel(NullTranslations):
    """NullTranslations doesn't have the domain related methods."""

    def dugettext(self, domain, string):
        return self.ugettext(string)

    def dungettext(self, domain, singular, plural, num):
        return self.ungettext(singular, plural, num)

has_babel = False

try:
    from babel import Locale
    from babel.support import LazyProxy, Translations

    class TranslationsProxy(object):
        """Delegate Translations calls to the currently active Translations.

        If there's none, wrap those calls in LazyProxy objects.

        Activation is controlled by `activate` and `deactivate` methods.
        However, if retrieving the locale information is costly, it's also
        possible to enable activation on demand only, by providing a callable
        to `make_activable`.
        """

        def __init__(self):
            self._current = ThreadLocal(args=None, translations=None)
            self._null_translations = NullTranslationsBabel()
            self._plugin_domains = {}
            self._plugin_domains_lock = threading.RLock()
            self._activate_failed = False

        # Public API

        def add_domain(self, domain, env_path, locales_dir):
            with self._plugin_domains_lock:
                domains = self._plugin_domains.setdefault(env_path, {})
                domains[domain] = locales_dir

        def make_activable(self, get_locale, env_path=None):
            self._current.args = (get_locale, env_path)

        def activate(self, locale, env_path=None):
            try:
                locale_dir = pkg_resources.resource_filename('trac', 'locale')
            except Exception:
                self._activate_failed = True
                return
            t = Translations.load(locale_dir, locale or 'en_US')
            if not t or t.__class__ is NullTranslations:
                t = self._null_translations
            else:
                t.add(Translations.load(locale_dir, locale or 'en_US',
                                        'tracini'))
                if env_path:
                    with self._plugin_domains_lock:
                        domains = self._plugin_domains.get(env_path, {})
                        domains = domains.items()
                    for domain, dirname in domains:
                        t.add(Translations.load(dirname, locale, domain))
            self._current.translations = t
            self._activate_failed = False

        def deactivate(self):
            self._current.args = None
            t, self._current.translations = self._current.translations, None
            return t

        def reactivate(self, t):
            if t:
                self._current.translations = t

        @property
        def active(self):
            return self._current.translations or self._null_translations

        @property
        def isactive(self):
            if self._current.args is not None:
                get_locale, env_path = self._current.args
                self._current.args = None
                self.activate(get_locale(), env_path)
            # FIXME: The following always returns True: either a translation is
            # active, or activation has failed.
            return self._current.translations is not None \
                   or self._activate_failed

        # Delegated methods

        def __getattr__(self, name):
            return getattr(self.active, name)

        def gettext(self, string, **kwargs):
            def _gettext():
                return safefmt(self.active.ugettext(string), kwargs)
            if not self.isactive:
                return LazyProxy(_gettext)
            return _gettext()

        def dgettext(self, domain, string, **kwargs):
            def _dgettext():
                return safefmt(self.active.dugettext(domain, string), kwargs)
            if not self.isactive:
                return LazyProxy(_dgettext)
            return _dgettext()

        def ngettext(self, singular, plural, num, **kwargs):
            kwargs = kwargs.copy()
            kwargs.setdefault('num', num)
            def _ngettext():
                trans = self.active.ungettext(singular, plural, num)
                return safefmt(trans, kwargs)
            if not self.isactive:
                return LazyProxy(_ngettext)
            return _ngettext()

        def dngettext(self, domain, singular, plural, num, **kwargs):
            kwargs = kwargs.copy()
            kwargs.setdefault('num', num)
            def _dngettext():
                trans = self.active.dungettext(domain, singular, plural, num)
                return safefmt(trans, kwargs)
            if not self.isactive:
                return LazyProxy(_dngettext)
            return _dngettext()

        def tgettext(self, string, **kwargs):
            def _tgettext():
                trans = self.active.ugettext(string)
                return _tag_kwargs(trans, kwargs) if kwargs else trans
            if not self.isactive:
                return LazyProxy(_tgettext)
            return _tgettext()

        def dtgettext(self, domain, string, **kwargs):
            def _dtgettext():
                trans = self.active.dugettext(domain, string)
                return _tag_kwargs(trans, kwargs) if kwargs else trans
            if not self.isactive:
                return LazyProxy(_dtgettext)
            return _dtgettext()

        def tngettext(self, singular, plural, num, **kwargs):
            kwargs = kwargs.copy()
            kwargs.setdefault('num', num)
            def _tngettext():
                trans = self.active.ungettext(singular, plural, num)
                return _tag_kwargs(trans, kwargs)
            if not self.isactive:
                return LazyProxy(_tngettext)
            return _tngettext()

        def dtngettext(self, domain, singular, plural, num, **kwargs):
            kwargs = kwargs.copy()
            def _dtngettext():
                trans = self.active.dungettext(domain, singular, plural, num)
                if '%(num)' in trans:
                    kwargs.update(num=num)
                return _tag_kwargs(trans, kwargs) if kwargs else trans
            if not self.isactive:
                return LazyProxy(_dtngettext)
            return _dtngettext()


    translations = TranslationsProxy()

    def domain_functions(domain, *symbols):
        """Prepare partial instantiations of domain translation functions.

        :param domain: domain used for partial instantiation
        :param symbols: remaining parameters are the name of commonly used
                        translation function which will be bound to the domain

        Note: the symbols can also be given as an iterable in the 2nd argument.
        """
        if symbols and not isinstance(symbols[0], basestring):
            symbols = symbols[0]
        _functions = {
          'gettext': translations.dgettext,
          '_': translations.dgettext,
          'ngettext': translations.dngettext,
          'tgettext': translations.dtgettext,
          'tag_': translations.dtgettext,
          'tngettext': translations.dtngettext,
          'tagn_': translations.dtngettext,
          'add_domain': translations.add_domain,
          }
        def wrapdomain(symbol):
            if symbol == 'N_':
                return _noop
            return lambda *args, **kw: _functions[symbol](domain, *args, **kw)
        return [wrapdomain(s) for s in symbols]

    gettext = translations.gettext
    _ = gettext
    dgettext = translations.dgettext
    ngettext = translations.ngettext
    dngettext = translations.dngettext
    tgettext = translations.tgettext
    tag_ = tgettext
    dtgettext = translations.dtgettext
    tngettext = translations.tngettext
    tagn_ = tngettext
    dtngettext = translations.dtngettext

    def deactivate():
        """Deactivate translations.
        :return: the current Translations, if any
        """
        return translations.deactivate()

    def reactivate(t):
        """Reactivate previously deactivated translations.
        :param t: the Translations, as returned by `deactivate`
        """
        return translations.reactivate(t)

    def make_activable(get_locale, env_path=None):
        """Defer activation of translations.
        :param get_locale: a callable returning a Babel Locale object
        :param env_path: the environment to use for looking up catalogs
        """
        translations.make_activable(get_locale, env_path)

    def activate(locale, env_path=None):
        translations.activate(locale, env_path)

    def add_domain(domain, env_path, locale_dir):
        translations.add_domain(domain, env_path, locale_dir)

    def get_translations():
        return translations

    def get_available_locales():
        """Return a list of locale identifiers of the locales for which
        translations are available.
        """
        try:
            return [dirname for dirname
                    in pkg_resources.resource_listdir('trac', 'locale')
                    if '.' not in dirname]
        except Exception:
            return []

    def get_negotiated_locale(preferred_locales):
        def normalize(locale_ids):
            return [id.replace('-', '_') for id in locale_ids if id]
        return Locale.negotiate(normalize(preferred_locales),
                                normalize(get_available_locales()))

    has_babel = True

except ImportError: # fall back on 0.11 behavior, i18n functions are no-ops
    gettext = _ = gettext_noop
    dgettext = dgettext_noop
    ngettext = ngettext_noop
    dngettext = dngettext_noop
    tgettext = tag_ = tgettext_noop
    dtgettext = dtgettext_noop
    tngettext = tagn_ = tngettext_noop
    dtngettext = dtngettext_noop

    translations = NullTranslationsBabel()

    def activate(locale, env_path=None):
        pass

    def deactivate():
        pass

    def reactivate(t):
        pass

    def make_activable(get_locale, env_path=None):
        pass

    def get_translations():
        return translations

    def get_available_locales():
        return []

    def get_negotiated_locale(preferred=None, default=None):
        return None

########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8 -*-
#
# Copyright (C) 2008 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.com/license.html.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/.

import os.path
import sys

from genshi.builder import tag

from trac.admin import IAdminCommandProvider, IAdminPanelProvider
from trac.config import ListOption
from trac.core import *
from trac.perm import IPermissionRequestor
from trac.util import as_bool, is_path_below
from trac.util.compat import any
from trac.util.text import breakable_path, normalize_whitespace, print_table, \
                           printout
from trac.util.translation import _, ngettext, tag_
from trac.versioncontrol import DbRepositoryProvider, RepositoryManager, \
                                is_default
from trac.web.chrome import Chrome, add_notice, add_warning


class VersionControlAdmin(Component):
    """trac-admin command provider for version control administration."""

    implements(IAdminCommandProvider, IPermissionRequestor)

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('changeset added', '<repos> <rev> [rev] [...]',
               """Notify trac about changesets added to a repository

               This command should be called from a post-commit hook. It will
               trigger a cache update and notify components about the addition.
               """,
               self._complete_repos, self._do_changeset_added)
        yield ('changeset modified', '<repos> <rev> [rev] [...]',
               """Notify trac about changesets modified in a repository

               This command should be called from a post-revprop hook after
               revision properties like the commit message, author or date
               have been changed. It will trigger a cache update for the given
               revisions and notify components about the change.
               """,
               self._complete_repos, self._do_changeset_modified)
        yield ('repository list', '',
               'List source repositories',
               None, self._do_list)
        yield ('repository resync', '<repos> [rev]',
               """Re-synchronize trac with repositories

               When [rev] is specified, only that revision is synchronized.
               Otherwise, the complete revision history is synchronized. Note
               that this operation can take a long time to complete.
               If synchronization gets interrupted, it can be resumed later
               using the `sync` command.

               To synchronize all repositories, specify "*" as the repository.
               """,
               self._complete_repos, self._do_resync)
        yield ('repository sync', '<repos> [rev]',
               """Resume synchronization of repositories

               It works like `resync`, except that it doesn't clear the already
               synchronized changesets, so it's a better way to resume an
               interrupted `resync`.

               See `resync` help for detailed usage.
               """,
               self._complete_repos, self._do_sync)

    def get_reponames(self):
        rm = RepositoryManager(self.env)
        return [reponame or '(default)' for reponame
                in rm.get_all_repositories()]

    def _complete_repos(self, args):
        if len(args) == 1:
            return self.get_reponames()

    def _do_changeset_added(self, reponame, *revs):
        if is_default(reponame):
            reponame = ''
        rm = RepositoryManager(self.env)
        rm.notify('changeset_added', reponame, revs)

    def _do_changeset_modified(self, reponame, *revs):
        if is_default(reponame):
            reponame = ''
        rm = RepositoryManager(self.env)
        rm.notify('changeset_modified', reponame, revs)

    def _do_list(self):
        rm = RepositoryManager(self.env)
        values = []
        for (reponame, info) in sorted(rm.get_all_repositories().iteritems()):
            alias = ''
            if 'alias' in info:
                alias = info['alias'] or '(default)'
            values.append((reponame or '(default)', info.get('type', ''),
                           alias, info.get('dir', '')))
        print_table(values, [_('Name'), _('Type'), _('Alias'), _('Directory')])

    def _sync(self, reponame, rev, clean):
        rm = RepositoryManager(self.env)
        if reponame == '*':
            if rev is not None:
                raise TracError(_('Cannot synchronize a single revision '
                                  'on multiple repositories'))
            repositories = rm.get_real_repositories()
        else:
            if is_default(reponame):
                reponame = ''
            repos = rm.get_repository(reponame)
            if repos is None:
                raise TracError(_("Repository '%(repo)s' not found",
                                  repo=reponame or '(default)'))
            if rev is not None:
                repos.sync_changeset(rev)
                printout(_('%(rev)s resynced on %(reponame)s.', rev=rev,
                           reponame=repos.reponame or '(default)'))
                return
            repositories = [repos]

        for repos in sorted(repositories, key=lambda r: r.reponame):
            printout(_('Resyncing repository history for %(reponame)s... ',
                       reponame=repos.reponame or '(default)'))
            repos.sync(self._sync_feedback, clean=clean)
            for cnt, in self.env.db_query(
                    "SELECT count(rev) FROM revision WHERE repos=%s",
                    (repos.id,)):
                printout(ngettext('%(num)s revision cached.',
                                  '%(num)s revisions cached.', num=cnt))
        printout(_('Done.'))

    def _sync_feedback(self, rev):
        sys.stdout.write(' [%s]\r' % rev)
        sys.stdout.flush()

    def _do_resync(self, reponame, rev=None):
        self._sync(reponame, rev, clean=True)

    def _do_sync(self, reponame, rev=None):
        self._sync(reponame, rev, clean=False)

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return [('VERSIONCONTROL_ADMIN', ['BROWSER_VIEW', 'CHANGESET_VIEW',
                                          'FILE_VIEW', 'LOG_VIEW'])]


class RepositoryAdminPanel(Component):
    """Web admin panel for repository administration."""

    implements(IAdminPanelProvider)

    allowed_repository_dir_prefixes = ListOption('versioncontrol',
        'allowed_repository_dir_prefixes', '',
        doc="""Comma-separated list of allowed prefixes for repository
        directories when adding and editing repositories in the repository
        admin panel. If the list is empty, all repository directories are
        allowed. (''since 0.12.1'')""")

    # IAdminPanelProvider methods

    def get_admin_panels(self, req):
        if 'VERSIONCONTROL_ADMIN' in req.perm:
            yield ('versioncontrol', _('Version Control'), 'repository',
                   _('Repositories'))

    def render_admin_panel(self, req, category, page, path_info):
        req.perm.require('VERSIONCONTROL_ADMIN')

        # Retrieve info for all repositories
        rm = RepositoryManager(self.env)
        all_repos = rm.get_all_repositories()
        db_provider = self.env[DbRepositoryProvider]

        if path_info:
            # Detail view
            reponame = path_info if not is_default(path_info) else ''
            info = all_repos.get(reponame)
            if info is None:
                raise TracError(_("Repository '%(repo)s' not found",
                                  repo=path_info))
            if req.method == 'POST':
                if req.args.get('cancel'):
                    req.redirect(req.href.admin(category, page))

                elif db_provider and req.args.get('save'):
                    # Modify repository
                    changes = {}
                    for field in db_provider.repository_attrs:
                        value = normalize_whitespace(req.args.get(field))
                        if (value is not None or field == 'hidden') \
                                and value != info.get(field):
                            changes[field] = value
                    if 'dir' in changes \
                            and not self._check_dir(req, changes['dir']):
                        changes = {}
                    if changes:
                        db_provider.modify_repository(reponame, changes)
                        add_notice(req, _('Your changes have been saved.'))
                    name = req.args.get('name')
                    resync = tag.tt('trac-admin $ENV repository resync "%s"'
                                    % (name or '(default)'))
                    if 'dir' in changes:
                        msg = tag_('You should now run %(resync)s to '
                                   'synchronize Trac with the repository.',
                                   resync=resync)
                        add_notice(req, msg)
                    elif 'type' in changes:
                        msg = tag_('You may have to run %(resync)s to '
                                   'synchronize Trac with the repository.',
                                   resync=resync)
                        add_notice(req, msg)
                    if name and name != path_info and not 'alias' in info:
                        cset_added = tag.tt('trac-admin $ENV changeset '
                                            'added "%s" $REV'
                                            % (name or '(default)'))
                        msg = tag_('You will need to update your post-commit '
                                   'hook to call %(cset_added)s with the new '
                                   'repository name.', cset_added=cset_added)
                        add_notice(req, msg)
                    if changes:
                        req.redirect(req.href.admin(category, page))

            Chrome(self.env).add_wiki_toolbars(req)
            data = {'view': 'detail', 'reponame': reponame}

        else:
            # List view
            if req.method == 'POST':
                # Add a repository
                if db_provider and req.args.get('add_repos'):
                    name = req.args.get('name')
                    type_ = req.args.get('type')
                    # Avoid errors when copy/pasting paths
                    dir = normalize_whitespace(req.args.get('dir', ''))
                    if name is None or type_ is None or not dir:
                        add_warning(req, _('Missing arguments to add a '
                                           'repository.'))
                    elif self._check_dir(req, dir):
                        db_provider.add_repository(name, dir, type_)
                        name = name or '(default)'
                        add_notice(req, _('The repository "%(name)s" has been '
                                          'added.', name=name))
                        resync = tag.tt('trac-admin $ENV repository resync '
                                        '"%s"' % name)
                        msg = tag_('You should now run %(resync)s to '
                                   'synchronize Trac with the repository.',
                                   resync=resync)
                        add_notice(req, msg)
                        cset_added = tag.tt('trac-admin $ENV changeset '
                                            'added "%s" $REV' % name)
                        msg = tag_('You should also set up a post-commit hook '
                                   'on the repository to call %(cset_added)s '
                                   'for each committed changeset.',
                                   cset_added=cset_added)
                        add_notice(req, msg)
                        req.redirect(req.href.admin(category, page))

                # Add a repository alias
                elif db_provider and req.args.get('add_alias'):
                    name = req.args.get('name')
                    alias = req.args.get('alias')
                    if name is not None and alias is not None:
                        db_provider.add_alias(name, alias)
                        add_notice(req, _('The alias "%(name)s" has been '
                                          'added.', name=name or '(default)'))
                        req.redirect(req.href.admin(category, page))
                    add_warning(req, _('Missing arguments to add an '
                                       'alias.'))

                # Refresh the list of repositories
                elif req.args.get('refresh'):
                    req.redirect(req.href.admin(category, page))

                # Remove repositories
                elif db_provider and req.args.get('remove'):
                    sel = req.args.getlist('sel')
                    if sel:
                        for name in sel:
                            db_provider.remove_repository(name)
                        add_notice(req, _('The selected repositories have '
                                          'been removed.'))
                        req.redirect(req.href.admin(category, page))
                    add_warning(req, _('No repositories were selected.'))

            data = {'view': 'list'}

        # Find repositories that are editable
        db_repos = {}
        if db_provider is not None:
            db_repos = dict(db_provider.get_repositories())

        # Prepare common rendering data
        repositories = dict((reponame, self._extend_info(reponame, info.copy(),
                                                         reponame in db_repos))
                            for (reponame, info) in all_repos.iteritems())
        types = sorted([''] + rm.get_supported_types())
        data.update({'types': types, 'default_type': rm.repository_type,
                     'repositories': repositories})

        return 'admin_repositories.html', data

    def _extend_info(self, reponame, info, editable):
        """Extend repository info for rendering."""
        info['name'] = reponame
        if info.get('dir') is not None:
            info['prettydir'] = breakable_path(info['dir']) or ''
        info['hidden'] = as_bool(info.get('hidden'))
        info['editable'] = editable
        if not info.get('alias'):
            try:
                repos = RepositoryManager(self.env).get_repository(reponame)
                youngest_rev = repos.get_youngest_rev()
                info['rev'] = youngest_rev
                info['display_rev'] = repos.display_rev(youngest_rev)
            except Exception:
                pass
        return info

    def _check_dir(self, req, dir):
        """Check that a repository directory is valid, and add a warning
        message if not.
        """
        if not os.path.isabs(dir):
            add_warning(req, _('The repository directory must be an absolute '
                               'path.'))
            return False
        prefixes = [os.path.join(self.env.path, prefix)
                    for prefix in self.allowed_repository_dir_prefixes]
        if prefixes and not any(is_path_below(dir, prefix)
                                for prefix in prefixes):
            add_warning(req, _('The repository directory must be located '
                               'below one of the following directories: '
                               '%(dirs)s', dirs=', '.join(prefixes)))
            return False
        return True

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2011 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import os.path
import time

from trac.admin import AdminCommandError, IAdminCommandProvider, get_dir_list
from trac.config import ConfigSection, ListOption, Option
from trac.core import *
from trac.resource import IResourceManager, Resource, ResourceNotFound
from trac.util.concurrency import threading
from trac.util.text import printout, to_unicode
from trac.util.translation import _
from trac.web.api import IRequestFilter


def is_default(reponame):
    """Check whether `reponame` is the default repository."""
    return not reponame or reponame in ('(default)', _('(default)'))


class IRepositoryConnector(Interface):
    """Provide support for a specific version control system."""

    error = None # place holder for storing relevant error message

    def get_supported_types():
        """Return the types of version control systems that are supported.

        Yields `(repotype, priority)` pairs, where `repotype` is used to
        match against the configured `[trac] repository_type` value in TracIni.

        If multiple provider match a given type, the `priority` is used to
        choose between them (highest number is highest priority).

        If the `priority` returned is negative, this indicates that the
        connector for the given `repotype` indeed exists but can't be
        used for some reason. The `error` property can then be used to
        store an error message or exception relevant to the problem detected.
        """

    def get_repository(repos_type, repos_dir, params):
        """Return a Repository instance for the given repository type and dir.
        """


class IRepositoryProvider(Interface):
    """Provide known named instances of Repository."""

    def get_repositories():
        """Generate repository information for known repositories.

        Repository information is a key,value pair, where the value is
        a dictionary which must contain at the very least either of
        the following entries:

         - `'dir'`: the repository directory which can be used by the
                    connector to create a `Repository` instance. This
                    defines a "real" repository.

         - `'alias'`: the name of another repository. This defines an
                      alias to another (real) repository.

        Optional entries:

         - `'type'`: the type of the repository (if not given, the
                     default repository type will be used).

         - `'description'`: a description of the repository (can
                            contain WikiFormatting).

         - `'hidden'`: if set to `'true'`, the repository is hidden
                       from the repository index.

         - `'url'`: the base URL for checking out the repository.
        """


class IRepositoryChangeListener(Interface):
    """Listen for changes in repositories."""

    def changeset_added(repos, changeset):
        """Called after a changeset has been added to a repository."""

    def changeset_modified(repos, changeset, old_changeset):
        """Called after a changeset has been modified in a repository.

        The `old_changeset` argument contains the metadata of the changeset
        prior to the modification. It is `None` if the old metadata cannot
        be retrieved.
        """


class DbRepositoryProvider(Component):
    """Component providing repositories registered in the DB."""

    implements(IRepositoryProvider, IAdminCommandProvider)

    repository_attrs = ('alias', 'description', 'dir', 'hidden', 'name',
                        'type', 'url')

    # IRepositoryProvider methods

    def get_repositories(self):
        """Retrieve repositories specified in the repository DB table."""
        repos = {}
        for id, name, value in self.env.db_query(
                "SELECT id, name, value FROM repository WHERE name IN (%s)"
                % ",".join("'%s'" % each for each in self.repository_attrs)):
            if value is not None:
                repos.setdefault(id, {})[name] = value
        reponames = {}
        for id, info in repos.iteritems():
            if 'name' in info and ('dir' in info or 'alias' in info):
                info['id'] = id
                reponames[info['name']] = info
        return reponames.iteritems()

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('repository add', '<repos> <dir> [type]',
               "Add a source repository",
               self._complete_add, self._do_add)
        yield ('repository alias', '<name> <target>',
               "Create an alias for a repository",
               self._complete_alias, self._do_alias)
        yield ('repository remove', '<repos>',
               "Remove a source repository",
               self._complete_repos, self._do_remove)
        yield ('repository set', '<repos> <key> <value>',
               """Set an attribute of a repository

               The following keys are supported: %s
               """ % ', '.join(self.repository_attrs),
               self._complete_set, self._do_set)

    def get_reponames(self):
        rm = RepositoryManager(self.env)
        return [reponame or '(default)' for reponame
                in rm.get_all_repositories()]

    def _complete_add(self, args):
        if len(args) == 2:
            return get_dir_list(args[-1], True)
        elif len(args) == 3:
            return RepositoryManager(self.env).get_supported_types()

    def _complete_alias(self, args):
        if len(args) == 2:
            return self.get_reponames()

    def _complete_repos(self, args):
        if len(args) == 1:
            return self.get_reponames()

    def _complete_set(self, args):
        if len(args) == 1:
            return self.get_reponames()
        elif len(args) == 2:
            return self.repository_attrs

    def _do_add(self, reponame, dir, type_=None):
        self.add_repository(reponame, os.path.abspath(dir), type_)

    def _do_alias(self, reponame, target):
        self.add_alias(reponame, target)

    def _do_remove(self, reponame):
        self.remove_repository(reponame)

    def _do_set(self, reponame, key, value):
        if key not in self.repository_attrs:
            raise AdminCommandError(_('Invalid key "%(key)s"', key=key))
        if key == 'dir':
            value = os.path.abspath(value)
        self.modify_repository(reponame, {key: value})
        if not reponame:
            reponame = '(default)'
        if key == 'dir':
            printout(_('You should now run "repository resync %(name)s".',
                       name=reponame))
        elif key == 'type':
            printout(_('You may have to run "repository resync %(name)s".',
                       name=reponame))

    # Public interface

    def add_repository(self, reponame, dir, type_=None):
        """Add a repository."""
        if not os.path.isabs(dir):
            raise TracError(_("The repository directory must be absolute"))
        if is_default(reponame):
            reponame = ''
        rm = RepositoryManager(self.env)
        if type_ and type_ not in rm.get_supported_types():
            raise TracError(_("The repository type '%(type)s' is not "
                              "supported", type=type_))
        with self.env.db_transaction as db:
            id = rm.get_repository_id(reponame)
            db.executemany(
                "INSERT INTO repository (id, name, value) VALUES (%s, %s, %s)",
                [(id, 'dir', dir),
                 (id, 'type', type_ or '')])
        rm.reload_repositories()

    def add_alias(self, reponame, target):
        """Create an alias repository."""
        if is_default(reponame):
            reponame = ''
        if is_default(target):
            target = ''
        rm = RepositoryManager(self.env)
        with self.env.db_transaction as db:
            id = rm.get_repository_id(reponame)
            db.executemany(
                "INSERT INTO repository (id, name, value) VALUES (%s, %s, %s)",
                [(id, 'dir', None),
                 (id, 'alias', target)])
        rm.reload_repositories()

    def remove_repository(self, reponame):
        """Remove a repository."""
        if is_default(reponame):
            reponame = ''
        rm = RepositoryManager(self.env)
        with self.env.db_transaction as db:
            id = rm.get_repository_id(reponame)
            db("DELETE FROM repository WHERE id=%s", (id,))
            db("DELETE FROM revision WHERE repos=%s", (id,))
            db("DELETE FROM node_change WHERE repos=%s", (id,))
        rm.reload_repositories()

    def modify_repository(self, reponame, changes):
        """Modify attributes of a repository."""
        if is_default(reponame):
            reponame = ''
        rm = RepositoryManager(self.env)
        with self.env.db_transaction as db:
            id = rm.get_repository_id(reponame)
            for (k, v) in changes.iteritems():
                if k not in self.repository_attrs:
                    continue
                if k in ('alias', 'name') and is_default(v):
                    v = ''
                if k == 'dir' and not os.path.isabs(v):
                    raise TracError(_("The repository directory must be "
                                      "absolute"))
                db("UPDATE repository SET value=%s WHERE id=%s AND name=%s",
                   (v, id, k))
                if not db(
                        "SELECT value FROM repository WHERE id=%s AND name=%s",
                        (id, k)):
                    db("""INSERT INTO repository (id, name, value)
                          VALUES (%s, %s, %s)
                          """, (id, k, v))
        rm.reload_repositories()


class RepositoryManager(Component):
    """Version control system manager."""

    implements(IRequestFilter, IResourceManager, IRepositoryProvider)

    connectors = ExtensionPoint(IRepositoryConnector)
    providers = ExtensionPoint(IRepositoryProvider)
    change_listeners = ExtensionPoint(IRepositoryChangeListener)

    repositories_section = ConfigSection('repositories',
        """One of the alternatives for registering new repositories is to
        populate the `[repositories]` section of the `trac.ini`.

        This is especially suited for setting up convenience aliases,
        short-lived repositories, or during the initial phases of an
        installation.

        See [TracRepositoryAdmin#Intrac.ini TracRepositoryAdmin] for details
        about the format adopted for this section and the rest of that page for
        the other alternatives.

        (''since 0.12'')""")

    repository_type = Option('trac', 'repository_type', 'svn',
        """Default repository connector type. (''since 0.10'')

        This is also used as the default repository type for repositories
        defined in [[TracIni#repositories-section repositories]] or using the
        "Repositories" admin panel. (''since 0.12'')
        """)

    repository_dir = Option('trac', 'repository_dir', '',
        """Path to the default repository. This can also be a relative path
        (''since 0.11'').

        This option is deprecated, and repositories should be defined in the
        [TracIni#repositories-section repositories] section, or using the
        "Repositories" admin panel. (''since 0.12'')""")

    repository_sync_per_request = ListOption('trac',
        'repository_sync_per_request', '(default)',
        doc="""List of repositories that should be synchronized on every page
        request.

        Leave this option empty if you have set up post-commit hooks calling
        `trac-admin $ENV changeset added` on all your repositories
        (recommended). Otherwise, set it to a comma-separated list of
        repository names. Note that this will negatively affect performance,
        and will prevent changeset listeners from receiving events from the
        repositories specified here. The default is to synchronize the default
        repository, for backward compatibility. (''since 0.12'')""")

    def __init__(self):
        self._cache = {}
        self._lock = threading.Lock()
        self._connectors = None
        self._all_repositories = None

    # IRequestFilter methods

    def pre_process_request(self, req, handler):
        from trac.web.chrome import Chrome, add_warning
        if handler is not Chrome(self.env):
            for reponame in self.repository_sync_per_request:
                start = time.time()
                if is_default(reponame):
                    reponame = ''
                try:
                    repo = self.get_repository(reponame)
                    if repo:
                        repo.sync()
                    else:
                        self.log.warning("Unable to find repository '%s' for "
                                         "synchronization",
                                         reponame or '(default)')
                        continue
                except TracError, e:
                    add_warning(req,
                        _("Can't synchronize with repository \"%(name)s\" "
                          "(%(error)s). Look in the Trac log for more "
                          "information.", name=reponame or '(default)',
                          error=to_unicode(e.message)))
                self.log.info("Synchronized '%s' repository in %0.2f seconds",
                              reponame or '(default)', time.time() - start)
        return handler

    def post_process_request(self, req, template, data, content_type):
        return (template, data, content_type)

    # IResourceManager methods

    def get_resource_realms(self):
        yield 'changeset'
        yield 'source'
        yield 'repository'

    def get_resource_description(self, resource, format=None, **kwargs):
        if resource.realm == 'changeset':
            parent = resource.parent
            reponame = parent and parent.id
            id = resource.id
            if reponame:
                return _("Changeset %(rev)s in %(repo)s", rev=id, repo=reponame)
            else:
                return _("Changeset %(rev)s", rev=id)
        elif resource.realm == 'source':
            parent = resource.parent
            reponame = parent and parent.id
            id = resource.id
            version = ''
            if format == 'summary':
                repos = self.get_repository(reponame)
                node = repos.get_node(resource.id, resource.version)
                if node.isdir:
                    kind = _("directory")
                elif node.isfile:
                    kind = _("file")
                if resource.version:
                    version = _(" at version %(rev)s", rev=resource.version)
            else:
                kind = _("path")
                if resource.version:
                    version = '@%s' % resource.version
            in_repo = _(" in %(repo)s", repo=reponame) if reponame else ''
            # TRANSLATOR: file /path/to/file.py at version 13 in reponame
            return _('%(kind)s %(id)s%(at_version)s%(in_repo)s',
                     kind=kind, id=id, at_version=version, in_repo=in_repo)
        elif resource.realm == 'repository':
            return _("Repository %(repo)s", repo=resource.id)

    def get_resource_url(self, resource, href, **kwargs):
        if resource.realm == 'changeset':
            parent = resource.parent
            return href.changeset(resource.id, parent and parent.id or None)
        elif resource.realm == 'source':
            parent = resource.parent
            return href.browser(parent and parent.id or None, resource.id,
                                rev=resource.version or None)
        elif resource.realm == 'repository':
            return href.browser(resource.id or None)

    def resource_exists(self, resource):
        if resource.realm == 'repository':
            reponame = resource.id
        else:
            reponame = resource.parent.id
        repos = self.env.get_repository(reponame)
        if not repos:
            return False
        if resource.realm == 'changeset':
            try:
                repos.get_changeset(resource.id)
                return True
            except NoSuchChangeset:
                return False
        elif resource.realm == 'source':
            try:
                repos.get_node(resource.id, resource.version)
                return True
            except NoSuchNode:
                return False
        elif resource.realm == 'repository':
            return True

    # IRepositoryProvider methods

    def get_repositories(self):
        """Retrieve repositories specified in TracIni.

        The `[repositories]` section can be used to specify a list
        of repositories.
        """
        repositories = self.repositories_section
        reponames = {}
        # eventually add pre-0.12 default repository
        if self.repository_dir:
            reponames[''] = {'dir': self.repository_dir}
        # first pass to gather the <name>.dir entries
        for option in repositories:
            if option.endswith('.dir'):
                reponames[option[:-4]] = {}
        # second pass to gather aliases
        for option in repositories:
            alias = repositories.get(option)
            if '.' not in option:   # Support <alias> = <repo> syntax
                option += '.alias'
            if option.endswith('.alias') and alias in reponames:
                reponames.setdefault(option[:-6], {})['alias'] = alias
        # third pass to gather the <name>.<detail> entries
        for option in repositories:
            if '.' in option:
                name, detail = option.rsplit('.', 1)
                if name in reponames and detail != 'alias':
                    reponames[name][detail] = repositories.get(option)

        for reponame, info in reponames.iteritems():
            yield (reponame, info)

    # Public API methods

    def get_supported_types(self):
        """Return the list of supported repository types."""
        types = set(type_ for connector in self.connectors
                    for (type_, prio) in connector.get_supported_types() or []
                    if prio >= 0)
        return list(types)

    def get_repositories_by_dir(self, directory):
        """Retrieve the repositories based on the given directory.

           :param directory: the key for identifying the repositories.
           :return: list of `Repository` instances.
        """
        directory = os.path.join(os.path.normcase(directory), '')
        repositories = []
        for reponame, repoinfo in self.get_all_repositories().iteritems():
            dir = repoinfo.get('dir')
            if dir:
                dir = os.path.join(os.path.normcase(dir), '')
                if dir.startswith(directory):
                    repos = self.get_repository(reponame)
                    if repos:
                        repositories.append(repos)
        return repositories

    def get_repository_id(self, reponame):
        """Return a unique id for the given repository name.

        This will create and save a new id if none is found.

        \note: this should probably be renamed as we're dealing
               exclusively with *db* repository ids here.
        """
        with self.env.db_transaction as db:
            for id, in db(
                    "SELECT id FROM repository WHERE name='name' AND value=%s",
                    (reponame,)):
                return id

            id = db("SELECT COALESCE(MAX(id), 0) FROM repository")[0][0] + 1
            db("INSERT INTO repository (id, name, value) VALUES (%s, %s, %s)",
               (id, 'name', reponame))
            return id

    def get_repository(self, reponame):
        """Retrieve the appropriate `Repository` for the given
        repository name.

           :param reponame: the key for specifying the repository.
                            If no name is given, take the default
                            repository.
           :return: if no corresponding repository was defined,
                    simply return `None`.
        """
        reponame = reponame or ''
        repoinfo = self.get_all_repositories().get(reponame, {})
        if 'alias' in repoinfo:
            reponame = repoinfo['alias']
            repoinfo = self.get_all_repositories().get(reponame, {})
        rdir = repoinfo.get('dir')
        if not rdir:
            return None
        rtype = repoinfo.get('type') or self.repository_type

        # get a Repository for the reponame (use a thread-level cache)
        with self.env.db_transaction: # prevent possible deadlock, see #4465
            with self._lock:
                tid = threading._get_ident()
                if tid in self._cache:
                    repositories = self._cache[tid]
                else:
                    repositories = self._cache[tid] = {}
                repos = repositories.get(reponame)
                if not repos:
                    if not os.path.isabs(rdir):
                        rdir = os.path.join(self.env.path, rdir)
                    connector = self._get_connector(rtype)
                    repos = connector.get_repository(rtype, rdir,
                                                     repoinfo.copy())
                    repositories[reponame] = repos
                return repos

    def get_repository_by_path(self, path):
        """Retrieve a matching `Repository` for the given `path`.

        :param path: the eventually scoped repository-scoped path
        :return: a `(reponame, repos, path)` triple, where `path` is
                 the remaining part of `path` once the `reponame` has
                 been truncated, if needed.
        """
        matches = []
        path = path.strip('/') + '/' if path else '/'
        for reponame in self.get_all_repositories().keys():
            stripped_reponame = reponame.strip('/') + '/'
            if path.startswith(stripped_reponame):
                matches.append((len(stripped_reponame), reponame))
        if matches:
            matches.sort()
            length, reponame = matches[-1]
            path = path[length:]
        else:
            reponame = ''
        return (reponame, self.get_repository(reponame),
                path.rstrip('/') or '/')

    def get_default_repository(self, context):
        """Recover the appropriate repository from the current context.

        Lookup the closest source or changeset resource in the context
        hierarchy and return the name of its associated repository.
        """
        while context:
            if context.resource.realm in ('source', 'changeset'):
                return context.resource.parent.id
            context = context.parent

    def get_all_repositories(self):
        """Return a dictionary of repository information, indexed by name."""
        if not self._all_repositories:
            all_repositories = {}
            for provider in self.providers:
                for reponame, info in provider.get_repositories() or []:
                    if reponame in all_repositories:
                        self.log.warn("Discarding duplicate repository '%s'",
                                      reponame)
                    else:
                        info['name'] = reponame
                        if 'id' not in info:
                            info['id'] = self.get_repository_id(reponame)
                        all_repositories[reponame] = info
            self._all_repositories = all_repositories
        return self._all_repositories

    def get_real_repositories(self):
        """Return a set of all real repositories (i.e. excluding aliases)."""
        repositories = set()
        for reponame in self.get_all_repositories():
            try:
                repos = self.get_repository(reponame)
                if repos is not None:
                    repositories.add(repos)
            except TracError:
                pass # Skip invalid repositories
        return repositories

    def reload_repositories(self):
        """Reload the repositories from the providers."""
        with self._lock:
            # FIXME: trac-admin doesn't reload the environment
            self._cache = {}
            self._all_repositories = None
        self.config.touch()     # Force environment reload

    def notify(self, event, reponame, revs):
        """Notify repositories and change listeners about repository events.

        The supported events are the names of the methods defined in the
        `IRepositoryChangeListener` interface.
        """
        self.log.debug("Event %s on %s for changesets %r",
                       event, reponame, revs)

        # Notify a repository by name, and all repositories with the same
        # base, or all repositories by base or by repository dir
        repos = self.get_repository(reponame)
        repositories = []
        if repos:
            base = repos.get_base()
        else:
            dir = os.path.abspath(reponame)
            repositories = self.get_repositories_by_dir(dir)
            if repositories:
                base = None
            else:
                base = reponame
        if base:
            repositories = [r for r in self.get_real_repositories()
                            if r.get_base() == base]
        if not repositories:
            self.log.warn("Found no repositories matching '%s' base.",
                          base or reponame)
            return
        for repos in sorted(repositories, key=lambda r: r.reponame):
            repos.sync()
            for rev in revs:
                args = []
                if event == 'changeset_modified':
                    args.append(repos.sync_changeset(rev))
                try:
                    changeset = repos.get_changeset(rev)
                except NoSuchChangeset:
                    try:
                        repos.sync_changeset(rev)
                        changeset = repos.get_changeset(rev)
                    except NoSuchChangeset:
                        continue
                self.log.debug("Event %s on %s for revision %s",
                               event, repos.reponame or '(default)', rev)
                for listener in self.change_listeners:
                    getattr(listener, event)(repos, changeset, *args)

    def shutdown(self, tid=None):
        """Free `Repository` instances bound to a given thread identifier"""
        if tid:
            assert tid == threading._get_ident()
            with self._lock:
                repositories = self._cache.pop(tid, {})
                for reponame, repos in repositories.iteritems():
                    repos.close()

    # private methods

    def _get_connector(self, rtype):
        """Retrieve the appropriate connector for the given repository type.

        Note that the self._lock must be held when calling this method.
        """
        if self._connectors is None:
            # build an environment-level cache for the preferred connectors
            self._connectors = {}
            for connector in self.connectors:
                for type_, prio in connector.get_supported_types() or []:
                    keep = (connector, prio)
                    if type_ in self._connectors and \
                            prio <= self._connectors[type_][1]:
                        keep = None
                    if keep:
                        self._connectors[type_] = keep
        if rtype in self._connectors:
            connector, prio = self._connectors[rtype]
            if prio >= 0: # no error condition
                return connector
            else:
                raise TracError(
                    _('Unsupported version control system "%(name)s"'
                      ': %(error)s', name=rtype,
                      error=to_unicode(connector.error)))
        else:
            raise TracError(
                _('Unsupported version control system "%(name)s": '
                  'Can\'t find an appropriate component, maybe the '
                  'corresponding plugin was not enabled? ', name=rtype))


class NoSuchChangeset(ResourceNotFound):
    def __init__(self, rev):
        ResourceNotFound.__init__(self,
                                  _('No changeset %(rev)s in the repository',
                                    rev=rev),
                                  _('No such changeset'))


class NoSuchNode(ResourceNotFound):
    def __init__(self, path, rev, msg=None):
        if msg is None:
            msg = _("No node %(path)s at revision %(rev)s", path=path, rev=rev)
        else:
            msg = _("%(msg)s: No node %(path)s at revision %(rev)s",
                    msg=msg, path=path, rev=rev)
        ResourceNotFound.__init__(self, msg, _('No such node'))


class Repository(object):
    """Base class for a repository provided by a version control system."""

    has_linear_changesets = False

    scope = '/'

    def __init__(self, name, params, log):
        """Initialize a repository.

           :param name: a unique name identifying the repository, usually a
                        type-specific prefix followed by the path to the
                        repository.
           :param params: a `dict` of parameters for the repository. Contains
                          the name of the repository under the key "name" and
                          the surrogate key that identifies the repository in
                          the database under the key "id".
           :param log: a logger instance.
        """
        self.name = name
        self.params = params
        self.reponame = params['name']
        self.id = params['id']
        self.log = log
        self.resource = Resource('repository', self.reponame)

    def close(self):
        """Close the connection to the repository."""
        raise NotImplementedError

    def get_base(self):
        """Return the name of the base repository for this repository.

        This function returns the name of the base repository to which scoped
        repositories belong. For non-scoped repositories, it returns the
        repository name.
        """
        return self.name

    def clear(self, youngest_rev=None):
        """Clear any data that may have been cached in instance properties.

        `youngest_rev` can be specified as a way to force the value
        of the `youngest_rev` property (''will change in 0.12'').
        """
        pass

    def sync(self, rev_callback=None, clean=False):
        """Perform a sync of the repository cache, if relevant.

        If given, `rev_callback` must be a callable taking a `rev` parameter.
        The backend will call this function for each `rev` it decided to
        synchronize, once the synchronization changes are committed to the
        cache. When `clean` is `True`, the cache is cleaned first.
        """
        pass

    def sync_changeset(self, rev):
        """Resync the repository cache for the given `rev`, if relevant.

        Returns a "metadata-only" changeset containing the metadata prior to
        the resync, or `None` if the old values cannot be retrieved (typically
        when the repository is not cached).
        """
        return None

    def get_quickjump_entries(self, rev):
        """Generate a list of interesting places in the repository.

        `rev` might be used to restrict the list of available locations,
        but in general it's best to produce all known locations.

        The generated results must be of the form (category, name, path, rev).
        """
        return []

    def get_path_url(self, path, rev):
        """Return the repository URL for the given path and revision.

        The returned URL can be `None`, meaning that no URL has been specified
        for the repository, an absolute URL, or a scheme-relative URL starting
        with `//`, in which case the scheme of the request should be prepended.
        """
        return None

    def get_changeset(self, rev):
        """Retrieve a Changeset corresponding to the given revision `rev`."""
        raise NotImplementedError

    def get_changeset_uid(self, rev):
        """Return a globally unique identifier for the ''rev'' changeset.

        Two changesets from different repositories can sometimes refer to
        the ''very same'' changeset (e.g. the repositories are clones).
        """

    def get_changesets(self, start, stop):
        """Generate Changeset belonging to the given time period (start, stop).
        """
        rev = self.youngest_rev
        while rev:
            chgset = self.get_changeset(rev)
            if chgset.date < start:
                return
            if chgset.date < stop:
                yield chgset
            rev = self.previous_rev(rev)

    def has_node(self, path, rev=None):
        """Tell if there's a node at the specified (path,rev) combination.

        When `rev` is `None`, the latest revision is implied.
        """
        try:
            self.get_node(path, rev)
            return True
        except TracError:
            return False

    def get_node(self, path, rev=None):
        """Retrieve a Node from the repository at the given path.

        A Node represents a directory or a file at a given revision in the
        repository.
        If the `rev` parameter is specified, the Node corresponding to that
        revision is returned, otherwise the Node corresponding to the youngest
        revision is returned.
        """
        raise NotImplementedError

    def get_oldest_rev(self):
        """Return the oldest revision stored in the repository."""
        raise NotImplementedError
    oldest_rev = property(lambda self: self.get_oldest_rev())

    def get_youngest_rev(self):
        """Return the youngest revision in the repository."""
        raise NotImplementedError
    youngest_rev = property(lambda self: self.get_youngest_rev())

    def previous_rev(self, rev, path=''):
        """Return the revision immediately preceding the specified revision.

        If `path` is given, filter out ancestor revisions having no changes
        below `path`.

        In presence of multiple parents, this follows the first parent.
        """
        raise NotImplementedError

    def next_rev(self, rev, path=''):
        """Return the revision immediately following the specified revision.

        If `path` is given, filter out descendant revisions having no changes
        below `path`.

        In presence of multiple children, this follows the first child.
        """
        raise NotImplementedError

    def parent_revs(self, rev):
        """Return a list of parents of the specified revision."""
        parent = self.previous_rev(rev)
        return [parent] if parent is not None else []

    def rev_older_than(self, rev1, rev2):
        """Provides a total order over revisions.

        Return `True` if `rev1` is an ancestor of `rev2`.
        """
        raise NotImplementedError

    def get_path_history(self, path, rev=None, limit=None):
        """Retrieve all the revisions containing this path.

        If given, `rev` is used as a starting point (i.e. no revision
        ''newer'' than `rev` should be returned).
        The result format should be the same as the one of Node.get_history()
        """
        raise NotImplementedError

    def normalize_path(self, path):
        """Return a canonical representation of path in the repos."""
        raise NotImplementedError

    def normalize_rev(self, rev):
        """Return a (unique) canonical representation of a revision.

        It's up to the backend to decide which string values of `rev`
        (usually provided by the user) should be accepted, and how they
        should be normalized. Some backends may for instance want to match
        against known tags or branch names.

        In addition, if `rev` is `None` or '', the youngest revision should
        be returned.
        """
        raise NotImplementedError

    def short_rev(self, rev):
        """Return a compact representation of a revision in the repos."""
        return self.normalize_rev(rev)

    def display_rev(self, rev):
        """Return a representation of a revision in the repos for displaying to
        the user.

        This can be a shortened revision string, e.g. for repositories using
        long hashes.
        """
        return self.normalize_rev(rev)

    def get_changes(self, old_path, old_rev, new_path, new_rev,
                    ignore_ancestry=1):
        """Generates changes corresponding to generalized diffs.

        Generator that yields change tuples (old_node, new_node, kind, change)
        for each node change between the two arbitrary (path,rev) pairs.

        The old_node is assumed to be None when the change is an ADD,
        the new_node is assumed to be None when the change is a DELETE.
        """
        raise NotImplementedError

    def is_viewable(self, perm):
        """Return True if view permission is granted on the repository."""
        return 'BROWSER_VIEW' in perm(self.resource.child('source', '/'))

    can_view = is_viewable  # 0.12 compatibility


class Node(object):
    """Represents a directory or file in the repository at a given revision."""

    DIRECTORY = "dir"
    FILE = "file"

    resource = property(lambda self: Resource('source', self.path,
                                              version=self.rev,
                                              parent=self.repos.resource))

    # created_path and created_rev properties refer to the Node "creation"
    # in the Subversion meaning of a Node in a versioned tree (see #3340).
    #
    # Those properties must be set by subclasses.
    #
    created_rev = None
    created_path = None

    def __init__(self, repos, path, rev, kind):
        assert kind in (Node.DIRECTORY, Node.FILE), \
               "Unknown node kind %s" % kind
        self.repos = repos
        self.path = to_unicode(path)
        self.rev = rev
        self.kind = kind

    def get_content(self):
        """Return a stream for reading the content of the node.

        This method will return `None` for directories.
        The returned object must support a `read([len])` method.
        """
        raise NotImplementedError

    def get_entries(self):
        """Generator that yields the immediate child entries of a directory.

        The entries are returned in no particular order.
        If the node is a file, this method returns `None`.
        """
        raise NotImplementedError

    def get_history(self, limit=None):
        """Provide backward history for this Node.

        Generator that yields `(path, rev, chg)` tuples, one for each revision
        in which the node was changed. This generator will follow copies and
        moves of a node (if the underlying version control system supports
        that), which will be indicated by the first element of the tuple
        (i.e. the path) changing.
        Starts with an entry for the current revision.

        :param limit: if given, yield at most ``limit`` results.
        """
        raise NotImplementedError

    def get_previous(self):
        """Return the change event corresponding to the previous revision.

        This returns a `(path, rev, chg)` tuple.
        """
        skip = True
        for p in self.get_history(2):
            if skip:
                skip = False
            else:
                return p

    def get_annotations(self):
        """Provide detailed backward history for the content of this Node.

        Retrieve an array of revisions, one `rev` for each line of content
        for that node.
        Only expected to work on (text) FILE nodes, of course.
        """
        raise NotImplementedError

    def get_properties(self):
        """Returns the properties (meta-data) of the node, as a dictionary.

        The set of properties depends on the version control system.
        """
        raise NotImplementedError

    def get_content_length(self):
        """The length in bytes of the content.

        Will be `None` for a directory.
        """
        raise NotImplementedError
    content_length = property(lambda self: self.get_content_length())

    def get_content_type(self):
        """The MIME type corresponding to the content, if known.

        Will be `None` for a directory.
        """
        raise NotImplementedError
    content_type = property(lambda self: self.get_content_type())

    def get_name(self):
        return self.path.split('/')[-1]
    name = property(lambda self: self.get_name())

    def get_last_modified(self):
        raise NotImplementedError
    last_modified = property(lambda self: self.get_last_modified())

    isdir = property(lambda self: self.kind == Node.DIRECTORY)
    isfile = property(lambda self: self.kind == Node.FILE)

    def is_viewable(self, perm):
        """Return True if view permission is granted on the node."""
        return ('BROWSER_VIEW' if self.isdir else 'FILE_VIEW') \
               in perm(self.resource)

    can_view = is_viewable  # 0.12 compatibility


class Changeset(object):
    """Represents a set of changes committed at once in a repository."""

    ADD = 'add'
    COPY = 'copy'
    DELETE = 'delete'
    EDIT = 'edit'
    MOVE = 'move'

    # change types which can have diff associated to them
    DIFF_CHANGES = (EDIT, COPY, MOVE) # MERGE
    OTHER_CHANGES = (ADD, DELETE)
    ALL_CHANGES = DIFF_CHANGES + OTHER_CHANGES

    resource = property(lambda self: Resource('changeset', self.rev,
                                              parent=self.repos.resource))

    def __init__(self, repos, rev, message, author, date):
        self.repos = repos
        self.rev = rev
        self.message = message or ''
        self.author = author or ''
        self.date = date

    def get_properties(self):
        """Returns the properties (meta-data) of the node, as a dictionary.

        The set of properties depends on the version control system.

        Warning: this used to yield 4-elements tuple (besides `name` and
        `text`, there were `wikiflag` and `htmlclass` values).
        This is now replaced by the usage of IPropertyRenderer (see #1601).
        """
        return []

    def get_changes(self):
        """Generator that produces a tuple for every change in the changeset.

        The tuple will contain `(path, kind, change, base_path, base_rev)`,
        where `change` can be one of Changeset.ADD, Changeset.COPY,
        Changeset.DELETE, Changeset.EDIT or Changeset.MOVE,
        and `kind` is one of Node.FILE or Node.DIRECTORY.
        The `path` is the targeted path for the `change` (which is
        the ''deleted'' path  for a DELETE change).
        The `base_path` and `base_rev` are the source path and rev for the
        action (`None` and `-1` in the case of an ADD change).
        """
        raise NotImplementedError

    def get_branches(self):
        """Yield branches to which this changeset belong.
        Each branch is given as a pair `(name, head)`, where `name` is
        the branch name and `head` a flag set if the changeset is a head
        for this branch (i.e. if it has no children changeset).
        """
        return []

    def get_tags(self):
        """Yield tags associated with this changeset.

        .. versionadded :: 1.0
        """
        return []

    def is_viewable(self, perm):
        """Return True if view permission is granted on the changeset."""
        return 'CHANGESET_VIEW' in perm(self.resource)

    can_view = is_viewable  # 0.12 compatibility


# Note: Since Trac 0.12, Exception PermissionDenied class is gone,
# and class Authorizer is gone as well.
#
# Fine-grained permissions are now handled via normal permission policies.

########NEW FILE########
__FILENAME__ = cache
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import os

from trac.cache import cached
from trac.core import TracError
from trac.util.datefmt import from_utimestamp, to_utimestamp
from trac.util.translation import _
from trac.versioncontrol import Changeset, Node, Repository, NoSuchChangeset


_kindmap = {'D': Node.DIRECTORY, 'F': Node.FILE}
_actionmap = {'A': Changeset.ADD, 'C': Changeset.COPY,
              'D': Changeset.DELETE, 'E': Changeset.EDIT,
              'M': Changeset.MOVE}

def _invert_dict(d):
    return dict(zip(d.values(), d.keys()))

_inverted_kindmap = _invert_dict(_kindmap)
_inverted_actionmap = _invert_dict(_actionmap)

CACHE_REPOSITORY_DIR = 'repository_dir'
CACHE_YOUNGEST_REV = 'youngest_rev'

CACHE_METADATA_KEYS = (CACHE_REPOSITORY_DIR, CACHE_YOUNGEST_REV)


class CachedRepository(Repository):

    has_linear_changesets = False

    scope = property(lambda self: self.repos.scope)

    def __init__(self, env, repos, log):
        self.env = env
        self.repos = repos
        self._metadata_id = str(self.repos.id)
        Repository.__init__(self, repos.name, repos.params, log)

    def close(self):
        self.repos.close()

    def get_base(self):
        return self.repos.get_base()

    def get_quickjump_entries(self, rev):
        return self.repos.get_quickjump_entries(self.normalize_rev(rev))

    def get_path_url(self, path, rev):
        return self.repos.get_path_url(path, rev)

    def get_changeset(self, rev):
        return CachedChangeset(self, self.normalize_rev(rev), self.env)

    def get_changeset_uid(self, rev):
        return self.repos.get_changeset_uid(rev)

    def get_changesets(self, start, stop):
        for rev, in self.env.db_query("""
                SELECT rev FROM revision
                WHERE repos=%s AND time >= %s AND time < %s
                ORDER BY time DESC, rev DESC
                """, (self.id, to_utimestamp(start), to_utimestamp(stop))):
            try:
                yield self.get_changeset(rev)
            except NoSuchChangeset:
                pass # skip changesets currently being resync'ed

    def sync_changeset(self, rev):
        cset = self.repos.get_changeset(rev)
        srev = self.db_rev(cset.rev)
        old_cset = None

        with self.env.db_transaction as db:
            for time, author, message in db("""
                    SELECT time, author, message FROM revision
                    WHERE repos=%s AND rev=%s
                    """, (self.id, srev)):
                old_cset = Changeset(self.repos, cset.rev, message, author,
                                     from_utimestamp(time))
            if old_cset:
                db("""UPDATE revision SET time=%s, author=%s, message=%s
                      WHERE repos=%s AND rev=%s
                      """, (to_utimestamp(cset.date), cset.author,
                            cset.message, self.id, srev))
            else:
                self._insert_changeset(db, rev, cset)
        return old_cset

    @cached('_metadata_id')
    def metadata(self):
        """Retrieve data for the cached `metadata` attribute."""
        return dict(self.env.db_query("""
                SELECT name, value FROM repository
                WHERE id=%%s AND name IN (%s)
                """ % ','.join(['%s'] * len(CACHE_METADATA_KEYS)),
                (self.id,) + CACHE_METADATA_KEYS))

    def sync(self, feedback=None, clean=False):
        if clean:
            self.log.info("Cleaning cache")
            with self.env.db_transaction as db:
                db("DELETE FROM revision WHERE repos=%s",
                   (self.id,))
                db("DELETE FROM node_change WHERE repos=%s",
                   (self.id,))
                db.executemany("DELETE FROM repository WHERE id=%s AND name=%s",
                               [(self.id, k) for k in CACHE_METADATA_KEYS])
                db.executemany("""
                      INSERT INTO repository (id, name, value)
                      VALUES (%s, %s, %s)
                      """, [(self.id, k, '') for k in CACHE_METADATA_KEYS])
                del self.metadata

        metadata = self.metadata

        with self.env.db_transaction as db:
            invalidate = False

            # -- check that we're populating the cache for the correct
            #    repository
            repository_dir = metadata.get(CACHE_REPOSITORY_DIR)
            if repository_dir:
                # directory part of the repo name can vary on case insensitive
                # fs
                if os.path.normcase(repository_dir) \
                        != os.path.normcase(self.name):
                    self.log.info("'repository_dir' has changed from %r to %r",
                                  repository_dir, self.name)
                    raise TracError(_("The repository directory has changed, "
                                      "you should resynchronize the "
                                      "repository with: trac-admin $ENV "
                                      "repository resync '%(reponame)s'",
                                      reponame=self.reponame or '(default)'))
            elif repository_dir is None: #
                self.log.info('Storing initial "repository_dir": %s',
                              self.name)
                db("""INSERT INTO repository (id, name, value)
                      VALUES (%s, %s, %s)
                      """, (self.id, CACHE_REPOSITORY_DIR, self.name))
                invalidate = True
            else: # 'repository_dir' cleared by a resync
                self.log.info('Resetting "repository_dir": %s', self.name)
                db("UPDATE repository SET value=%s WHERE id=%s AND name=%s",
                   (self.name, self.id, CACHE_REPOSITORY_DIR))
                invalidate = True

            # -- insert a 'youngeset_rev' for the repository if necessary
            if metadata.get(CACHE_YOUNGEST_REV) is None:
                db("""INSERT INTO repository (id, name, value)
                      VALUES (%s, %s, %s)
                      """, (self.id, CACHE_YOUNGEST_REV, ''))
                invalidate = True

            if invalidate:
                del self.metadata

        # -- retrieve the youngest revision in the repository and the youngest
        #    revision cached so far
        self.repos.clear()
        repos_youngest = self.repos.youngest_rev
        youngest = metadata.get(CACHE_YOUNGEST_REV)

        # -- verify and normalize youngest revision
        if youngest:
            youngest = self.repos.normalize_rev(youngest)
            if not youngest:
                self.log.debug('normalize_rev failed (youngest_rev=%r)',
                               self.youngest_rev)
        else:
            self.log.debug('cache metadata undefined (youngest_rev=%r)',
                           self.youngest_rev)
            youngest = None

        # -- compare them and try to resync if different
        next_youngest = None
        if youngest != repos_youngest:
            self.log.info("repos rev [%s] != cached rev [%s]",
                          repos_youngest, youngest)
            if youngest:
                next_youngest = self.repos.next_rev(youngest)
            else:
                try:
                    next_youngest = self.repos.oldest_rev
                    # Ugly hack needed because doing that everytime in
                    # oldest_rev suffers from horrendeous performance (#5213)
                    if self.repos.scope != '/' and not \
                            self.repos.has_node('/', next_youngest):
                        next_youngest = self.repos.next_rev(next_youngest,
                                find_initial_rev=True)
                    next_youngest = self.repos.normalize_rev(next_youngest)
                except TracError:
                    # can't normalize oldest_rev: repository was empty
                    return

            if next_youngest is None: # nothing to cache yet
                return
            srev = self.db_rev(next_youngest)

            # 0. first check if there's no (obvious) resync in progress
            with self.env.db_query as db:
                for rev, in db(
                        "SELECT rev FROM revision WHERE repos=%s AND rev=%s",
                        (self.id, srev)):
                    # already there, but in progress, so keep ''previous''
                    # notion of 'youngest'
                    self.repos.clear(youngest_rev=youngest)
                    return

            # prepare for resyncing (there might still be a race
            # condition at this point)
            while next_youngest is not None:
                srev = self.db_rev(next_youngest)

                with self.env.db_transaction as db:
                    self.log.info("Trying to sync revision [%s]",
                                  next_youngest)
                    cset = self.repos.get_changeset(next_youngest)
                    try:
                        # steps 1. and 2.
                        self._insert_changeset(db, next_youngest, cset)
                    except Exception, e: # *another* 1.1. resync attempt won
                        self.log.warning('Revision %s already cached: %r',
                                         next_youngest, e)
                        # the other resync attempts is also
                        # potentially still in progress, so for our
                        # process/thread, keep ''previous'' notion of
                        # 'youngest'
                        self.repos.clear(youngest_rev=youngest)
                        # FIXME: This aborts a containing transaction
                        db.rollback()
                        return

                    # 3. update 'youngest_rev' metadata (minimize
                    # possibility of failures at point 0.)
                    db("""
                        UPDATE repository SET value=%s WHERE id=%s AND name=%s
                        """, (str(next_youngest), self.id, CACHE_YOUNGEST_REV))
                    del self.metadata

                # 4. iterate (1. should always succeed now)
                youngest = next_youngest
                next_youngest = self.repos.next_rev(next_youngest)

                # 5. provide some feedback
                if feedback:
                    feedback(youngest)

    def _insert_changeset(self, db, rev, cset):
        srev = self.db_rev(rev)
        # 1. Attempt to resync the 'revision' table.  In case of
        # concurrent syncs, only such insert into the `revision` table
        # will succeed, the others will fail and raise an exception.
        db("""
            INSERT INTO revision (repos,rev,time,author,message)
            VALUES (%s,%s,%s,%s,%s)
            """, (self.id, srev, to_utimestamp(cset.date),
                  cset.author, cset.message))
        # 2. now *only* one process was able to get there (i.e. there
        # *shouldn't* be any race condition here)
        for path, kind, action, bpath, brev in cset.get_changes():
            self.log.debug("Caching node change in [%s]: %r", rev,
                           (path, kind, action, bpath, brev))
            kind = _inverted_kindmap[kind]
            action = _inverted_actionmap[action]
            db("""
                INSERT INTO node_change
                    (repos,rev,path,node_type,change_type,base_path,
                     base_rev)
                VALUES (%s,%s,%s,%s,%s,%s,%s)
                """, (self.id, srev, path, kind, action, bpath, brev))

    def get_node(self, path, rev=None):
        return self.repos.get_node(path, self.normalize_rev(rev))

    def _get_node_revs(self, path, last=None, first=None):
        """Return the revisions affecting `path` between `first` and `last`
        revisions.
        """
        last = self.normalize_rev(last)
        slast = self.db_rev(last)
        node = self.get_node(path, last)    # Check node existence
        with self.env.db_query as db:
            if first is None:
                first = db("""
                    SELECT rev FROM node_change
                    WHERE repos=%s AND rev<=%s AND path=%s
                      AND change_type IN ('A', 'C', 'M')
                    ORDER BY rev DESC LIMIT 1
                    """, (self.id, slast, path))
                first = int(first[0][0]) if first else 0
            sfirst = self.db_rev(first)
            return [int(rev) for rev, in db("""
                    SELECT DISTINCT rev FROM node_change
                    WHERE repos=%%s AND rev>=%%s AND rev<=%%s
                      AND (path=%%s OR path %s)""" % db.like(),
                    (self.id, sfirst, slast, path,
                     db.like_escape(path + '/') + '%'))]

    def has_node(self, path, rev=None):
        return self.repos.has_node(path, self.normalize_rev(rev))

    def get_oldest_rev(self):
        return self.repos.oldest_rev

    def get_youngest_rev(self):
        return self.rev_db(self.metadata.get(CACHE_YOUNGEST_REV))

    def previous_rev(self, rev, path=''):
        if self.has_linear_changesets:
            return self._next_prev_rev('<', rev, path)
        else:
            return self.repos.previous_rev(self.normalize_rev(rev), path)

    def next_rev(self, rev, path=''):
        if self.has_linear_changesets:
            return self._next_prev_rev('>', rev, path)
        else:
            return self.repos.next_rev(self.normalize_rev(rev), path)

    def _next_prev_rev(self, direction, rev, path=''):
        srev = self.db_rev(rev)
        with self.env.db_query as db:
            # the changeset revs are sequence of ints:
            sql = "SELECT rev FROM node_change WHERE repos=%s AND " + \
                  "rev" + direction + "%s"
            args = [self.id, srev]

            if path:
                path = path.lstrip('/')
                # changes on path itself or its children
                sql += " AND (path=%s OR path " + db.like()
                args.extend((path, db.like_escape(path + '/') + '%'))
                # deletion of path ancestors
                components = path.lstrip('/').split('/')
                parents = ','.join(('%s',) * len(components))
                sql += " OR (path IN (" + parents + ") AND change_type='D'))"
                for i in range(1, len(components) + 1):
                    args.append('/'.join(components[:i]))

            sql += " ORDER BY rev" + (" DESC" if direction == '<' else "") \
                   + " LIMIT 1"

            for rev, in db(sql, args):
                return int(rev)

    def rev_older_than(self, rev1, rev2):
        return self.repos.rev_older_than(self.normalize_rev(rev1),
                                         self.normalize_rev(rev2))

    def get_path_history(self, path, rev=None, limit=None):
        return self.repos.get_path_history(path, self.normalize_rev(rev),
                                           limit)

    def normalize_path(self, path):
        return self.repos.normalize_path(path)

    def normalize_rev(self, rev):
        if rev is None or isinstance(rev, basestring) and \
               rev.lower() in ('', 'head', 'latest', 'youngest'):
            return self.rev_db(self.youngest_rev or 0)
        else:
            try:
                rev = int(rev)
                if rev <= self.youngest_rev:
                    return rev
            except (ValueError, TypeError):
                pass
            raise NoSuchChangeset(rev)

    def db_rev(self, rev):
        """Convert a revision to its representation in the database."""
        return str(rev)

    def rev_db(self, rev):
        """Convert a revision from its representation in the database."""
        return rev

    def get_changes(self, old_path, old_rev, new_path, new_rev,
                    ignore_ancestry=1):
        return self.repos.get_changes(old_path, self.normalize_rev(old_rev),
                                      new_path, self.normalize_rev(new_rev),
                                      ignore_ancestry)


class CachedChangeset(Changeset):

    def __init__(self, repos, rev, env):
        self.env = env
        for _date, author, message in self.env.db_query("""
                SELECT time, author, message FROM revision
                WHERE repos=%s AND rev=%s
                """, (repos.id, repos.db_rev(rev))):
            date = from_utimestamp(_date)
            Changeset.__init__(self, repos, repos.rev_db(rev), message, author,
                               date)
            break
        else:
            raise NoSuchChangeset(rev)

    def get_changes(self):
        for path, kind, change, base_path, base_rev in sorted(
                self.env.db_query("""
                SELECT path, node_type, change_type, base_path, base_rev
                FROM node_change WHERE repos=%s AND rev=%s
                ORDER BY path
                """, (self.repos.id, self.repos.db_rev(self.rev)))):
            kind = _kindmap[kind]
            change = _actionmap[change]
            yield path, kind, change, base_path, self.repos.rev_db(base_rev)

    def get_properties(self):
        return self.repos.repos.get_changeset(self.rev).get_properties()

########NEW FILE########
__FILENAME__ = diff
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004-2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

import difflib
import re

from genshi import Markup, escape

from trac.util.text import expandtabs

__all__ = ['diff_blocks', 'get_change_extent', 'get_diff_options',
           'unified_diff']


def get_change_extent(str1, str2):
    """Determines the extent of differences between two strings.

    Returns a pair containing the offset at which the changes start,
    and the negative offset at which the changes end.

    If the two strings have neither a common prefix nor a common
    suffix, ``(0, 0)`` is returned.
    """
    start = 0
    limit = min(len(str1), len(str2))
    while start < limit and str1[start] == str2[start]:
        start += 1
    end = -1
    limit = limit - start
    while -end <= limit and str1[end] == str2[end]:
        end -= 1
    return (start, end + 1)


def get_filtered_hunks(fromlines, tolines, context=None,
                       ignore_blank_lines=False, ignore_case=False,
                       ignore_space_changes=False):
    """Retrieve differences in the form of `difflib.SequenceMatcher`
    opcodes, grouped according to the ``context`` and ``ignore_*``
    parameters.

    :param fromlines: list of lines corresponding to the old content
    :param tolines: list of lines corresponding to the new content
    :param ignore_blank_lines: differences about empty lines only are ignored
    :param ignore_case: upper case / lower case only differences are ignored
    :param ignore_space_changes: differences in amount of spaces are ignored
    :param context: the number of "equal" lines kept for representing
                    the context of the change
    :return: generator of grouped `difflib.SequenceMatcher` opcodes

    If none of the ``ignore_*`` parameters is `True`, there's nothing
    to filter out the results will come straight from the
    SequenceMatcher.
    """
    hunks = get_hunks(fromlines, tolines, context)
    if ignore_space_changes or ignore_case or ignore_blank_lines:
        hunks = filter_ignorable_lines(hunks, fromlines, tolines, context,
                                       ignore_blank_lines, ignore_case,
                                       ignore_space_changes)
    return hunks


def get_hunks(fromlines, tolines, context=None):
    """Generator yielding grouped opcodes describing differences .

    See `get_filtered_hunks` for the parameter descriptions.
    """
    matcher = difflib.SequenceMatcher(None, fromlines, tolines)
    if context is None:
        return (hunk for hunk in [matcher.get_opcodes()])
    else:
        return matcher.get_grouped_opcodes(context)


def filter_ignorable_lines(hunks, fromlines, tolines, context,
                           ignore_blank_lines, ignore_case,
                           ignore_space_changes):
    """Detect line changes that should be ignored and emits them as
    tagged as "equal", possibly joined with the preceding and/or
    following "equal" block.

    See `get_filtered_hunks` for the parameter descriptions.
    """
    def is_ignorable(tag, fromlines, tolines):
        if tag == 'delete' and ignore_blank_lines:
            if ''.join(fromlines) == '':
                return True
        elif tag == 'insert' and ignore_blank_lines:
            if ''.join(tolines) == '':
                return True
        elif tag == 'replace' and (ignore_case or ignore_space_changes):
            if len(fromlines) != len(tolines):
                return False
            def f(str):
                if ignore_case:
                    str = str.lower()
                if ignore_space_changes:
                    str = ' '.join(str.split())
                return str
            for i in range(len(fromlines)):
                if f(fromlines[i]) != f(tolines[i]):
                    return False
            return True

    hunks = list(hunks)
    opcodes = []
    ignored_lines = False
    prev = None
    for hunk in hunks:
        for tag, i1, i2, j1, j2 in hunk:
            if tag == 'equal':
                if prev:
                    prev = (tag, prev[1], i2, prev[3], j2)
                else:
                    prev = (tag, i1, i2, j1, j2)
            else:
                if is_ignorable(tag, fromlines[i1:i2], tolines[j1:j2]):
                    ignored_lines = True
                    if prev:
                        prev = 'equal', prev[1], i2, prev[3], j2
                    else:
                        prev = 'equal', i1, i2, j1, j2
                    continue
                if prev:
                    opcodes.append(prev)
                opcodes.append((tag, i1, i2, j1, j2))
                prev = None
    if prev:
        opcodes.append(prev)

    if ignored_lines:
        if context is None:
            yield opcodes
        else:
            # we leave at most n lines with the tag 'equal' before and after
            # every change
            n = context
            nn = n + n

            group = []
            def all_equal():
                all(op[0] == 'equal' for op in group)
            for idx, (tag, i1, i2, j1, j2) in enumerate(opcodes):
                if idx == 0 and tag == 'equal': # Fixup leading unchanged block
                    i1, j1 = max(i1, i2 - n), max(j1, j2 - n)
                elif tag == 'equal' and i2 - i1 > nn:
                    group.append((tag, i1, min(i2, i1 + n), j1,
                                  min(j2, j1 + n)))
                    if not all_equal():
                        yield group
                    group = []
                    i1, j1 = max(i1, i2 - n), max(j1, j2 - n)
                group.append((tag, i1, i2, j1, j2))

            if group and not (len(group) == 1 and group[0][0] == 'equal'):
                if group[-1][0] == 'equal': # Fixup trailing unchanged block
                    tag, i1, i2, j1, j2 = group[-1]
                    group[-1] = tag, i1, min(i2, i1 + n), j1, min(j2, j1 + n)
                if not all_equal():
                    yield group
    else:
        for hunk in hunks:
            yield hunk


def hdf_diff(*args, **kwargs):
    """:deprecated: use `diff_blocks` (will be removed in 1.1.1)"""
    return diff_blocks(*args, **kwargs)

def diff_blocks(fromlines, tolines, context=None, tabwidth=8,
                ignore_blank_lines=0, ignore_case=0, ignore_space_changes=0):
    """Return an array that is adequate for adding to the data dictionary

    See `get_filtered_hunks` for the parameter descriptions.

    See also the diff_div.html template.
    """

    type_map = {'replace': 'mod', 'delete': 'rem', 'insert': 'add',
                'equal': 'unmod'}

    space_re = re.compile(' ( +)|^ ')
    def htmlify(match):
        div, mod = divmod(len(match.group(0)), 2)
        return div * '&nbsp; ' + mod * '&nbsp;'

    def markup_intraline_changes(opcodes):
        for tag, i1, i2, j1, j2 in opcodes:
            if tag == 'replace' and i2 - i1 == j2 - j1:
                for i in range(i2 - i1):
                    fromline, toline = fromlines[i1 + i], tolines[j1 + i]
                    (start, end) = get_change_extent(fromline, toline)
                    if start != 0 or end != 0:
                        last = end + len(fromline)
                        fromlines[i1 + i] = (
                            fromline[:start] + '\0' + fromline[start:last] +
                            '\1' + fromline[last:])
                        last = end+len(toline)
                        tolines[j1 + i] = (
                            toline[:start] + '\0' + toline[start:last] +
                            '\1' + toline[last:])
            yield tag, i1, i2, j1, j2

    changes = []
    for group in get_filtered_hunks(fromlines, tolines, context,
                                    ignore_blank_lines, ignore_case,
                                    ignore_space_changes):
        blocks = []
        last_tag = None
        for tag, i1, i2, j1, j2 in markup_intraline_changes(group):
            if tag != last_tag:
                blocks.append({'type': type_map[tag],
                               'base': {'offset': i1, 'lines': []},
                               'changed': {'offset': j1, 'lines': []}})
            if tag == 'equal':
                for line in fromlines[i1:i2]:
                    line = line.expandtabs(tabwidth)
                    line = space_re.sub(htmlify, escape(line, quotes=False))
                    blocks[-1]['base']['lines'].append(Markup(unicode(line)))
                for line in tolines[j1:j2]:
                    line = line.expandtabs(tabwidth)
                    line = space_re.sub(htmlify, escape(line, quotes=False))
                    blocks[-1]['changed']['lines'].append(Markup(unicode(line)))
            else:
                if tag in ('replace', 'delete'):
                    for line in fromlines[i1:i2]:
                        line = expandtabs(line, tabwidth, '\0\1')
                        line = escape(line, quotes=False)
                        line = '<del>'.join([space_re.sub(htmlify, seg)
                                             for seg in line.split('\0')])
                        line = line.replace('\1', '</del>')
                        blocks[-1]['base']['lines'].append(
                            Markup(unicode(line)))
                if tag in ('replace', 'insert'):
                    for line in tolines[j1:j2]:
                        line = expandtabs(line, tabwidth, '\0\1')
                        line = escape(line, quotes=False)
                        line = '<ins>'.join([space_re.sub(htmlify, seg)
                                             for seg in line.split('\0')])
                        line = line.replace('\1', '</ins>')
                        blocks[-1]['changed']['lines'].append(
                            Markup(unicode(line)))
        changes.append(blocks)
    return changes


def unified_diff(fromlines, tolines, context=None, ignore_blank_lines=0,
                 ignore_case=0, ignore_space_changes=0):
    """Generator producing lines corresponding to a textual diff.

    See `get_filtered_hunks` for the parameter descriptions.
    """
    for group in get_filtered_hunks(fromlines, tolines, context,
                                    ignore_blank_lines, ignore_case,
                                    ignore_space_changes):
        i1, i2, j1, j2 = group[0][1], group[-1][2], group[0][3], group[-1][4]
        if i1 == 0 and i2 == 0:
            i1, i2 = -1, -1 # support for 'A'dd changes
        yield '@@ -%d,%d +%d,%d @@' % (i1 + 1, i2 - i1, j1 + 1, j2 - j1)
        for tag, i1, i2, j1, j2 in group:
            if tag == 'equal':
                for line in fromlines[i1:i2]:
                    yield ' ' + line
            else:
                if tag in ('replace', 'delete'):
                    for line in fromlines[i1:i2]:
                        yield '-' + line
                if tag in ('replace', 'insert'):
                    for line in tolines[j1:j2]:
                        yield '+' + line


def get_diff_options(req):
    """Retrieve user preferences for diffs.

    :return: ``(style, options, data)`` triple.

      ``style``
        can be ``'inline'`` or ``'sidebyside'``,
      ``options``
        a sequence of "diff" flags,
      ``data``
        the style and options information represented as
        key/value pairs in dictionaries, for example::

          {'style': u'sidebyside',
           'options': {'contextall': 1, 'contextlines': 2,
                       'ignorecase': 0,  'ignoreblanklines': 0,
                       'ignorewhitespace': 1}}

    """
    options_data = {}
    data = {'options': options_data}

    def get_bool_option(name, default=0):
        pref = int(req.session.get('diff_' + name, default))
        arg = int(name in req.args)
        if 'update' in req.args and arg != pref:
            req.session.set('diff_' + name, arg, default)
        else:
            arg = pref
        return arg

    pref = req.session.get('diff_style', 'inline')
    style = req.args.get('style', pref)
    if 'update' in req.args and style != pref:
        req.session.set('diff_style', style, 'inline')
    data['style'] = style

    pref = int(req.session.get('diff_contextlines', 2))
    try:
        context = int(req.args.get('contextlines', pref))
    except ValueError:
        context = -1
    if 'update' in req.args and context != pref:
        req.session.set('diff_contextlines', context, 2)
    options_data['contextlines'] = context

    arg = int(req.args.get('contextall', 0))
    options_data['contextall'] = arg
    options = ['-U%d' % (-1 if arg else context)]

    arg = get_bool_option('ignoreblanklines')
    if arg:
        options.append('-B')
    options_data['ignoreblanklines'] = arg

    arg = get_bool_option('ignorecase')
    if arg:
        options.append('-i')
    options_data['ignorecase'] = arg

    arg = get_bool_option('ignorewhitespace')
    if arg:
        options.append('-b')
    options_data['ignorewhitespace'] = arg

    return (style, options, data)

########NEW FILE########
__FILENAME__ = svn_authz
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004 Francois Harvey <fharvey@securiweb.net>
# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Francois Harvey <fharvey@securiweb.net>
#         Matthew Good <trac@matt-good.net>

import os.path

from trac.config import Option, PathOption
from trac.core import *
from trac.perm import IPermissionPolicy
from trac.util import read_file
from trac.util.text import exception_to_unicode, to_unicode
from trac.util.translation import _
from trac.versioncontrol.api import RepositoryManager


def parent_iter(path):
    while 1:
        yield path
        if path == '/':
            return
        path = path[:-1]
        yield path
        idx = path.rfind('/')
        path = path[:idx + 1]


def join(*args):
    args = (arg.strip('/') for arg in args)
    return '/'.join(arg for arg in args if arg)


class ParseError(Exception):
    """Exception thrown for parse errors in authz files"""


def parse(authz, modules):
    """Parse a Subversion authorization file.

    Return a dict of modules, each containing a dict of paths, each containing
    a dict mapping users to permissions. Only modules contained in `modules`
    are retained.
    """
    groups = {}
    aliases = {}
    sections = {}
    section = None
    lineno = 0
    for line in authz.splitlines():
        lineno += 1
        line = to_unicode(line.strip())
        if not line or line.startswith(('#', ';')):
            continue
        if line.startswith('[') and line.endswith(']'):
            section = line[1:-1]
            continue
        if section is None:
            raise ParseError(_('Line %(lineno)d: Entry before first '
                               'section header', lineno=lineno))
        parts = line.split('=', 1)
        if len(parts) != 2:
            raise ParseError(_('Line %(lineno)d: Invalid entry',
                               lineno=lineno))
        name, value = parts
        name = name.strip()
        if section == 'groups':
            group = groups.setdefault(name, set())
            group.update(each.strip() for each in value.split(','))
        elif section == 'aliases':
            aliases[name] = value.strip()
        else:
            parts = section.split(':', 1)
            module, path = parts[0] if len(parts) > 1 else '', parts[-1]
            if module in modules:
                sections.setdefault((module, path), []).append((name, value))

    def resolve(subject, done):
        if subject.startswith('@'):
            done.add(subject)
            for members in groups[subject[1:]] - done:
                for each in resolve(members, done):
                    yield each
        elif subject.startswith('&'):
            yield aliases[subject[1:]]
        else:
            yield subject

    authz = {}
    for (module, path), items in sections.iteritems():
        section = authz.setdefault(module, {}).setdefault(path, {})
        for subject, perms in items:
            for user in resolve(subject, set()):
                section.setdefault(user, 'r' in perms)  # The first match wins

    return authz


class AuthzSourcePolicy(Component):
    """Permission policy for `source:` and `changeset:` resources using a
    Subversion authz file.

    `FILE_VIEW` and `BROWSER_VIEW` permissions are granted as specified in the
    authz file.

    `CHANGESET_VIEW` permission is granted for changesets where `FILE_VIEW` is
    granted on at least one modified file, as well as for empty changesets.
    """

    implements(IPermissionPolicy)

    authz_file = PathOption('trac', 'authz_file', '',
        """The path to the Subversion
        [http://svnbook.red-bean.com/en/1.5/svn.serverconfig.pathbasedauthz.html authorization (authz) file].
        To enable authz permission checking, the `AuthzSourcePolicy` permission
        policy must be added to `[trac] permission_policies`.
        """)

    authz_module_name = Option('trac', 'authz_module_name', '',
        """The module prefix used in the `authz_file` for the default
        repository. If left empty, the global section is used.
        """)

    _mtime = 0
    _authz = {}
    _users = set()

    _handled_perms = frozenset([(None, 'BROWSER_VIEW'),
                                (None, 'CHANGESET_VIEW'),
                                (None, 'FILE_VIEW'),
                                (None, 'LOG_VIEW'),
                                ('source', 'BROWSER_VIEW'),
                                ('source', 'FILE_VIEW'),
                                ('source', 'LOG_VIEW'),
                                ('changeset', 'CHANGESET_VIEW')])

    # IPermissionPolicy methods

    def check_permission(self, action, username, resource, perm):
        realm = resource.realm if resource else None
        if (realm, action) in self._handled_perms:
            authz, users = self._get_authz_info()
            if authz is None:
                return False

            if username == 'anonymous':
                usernames = ('$anonymous', '*')
            else:
                usernames = (username, '$authenticated', '*')
            if resource is None:
                return True if users & set(usernames) else None

            rm = RepositoryManager(self.env)
            try:
                repos = rm.get_repository(resource.parent.id)
            except TracError:
                return True # Allow error to be displayed in the repo index
            if repos is None:
                return True
            modules = [resource.parent.id or self.authz_module_name]
            if modules[0]:
                modules.append('')

            def check_path(path):
                path = '/' + join(repos.scope, path)
                if path != '/':
                    path += '/'

                # Allow access to parent directories of allowed resources
                if any(section.get(user) is True
                       for module in modules
                       for spath, section in authz.get(module, {}).iteritems()
                       if spath.startswith(path)
                       for user in usernames):
                    return True

                # Walk from resource up parent directories
                for spath in parent_iter(path):
                    for module in modules:
                        section = authz.get(module, {}).get(spath)
                        if section:
                            for user in usernames:
                                result = section.get(user)
                                if result is not None:
                                    return result

            if realm == 'source':
                return check_path(resource.id)

            elif realm == 'changeset':
                changes = list(repos.get_changeset(resource.id).get_changes())
                if not changes or any(check_path(change[0])
                                      for change in changes):
                    return True

    def _get_authz_info(self):
        try:
            mtime = os.path.getmtime(self.authz_file)
        except OSError, e:
            if self._authz is not None:
                self.log.error('Error accessing authz file: %s',
                               exception_to_unicode(e))
            self._mtime = mtime = 0
            self._authz = None
            self._users = set()
        if mtime > self._mtime:
            self._mtime = mtime
            rm = RepositoryManager(self.env)
            modules = set(repos.reponame
                          for repos in rm.get_real_repositories())
            if '' in modules and self.authz_module_name:
                modules.add(self.authz_module_name)
            modules.add('')
            self.log.info('Parsing authz file: %s' % self.authz_file)
            try:
                self._authz = parse(read_file(self.authz_file), modules)
                self._users = set(user for paths in self._authz.itervalues()
                                  for path in paths.itervalues()
                                  for user, result in path.iteritems()
                                  if result)
            except Exception, e:
                self._authz = None
                self._users = set()
                self.log.error('Error parsing authz file: %s',
                               exception_to_unicode(e))
        return self._authz, self._users

########NEW FILE########
__FILENAME__ = svn_fs
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from trac.util import import_namespace
import_namespace(globals(), 'tracopt.versioncontrol.svn.svn_fs')

# This module is a stub provided for backward compatibility. The svn_fs
# module has been moved to tracopt.versioncontrol.svn. Please update your
# code to use the new location.

########NEW FILE########
__FILENAME__ = svn_prop
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from trac.util import import_namespace
import_namespace(globals(), 'tracopt.versioncontrol.svn.svn_prop')

# This module is a stub provided for backward compatibility. The svn_prop
# module has been moved to tracopt.versioncontrol.svn. Please update your
# code to use the new location.

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007 CommProve, Inc. <eli.carter@commprove.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Eli Carter <eli.carter@commprove.com>

import unittest

from trac.resource import Resource, get_resource_description, get_resource_url
from trac.test import EnvironmentStub
from trac.versioncontrol.api import Repository


class ApiTestCase(unittest.TestCase):

    def setUp(self):
        self.repo_base = Repository('testrepo', {'name': 'testrepo', 'id': 1},
                                    None)

    def test_raise_NotImplementedError_close(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.close)

    def test_raise_NotImplementedError_get_changeset(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.get_changeset, 1)

    def test_raise_NotImplementedError_get_node(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.get_node, 'path')

    def test_raise_NotImplementedError_get_oldest_rev(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.get_oldest_rev)

    def test_raise_NotImplementedError_get_youngest_rev(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.get_youngest_rev)

    def test_raise_NotImplementedError_previous_rev(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.previous_rev, 1)

    def test_raise_NotImplementedError_next_rev(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.next_rev, 1)

    def test_raise_NotImplementedError_rev_older_than(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.rev_older_than, 1, 2)

    def test_raise_NotImplementedError_get_path_history(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.get_path_history, 'path')

    def test_raise_NotImplementedError_normalize_path(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.normalize_path, 'path')

    def test_raise_NotImplementedError_normalize_rev(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.normalize_rev, 1)

    def test_raise_NotImplementedError_get_changes(self):
        self.failUnlessRaises(NotImplementedError, self.repo_base.get_changes, 'path', 1, 'path', 2)


class ResourceManagerTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)

    def test_resource_changeset(self):
        res = Resource('changeset', '42')
        self.assertEqual('Changeset 42', get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/changeset/42',
                         get_resource_url(self.env, res, self.env.href))

        repo = Resource('repository', 'repo')
        res = Resource('changeset', '42', parent=repo)
        self.assertEqual('Changeset 42 in repo',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/changeset/42/repo',
                         get_resource_url(self.env, res, self.env.href))

    def test_resource_source(self):
        res = Resource('source', '/trunk/src')
        self.assertEqual('path /trunk/src',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/browser/trunk/src',
                         get_resource_url(self.env, res, self.env.href))

        repo = Resource('repository', 'repo')
        res = Resource('source', '/trunk/src', parent=repo)
        self.assertEqual('path /trunk/src in repo',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/browser/repo/trunk/src',
                         get_resource_url(self.env, res, self.env.href))

        repo = Resource('repository', 'repo')
        res = Resource('source', '/trunk/src', version=42, parent=repo)
        self.assertEqual('path /trunk/src@42 in repo',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/browser/repo/trunk/src?rev=42',
                         get_resource_url(self.env, res, self.env.href))


    def test_resource_repository(self):
        res = Resource('repository', 'testrepo')
        self.assertEqual('Repository testrepo',
                         get_resource_description(self.env, res))
        self.assertEqual('/trac.cgi/browser/testrepo',
                         get_resource_url(self.env, res, self.env.href))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(ApiTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ResourceManagerTestCase, 'test'))
    return suite


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = cache
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

from datetime import datetime

from trac.test import EnvironmentStub, Mock
from trac.util.datefmt import to_utimestamp, utc
from trac.versioncontrol import Repository, Changeset, Node, NoSuchChangeset
from trac.versioncontrol.cache import CachedRepository

import unittest


class CacheTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        self.log = self.env.log
        self.env.db_transaction.executemany(
            "INSERT INTO repository (id, name, value) VALUES (%s, %s, %s)",
            [(1, 'name', 'test-repos'),
             (1, 'youngest_rev', '')])

    def tearDown(self):
        self.env.reset_db()

    # Helpers

    def get_repos(self, get_changeset=None, youngest_rev=1):
        if get_changeset is None:
            def no_changeset(rev):
                raise NoSuchChangeset(rev)
            get_changeset = no_changeset
        return Mock(Repository, 'test-repos', {'name': 'test-repos', 'id': 1},
                    self.log,
                    get_changeset=get_changeset,
                    get_oldest_rev=lambda: 0,
                    get_youngest_rev=lambda: youngest_rev,
                    normalize_rev=lambda x: get_changeset(x).rev,
                    next_rev=(lambda x: int(x) < youngest_rev and x + 1 \
                              or None))

    def preset_cache(self, *args):
        """Each arg is a (rev tuple, changes list of tuples) pair."""
        with self.env.db_transaction as db:
            for rev, changes in args:
                db("""INSERT INTO revision (repos, rev, time, author, message)
                      VALUES (1,%s,%s,%s,%s)
                      """, rev)
                if changes:
                    db.executemany("""
                          INSERT INTO node_change (repos, rev, path, node_type,
                                                   change_type, base_path,
                                                   base_rev)
                          VALUES (1, %s, %s, %s, %s, %s, %s)
                          """, [(rev[0],) + change for change in changes])
            db("""UPDATE repository SET value=%s
                  WHERE id=1 AND name='youngest_rev'
                  """, (args[-1][0][0],))

    # Tests

    def test_initial_sync_with_empty_repos(self):
        repos = self.get_repos()
        cache = CachedRepository(self.env, repos, self.log)
        cache.sync()

        with self.env.db_query as db:
            self.assertEquals([], db(
                "SELECT rev, time, author, message FROM revision"))
            self.assertEquals(0, db("SELECT COUNT(*) FROM node_change")[0][0])

    def test_initial_sync(self):
        t1 = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        t2 = datetime(2002, 1, 1, 1, 1, 1, 0, utc)
        repos = self.get_repos(get_changeset=lambda x: changesets[int(x)],
                               youngest_rev=1)
        changes = [('trunk', Node.DIRECTORY, Changeset.ADD, None, None),
                   ('trunk/README', Node.FILE, Changeset.ADD, None, None)]
        changesets = [Mock(Changeset, repos, 0, '', '', t1,
                           get_changes=lambda: []),
                      Mock(Changeset, repos, 1, 'Import', 'joe', t2,
                           get_changes=lambda: iter(changes))]
        cache = CachedRepository(self.env, repos, self.log)
        cache.sync()

        with self.env.db_query as db:
            rows = db("SELECT rev, time, author, message FROM revision")
            self.assertEquals(len(rows), 2)
            self.assertEquals(('0', to_utimestamp(t1), '', ''), rows[0])
            self.assertEquals(('1', to_utimestamp(t2), 'joe', 'Import'),
                              rows[1])
            rows = db("""
                SELECT rev, path, node_type, change_type, base_path, base_rev
                FROM node_change""")
            self.assertEquals(len(rows), 2)
            self.assertEquals(('1', 'trunk', 'D', 'A', None, None), rows[0])
            self.assertEquals(('1', 'trunk/README', 'F', 'A', None, None),
                              rows[1])

    def test_update_sync(self):
        t1 = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        t2 = datetime(2002, 1, 1, 1, 1, 1, 0, utc)
        t3 = datetime(2003, 1, 1, 1, 1, 1, 0, utc)
        self.preset_cache(
            (('0', to_utimestamp(t1), '', ''), []),
            (('1', to_utimestamp(t2), 'joe', 'Import'),
             [('trunk', 'D', 'A', None, None),
              ('trunk/README', 'F', 'A', None, None)]),
            )
        repos = self.get_repos(get_changeset=lambda x: changesets[int(x)],
                               youngest_rev=2)
        changes = [('trunk/README', Node.FILE, Changeset.EDIT, 'trunk/README',
                    1)]
        changesets = [
            None,
            Mock(Changeset, repos, 1, '', '', t2, get_changes=lambda: []),
            Mock(Changeset, repos, 2, 'Update', 'joe', t3,
                 get_changes=lambda: iter(changes))
            ]
        cache = CachedRepository(self.env, repos, self.log)
        cache.sync()

        with self.env.db_query as db:
            self.assertEquals([(to_utimestamp(t3), 'joe', 'Update')],
                db("SELECT time, author, message FROM revision WHERE rev='2'"))
            self.assertEquals([('trunk/README', 'F', 'E', 'trunk/README',
                                '1')],
                    db("""SELECT path, node_type, change_type, base_path,
                                 base_rev
                          FROM node_change WHERE rev='2'"""))

    def test_clean_sync(self):
        t1 = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        t2 = datetime(2002, 1, 1, 1, 1, 1, 0, utc)
        t3 = datetime(2003, 1, 1, 1, 1, 1, 0, utc)
        self.preset_cache(
            (('0', to_utimestamp(t1), '', ''), []),
            (('1', to_utimestamp(t2), 'joe', 'Import'),
             [('trunk', 'D', 'A', None, None),
              ('trunk/README', 'F', 'A', None, None)]),
            )
        repos = self.get_repos(get_changeset=lambda x: changesets[int(x)],
                               youngest_rev=2)
        changes1 = [('trunk', Node.DIRECTORY, Changeset.ADD, None, None),
                    ('trunk/README', Node.FILE, Changeset.ADD, None, None)]
        changes2 = [('trunk/README', Node.FILE, Changeset.EDIT, 'trunk/README',
                     1)]
        changesets = [
            Mock(Changeset, repos, 0, '**empty**', 'joe', t1,
                 get_changes=lambda: []),
            Mock(Changeset, repos, 1, 'Initial Import', 'joe', t2,
                 get_changes=lambda: iter(changes1)),
            Mock(Changeset, repos, 2, 'Update', 'joe', t3,
                 get_changes=lambda: iter(changes2))
            ]
        cache = CachedRepository(self.env, repos, self.log)
        cache.sync(clean=True)

        rows = self.env.db_query("""
            SELECT time, author, message FROM revision ORDER BY rev
            """)
        self.assertEquals(3, len(rows))
        self.assertEquals((to_utimestamp(t1), 'joe', '**empty**'), rows[0])
        self.assertEquals((to_utimestamp(t2), 'joe', 'Initial Import'),
                          rows[1])
        self.assertEquals((to_utimestamp(t3), 'joe', 'Update'), rows[2])

        rows = self.env.db_query("""
            SELECT rev, path, node_type, change_type, base_path, base_rev
            FROM node_change ORDER BY rev, path""")
        self.assertEquals(3, len(rows))
        self.assertEquals(('1', 'trunk', 'D', 'A', None, None), rows[0])
        self.assertEquals(('1', 'trunk/README', 'F', 'A', None, None), rows[1])
        self.assertEquals(('2', 'trunk/README', 'F', 'E', 'trunk/README', '1'),
                          rows[2])

    def test_sync_changeset(self):
        t1 = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        t2 = datetime(2002, 1, 1, 1, 1, 1, 0, utc)
        self.preset_cache(
            (('0', to_utimestamp(t1), '', ''), []),
            (('1', to_utimestamp(t2), 'joe', 'Import'),
             [('trunk', 'D', 'A', None, None),
              ('trunk/README', 'F', 'A', None, None)]),
            )
        repos = self.get_repos(get_changeset=lambda x: changesets[int(x)],
                               youngest_rev=1)
        changes1 = [('trunk', Node.DIRECTORY, Changeset.ADD, None, None),
                    ('trunk/README', Node.FILE, Changeset.ADD, None, None)]
        changesets = [
            Mock(Changeset, repos, 0, '**empty**', 'joe', t1,
                 get_changes=lambda: []),
            Mock(Changeset, repos, 1, 'Initial Import', 'joe', t2,
                 get_changes=lambda: iter(changes1)),
            ]
        cache = CachedRepository(self.env, repos, self.log)
        cache.sync_changeset(0)


        rows = self.env.db_query(
                "SELECT time, author, message FROM revision ORDER BY rev")
        self.assertEquals(2, len(rows))
        self.assertEquals((to_utimestamp(t1), 'joe', '**empty**'), rows[0])
        self.assertEquals((to_utimestamp(t2), 'joe', 'Import'), rows[1])

    def test_sync_changeset_if_not_exists(self):
        t = [
            datetime(2001, 1, 1, 1, 1, 1, 0, utc), # r0
            datetime(2002, 1, 1, 1, 1, 1, 0, utc), # r1
            datetime(2003, 1, 1, 1, 1, 1, 0, utc), # r2
            datetime(2004, 1, 1, 1, 1, 1, 0, utc), # r3
        ]
        self.preset_cache(
            (('0', to_utimestamp(t[0]), 'joe', '**empty**'), []),
            (('1', to_utimestamp(t[1]), 'joe', 'Import'),
             [('trunk', 'D', 'A', None, None),
              ('trunk/README', 'F', 'A', None, None)]),
            # not exists r2
            (('3', to_utimestamp(t[3]), 'joe', 'Add COPYING'),
             [('trunk/COPYING', 'F', 'A', None, None)]),
            )
        repos = self.get_repos(get_changeset=lambda x: changesets[int(x)],
                               youngest_rev=3)
        changes = [
            None,                                                       # r0
            [('trunk', Node.DIRECTORY, Changeset.ADD, None, None),      # r1
             ('trunk/README', Node.FILE, Changeset.ADD, None, None)],
            [('branches', Node.DIRECTORY, Changeset.ADD, None, None),   # r2
             ('tags', Node.DIRECTORY, Changeset.ADD, None, None)],
            [('trunk/COPYING', Node.FILE, Changeset.ADD, None, None)],  # r3
        ]
        changesets = [
            Mock(Changeset, repos, 0, '**empty**', 'joe', t[0],
                 get_changes=lambda: []),
            Mock(Changeset, repos, 1, 'Initial Import', 'joe', t[1],
                 get_changes=lambda: iter(changes[1])),
            Mock(Changeset, repos, 2, 'Created directories', 'john', t[2],
                 get_changes=lambda: iter(changes[2])),
            Mock(Changeset, repos, 3, 'Add COPYING', 'joe', t[3],
                 get_changes=lambda: iter(changes[3])),
            ]
        cache = CachedRepository(self.env, repos, self.log)
        self.assertRaises(NoSuchChangeset, cache.get_changeset, 2)
        cache.sync()
        self.assertRaises(NoSuchChangeset, cache.get_changeset, 2)

        self.assertEqual(None, cache.sync_changeset(2))
        cset = cache.get_changeset(2)
        self.assertEqual('john', cset.author)
        self.assertEqual('Created directories', cset.message)
        self.assertEqual(t[2], cset.date)
        cset_changes = cset.get_changes()
        self.assertEqual(('branches', Node.DIRECTORY, Changeset.ADD, None,
                          None),
                         cset_changes.next())
        self.assertEqual(('tags', Node.DIRECTORY, Changeset.ADD, None, None),
                         cset_changes.next())
        self.assertRaises(StopIteration, cset_changes.next)

        rows = self.env.db_query(
                "SELECT time,author,message FROM revision ORDER BY rev")
        self.assertEquals(4, len(rows))
        self.assertEquals((to_utimestamp(t[0]), 'joe', '**empty**'), rows[0])
        self.assertEquals((to_utimestamp(t[1]), 'joe', 'Import'), rows[1])
        self.assertEquals((to_utimestamp(t[2]), 'john', 'Created directories'),
                          rows[2])
        self.assertEquals((to_utimestamp(t[3]), 'joe', 'Add COPYING'), rows[3])

    def test_get_changes(self):
        t1 = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        t2 = datetime(2002, 1, 1, 1, 1, 1, 0, utc)
        self.preset_cache(
            (('0', to_utimestamp(t1), '', ''), []),
            (('1', to_utimestamp(t2), 'joe', 'Import'),
             [('trunk', 'D', 'A', None, None),
              ('trunk/RDME', 'F', 'A', None, None)]),
            )
        repos = self.get_repos()
        cache = CachedRepository(self.env, repos, self.log)
        self.assertEqual('1', cache.youngest_rev)
        changeset = cache.get_changeset(1)
        self.assertEqual('joe', changeset.author)
        self.assertEqual('Import', changeset.message)
        self.assertEqual(t2, changeset.date)
        changes = changeset.get_changes()
        self.assertEqual(('trunk', Node.DIRECTORY, Changeset.ADD, None, None),
                         changes.next())
        self.assertEqual(('trunk/RDME', Node.FILE, Changeset.ADD, None, None),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)


def suite():
    return unittest.makeSuite(CacheTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = diff
from trac.versioncontrol import diff

import unittest

def get_opcodes(*args, **kwargs):
    for hunk in diff.get_filtered_hunks(*args, **kwargs):
        for opcode in hunk:
            yield opcode

class DiffTestCase(unittest.TestCase):

    def testget_change_extent(self):
        self.assertEqual((3, 0), diff.get_change_extent('xxx', 'xxx'))
        self.assertEqual((0, 0), diff.get_change_extent('', 'xxx'))
        self.assertEqual((0, 0), diff.get_change_extent('xxx', ''))
        self.assertEqual((0, 0), diff.get_change_extent('xxx', 'yyy'))
        self.assertEqual((1, -1), diff.get_change_extent('xxx', 'xyx'))
        self.assertEqual((1, -1), diff.get_change_extent('xxx', 'xyyyx'))
        self.assertEqual((1, 0), diff.get_change_extent('xy', 'xzz'))
        self.assertEqual((1, -1), diff.get_change_extent('xyx', 'xzzx'))
        self.assertEqual((1, -1), diff.get_change_extent('xzzx', 'xyx'))

    def test_insert_blank_line(self):
        opcodes = get_opcodes(['A', 'B'], ['A', 'B', ''], ignore_blank_lines=0)
        self.assertEqual(('equal', 0, 2, 0, 2), opcodes.next())
        self.assertEqual(('insert', 2, 2, 2, 3), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A', 'B'], ['A', 'B', ''], ignore_blank_lines=1)
        self.assertEqual(('equal', 0, 2, 0, 3), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A'], ['A', 'B', ''], ignore_blank_lines=0)
        self.assertEqual(('equal', 0, 1, 0, 1), opcodes.next())
        self.assertEqual(('insert', 1, 1, 1, 3), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A'], ['A', 'B', ''], ignore_blank_lines=1)
        self.assertEqual(('equal', 0, 1, 0, 1), opcodes.next())
        self.assertEqual(('insert', 1, 1, 1, 3), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

    def test_delete_blank_line(self):
        opcodes = get_opcodes(['A', 'B', ''], ['A', 'B'], ignore_blank_lines=0)
        self.assertEqual(('equal', 0, 2, 0, 2), opcodes.next())
        self.assertEqual(('delete', 2, 3, 2, 2), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A', 'B', ''], ['A', 'B'], ignore_blank_lines=1)
        self.assertEqual(('equal', 0, 3, 0, 2), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A', 'B', ''], ['A'], ignore_blank_lines=0)
        self.assertEqual(('equal', 0, 1, 0, 1), opcodes.next())
        self.assertEqual(('delete', 1, 3, 1, 1), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A', 'B', ''], ['A'], ignore_blank_lines=1)
        self.assertEqual(('equal', 0, 1, 0, 1), opcodes.next())
        self.assertEqual(('delete', 1, 3, 1, 1), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

    def test_space_changes(self):
        opcodes = get_opcodes(['A', 'B b'], ['A', 'B  b'],
                              ignore_space_changes=0)
        self.assertEqual(('equal', 0, 1, 0, 1), opcodes.next())
        self.assertEqual(('replace', 1, 2, 1, 2), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A', 'B b'], ['A', 'B  b'],
                              ignore_space_changes=1)
        self.assertEqual(('equal', 0, 2, 0, 2), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

    def test_case_changes(self):
        opcodes = get_opcodes(['A', 'B b'], ['A', 'B B'], ignore_case=0)
        self.assertEqual(('equal', 0, 1, 0, 1), opcodes.next())
        self.assertEqual(('replace', 1, 2, 1, 2), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A', 'B b'], ['A', 'B B'], ignore_case=1)
        self.assertEqual(('equal', 0, 2, 0, 2), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

    def test_space_and_case_changes(self):
        opcodes = get_opcodes(['A', 'B b'], ['A', 'B  B'],
                              ignore_case=0, ignore_space_changes=0)
        self.assertEqual(('equal', 0, 1, 0, 1), opcodes.next())
        self.assertEqual(('replace', 1, 2, 1, 2), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

        opcodes = get_opcodes(['A', 'B b'], ['A', 'B  B'],
                              ignore_case=1, ignore_space_changes=1)
        self.assertEqual(('equal', 0, 2, 0, 2), opcodes.next())
        self.assertRaises(StopIteration, opcodes.next)

    def test_grouped_opcodes_context1(self):
        groups = diff.get_filtered_hunks(
            ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'],
            ['A', 'B', 'C', 'd', 'e', 'f', 'G', 'H'], context=1)
        group = groups.next()
        self.assertRaises(StopIteration, groups.next)
        self.assertEqual(('equal', 2, 3, 2, 3), group[0])
        self.assertEqual(('replace', 3, 6, 3, 6), group[1])
        self.assertEqual(('equal', 6, 7, 6, 7), group[2])

    def test_grouped_opcodes_context1_ignorecase(self):
        old = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']
        new = ['X', 'B', 'C', 'd', 'e', 'f', 'G', 'Y']
        groups = diff.get_filtered_hunks(old, new, context=1, ignore_case=1)
        group = groups.next()
        self.assertEqual([('replace', 0, 1, 0, 1), ('equal', 1, 2, 1, 2)],
                         group)
        group = groups.next()
        self.assertRaises(StopIteration, groups.next)
        self.assertEqual([('equal', 6, 7, 6, 7), ('replace', 7, 8, 7, 8)],
                         group)

    def test_grouped_opcodes_full_context(self):
        old = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']
        new = ['X', 'B', 'C', 'd', 'e', 'f', 'G', 'Y']
        groups = diff.get_filtered_hunks(old, new, context=None)
        group = groups.next()
        self.assertRaises(StopIteration, groups.next)
        self.assertEqual([
                ('replace', 0, 1, 0, 1),
                ('equal', 1, 3, 1, 3),
                ('replace', 3, 6, 3, 6),
                ('equal', 6, 7, 6, 7),
                ('replace', 7, 8, 7, 8),
                ], group)

        groups = diff.get_filtered_hunks(old, new, context=None, ignore_case=1)
        group = groups.next()
        self.assertRaises(StopIteration, groups.next)
        self.assertEqual([
                ('replace', 0, 1, 0, 1),
                ('equal', 1, 7, 1, 7),
                ('replace', 7, 8, 7, 8),
                ], group)

    def test_grouped_opcodes_insert_blank_line_at_top(self):
        """
        Regression test for #2090. Make sure that the equal block following an
        insert at the top of a file is correct.
        """
        groups = diff.get_filtered_hunks(['B', 'C', 'D', 'E', 'F', 'G'],
                                         ['A', 'B', 'C', 'D', 'E', 'F', 'G'],
                                         context=3)
        self.assertEqual([('insert', 0, 0, 0, 1), ('equal', 0, 3, 1, 4)],
                         groups.next())
        self.assertRaises(StopIteration, groups.next)

    def test_unified_diff_no_context(self):
        diff_lines = list(diff.unified_diff(['a'], ['b']))
        self.assertEqual(['@@ -1,1 +1,1 @@', '-a', '+b'], diff_lines)

    def test_quotes_not_marked_up(self):
        """Make sure that the escape calls leave quotes along, we don't need
        to escape them."""
        changes = diff.diff_blocks(['ab'], ['a"b'])
        self.assertEquals(len(changes), 1)
        blocks = changes[0]
        self.assertEquals(len(blocks), 1)
        block = blocks[0]
        self.assertEquals(block['type'], 'mod')
        self.assertEquals(str(block['base']['lines'][0]), 'a<del></del>b')
        self.assertEquals(str(block['changed']['lines'][0]), 'a<ins>"</ins>b')

    def test_whitespace_marked_up1(self):
        """Regression test for #5795"""
        changes = diff.diff_blocks(['*a'], [' *a'])
        block = changes[0][0]
        self.assertEquals(block['type'], 'mod')
        self.assertEquals(str(block['base']['lines'][0]), '<del></del>*a')
        self.assertEquals(str(block['changed']['lines'][0]),
                          '<ins>&nbsp;</ins>*a')

    def test_whitespace_marked_up2(self):
        """Related to #5795"""
        changes = diff.diff_blocks(['   a'], ['   b'])
        block = changes[0][0]
        self.assertEquals(block['type'], 'mod')
        self.assertEquals(str(block['base']['lines'][0]),
                          '&nbsp; &nbsp;<del>a</del>')
        self.assertEquals(str(block['changed']['lines'][0]),
                          '&nbsp; &nbsp;<ins>b</ins>')

    def test_whitespace_marked_up3(self):
        """Related to #5795"""
        changes = diff.diff_blocks(['a   '], ['b   '])
        block = changes[0][0]
        self.assertEquals(block['type'], 'mod')
        self.assertEquals(str(block['base']['lines'][0]),
                          '<del>a</del>&nbsp; &nbsp;')
        self.assertEquals(str(block['changed']['lines'][0]),
                          '<ins>b</ins>&nbsp; &nbsp;')

    def test_expandtabs_works_right(self):
        """Regression test for #4557"""
        changes = diff.diff_blocks(['aa\tb'], ['aaxb'])
        block = changes[0][0]
        self.assertEquals(block['type'], 'mod')
        self.assertEquals(str(block['base']['lines'][0]),
                          'aa<del>&nbsp; &nbsp; &nbsp; </del>b')
        self.assertEquals(str(block['changed']['lines'][0]),
                          'aa<ins>x</ins>b')

def suite():
    return unittest.makeSuite(DiffTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = functional
#!/usr/bin/python
from trac.tests.functional import *


class TestEmptySvnRepo(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Check empty repository"""
        browser_url = self._tester.url + '/browser'
        tc.go(browser_url)
        tc.url(browser_url)
        # This tests the current behavior; I'm not sure it's the best
        # behavior.
        tc.follow('Last Change')
        tc.find('Error: No such changeset')
        tc.back()
        tc.follow('Revision Log')
        tc.notfind('Error: Nonexistent path')


class TestRepoCreation(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Create a directory tree in the repository"""
        # This should probably use the svn bindings...
        directories = []
        for component in ('component1', 'component2'):
            directories.append(component)
            for subdir in ('branches', 'tags', 'trunk'):
                directories.append('/'.join([component, subdir]))
        commit_message = 'Create component trees.'
        self._testenv.svn_mkdir(directories, commit_message)

        browser_url = self._tester.url + '/browser'
        tc.go(browser_url)
        tc.url(browser_url)
        tc.find('component1')
        tc.find('component2')
        tc.follow('Last Change')
        tc.url(self._tester.url + '/changeset/1/')
        tc.find(commit_message)
        for directory in directories:
            tc.find(directory)
        tc.back()
        tc.follow('Revision Log')
        # (Note that our commit log message is short enough to avoid
        # truncation.)
        tc.find(commit_message)
        tc.follow('Timeline')
        # (Note that our commit log message is short enough to avoid
        # truncation.)
        tc.find(commit_message)
        tc.formvalue('prefs', 'ticket', False)
        tc.formvalue('prefs', 'milestone', False)
        tc.formvalue('prefs', 'wiki', False)
        tc.submit()
        tc.find('by.*admin')
        # (Note that our commit log message is short enough to avoid
        # truncation.)
        tc.find(commit_message)


class TestRepoBrowse(FunctionalTwillTestCaseSetup):
    # TODO: move this out to a subversion-specific testing module
    def runTest(self):
        """Add a file to the repository and verify it is in the browser"""
        # Add a file to Subversion
        tempfilename = random_word()
        fulltempfilename = 'component1/trunk/' + tempfilename
        revision = self._testenv.svn_add(fulltempfilename, random_page())

        # Verify that it appears in the browser view:
        browser_url = self._tester.url + '/browser'
        tc.go(browser_url)
        tc.url(browser_url)
        tc.find('component1')
        tc.follow('component1')
        tc.follow('trunk')
        tc.follow(tempfilename)
        self._tester.quickjump('[%s]' % revision)
        tc.find('Changeset %s' % revision)
        tc.find('admin')
        tc.find('Add %s' % fulltempfilename)
        tc.find('1 added')
        tc.follow('Timeline')
        tc.find('Add %s' % fulltempfilename)


class TestNewFileLog(FunctionalTwillTestCaseSetup):
    # TODO: move this out to a subversion-specific testing module
    def runTest(self):
        """Verify browser log for a new file"""
        tempfilename = random_word() + '_new.txt'
        fulltempfilename = 'component1/trunk/' + tempfilename
        revision = self._testenv.svn_add(fulltempfilename, '')
        tc.go(self._tester.url + '/log/' + fulltempfilename)
        tc.find('@%d' % revision)
        tc.find('Add %s' % fulltempfilename)


class RegressionTestTicket5819(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/5819
        Events with identical dates are reversed in timeline
        """
        # Multiple events very close together
        files = ['a', 'b', 'c', 'd']
        for filename in files:
            # We do a mkdir because it's easy.
            self._testenv.svn_mkdir(['component1/trunk/' + filename],
                     'Create component1/%s' % filename)
        self._tester.go_to_timeline()
        # They are supposed to show up in d, c, b, a order.
        components = '.*'.join(['Create component1/%s' % f for f in
                                      reversed(files)])
        tc.find(components, 's')


class RegressionTestRev5877(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of the source browser fix in r5877"""
        tc.go(self._tester.url + '/browser?range_min_secs=1')
        tc.notfind(internal_error)


def functionalSuite(suite=None):
    if not suite:
        import trac.tests.functional.testcases
        suite = trac.tests.functional.testcases.functionalSuite()
    if has_svn:
        suite.addTest(TestEmptySvnRepo())
        suite.addTest(TestRepoCreation())
        suite.addTest(TestRepoBrowse())
        suite.addTest(TestNewFileLog())
        suite.addTest(RegressionTestTicket5819())
        suite.addTest(RegressionTestRev5877())
    else:
        print "SKIP: versioncontrol/tests/functional.py (no svn bindings)"

    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = svn_authz
# -*- coding: utf-8 -*-
#
# Copyright (C) 2010 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os.path
import tempfile
import unittest

from trac.resource import Resource
from trac.test import EnvironmentStub, Mock
from trac.util import create_file
from trac.versioncontrol.api import RepositoryManager
from trac.versioncontrol.svn_authz import AuthzSourcePolicy, ParseError, \
                                          parse


class AuthzParserTestCase(unittest.TestCase):

    def test_parse_file(self):
        authz = parse("""\
[groups]
developers = foo, bar
users = @developers, &baz

[aliases]
baz = CN=Hrld Hacker,OU=Enginers,DC=red-bean,DC=com

# Applies to all repositories
[/]
* = r

[/trunk]
@developers = rw
&baz =
@users = r

[/branches]
bar = rw

; Applies only to module
[module:/trunk]
foo = rw
&baz = r

; Unicode module names
[module:/c/rsum]
bar = rw

; Unused module, not parsed
[unused:/some/path]
foo = r
""", set(['', 'module']))
        self.assertEqual({
            '': {
                '/': {
                    '*': True,
                },
                '/trunk': {
                    'foo': True,
                    'bar': True,
                    u'CN=Hrld Hacker,OU=Enginers,DC=red-bean,DC=com': False,
                },
                '/branches': {
                    'bar': True,
                },
            },
            'module': {
                '/trunk': {
                    'foo': True,
                    u'CN=Hrld Hacker,OU=Enginers,DC=red-bean,DC=com': True,
                },
                u'/c/rsum': {
                    'bar': True,
                },
            },
        }, authz)

    def test_parse_errors(self):
        self.assertRaises(ParseError, parse, """\
user = r

[module:/trunk]
user = r
""", set(['', 'module']))
        self.assertRaises(ParseError, parse, """\
[module:/trunk]
user
""", set(['', 'module']))


class AuthzSourcePolicyTestCase(unittest.TestCase):

    def setUp(self):
        tmpdir = os.path.realpath(tempfile.gettempdir())
        self.authz = os.path.join(tmpdir, 'trac-authz')
        create_file(self.authz, """\
[groups]
group1 = user
group2 = @group1

cycle1 = @cycle2
cycle2 = @cycle3
cycle3 = @cycle1, user

alias1 = &jekyll
alias2 = @alias1

[aliases]
jekyll = Mr Hyde

# Read / write permissions
[/readonly]
user = r
[/writeonly]
user = w
[/readwrite]
user = rw
[/empty]
user =

# Trailing slashes
[/trailing_a]
user = r
[/trailing_b/]
user = r

# Sub-paths
[/sub/path]
user = r

# Module usage
[module:/module_a]
user = r
[other:/module_b]
user = r
[/module_c]
user = r
[module:/module_d]
user =
[/module_d]
user = r

# Wildcards
[/wildcard]
* = r

# Special tokens
[/special/anonymous]
$anonymous = r
[/special/authenticated]
$authenticated = r

# Groups
[/groups_a]
@group1 = r
[/groups_b]
@group2 = r
[/cyclic]
@cycle1 = r

# Precedence
[module:/precedence_a]
user =
[/precedence_a]
user = r
[/precedence_b]
user = r
[/precedence_b/sub]
user =
[/precedence_b/sub/test]
user = r
[/precedence_c]
user =
@group1 = r
[/precedence_d]
@group1 = r
user =

# Aliases
[/aliases_a]
&jekyll = r
[/aliases_b]
@alias2 = r

# Scoped repository
[scoped:/scope/dir1]
joe = r
[scoped:/scope/dir2]
jane = r
""")
        self.env = EnvironmentStub(enable=[AuthzSourcePolicy])
        self.env.config.set('trac', 'authz_file', self.authz)
        self.policy = AuthzSourcePolicy(self.env)

        # Monkey-subclass RepositoryManager to serve mock repositories
        rm = RepositoryManager(self.env)

        class TestRepositoryManager(rm.__class__):
            def get_real_repositories(self):
                return set([Mock(reponame='module'),
                            Mock(reponame='other'),
                            Mock(reponame='scoped')])

            def get_repository(self, reponame):
                if reponame == 'scoped':
                    def get_changeset(rev):
                        if rev == 123:
                            def get_changes():
                                yield ('/dir1/file',)
                        elif rev == 456:
                            def get_changes():
                                yield ('/dir2/file',)
                        else:
                            def get_changes():
                                return iter([])
                        return Mock(get_changes=get_changes)
                    return Mock(scope='/scope',
                                get_changeset=get_changeset)
                return Mock(scope='/')

        rm.__class__ = TestRepositoryManager

    def tearDown(self):
        self.env.reset_db()
        os.remove(self.authz)

    def assertPathPerm(self, result, user, reponame=None, path=None):
        """Assert that `user` is granted access `result` to `path` within
        the repository `reponame`.
        """
        resource = None
        if reponame is not None:
            resource = Resource('source', path,
                                parent=Resource('repository', reponame))
        for perm in ('BROWSER_VIEW', 'FILE_VIEW', 'LOG_VIEW'):
            check = self.policy.check_permission(perm, user, resource, None)
            self.assertEqual(result, check)

    def assertRevPerm(self, result, user, reponame=None, rev=None):
        """Assert that `user` is granted access `result` to `rev` within
        the repository `reponame`.
        """
        resource = None
        if reponame is not None:
            resource = Resource('changeset', rev,
                                parent=Resource('repository', reponame))
        check = self.policy.check_permission('CHANGESET_VIEW', user, resource,
                                             None)
        self.assertEqual(result, check)

    def test_coarse_permissions(self):
        # Granted to all due to wildcard
        self.assertPathPerm(True, 'unknown')
        self.assertPathPerm(True, 'joe')
        self.assertRevPerm(True, 'unknown')
        self.assertRevPerm(True, 'joe')
        # Granted if at least one fine permission is granted
        self.policy._mtime = 0
        create_file(self.authz, """\
[/somepath]
joe = r
denied =
[module:/otherpath]
jane = r
$anonymous = r
[inactive:/not-in-this-instance]
unknown = r
""")
        self.assertPathPerm(None, 'unknown')
        self.assertRevPerm(None, 'unknown')
        self.assertPathPerm(None, 'denied')
        self.assertRevPerm(None, 'denied')
        self.assertPathPerm(True, 'joe')
        self.assertRevPerm(True, 'joe')
        self.assertPathPerm(True, 'jane')
        self.assertRevPerm(True, 'jane')
        self.assertPathPerm(True, 'anonymous')
        self.assertRevPerm(True, 'anonymous')

    def test_default_permission(self):
        # By default, permissions are undecided
        self.assertPathPerm(None, 'joe', '', '/not_defined')
        self.assertPathPerm(None, 'jane', 'repo', '/not/defined/either')

    def test_read_write(self):
        # Allow 'r' and 'rw' entries, deny 'w' and empty entries
        self.assertPathPerm(True, 'user', '', '/readonly')
        self.assertPathPerm(True, 'user', '', '/readwrite')
        self.assertPathPerm(False, 'user', '', '/writeonly')
        self.assertPathPerm(False, 'user', '', '/empty')

    def test_trailing_slashes(self):
        # Combinations of trailing slashes in the file and in the path
        self.assertPathPerm(True, 'user', '', '/trailing_a')
        self.assertPathPerm(True, 'user', '', '/trailing_a/')
        self.assertPathPerm(True, 'user', '', '/trailing_b')
        self.assertPathPerm(True, 'user', '', '/trailing_b/')

    def test_sub_path(self):
        # Permissions are inherited from containing directories
        self.assertPathPerm(True, 'user', '', '/sub/path')
        self.assertPathPerm(True, 'user', '', '/sub/path/test')
        self.assertPathPerm(True, 'user', '', '/sub/path/other/sub')

    def test_module_usage(self):
        # If a module name is specified, the rules are specific to the module
        self.assertPathPerm(True, 'user', 'module', '/module_a')
        self.assertPathPerm(None, 'user', 'module', '/module_b')
        # If a module is specified, but the configuration contains a non-module
        # path, the non-module path can still apply
        self.assertPathPerm(True, 'user', 'module', '/module_c')
        # The module-specific rule takes precedence
        self.assertPathPerm(False, 'user', 'module', '/module_d')

    def test_wildcard(self):
        # The * wildcard matches all users, including anonymous
        self.assertPathPerm(True, 'anonymous', '', '/wildcard')
        self.assertPathPerm(True, 'joe', '', '/wildcard')
        self.assertPathPerm(True, 'jane', '', '/wildcard')

    def test_special_tokens(self):
        # The $anonymous token matches only anonymous users
        self.assertPathPerm(True, 'anonymous', '', '/special/anonymous')
        self.assertPathPerm(None, 'user', '', '/special/anonymous')
        # The $authenticated token matches all authenticated users
        self.assertPathPerm(None, 'anonymous', '', '/special/authenticated')
        self.assertPathPerm(True, 'joe', '', '/special/authenticated')
        self.assertPathPerm(True, 'jane', '', '/special/authenticated')

    def test_groups(self):
        # Groups are specified in a separate section and used with an @ prefix
        self.assertPathPerm(True, 'user', '', '/groups_a')
        # Groups can also be members of other groups
        self.assertPathPerm(True, 'user', '', '/groups_b')
        # Groups should not be defined cyclically, but they are still handled
        # correctly to avoid infinite loops
        self.assertPathPerm(True, 'user', '', '/cyclic')

    def test_precedence(self):
        # Module-specific sections take precedence over non-module sections
        self.assertPathPerm(False, 'user', 'module', '/precedence_a')
        # The most specific section applies
        self.assertPathPerm(True, 'user', '', '/precedence_b/sub/test')
        # ... intentional deviation from SVN's rules as we need to
        # make '/precedence_b/sub' browseable so that the user can see
        # '/precedence_b/sub/test':
        self.assertPathPerm(True, 'user', '', '/precedence_b/sub')
        self.assertPathPerm(True, 'user', '', '/precedence_b')
        # Within a section, the first matching rule applies
        self.assertPathPerm(False, 'user', '', '/precedence_c')
        self.assertPathPerm(True, 'user', '', '/precedence_d')

    def test_aliases(self):
        # Aliases are specified in a separate section and used with an & prefix
        self.assertPathPerm(True, 'Mr Hyde', '', '/aliases_a')
        # Aliases can also be used in groups
        self.assertPathPerm(True, 'Mr Hyde', '', '/aliases_b')

    def test_scoped_repository(self):
        # Take repository scope into account
        self.assertPathPerm(True, 'joe', 'scoped', '/dir1')
        self.assertPathPerm(None, 'joe', 'scoped', '/dir2')
        self.assertPathPerm(True, 'joe', 'scoped', '/')
        self.assertPathPerm(None, 'jane', 'scoped', '/dir1')
        self.assertPathPerm(True, 'jane', 'scoped', '/dir2')
        self.assertPathPerm(True, 'jane', 'scoped', '/')

    def test_changesets(self):
        # Changesets are allowed if at least one changed path is allowed, or
        # if the changeset is empty
        self.assertRevPerm(True, 'joe', 'scoped', 123)
        self.assertRevPerm(None, 'joe', 'scoped', 456)
        self.assertRevPerm(True, 'joe', 'scoped', 789)
        self.assertRevPerm(None, 'jane', 'scoped', 123)
        self.assertRevPerm(True, 'jane', 'scoped', 456)
        self.assertRevPerm(True, 'jane', 'scoped', 789)
        self.assertRevPerm(None, 'user', 'scoped', 123)
        self.assertRevPerm(None, 'user', 'scoped', 456)
        self.assertRevPerm(True, 'user', 'scoped', 789)


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(AuthzParserTestCase, 'test'))
    suite.addTest(unittest.makeSuite(AuthzSourcePolicyTestCase, 'test'))
    return suite


if __name__ == '__main__':
    runner = unittest.TextTestRunner()
    runner.run(suite())


########NEW FILE########
__FILENAME__ = browser
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2010 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>

from datetime import datetime, timedelta
from fnmatch import fnmatchcase
import re

from genshi.builder import tag

from trac.config import ListOption, BoolOption, Option
from trac.core import *
from trac.mimeview.api import IHTMLPreviewAnnotator, Mimeview, is_binary
from trac.perm import IPermissionRequestor
from trac.resource import Resource, ResourceNotFound
from trac.util import as_bool, embedded_numbers
from trac.util.compat import cleandoc
from trac.util.datefmt import http_date, to_datetime, utc
from trac.util.html import escape, Markup
from trac.util.text import exception_to_unicode, shorten_line
from trac.util.translation import _, cleandoc_
from trac.web import IRequestHandler, RequestDone
from trac.web.chrome import (INavigationContributor, add_ctxtnav, add_link,
                             add_script, add_stylesheet, prevnext_nav,
                             web_context)
from trac.wiki.api import IWikiSyntaxProvider, IWikiMacroProvider, parse_args
from trac.wiki.formatter import format_to_html, format_to_oneliner

from ..api import NoSuchChangeset, RepositoryManager
from trac.versioncontrol.web_ui.util import * # `from .util import *` FIXME 2.6


CHUNK_SIZE = 4096


class IPropertyRenderer(Interface):
    """Render node properties in TracBrowser and TracChangeset views."""

    def match_property(name, mode):
        """Indicate whether this renderer can treat the given property

        `mode` is the current rendering context, which can be:
         - 'browser' rendered in the browser view
         - 'changeset' rendered in the changeset view as a node property
         - 'revprop' rendered in the changeset view as a revision property
        Other identifiers might be used by plugins, so it's advised to simply
        ignore unknown modes.

        Returns a quality number, ranging from 0 (unsupported) to 9
        (''perfect'' match).
        """

    def render_property(name, mode, context, props):
        """Render the given property.

        `name` is the property name as given to `match()`,
        `mode` is the same as for `match_property`,
        `context` is the context for the node being render
        (useful when the rendering depends on the node kind) and
        `props` is the collection of the corresponding properties
        (i.e. the `node.get_properties()`).

        The rendered result can be one of the following:
        - `None`: the property will be skipped
        - an `unicode` value: the property will be displayed as text
        - a `RenderedProperty` instance: the property will only be displayed
          using the instance's `content` attribute, and the other attributes
          will also be used in some display contexts (like `revprop`)
        - `Markup` or other Genshi content: the property will be displayed
          normally, using that content as a block-level markup
        """


class RenderedProperty(object):
    def __init__(self, name=None, name_attributes=None,
                 content=None, content_attributes=None):
        self.name = name
        self.name_attributes = name_attributes
        self.content = content
        self.content_attributes = content_attributes


class DefaultPropertyRenderer(Component):
    """Default version control property renderer."""

    implements(IPropertyRenderer)

    def match_property(self, name, mode):
        return 1

    def render_property(self, name, mode, context, props):
        # No special treatment besides respecting newlines in values.
        value = props[name]
        if value and '\n' in value:
            value = Markup(''.join(['<br />%s' % escape(v)
                                    for v in value.split('\n')]))
        return value


class WikiPropertyRenderer(Component):
    """Wiki text property renderer."""

    implements(IPropertyRenderer)

    wiki_properties = ListOption('browser', 'wiki_properties',
                                 'trac:description',
        doc="""Comma-separated list of version control properties to render
        as wiki content in the repository browser.

        (''since 0.11'')""")

    oneliner_properties = ListOption('browser', 'oneliner_properties',
                                 'trac:summary',
        doc="""Comma-separated list of version control properties to render
        as oneliner wiki content in the repository browser.

        (''since 0.11'')""")

    def match_property(self, name, mode):
        return 4 if name in self.wiki_properties \
                    or name in self.oneliner_properties else 0

    def render_property(self, name, mode, context, props):
        if name in self.wiki_properties:
            return format_to_html(self.env, context, props[name])
        else:
            return format_to_oneliner(self.env, context, props[name])


class TimeRange(object):

    min = datetime(1, 1, 1, 0, 0, 0, 0, utc) # tz aware version of datetime.min

    def __init__(self, base):
        self.oldest = self.newest = base
        self._total = None

    def seconds_between(self, dt1, dt2):
        delta = dt1 - dt2
        return delta.days * 24 * 3600 + delta.seconds

    def to_seconds(self, dt):
        return self.seconds_between(dt, TimeRange.min)

    def from_seconds(self, secs):
        return TimeRange.min + timedelta(*divmod(secs, 24* 3600))

    def relative(self, datetime):
        if self._total is None:
            self._total = float(self.seconds_between(self.newest, self.oldest))
        age = 1.0
        if self._total:
            age = self.seconds_between(datetime, self.oldest) / self._total
        return age

    def insert(self, datetime):
        self._total = None
        self.oldest = min(self.oldest, datetime)
        self.newest = max(self.newest, datetime)



class BrowserModule(Component):

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
               IWikiSyntaxProvider, IHTMLPreviewAnnotator,
               IWikiMacroProvider)

    property_renderers = ExtensionPoint(IPropertyRenderer)

    downloadable_paths = ListOption('browser', 'downloadable_paths',
                                    '/trunk, /branches/*, /tags/*',
        doc="""List of repository paths that can be downloaded.

        Leave this option empty if you want to disable all downloads, otherwise
        set it to a comma-separated list of authorized paths (those paths are
        glob patterns, i.e. "*" can be used as a wild card). In a
        multi-repository environment, the path must be qualified with the
        repository name if the path does not point to the default repository
        (e.g. /reponame/trunk). Note that a simple prefix matching is
        performed on the paths, so aliases won't get automatically resolved.
        (''since 0.10'')""")

    color_scale = BoolOption('browser', 'color_scale', True,
        doc="""Enable colorization of the ''age'' column.

        This uses the same color scale as the source code annotation:
        blue is older, red is newer.
        (''since 0.11'')""")

    NEWEST_COLOR = (255, 136, 136)

    newest_color = Option('browser', 'newest_color', repr(NEWEST_COLOR),
        doc="""(r,g,b) color triple to use for the color corresponding
        to the newest color, for the color scale used in ''blame'' or
        the browser ''age'' column if `color_scale` is enabled.
        (''since 0.11'')""")

    OLDEST_COLOR = (136, 136, 255)

    oldest_color = Option('browser', 'oldest_color', repr(OLDEST_COLOR),
        doc="""(r,g,b) color triple to use for the color corresponding
        to the oldest color, for the color scale used in ''blame'' or
        the browser ''age'' column if `color_scale` is enabled.
        (''since 0.11'')""")

    intermediate_point = Option('browser', 'intermediate_point', '',
        doc="""If set to a value between 0 and 1 (exclusive), this will be the
        point chosen to set the `intermediate_color` for interpolating
        the color value.
        (''since 0.11'')""")

    intermediate_color = Option('browser', 'intermediate_color', '',
        doc="""(r,g,b) color triple to use for the color corresponding
        to the intermediate color, if two linear interpolations are used
        for the color scale (see `intermediate_point`).
        If not set, the intermediate color between `oldest_color` and
        `newest_color` will be used.
        (''since 0.11'')""")

    render_unsafe_content = BoolOption('browser', 'render_unsafe_content',
                                        'false',
        """Whether raw files should be rendered in the browser, or only made
        downloadable.

        Pretty much any file may be interpreted as HTML by the browser,
        which allows a malicious user to create a file containing cross-site
        scripting attacks.

        For open repositories where anyone can check-in a file, it is
        recommended to leave this option disabled (which is the default).""")

    hidden_properties = ListOption('browser', 'hide_properties', 'svk:merge',
        doc="""Comma-separated list of version control properties to hide from
        the repository browser.
        (''since 0.9'')""")

    # public methods

    def get_custom_colorizer(self):
        """Returns a converter for values from [0.0, 1.0] to a RGB triple."""

        def interpolate(old, new, value):
            # Provides a linearly interpolated color triple for `value`
            # which must be a floating point value between 0.0 and 1.0
            return tuple([int(b + (a - b) * value) for a, b in zip(new, old)])

        def parse_color(rgb, default):
            # Get three ints out of a `rgb` string or return `default`
            try:
                t = tuple([int(v) for v in re.split(r'(\d+)', rgb)[1::2]])
                return t if len(t) == 3 else default
            except ValueError:
                return default

        newest_color = parse_color(self.newest_color, self.NEWEST_COLOR)
        oldest_color = parse_color(self.oldest_color, self.OLDEST_COLOR)
        try:
            intermediate = float(self.intermediate_point)
        except ValueError:
            intermediate = None
        if intermediate:
            intermediate_color = parse_color(self.intermediate_color, None)
            if not intermediate_color:
                intermediate_color = tuple([(a + b) / 2 for a, b in
                                            zip(newest_color, oldest_color)])
            def colorizer(value):
                if value <= intermediate:
                    value = value / intermediate
                    return interpolate(oldest_color, intermediate_color, value)
                else:
                    value = (value - intermediate) / (1.0 - intermediate)
                    return interpolate(intermediate_color, newest_color, value)
        else:
            def colorizer(value):
                return interpolate(oldest_color, newest_color, value)
        return colorizer

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'browser'

    def get_navigation_items(self, req):
        rm = RepositoryManager(self.env)
        if 'BROWSER_VIEW' in req.perm and rm.get_real_repositories():
            yield ('mainnav', 'browser',
                   tag.a(_('Browse Source'), href=req.href.browser()))

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['BROWSER_VIEW', 'FILE_VIEW']

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/(export|browser|file)(/.*)?$', req.path_info)
        if match:
            mode, path = match.groups()
            if mode == 'export':
                if path and '/' in path:
                    path_elts = path.split('/', 2)
                    if len(path_elts) != 3:
                        return False
                    path = path_elts[2]
                    req.args['rev'] = path_elts[1]
                    req.args['format'] = 'raw'
            elif mode == 'file':
                req.redirect(req.href.browser(path, rev=req.args.get('rev'),
                                              format=req.args.get('format')),
                             permanent=True)
            req.args['path'] = path or '/'
            return True

    def process_request(self, req):
        req.perm.require('BROWSER_VIEW')

        presel = req.args.get('preselected')
        if presel and (presel + '/').startswith(req.href.browser() + '/'):
            req.redirect(presel)

        path = req.args.get('path', '/')
        rev = req.args.get('rev', '')
        if rev.lower() in ('', 'head'):
            rev = None
        order = req.args.get('order', 'name').lower()
        desc = req.args.has_key('desc')
        xhr = req.get_header('X-Requested-With') == 'XMLHttpRequest'

        rm = RepositoryManager(self.env)
        all_repositories = rm.get_all_repositories()
        reponame, repos, path = rm.get_repository_by_path(path)

        # Repository index
        show_index = not reponame and path == '/'
        if show_index:
            if repos and (as_bool(all_repositories[''].get('hidden'))
                          or not repos.is_viewable(req.perm)):
                repos = None

        if not repos and reponame:
            raise ResourceNotFound(_("Repository '%(repo)s' not found",
                                     repo=reponame))

        if reponame and reponame != repos.reponame: # Redirect alias
            qs = req.query_string
            req.redirect(req.href.browser(repos.reponame or None, path)
                         + ('?' + qs if qs else ''))
        reponame = repos.reponame if repos else None

        # Find node for the requested path/rev
        context = web_context(req)
        node = None
        display_rev = lambda rev: rev
        if repos:
            try:
                if rev:
                    rev = repos.normalize_rev(rev)
                # If `rev` is `None`, we'll try to reuse `None` consistently,
                # as a special shortcut to the latest revision.
                rev_or_latest = rev or repos.youngest_rev
                node = get_existing_node(req, repos, path, rev_or_latest)
            except NoSuchChangeset, e:
                raise ResourceNotFound(e.message,
                                       _('Invalid changeset number'))

            context = context.child(repos.resource.child('source', path,
                                                   version=rev_or_latest))
            display_rev = repos.display_rev

        # Prepare template data
        path_links = get_path_links(req.href, reponame, path, rev,
                                    order, desc)

        repo_data = dir_data = file_data = None
        if show_index:
            repo_data = self._render_repository_index(
                                        context, all_repositories, order, desc)
        if node:
            if node.isdir:
                dir_data = self._render_dir(req, repos, node, rev, order, desc)
            elif node.isfile:
                file_data = self._render_file(req, context, repos, node, rev)

        if not repos and not (repo_data and repo_data['repositories']):
            raise ResourceNotFound(_("No node %(path)s", path=path))

        quickjump_data = properties_data = None
        if node and not xhr:
            properties_data = self.render_properties(
                    'browser', context, node.get_properties())
            quickjump_data = list(repos.get_quickjump_entries(rev))

        data = {
            'context': context, 'reponame': reponame, 'repos': repos,
            'repoinfo': all_repositories.get(reponame or ''),
            'path': path, 'rev': node and node.rev, 'stickyrev': rev,
            'display_rev': display_rev,
            'created_path': node and node.created_path,
            'created_rev': node and node.created_rev,
            'properties': properties_data,
            'path_links': path_links,
            'order': order, 'desc': 1 if desc else None,
            'repo': repo_data, 'dir': dir_data, 'file': file_data,
            'quickjump_entries': quickjump_data,
            'wiki_format_messages': \
                self.config['changeset'].getbool('wiki_format_messages'),
            'xhr': xhr,
        }
        if xhr: # render and return the content only
            return 'dir_entries.html', data, None

        if dir_data or repo_data:
            add_script(req, 'common/js/expand_dir.js')
            add_script(req, 'common/js/keyboard_nav.js')

        # Links for contextual navigation
        if node:
            if node.isfile:
                prev_rev = repos.previous_rev(rev=node.created_rev,
                                              path=node.created_path)
                if prev_rev:
                    href = req.href.browser(reponame,
                                            node.created_path, rev=prev_rev)
                    add_link(req, 'prev', href,
                             _('Revision %(num)s', num=display_rev(prev_rev)))
                if rev is not None:
                    add_link(req, 'up', req.href.browser(reponame,
                                                         node.created_path))
                next_rev = repos.next_rev(rev=node.created_rev,
                                          path=node.created_path)
                if next_rev:
                    href = req.href.browser(reponame, node.created_path,
                                            rev=next_rev)
                    add_link(req, 'next', href,
                             _('Revision %(num)s', num=display_rev(next_rev)))
                prevnext_nav(req, _('Previous Revision'), _('Next Revision'),
                             _('Latest Revision'))
            else:
                if path != '/':
                    add_link(req, 'up', path_links[-2]['href'],
                             _('Parent directory'))
                add_ctxtnav(req, tag.a(_('Last Change'),
                            href=req.href.changeset(node.created_rev, reponame,
                                                    node.created_path)))
            if node.isfile:
                annotate = data['file']['annotate']
                if annotate:
                    add_ctxtnav(req, _('Normal'),
                                title=_('View file without annotations'),
                                href=req.href.browser(reponame,
                                                      node.created_path,
                                                      rev=rev))
                if annotate != 'blame':
                    add_ctxtnav(req, _('Blame'),
                                title=_('Annotate each line with the last '
                                        'changed revision '
                                        '(this can be time consuming...)'),
                                href=req.href.browser(reponame,
                                                      node.created_path,
                                                      rev=rev,
                                                      annotate='blame'))
            add_ctxtnav(req, _('Revision Log'),
                        href=req.href.log(reponame, path, rev=rev))
            path_url = repos.get_path_url(path, rev)
            if path_url:
                if path_url.startswith('//'):
                    path_url = req.scheme + ':' + path_url
                add_ctxtnav(req, _('Repository URL'), href=path_url)

        add_stylesheet(req, 'common/css/browser.css')
        return 'browser.html', data, None

    # Internal methods

    def _render_repository_index(self, context, all_repositories, order, desc):
        # Color scale for the age column
        timerange = custom_colorizer = None
        if self.color_scale:
            custom_colorizer = self.get_custom_colorizer()

        rm = RepositoryManager(self.env)
        repositories = []
        for reponame, repoinfo in all_repositories.iteritems():
            if not reponame or as_bool(repoinfo.get('hidden')):
                continue
            try:
                repos = rm.get_repository(reponame)
                if repos:
                    if not repos.is_viewable(context.perm):
                        continue
                    try:
                        youngest = repos.get_changeset(repos.youngest_rev)
                    except NoSuchChangeset:
                        youngest = None
                    if self.color_scale and youngest:
                        if not timerange:
                            timerange = TimeRange(youngest.date)
                        else:
                            timerange.insert(youngest.date)
                    raw_href = self._get_download_href(context.href, repos,
                                                       None, None)
                    entry = (reponame, repoinfo, repos, youngest, None,
                             raw_href)
                else:
                    entry = (reponame, repoinfo, None, None, u"\u2013", None)
            except TracError, err:
                entry = (reponame, repoinfo, None, None,
                         exception_to_unicode(err), None)
            if entry[-1] is not None:   # Check permission in case of error
                root = Resource('repository', reponame).child('source', '/')
                if 'BROWSER_VIEW' not in context.perm(root):
                    continue
            repositories.append(entry)

        # Ordering of repositories
        if order == 'date':
            def repo_order((reponame, repoinfo, repos, youngest, err, href)):
                return (youngest.date if youngest else to_datetime(0),
                        embedded_numbers(reponame.lower()))
        elif order == 'author':
            def repo_order((reponame, repoinfo, repos, youngest, err, href)):
                return (youngest.author.lower() if youngest else '',
                        embedded_numbers(reponame.lower()))
        else:
            def repo_order((reponame, repoinfo, repos, youngest, err, href)):
                return embedded_numbers(reponame.lower())

        repositories = sorted(repositories, key=repo_order, reverse=desc)

        return {'repositories' : repositories,
                'timerange': timerange, 'colorize_age': custom_colorizer}

    def _render_dir(self, req, repos, node, rev, order, desc):
        req.perm(node.resource).require('BROWSER_VIEW')
        download_href = self._get_download_href

        # Entries metadata
        class entry(object):
            _copy = 'name rev created_rev kind isdir path content_length' \
                    .split()
            __slots__ = _copy + ['raw_href']

            def __init__(self, node):
                for f in entry._copy:
                    setattr(self, f, getattr(node, f))
                self.raw_href = download_href(req.href, repos, node, rev)

        entries = [entry(n) for n in node.get_entries()
                   if n.is_viewable(req.perm)]
        changes = get_changes(repos, [i.created_rev for i in entries],
                              self.log)

        if rev:
            newest = repos.get_changeset(rev).date
        else:
            newest = datetime.now(req.tz)

        # Color scale for the age column
        timerange = custom_colorizer = None
        if self.color_scale:
            timerange = TimeRange(newest)
            max_s = req.args.get('range_max_secs')
            min_s = req.args.get('range_min_secs')
            parent_range = [timerange.from_seconds(long(s))
                            for s in [max_s, min_s] if s]
            this_range = [c.date for c in changes.values() if c]
            for dt in this_range + parent_range:
                timerange.insert(dt)
            custom_colorizer = self.get_custom_colorizer()

        # Ordering of entries
        if order == 'date':
            def file_order(a):
                return (changes[a.created_rev].date,
                        embedded_numbers(a.name.lower()))
        elif order == 'size':
            def file_order(a):
                return (a.content_length,
                        embedded_numbers(a.name.lower()))
        elif order == 'author':
            def file_order(a):
                return (changes[a.created_rev].author.lower(),
                        embedded_numbers(a.name.lower()))
        else:
            def file_order(a):
                return embedded_numbers(a.name.lower())

        dir_order = 1 if desc else -1

        def browse_order(a):
            return dir_order if a.isdir else 0, file_order(a)
        entries = sorted(entries, key=browse_order, reverse=desc)

        # ''Zip Archive'' alternate link
        zip_href = self._get_download_href(req.href, repos, node, rev)
        if zip_href:
            add_link(req, 'alternate', zip_href, _('Zip Archive'),
                     'application/zip', 'zip')

        return {'entries': entries, 'changes': changes,
                'timerange': timerange, 'colorize_age': custom_colorizer,
                'range_max_secs': (timerange and
                                   timerange.to_seconds(timerange.newest)),
                'range_min_secs': (timerange and
                                   timerange.to_seconds(timerange.oldest)),
                }

    def _render_file(self, req, context, repos, node, rev=None):
        req.perm(node.resource).require('FILE_VIEW')

        mimeview = Mimeview(self.env)

        # MIME type detection
        content = node.get_content()
        chunk = content.read(CHUNK_SIZE)
        mime_type = node.content_type
        if not mime_type or mime_type == 'application/octet-stream':
            mime_type = mimeview.get_mimetype(node.name, chunk) or \
                        mime_type or 'text/plain'

        # Eventually send the file directly
        format = req.args.get('format')
        if format in ('raw', 'txt'):
            req.send_response(200)
            req.send_header('Content-Type',
                            'text/plain' if format == 'txt' else mime_type)
            req.send_header('Content-Length', node.content_length)
            req.send_header('Last-Modified', http_date(node.last_modified))
            if rev is None:
                req.send_header('Pragma', 'no-cache')
                req.send_header('Cache-Control', 'no-cache')
                req.send_header('Expires', 'Fri, 01 Jan 1999 00:00:00 GMT')
            if not self.render_unsafe_content:
                # Force browser to download files instead of rendering
                # them, since they might contain malicious code enabling
                # XSS attacks
                req.send_header('Content-Disposition', 'attachment')
            req.end_headers()

            while 1:
                if not chunk:
                    raise RequestDone
                req.write(chunk)
                chunk = content.read(CHUNK_SIZE)
        else:
            # The changeset corresponding to the last change on `node`
            # is more interesting than the `rev` changeset.
            changeset = repos.get_changeset(node.created_rev)

            # add ''Plain Text'' alternate link if needed
            if not is_binary(chunk) and mime_type != 'text/plain':
                plain_href = req.href.browser(repos.reponame or None,
                                              node.path, rev=rev, format='txt')
                add_link(req, 'alternate', plain_href, _('Plain Text'),
                         'text/plain')

            # add ''Original Format'' alternate link (always)
            raw_href = req.href.export(rev or repos.youngest_rev,
                                       repos.reponame or None, node.path)
            add_link(req, 'alternate', raw_href, _('Original Format'),
                     mime_type)

            self.log.debug("Rendering preview of node %s@%s with mime-type %s"
                           % (node.name, str(rev), mime_type))

            del content # the remainder of that content is not needed

            add_stylesheet(req, 'common/css/code.css')

            annotations = ['lineno']
            annotate = req.args.get('annotate')
            if annotate:
                annotations.insert(0, annotate)
            preview_data = mimeview.preview_data(context, node.get_content(),
                                                 node.get_content_length(),
                                                 mime_type, node.created_path,
                                                 raw_href,
                                                 annotations=annotations,
                                                 force_source=bool(annotate))
            return {
                'changeset': changeset,
                'size': node.content_length,
                'preview': preview_data,
                'annotate': annotate,
                }

    def _get_download_href(self, href, repos, node, rev):
        """Return the URL for downloading a file, or a directory as a ZIP."""
        if node is not None and node.isfile:
            return href.export(rev or 'HEAD', repos.reponame or None,
                               node.path)
        path = npath = '' if node is None else node.path.strip('/')
        if repos.reponame:
            path = (repos.reponame + '/' + npath).rstrip('/')
        if any(fnmatchcase(path, p.strip('/'))
               for p in self.downloadable_paths):
            return href.changeset(rev or repos.youngest_rev,
                                  repos.reponame or None, npath,
                                  old=rev, old_path=repos.reponame or '/',
                                  format='zip')

    # public methods

    def render_properties(self, mode, context, props):
        """Prepare rendering of a collection of properties."""
        return filter(None, [self.render_property(name, mode, context, props)
                             for name in sorted(props)])

    def render_property(self, name, mode, context, props):
        """Renders a node property to HTML."""
        if name in self.hidden_properties:
            return
        candidates = []
        for renderer in self.property_renderers:
            quality = renderer.match_property(name, mode)
            if quality > 0:
                candidates.append((quality, renderer))
        candidates.sort(reverse=True)
        for (quality, renderer) in candidates:
            try:
                rendered = renderer.render_property(name, mode, context, props)
                if not rendered:
                    return rendered
                if isinstance(rendered, RenderedProperty):
                    value = rendered.content
                else:
                    value = rendered
                    rendered = None
                prop = {'name': name, 'value': value, 'rendered': rendered}
                return prop
            except Exception, e:
                self.log.warning('Rendering failed for property %s with '
                                 'renderer %s: %s', name,
                                 renderer.__class__.__name__,
                                 exception_to_unicode(e, traceback=True))

    # IWikiSyntaxProvider methods

    def get_wiki_syntax(self):
        return []

    def get_link_resolvers(self):
        """TracBrowser link resolvers.
         - `source:` and `browser:`
             * simple paths (/dir/file)
             * paths at a given revision (/dir/file@234)
             * paths with line number marks (/dir/file@234:10,20-30)
             * paths with line number anchor (/dir/file@234#L100)
            Marks and anchor can be combined.
            The revision must be present when specifying line numbers.
            In the few cases where it would be redundant (e.g. for tags), the
            revision number itself can be omitted: /tags/v10/file@100-110#L99
        """
        return [('repos', self._format_browser_link),
                ('export', self._format_export_link),
                ('source', self._format_browser_link),
                ('browser', self._format_browser_link)]

    def _format_export_link(self, formatter, ns, export, label):
        export, query, fragment = formatter.split_link(export)
        if ':' in export:
            rev, path = export.split(':', 1)
        elif '@' in export:
            path, rev = export.split('@', 1)
        else:
            rev, path = None, export
        node, raw_href, title = self._get_link_info(path, rev, formatter.href,
                                                    formatter.perm)
        if raw_href:
            return tag.a(label, class_='export', href=raw_href + fragment,
                         title=title)
        return tag.a(label, class_='missing export')

    def _format_browser_link(self, formatter, ns, path, label):
        path, query, fragment = formatter.split_link(path)
        rev = marks = None
        match = self.PATH_LINK_RE.match(path)
        if match:
            path, rev, marks = match.groups()
        href = formatter.href
        src_href = href.browser(path, rev=rev, marks=marks) + query + fragment
        node, raw_href, title = self._get_link_info(path, rev, formatter.href,
                                                    formatter.perm)
        if not node:
            return tag.a(label, class_='missing source')
        link = tag.a(label, class_='source', href=src_href)
        if raw_href:
            link = tag(link, tag.a(u'\u200b', href=raw_href + fragment,
                                   title=title,
                                   class_='trac-rawlink' if node.isfile
                                          else 'trac-ziplink'))
        return link

    PATH_LINK_RE = re.compile(r"([^@#:]*)"     # path
                              r"[@:]([^#:]+)?" # rev
                              r"(?::(\d+(?:-\d+)?(?:,\d+(?:-\d+)?)*))?" # marks
                              )

    def _get_link_info(self, path, rev, href, perm):
        rm = RepositoryManager(self.env)
        node = raw_href = title = None
        try:
            reponame, repos, npath = rm.get_repository_by_path(path)
            node = get_allowed_node(repos, npath, rev, perm)
            if node is not None:
                raw_href = self._get_download_href(href, repos, node, rev)
                title = _("Download") if node.isfile \
                        else _("Download as Zip archive")
        except TracError:
            pass
        return (node, raw_href, title)

    # IHTMLPreviewAnnotator methods

    def get_annotation_type(self):
        return 'blame', _('Rev'), _('Revision in which the line changed')

    def get_annotation_data(self, context):
        """Cache the annotation data corresponding to each revision."""
        return BlameAnnotator(self.env, context)

    def annotate_row(self, context, row, lineno, line, blame_annotator):
        blame_annotator.annotate(row, lineno)

    # IWikiMacroProvider methods

    def get_macros(self):
        yield "RepositoryIndex"

    def get_macro_description(self, name):
        description = cleandoc_("""
        Display the list of available repositories.

        Can be given the following named arguments:

          ''format''::
            Select the rendering format:
            - ''compact'' produces a comma-separated list of repository prefix
              names (default)
            - ''list'' produces a description list of repository prefix names
            - ''table'' produces a table view, similar to the one visible in
              the ''Browse View'' page
          ''glob''::
            Do a glob-style filtering on the repository names (defaults to '*')
          ''order''::
            Order repositories by the given column (one of "name", "date" or
            "author")
          ''desc''::
            When set to 1, order by descending order

        (''since 0.12'')
        """)
        return 'messages', description

    def expand_macro(self, formatter, name, content):
        args, kwargs = parse_args(content)
        format = kwargs.get('format', 'compact')
        glob = kwargs.get('glob', '*')
        order = kwargs.get('order')
        desc = as_bool(kwargs.get('desc', 0))

        rm = RepositoryManager(self.env)
        all_repos = dict(rdata for rdata in rm.get_all_repositories().items()
                         if fnmatchcase(rdata[0], glob))

        if format == 'table':
            repo = self._render_repository_index(formatter.context, all_repos,
                                                 order, desc)

            add_stylesheet(formatter.req, 'common/css/browser.css')
            wiki_format_messages = self.config['changeset'] \
                                       .getbool('wiki_format_messages')
            data = {'repo': repo, 'order': order, 'desc': 1 if desc else None,
                    'reponame': None, 'path': '/', 'stickyrev': None,
                    'wiki_format_messages': wiki_format_messages}
            from trac.web.chrome import Chrome
            return Chrome(self.env).render_template(
                    formatter.req, 'repository_index.html', data, None,
                    fragment=True)

        def get_repository(reponame):
            try:
                return rm.get_repository(reponame)
            except TracError:
                return

        all_repos = [(reponame, get_repository(reponame))
                     for reponame in all_repos]
        all_repos = sorted(((reponame, repos) for reponame, repos in all_repos
                            if repos
                            and not as_bool(repos.params.get('hidden'))
                            and repos.is_viewable(formatter.perm)),
                           reverse=desc)

        def repolink(reponame, repos):
            label = reponame or _('(default)')
            return Markup(tag.a(label,
                          title=_('View repository %(repo)s', repo=label),
                          href=formatter.href.browser(repos.reponame or None)))

        if format == 'list':
            return tag.dl([
                tag(tag.dt(repolink(reponame, repos)),
                    tag.dd(repos.params.get('description')))
                for reponame, repos in all_repos])
        else: # compact
            return Markup(', ').join([repolink(reponame, repos)
                                      for reponame, repos in all_repos])



class BlameAnnotator(object):

    def __init__(self, env, context):
        self.env = env
        self.context = context
        rm = RepositoryManager(self.env)
        self.repos = rm.get_repository(context.resource.parent.id)
        self.path = context.resource.id
        self.rev = context.resource.version
        # maintain state
        self.prev_chgset = None
        self.chgset_data = {}
        add_script(context.req, 'common/js/blame.js')
        add_stylesheet(context.req, 'common/css/changeset.css')
        add_stylesheet(context.req, 'common/css/diff.css')
        self.reset()

    def reset(self):
        rev = self.rev
        node = self.repos.get_node(self.path, rev)
        # FIXME: get_annotations() should be in the Resource API
        # -- get revision numbers for each line
        self.annotations = node.get_annotations()
        # -- from the annotations, retrieve changesets and
        # determine the span of dates covered, for the color code.
        # Note: changesets[i].rev can differ from annotations[i]
        # (long form vs. compact, short rev form for the latter).
        self.changesets = []
        chgset = self.repos.get_changeset(rev)
        chgsets = {rev: chgset}
        self.timerange = TimeRange(chgset.date)
        for idx in range(len(self.annotations)):
            rev = self.annotations[idx]
            chgset = chgsets.get(rev)
            if not chgset:
                chgset = self.repos.get_changeset(rev)
                chgsets[rev] = chgset
                self.timerange.insert(chgset.date)
            # get list of changeset parallel to annotations
            self.changesets.append(chgset)
        # -- retrieve the original path of the source, for each rev
        # (support for copy/renames)
        self.paths = {}
        for path, rev, chg in node.get_history():
            self.paths[rev] = path
        # -- get custom colorize function
        browser = BrowserModule(self.env)
        self.colorize_age = browser.get_custom_colorizer()

    def annotate(self, row, lineno):
        if lineno > len(self.annotations):
            row.append(tag.th())
            return
        rev = self.annotations[lineno-1]
        chgset = self.changesets[lineno-1]
        path = self.paths.get(rev, None)
        # Note: path will be None if copy/rename is not supported
        # by get_history

        # -- compute anchor and style once per revision
        if rev not in self.chgset_data:
            chgset_href = \
                self.context.href.changeset(rev, self.repos.reponame or None,
                                            path)
            short_author = chgset.author.split(' ', 1)[0]
            title = shorten_line('%s: %s' % (short_author, chgset.message))
            anchor = tag.a('[%s]' % self.repos.short_rev(rev), # shortname
                           title=title, href=chgset_href)
            color = self.colorize_age(self.timerange.relative(chgset.date))
            style = 'background-color: rgb(%d, %d, %d);' % color
            self.chgset_data[rev] = (anchor, style)
        else:
            anchor, style = self.chgset_data[rev]

        if self.prev_chgset != chgset:
            self.prev_style = style
        # optimize away the path if there's no copy/rename info
        if not path or path == self.path:
            path = ''
        # -- produce blame column, eventually with an anchor
        style = self.prev_style
        if lineno < len(self.changesets) and self.changesets[lineno] == chgset:
            style += ' border-bottom: none;'
        blame_col = tag.th(style=style, class_='blame r%s' % rev)
        if self.prev_chgset != chgset:
            blame_col.append(anchor)
            self.prev_chgset = chgset
        row.append(blame_col)

########NEW FILE########
__FILENAME__ = changeset
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2006 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005-2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>
#         Christian Boos <cboos@edgewall.org>

from __future__ import with_statement

from itertools import groupby
import os
import posixpath
import re
from StringIO import StringIO

from genshi.builder import tag

from trac.config import Option, BoolOption, IntOption
from trac.core import *
from trac.mimeview.api import Mimeview
from trac.perm import IPermissionRequestor
from trac.resource import Resource, ResourceNotFound
from trac.search import ISearchSource, search_to_sql, shorten_result
from trac.timeline.api import ITimelineEventProvider
from trac.util import as_bool, content_disposition, embedded_numbers, pathjoin
from trac.util.datefmt import from_utimestamp, pretty_timedelta
from trac.util.text import exception_to_unicode, to_unicode, \
                           unicode_urlencode, shorten_line, CRLF
from trac.util.translation import _, ngettext
from trac.versioncontrol.api import RepositoryManager, Changeset, Node, \
                                    NoSuchChangeset
from trac.versioncontrol.diff import get_diff_options, diff_blocks, \
                                     unified_diff
from trac.versioncontrol.web_ui.browser import BrowserModule
from trac.web import IRequestHandler, RequestDone
from trac.web.chrome import (Chrome, INavigationContributor, add_ctxtnav,
                             add_link, add_script, add_stylesheet,
                             prevnext_nav, web_context)
from trac.wiki import IWikiSyntaxProvider, WikiParser
from trac.wiki.formatter import format_to


class IPropertyDiffRenderer(Interface):
    """Render node properties in TracBrowser and TracChangeset views."""

    def match_property_diff(name):
        """Indicate whether this renderer can treat the given property diffs

        Returns a quality number, ranging from 0 (unsupported) to 9
        (''perfect'' match).
        """

    def render_property_diff(name, old_context, old_props,
                             new_context, new_props, options):
        """Render the given diff of property to HTML.

        `name` is the property name as given to `match_property_diff()`,
        `old_context` corresponds to the old node being render
        (useful when the rendering depends on the node kind)
        and `old_props` is the corresponding collection of all properties.
        Same for `new_node` and `new_props`.
        `options` are the current diffs options.

        The rendered result can be one of the following:
        - `None`: the property change will be shown the normal way
          (''changed from `old` to `new`'')
        - an `unicode` value: the change will be shown as textual content
        - `Markup` or other Genshi content: the change will shown as block
          markup
        """


class DefaultPropertyDiffRenderer(Component):
    """Default version control property difference renderer."""

    implements(IPropertyDiffRenderer)

    def match_property_diff(self, name):
        return 1

    def render_property_diff(self, name, old_context, old_props,
                             new_context, new_props, options):
        old, new = old_props[name], new_props[name]
        # Render as diff only if multiline (see #3002)
        if '\n' not in old and '\n' not in new:
            return None
        unidiff = '--- \n+++ \n' + \
                  '\n'.join(unified_diff(old.splitlines(), new.splitlines(),
                                         options.get('contextlines', 3)))
        return tag.li('Property ', tag.strong(name),
                      Mimeview(self.env).render(old_context, 'text/x-diff',
                                                unidiff))


class ChangesetModule(Component):
    """Renderer providing flexible functionality for showing sets of
    differences.

    If the differences shown are coming from a specific changeset,
    then that changeset information can be shown too.

    In addition, it is possible to show only a subset of the changeset:
    Only the changes affecting a given path will be shown. This is called
    the ''restricted'' changeset.

    But the differences can also be computed in a more general way,
    between two arbitrary paths and/or between two arbitrary revisions.
    In that case, there's no changeset information displayed.
    """

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
               ITimelineEventProvider, IWikiSyntaxProvider, ISearchSource)

    property_diff_renderers = ExtensionPoint(IPropertyDiffRenderer)

    timeline_show_files = Option('timeline', 'changeset_show_files', '0',
        """Number of files to show (`-1` for unlimited, `0` to disable).

        This can also be `location`, for showing the common prefix for the
        changed files. (since 0.11).
        """)

    timeline_long_messages = BoolOption('timeline', 'changeset_long_messages',
                                        'false',
        """Whether wiki-formatted changeset messages should be multiline or
        not.

        If this option is not specified or is false and `wiki_format_messages`
        is set to true, changeset messages will be single line only, losing
        some formatting (bullet points, etc).""")

    timeline_collapse = BoolOption('timeline', 'changeset_collapse_events',
                                   'false',
        """Whether consecutive changesets from the same author having
        exactly the same message should be presented as one event.
        That event will link to the range of changesets in the log view.
        (''since 0.11'')""")

    max_diff_files = IntOption('changeset', 'max_diff_files', 0,
        """Maximum number of modified files for which the changeset view will
        attempt to show the diffs inlined (''since 0.10'').""")

    max_diff_bytes = IntOption('changeset', 'max_diff_bytes', 10000000,
        """Maximum total size in bytes of the modified files (their old size
        plus their new size) for which the changeset view will attempt to show
        the diffs inlined (''since 0.10'').""")

    wiki_format_messages = BoolOption('changeset', 'wiki_format_messages',
                                      'true',
        """Whether wiki formatting should be applied to changeset messages.

        If this option is disabled, changeset messages will be rendered as
        pre-formatted text.""")

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'browser'

    def get_navigation_items(self, req):
        return []

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['CHANGESET_VIEW']

    # IRequestHandler methods

    _request_re = re.compile(r"/changeset(?:/([^/]+)(/.*)?)?$")

    def match_request(self, req):
        match = re.match(self._request_re, req.path_info)
        if match:
            new, new_path = match.groups()
            if new:
                req.args['new'] = new
            if new_path:
                req.args['new_path'] = new_path
            return True

    def process_request(self, req):
        """The appropriate mode of operation is inferred from the request
        parameters:

         * If `new_path` and `old_path` are equal (or `old_path` is omitted)
           and `new` and `old` are equal (or `old` is omitted),
           then we're about to view a revision Changeset: `chgset` is True.
           Furthermore, if the path is not the root, the changeset is
           ''restricted'' to that path (only the changes affecting that path,
           its children or its ancestor directories will be shown).
         * In any other case, the set of changes corresponds to arbitrary
           differences between path@rev pairs. If `new_path` and `old_path`
           are equal, the ''restricted'' flag will also be set, meaning in this
           case that the differences between two revisions are restricted to
           those occurring on that path.

        In any case, either path@rev pairs must exist.
        """
        req.perm.require('CHANGESET_VIEW')

        # -- retrieve arguments
        full_new_path = new_path = req.args.get('new_path')
        new = req.args.get('new')
        full_old_path = old_path = req.args.get('old_path')
        old = req.args.get('old')
        reponame = req.args.get('reponame')

        xhr = req.get_header('X-Requested-With') == 'XMLHttpRequest'

        # -- support for the revision log ''View changes'' form,
        #    where we need to give the path and revision at the same time
        if old and '@' in old:
            old, old_path = old.split('@', 1)
        if new and '@' in new:
            new, new_path = new.split('@', 1)

        rm = RepositoryManager(self.env)
        if reponame:
            repos = rm.get_repository(reponame)
        else:
            reponame, repos, new_path = rm.get_repository_by_path(new_path)

            if old_path:
                old_reponame, old_repos, old_path = \
                    rm.get_repository_by_path(old_path)
                if old_repos != repos:
                    raise TracError(_("Can't compare across different "
                                      "repositories: %(old)s vs. %(new)s",
                                      old=old_reponame, new=reponame))

        if not repos:
            if reponame or (new_path and new_path != '/'):
                raise TracError(_("Repository '%(repo)s' not found",
                                  repo=reponame or new_path.strip('/')))
            else:
                raise TracError(_("No repository specified and no default "
                                  "repository configured."))

        # -- normalize and check for special case
        try:
            new_path = repos.normalize_path(new_path)
            new = repos.normalize_rev(new)
            full_new_path = '/' + pathjoin(repos.reponame, new_path)
            old_path = repos.normalize_path(old_path or new_path)
            old = repos.normalize_rev(old or new)
            full_old_path = '/' + pathjoin(repos.reponame, old_path)
        except NoSuchChangeset, e:
            raise ResourceNotFound(e.message, _('Invalid Changeset Number'))

        if old_path == new_path and old == new: # revert to Changeset
            old_path = old = None

        style, options, diff_data = get_diff_options(req)
        diff_opts = diff_data['options']

        # -- setup the `chgset` and `restricted` flags, see docstring above.
        chgset = not old and not old_path
        if chgset:
            restricted = new_path not in ('', '/') # (subset or not)
        else:
            restricted = old_path == new_path # (same path or not)

        # -- redirect if changing the diff options or alias requested
        if 'update' in req.args or reponame != repos.reponame:
            contextall = diff_opts['contextall'] or None
            reponame = repos.reponame or None
            if chgset:
                if restricted:
                    req.redirect(req.href.changeset(new, reponame, new_path,
                                                    contextall=contextall))
                else:
                    req.redirect(req.href.changeset(new, reponame,
                                                    contextall=contextall))
            else:
                req.redirect(req.href.changeset(new, reponame,
                                                new_path, old=old,
                                                old_path=full_old_path,
                                                contextall=contextall))

        # -- preparing the data
        if chgset:
            prev = repos.get_node(new_path, new).get_previous()
            if prev:
                prev_path, prev_rev = prev[:2]
            else:
                prev_path, prev_rev = new_path, repos.previous_rev(new)
            data = {'old_path': prev_path, 'old_rev': prev_rev,
                    'new_path': new_path, 'new_rev': new}
        else:
            if not new:
                new = repos.youngest_rev
            elif not old:
                old = repos.youngest_rev
            if not old_path:
                old_path = new_path
            data = {'old_path': old_path, 'old_rev': old,
                    'new_path': new_path, 'new_rev': new}
        data.update({'repos': repos, 'reponame': repos.reponame or None,
                     'diff': diff_data,
                     'wiki_format_messages': self.wiki_format_messages})

        if chgset:
            chgset = repos.get_changeset(new)
            req.perm(chgset.resource).require('CHANGESET_VIEW')

            # TODO: find a cheaper way to reimplement r2636
            req.check_modified(chgset.date, [
                style, ''.join(options), repos.name,
                diff_opts['contextlines'], diff_opts['contextall'],
                repos.rev_older_than(new, repos.youngest_rev),
                chgset.message, xhr,
                pretty_timedelta(chgset.date, None, 3600)])

        format = req.args.get('format')

        if format in ['diff', 'zip']:
            # choosing an appropriate filename
            rpath = new_path.replace('/','_')
            if chgset:
                if restricted:
                    filename = 'changeset_%s_%s' % (rpath, new)
                else:
                    filename = 'changeset_%s' % new
            else:
                if restricted:
                    filename = 'diff-%s-from-%s-to-%s' \
                                  % (rpath, old, new)
                elif old_path == '/': # special case for download (#238)
                    filename = '%s-%s' % (rpath, old)
                else:
                    filename = 'diff-from-%s-%s-to-%s-%s' \
                               % (old_path.replace('/','_'), old, rpath, new)
            if format == 'diff':
                self._render_diff(req, filename, repos, data)
            elif format == 'zip':
                self._render_zip(req, filename, repos, data)

        # -- HTML format
        self._render_html(req, repos, chgset, restricted, xhr, data)

        if chgset:
            diff_params = 'new=%s' % new
        else:
            diff_params = unicode_urlencode({
                'new_path': full_new_path, 'new': new,
                'old_path': full_old_path, 'old': old})
        add_link(req, 'alternate', '?format=diff&' + diff_params,
                 _('Unified Diff'), 'text/plain', 'diff')
        add_link(req, 'alternate', '?format=zip&' + diff_params,
                 _('Zip Archive'), 'application/zip', 'zip')
        add_script(req, 'common/js/diff.js')
        add_stylesheet(req, 'common/css/changeset.css')
        add_stylesheet(req, 'common/css/diff.css')
        add_stylesheet(req, 'common/css/code.css')
        if chgset:
            if restricted:
                prevnext_nav(req, _('Previous Change'), _('Next Change'))
            else:
                prevnext_nav(req, _('Previous Changeset'), _('Next Changeset'))
        else:
            rev_href = req.href.changeset(old, full_old_path,
                                          old=new, old_path=full_new_path)
            add_ctxtnav(req, _('Reverse Diff'), href=rev_href)

        return 'changeset.html', data, None

    # Internal methods

    def _render_html(self, req, repos, chgset, restricted, xhr, data):
        """HTML version"""
        data['restricted'] = restricted
        display_rev = repos.display_rev
        data['display_rev'] = display_rev
        browser = BrowserModule(self.env)
        reponame = repos.reponame or None

        if chgset: # Changeset Mode (possibly restricted on a path)
            path, rev = data['new_path'], data['new_rev']

            # -- getting the change summary from the Changeset.get_changes
            def get_changes():
                for npath, kind, change, opath, orev in chgset.get_changes():
                    old_node = new_node = None
                    if (restricted and
                        not (npath == path or                # same path
                             npath.startswith(path + '/') or # npath is below
                             path.startswith(npath + '/'))): # npath is above
                        continue
                    if change != Changeset.ADD:
                        old_node = repos.get_node(opath, orev)
                    if change != Changeset.DELETE:
                        new_node = repos.get_node(npath, rev)
                    else:
                        # support showing paths deleted below a copy target
                        old_node.path = npath
                    yield old_node, new_node, kind, change

            def _changeset_title(rev):
                rev = display_rev(rev)
                if restricted:
                    return _('Changeset %(id)s for %(path)s', id=rev,
                             path=path)
                else:
                    return _('Changeset %(id)s', id=rev)

            data['changeset'] = chgset
            title = _changeset_title(rev)

            # Support for revision properties (#2545)
            context = web_context(req, 'changeset', chgset.rev,
                                  parent=repos.resource)
            data['context'] = context
            revprops = chgset.get_properties()
            data['properties'] = browser.render_properties('revprop', context,
                                                           revprops)
            oldest_rev = repos.oldest_rev
            if chgset.rev != oldest_rev:
                if restricted:
                    prev = repos.get_node(path, rev).get_previous()
                    if prev:
                        prev_path, prev_rev = prev[:2]
                        if prev_rev:
                            prev_href = req.href.changeset(prev_rev, reponame,
                                                           prev_path)
                    else:
                        prev_path = prev_rev = None
                else:
                    add_link(req, 'first',
                             req.href.changeset(oldest_rev, reponame),
                             _('Changeset %(id)s', id=display_rev(oldest_rev)))
                    prev_path = data['old_path']
                    prev_rev = repos.previous_rev(chgset.rev)
                    if prev_rev:
                        prev_href = req.href.changeset(prev_rev, reponame)
                if prev_rev:
                    add_link(req, 'prev', prev_href,
                             _changeset_title(prev_rev))
            youngest_rev = repos.youngest_rev
            if str(chgset.rev) != str(youngest_rev):
                if restricted:
                    next_rev = repos.next_rev(chgset.rev, path)
                    if next_rev:
                        if repos.has_node(path, next_rev):
                            next_href = req.href.changeset(next_rev, reponame,
                                                           path)
                        else: # must be a 'D'elete or 'R'ename, show full cset
                            next_href = req.href.changeset(next_rev, reponame)
                else:
                    add_link(req, 'last',
                             req.href.changeset(youngest_rev, reponame),
                             _('Changeset %(id)s',
                               id=display_rev(youngest_rev)))
                    next_rev = repos.next_rev(chgset.rev)
                    if next_rev:
                        next_href = req.href.changeset(next_rev, reponame)
                if next_rev:
                    add_link(req, 'next', next_href,
                             _changeset_title(next_rev))
        else: # Diff Mode
            # -- getting the change summary from the Repository.get_changes
            def get_changes():
                for d in repos.get_changes(
                    new_path=data['new_path'], new_rev=data['new_rev'],
                    old_path=data['old_path'], old_rev=data['old_rev']):
                    yield d
            title = self.title_for_diff(data)
            data['changeset'] = False

        data['title'] = title

        if 'BROWSER_VIEW' not in req.perm:
            return

        def node_info(node, annotated):
            href = req.href.browser(
                reponame, node.created_path, rev=node.created_rev,
                annotate='blame' if annotated else None)
            title = _('Show revision %(rev)s of this file in browser',
                      rev=display_rev(node.rev))
            return {'path': node.path, 'rev': node.rev,
                    'shortrev': repos.short_rev(node.rev),
                    'href': href, 'title': title}
        # Reminder: node.path may not exist at node.rev
        #           as long as node.rev==node.created_rev
        #           ... and data['old_rev'] may have nothing to do
        #           with _that_ node specific history...

        options = data['diff']['options']

        def _prop_changes(old_node, new_node):
            old_props = old_node.get_properties()
            new_props = new_node.get_properties()
            old_ctx = web_context(req, old_node.resource)
            new_ctx = web_context(req, new_node.resource)
            changed_properties = []
            if old_props != new_props:
                for k, v in sorted(old_props.items()):
                    new = old = diff = None
                    if not k in new_props:
                        old = v # won't be displayed, no need to render it
                    elif v != new_props[k]:
                        diff = self.render_property_diff(
                            k, old_ctx, old_props, new_ctx, new_props, options)
                        if not diff:
                            old = browser.render_property(k, 'changeset',
                                                          old_ctx, old_props)
                            new = browser.render_property(k, 'changeset',
                                                          new_ctx, new_props)
                    if new or old or diff:
                        changed_properties.append({'name': k, 'old': old,
                                                   'new': new, 'diff': diff})
                for k, v in sorted(new_props.items()):
                    if not k in old_props:
                        new = browser.render_property(k, 'changeset',
                                                      new_ctx, new_props)
                        if new is not None:
                            changed_properties.append({'name': k, 'new': new,
                                                       'old': None})
            return changed_properties

        def _estimate_changes(old_node, new_node):
            old_size = old_node.get_content_length()
            new_size = new_node.get_content_length()
            return old_size + new_size

        def _content_changes(old_node, new_node):
            """Returns the list of differences.

            The list is empty when no differences between comparable files
            are detected, but the return value is None for non-comparable
            files.
            """
            mview = Mimeview(self.env)
            if mview.is_binary(old_node.content_type, old_node.path):
                return None
            if mview.is_binary(new_node.content_type, new_node.path):
                return None
            old_content = old_node.get_content().read()
            if mview.is_binary(content=old_content):
                return None
            new_content = new_node.get_content().read()
            if mview.is_binary(content=new_content):
                return None

            old_content = mview.to_unicode(old_content, old_node.content_type)
            new_content = mview.to_unicode(new_content, new_node.content_type)

            if old_content != new_content:
                context = options.get('contextlines', 3)
                if context < 0 or options.get('contextall'):
                    context = None
                tabwidth = self.config['diff'].getint('tab_width') or \
                           self.config['mimeviewer'].getint('tab_width', 8)
                ignore_blank_lines = options.get('ignoreblanklines')
                ignore_case = options.get('ignorecase')
                ignore_space = options.get('ignorewhitespace')
                return diff_blocks(old_content.splitlines(),
                                   new_content.splitlines(),
                                   context, tabwidth,
                                   ignore_blank_lines=ignore_blank_lines,
                                   ignore_case=ignore_case,
                                   ignore_space_changes=ignore_space)
            else:
                return []

        diff_bytes = diff_files = 0
        if self.max_diff_bytes or self.max_diff_files:
            for old_node, new_node, kind, change in get_changes():
                if change in Changeset.DIFF_CHANGES and kind == Node.FILE \
                        and old_node.is_viewable(req.perm) \
                        and new_node.is_viewable(req.perm):
                    diff_files += 1
                    diff_bytes += _estimate_changes(old_node, new_node)
        show_diffs = (not self.max_diff_files or \
                      0 < diff_files <= self.max_diff_files) and \
                     (not self.max_diff_bytes or \
                      diff_bytes <= self.max_diff_bytes or \
                      diff_files == 1)

        # XHR is used for blame support: display the changeset view without
        # the navigation and with the changes concerning the annotated file
        annotated = False
        if xhr:
            show_diffs = False
            annotated = repos.normalize_path(req.args.get('annotate'))

        has_diffs = False
        filestats = self._prepare_filestats()
        changes = []
        files = []
        for old_node, new_node, kind, change in get_changes():
            props = []
            diffs = []
            show_old = old_node and old_node.is_viewable(req.perm)
            show_new = new_node and new_node.is_viewable(req.perm)
            show_entry = change != Changeset.EDIT
            show_diff = show_diffs or (new_node and new_node.path == annotated)

            if change in Changeset.DIFF_CHANGES and show_old and show_new:
                assert old_node and new_node
                props = _prop_changes(old_node, new_node)
                if props:
                    show_entry = True
                if kind == Node.FILE and show_diff:
                    diffs = _content_changes(old_node, new_node)
                    if diffs != []:
                        if diffs:
                            has_diffs = True
                        # elif None (means: manually compare to (previous))
                        show_entry = True
            if (show_old or show_new) and (show_entry or not show_diff):
                info = {'change': change,
                        'old': old_node and node_info(old_node, annotated),
                        'new': new_node and node_info(new_node, annotated),
                        'props': props,
                        'diffs': diffs}
                files.append(new_node.path if new_node else \
                             old_node.path if old_node else '')
                filestats[change] += 1
                if change in Changeset.DIFF_CHANGES:
                    if chgset:
                        href = req.href.changeset(new_node.rev, reponame,
                                                  new_node.path)
                        title = _('Show the changeset %(id)s restricted to '
                                  '%(path)s', id=display_rev(new_node.rev),
                                  path=new_node.path)
                    else:
                        href = req.href.changeset(
                            new_node.created_rev, reponame,
                            new_node.created_path,
                            old=old_node.created_rev,
                            old_path=pathjoin(repos.reponame,
                                              old_node.created_path))
                        title = _('Show the %(range)s differences restricted '
                                  'to %(path)s', range='[%s:%s]' % (
                                      display_rev(old_node.rev),
                                      display_rev(new_node.rev)),
                                  path=new_node.path)
                    info['href'] = href
                    info['title'] = old_node and title
                if change in Changeset.DIFF_CHANGES and not show_diff:
                    info['hide_diff'] = True
            else:
                info = None
            changes.append(info) # the sequence should be immutable

        data.update({'has_diffs': has_diffs, 'changes': changes, 'xhr': xhr,
                     'filestats': filestats, 'annotated': annotated,
                     'files': files,
                     'location': self._get_parent_location(files),
                     'longcol': 'Revision', 'shortcol': 'r'})

        if xhr: # render and return the content only
            stream = Chrome(self.env).render_template(req, 'changeset.html',
                                                      data, fragment=True)
            content = stream.select('//div[@id="content"]')
            str_content = content.render('xhtml', encoding='utf-8')
            req.send_header('Content-Length', len(str_content))
            req.end_headers()
            req.write(str_content)
            raise RequestDone

        return data

    def _render_diff(self, req, filename, repos, data):
        """Raw Unified Diff version"""
        req.send_response(200)
        req.send_header('Content-Type', 'text/x-patch;charset=utf-8')
        req.send_header('Content-Disposition',
                        content_disposition('attachment', filename + '.diff'))
        buf = StringIO()
        mimeview = Mimeview(self.env)

        for old_node, new_node, kind, change in repos.get_changes(
                new_path=data['new_path'], new_rev=data['new_rev'],
                old_path=data['old_path'], old_rev=data['old_rev']):
            # TODO: Property changes

            # Content changes
            if kind == Node.DIRECTORY:
                continue

            new_content = old_content = ''
            new_node_info = old_node_info = ('','')

            if old_node:
                if not old_node.is_viewable(req.perm):
                    continue
                if mimeview.is_binary(old_node.content_type, old_node.path):
                    continue
                old_content = old_node.get_content().read()
                if mimeview.is_binary(content=old_content):
                    continue
                old_node_info = (old_node.path, old_node.rev)
                old_content = mimeview.to_unicode(old_content,
                                                  old_node.content_type)
            if new_node:
                if not new_node.is_viewable(req.perm):
                    continue
                if mimeview.is_binary(new_node.content_type, new_node.path):
                    continue
                new_content = new_node.get_content().read()
                if mimeview.is_binary(content=new_content):
                    continue
                new_node_info = (new_node.path, new_node.rev)
                new_path = new_node.path
                new_content = mimeview.to_unicode(new_content,
                                                  new_node.content_type)
            else:
                old_node_path = repos.normalize_path(old_node.path)
                diff_old_path = repos.normalize_path(data['old_path'])
                new_path = pathjoin(data['new_path'],
                                    old_node_path[len(diff_old_path) + 1:])

            if old_content != new_content:
                options = data['diff']['options']
                context = options.get('contextlines', 3)
                if context < 0 or options.get('contextall'):
                    context = 3 # FIXME: unified_diff bugs with context=None
                ignore_blank_lines = options.get('ignoreblanklines')
                ignore_case = options.get('ignorecase')
                ignore_space = options.get('ignorewhitespace')
                if not old_node_info[0]:
                    old_node_info = new_node_info # support for 'A'dd changes
                buf.write('Index: ' + new_path + CRLF)
                buf.write('=' * 67 + CRLF)
                buf.write('--- %s\t(revision %s)' % old_node_info + CRLF)
                buf.write('+++ %s\t(revision %s)' % new_node_info + CRLF)
                for line in unified_diff(old_content.splitlines(),
                                         new_content.splitlines(), context,
                                         ignore_blank_lines=ignore_blank_lines,
                                         ignore_case=ignore_case,
                                         ignore_space_changes=ignore_space):
                    buf.write(line + CRLF)

        diff_str = buf.getvalue().encode('utf-8')
        req.send_header('Content-Length', len(diff_str))
        req.end_headers()
        req.write(diff_str)
        raise RequestDone

    def _render_zip(self, req, filename, repos, data):
        """ZIP archive containing all the added and/or modified files."""
        req.send_response(200)
        req.send_header('Content-Type', 'application/zip')
        req.send_header('Content-Disposition',
                        content_disposition('attachment', filename + '.zip'))

        from zipfile import ZipFile, ZipInfo, ZIP_DEFLATED as compression

        buf = StringIO()
        zipfile = ZipFile(buf, 'w', compression)
        for old_node, new_node, kind, change in repos.get_changes(
            new_path=data['new_path'], new_rev=data['new_rev'],
            old_path=data['old_path'], old_rev=data['old_rev']):
            if (kind == Node.FILE or kind == Node.DIRECTORY) and \
                    change != Changeset.DELETE \
                    and new_node.is_viewable(req.perm):
                zipinfo = ZipInfo()
                # Note: unicode filenames are not supported by zipfile.
                # UTF-8 is not supported by all Zip tools either,
                # but as some do, UTF-8 is the best option here.
                zipinfo.filename = new_node.path.strip('/').encode('utf-8')
                zipinfo.flag_bits |= 0x800 # filename is encoded with utf-8
                zipinfo.date_time = new_node.last_modified.utctimetuple()[:6]
                zipinfo.compress_type = compression
                # setting zipinfo.external_attr is needed since Python 2.5
                if new_node.isfile:
                    zipinfo.external_attr = 0644 << 16L
                    content = new_node.get_content().read()
                elif new_node.isdir:
                    zipinfo.filename += '/'
                    zipinfo.external_attr = 040755 << 16L
                    content = ''
                zipfile.writestr(zipinfo, content)
        zipfile.close()

        zip_str = buf.getvalue()
        req.send_header("Content-Length", len(zip_str))
        req.end_headers()
        req.write(zip_str)
        raise RequestDone

    def title_for_diff(self, data):
        # TRANSLATOR: 'latest' (revision)
        latest = _('latest')
        if data['new_path'] == data['old_path']:
            # ''diff between 2 revisions'' mode
            return _('Diff [%(old_rev)s:%(new_rev)s] for %(path)s',
                     old_rev=data['old_rev'] or latest,
                     new_rev=data['new_rev'] or latest,
                     path=data['new_path'] or '/')
        else:
            # ''generalized diff'' mode
            return _('Diff from %(old_path)s@%(old_rev)s to %(new_path)s@'
                     '%(new_rev)s',
                     old_path=data['old_path'] or '/',
                     old_rev=data['old_rev'] or latest,
                     new_path=data['new_path'] or '/',
                     new_rev=data['new_rev'] or latest)

    def render_property_diff(self, name, old_node, old_props,
                             new_node, new_props, options):
        """Renders diffs of a node property to HTML."""
        if name in BrowserModule(self.env).hidden_properties:
            return
        candidates = []
        for renderer in self.property_diff_renderers:
            quality = renderer.match_property_diff(name)
            if quality > 0:
                candidates.append((quality, renderer))
        candidates.sort(reverse=True)
        for (quality, renderer) in candidates:
            try:
                return renderer.render_property_diff(name, old_node, old_props,
                                                     new_node, new_props,
                                                     options)
            except Exception, e:
                self.log.warning('Diff rendering failed for property %s with '
                                 'renderer %s: %s', name,
                                 renderer.__class__.__name__,
                                 exception_to_unicode(e, traceback=True))

    def _get_location(self, files):
        """Return the deepest common path for the given files.
           If all the files are actually the same, return that location."""
        if len(files) == 1:
            return files[0]
        else:
            return '/'.join(os.path.commonprefix([f.split('/')
                                                  for f in files]))
    def _get_parent_location(self, files):
        """Only get a location when there are different files,
           otherwise return the empty string."""
        if files:
            files.sort()
            prev = files[0]
            for f in files[1:]:
                if f != prev:
                    return self._get_location(files)
        return ''

    def _prepare_filestats(self):
        filestats = {}
        for chg in Changeset.ALL_CHANGES:
            filestats[chg] = 0
        return filestats

    # ITimelineEventProvider methods

    def get_timeline_filters(self, req):
        if 'CHANGESET_VIEW' in req.perm:
            # Non-'hidden' repositories will be listed as additional
            # repository filters, unless there is only a single repository.
            filters = []
            rm = RepositoryManager(self.env)
            repositories = rm.get_real_repositories()
            if len(repositories) > 1:
                filters = [
                    ('repo-' + repos.reponame,
                     u"\xa0\xa0-\xa0" + (repos.reponame or _('(default)')))
                    for repos in repositories
                    if not as_bool(repos.params.get('hidden'))
                    and repos.is_viewable(req.perm)]
                filters.sort()
                add_script(req, 'common/js/timeline_multirepos.js')
                changeset_label = _('Changesets in all repositories')
            else:
                changeset_label = _('Repository changesets')
            filters.insert(0, ('changeset', changeset_label))
            return filters
        else:
            return []

    def get_timeline_events(self, req, start, stop, filters):
        all_repos = 'changeset' in filters
        repo_filters = set(f for f in filters if f.startswith('repo-'))
        if all_repos or repo_filters:
            show_files = self.timeline_show_files
            show_location = show_files == 'location'
            if show_files in ('-1', 'unlimited'):
                show_files = -1
            elif show_files.isdigit():
                show_files = int(show_files)
            else:
                show_files = 0 # disabled

            if self.timeline_collapse:
                collapse_changesets = lambda c: (c.author, c.message)
            else:
                collapse_changesets = lambda c: c.rev

            uids_seen = {}
            def generate_changesets(repos):
                for _, changesets in groupby(repos.get_changesets(start, stop),
                                             key=collapse_changesets):
                    viewable_changesets = []
                    for cset in changesets:
                        cset_resource = Resource('changeset', cset.rev,
                                                 parent=repos.resource)
                        if cset.is_viewable(req.perm):
                            repos_for_uid = [repos.reponame]
                            uid = repos.get_changeset_uid(cset.rev)
                            if uid:
                                # uid can be seen in multiple repositories
                                if uid in uids_seen:
                                    uids_seen[uid].append(repos.reponame)
                                    continue # already viewable, simply append
                                uids_seen[uid] = repos_for_uid
                            viewable_changesets.append((cset, cset_resource,
                                                        repos_for_uid))
                    if viewable_changesets:
                        cset = viewable_changesets[-1][0]
                        yield ('changeset', cset.date, cset.author,
                               (viewable_changesets,
                                show_location, show_files))

            rm = RepositoryManager(self.env)
            for repos in sorted(rm.get_real_repositories(),
                                key=lambda repos: repos.reponame):
                if all_repos or ('repo-' + repos.reponame) in repo_filters:
                    try:
                        for event in generate_changesets(repos):
                            yield event
                    except TracError, e:
                        self.log.error("Timeline event provider for repository"
                                       " '%s' failed: %r",
                                       repos.reponame, exception_to_unicode(e))

    def render_timeline_event(self, context, field, event):
        changesets, show_location, show_files = event[3]
        cset, cset_resource, repos_for_uid = changesets[0]
        older_cset = changesets[-1][0]
        message = cset.message or ''
        reponame = cset_resource.parent.id
        rev_b, rev_a = cset.rev, older_cset.rev

        if field == 'url':
            if rev_a == rev_b:
                return context.href.changeset(rev_a, reponame or None)
            else:
                return context.href.log(reponame or None, rev=rev_b,
                                        stop_rev=rev_a)

        elif field == 'description':
            if self.wiki_format_messages:
                markup = ''
                if self.timeline_long_messages: # override default flavor
                    context = context.child()
                    context.set_hints(wiki_flavor='html',
                                      preserve_newlines=True)
            else:
                markup = message
                message = None
            if 'BROWSER_VIEW' in context.perm:
                files = []
                if show_location:
                    filestats = self._prepare_filestats()
                    for c, r, repos_for_c in changesets:
                        for chg in c.get_changes():
                            resource = c.resource.parent.child('source',
                                                        chg[0] or '/', r.id)
                            if not 'FILE_VIEW' in context.perm(resource):
                                continue
                            filestats[chg[2]] += 1
                            files.append(chg[0])
                    stats = [(tag.div(class_=kind),
                              tag.span(count, ' ',
                                       count > 1 and
                                       (kind == 'copy' and
                                        'copies' or kind + 's') or kind))
                             for kind in Changeset.ALL_CHANGES
                             for count in (filestats[kind],) if count]
                    markup = tag.ul(
                        tag.li(stats, ' in ',
                               tag.strong(self._get_location(files) or '/')),
                        markup, class_="changes")
                elif show_files:
                    unique_files = set()
                    for c, r, repos_for_c in changesets:
                        for chg in c.get_changes():
                            resource = c.resource.parent.child('source',
                                                        chg[0] or '/', r.id)
                            if not 'FILE_VIEW' in context.perm(resource):
                                continue
                            if show_files > 0 and len(files) > show_files:
                                break
                            unique_files.add((chg[0], chg[2]))
                    files = [tag.li(tag.div(class_=mod), path or '/')
                             for path, mod in sorted(unique_files)]
                    if show_files > 0 and len(files) > show_files:
                        files = files[:show_files] + [tag.li(u'\u2026')]
                    markup = tag(tag.ul(files, class_="changes"), markup)
            if message:
                markup += format_to(self.env, None,
                                    context.child(cset_resource), message)
            return markup

        single = rev_a == rev_b
        if not repos_for_uid[0]:
            repos_for_uid[0] = _('(default)')
        if reponame or len(repos_for_uid) > 1:
            title = ngettext('Changeset in %(repo)s ',
                             'Changesets in %(repo)s ',
                             1 if single else 2, repo=', '.join(repos_for_uid))
        else:
            title = ngettext('Changeset ', 'Changesets ', 1 if single else 2)
        drev_a = older_cset.repos.display_rev(rev_a)
        if single:
            title = tag(title, tag.em('[%s]' % drev_a))
        else:
            drev_b = cset.repos.display_rev(rev_b)
            title = tag(title, tag.em('[%s-%s]' % (drev_a, drev_b)))
        if field == 'title':
            labels = []
            for name, head in cset.get_branches():
                if not head and name in ('default', 'master'):
                    continue
                class_ = 'branch'
                if head:
                    class_ += ' head'
                labels.append(tag.span(name, class_=class_))
            for name in cset.get_tags():
                labels.append(tag.span(name, class_='tag'))
            return title if not labels else tag(title, labels)
        elif field == 'summary':
            return _("%(title)s: %(message)s",
                     title=title, message=shorten_line(message))

    # IWikiSyntaxProvider methods

    CHANGESET_ID = r"(?:[0-9]+|[a-fA-F0-9]{8,})" # only "long enough" hexa ids

    def get_wiki_syntax(self):
        yield (
            # [...] form: start with optional intertrac: [T... or [trac ...
            r"!?\[(?P<it_changeset>%s\s*)" % WikiParser.INTERTRAC_SCHEME +
            # hex digits + optional /path for the restricted changeset
            # + optional query and fragment
            r"%s(?:/[^\]]*)?(?:\?[^\]]*)?(?:#[^\]]*)?\]|" % self.CHANGESET_ID +
            # r... form: allow r1 but not r1:2 (handled by the log syntax)
            r"(?:\b|!)r[0-9]+\b(?!:[0-9])(?:/[a-zA-Z0-9_/+-]+)?",
            lambda x, y, z:
            self._format_changeset_link(x, 'changeset',
                                        y[1:] if y[0] == 'r' else y[1:-1],
                                        y, z))

    def get_link_resolvers(self):
        yield ('changeset', self._format_changeset_link)
        yield ('diff', self._format_diff_link)

    def _format_changeset_link(self, formatter, ns, chgset, label,
                               fullmatch=None):
        intertrac = formatter.shorthand_intertrac_helper(ns, chgset, label,
                                                         fullmatch)
        if intertrac:
            return intertrac

        # identifying repository
        rm = RepositoryManager(self.env)
        chgset, params, fragment = formatter.split_link(chgset)
        sep = chgset.find('/')
        if sep > 0:
            rev, path = chgset[:sep], chgset[sep:]
        else:
            rev, path = chgset, '/'
        try:
            reponame, repos, path = rm.get_repository_by_path(path)
            if not reponame:
                reponame = rm.get_default_repository(formatter.context)
                if reponame is not None:
                    repos = rm.get_repository(reponame)
            if path == '/':
                path = None

            # rendering changeset link
            if repos:
                changeset = repos.get_changeset(rev)
                if changeset.is_viewable(formatter.perm):
                    href = formatter.href.changeset(rev,
                                                    repos.reponame or None,
                                                    path)
                    return tag.a(label, class_="changeset",
                                 title=shorten_line(changeset.message),
                                 href=href + params + fragment)
                errmsg = _("No permission to view changeset %(rev)s "
                           "on %(repos)s", rev=rev,
                           repos=reponame or _('(default)'))
            elif reponame:
                errmsg = _("Repository '%(repo)s' not found", repo=reponame)
            else:
                errmsg = _("No default repository defined")
        except TracError, e:
            errmsg = to_unicode(e)
        return tag.a(label, class_="missing changeset", title=errmsg)

    def _format_diff_link(self, formatter, ns, target, label):
        params, query, fragment = formatter.split_link(target)
        def pathrev(path):
            if '@' in path:
                return path.split('@', 1)
            else:
                return (path, None)
        if '//' in params:
            p1, p2 = params.split('//', 1)
            old, new = pathrev(p1), pathrev(p2)
            data = {'old_path': old[0], 'old_rev': old[1],
                    'new_path': new[0], 'new_rev': new[1]}
        else:
            old_path, old_rev = pathrev(params)
            new_rev = None
            if old_rev and ':' in old_rev:
                old_rev, new_rev = old_rev.split(':', 1)
            data = {'old_path': old_path, 'old_rev': old_rev,
                    'new_path': old_path, 'new_rev': new_rev}
        title = self.title_for_diff(data)
        href = None
        if any(data.values()):
            if query:
                query = '&' + query[1:]
            href = formatter.href.changeset(new_path=data['new_path'] or None,
                                            new=data['new_rev'],
                                            old_path=data['old_path'] or None,
                                            old=data['old_rev']) + query
        return tag.a(label, class_="changeset", title=title, href=href)

    # ISearchSource methods

    ### FIXME: move this specific implementation into cache.py

    def get_search_filters(self, req):
        if 'CHANGESET_VIEW' in req.perm:
            yield ('changeset', _('Changesets'))

    def get_search_results(self, req, terms, filters):
        if not 'changeset' in filters:
            return
        rm = RepositoryManager(self.env)
        repositories = dict((repos.params['id'], repos)
                            for repos in rm.get_real_repositories())
        with self.env.db_query as db:
            sql, args = search_to_sql(db, ['rev', 'message', 'author'], terms)
            for id, rev, ts, author, log in db("""
                    SELECT repos, rev, time, author, message
                    FROM revision WHERE """ + sql,
                    args):
                try:
                    rev = int(rev)
                except ValueError:
                    pass
                repos = repositories.get(id)
                if not repos:
                    continue # revisions for a no longer active repository
                cset = repos.resource.child('changeset', rev)
                if 'CHANGESET_VIEW' in req.perm(cset):
                    yield (req.href.changeset(rev, repos.reponame or None),
                           '[%s]: %s' % (rev, shorten_line(log)),
                           from_utimestamp(ts), author,
                           shorten_result(log, terms))


class AnyDiffModule(Component):

    implements(IRequestHandler)

    # IRequestHandler methods

    def match_request(self, req):
        return req.path_info == '/diff'

    def process_request(self, req):
        rm = RepositoryManager(self.env)

        if req.get_header('X-Requested-With') == 'XMLHttpRequest':
            dirname, prefix = posixpath.split(req.args.get('q'))
            prefix = prefix.lower()
            reponame, repos, path = rm.get_repository_by_path(dirname)
            # an entry is a (isdir, name, path) tuple
            def kind_order(entry):
                return (not entry[0], embedded_numbers(entry[1]))

            entries = []
            if repos:
                entries.extend((e.isdir, e.name,
                                '/' + pathjoin(repos.reponame, e.path))
                               for e in repos.get_node(path).get_entries()
                               if e.is_viewable(req.perm))
            if not reponame:
                entries.extend((True, repos.reponame, '/' + repos.reponame)
                               for repos in rm.get_real_repositories()
                               if repos.is_viewable(req.perm))

            elem = tag.ul(
                [tag.li(tag.b(path) if isdir else path)
                 for (isdir, name, path) in sorted(entries, key=kind_order)
                 if name.lower().startswith(prefix)])

            xhtml = elem.generate().render('xhtml', encoding='utf-8')
            req.send_header('Content-Length', len(xhtml))
            req.write(xhtml)
            return

        # -- retrieve arguments
        new_path = req.args.get('new_path')
        new_rev = req.args.get('new_rev')
        old_path = req.args.get('old_path')
        old_rev = req.args.get('old_rev')

        # -- normalize and prepare rendering
        new_reponame, new_repos, new_path = \
            rm.get_repository_by_path(new_path)
        old_reponame, old_repos, old_path = \
            rm.get_repository_by_path(old_path)

        data = {}
        if new_repos:
            data.update(new_path='/' + pathjoin(new_repos.reponame, new_path),
                        new_rev=new_repos.normalize_rev(new_rev))
        else:
            data.update(new_path=req.args.get('new_path'), new_rev=new_rev)
        if old_repos:
            data.update(old_path='/' + pathjoin(old_repos.reponame, old_path),
                        old_rev=old_repos.normalize_rev(old_rev))
        else:
            data.update(old_path=req.args.get('old_path'), old_rev=old_rev)

        add_script(req, 'common/js/suggest.js')
        return 'diff_form.html', data, None

########NEW FILE########
__FILENAME__ = log
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005-2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christian Boos <cboos@edgewall.org>

import re

from genshi.core import Markup
from genshi.builder import tag

from trac.config import IntOption, ListOption
from trac.core import *
from trac.perm import IPermissionRequestor
from trac.resource import ResourceNotFound
from trac.util import Ranges
from trac.util.text import to_unicode, wrap
from trac.util.translation import _
from trac.versioncontrol.api import (RepositoryManager, Changeset,
                                     NoSuchChangeset)
from trac.versioncontrol.web_ui.changeset import ChangesetModule
from trac.versioncontrol.web_ui.util import *
from trac.web import IRequestHandler
from trac.web.chrome import (Chrome, INavigationContributor, add_ctxtnav,
                             add_link, add_script, add_script_data,
                             add_stylesheet, auth_link, web_context)
from trac.wiki import IWikiSyntaxProvider, WikiParser


class LogModule(Component):

    implements(INavigationContributor, IPermissionRequestor, IRequestHandler,
               IWikiSyntaxProvider)

    default_log_limit = IntOption('revisionlog', 'default_log_limit', 100,
        """Default value for the limit argument in the TracRevisionLog.
        (''since 0.11'')""")

    graph_colors = ListOption('revisionlog', 'graph_colors',
        ['#cc0', '#0c0', '#0cc', '#00c', '#c0c', '#c00'],
        doc="""Comma-separated list of colors to use for the TracRevisionLog
        graph display. (''since 1.0'')""")

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'browser'

    def get_navigation_items(self, req):
        return []

    # IPermissionRequestor methods

    def get_permission_actions(self):
        return ['LOG_VIEW']

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/log(/.*)?$', req.path_info)
        if match:
            req.args['path'] = match.group(1) or '/'
            return True

    def process_request(self, req):
        req.perm.require('LOG_VIEW')

        mode = req.args.get('mode', 'stop_on_copy')
        path = req.args.get('path', '/')
        rev = req.args.get('rev')
        stop_rev = req.args.get('stop_rev')
        revs = req.args.get('revs')
        format = req.args.get('format')
        verbose = req.args.get('verbose')
        limit = int(req.args.get('limit') or self.default_log_limit)

        rm = RepositoryManager(self.env)
        reponame, repos, path = rm.get_repository_by_path(path)

        if not repos:
            raise ResourceNotFound(_("Repository '%(repo)s' not found",
                                   repo=reponame))

        if reponame != repos.reponame:  # Redirect alias
            qs = req.query_string
            req.redirect(req.href.log(repos.reponame or None, path)
                         + ('?' + qs if qs else ''))

        normpath = repos.normalize_path(path)
        # if `revs` parameter is given, then we're restricted to the
        # corresponding revision ranges.
        # If not, then we're considering all revisions since `rev`,
        # on that path, in which case `revranges` will be None.
        revranges = None
        if revs:
            try:
                revranges = Ranges(revs)
                rev = revranges.b
            except ValueError:
                pass
        rev = unicode(repos.normalize_rev(rev))
        display_rev = repos.display_rev

        # The `history()` method depends on the mode:
        #  * for ''stop on copy'' and ''follow copies'', it's `Node.history()`
        #    unless explicit ranges have been specified
        #  * for ''show only add, delete'' we're using
        #   `Repository.get_path_history()`
        cset_resource = repos.resource.child('changeset')
        show_graph = False
        if mode == 'path_history':
            def history():
                for h in repos.get_path_history(path, rev):
                    if 'CHANGESET_VIEW' in req.perm(cset_resource(id=h[1])):
                        yield h
        elif revranges:
            def history():
                prevpath = path
                expected_next_item = None
                ranges = list(revranges.pairs)
                ranges.reverse()
                for (a, b) in ranges:
                    a = repos.normalize_rev(a)
                    b = repos.normalize_rev(b)
                    while not repos.rev_older_than(b, a):
                        node = get_existing_node(req, repos, prevpath, b)
                        node_history = list(node.get_history(2))
                        p, rev, chg = node_history[0]
                        if repos.rev_older_than(rev, a):
                            break # simply skip, no separator
                        if 'CHANGESET_VIEW' in req.perm(cset_resource(id=rev)):
                            if expected_next_item:
                                # check whether we're continuing previous range
                                np, nrev, nchg = expected_next_item
                                if rev != nrev: # no, we need a separator
                                    yield (np, nrev, None)
                            yield node_history[0]
                        prevpath = node_history[-1][0] # follow copy
                        b = repos.previous_rev(rev)
                        if len(node_history) > 1:
                            expected_next_item = node_history[-1]
                        else:
                            expected_next_item = None
                if expected_next_item:
                    yield (expected_next_item[0], expected_next_item[1], None)
        else:
            show_graph = path == '/' and not verbose \
                         and not repos.has_linear_changesets
            def history():
                node = get_existing_node(req, repos, path, rev)
                for h in node.get_history():
                    if 'CHANGESET_VIEW' in req.perm(cset_resource(id=h[1])):
                        yield h

        # -- retrieve history, asking for limit+1 results
        info = []
        depth = 1
        previous_path = normpath
        count = 0
        for old_path, old_rev, old_chg in history():
            if stop_rev and repos.rev_older_than(old_rev, stop_rev):
                break
            old_path = repos.normalize_path(old_path)

            item = {
                'path': old_path, 'rev': old_rev, 'existing_rev': old_rev,
                'change': old_chg, 'depth': depth,
            }

            if old_chg == Changeset.DELETE:
                item['existing_rev'] = repos.previous_rev(old_rev, old_path)
            if not (mode == 'path_history' and old_chg == Changeset.EDIT):
                info.append(item)
            if old_path and old_path != previous_path and \
                    not (mode == 'path_history' and old_path == normpath):
                depth += 1
                item['depth'] = depth
                item['copyfrom_path'] = old_path
                if mode == 'stop_on_copy':
                    break
                elif mode == 'path_history':
                    depth -= 1
            if old_chg is None: # separator entry
                stop_limit = limit
            else:
                count += 1
                stop_limit = limit + 1
            if count >= stop_limit:
                break
            previous_path = old_path
        if info == []:
            node = get_existing_node(req, repos, path, rev)
            if repos.rev_older_than(stop_rev, node.created_rev):
                # FIXME: we should send a 404 error here
                raise TracError(_("The file or directory '%(path)s' doesn't "
                    "exist at revision %(rev)s or at any previous revision.",
                    path=path, rev=display_rev(rev)), _('Nonexistent path'))

        # Generate graph data
        graph = {}
        if show_graph:
            threads, vertices, columns = \
                make_log_graph(repos, (item['rev'] for item in info))
            graph.update(threads=threads, vertices=vertices, columns=columns,
                         colors=self.graph_colors,
                         line_width=0.04, dot_radius=0.1)
            add_script(req, 'common/js/excanvas.js', ie_if='IE')
            add_script(req, 'common/js/log_graph.js')
            add_script_data(req, graph=graph)

        def make_log_href(path, **args):
            link_rev = rev
            if rev == str(repos.youngest_rev):
                link_rev = None
            params = {'rev': link_rev, 'mode': mode, 'limit': limit}
            params.update(args)
            if verbose:
                params['verbose'] = verbose
            return req.href.log(repos.reponame or None, path, **params)

        if format in ('rss', 'changelog'):
            info = [i for i in info if i['change']] # drop separators
            if info and count > limit:
                del info[-1]
        elif info and count >= limit:
            # stop_limit reached, there _might_ be some more
            next_rev = info[-1]['rev']
            next_path = info[-1]['path']
            next_revranges = None
            if revranges:
                next_revranges = str(revranges.truncate(next_rev))
            if next_revranges or not revranges:
                older_revisions_href = make_log_href(next_path, rev=next_rev,
                                                     revs=next_revranges)
                add_link(req, 'next', older_revisions_href,
                    _('Revision Log (restarting at %(path)s, rev. %(rev)s)',
                    path=next_path, rev=display_rev(next_rev)))
            # only show fully 'limit' results, use `change == None` as a marker
            info[-1]['change'] = None

        revisions = [i['rev'] for i in info]
        changes = get_changes(repos, revisions, self.log)
        extra_changes = {}

        if format == 'changelog':
            for rev in revisions:
                changeset = changes[rev]
                cs = {}
                cs['message'] = wrap(changeset.message, 70,
                                     initial_indent='\t',
                                     subsequent_indent='\t')
                files = []
                actions = []
                for cpath, kind, chg, bpath, brev in changeset.get_changes():
                    files.append(bpath if chg == Changeset.DELETE else cpath)
                    actions.append(chg)
                cs['files'] = files
                cs['actions'] = actions
                extra_changes[rev] = cs

        data = {
            'context': web_context(req, 'source', path, parent=repos.resource),
            'reponame': repos.reponame or None, 'repos': repos,
            'path': path, 'rev': rev, 'stop_rev': stop_rev,
            'display_rev': display_rev, 'revranges': revranges,
            'mode': mode, 'verbose': verbose, 'limit' : limit,
            'items': info, 'changes': changes, 'extra_changes': extra_changes,
            'graph': graph,
            'wiki_format_messages':
            self.config['changeset'].getbool('wiki_format_messages')
        }

        if format == 'changelog':
            return 'revisionlog.txt', data, 'text/plain'
        elif format == 'rss':
            data['email_map'] = Chrome(self.env).get_email_map()
            data['context'] = web_context(req, 'source',
                                          path, parent=repos.resource,
                                          absurls=True)
            return 'revisionlog.rss', data, 'application/rss+xml'

        item_ranges = []
        range = []
        for item in info:
            if item['change'] is None: # separator
                if range: # start new range
                    range.append(item)
                    item_ranges.append(range)
                    range = []
            else:
                range.append(item)
        if range:
            item_ranges.append(range)
        data['item_ranges'] = item_ranges

        add_stylesheet(req, 'common/css/diff.css')
        add_stylesheet(req, 'common/css/browser.css')

        path_links = get_path_links(req.href, repos.reponame, path, rev)
        if path_links:
            data['path_links'] = path_links
        if path != '/':
            add_link(req, 'up', path_links[-2]['href'], _('Parent directory'))

        rss_href = make_log_href(path, format='rss', revs=revs,
                                 stop_rev=stop_rev)
        add_link(req, 'alternate', auth_link(req, rss_href), _('RSS Feed'),
                 'application/rss+xml', 'rss')
        changelog_href = make_log_href(path, format='changelog', revs=revs,
                                       stop_rev=stop_rev)
        add_link(req, 'alternate', changelog_href, _('ChangeLog'), 'text/plain')

        add_ctxtnav(req, _('View Latest Revision'),
                    href=req.href.browser(repos.reponame or None, path))
        if 'next' in req.chrome['links']:
            next = req.chrome['links']['next'][0]
            add_ctxtnav(req, tag.span(tag.a(_('Older Revisions'),
                                            href=next['href']),
                                      Markup(' &rarr;')))

        return 'revisionlog.html', data, None

    # IWikiSyntaxProvider methods

    REV_RANGE = r"(?:%s|%s)" % (Ranges.RE_STR, ChangesetModule.CHANGESET_ID)
    #                          int rev ranges or any kind of rev

    def get_wiki_syntax(self):
        yield (
            # [...] form, starts with optional intertrac: [T... or [trac ...
            r"!?\[(?P<it_log>%s\s*)" % WikiParser.INTERTRAC_SCHEME +
            # <from>:<to> + optional path restriction
            r"(?P<log_revs>%s)(?P<log_path>[/?][^\]]*)?\]" % self.REV_RANGE,
            lambda x, y, z: self._format_link(x, 'log1', y[1:-1], y, z))
        yield (
            # r<from>:<to> form + optional path restriction (no intertrac)
            r"(?:\b|!)r%s\b(?:/[a-zA-Z0-9_/+-]+)?" % Ranges.RE_STR,
            lambda x, y, z: self._format_link(x, 'log2', '@' + y[1:], y))

    def get_link_resolvers(self):
        yield ('log', self._format_link)

    def _format_link(self, formatter, ns, match, label, fullmatch=None):
        if ns == 'log1':
            groups = fullmatch.groupdict()
            it_log = groups.get('it_log')
            revs = groups.get('log_revs')
            path = groups.get('log_path') or '/'
            target = '%s%s@%s' % (it_log, path, revs)
            # prepending it_log is needed, as the helper expects it there
            intertrac = formatter.shorthand_intertrac_helper(
                'log', target, label, fullmatch)
            if intertrac:
                return intertrac
            path, query, fragment = formatter.split_link(path)
        else:
            assert ns in ('log', 'log2')
            if ns == 'log':
                match, query, fragment = formatter.split_link(match)
            else:
                query = fragment = ''
                match = ''.join(reversed(match.split('/', 1)))
            path = match
            revs = ''
            if self.LOG_LINK_RE.match(match):
                indexes = [sep in match and match.index(sep) for sep in ':@']
                idx = min([i for i in indexes if i is not False])
                path, revs = match[:idx], match[idx+1:]

        rm = RepositoryManager(self.env)
        try:
            reponame, repos, path = rm.get_repository_by_path(path)
            if not reponame:
                reponame = rm.get_default_repository(formatter.context)
                if reponame is not None:
                    repos = rm.get_repository(reponame)

            if repos:
                revranges = None
                if any(c for c in ':-,' if c in revs):
                    revranges = self._normalize_ranges(repos, path, revs)
                    revs = None
                if 'LOG_VIEW' in formatter.perm:
                    if revranges:
                        href = formatter.href.log(repos.reponame or None,
                                                  path or '/',
                                                  revs=str(revranges))
                    else:
                        try:
                            rev = repos.normalize_rev(revs)
                        except NoSuchChangeset:
                            rev = None
                        href = formatter.href.log(repos.reponame or None,
                                                  path or '/', rev=rev)
                    if query and (revranges or revs):
                        query = '&' + query[1:]
                    return tag.a(label, class_='source',
                                 href=href + query + fragment)
                errmsg = _("No permission to view change log")
            elif reponame:
                errmsg = _("Repository '%(repo)s' not found", repo=reponame)
            else:
                errmsg = _("No default repository defined")
        except TracError, e:
            errmsg = to_unicode(e)
        return tag.a(label, class_='missing source', title=errmsg)

    LOG_LINK_RE = re.compile(r"([^@:]*)[@:]%s?" % REV_RANGE)

    def _normalize_ranges(self, repos, path, revs):
        ranges = revs.replace(':', '-')
        try:
            # fast path; only numbers
            return Ranges(ranges, reorder=True)
        except ValueError:
            # slow path, normalize each rev
            splitted_ranges = re.split(r'([-,])', ranges)
            try:
                revs = [repos.normalize_rev(r) for r in splitted_ranges[::2]]
            except NoSuchChangeset:
                return None
            seps = splitted_ranges[1::2] + ['']
            ranges = ''.join([str(rev)+sep for rev, sep in zip(revs, seps)])
            return Ranges(ranges)

########NEW FILE########
__FILENAME__ = main
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import pkg_resources

from trac.core import *
from trac.web.chrome import ITemplateProvider


class VersionControlUI(Component):

    implements(ITemplateProvider)

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        return [pkg_resources.resource_filename('trac.versioncontrol',
                                                'templates')]

########NEW FILE########
__FILENAME__ = wikisyntax
# -*- encoding: utf-8 -*-

import unittest

from trac.test import Mock
from trac.versioncontrol import NoSuchChangeset, NoSuchNode
from trac.versioncontrol.api import *
from trac.versioncontrol.web_ui import *
from trac.wiki.tests import formatter


def _get_changeset(rev):
    if rev == '1':
        return Mock(message="start", is_viewable=lambda perm: True)
    else:
        raise NoSuchChangeset(rev)

def _normalize_rev(rev):
    try:
        return int(rev)
    except ValueError:
        if rev == 'head':
            return '200'
        else:
            raise NoSuchChangeset(rev)

def _get_node(path, rev=None):
    if path == 'foo':
        return Mock(path=path, rev=rev, isfile=False,
                    is_viewable=lambda resource: True)
    elif path == 'missing/file':
        raise NoSuchNode(path, rev)
    else:
        return Mock(path=path, rev=rev, isfile=True,
                    is_viewable=lambda resource: True)

def _get_repository(reponame):
    return Mock(reponame=reponame, youngest_rev='200',
                get_changeset=_get_changeset,
                normalize_rev=_normalize_rev,
                get_node=_get_node)

def repository_setup(tc):
    setattr(tc.env, 'get_repository', _get_repository)
    setattr(RepositoryManager(tc.env), 'get_repository', _get_repository)


CHANGESET_TEST_CASES = u"""
============================== changeset: link resolver
changeset:1
changeset:12
changeset:abc
changeset:1, changeset:1/README.txt
------------------------------
<p>
<a class="changeset" href="/changeset/1" title="start">changeset:1</a>
<a class="missing changeset" title="No changeset 12 in the repository">changeset:12</a>
<a class="missing changeset" title="No changeset abc in the repository">changeset:abc</a>
<a class="changeset" href="/changeset/1" title="start">changeset:1</a>, <a class="changeset" href="/changeset/1/README.txt" title="start">changeset:1/README.txt</a>
</p>
------------------------------
============================== changeset: link resolver + query and fragment
changeset:1?format=diff
changeset:1#file0
------------------------------
<p>
<a class="changeset" href="/changeset/1?format=diff" title="start">changeset:1?format=diff</a>
<a class="changeset" href="/changeset/1#file0" title="start">changeset:1#file0</a>
</p>
------------------------------
============================== changeset shorthand syntax
[1], r1
[12], r12, rABC
[1/README.txt], r1/trunk, rABC/trunk
------------------------------
<p>
<a class="changeset" href="/changeset/1" title="start">[1]</a>, <a class="changeset" href="/changeset/1" title="start">r1</a>
<a class="missing changeset" title="No changeset 12 in the repository">[12]</a>, <a class="missing changeset" title="No changeset 12 in the repository">r12</a>, rABC
<a class="changeset" href="/changeset/1/README.txt" title="start">[1/README.txt]</a>, <a class="changeset" href="/changeset/1/trunk" title="start">r1/trunk</a>, rABC/trunk
</p>
------------------------------
============================== changeset shorthand syntax + query and fragment
[1?format=diff]
[1#file0]
[1/README.txt?format=diff]
[1/README.txt#file0]
------------------------------
<p>
<a class="changeset" href="/changeset/1?format=diff" title="start">[1?format=diff]</a>
<a class="changeset" href="/changeset/1#file0" title="start">[1#file0]</a>
<a class="changeset" href="/changeset/1/README.txt?format=diff" title="start">[1/README.txt?format=diff]</a>
<a class="changeset" href="/changeset/1/README.txt#file0" title="start">[1/README.txt#file0]</a>
</p>
------------------------------
============================== escaping the above
![1], !r1
------------------------------
<p>
[1], r1
</p>
------------------------------
============================== unicode digits
[], r, [ABCD]
------------------------------
<p>
[], r, [ABCD]
</p>
------------------------------
============================== Link resolver counter examples
Change:[10] There should be a link to changeset [10]

rfc and rfc:4180 should not be changeset links, neither should rfc4180
------------------------------
<p>
Change:<a class="missing changeset" title="No changeset 10 in the repository">[10]</a> There should be a link to changeset <a class="missing changeset" title="No changeset 10 in the repository">[10]</a>
</p>
<p>
rfc and rfc:4180 should not be changeset links, neither should rfc4180
</p>
------------------------------
Change:<a class="missing changeset" title="No changeset 10 in the repository">[10]</a> There should be a link to changeset <a class="missing changeset" title="No changeset 10 in the repository">[10]</a>

rfc and rfc:4180 should not be changeset links, neither should rfc4180
============================== InterTrac for changesets
trac:changeset:2081
[trac:changeset:2081 Trac r2081]
------------------------------
<p>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/changeset%3A2081" title="changeset:2081 in Trac's Trac"><span class="icon"></span>trac:changeset:2081</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/changeset%3A2081" title="changeset:2081 in Trac's Trac"><span class="icon"></span>Trac r2081</a>
</p>
------------------------------
============================== Changeset InterTrac shorthands
[T2081]
[trac 2081]
[trac 2081/trunk]
T:r2081
------------------------------
<p>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/changeset%3A2081" title="changeset:2081 in Trac's Trac"><span class="icon"></span>[T2081]</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/changeset%3A2081" title="changeset:2081 in Trac's Trac"><span class="icon"></span>[trac 2081]</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/changeset%3A2081/trunk" title="changeset:2081/trunk in Trac\'s Trac"><span class="icon"></span>[trac 2081/trunk]</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/r2081" title="r2081 in Trac's Trac"><span class="icon"></span>T:r2081</a>
</p>
------------------------------
""" #"


LOG_TEST_CASES = u"""
============================== Log range TracLinks
[1:2], r1:2, [12:23], r12:23
[1:2/trunk], r1:2/trunk
[2:1/trunk] reversed, r2:1/trunk reversed
------------------------------
<p>
<a class="source" href="/log/?revs=1-2">[1:2]</a>, <a class="source" href="/log/?revs=1-2">r1:2</a>, <a class="source" href="/log/?revs=12-23">[12:23]</a>, <a class="source" href="/log/?revs=12-23">r12:23</a>
<a class="source" href="/log/trunk?revs=1-2">[1:2/trunk]</a>, <a class="source" href="/log/trunk?revs=1-2">r1:2/trunk</a>
<a class="source" href="/log/trunk?revs=1-2">[2:1/trunk]</a> reversed, <a class="source" href="/log/trunk?revs=1-2">r2:1/trunk</a> reversed
</p>
------------------------------
============================== Big ranges (#9955 regression)
[1234567890:12345678901]
------------------------------
<p>
<a class="source" href="/log/?revs=1234567890-12345678901">[1234567890:12345678901]</a>
</p>
------------------------------
<a class="source" href="/log/?revs=1234567890-12345678901">[1234567890:12345678901]</a>
============================== Escaping Log range TracLinks
![1:2], !r1:2, ![12:23], !r12:23
------------------------------
<p>
[1:2], r1:2, [12:23], r12:23
</p>
------------------------------
[1:2], r1:2, [12:23], r12:23
============================== log: link resolver
log:@12
log:trunk
log:trunk@12
log:trunk@12:23
log:trunk@12-23
log:trunk:12:23
log:trunk:12-23
log:trunk:12-head
log:trunk:12@23 (bad, but shouldn't error out)
------------------------------
<p>
<a class="source" href="/log/?rev=12">log:@12</a>
<a class="source" href="/log/trunk">log:trunk</a>
<a class="source" href="/log/trunk?rev=12">log:trunk@12</a>
<a class="source" href="/log/trunk?revs=12-23">log:trunk@12:23</a>
<a class="source" href="/log/trunk?revs=12-23">log:trunk@12-23</a>
<a class="source" href="/log/trunk?revs=12-23">log:trunk:12:23</a>
<a class="source" href="/log/trunk?revs=12-23">log:trunk:12-23</a>
<a class="source" href="/log/trunk?revs=12-200">log:trunk:12-head</a>
<a class="source" href="/log/trunk">log:trunk:12@23</a> (bad, but shouldn't error out)
</p>
------------------------------
============================== log: link resolver + query
log:?limit=10
log:@12?limit=10
log:trunk?limit=10
log:trunk@12?limit=10
[10:20?verbose=yes&format=changelog]
[10:20/trunk?verbose=yes&format=changelog]
------------------------------
<p>
<a class="source" href="/log/?limit=10">log:?limit=10</a>
<a class="source" href="/log/?rev=12&amp;limit=10">log:@12?limit=10</a>
<a class="source" href="/log/trunk?limit=10">log:trunk?limit=10</a>
<a class="source" href="/log/trunk?rev=12&amp;limit=10">log:trunk@12?limit=10</a>
<a class="source" href="/log/?revs=10-20&amp;verbose=yes&amp;format=changelog">[10:20?verbose=yes&amp;format=changelog]</a>
<a class="source" href="/log/trunk?revs=10-20&amp;verbose=yes&amp;format=changelog">[10:20/trunk?verbose=yes&amp;format=changelog]</a>
</p>
------------------------------
============================== Multiple Log ranges
r12:20,25,35:56,68,69,100-120
[12:20,25,35:56,68,69,100-120]
[12:20,25,88:head,68,69] (not supported)
------------------------------
<p>
<a class="source" href="/log/?revs=12-20%2C25%2C35-56%2C68-69%2C100-120">r12:20,25,35:56,68,69,100-120</a>
<a class="source" href="/log/?revs=12-20%2C25%2C35-56%2C68-69%2C100-120">[12:20,25,35:56,68,69,100-120]</a>
[12:20,25,88:head,68,69] (not supported)
</p>
------------------------------
============================== Link resolver counter examples
rfc:4180 should not be a log link
------------------------------
<p>
rfc:4180 should not be a log link
</p>
------------------------------
============================== Log range InterTrac shorthands
[T3317:3318]
[trac 3317:3318]
[trac 3317:3318/trunk]
------------------------------
<p>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/log%3A/%403317%3A3318" title="log:/@3317:3318 in Trac\'s Trac"><span class="icon"></span>[T3317:3318]</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/log%3A/%403317%3A3318" title="log:/@3317:3318 in Trac\'s Trac"><span class="icon"></span>[trac 3317:3318]</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/log%3A/trunk%403317%3A3318" title="log:/trunk@3317:3318 in Trac\'s Trac"><span class="icon"></span>[trac 3317:3318/trunk]</a>
</p>
------------------------------
============================== Log range with unicode digits
r:,,-
[:,,-]
[T:]
[trac :]
------------------------------
<p>
r:,,-
[:,,-]
[T:]
[trac :]
</p>
------------------------------
"""


DIFF_TEST_CASES = u"""
============================== diff: link resolver
diff:trunk//branch
diff:trunk@12//branch@23
diff:trunk@12:23
diff:@12:23
------------------------------
<p>
<a class="changeset" href="/changeset?new_path=branch&amp;old_path=trunk" title="Diff from trunk@latest to branch@latest">diff:trunk//branch</a>
<a class="changeset" href="/changeset?new=23&amp;new_path=branch&amp;old=12&amp;old_path=trunk" title="Diff from trunk@12 to branch@23">diff:trunk@12//branch@23</a>
<a class="changeset" href="/changeset?new=23&amp;new_path=trunk&amp;old=12&amp;old_path=trunk" title="Diff [12:23] for trunk">diff:trunk@12:23</a>
<a class="changeset" href="/changeset?new=23&amp;old=12" title="Diff [12:23] for /">diff:@12:23</a>
</p>
------------------------------
============================== diff: link resolver + query
diff:trunk//branch?format=diff
------------------------------
<p>
<a class="changeset" href="/changeset?new_path=branch&amp;old_path=trunk&amp;format=diff" title="Diff from trunk@latest to branch@latest">diff:trunk//branch?format=diff</a>
</p>
------------------------------
============================== diff: link, empty diff
diff://
------------------------------
<p>
<a class="changeset" title="Diff [latest:latest] for /">diff://</a>
</p>
------------------------------
"""


SOURCE_TEST_CASES = u"""
============================== source: link resolver
source:/foo/bar
source:/foo/bar#42   # no long works as rev spec
source:/foo/bar#head #
source:/foo/bar@42
source:/foo/bar@head
source:/foo%20bar/baz%2Bquux
source:@42
source:/foo/bar@42#L20
source:/foo/bar@head#L20
source:/foo/bar@#L20
source:/missing/file
------------------------------
<p>
<a class="source" href="/browser/foo/bar">source:/foo/bar</a><a class="trac-rawlink" href="/export/HEAD/foo/bar" title="Download"></a>
<a class="source" href="/browser/foo/bar#42">source:/foo/bar#42</a><a class="trac-rawlink" href="/export/HEAD/foo/bar#42" title="Download"></a>   # no long works as rev spec
<a class="source" href="/browser/foo/bar#head">source:/foo/bar#head</a><a class="trac-rawlink" href="/export/HEAD/foo/bar#head" title="Download"></a> #
<a class="source" href="/browser/foo/bar?rev=42">source:/foo/bar@42</a><a class="trac-rawlink" href="/export/42/foo/bar" title="Download"></a>
<a class="source" href="/browser/foo/bar?rev=head">source:/foo/bar@head</a><a class="trac-rawlink" href="/export/head/foo/bar" title="Download"></a>
<a class="source" href="/browser/foo%2520bar/baz%252Bquux">source:/foo%20bar/baz%2Bquux</a><a class="trac-rawlink" href="/export/HEAD/foo%2520bar/baz%252Bquux" title="Download"></a>
<a class="source" href="/browser/?rev=42">source:@42</a><a class="trac-rawlink" href="/export/42/" title="Download"></a>
<a class="source" href="/browser/foo/bar?rev=42#L20">source:/foo/bar@42#L20</a><a class="trac-rawlink" href="/export/42/foo/bar#L20" title="Download"></a>
<a class="source" href="/browser/foo/bar?rev=head#L20">source:/foo/bar@head#L20</a><a class="trac-rawlink" href="/export/head/foo/bar#L20" title="Download"></a>
<a class="source" href="/browser/foo/bar#L20">source:/foo/bar@#L20</a><a class="trac-rawlink" href="/export/HEAD/foo/bar#L20" title="Download"></a>
<a class="missing source">source:/missing/file</a>
</p>
------------------------------
============================== source: link resolver + query
source:/foo?order=size&desc=1
source:/foo/bar?format=raw
------------------------------
<p>
<a class="source" href="/browser/foo?order=size&amp;desc=1">source:/foo?order=size&amp;desc=1</a>
<a class="source" href="/browser/foo/bar?format=raw">source:/foo/bar?format=raw</a><a class="trac-rawlink" href="/export/HEAD/foo/bar" title="Download"></a>
</p>
------------------------------
============================== source: provider, with quoting
source:'even with whitespaces'
source:"even with whitespaces"
[source:'even with whitespaces' Path with spaces]
[source:"even with whitespaces" Path with spaces]
------------------------------
<p>
<a class="source" href="/browser/even%20with%20whitespaces">source:'even with whitespaces'</a><a class="trac-rawlink" href="/export/HEAD/even%20with%20whitespaces" title="Download"></a>
<a class="source" href="/browser/even%20with%20whitespaces">source:"even with whitespaces"</a><a class="trac-rawlink" href="/export/HEAD/even%20with%20whitespaces" title="Download"></a>
<a class="source" href="/browser/even%20with%20whitespaces">Path with spaces</a><a class="trac-rawlink" href="/export/HEAD/even%20with%20whitespaces" title="Download"></a>
<a class="source" href="/browser/even%20with%20whitespaces">Path with spaces</a><a class="trac-rawlink" href="/export/HEAD/even%20with%20whitespaces" title="Download"></a>
</p>
------------------------------
============================== export: link resolver
export:/foo/bar.html
export:123:/foo/pict.gif
export:/foo/pict.gif@123
------------------------------
<p>
<a class="export" href="/export/HEAD/foo/bar.html" title="Download">export:/foo/bar.html</a>
<a class="export" href="/export/123/foo/pict.gif" title="Download">export:123:/foo/pict.gif</a>
<a class="export" href="/export/123/foo/pict.gif" title="Download">export:/foo/pict.gif@123</a>
</p>
------------------------------
============================== export: link resolver + fragment
export:/foo/bar.html#header
------------------------------
<p>
<a class="export" href="/export/HEAD/foo/bar.html#header" title="Download">export:/foo/bar.html#header</a>
</p>
------------------------------
""" # " (be Emacs friendly...)



def suite():
    suite = unittest.TestSuite()
    suite.addTest(formatter.suite(CHANGESET_TEST_CASES, repository_setup,
                                  __file__))
    suite.addTest(formatter.suite(LOG_TEST_CASES, repository_setup,
                                  file=__file__))
    suite.addTest(formatter.suite(DIFF_TEST_CASES, file=__file__))
    suite.addTest(formatter.suite(SOURCE_TEST_CASES, repository_setup,
                                  file=__file__))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christian Boos <cboos@edgewall.org>

from itertools import izip

from genshi.builder import tag

from trac.resource import ResourceNotFound
from trac.util.datefmt import datetime, utc
from trac.util.translation import tag_, _
from trac.versioncontrol.api import Changeset, NoSuchNode, NoSuchChangeset

__all__ = ['get_changes', 'get_path_links', 'get_existing_node',
           'get_allowed_node', 'make_log_graph']


def get_changes(repos, revs, log=None):
    changes = {}
    for rev in revs:
        if rev in changes:
            continue
        try:
            changeset = repos.get_changeset(rev)
        except NoSuchChangeset:
            changeset = Changeset(repos, rev, '', '',
                                  datetime(1970, 1, 1, tzinfo=utc))
            if log is not None:
                log.warning("Unable to get changeset [%s]", rev)
        changes[rev] = changeset
    return changes


def get_path_links(href, reponame, path, rev, order=None, desc=None):
    desc = desc or None
    links = [{'name': 'source:',
              'href': href.browser(rev=rev if reponame == '' else None,
                                   order=order, desc=desc)}]
    if reponame:
        links.append({
            'name': reponame,
            'href': href.browser(reponame, rev=rev, order=order, desc=desc)})
    partial_path = ''
    for part in [p for p in path.split('/') if p]:
        partial_path += part + '/'
        links.append({
            'name': part,
            'href': href.browser(reponame or None, partial_path, rev=rev,
                                 order=order, desc=desc)
            })
    return links


def get_existing_node(req, repos, path, rev):
    try:
        return repos.get_node(path, rev)
    except NoSuchNode, e:
        # TRANSLATOR: You can 'search' in the repository history... (link)
        search_a = tag.a(_("search"),
                         href=req.href.log(repos.reponame or None, path,
                                           rev=rev, mode='path_history'))
        raise ResourceNotFound(tag(
            tag.p(e.message, class_="message"),
            tag.p(tag_("You can %(search)s in the repository history to see "
                       "if that path existed but was later removed",
                       search=search_a))))


def get_allowed_node(repos, path, rev, perm):
    if repos is not None:
        try:
            node = repos.get_node(path, rev)
        except (NoSuchNode, NoSuchChangeset):
            return None
        if node.is_viewable(perm):
            return node


def make_log_graph(repos, revs):
    """Generate graph information for the given revisions.

    Returns a tuple `(threads, vertices, columns)`, where:

     * `threads`: List of paint command lists `[(type, column, line)]`, where
       `type` is either 0 for "move to" or 1 for "line to", and `column` and
       `line` are coordinates.
     * `vertices`: List of `(column, thread_index)` tuples, where the `i`th
       item specifies the column in which to draw the dot in line `i` and the
       corresponding thread.
     * `columns`: Maximum width of the graph.
    """
    threads = []
    vertices = []
    columns = 0
    revs = iter(revs)

    def add_edge(thread, column, line):
        if thread and thread[-1][:2] == [1, column] \
                and thread[-2][1] == column:
            thread[-1][2] = line
        else:
            thread.append([1, column, line])

    try:
        next_rev = revs.next()
        line = 0
        active = []
        active_thread = []
        while True:
            rev = next_rev
            if rev not in active:
                # Insert new head
                threads.append([[0, len(active), line]])
                active_thread.append(threads[-1])
                active.append(rev)

            columns = max(columns, len(active))
            column = active.index(rev)
            vertices.append((column, threads.index(active_thread[column])))

            next_rev = revs.next() # Raises StopIteration when no more revs
            next = active[:]
            parents = list(repos.parent_revs(rev))

            # Replace current item with parents not already present
            new_parents = [p for p in parents if p not in active]
            next[column : column + 1] = new_parents

            # Add edges to parents
            for col, (r, thread) in enumerate(izip(active, active_thread)):
                if r in next:
                    add_edge(thread, next.index(r), line + 1)
                elif r == rev:
                    if new_parents:
                        parents.remove(new_parents[0])
                        parents.append(new_parents[0])
                    for parent in parents:
                        if parent != parents[0]:
                            thread.append([0, col, line])
                        add_edge(thread, next.index(parent), line + 1)

            if not new_parents:
                del active_thread[column]
            else:
                base = len(threads)
                threads.extend([[0, column + 1 + i, line + 1]]
                                for i in xrange(len(new_parents) - 1))
                active_thread[column + 1 : column + 1] = threads[base:]

            active = next
            line += 1
    except StopIteration:
        pass
    return threads, vertices, columns

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from BaseHTTPServer import BaseHTTPRequestHandler
from Cookie import CookieError, BaseCookie, SimpleCookie
import cgi
from datetime import datetime
import errno
from hashlib import md5
import new
import mimetypes
import os
import socket
from StringIO import StringIO
import sys
import urlparse

from trac.core import Interface, TracError
from trac.util import get_last_traceback, unquote
from trac.util.datefmt import http_date, localtz
from trac.util.text import empty, to_unicode
from trac.util.translation import _
from trac.web.href import Href
from trac.web.wsgi import _FileWrapper

class IAuthenticator(Interface):
    """Extension point interface for components that can provide the name
    of the remote user."""

    def authenticate(req):
        """Return the name of the remote user, or `None` if the identity of the
        user is unknown."""


class IRequestHandler(Interface):
    """Decide which `trac.core.Component` handles which `Request`, and how."""

    def match_request(req):
        """Return whether the handler wants to process the given request."""

    def process_request(req):
        """Process the request.

        Return a `(template_name, data, content_type)` tuple,
        where `data` is a dictionary of substitutions for the Genshi template.

        "text/html" is assumed if `content_type` is `None`.

        Note that if template processing should not occur, this method can
        simply send the response itself and not return anything.

        :Since 1.0: Clearsilver templates are no longer supported.
        """


class IRequestFilter(Interface):
    """Enable components to interfere with the processing done by the
    main handler, either before and/or after it enters in action.
    """

    def pre_process_request(req, handler):
        """Called after initial handler selection, and can be used to change
        the selected handler or redirect request.

        Always returns the request handler, even if unchanged.
        """

    def post_process_request(req, template, data, content_type):
        """Do any post-processing the request might need; typically adding
        values to the template `data` dictionary, or changing the Genshi
        template or mime type.

        `data` may be updated in place.

        Always returns a tuple of (template, data, content_type), even if
        unchanged.

        Note that `template`, `data`, `content_type` will be `None` if:
         - called when processing an error page
         - the default request handler did not return any result

        :Since 0.11: there's a `data` argument for supporting Genshi templates;
           this introduced a difference in arity which made it possible to
           distinguish between the IRequestFilter components still targeted
           at ClearSilver templates and the newer ones targeted at Genshi
           templates.

        :Since 1.0: Clearsilver templates are no longer supported.
        """


class ITemplateStreamFilter(Interface):
    """Transform the generated content by filtering the Genshi event stream
    generated by the template, prior to its serialization.
    """

    def filter_stream(req, method, filename, stream, data):
        """Return a filtered Genshi event stream, or the original unfiltered
        stream if no match.

        `req` is the current request object, `method` is the Genshi render
        method (xml, xhtml or text), `filename` is the filename of the template
        to be rendered, `stream` is the event stream and `data` is the data for
        the current template.

        See the Genshi_ documentation for more information.

        .. _Genshi: http://genshi.edgewall.org/wiki/Documentation/filters.html
        """


HTTP_STATUS = dict([(code, reason.title()) for code, (reason, description)
                    in BaseHTTPRequestHandler.responses.items()])


class HTTPException(Exception):

    def __init__(self, detail, *args):
        if isinstance(detail, TracError):
            self.detail = detail.message
            self.reason = detail.title
        else:
            self.detail = detail
        if args:
            self.detail = self.detail % args
        Exception.__init__(self, '%s %s (%s)' % (self.code, self.reason,
                                                 self.detail))

    @classmethod
    def subclass(cls, name, code):
        """Create a new Exception class representing a HTTP status code."""
        reason = HTTP_STATUS.get(code, 'Unknown')
        new_class = new.classobj(name, (HTTPException,), {
            '__doc__': 'Exception for HTTP %d %s' % (code, reason)
        })
        new_class.code = code
        new_class.reason = reason
        return new_class

_HTTPException_subclass_names = []
for code in [code for code in HTTP_STATUS if code >= 400]:
    exc_name = HTTP_STATUS[code].replace(' ', '').replace('-', '')
    # 2.5 compatibility hack:
    if exc_name == 'InternalServerError':
        exc_name = 'InternalError'
    if exc_name.lower().startswith('http'):
        exc_name = exc_name[4:]
    exc_name = 'HTTP' + exc_name
    setattr(sys.modules[__name__], exc_name,
            HTTPException.subclass(exc_name, code))
    _HTTPException_subclass_names.append(exc_name)
del code, exc_name


class _FieldStorage(cgi.FieldStorage):
    """Our own version of cgi.FieldStorage, with tweaks."""

    def read_multi(self, *args, **kwargs):
        try:
            cgi.FieldStorage.read_multi(self, *args, **kwargs)
        except ValueError:
            # Most likely "Invalid boundary in multipart form",
            # possibly an upload of a .mht file? See #9880.
            self.read_single()


class _RequestArgs(dict):
    """Dictionary subclass that provides convenient access to request
    parameters that may contain multiple values."""

    def getfirst(self, name, default=None):
        """Return the first value for the specified parameter, or `default` if
        the parameter was not provided.
        """
        if name not in self:
            return default
        val = self[name]
        if isinstance(val, list):
            val = val[0]
        return val

    def getlist(self, name):
        """Return a list of values for the specified parameter, even if only
        one value was provided.
        """
        if name not in self:
            return []
        val = self[name]
        if not isinstance(val, list):
            val = [val]
        return val


def parse_arg_list(query_string):
    """Parse a query string into a list of `(name, value)` tuples."""
    args = []
    if not query_string:
        return args
    for arg in query_string.split('&'):
        nv = arg.split('=', 1)
        if len(nv) == 2:
            (name, value) = nv
        else:
            (name, value) = (nv[0], empty)
        name = unquote(name.replace('+', ' '))
        if isinstance(name, str):
            name = unicode(name, 'utf-8')
        value = unquote(value.replace('+', ' '))
        if isinstance(value, str):
            value = unicode(value, 'utf-8')
        args.append((name, value))
    return args


def arg_list_to_args(arg_list):
    """Convert a list of `(name, value)` tuples into into a `_RequestArgs`."""
    args = _RequestArgs()
    for name, value in arg_list:
        if name in args:
            if isinstance(args[name], list):
                args[name].append(value)
            else:
                args[name] = [args[name], value]
        else:
            args[name] = value
    return args


class RequestDone(Exception):
    """Marker exception that indicates whether request processing has completed
    and a response was sent.
    """


class Cookie(SimpleCookie):
    def load(self, rawdata, ignore_parse_errors=False):
        if ignore_parse_errors:
            self.bad_cookies = []
            self._BaseCookie__set = self._loose_set
        SimpleCookie.load(self, rawdata)
        if ignore_parse_errors:
            self._BaseCookie__set = self._strict_set
            for key in self.bad_cookies:
                del self[key]

    _strict_set = BaseCookie._BaseCookie__set

    def _loose_set(self, key, real_value, coded_value):
        # If a key appears multiple times, the first occurrence has the
        # narrowest scope, keep that
        if key in self:
            return
        try:
            self._strict_set(key, real_value, coded_value)
        except CookieError:
            self.bad_cookies.append(key)
            dict.__setitem__(self, key, None)


class Request(object):
    """Represents a HTTP request/response pair.

    This class provides a convenience API over WSGI.
    """

    def __init__(self, environ, start_response):
        """Create the request wrapper.

        :param environ: The WSGI environment dict
        :param start_response: The WSGI callback for starting the response
        :param callbacks: A dictionary of functions that are used to lazily
            evaluate attribute lookups
        """
        self.environ = environ
        self._start_response = start_response
        self._write = None
        self._status = '200 OK'
        self._response = None

        self._outheaders = []
        self._outcharset = None
        self.outcookie = Cookie()

        self.callbacks = {
            'arg_list': Request._parse_arg_list,
            'args': lambda req: arg_list_to_args(req.arg_list),
            'languages': Request._parse_languages,
            'incookie': Request._parse_cookies,
            '_inheaders': Request._parse_headers
        }
        self.redirect_listeners = []

        self.base_url = self.environ.get('trac.base_url')
        if not self.base_url:
            self.base_url = self._reconstruct_url()
        self.href = Href(self.base_path)
        self.abs_href = Href(self.base_url)

    def __getattr__(self, name):
        """Performs lazy attribute lookup by delegating to the functions in the
        callbacks dictionary."""
        if name in self.callbacks:
            value = self.callbacks[name](self)
            setattr(self, name, value)
            return value
        raise AttributeError(name)

    def __repr__(self):
        path_info = self.environ.get('PATH_INFO', '')
        return '<%s "%s %r">' % (self.__class__.__name__, self.method,
                                 path_info)

    # Public API

    @property
    def method(self):
        """The HTTP method of the request"""
        return self.environ['REQUEST_METHOD']

    @property
    def path_info(self):
        """Path inside the application"""
        path_info = self.environ.get('PATH_INFO', '')
        try:
            return unicode(path_info, 'utf-8')
        except UnicodeDecodeError:
            raise HTTPNotFound(_("Invalid URL encoding (was %(path_info)r)",
                                 path_info=path_info))

    @property
    def query_string(self):
        """Query part of the request"""
        return self.environ.get('QUERY_STRING', '')

    @property
    def remote_addr(self):
        """IP address of the remote user"""
        return self.environ.get('REMOTE_ADDR')

    @property
    def remote_user(self):
        """ Name of the remote user.

        Will be `None` if the user has not logged in using HTTP authentication.
        """
        return self.environ.get('REMOTE_USER')

    @property
    def scheme(self):
        """The scheme of the request URL"""
        return self.environ['wsgi.url_scheme']

    @property
    def base_path(self):
        """The root path of the application"""
        return self.environ.get('SCRIPT_NAME', '')

    @property
    def server_name(self):
        """Name of the server"""
        return self.environ['SERVER_NAME']

    @property
    def server_port(self):
        """Port number the server is bound to"""
        return int(self.environ['SERVER_PORT'])

    def add_redirect_listener(self, listener):
        """Add a callable to be called prior to executing a redirect.

        The callable is passed the arguments to the `redirect()` call.
        """
        self.redirect_listeners.append(listener)

    def get_header(self, name):
        """Return the value of the specified HTTP header, or `None` if there's
        no such header in the request.
        """
        name = name.lower()
        for key, value in self._inheaders:
            if key == name:
                return value
        return None

    def send_response(self, code=200):
        """Set the status code of the response."""
        self._status = '%s %s' % (code, HTTP_STATUS.get(code, 'Unknown'))

    def send_header(self, name, value):
        """Send the response header with the specified name and value.

        `value` must either be an `unicode` string or can be converted to one
        (e.g. numbers, ...)
        """
        if name.lower() == 'content-type':
            ctpos = value.find('charset=')
            if ctpos >= 0:
                self._outcharset = value[ctpos + 8:].strip()
        elif name.lower() == 'content-length':
            self._content_length = int(value)
        self._outheaders.append((name, unicode(value).encode('utf-8')))

    def end_headers(self):
        """Must be called after all headers have been sent and before the
        actual content is written.
        """
        self._send_cookie_headers()
        self._write = self._start_response(self._status, self._outheaders)

    def check_modified(self, datetime, extra=''):
        """Check the request "If-None-Match" header against an entity tag.

        The entity tag is generated from the specified last modified time
        (`datetime`), optionally appending an `extra` string to
        indicate variants of the requested resource.

        That `extra` parameter can also be a list, in which case the MD5 sum
        of the list content will be used.

        If the generated tag matches the "If-None-Match" header of the request,
        this method sends a "304 Not Modified" response to the client.
        Otherwise, it adds the entity tag as an "ETag" header to the response
        so that consecutive requests can be cached.
        """
        if isinstance(extra, list):
            m = md5()
            for elt in extra:
                m.update(repr(elt))
            extra = m.hexdigest()
        etag = 'W/"%s/%s/%s"' % (self.authname, http_date(datetime), extra)
        inm = self.get_header('If-None-Match')
        if (not inm or inm != etag):
            self.send_header('ETag', etag)
        else:
            self.send_response(304)
            self.send_header('Content-Length', 0)
            self.end_headers()
            raise RequestDone

    def redirect(self, url, permanent=False):
        """Send a redirect to the client, forwarding to the specified URL.

        The `url` may be relative or absolute, relative URLs will be translated
        appropriately.
        """
        for listener in self.redirect_listeners:
            listener(self, url, permanent)

        if permanent:
            status = 301 # 'Moved Permanently'
        elif self.method == 'POST':
            status = 303 # 'See Other' -- safe to use in response to a POST
        else:
            status = 302 # 'Found' -- normal temporary redirect

        self.send_response(status)
        if not url.startswith(('http://', 'https://')):
            # Make sure the URL is absolute
            scheme, host = urlparse.urlparse(self.base_url)[:2]
            url = urlparse.urlunparse((scheme, host, url, None, None, None))

        # Workaround #10382, IE6+ bug when post and redirect with hash
        if status == 303 and '#' in url and \
                ' MSIE ' in self.environ.get('HTTP_USER_AGENT', ''):
            url = url.replace('#', '#__msie303:')

        self.send_header('Location', url)
        self.send_header('Content-Type', 'text/plain')
        self.send_header('Content-Length', 0)
        self.send_header('Pragma', 'no-cache')
        self.send_header('Cache-Control', 'no-cache')
        self.send_header('Expires', 'Fri, 01 Jan 1999 00:00:00 GMT')
        self.end_headers()
        raise RequestDone

    def send(self, content, content_type='text/html', status=200):
        self.send_response(status)
        self.send_header('Cache-Control', 'must-revalidate')
        self.send_header('Expires', 'Fri, 01 Jan 1999 00:00:00 GMT')
        self.send_header('Content-Type', content_type + ';charset=utf-8')
        self.send_header('Content-Length', len(content))
        self.end_headers()

        if self.method != 'HEAD':
            self.write(content)
        raise RequestDone

    def send_error(self, exc_info, template='error.html',
                   content_type='text/html', status=500, env=None, data={}):
        try:
            if template.endswith('.html'):
                if env:
                    from trac.web.chrome import Chrome
                    try:
                        data = Chrome(env).render_template(self, template,
                                                           data, 'text/html')
                    except Exception:
                        # second chance rendering, in "safe" mode
                        data['trac_error_rendering'] = True
                        data = Chrome(env).render_template(self, template,
                                                           data, 'text/html')
                else:
                    content_type = 'text/plain'
                    data = '%s\n\n%s: %s' % (data.get('title'),
                                             data.get('type'),
                                             data.get('message'))
        except Exception: # failed to render
            data = get_last_traceback()
            content_type = 'text/plain'

        if isinstance(data, unicode):
            data = data.encode('utf-8')

        self.send_response(status)
        self._outheaders = []
        self.send_header('Cache-Control', 'must-revalidate')
        self.send_header('Expires', 'Fri, 01 Jan 1999 00:00:00 GMT')
        self.send_header('Content-Type', content_type + ';charset=utf-8')
        self.send_header('Content-Length', len(data))
        self._send_cookie_headers()

        self._write = self._start_response(self._status, self._outheaders,
                                           exc_info)

        if self.method != 'HEAD':
            self.write(data)
        raise RequestDone

    def send_no_content(self):
        self.send_response(204)
        self.send_header('Content-Length', 0)
        self.send_header('Content-Type', 'text/plain')
        self.end_headers()
        raise RequestDone

    def send_file(self, path, mimetype=None):
        """Send a local file to the browser.

        This method includes the "Last-Modified", "Content-Type" and
        "Content-Length" headers in the response, corresponding to the file
        attributes. It also checks the last modification time of the local file
        against the "If-Modified-Since" provided by the user agent, and sends a
        "304 Not Modified" response if it matches.
        """
        if not os.path.isfile(path):
            raise HTTPNotFound(_("File %(path)s not found", path=path))

        stat = os.stat(path)
        mtime = datetime.fromtimestamp(stat.st_mtime, localtz)
        last_modified = http_date(mtime)
        if last_modified == self.get_header('If-Modified-Since'):
            self.send_response(304)
            self.send_header('Content-Length', 0)
            self.end_headers()
            raise RequestDone

        if not mimetype:
            mimetype = mimetypes.guess_type(path)[0] or \
                       'application/octet-stream'

        self.send_response(200)
        self.send_header('Content-Type', mimetype)
        self.send_header('Content-Length', stat.st_size)
        self.send_header('Last-Modified', last_modified)
        use_xsendfile = getattr(self, 'use_xsendfile', False)
        if use_xsendfile:
            self.send_header('X-Sendfile', os.path.abspath(path))
        self.end_headers()

        if not use_xsendfile and self.method != 'HEAD':
            fileobj = file(path, 'rb')
            file_wrapper = self.environ.get('wsgi.file_wrapper', _FileWrapper)
            self._response = file_wrapper(fileobj, 4096)
        raise RequestDone

    def read(self, size=None):
        """Read the specified number of bytes from the request body."""
        fileobj = self.environ['wsgi.input']
        if size is None:
            size = self.get_header('Content-Length')
            if size is None:
                size = -1
            else:
                size = int(size)
        data = fileobj.read(size)
        return data

    def write(self, data):
        """Write the given data to the response body.

        `data` *must* be a `str` string, encoded with the charset
        which has been specified in the ''Content-Type'' header
        or 'utf-8' otherwise.

        Note that the ''Content-Length'' header must have been specified.
        Its value either corresponds to the length of `data`, or, if there
        are multiple calls to `write`, to the cumulated length of the `data`
        arguments.
        """
        if not self._write:
            self.end_headers()
        if not hasattr(self, '_content_length'):
            raise RuntimeError("No Content-Length header set")
        if isinstance(data, unicode):
            raise ValueError("Can't send unicode content")
        try:
            self._write(data)
        except (IOError, socket.error), e:
            if e.args[0] in (errno.EPIPE, errno.ECONNRESET, 10053, 10054):
                raise RequestDone
            raise

    # Internal methods

    def _parse_arg_list(self):
        """Parse the supplied request parameters into a list of
        `(name, value)` tuples.
        """
        fp = self.environ['wsgi.input']

        # Avoid letting cgi.FieldStorage consume the input stream when the
        # request does not contain form data
        ctype = self.get_header('Content-Type')
        if ctype:
            ctype, options = cgi.parse_header(ctype)
        if ctype not in ('application/x-www-form-urlencoded',
                         'multipart/form-data'):
            fp = StringIO('')

        # Python 2.6 introduced a backwards incompatible change for
        # FieldStorage where QUERY_STRING is no longer ignored for POST
        # requests. We'll keep the pre 2.6 behaviour for now...
        if self.method == 'POST':
            qs_on_post = self.environ.pop('QUERY_STRING', '')
        fs = _FieldStorage(fp, environ=self.environ, keep_blank_values=True)
        if self.method == 'POST':
            self.environ['QUERY_STRING'] = qs_on_post

        args = []
        for value in fs.list or ():
            name = value.name
            if not value.filename:
                value = unicode(value.value, 'utf-8')
            args.append((name, value))
        return args

    def _parse_cookies(self):
        cookies = Cookie()
        header = self.get_header('Cookie')
        if header:
            cookies.load(header, ignore_parse_errors=True)
        return cookies

    def _parse_headers(self):
        headers = [(name[5:].replace('_', '-').lower(), value)
                   for name, value in self.environ.items()
                   if name.startswith('HTTP_')]
        if 'CONTENT_LENGTH' in self.environ:
            headers.append(('content-length', self.environ['CONTENT_LENGTH']))
        if 'CONTENT_TYPE' in self.environ:
            headers.append(('content-type', self.environ['CONTENT_TYPE']))
        return headers

    def _parse_languages(self):
        """The list of languages preferred by the remote user, taken from the
        ``Accept-Language`` header.
        """
        header = self.get_header('Accept-Language') or 'en-us'
        langs = []
        for i, lang in enumerate(header.split(',')):
            code, params = cgi.parse_header(lang)
            q = 1
            if 'q' in params:
                try:
                    q = float(params['q'])
                except ValueError:
                    q = 0
            langs.append((-q, i, code))
        langs.sort()
        return [code for q, i, code in langs]

    def _reconstruct_url(self):
        """Reconstruct the absolute base URL of the application."""
        host = self.get_header('Host')
        if not host:
            # Missing host header, so reconstruct the host from the
            # server name and port
            default_port = {'http': 80, 'https': 443}
            if self.server_port and self.server_port != \
                   default_port[self.scheme]:
                host = '%s:%d' % (self.server_name, self.server_port)
            else:
                host = self.server_name
        return urlparse.urlunparse((self.scheme, host, self.base_path, None,
                                    None, None))

    def _send_cookie_headers(self):
        for name in self.outcookie.keys():
            path = self.outcookie[name].get('path')
            if path:
                path = path.replace(' ', '%20') \
                           .replace(';', '%3B') \
                           .replace(',', '%3C')
            self.outcookie[name]['path'] = path

        cookies = to_unicode(self.outcookie.output(header='')).encode('utf-8')
        for cookie in cookies.splitlines():
            self._outheaders.append(('Set-Cookie', cookie.strip()))

__no_apidoc__ = _HTTPException_subclass_names

########NEW FILE########
__FILENAME__ = auth
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>

from __future__ import with_statement

try:
    from base64 import b64decode, b64encode
except ImportError:
    from base64 import decodestring as b64decode
    from base64 import encodestring as b64encode
from hashlib import md5, sha1
import os
import re
import sys
import time
import urllib2
import urlparse

from genshi.builder import tag

from trac.config import BoolOption, IntOption, Option
from trac.core import *
from trac.web.api import IAuthenticator, IRequestHandler
from trac.web.chrome import INavigationContributor
from trac.util import hex_entropy, md5crypt
from trac.util.concurrency import threading
from trac.util.translation import _, tag_


class LoginModule(Component):
    """User authentication manager.

    This component implements user authentication based on HTTP
    authentication provided by the web-server, combined with cookies
    for communicating the login information across the whole site.

    This mechanism expects that the web-server is setup so that a
    request to the path '/login' requires authentication (such as
    Basic or Digest). The login name is then stored in the database
    and associated with a unique key that gets passed back to the user
    agent using the 'trac_auth' cookie. This cookie is used to
    identify the user in subsequent requests to non-protected
    resources.
    """

    implements(IAuthenticator, INavigationContributor, IRequestHandler)

    check_ip = BoolOption('trac', 'check_auth_ip', 'false',
         """Whether the IP address of the user should be checked for
         authentication (''since 0.9'').""")

    ignore_case = BoolOption('trac', 'ignore_auth_case', 'false',
        """Whether login names should be converted to lower case
        (''since 0.9'').""")

    auth_cookie_lifetime = IntOption('trac', 'auth_cookie_lifetime', 0,
        """Lifetime of the authentication cookie, in seconds.

        This value determines how long the browser will cache
        authentication information, and therefore, after how much
        inactivity a user will have to log in again. The default value
        of 0 makes the cookie expire at the end of the browsing
        session. (''since 0.12'')""")

    auth_cookie_path = Option('trac', 'auth_cookie_path', '',
        """Path for the authentication cookie. Set this to the common
        base path of several Trac instances if you want them to share
        the cookie.  (''since 0.12'')""")

    # IAuthenticator methods

    def authenticate(self, req):
        authname = None
        if req.remote_user:
            authname = req.remote_user
        elif req.incookie.has_key('trac_auth'):
            authname = self._get_name_for_cookie(req,
                                                 req.incookie['trac_auth'])

        if not authname:
            return None

        if self.ignore_case:
            authname = authname.lower()

        return authname

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'login'

    def get_navigation_items(self, req):
        if req.authname and req.authname != 'anonymous':
            yield ('metanav', 'login', _('logged in as %(user)s',
                                         user=req.authname))
            yield ('metanav', 'logout',
                   tag.a(_('Logout'), href=req.href.logout()))
        else:
            yield ('metanav', 'login',
                   tag.a(_('Login'), href=req.href.login()))

    # IRequestHandler methods

    def match_request(self, req):
        return re.match('/(login|logout)/?$', req.path_info)

    def process_request(self, req):
        if req.path_info.startswith('/login'):
            self._do_login(req)
        elif req.path_info.startswith('/logout'):
            self._do_logout(req)
        self._redirect_back(req)

    # Internal methods

    def _do_login(self, req):
        """Log the remote user in.

        This function expects to be called when the remote user name
        is available. The user name is inserted into the `auth_cookie`
        table and a cookie identifying the user on subsequent requests
        is sent back to the client.

        If the Authenticator was created with `ignore_case` set to
        true, then the authentication name passed from the web server
        in req.remote_user will be converted to lower case before
        being used. This is to avoid problems on installations
        authenticating against Windows which is not case sensitive
        regarding user names and domain names
        """
        if not req.remote_user:
            # TRANSLATOR: ... refer to the 'installation documentation'. (link)
            inst_doc = tag.a(_('installation documentation'),
                             title=_("Configuring Authentication"),
                             href=req.href.wiki('TracInstall')
                                  + "#ConfiguringAuthentication")
            raise TracError(tag_("Authentication information not available. "
                                 "Please refer to the %(inst_doc)s.",
                                 inst_doc=inst_doc))
        remote_user = req.remote_user
        if self.ignore_case:
            remote_user = remote_user.lower()

        assert req.authname in ('anonymous', remote_user), \
               _('Already logged in as %(user)s.', user=req.authname)

        with self.env.db_transaction as db:
            # Delete cookies older than 10 days
            db("DELETE FROM auth_cookie WHERE time < %s",
               (int(time.time()) - 86400 * 10,))
            # Insert a new cookie if we haven't already got one
            cookie = None
            trac_auth = req.incookie.get('trac_auth')
            if trac_auth is not None:
                name = self._cookie_to_name(req, trac_auth)
                cookie = trac_auth.value if name == remote_user else None
            if cookie is None:
                cookie = hex_entropy()
                db("""
                    INSERT INTO auth_cookie (cookie, name, ipnr, time)
                         VALUES (%s, %s, %s, %s)
                   """, (cookie, remote_user, req.remote_addr,
                         int(time.time())))
        req.authname = remote_user
        req.outcookie['trac_auth'] = cookie
        req.outcookie['trac_auth']['path'] = self.auth_cookie_path \
                                             or req.base_path or '/'
        if self.env.secure_cookies:
            req.outcookie['trac_auth']['secure'] = True
        if sys.version_info >= (2, 6):
            req.outcookie['trac_auth']['httponly'] = True
        if self.auth_cookie_lifetime > 0:
            req.outcookie['trac_auth']['expires'] = self.auth_cookie_lifetime

    def _do_logout(self, req):
        """Log the user out.

        Simply deletes the corresponding record from the auth_cookie
        table.
        """
        if req.authname == 'anonymous':
            # Not logged in
            return

        if 'trac_auth' in req.incookie:
            self.env.db_transaction("DELETE FROM auth_cookie WHERE cookie=%s",
                                    (req.incookie['trac_auth'].value,))
        else:
            self.env.db_transaction("DELETE FROM auth_cookie WHERE name=%s",
                                    (req.authname,))
        self._expire_cookie(req)
        custom_redirect = self.config['metanav'].get('logout.redirect')
        if custom_redirect:
            if not re.match(r'https?:|/', custom_redirect):
                custom_redirect = req.href(custom_redirect)
            req.redirect(custom_redirect)

    def _expire_cookie(self, req):
        """Instruct the user agent to drop the auth cookie by setting
        the "expires" property to a date in the past.
        """
        req.outcookie['trac_auth'] = ''
        req.outcookie['trac_auth']['path'] = self.auth_cookie_path \
                                             or req.base_path or '/'
        req.outcookie['trac_auth']['expires'] = -10000
        if self.env.secure_cookies:
            req.outcookie['trac_auth']['secure'] = True
        if sys.version_info >= (2, 6):
            req.outcookie['trac_auth']['httponly'] = True

    def _cookie_to_name(self, req, cookie):
        # This is separated from _get_name_for_cookie(), because the
        # latter is overridden in AccountManager.
        if self.check_ip:
            sql = "SELECT name FROM auth_cookie WHERE cookie=%s AND ipnr=%s"
            args = (cookie.value, req.remote_addr)
        else:
            sql = "SELECT name FROM auth_cookie WHERE cookie=%s"
            args = (cookie.value,)
        for name, in self.env.db_query(sql, args):
            return name

    def _get_name_for_cookie(self, req, cookie):
        name = self._cookie_to_name(req, cookie)
        if name is None:
            # The cookie is invalid (or has been purged from the
            # database), so tell the user agent to drop it as it is
            # invalid
            self._expire_cookie(req)
        return name

    def _redirect_back(self, req):
        """Redirect the user back to the URL she came from."""
        referer = self._referer(req)
        if referer:
            if not referer.startswith(('http://', 'https://')):
                # Make URL absolute
                scheme, host = urlparse.urlparse(req.base_url)[:2]
                referer = urlparse.urlunparse((scheme, host, referer, None,
                                               None, None))
            pos = req.base_url.find(':')
            base_scheme = req.base_url[:pos]
            base_noscheme = req.base_url[pos:]
            base_noscheme_norm = base_noscheme.rstrip('/')
            referer_noscheme = referer[referer.find(':'):]
            # only redirect to referer if it is from the same site
            if referer_noscheme == base_noscheme or \
                    referer_noscheme.startswith(base_noscheme_norm + '/'):
                # avoid redirect loops
                if referer_noscheme.rstrip('/') != \
                        base_noscheme_norm + req.path_info.rstrip('/'):
                    req.redirect(base_scheme + referer_noscheme)
        req.redirect(req.abs_href())

    def _referer(self, req):
        return req.args.get('referer') or req.get_header('Referer')


class HTTPAuthentication(object):

    def do_auth(self, environ, start_response):
        raise NotImplementedError


class PasswordFileAuthentication(HTTPAuthentication):
    def __init__(self, filename):
        self.filename = filename
        self.mtime = os.stat(filename).st_mtime
        self.load(self.filename)
        self._lock = threading.Lock()

    def check_reload(self):
        with self._lock:
            mtime = os.stat(self.filename).st_mtime
            if mtime > self.mtime:
                self.mtime = mtime
                self.load(self.filename)


class BasicAuthentication(PasswordFileAuthentication):

    def __init__(self, htpasswd, realm):
        # FIXME pass a logger
        self.realm = realm
        try:
            import crypt
            self.crypt = crypt.crypt
        except ImportError:
            try:
                import fcrypt
                self.crypt = fcrypt.crypt
            except ImportError:
                self.crypt = None
        PasswordFileAuthentication.__init__(self, htpasswd)

    def load(self, filename):
        # FIXME use a logger
        self.hash = {}
        fd = open(filename, 'r')
        for line in fd:
            line = line.strip()
            if not line:
                continue
            try:
                u, h = line.split(':')
            except ValueError:
                print>>sys.stderr, 'Warning: invalid password line in %s: ' \
                    '%s' % (filename, line)
                continue
            if '$' in h or h.startswith('{SHA}') or self.crypt:
                self.hash[u] = h
            else:
                print>>sys.stderr, 'Warning: cannot parse password for ' \
                    'user "%s" without the "crypt" module' % u

        if self.hash == {}:
            print>>sys.stderr, "Warning: found no users in file:", filename

    def test(self, user, password):
        self.check_reload()
        the_hash = self.hash.get(user)
        if the_hash is None:
            return False

        if the_hash.startswith('{SHA}'):
            return b64encode(sha1(password).digest()) == the_hash[5:]

        if not '$' in the_hash:
            return self.crypt(password, the_hash[:2]) == the_hash

        magic, salt = the_hash[1:].split('$')[:2]
        magic = '$' + magic + '$'
        return md5crypt(password, salt, magic) == the_hash

    def do_auth(self, environ, start_response):
        header = environ.get('HTTP_AUTHORIZATION')
        if header and header.startswith('Basic'):
            auth = b64decode(header[6:]).split(':')
            if len(auth) == 2:
                user, password = auth
                if self.test(user, password):
                    return user

        start_response('401 Unauthorized',
                       [('WWW-Authenticate', 'Basic realm="%s"' % self.realm),
                        ('Content-Length', '0')])('')


class DigestAuthentication(PasswordFileAuthentication):
    """A simple HTTP digest authentication implementation
    (:rfc:`2617`)."""

    MAX_NONCES = 100

    def __init__(self, htdigest, realm):
        # FIXME pass a logger
        self.active_nonces = []
        self.realm = realm
        PasswordFileAuthentication.__init__(self, htdigest)

    def load(self, filename):
        """Load account information from apache style htdigest files,
        only users from the specified realm are used
        """
        # FIXME use a logger
        self.hash = {}
        fd = open(filename, 'r')
        for line in fd.readlines():
            line = line.strip()
            if not line:
                continue
            try:
                u, r, a1 = line.split(':')
            except ValueError:
                print>>sys.stderr, 'Warning: invalid digest line in %s: %s' \
                    % (filename, line)
                continue
            if r == self.realm:
                self.hash[u] = a1
        if self.hash == {}:
            print>>sys.stderr, "Warning: found no users in realm:", self.realm

    def parse_auth_header(self, authorization):
        values = {}
        for value in urllib2.parse_http_list(authorization):
            n, v = value.split('=', 1)
            if v[0] == '"' and v[-1] == '"':
                values[n] = v[1:-1]
            else:
                values[n] = v
        return values

    def send_auth_request(self, environ, start_response, stale='false'):
        """Send a digest challange to the browser. Record used nonces
        to avoid replay attacks.
        """
        nonce = hex_entropy()
        self.active_nonces.append(nonce)
        if len(self.active_nonces) > self.MAX_NONCES:
            self.active_nonces = self.active_nonces[-self.MAX_NONCES:]
        start_response('401 Unauthorized',
                       [('WWW-Authenticate',
                        'Digest realm="%s", nonce="%s", qop="auth", stale="%s"'
                        % (self.realm, nonce, stale)),
                        ('Content-Length', '0')])('')

    def do_auth(self, environ, start_response):
        header = environ.get('HTTP_AUTHORIZATION')
        if not header or not header.startswith('Digest'):
            self.send_auth_request(environ, start_response)
            return None

        auth = self.parse_auth_header(header[7:])
        required_keys = ['username', 'realm', 'nonce', 'uri', 'response',
                         'nc', 'cnonce']
        # Invalid response?
        for key in required_keys:
            if not auth.has_key(key):
                self.send_auth_request(environ, start_response)
                return None
        # Unknown user?
        self.check_reload()
        if not self.hash.has_key(auth['username']):
            self.send_auth_request(environ, start_response)
            return None

        kd = lambda x: md5(':'.join(x)).hexdigest()
        a1 = self.hash[auth['username']]
        a2 = kd([environ['REQUEST_METHOD'], auth['uri']])
        # Is the response correct?
        correct = kd([a1, auth['nonce'], auth['nc'],
                      auth['cnonce'], auth['qop'], a2])
        if auth['response'] != correct:
            self.send_auth_request(environ, start_response)
            return None
        # Is the nonce active, if not ask the client to use a new one
        if not auth['nonce'] in self.active_nonces:
            self.send_auth_request(environ, start_response, stale='true')
            return None
        self.active_nonces.remove(auth['nonce'])
        return auth['username']

########NEW FILE########
__FILENAME__ = cgi_frontend
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>
#         Matthew Good <trac@matt-good.net>

import os
import pkg_resources
import sys

from trac import __version__ as VERSION
from trac.web.main import dispatch_request
from trac.web.wsgi import WSGIGateway


class CGIGateway(WSGIGateway):

    wsgi_multithread = False
    wsgi_multiprocess = False
    wsgi_run_once = True

    def __init__(self):
        WSGIGateway.__init__(self, dict(os.environ))

    def _write(self, data):
        assert self.headers_set, 'Response not started'

        if not self.headers_sent:
            status, headers = self.headers_sent = self.headers_set
            sys.stdout.write('Status: %s\r\n' % status)
            for header in headers:
                sys.stdout.write('%s: %s\r\n' % header)
            sys.stdout.write('\r\n')
            sys.stdout.flush()

        sys.stdout.write(data)
        sys.stdout.flush()


def run():
    try: # Make FreeBSD use blocking I/O like other platforms
        import fcntl
        for stream in [sys.stdin, sys.stdout]:
            fd = stream.fileno()
            flags = fcntl.fcntl(fd, fcntl.F_GETFL)
            fcntl.fcntl(fd, fcntl.F_SETFL, flags & ~os.O_NONBLOCK)
    except (ImportError, AttributeError):
        pass

    try: # Use binary I/O on Windows
        import msvcrt
        msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
        msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
    except ImportError:
        pass

    gateway = CGIGateway()
    gateway.run(dispatch_request)

if __name__ == '__main__':
    pkg_resources.require('Trac==%s' % VERSION)
    run()

########NEW FILE########
__FILENAME__ = chrome
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2010 Edgewall Software
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

"""Content presentation for the web layer.

The Chrome module deals with delivering and shaping content to the end user,
mostly targeting (X)HTML generation but not exclusively, RSS or other forms of
web content are also using facilities provided here.
"""

from __future__ import with_statement

import datetime
from functools import partial
import itertools
import os.path
import pkg_resources
import pprint
import re
try:
    from cStringIO import StringIO
except ImportError:
    from StringIO import StringIO

from genshi import Markup
from genshi.builder import tag, Element
from genshi.core import Attrs, START
from genshi.filters import Translator
from genshi.output import DocType
from genshi.template import TemplateLoader, MarkupTemplate, NewTextTemplate

from trac import __version__ as VERSION
from trac.config import *
from trac.core import *
from trac.env import IEnvironmentSetupParticipant, ISystemInfoProvider
from trac.mimeview.api import RenderingContext, get_mimetype
from trac.resource import *
from trac.util import compat, get_reporter_id, presentation, get_pkginfo, \
                      pathjoin, translation
from trac.util.html import escape, plaintext
from trac.util.text import pretty_size, obfuscate_email_address, \
                           shorten_line, unicode_quote_plus, to_unicode, \
                           javascript_quote, exception_to_unicode
from trac.util.datefmt import (
    pretty_timedelta, format_datetime, format_date, format_time,
    from_utimestamp, http_date, utc, get_date_format_jquery_ui, is_24_hours,
    get_time_format_jquery_ui, user_time, get_month_names_jquery_ui,
    get_day_names_jquery_ui, get_timezone_list_jquery_ui,
    get_first_week_day_jquery_ui)
from trac.util.translation import _, get_available_locales
from trac.web.api import IRequestHandler, ITemplateStreamFilter, HTTPNotFound
from trac.web.href import Href
from trac.wiki import IWikiSyntaxProvider
from trac.wiki.formatter import format_to, format_to_html, format_to_oneliner


class INavigationContributor(Interface):
    """Extension point interface for components that contribute items to the
    navigation.
    """

    def get_active_navigation_item(req):
        """This method is only called for the `IRequestHandler` processing the
        request.

        It should return the name of the navigation item that should be
        highlighted as active/current.
        """

    def get_navigation_items(req):
        """Should return an iterable object over the list of navigation items
        to add, each being a tuple in the form (category, name, text).
        """


class ITemplateProvider(Interface):
    """Extension point interface for components that provide their own
    Genshi templates and accompanying static resources.
    """

    def get_htdocs_dirs():
        """Return a list of directories with static resources (such as style
        sheets, images, etc.)

        Each item in the list must be a `(prefix, abspath)` tuple. The
        `prefix` part defines the path in the URL that requests to these
        resources are prefixed with.

        The `abspath` is the absolute path to the directory containing the
        resources on the local file system.
        """

    def get_templates_dirs():
        """Return a list of directories containing the provided template
        files.
        """


def add_meta(req, content, http_equiv=None, name=None, scheme=None, lang=None):
    """Add a `<meta>` tag into the `<head>` of the generated HTML."""
    meta = {'content': content, 'http-equiv': http_equiv, 'name': name,
            'scheme': scheme, 'lang': lang, 'xml:lang': lang}
    req.chrome.setdefault('metas', []).append(meta)

def add_link(req, rel, href, title=None, mimetype=None, classname=None,
             **attrs):
    """Add a link to the chrome info that will be inserted as <link> element in
    the <head> of the generated HTML
    """
    linkid = '%s:%s' % (rel, href)
    linkset = req.chrome.setdefault('linkset', set())
    if linkid in linkset:
        return # Already added that link

    link = {'href': href, 'title': title, 'type': mimetype, 'class': classname}
    link.update(attrs)
    links = req.chrome.setdefault('links', {})
    links.setdefault(rel, []).append(link)
    linkset.add(linkid)

def add_stylesheet(req, filename, mimetype='text/css', media=None):
    """Add a link to a style sheet to the chrome info so that it gets included
    in the generated HTML page.

    If the filename is absolute (i.e. starts with a slash), the generated link
    will be based off the application root path. If it is relative, the link
    will be based off the `/chrome/` path.
    """
    if filename.startswith(('http://', 'https://')):
        href = filename
    elif filename.startswith('common/') and 'htdocs_location' in req.chrome:
        href = Href(req.chrome['htdocs_location'])(filename[7:])
    else:
        href = req.href
        if not filename.startswith('/'):
            href = href.chrome
        href = href(filename)
    add_link(req, 'stylesheet', href, mimetype=mimetype, media=media)

def add_script(req, filename, mimetype='text/javascript', charset='utf-8',
               ie_if=None):
    """Add a reference to an external javascript file to the template.

    If the filename is absolute (i.e. starts with a slash), the generated link
    will be based off the application root path. If it is relative, the link
    will be based off the `/chrome/` path.
    """
    scriptset = req.chrome.setdefault('scriptset', set())
    if filename in scriptset:
        return False # Already added that script

    if filename.startswith(('http://', 'https://')):
        href = filename
    elif filename.startswith('common/') and 'htdocs_location' in req.chrome:
        href = Href(req.chrome['htdocs_location'])(filename[7:])
    else:
        href = req.href
        if not filename.startswith('/'):
            href = href.chrome
        href = href(filename)
    script = {'href': href, 'type': mimetype, 'charset': charset,
              'prefix': Markup('<!--[if %s]>' % ie_if) if ie_if else None,
              'suffix': Markup('<![endif]-->') if ie_if else None}

    req.chrome.setdefault('scripts', []).append(script)
    scriptset.add(filename)

def add_script_data(req, data={}, **kwargs):
    """Add data to be made available in javascript scripts as global variables.

    The keys in `data` and the keyword argument names provide the names of the
    global variables. The values are converted to JSON and assigned to the
    corresponding variables.
    """
    script_data = req.chrome.setdefault('script_data', {})
    script_data.update(data)
    script_data.update(kwargs)

def add_javascript(req, filename):
    """:deprecated: use `add_script` instead."""
    add_script(req, filename, mimetype='text/javascript')

def add_warning(req, msg, *args):
    """Add a non-fatal warning to the request object.

    When rendering pages, all warnings will be rendered to the user. Note that
    the message is escaped (and therefore converted to `Markup`) before it is
    stored in the request object.
    """
    if args:
        msg %= args
    msg = escape(msg, False)
    if msg not in req.chrome['warnings']:
        req.chrome['warnings'].append(msg)

def add_notice(req, msg, *args):
    """Add an informational notice to the request object.

    When rendering pages, all notices will be rendered to the user. Note that
    the message is escaped (and therefore converted to `Markup`) before it is
    stored in the request object.
    """
    if args:
        msg %= args
    msg = escape(msg, False)
    if msg not in req.chrome['notices']:
        req.chrome['notices'].append(msg)

def add_ctxtnav(req, elm_or_label, href=None, title=None):
    """Add an entry to the current page's ctxtnav bar."""
    if href:
        elm = tag.a(elm_or_label, href=href, title=title)
    else:
        elm = elm_or_label
    req.chrome.setdefault('ctxtnav', []).append(elm)

def prevnext_nav(req, prev_label, next_label, up_label=None):
    """Add Previous/Up/Next navigation links.

       :param        req: a `Request` object
       :param prev_label: the label to use for left (previous) link
       :param   up_label: the label to use for the middle (up) link
       :param next_label: the label to use for right (next) link
    """
    links = req.chrome['links']
    prev_link = next_link = None

    if not any(lnk in links for lnk in ('prev', 'up', 'next')): # Short circuit
        return

    if 'prev' in links:
        prev = links['prev'][0]
        prev_link = tag.a(prev_label, href=prev['href'], title=prev['title'],
                          class_='prev')

    add_ctxtnav(req, tag.span(Markup('&larr; '), prev_link or prev_label,
                              class_='missing' if not prev_link else None))

    if up_label and 'up' in links:
        up = links['up'][0]
        add_ctxtnav(req, tag.a(up_label, href=up['href'], title=up['title']))

    if 'next' in links:
        next_ = links['next'][0]
        next_link = tag.a(next_label, href=next_['href'], title=next_['title'],
                          class_='next')

    add_ctxtnav(req, tag.span(next_link or next_label, Markup(' &rarr;'),
                              class_='missing' if not next_link else None))


def web_context(req, resource=None, id=False, version=False, parent=False,
                absurls=False):
    """Create a rendering context from a request.

    The `perm` and `href` properties of the context will be initialized
    from the corresponding properties of the request object.

    >>> from trac.test import Mock, MockPerm
    >>> req = Mock(href=Mock(), perm=MockPerm())
    >>> context = web_context(req)
    >>> context.href is req.href
    True
    >>> context.perm is req.perm
    True

    :param      req: the HTTP request object
    :param resource: the `Resource` object or realm
    :param       id: the resource identifier
    :param  version: the resource version
    :param  absurls: whether URLs generated by the ``href`` object should
                     be absolute (including the protocol scheme and host
                     name)
    :return: a new rendering context
    :rtype: `RenderingContext`
    """
    if req:
        href = req.abs_href if absurls else req.href
        perm = req.perm
    else:
        href = None
        perm = None
    self = RenderingContext(Resource(resource, id=id, version=version,
                                     parent=parent), href=href, perm=perm)
    self.req = req
    return self


def auth_link(req, link):
    """Return an "authenticated" link to `link` for authenticated users.

    If the user is anonymous, returns `link` unchanged. For authenticated
    users, returns a link to `/login` that redirects to `link` after
    authentication.
    """
    if req.authname != 'anonymous':
        return req.href.login(referer=link)
    return link


def _save_messages(req, url, permanent):
    """Save warnings and notices in case of redirect, so that they can
    be displayed after the redirect."""
    for type_ in ['warnings', 'notices']:
        for (i, message) in enumerate(req.chrome[type_]):
            req.session['chrome.%s.%d' % (type_, i)] = escape(message, False)


# Mappings for removal of control characters
_translate_nop = "".join([chr(i) for i in range(256)])
_invalid_control_chars = "".join([chr(i) for i in range(32)
                                  if i not in [0x09, 0x0a, 0x0d]])


class Chrome(Component):
    """Web site chrome assembly manager.

    Chrome is everything that is not actual page content.
    """
    required = True

    implements(ISystemInfoProvider, IEnvironmentSetupParticipant,
               IRequestHandler, ITemplateProvider, IWikiSyntaxProvider)

    navigation_contributors = ExtensionPoint(INavigationContributor)
    template_providers = ExtensionPoint(ITemplateProvider)
    stream_filters = ExtensionPoint(ITemplateStreamFilter)

    shared_templates_dir = PathOption('inherit', 'templates_dir', '',
        """Path to the //shared templates directory//.

        Templates in that directory are loaded in addition to those in the
        environments `templates` directory, but the latter take precedence.

        (''since 0.11'')""")

    shared_htdocs_dir = PathOption('inherit', 'htdocs_dir', '',
        """Path to the //shared htdocs directory//.

        Static resources in that directory are mapped to /chrome/shared
        under the environment URL, in addition to common and site locations.

        This can be useful in site.html for common interface customization
        of multiple Trac environments.

        (''since 1.0'')""")

    auto_reload = BoolOption('trac', 'auto_reload', False,
        """Automatically reload template files after modification.""")

    genshi_cache_size = IntOption('trac', 'genshi_cache_size', 128,
        """The maximum number of templates that the template loader will cache
        in memory. The default value is 128. You may want to choose a higher
        value if your site uses a larger number of templates, and you have
        enough memory to spare, or you can reduce it if you are short on
        memory.""")

    htdocs_location = Option('trac', 'htdocs_location', '',
        """Base URL for serving the core static resources below
        `/chrome/common/`.

        It can be left empty, and Trac will simply serve those resources
        itself.

        Advanced users can use this together with
        [TracAdmin trac-admin ... deploy <deploydir>] to allow serving the
        static resources for Trac directly from the web server.
        Note however that this only applies to the `<deploydir>/htdocs/common`
        directory, the other deployed resources (i.e. those from plugins)
        will not be made available this way and additional rewrite
        rules will be needed in the web server.""")

    jquery_location = Option('trac', 'jquery_location', '',
        """Location of the jQuery !JavaScript library (version 1.7.2).

        An empty value loads jQuery from the copy bundled with Trac.

        Alternatively, jQuery could be loaded from a CDN, for example:
        http://code.jquery.com/jquery-1.7.2.min.js,
        http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.7.2.min.js or
        https://ajax.googleapis.com/ajax/libs/jquery/1.7.2/jquery.min.js.

        (''since 1.0'')""")

    jquery_ui_location = Option('trac', 'jquery_ui_location', '',
        """Location of the jQuery UI !JavaScript library (version 1.8.21).

        An empty value loads jQuery UI from the copy bundled with Trac.

        Alternatively, jQuery UI could be loaded from a CDN, for example:
        https://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/jquery-ui.min.js
        or
        http://ajax.aspnetcdn.com/ajax/jquery.ui/1.8.21/jquery-ui.min.js.

        (''since 1.0'')""")

    jquery_ui_theme_location = Option('trac', 'jquery_ui_theme_location', '',
        """Location of the theme to be used with the jQuery UI !JavaScript
        library (version 1.8.21).

        An empty value loads the custom Trac jQuery UI theme from the copy
        bundled with Trac.

        Alternatively, a jQuery UI theme could be loaded from a CDN, for
        example:
        https://ajax.googleapis.com/ajax/libs/jqueryui/1.8.21/themes/start/jquery-ui.css
        or
        http://ajax.aspnetcdn.com/ajax/jquery.ui/1.8.21/themes/start/jquery-ui.css.

        (''since 1.0'')""")

    metanav_order = ListOption('trac', 'metanav',
                               'login, logout, prefs, help, about', doc=
        """Order of the items to display in the `metanav` navigation bar,
           listed by IDs. See also TracNavigation.""")

    mainnav_order = ListOption('trac', 'mainnav',
                               'wiki, timeline, roadmap, browser, tickets, '
                               'newticket, search', doc=
        """Order of the items to display in the `mainnav` navigation bar,
           listed by IDs. See also TracNavigation.""")

    logo_link = Option('header_logo', 'link', '',
        """URL to link to, from the header logo.""")

    logo_src = Option('header_logo', 'src', 'site/your_project_logo.png',
        """URL of the image to use as header logo.
        It can be absolute, server relative or relative.

        If relative, it is relative to one of the `/chrome` locations:
        `site/your-logo.png` if `your-logo.png` is located in the `htdocs`
        folder within your TracEnvironment;
        `common/your-logo.png` if `your-logo.png` is located in the
        folder mapped to the [#trac-section htdocs_location] URL.
        Only specifying `your-logo.png` is equivalent to the latter.""")

    logo_alt = Option('header_logo', 'alt',
        "(please configure the [header_logo] section in trac.ini)",
        """Alternative text for the header logo.""")

    logo_width = IntOption('header_logo', 'width', -1,
        """Width of the header logo image in pixels.""")

    logo_height = IntOption('header_logo', 'height', -1,
        """Height of the header logo image in pixels.""")

    show_email_addresses = BoolOption('trac', 'show_email_addresses', 'false',
        """Show email addresses instead of usernames. If false, we obfuscate
        email addresses. (''since 0.11'')""")

    never_obfuscate_mailto = BoolOption('trac', 'never_obfuscate_mailto',
        'false',
        """Never obfuscate `mailto:` links explicitly written in the wiki,
        even if `show_email_addresses` is false or the user has not the
        EMAIL_VIEW permission (''since 0.11.6'').""")

    show_ip_addresses = BoolOption('trac', 'show_ip_addresses', 'false',
        """Show IP addresses for resource edits (e.g. wiki).
        (''since 0.11.3'')""")

    resizable_textareas = BoolOption('trac', 'resizable_textareas', 'true',
        """Make `<textarea>` fields resizable. Requires !JavaScript.
        (''since 0.12'')""")

    auto_preview_timeout = FloatOption('trac', 'auto_preview_timeout', 2.0,
        """Inactivity timeout in seconds after which the automatic wiki preview
        triggers an update. This option can contain floating-point values. The
        lower the setting, the more requests will be made to the server. Set
        this to 0 to disable automatic preview. The default is 2.0 seconds.
        (''since 0.12'')""")

    default_dateinfo_format = Option('trac', 'default_dateinfo_format',
        'relative',
        """The date information format. Valid options are 'relative' for
        displaying relative format and 'absolute' for displaying absolute
        format. (''since 1.0'')
        """)

    templates = None

    # default doctype for 'text/html' output
    default_html_doctype = DocType.XHTML_STRICT

    # A dictionary of default context data for templates
    _default_context_data = {
        '_': translation.gettext,
        'all': all,
        'any': any,
        'classes': presentation.classes,
        'date': datetime.date,
        'datetime': datetime.datetime,
        'dgettext': translation.dgettext,
        'dngettext': translation.dngettext,
        'first_last': presentation.first_last,
        'get_reporter_id': get_reporter_id,
        'gettext': translation.gettext,
        'group': presentation.group,
        'groupby': compat.py_groupby, # http://bugs.python.org/issue2246
        'http_date': http_date,
        'istext': presentation.istext,
        'javascript_quote': javascript_quote,
        'ngettext': translation.ngettext,
        'paginate': presentation.paginate,
        'partial': partial,
        'pathjoin': pathjoin,
        'plaintext': plaintext,
        'pprint': pprint.pformat,
        'pretty_size': pretty_size,
        'pretty_timedelta': pretty_timedelta,
        'quote_plus': unicode_quote_plus,
        'reversed': reversed,
        'separated': presentation.separated,
        'shorten_line': shorten_line,
        'sorted': sorted,
        'time': datetime.time,
        'timedelta': datetime.timedelta,
        'to_json': presentation.to_json,
        'to_unicode': to_unicode,
        'utc': utc,
    }

    # ISystemInfoProvider methods

    def get_system_info(self):
        import genshi
        info = get_pkginfo(genshi).get('version')
        if hasattr(genshi, '_speedups'):
            info += ' (with speedups)'
        else:
            info += ' (without speedups)'
        yield 'Genshi', info
        try:
            import babel
        except ImportError:
            babel = None
        if babel is not None:
            info = get_pkginfo(babel).get('version')
            if not get_available_locales():
                info += " (translations unavailable)" # No i18n on purpose
                self.log.warning("Locale data is missing")
            yield 'Babel', info

    # IEnvironmentSetupParticipant methods

    def environment_created(self):
        """Create the environment templates directory."""
        if self.env.path:
            templates_dir = os.path.join(self.env.path, 'templates')
            if not os.path.exists(templates_dir):
                os.mkdir(templates_dir)

            site_path = os.path.join(templates_dir, 'site.html.sample')
            with open(site_path, 'w') as fileobj:
                fileobj.write("""\
<html xmlns="http://www.w3.org/1999/xhtml"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:py="http://genshi.edgewall.org/"
      py:strip="">
  <!--!
    This file allows customizing the appearance of the Trac installation.
    Add your customizations here and rename the file to site.html. Note that
    it will take precedence over a global site.html placed in the directory
    specified by [inherit] templates_dir.

    More information about site appearance customization can be found here:

      http://trac.edgewall.org/wiki/TracInterfaceCustomization#SiteAppearance
  -->
</html>
""")

    def environment_needs_upgrade(self, db):
        return False

    def upgrade_environment(self, db):
        pass

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/chrome/(?P<prefix>[^/]+)/+(?P<filename>.+)',
                         req.path_info)
        if match:
            req.args['prefix'] = match.group('prefix')
            req.args['filename'] = match.group('filename')
            return True

    def process_request(self, req):
        prefix = req.args['prefix']
        filename = req.args['filename']

        dirs = []
        for provider in self.template_providers:
            for dir in [os.path.normpath(dir[1]) for dir
                        in provider.get_htdocs_dirs() or []
                        if dir[0] == prefix]:
                dirs.append(dir)
                path = os.path.normpath(os.path.join(dir, filename))
                assert os.path.commonprefix([dir, path]) == dir
                if os.path.isfile(path):
                    req.send_file(path, get_mimetype(path))

        self.log.warning('File %s not found in any of %s', filename, dirs)
        raise HTTPNotFound('File %s not found', filename)

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return [('common', pkg_resources.resource_filename('trac', 'htdocs')),
                ('shared', self.shared_htdocs_dir),
                ('site', self.env.get_htdocs_dir())]

    def get_templates_dirs(self):
        return filter(None, [
            self.env.get_templates_dir(),
            self.shared_templates_dir,
            pkg_resources.resource_filename('trac', 'templates'),
        ])

    # IWikiSyntaxProvider methods

    def get_wiki_syntax(self):
        return []

    def get_link_resolvers(self):
        yield ('htdocs', self._format_link)

    def _format_link(self, formatter, ns, file, label):
        file, query, fragment = formatter.split_link(file)
        href = formatter.href.chrome('site', file) + query + fragment
        return tag.a(label, href=href)

    # Public API methods

    def get_all_templates_dirs(self):
        """Return a list of the names of all known templates directories."""
        dirs = []
        for provider in self.template_providers:
            dirs.extend(provider.get_templates_dirs() or [])
        return dirs

    def prepare_request(self, req, handler=None):
        """Prepare the basic chrome data for the request.

        :param     req: the request object
        :param handler: the `IRequestHandler` instance that is processing the
                        request
        """
        self.log.debug('Prepare chrome data for request')

        chrome = {'metas': [], 'links': {}, 'scripts': [], 'script_data': {},
                  'ctxtnav': [], 'warnings': [], 'notices': []}
        req.chrome = chrome

        htdocs_location = self.htdocs_location or req.href.chrome('common')
        chrome['htdocs_location'] = htdocs_location.rstrip('/') + '/'

        # HTML <head> links
        add_link(req, 'start', req.href.wiki())
        add_link(req, 'search', req.href.search())
        add_link(req, 'help', req.href.wiki('TracGuide'))
        add_stylesheet(req, 'common/css/trac.css')
        add_script(req, self.jquery_location or 'common/js/jquery.js')
        # Only activate noConflict mode if requested to by the handler
        if handler is not None and \
           getattr(handler.__class__, 'jquery_noconflict', False):
            add_script(req, 'common/js/noconflict.js')
        add_script(req, 'common/js/babel.js')
        if req.locale is not None:
            add_script(req, 'common/js/messages/%s.js' % req.locale)
        add_script(req, 'common/js/trac.js')
        add_script(req, 'common/js/search.js')

        # Shortcut icon
        chrome['icon'] = self.get_icon_data(req)
        if chrome['icon']:
            src = chrome['icon']['src']
            mimetype = chrome['icon']['mimetype']
            add_link(req, 'icon', src, mimetype=mimetype)
            add_link(req, 'shortcut icon', src, mimetype=mimetype)

        # Logo image
        chrome['logo'] = self.get_logo_data(req.href, req.abs_href)

        # Navigation links
        allitems = {}
        active = None
        for contributor in self.navigation_contributors:
            try:
                for category, name, text in \
                        contributor.get_navigation_items(req) or []:
                    category_section = self.config[category]
                    if category_section.getbool(name, True):
                        # the navigation item is enabled (this is the default)
                        item = None
                        if isinstance(text, Element) and \
                                text.tag.localname == 'a':
                            item = text
                        label = category_section.get(name + '.label')
                        href = category_section.get(name + '.href')
                        if href:
                            if href.startswith('/'):
                                href = req.href + href
                            if label:
                                item = tag.a(label) # create new label
                            elif not item:
                                item = tag.a(text) # wrap old text
                            item = item(href=href) # use new href
                        elif label and item: # create new label, use old href
                            item = tag.a(label, href=item.attrib.get('href'))
                        elif not item: # use old text
                            item = text
                        allitems.setdefault(category, {})[name] = item
                if contributor is handler:
                    active = contributor.get_active_navigation_item(req)
            except Exception, e:
                name = contributor.__class__.__name__
                if isinstance(e, TracError):
                    self.log.warning("Error with navigation contributor %s",
                                     name)
                else:
                    self.log.error("Error with navigation contributor %s: %s",
                                   name, exception_to_unicode(e))
                add_warning(req, _("Error with navigation contributor "
                                   '"%(name)s"', name=name))

        nav = {}
        for category, items in [(k, v.items()) for k, v in allitems.items()]:
            category_order = category + '_order'
            if hasattr(self, category_order):
                order = getattr(self, category_order)
                def navcmp(x, y):
                    if x[0] not in order:
                        return int(y[0] in order)
                    if y[0] not in order:
                        return -int(x[0] in order)
                    return cmp(order.index(x[0]), order.index(y[0]))
                items.sort(navcmp)

            nav[category] = []
            for name, label in items:
                nav[category].append({
                    'name': name,
                    'label': label,
                    'active': name == active
                })

        chrome['nav'] = nav

        # Default theme file
        chrome['theme'] = 'theme.html'

        # Avoid recursion by registering as late as possible (#8583)
        req.add_redirect_listener(_save_messages)

        return chrome

    def get_icon_data(self, req):
        icon = {}
        icon_src = icon_abs_src = self.env.project_icon
        if icon_src:
            if not icon_src.startswith('/') and icon_src.find('://') == -1:
                if '/' in icon_src:
                    icon_abs_src = req.abs_href.chrome(icon_src)
                    icon_src = req.href.chrome(icon_src)
                else:
                    icon_abs_src = req.abs_href.chrome('common', icon_src)
                    icon_src = req.href.chrome('common', icon_src)
            mimetype = get_mimetype(icon_src)
            icon = {'src': icon_src, 'abs_src': icon_abs_src,
                    'mimetype': mimetype}
        return icon

    def get_logo_data(self, href, abs_href=None):
        # TODO: Possibly, links to 'common/' could use chrome.htdocs_location
        logo = {}
        logo_src = self.logo_src
        if logo_src:
            abs_href = abs_href or href
            if logo_src.startswith(('http://', 'https://', '/')):
                # Nothing further can be calculated
                logo_src_abs = logo_src
            elif '/' in logo_src:
                # Like 'common/trac_banner.png' or 'site/my_banner.png'
                logo_src_abs = abs_href.chrome(logo_src)
                logo_src = href.chrome(logo_src)
            else:
                # Like 'trac_banner.png'
                logo_src_abs = abs_href.chrome('common', logo_src)
                logo_src = href.chrome('common', logo_src)
            width = self.logo_width if self.logo_width > -1 else None
            height = self.logo_height if self.logo_height > -1 else None
            logo = {
                'link': self.logo_link, 'src': logo_src,
                'src_abs': logo_src_abs, 'alt': self.logo_alt,
                'width': width, 'height': height
            }
        else:
            logo = {'link': self.logo_link, 'alt': self.logo_alt}
        return logo

    def populate_data(self, req, data):
        d = self._default_context_data.copy()
        d['trac'] = {
            'version': pkg_resources.resource_string('trac', 'TRAC_VERSION').strip(),
            'homepage': 'http://trac.edgewall.org/', # FIXME: use setup data
        }

        href = req and req.href
        abs_href = req.abs_href if req else self.env.abs_href
        admin_href = None
        if self.env.project_admin_trac_url == '.':
            admin_href = href
        elif self.env.project_admin_trac_url:
            admin_href = Href(self.env.project_admin_trac_url)

        d['project'] = {
            'name': self.env.project_name,
            'descr': self.env.project_description,
            'url': self.env.project_url,
            'admin': self.env.project_admin,
            'admin_href': admin_href,
            'admin_trac_url': self.env.project_admin_trac_url,
        }
        footer = self.env.project_footer
        d['chrome'] = {
            'footer': Markup(footer and translation.gettext(footer))
        }
        if req:
            d['chrome'].update(req.chrome)
        else:
            d['chrome'].update({
                'htdocs_location': self.htdocs_location,
                'logo': self.get_logo_data(self.env.abs_href),
            })

        try:
            show_email_addresses = (self.show_email_addresses or not req or \
                                'EMAIL_VIEW' in req.perm)
        except Exception, e:
            # simply log the exception here, as we might already be rendering
            # the error page
            self.log.error("Error during check of EMAIL_VIEW: %s",
                           exception_to_unicode(e))
            show_email_addresses = False

        def pretty_dateinfo(date, format=None, dateonly=False):
            absolute = user_time(req, format_datetime, date)
            relative = pretty_timedelta(date)
            if not format:
                format = req.session.get('dateinfo',
                                         self.default_dateinfo_format)
            if format == 'absolute':
                label = absolute
                title = _("%(relativetime)s ago", relativetime=relative)
            else:
                label = _("%(relativetime)s ago", relativetime=relative) \
                        if not dateonly else relative
                title = absolute
            return tag.span(label, title=title)

        def dateinfo(date):
            return pretty_dateinfo(date, format='relative', dateonly=True)

        def get_rel_url(resource, **kwargs):
            return get_resource_url(self.env, resource, href, **kwargs)

        def get_abs_url(resource, **kwargs):
            return get_resource_url(self.env, resource, abs_href, **kwargs)

        d.update({
            'context': web_context(req) if req else None,
            'Resource': Resource,
            'Neighborhood': Neighborhood,
            'url_of': get_rel_url,
            'abs_url_of': get_abs_url,
            'name_of': partial(get_resource_name, self.env),
            'shortname_of': partial(get_resource_shortname, self.env),
            'summary_of': partial(get_resource_summary, self.env),
            'req': req,
            'abs_href': abs_href,
            'href': href,
            'perm': req and req.perm,
            'authname': req.authname if req else '<trac>',
            'locale': req and req.locale,
            'show_email_addresses': show_email_addresses,
            'show_ip_addresses': self.show_ip_addresses,
            'authorinfo': partial(self.authorinfo, req),
            'authorinfo_short': self.authorinfo_short,
            'format_author': partial(self.format_author, req),
            'format_emails': self.format_emails,
            'get_systeminfo': self.env.get_systeminfo,
            'captioned_button': partial(presentation.captioned_button, req),

            # Date/time formatting
            'dateinfo': dateinfo,
            'pretty_dateinfo': pretty_dateinfo,
            'format_datetime': partial(user_time, req, format_datetime),
            'format_date': partial(user_time, req, format_date),
            'format_time': partial(user_time, req, format_time),
            'fromtimestamp': partial(datetime.datetime.fromtimestamp,
                                     tz=req and req.tz),
            'from_utimestamp': from_utimestamp,

            # Wiki-formatting functions
            'wiki_to': partial(format_to, self.env),
            'wiki_to_html': partial(format_to_html, self.env),
            'wiki_to_oneliner': partial(format_to_oneliner, self.env),
        })

        # Finally merge in the page-specific data
        d.update(data)
        return d

    def load_template(self, filename, method=None):
        """Retrieve a Template and optionally preset the template data.

        Also, if the optional `method` argument is set to `'text'`, a
        `NewTextTemplate` instance will be created instead of a
        `MarkupTemplate`.
        """
        if not self.templates:
            self.templates = TemplateLoader(
                self.get_all_templates_dirs(), auto_reload=self.auto_reload,
                max_cache_size=self.genshi_cache_size,
                default_encoding="utf-8",
                variable_lookup='lenient', callback=lambda template:
                Translator(translation.get_translations()).setup(template))

        if method == 'text':
            cls = NewTextTemplate
        else:
            cls = MarkupTemplate

        return self.templates.load(filename, cls=cls)

    def render_template(self, req, filename, data, content_type=None,
                        fragment=False):
        """Render the `filename` using the `data` for the context.

        The `content_type` argument is used to choose the kind of template
        used (`NewTextTemplate` if `'text/plain'`, `MarkupTemplate` otherwise),
        and tweak the rendering process. Doctype for `'text/html'` can be
        specified by setting the default_html_doctype (default is XHTML Strict)

        When `fragment` is specified, the (filtered) Genshi stream is
        returned.
        """
        if content_type is None:
            content_type = 'text/html'
        method = {'text/html': 'xhtml',
                  'text/plain': 'text'}.get(content_type, 'xml')

        if method == "xhtml":
            # Retrieve post-redirect messages saved in session
            for type_ in ['warnings', 'notices']:
                try:
                    for i in itertools.count():
                        message = Markup(req.session.pop('chrome.%s.%d'
                                                         % (type_, i)))
                        if message not in req.chrome[type_]:
                            req.chrome[type_].append(message)
                except KeyError:
                    pass

        template = self.load_template(filename, method=method)
        data = self.populate_data(req, data)
        data['chrome']['content_type'] = content_type

        stream = template.generate(**data)

        # Filter through ITemplateStreamFilter plugins
        if self.stream_filters:
            stream |= self._filter_stream(req, method, filename, stream, data)

        if fragment:
            return stream

        if method == 'text':
            buffer = StringIO()
            stream.render('text', out=buffer, encoding='utf-8')
            return buffer.getvalue()

        doctype = {'text/html': Chrome.default_html_doctype}.get(content_type)
        if doctype:
            if req.form_token:
                stream |= self._add_form_token(req.form_token)
            if not int(req.session.get('accesskeys', 0)):
                stream |= self._strip_accesskeys

        links = req.chrome.get('links')
        scripts = req.chrome.get('scripts')
        script_data = req.chrome.get('script_data')
        req.chrome['links'] = {}
        req.chrome['scripts'] = []
        req.chrome['script_data'] = {}
        data.setdefault('chrome', {}).update({
            'late_links': req.chrome['links'],
            'late_scripts': req.chrome['scripts'],
            'late_script_data': req.chrome['script_data'],
        })

        try:
            buffer = StringIO()
            stream.render(method, doctype=doctype, out=buffer,
                          encoding='utf-8')
            return buffer.getvalue().translate(_translate_nop,
                                               _invalid_control_chars)
        except Exception, e:
            # restore what may be needed by the error template
            req.chrome['links'] = links
            req.chrome['scripts'] = scripts
            req.chrome['script_data'] = script_data
            # give some hints when hitting a Genshi unicode error
            if isinstance(e, UnicodeError):
                pos = self._stream_location(stream)
                if pos:
                    location = "'%s', line %s, char %s" % pos
                else:
                    location = _("(unknown template location)")
                raise TracError(_("Genshi %(error)s error while rendering "
                                  "template %(location)s",
                                  error=e.__class__.__name__,
                                  location=location))
            raise

    # E-mail formatting utilities

    def cc_list(self, cc_field):
        """Split a CC: value in a list of addresses."""
        ccs = []
        for cc in re.split(r'[;,]', cc_field):
            cc = cc.strip()
            if cc:
                ccs.append(cc)
        return ccs

    def format_emails(self, context, value, sep=', '):
        """Normalize a list of e-mails and obfuscate them if needed.

        :param context: the context in which the check for obfuscation should
                        be done
        :param   value: a string containing a comma-separated list of e-mails
        :param     sep: the separator to use when rendering the list again
        """
        all_cc = self.cc_list(value)
        if not (self.show_email_addresses or 'EMAIL_VIEW' in context.perm):
            all_cc = [obfuscate_email_address(cc) for cc in all_cc]
        return sep.join(all_cc)

    def authorinfo(self, req, author, email_map=None):
        return self.format_author(req,
                                  email_map and '@' not in author and
                                  email_map.get(author) or author)

    def get_email_map(self):
        """Get the email addresses of all known users."""
        email_map = {}
        if self.show_email_addresses:
            for username, name, email in self.env.get_known_users():
                if email:
                    email_map[username] = email
        return email_map

    _long_author_re = re.compile(r'.*<([^@]+)@[^@]+>\s*|([^@]+)@[^@]+')

    def authorinfo_short(self, author):
        if not author or author == 'anonymous':
            return _("anonymous")
        match = self._long_author_re.match(author)
        if match:
            return match.group(1) or match.group(2)
        return author

    def format_author(self, req, author):
        if not author or author == 'anonymous':
            return _("anonymous")
        if self.show_email_addresses or not req or 'EMAIL_VIEW' in req.perm:
            return author
        return obfuscate_email_address(author)

    # Element modifiers

    def add_textarea_grips(self, req):
        """Make `<textarea class="trac-resizable">` fields resizable if enabled
        by configuration."""
        if self.resizable_textareas:
            add_script(req, 'common/js/resizer.js')

    def add_wiki_toolbars(self, req):
        """Add wiki toolbars to `<textarea class="wikitext">` fields."""
        add_script(req, 'common/js/wikitoolbar.js')
        self.add_textarea_grips(req)

    def add_auto_preview(self, req):
        """Setup auto-preview for `<textarea>` fields."""
        add_script(req, 'common/js/auto_preview.js')
        add_script_data(req, auto_preview_timeout=self.auto_preview_timeout,
                        form_token=req.form_token)

    def add_jquery_ui(self, req):
        """Add a reference to the jQuery UI script and link the stylesheet."""
        add_script(req, self.jquery_ui_location
                        or 'common/js/jquery-ui.js')
        add_stylesheet(req, self.jquery_ui_theme_location
                            or 'common/css/jquery-ui/jquery-ui.css')
        add_script(req, 'common/js/jquery-ui-addons.js')
        add_stylesheet(req, 'common/css/jquery-ui-addons.css')
        is_iso8601 = req.lc_time == 'iso8601'
        add_script_data(req, jquery_ui={
            'month_names': get_month_names_jquery_ui(req),
            'day_names': get_day_names_jquery_ui(req),
            'date_format': get_date_format_jquery_ui(req.lc_time),
            'time_format': get_time_format_jquery_ui(req.lc_time),
            'ampm': not is_24_hours(req.lc_time),
            'first_week_day': get_first_week_day_jquery_ui(req),
            'timepicker_separator': 'T' if is_iso8601 else ' ',
            'show_timezone': is_iso8601,
            'timezone_list': get_timezone_list_jquery_ui() \
                             if is_iso8601 else [],
            'timezone_iso8601': is_iso8601,
        })
        add_script(req, 'common/js/jquery-ui-i18n.js')

    # Template filters

    def _add_form_token(self, token):
        elem = tag.div(
            tag.input(type='hidden', name='__FORM_TOKEN', value=token)
        )
        def _generate(stream, ctxt=None):
            for kind, data, pos in stream:
                if kind is START and data[0].localname == 'form' \
                                 and data[1].get('method', '').lower() == 'post':
                    yield kind, data, pos
                    for event in elem.generate():
                        yield event
                else:
                    yield kind, data, pos
        return _generate

    def _strip_accesskeys(self, stream, ctxt=None):
        for kind, data, pos in stream:
            if kind is START and 'accesskey' in data[1]:
                data = data[0], Attrs([(k, v) for k, v in data[1]
                                       if k != 'accesskey'])
            yield kind, data, pos

    def _filter_stream(self, req, method, filename, stream, data):
        def inner(stream, ctxt=None):
            for filter in self.stream_filters:
                stream = filter.filter_stream(req, method, filename, stream,
                                              data)
            return stream
        return inner

    def _stream_location(self, stream):
        for kind, data, pos in stream:
            return pos


########NEW FILE########
__FILENAME__ = fcgi_frontend
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Matthew Good <trac@matt-good.net>

import os
import pkg_resources
import urllib

from trac import __version__ as VERSION
from trac.web.main import dispatch_request

use_flup = os.environ.get('TRAC_USE_FLUP', False)
if use_flup in ('0', 'no', 'off'):
    use_flup = False


class FlupMiddleware(object):
    """Flup doesn't URL unquote the PATH_INFO, so we need to do it."""
    def __init__(self, application):
        self.application = application

    def __call__(self, environ, start_response):
        environ['PATH_INFO'] = urllib.unquote(environ.get('PATH_INFO', ''))
        return self.application(environ, start_response)

params = {}

if use_flup:
    try:
        from flup.server.fcgi import WSGIServer
        params['maxThreads'] = 15
        dispatch_request = FlupMiddleware(dispatch_request)
    except ImportError:
        use_flup = False

if not use_flup:
    from _fcgi import WSGIServer

def run():
    WSGIServer(dispatch_request, **params).run()

if __name__ == '__main__':
    pkg_resources.require('Trac==%s' % VERSION)
    run()

########NEW FILE########
__FILENAME__ = href
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2004 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

import re

from trac.util.text import unicode_quote, unicode_urlencode


slashes_re = re.compile(r'/{2,}')


class Href(object):
    """Implements a callable that constructs URLs with the given base. The
    function can be called with any number of positional and keyword
    arguments which then are used to assemble the URL.

    Positional arguments are appended as individual segments to
    the path of the URL:

    >>> href = Href('/trac')
    >>> href('ticket', 540)
    '/trac/ticket/540'
    >>> href('ticket', 540, 'attachment', 'bugfix.patch')
    '/trac/ticket/540/attachment/bugfix.patch'
    >>> href('ticket', '540/attachment/bugfix.patch')
    '/trac/ticket/540/attachment/bugfix.patch'

    If a positional parameter evaluates to None, it will be skipped:

    >>> href('ticket', 540, 'attachment', None)
    '/trac/ticket/540/attachment'

    The first path segment can also be specified by calling an attribute
    of the instance, as follows:

    >>> href.ticket(540)
    '/trac/ticket/540'
    >>> href.changeset(42, format='diff')
    '/trac/changeset/42?format=diff'

    Simply calling the Href object with no arguments will return the base URL:

    >>> href()
    '/trac'

    Keyword arguments are added to the query string, unless the value is None:

    >>> href = Href('/trac')
    >>> href('timeline', format='rss')
    '/trac/timeline?format=rss'
    >>> href('timeline', format=None)
    '/trac/timeline'
    >>> href('search', q='foo bar')
    '/trac/search?q=foo+bar'

    Multiple values for one parameter are specified using a sequence (a list or
    tuple) for the parameter:

    >>> href('timeline', show=['ticket', 'wiki', 'changeset'])
    '/trac/timeline?show=ticket&show=wiki&show=changeset'

    Alternatively, query string parameters can be added by passing a dict or
    list as last positional argument:

    >>> href('timeline', {'from': '02/24/05', 'daysback': 30})
    '/trac/timeline?daysback=30&from=02%2F24%2F05'
    >>> href('timeline', {})
    '/trac/timeline'
    >>> href('timeline', [('from', '02/24/05')])
    '/trac/timeline?from=02%2F24%2F05'
    >>> href('timeline', ()) == href('timeline', []) == href('timeline', {})
    True

    The usual way of quoting arguments that would otherwise be interpreted
    as Python keywords is supported too:

    >>> href('timeline', from_='02/24/05', daysback=30)
    '/trac/timeline?from=02%2F24%2F05&daysback=30'

    If the order of query string parameters should be preserved, you may also
    pass a sequence of (name, value) tuples as last positional argument:

    >>> href('query', (('group', 'component'), ('groupdesc', 1)))
    '/trac/query?group=component&groupdesc=1'

    >>> params = []
    >>> params.append(('group', 'component'))
    >>> params.append(('groupdesc', 1))
    >>> href('query', params)
    '/trac/query?group=component&groupdesc=1'

    By specifying an absolute base, the function returned will also generate
    absolute URLs:

    >>> href = Href('http://trac.edgewall.org')
    >>> href('ticket', 540)
    'http://trac.edgewall.org/ticket/540'

    >>> href = Href('https://trac.edgewall.org')
    >>> href('ticket', 540)
    'https://trac.edgewall.org/ticket/540'

    In common usage, it may improve readability to use the function-calling
    ability for the first component of the URL as mentioned earlier:

    >>> href = Href('/trac')
    >>> href.ticket(540)
    '/trac/ticket/540'
    >>> href.browser('/trunk/README.txt', format='txt')
    '/trac/browser/trunk/README.txt?format=txt'

    The ``path_safe`` argument specifies the characters that don't
    need to be quoted in the path arguments. Likewise, the
    ``query_safe`` argument specifies the characters that don't need
    to be quoted in the query string:

    >>> href = Href('')
    >>> href.milestone('<look,here>', param='<here,too>')
    '/milestone/%3Clook%2Chere%3E?param=%3Chere%2Ctoo%3E'

    >>> href = Href('', path_safe='/<,', query_safe=',>')
    >>> href.milestone('<look,here>', param='<here,too>')
    '/milestone/<look,here%3E?param=%3Chere,too>'
    """

    def __init__(self, base, path_safe="/!~*'()", query_safe="!~*'()"):
        self.base = base.rstrip('/')
        self.path_safe = path_safe
        self.query_safe = query_safe
        self._derived = {}

    def __call__(self, *args, **kw):
        href = self.base
        params = []

        def add_param(name, value):
            if isinstance(value, (list, tuple)):
                for i in [i for i in value if i is not None]:
                    params.append((name, i))
            elif value is not None:
                params.append((name, value))

        if args:
            lastp = args[-1]
            if isinstance(lastp, dict):
                for k, v in lastp.items():
                    add_param(k, v)
                args = args[:-1]
            elif isinstance(lastp, (list, tuple)):
                for k, v in lastp:
                    add_param(k, v)
                args = args[:-1]

        # build the path
        path = '/'.join(unicode_quote(unicode(arg).strip('/'), self.path_safe)
                        for arg in args if arg is not None)
        if path:
            href += '/' + slashes_re.sub('/', path).lstrip('/')
        elif not href:
            href = '/'

        # assemble the query string
        for k, v in kw.items():
            add_param(k[:-1] if k.endswith('_') else k, v)
        if params:
            href += '?' + unicode_urlencode(params, self.query_safe)

        return href

    def __getattr__(self, name):
        if name not in self._derived:
            self._derived[name] = lambda *args, **kw: self(name, *args, **kw)
        return self._derived[name]

    def __add__(self, rhs):
        if rhs.startswith('/'):
            return self.base + rhs
        if rhs:
            return self.base + '/' + rhs
        return self.base or '/'


if __name__ == '__main__':
    import doctest, sys
    doctest.testmod(sys.modules[__name__])

########NEW FILE########
__FILENAME__ = main
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2007 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>
#         Matthew Good <trac@matt-good.net>

import cgi
import dircache
import fnmatch
from functools import partial
import gc
import locale
import os
import pkg_resources
from pprint import pformat, pprint
import re
import sys

from genshi.builder import Fragment, tag
from genshi.output import DocType
from genshi.template import TemplateLoader

from trac import __version__ as TRAC_VERSION
from trac.config import BoolOption, ExtensionOption, Option, \
                        OrderedExtensionsOption
from trac.core import *
from trac.env import open_environment
from trac.loader import get_plugin_info, match_plugins_to_frames
from trac.perm import PermissionCache, PermissionError
from trac.resource import ResourceNotFound
from trac.util import arity, get_frame_info, get_last_traceback, hex_entropy, \
                      read_file, safe_repr, translation
from trac.util.concurrency import threading
from trac.util.datefmt import format_datetime, localtz, timezone, user_time
from trac.util.text import exception_to_unicode, shorten_line, to_unicode
from trac.util.translation import _, get_negotiated_locale, has_babel, \
                                  safefmt, tag_
from trac.web.api import *
from trac.web.chrome import Chrome
from trac.web.href import Href
from trac.web.session import Session

#: This URL is used for semi-automatic bug reports (see
#: `send_internal_error`).  Please modify it to point to your own
#: Trac instance if you distribute a patched version of Trac.
default_tracker = 'http://trac.edgewall.org'


class FakeSession(dict):
    sid = None
    def save(self):
        pass


class FakePerm(dict):
    def require(self, *args):
        return False
    def __call__(self, *args):
        return self


class RequestWithSession(Request):
    """A request that saves its associated session when sending the reply."""

    def send_response(self, code=200):
        if code < 400:
            self.session.save()
        super(RequestWithSession, self).send_response(code)


class RequestDispatcher(Component):
    """Web request dispatcher.

    This component dispatches incoming requests to registered
    handlers.  Besides, it also takes care of user authentication and
    request pre- and post-processing.
    """
    required = True

    authenticators = ExtensionPoint(IAuthenticator)
    handlers = ExtensionPoint(IRequestHandler)

    filters = OrderedExtensionsOption('trac', 'request_filters',
                                      IRequestFilter,
        doc="""Ordered list of filters to apply to all requests
            (''since 0.10'').""")

    default_handler = ExtensionOption('trac', 'default_handler',
                                      IRequestHandler, 'WikiModule',
        """Name of the component that handles requests to the base
        URL.

        Options include `TimelineModule`, `RoadmapModule`,
        `BrowserModule`, `QueryModule`, `ReportModule`, `TicketModule`
        and `WikiModule`. The default is `WikiModule`. (''since 0.9'')""")

    default_timezone = Option('trac', 'default_timezone', '',
        """The default timezone to use""")

    default_language = Option('trac', 'default_language', '',
        """The preferred language to use if no user preference has
        been set. (''since 0.12.1'')
        """)

    default_date_format = Option('trac', 'default_date_format', '',
        """The date format. Valid options are 'iso8601' for selecting
        ISO 8601 format, or leave it empty which means the default
        date format will be inferred from the browser's default
        language. (''since 1.0'')
        """)

    use_xsendfile = BoolOption('trac', 'use_xsendfile', 'false',
        """When true, send a `X-Sendfile` header and no content when sending
        files from the filesystem, so that the web server handles the content.
        This requires a web server that knows how to handle such a header,
        like Apache with `mod_xsendfile` or lighttpd. (''since 1.0'')
        """)

    # Public API

    def authenticate(self, req):
        for authenticator in self.authenticators:
            authname = authenticator.authenticate(req)
            if authname:
                return authname
        else:
            return 'anonymous'

    def dispatch(self, req):
        """Find a registered handler that matches the request and let
        it process it.

        In addition, this method initializes the data dictionary
        passed to the the template and adds the web site chrome.
        """
        self.log.debug('Dispatching %r', req)
        chrome = Chrome(self.env)

        # Setup request callbacks for lazily-evaluated properties
        req.callbacks.update({
            'authname': self.authenticate,
            'chrome': chrome.prepare_request,
            'perm': self._get_perm,
            'session': self._get_session,
            'locale': self._get_locale,
            'lc_time': self._get_lc_time,
            'tz': self._get_timezone,
            'form_token': self._get_form_token,
            'use_xsendfile': self._get_use_xsendfile,
        })

        try:
            try:
                # Select the component that should handle the request
                chosen_handler = None
                try:
                    for handler in self.handlers:
                        if handler.match_request(req):
                            chosen_handler = handler
                            break
                    if not chosen_handler:
                        if not req.path_info or req.path_info == '/':
                            chosen_handler = self.default_handler
                    # pre-process any incoming request, whether a handler
                    # was found or not
                    chosen_handler = self._pre_process_request(req,
                                                            chosen_handler)
                except TracError, e:
                    raise HTTPInternalError(e)
                if not chosen_handler:
                    if req.path_info.endswith('/'):
                        # Strip trailing / and redirect
                        target = req.path_info.rstrip('/').encode('utf-8')
                        if req.query_string:
                            target += '?' + req.query_string
                        req.redirect(req.href + target, permanent=True)
                    raise HTTPNotFound('No handler matched request to %s',
                                       req.path_info)

                req.callbacks['chrome'] = partial(chrome.prepare_request,
                                                  handler=chosen_handler)

                # Protect against CSRF attacks: we validate the form token
                # for all POST requests with a content-type corresponding
                # to form submissions
                if req.method == 'POST':
                    ctype = req.get_header('Content-Type')
                    if ctype:
                        ctype, options = cgi.parse_header(ctype)
                    if ctype in ('application/x-www-form-urlencoded',
                                 'multipart/form-data') and \
                            req.args.get('__FORM_TOKEN') != req.form_token:
                        if self.env.secure_cookies and req.scheme == 'http':
                            msg = _('Secure cookies are enabled, you must '
                                    'use https to submit forms.')
                        else:
                            msg = _('Do you have cookies enabled?')
                        raise HTTPBadRequest(_('Missing or invalid form token.'
                                               ' %(msg)s', msg=msg))

                # Process the request and render the template
                resp = chosen_handler.process_request(req)
                if resp:
                    if len(resp) == 2: # old Clearsilver template and HDF data
                        self.log.error("Clearsilver template are no longer "
                                       "supported (%s)", resp[0])
                        raise TracError(
                            _("Clearsilver templates are no longer supported, "
                              "please contact your Trac administrator."))
                    # Genshi
                    template, data, content_type = \
                              self._post_process_request(req, *resp)
                    if 'hdfdump' in req.args:
                        req.perm.require('TRAC_ADMIN')
                        # debugging helper - no need to render first
                        out = StringIO()
                        pprint(data, out)
                        req.send(out.getvalue(), 'text/plain')

                    output = chrome.render_template(req, template, data,
                                                    content_type)
                    req.send(output, content_type or 'text/html')
                else:
                    self._post_process_request(req)
            except RequestDone:
                raise
            except:
                # post-process the request in case of errors
                err = sys.exc_info()
                try:
                    self._post_process_request(req)
                except RequestDone:
                    raise
                except Exception, e:
                    self.log.error("Exception caught while post-processing"
                                   " request: %s",
                                   exception_to_unicode(e, traceback=True))
                raise err[0], err[1], err[2]
        except PermissionError, e:
            raise HTTPForbidden(to_unicode(e))
        except ResourceNotFound, e:
            raise HTTPNotFound(e)
        except TracError, e:
            raise HTTPInternalError(e)

    # Internal methods

    def _get_perm(self, req):
        if isinstance(req.session, FakeSession):
            return FakePerm()
        else:
            return PermissionCache(self.env, self.authenticate(req))

    def _get_session(self, req):
        try:
            return Session(self.env, req)
        except TracError, e:
            self.log.error("can't retrieve session: %s",
                           exception_to_unicode(e))
            return FakeSession()

    def _get_locale(self, req):
        if has_babel:
            preferred = req.session.get('language')
            default = self.env.config.get('trac', 'default_language', '')
            negotiated = get_negotiated_locale([preferred, default] +
                                               req.languages)
            self.log.debug("Negotiated locale: %s -> %s", preferred, negotiated)
            return negotiated

    def _get_lc_time(self, req):
        lc_time = req.session.get('lc_time')
        if not lc_time or lc_time == 'locale' and not has_babel:
            lc_time = self.default_date_format
        if lc_time == 'iso8601':
            return 'iso8601'
        return req.locale

    def _get_timezone(self, req):
        try:
            return timezone(req.session.get('tz', self.default_timezone
                                            or 'missing'))
        except Exception:
            return localtz

    def _get_form_token(self, req):
        """Used to protect against CSRF.

        The 'form_token' is strong shared secret stored in a user
        cookie.  By requiring that every POST form to contain this
        value we're able to protect against CSRF attacks. Since this
        value is only known by the user and not by an attacker.

        If the the user does not have a `trac_form_token` cookie a new
        one is generated.
        """
        if req.incookie.has_key('trac_form_token'):
            return req.incookie['trac_form_token'].value
        else:
            req.outcookie['trac_form_token'] = hex_entropy(24)
            req.outcookie['trac_form_token']['path'] = req.base_path or '/'
            if self.env.secure_cookies:
                req.outcookie['trac_form_token']['secure'] = True
            if sys.version_info >= (2, 6):
                req.outcookie['trac_form_token']['httponly'] = True
            return req.outcookie['trac_form_token'].value

    def _get_use_xsendfile(self, req):
        return self.use_xsendfile

    def _pre_process_request(self, req, chosen_handler):
        for filter_ in self.filters:
            chosen_handler = filter_.pre_process_request(req, chosen_handler)
        return chosen_handler

    def _post_process_request(self, req, *args):
        nbargs = len(args)
        resp = args
        for f in reversed(self.filters):
            # As the arity of `post_process_request` has changed since
            # Trac 0.10, only filters with same arity gets passed real values.
            # Errors will call all filters with None arguments,
            # and results will not be not saved.
            extra_arg_count = arity(f.post_process_request) - 1
            if extra_arg_count == nbargs:
                resp = f.post_process_request(req, *resp)
            elif nbargs == 0:
                f.post_process_request(req, *(None,)*extra_arg_count)
        return resp

_slashes_re = re.compile(r'/+')


def dispatch_request(environ, start_response):
    """Main entry point for the Trac web interface.

    :param environ: the WSGI environment dict
    :param start_response: the WSGI callback for starting the response
    """

    # SCRIPT_URL is an Apache var containing the URL before URL rewriting
    # has been applied, so we can use it to reconstruct logical SCRIPT_NAME
    script_url = environ.get('SCRIPT_URL')
    if script_url is not None:
        path_info = environ.get('PATH_INFO')
        if not path_info:
            environ['SCRIPT_NAME'] = script_url
        else:
            # mod_wsgi squashes slashes in PATH_INFO (!)
            script_url = _slashes_re.sub('/', script_url)
            path_info = _slashes_re.sub('/', path_info)
            if script_url.endswith(path_info):
                environ['SCRIPT_NAME'] = script_url[:-len(path_info)]

    # If the expected configuration keys aren't found in the WSGI environment,
    # try looking them up in the process environment variables
    environ.setdefault('trac.env_path', os.getenv('TRAC_ENV'))
    environ.setdefault('trac.env_parent_dir',
                       os.getenv('TRAC_ENV_PARENT_DIR'))
    environ.setdefault('trac.env_index_template',
                       os.getenv('TRAC_ENV_INDEX_TEMPLATE'))
    environ.setdefault('trac.template_vars',
                       os.getenv('TRAC_TEMPLATE_VARS'))
    environ.setdefault('trac.locale', '')
    environ.setdefault('trac.base_url',
                       os.getenv('TRAC_BASE_URL'))
    environ.setdefault('trac.bootstrap_handler',
                       os.getenv('TRAC_BOOTSTRAP_HANDLER'))

    locale.setlocale(locale.LC_ALL, environ['trac.locale'])

    # Load handler for environment lookup and instantiation of request objects
    from trac.hooks import load_bootstrap_handler
    bootstrap_ep = environ['trac.bootstrap_handler']
    bootstrap = load_bootstrap_handler(bootstrap_ep, environ.get('wsgi.errors'))

    # Determine the environment
    
    env = env_error = None
    try:
        env = bootstrap.open_environment(environ, start_response)
    except RequestDone:
        return []
    except EnvironmentError, e:
        if e.__class__ is EnvironmentError:
            raise
        else:
            env_error = e
    except Exception, e:
        env_error = e
    else:
        try:
            if env.base_url_for_redirect:
                environ['trac.base_url'] = env.base_url
    
            # Web front-end type and version information
            if not hasattr(env, 'webfrontend'):
                mod_wsgi_version = environ.get('mod_wsgi.version')
                if mod_wsgi_version:
                    mod_wsgi_version = (
                            "%s (WSGIProcessGroup %s WSGIApplicationGroup %s)" %
                            ('.'.join([str(x) for x in mod_wsgi_version]),
                             environ.get('mod_wsgi.process_group'),
                             environ.get('mod_wsgi.application_group') or
                             '%{GLOBAL}'))
                    environ.update({
                        'trac.web.frontend': 'mod_wsgi',
                        'trac.web.version': mod_wsgi_version})
                env.webfrontend = environ.get('trac.web.frontend')
                if env.webfrontend:
                    env.systeminfo.append((env.webfrontend,
                                           environ['trac.web.version']))
        except Exception, e:
            env_error = e

    run_once = environ['wsgi.run_once']

    req = None
    if env_error is None:
        try:
            req = bootstrap.create_request(env, environ, start_response) \
                if env is not None else Request(environ, start_response)
        except Exception, e:
            log = environ.get('wsgi.errors')
            if log:
                log.write("[FAIL] [Trac] Entry point '%s' "
                          "Method 'create_request' Reason %s" %
                          (bootstrap_ep, repr(exception_to_unicode(e))))
    if req is None:
        req = RequestWithSession(environ, start_response)
    translation.make_activable(lambda: req.locale, env.path if env else None)
    try:
        return _dispatch_request(req, env, env_error)
    finally:
        translation.deactivate()
        if env and not run_once:
            env.shutdown(threading._get_ident())
            # Now it's a good time to do some clean-ups
            #
            # Note: enable the '##' lines as soon as there's a suspicion
            #       of memory leak due to uncollectable objects (typically
            #       objects with a __del__ method caught in a cycle)
            #
            ##gc.set_debug(gc.DEBUG_UNCOLLECTABLE)
            unreachable = gc.collect()
            ##env.log.debug("%d unreachable objects found.", unreachable)
            ##uncollectable = len(gc.garbage)
            ##if uncollectable:
            ##    del gc.garbage[:]
            ##    env.log.warn("%d uncollectable objects found.", uncollectable)


def _dispatch_request(req, env, env_error):
    resp = []

    # fixup env.abs_href if `[trac] base_url` was not specified
    if env and not env.abs_href.base:
        env._abs_href = req.abs_href

    try:
        if not env and env_error:
            raise HTTPInternalError(env_error)
        try:
            dispatcher = RequestDispatcher(env)
            dispatcher.dispatch(req)
        except RequestDone:
            pass
        resp = req._response or []
    except HTTPException, e:
        _send_user_error(req, env, e)
    except Exception, e:
        send_internal_error(env, req, sys.exc_info())
    return resp


def _send_user_error(req, env, e):
    # See trac/web/api.py for the definition of HTTPException subclasses.
    if env:
        env.log.warn('[%s] %s' % (req.remote_addr, exception_to_unicode(e)))
    try:
        # We first try to get localized error messages here, but we
        # should ignore secondary errors if the main error was also
        # due to i18n issues
        title = _('Error')
        if e.reason:
            if title.lower() in e.reason.lower():
                title = e.reason
            else:
                title = _('Error: %(message)s', message=e.reason)
    except Exception:
        title = 'Error'
    # The message is based on the e.detail, which can be an Exception
    # object, but not a TracError one: when creating HTTPException,
    # a TracError.message is directly assigned to e.detail
    if isinstance(e.detail, Exception): # not a TracError
        message = exception_to_unicode(e.detail)
    elif isinstance(e.detail, Fragment): # markup coming from a TracError
        message = e.detail
    else:
        message = to_unicode(e.detail)
    data = {'title': title, 'type': 'TracError', 'message': message,
            'frames': [], 'traceback': None}
    if e.code == 403 and req.authname == 'anonymous':
        # TRANSLATOR: ... not logged in, you may want to 'do so' now (link)
        do_so = tag.a(_("do so"), href=req.href.login())
        req.chrome['notices'].append(
            tag_("You are currently not logged in. You may want to "
                 "%(do_so)s now.", do_so=do_so))
    try:
        req.send_error(sys.exc_info(), status=e.code, env=env, data=data)
    except RequestDone:
        pass

def send_internal_error(env, req, exc_info):
    if env:
        env.log.error("Internal Server Error: %s",
                      exception_to_unicode(exc_info[1], traceback=True))
    message = exception_to_unicode(exc_info[1])
    traceback = get_last_traceback()

    frames, plugins, faulty_plugins = [], [], []
    th = 'http://trac-hacks.org'
    has_admin = False
    try:
        has_admin = 'TRAC_ADMIN' in req.perm
    except Exception:
        pass

    tracker = default_tracker
    if has_admin and not isinstance(exc_info[1], MemoryError):
        # Collect frame and plugin information
        frames = get_frame_info(exc_info[2])
        if env:
            plugins = [p for p in get_plugin_info(env)
                       if any(c['enabled']
                              for m in p['modules'].itervalues()
                              for c in m['components'].itervalues())]
            match_plugins_to_frames(plugins, frames)

            # Identify the tracker where the bug should be reported
            faulty_plugins = [p for p in plugins if 'frame_idx' in p]
            faulty_plugins.sort(key=lambda p: p['frame_idx'])
            if faulty_plugins:
                info = faulty_plugins[0]['info']
                if 'trac' in info:
                    tracker = info['trac']
                elif info.get('home_page', '').startswith(th):
                    tracker = th

    def get_description(_):
        if env and has_admin:
            sys_info = "".join("|| '''`%s`''' || `%s` ||\n"
                               % (k, v.replace('\n', '` [[br]] `'))
                               for k, v in env.get_systeminfo())
            sys_info += "|| '''`jQuery`''' || `#JQUERY#` ||\n"
            enabled_plugins = "".join("|| '''`%s`''' || `%s` ||\n"
                                      % (p['name'], p['version'] or _('N/A'))
                                      for p in plugins)
        else:
            sys_info = _("''System information not available''\n")
            enabled_plugins = _("''Plugin information not available''\n")
        return _("""\
==== How to Reproduce ====

While doing a %(method)s operation on `%(path_info)s`, Trac issued an internal error.

''(please provide additional details here)''

Request parameters:
{{{
%(req_args)s
}}}

User agent: `#USER_AGENT#`

==== System Information ====
%(sys_info)s
==== Enabled Plugins ====
%(enabled_plugins)s
==== Python Traceback ====
{{{
%(traceback)s}}}""",
            method=req.method, path_info=req.path_info,
            req_args=pformat(req.args), sys_info=sys_info,
            enabled_plugins=enabled_plugins, traceback=to_unicode(traceback))

    # Generate the description once in English, once in the current locale
    description_en = get_description(lambda s, **kw: safefmt(s, kw))
    try:
        description = get_description(_)
    except Exception:
        description = description_en

    data = {'title': 'Internal Error',
            'type': 'internal', 'message': message,
            'traceback': traceback, 'frames': frames,
            'shorten_line': shorten_line, 'repr': safe_repr,
            'plugins': plugins, 'faulty_plugins': faulty_plugins,
            'tracker': tracker,
            'description': description, 'description_en': description_en}

    try:
        req.send_error(exc_info, status=500, env=env, data=data)
    except RequestDone:
        pass


def send_project_index(environ, start_response, parent_dir=None,
                       env_paths=None):
    req = Request(environ, start_response)

    loadpaths = [pkg_resources.resource_filename('trac', 'templates')]
    if req.environ.get('trac.env_index_template'):
        env_index_template = req.environ['trac.env_index_template']
        tmpl_path, template = os.path.split(env_index_template)
        loadpaths.insert(0, tmpl_path)
    else:
        template = 'index.html'

    data = {'trac': {'version': TRAC_VERSION,
                     'time': user_time(req, format_datetime)},
            'req': req}
    if req.environ.get('trac.template_vars'):
        for pair in req.environ['trac.template_vars'].split(','):
            key, val = pair.split('=')
            data[key] = val
    try:
        href = Href(req.base_path)
        projects = []
        for env_name, env_path in get_environments(environ).items():
            try:
                env = open_environment(env_path,
                                       use_cache=not environ['wsgi.run_once'])
                proj = {
                    'env': env,
                    'name': env.project_name,
                    'description': env.project_description,
                    'href': href(env_name)
                }
            except Exception, e:
                proj = {'name': env_name, 'description': to_unicode(e)}
            projects.append(proj)
        projects.sort(lambda x, y: cmp(x['name'].lower(), y['name'].lower()))

        data['projects'] = projects

        loader = TemplateLoader(loadpaths, variable_lookup='lenient',
                                default_encoding='utf-8')
        tmpl = loader.load(template)
        stream = tmpl.generate(**data)
        if template.endswith('.xml'):
            output = stream.render('xml')
            req.send(output, 'text/xml')
        else:
            output = stream.render('xhtml', doctype=DocType.XHTML_STRICT,
                                   encoding='utf-8')
            req.send(output, 'text/html')

    except RequestDone:
        pass


def get_tracignore_patterns(env_parent_dir):
    """Return the list of patterns from env_parent_dir/.tracignore or
    a default pattern of `".*"` if the file doesn't exist.
    """
    path = os.path.join(env_parent_dir, '.tracignore')
    try:
        lines = [line.strip() for line in read_file(path).splitlines()]
    except IOError:
        return ['.*']
    return [line for line in lines if line and not line.startswith('#')]


def get_environments(environ, warn=False):
    """Retrieve canonical environment name to path mapping.

    The environments may not be all valid environments, but they are
    good candidates.
    """
    env_paths = environ.get('trac.env_paths', [])
    env_parent_dir = environ.get('trac.env_parent_dir')
    if env_parent_dir:
        env_parent_dir = os.path.normpath(env_parent_dir)
        paths = dircache.listdir(env_parent_dir)[:]
        dircache.annotate(env_parent_dir, paths)

        # Filter paths that match the .tracignore patterns
        ignore_patterns = get_tracignore_patterns(env_parent_dir)
        paths = [path[:-1] for path in paths if path[-1] == '/'
                 and not any(fnmatch.fnmatch(path[:-1], pattern)
                             for pattern in ignore_patterns)]
        env_paths.extend(os.path.join(env_parent_dir, project) \
                         for project in paths)
    envs = {}
    for env_path in env_paths:
        env_path = os.path.normpath(env_path)
        if not os.path.isdir(env_path):
            continue
        env_name = os.path.split(env_path)[1]
        if env_name in envs:
            if warn:
                print >> sys.stderr, ('Warning: Ignoring project "%s" since '
                                      'it conflicts with project "%s"'
                                      % (env_path, envs[env_name]))
        else:
            envs[env_name] = env_path
    return envs

########NEW FILE########
__FILENAME__ = modpython_frontend
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004-2007 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005 Matthew Good <trac@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>
#         Matthew Good <trac@matt-good.net>

from __future__ import with_statement

import os
import pkg_resources
import sys
import urllib
try:
    import threading
except ImportError:
    import dummy_threading as threading

from mod_python import apache
try:
    from mod_python import version
except ImportError:
    version = "< 3.2"

from trac import __version__ as VERSION
from trac.web.wsgi import WSGIGateway, _ErrorsWrapper


class InputWrapper(object):

    def __init__(self, req):
        self.req = req

    def close(self):
        pass

    def read(self, size=-1):
        return self.req.read(size)

    def readline(self, size=-1):
        return self.req.readline(size)

    def readlines(self, hint=-1):
        return self.req.readlines(hint)


class ModPythonGateway(WSGIGateway):

    wsgi_multithread = apache.mpm_query(apache.AP_MPMQ_IS_THREADED) > 0
    wsgi_multiprocess = apache.mpm_query(apache.AP_MPMQ_IS_FORKED) > 0

    def __init__(self, req, options):
        environ = {}
        environ.update(apache.build_cgi_env(req))

        environ['trac.web.frontend'] = 'mod_python'
        environ['trac.web.version'] = version

        if 'TracEnv' in options:
            environ['trac.env_path'] = options['TracEnv']
        if 'TracEnvParentDir' in options:
            environ['trac.env_parent_dir'] = options['TracEnvParentDir']
        if 'TracEnvIndexTemplate' in options:
            environ['trac.env_index_template'] = options['TracEnvIndexTemplate']
        if 'TracTemplateVars' in options:
            environ['trac.template_vars'] = options['TracTemplateVars']
        if 'TracLocale' in options:
            environ['trac.locale'] = options['TracLocale']

        if 'TracUriRoot' in options:
            # Special handling of SCRIPT_NAME/PATH_INFO for mod_python, which
            # tends to get confused for whatever reason
            root_uri = options['TracUriRoot'].rstrip('/')
            request_uri = environ['REQUEST_URI'].split('?', 1)[0]
            if not request_uri.startswith(root_uri):
                raise ValueError('TracUriRoot set to %s but request URL '
                                 'is %s' % (root_uri, request_uri))
            environ['SCRIPT_NAME'] = root_uri
            environ['PATH_INFO'] = urllib.unquote(request_uri[len(root_uri):])

        WSGIGateway.__init__(self, environ, InputWrapper(req),
                             _ErrorsWrapper(lambda x: req.log_error(x)))
        self.req = req

    def _send_headers(self):
        assert self.headers_set, 'Response not started'

        if not self.headers_sent:
            status, headers = self.headers_sent = self.headers_set
            self.req.status = int(status[:3])
            for name, value in headers:
                if name.lower() == 'content-length':
                    self.req.set_content_length(int(value))
                elif name.lower() == 'content-type':
                    self.req.content_type = value
                else:
                    self.req.headers_out.add(name, value)

    def _sendfile(self, fileobj):
        self._send_headers()
        try:
            self.req.sendfile(fileobj.name)
        except IOError, e:
            if 'client closed connection' not in str(e):
                raise

    def _write(self, data):
        self._send_headers()
        try:
            self.req.write(data)
        except IOError, e:
            if 'client closed connection' not in str(e):
                raise

_first = True
_first_lock = threading.Lock()

def handler(req):
    global _first
    with _first_lock:
        if _first:
            _first = False
            options = req.get_options()
            egg_cache = options.get('PYTHON_EGG_CACHE')
            if not egg_cache and options.get('TracEnv'):
                egg_cache = os.path.join(options.get('TracEnv'), '.egg-cache')
            if not egg_cache and options.get('TracEnvParentDir'):
                egg_cache = os.path.join(options.get('TracEnvParentDir'), '.egg-cache')
            if not egg_cache and req.subprocess_env.get('PYTHON_EGG_CACHE'):
                egg_cache = req.subprocess_env.get('PYTHON_EGG_CACHE')
            if egg_cache:
                pkg_resources.set_extraction_path(egg_cache)
            reload(sys.modules['trac.web'])
    pkg_resources.require('Trac==%s' % VERSION)
    gateway = ModPythonGateway(req, req.get_options())
    from trac.web.main import dispatch_request
    gateway.run(dispatch_request)
    return apache.OK

########NEW FILE########
__FILENAME__ = session
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004 Daniel Lundin <daniel@edgewall.com>
# Copyright (C) 2004-2006 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2006 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2008 Matt Good <matt@matt-good.net>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import sys
import time

from trac.admin.api import console_date_format
from trac.core import TracError, Component, implements
from trac.util import hex_entropy
from trac.util.text import print_table
from trac.util.translation import _
from trac.util.datefmt import format_date, parse_date, to_datetime, \
                              to_timestamp
from trac.admin.api import IAdminCommandProvider, AdminCommandError

UPDATE_INTERVAL = 3600 * 24 # Update session last_visit time stamp after 1 day
PURGE_AGE = 3600 * 24 * 90 # Purge session after 90 days idle
COOKIE_KEY = 'trac_session'

# Note: as we often manipulate both the `session` and the
#       `session_attribute` tables, there's a possibility of table
#       deadlocks (#9705). We try to prevent them to happen by always
#       accessing the tables in the same order within the transaction,
#       first `session`, then `session_attribute`.

class DetachedSession(dict):
    def __init__(self, env, sid):
        dict.__init__(self)
        self.env = env
        self.sid = None
        if sid:
            self.get_session(sid, authenticated=True)
        else:
            self.authenticated = False
            self.last_visit = 0
            self._new = True
            self._old = {}

    def __setitem__(self, key, value):
        dict.__setitem__(self, key, unicode(value))

    def set(self, key, value, default=None):
        """Set a variable in the session, or remove it if it's equal to the
        default value.
        """
        value = unicode(value)
        if default is not None:
            default = unicode(default)
            if value == default:
                self.pop(key, None)
                return
        dict.__setitem__(self, key, value)

    def get_session(self, sid, authenticated=False):
        self.env.log.debug("Retrieving session for ID %r", sid)

        with self.env.db_query as db:
            self.sid = sid
            self.authenticated = authenticated
            self.clear()

            for last_visit, in db("""
                    SELECT last_visit FROM session
                    WHERE sid=%s AND authenticated=%s
                    """, (sid, int(authenticated))):
                self._new = False
                self.last_visit = int(last_visit or 0)
                self.update(db("""
                    SELECT name, value FROM session_attribute
                    WHERE sid=%s and authenticated=%s
                    """, (sid, int(authenticated))))
                self._old = self.copy()
                break
            else:
                self.last_visit = 0
                self._new = True
                self._old = {}

    def save(self):
        items = self.items()
        if not self._old and not items:
            # The session doesn't have associated data, so there's no need to
            # persist it
            return

        authenticated = int(self.authenticated)
        now = int(time.time())

        # We can't do the session management in one big transaction,
        # as the intertwined changes to both the session and
        # session_attribute tables are prone to deadlocks (#9705).
        # Therefore we first we save the current session, then we
        # eventually purge the tables.

        session_saved = False

        with self.env.db_transaction as db:
            # Try to save the session if it's a new one. A failure to
            # do so is not critical but we nevertheless skip the
            # following steps.

            if self._new:
                self.last_visit = now
                self._new = False
                # The session might already exist even if _new is True since
                # it could have been created by a concurrent request (#3563).
                try:
                    db("""INSERT INTO session (sid, last_visit, authenticated)
                          VALUES (%s,%s,%s)
                          """, (self.sid, self.last_visit, authenticated))
                except self.env.db_exc.IntegrityError:
                    self.env.log.warning('Session %s already exists', self.sid)
                    db.rollback()
                    return

            # Remove former values for session_attribute and save the
            # new ones. The last concurrent request to do so "wins".

            if self._old != self:
                if not items and not authenticated:
                    # No need to keep around empty unauthenticated sessions
                    db("DELETE FROM session WHERE sid=%s AND authenticated=0",
                       (self.sid,))
                db("""DELETE FROM session_attribute
                      WHERE sid=%s AND authenticated=%s
                      """, (self.sid, authenticated))
                self._old = dict(self.items())
                # The session variables might already have been updated by a
                # concurrent request.
                try:
                    db.executemany("""
                        INSERT INTO session_attribute
                          (sid,authenticated,name,value)
                        VALUES (%s,%s,%s,%s)
                        """, [(self.sid, authenticated, k, v)
                              for k, v in items])
                except self.env.db_exc.IntegrityError:
                    self.env.log.warning('Attributes for session %s already '
                                         'updated', self.sid)
                    db.rollback()
                    return
                session_saved = True

        # Purge expired sessions. We do this only when the session was
        # changed as to minimize the purging.

        if session_saved and now - self.last_visit > UPDATE_INTERVAL:
            self.last_visit = now
            mintime = now - PURGE_AGE

            with self.env.db_transaction as db:
                # Update the session last visit time if it is over an
                # hour old, so that session doesn't get purged
                self.env.log.info("Refreshing session %s", self.sid)
                db("""UPDATE session SET last_visit=%s
                      WHERE sid=%s AND authenticated=%s
                      """, (self.last_visit, self.sid, authenticated))
                self.env.log.debug('Purging old, expired, sessions.')
                db("""DELETE FROM session_attribute
                      WHERE authenticated=0 AND sid IN (
                          SELECT sid FROM session
                          WHERE authenticated=0 AND last_visit < %s
                      )
                      """, (mintime,))

            # Avoid holding locks on lot of rows on both session_attribute
            # and session tables
            with self.env.db_transaction as db:
                db("""
                    DELETE FROM session
                    WHERE authenticated=0 AND last_visit < %s
                    """, (mintime,))


class Session(DetachedSession):
    """Basic session handling and per-session storage."""

    def __init__(self, env, req):
        super(Session, self).__init__(env, None)
        self.req = req
        if req.authname == 'anonymous':
            if not req.incookie.has_key(COOKIE_KEY):
                self.sid = hex_entropy(24)
                self.bake_cookie()
            else:
                sid = req.incookie[COOKIE_KEY].value
                self.get_session(sid)
        else:
            if req.incookie.has_key(COOKIE_KEY):
                sid = req.incookie[COOKIE_KEY].value
                self.promote_session(sid)
            self.get_session(req.authname, authenticated=True)

    def bake_cookie(self, expires=PURGE_AGE):
        assert self.sid, 'Session ID not set'
        self.req.outcookie[COOKIE_KEY] = self.sid
        self.req.outcookie[COOKIE_KEY]['path'] = self.req.base_path or '/'
        self.req.outcookie[COOKIE_KEY]['expires'] = expires
        if self.env.secure_cookies:
            self.req.outcookie[COOKIE_KEY]['secure'] = True
        if sys.version_info >= (2, 6):
            self.req.outcookie[COOKIE_KEY]['httponly'] = True

    def get_session(self, sid, authenticated=False):
        refresh_cookie = False

        if self.sid and sid != self.sid:
            refresh_cookie = True

        super(Session, self).get_session(sid, authenticated)
        if self.last_visit and time.time() - self.last_visit > UPDATE_INTERVAL:
            refresh_cookie = True

        # Refresh the session cookie if this is the first visit after a day
        if not authenticated and refresh_cookie:
            self.bake_cookie()

    def change_sid(self, new_sid):
        assert self.req.authname == 'anonymous', \
               'Cannot change ID of authenticated session'
        assert new_sid, 'Session ID cannot be empty'
        if new_sid == self.sid:
            return
        with self.env.db_transaction as db:
            if db("SELECT sid FROM session WHERE sid=%s", (new_sid,)):
                raise TracError(_("Session '%(id)s' already exists. "
                                  "Please choose a different session ID.",
                                  id=new_sid),
                                _("Error renaming session"))
            self.env.log.debug("Changing session ID %s to %s", self.sid,
                               new_sid)
            db("UPDATE session SET sid=%s WHERE sid=%s AND authenticated=0",
               (new_sid, self.sid))
            db("""UPDATE session_attribute SET sid=%s
                  WHERE sid=%s and authenticated=0
                  """, (new_sid, self.sid))
        self.sid = new_sid
        self.bake_cookie()

    def promote_session(self, sid):
        """Promotes an anonymous session to an authenticated session, if there
        is no preexisting session data for that user name.
        """
        assert self.req.authname != 'anonymous', \
               "Cannot promote session of anonymous user"

        with self.env.db_transaction as db:
            authenticated_flags = [authenticated for authenticated, in db(
                "SELECT authenticated FROM session WHERE sid=%s OR sid=%s",
                (sid, self.req.authname))]

            if len(authenticated_flags) == 2:
                # There's already an authenticated session for the user,
                # we simply delete the anonymous session
                db("DELETE FROM session WHERE sid=%s AND authenticated=0",
                   (sid,))
                db("""DELETE FROM session_attribute
                      WHERE sid=%s AND authenticated=0
                      """, (sid,))
            elif len(authenticated_flags) == 1:
                if not authenticated_flags[0]:
                    # Update the anomymous session records so the session ID
                    # becomes the user name, and set the authenticated flag.
                    self.env.log.debug("Promoting anonymous session %s to "
                                       "authenticated session for user %s",
                                       sid, self.req.authname)
                    db("""UPDATE session SET sid=%s, authenticated=1
                          WHERE sid=%s AND authenticated=0
                          """, (self.req.authname, sid))
                    db("""UPDATE session_attribute SET sid=%s, authenticated=1
                          WHERE sid=%s
                          """, (self.req.authname, sid))
            else:
                # We didn't have an anonymous session for this sid. The
                # authenticated session might have been inserted between the
                # SELECT above and here, so we catch the error.
                try:
                    db("""INSERT INTO session (sid, last_visit, authenticated)
                          VALUES (%s, %s, 1)
                          """, (self.req.authname, int(time.time())))
                except self.env.db_exc.IntegrityError:
                    self.env.log.warning('Authenticated session for %s '
                                         'already exists', self.req.authname)
                    db.rollback()
        self._new = False

        self.sid = sid
        self.bake_cookie(0) # expire the cookie


class SessionAdmin(Component):
    """trac-admin command provider for session management"""

    implements(IAdminCommandProvider)

    def get_admin_commands(self):
        yield ('session list', '[sid[:0|1]] [...]',
               """List the name and email for the given sids

               Specifying the sid 'anonymous' lists all unauthenticated
               sessions, and 'authenticated' all authenticated sessions.
               '*' lists all sessions, and is the default if no sids are
               given.

               An sid suffix ':0' operates on an unauthenticated session with
               the given sid, and a suffix ':1' on an authenticated session
               (the default).""",
               self._complete_list, self._do_list)

        yield ('session add', '<sid[:0|1]> [name] [email]',
               """Create a session for the given sid

               Populates the name and email attributes for the given session.
               Adding a suffix ':0' to the sid makes the session
               unauthenticated, and a suffix ':1' makes it authenticated (the
               default if no suffix is specified).""",
               None, self._do_add)

        yield ('session set', '<name|email> <sid[:0|1]> <value>',
               """Set the name or email attribute of the given sid

               An sid suffix ':0' operates on an unauthenticated session with
               the given sid, and a suffix ':1' on an authenticated session
               (the default).""",
               self._complete_set, self._do_set)

        yield ('session delete', '<sid[:0|1]> [...]',
               """Delete the session of the specified sid

               An sid suffix ':0' operates on an unauthenticated session with
               the given sid, and a suffix ':1' on an authenticated session
               (the default). Specifying the sid 'anonymous' will delete all
               anonymous sessions.""",
               self._complete_delete, self._do_delete)

        yield ('session purge', '<age>',
               """Purge all anonymous sessions older than the given age

               Age may be specified as a relative time like "90 days ago", or
               in YYYYMMDD format.""",
               None, self._do_purge)

    def _split_sid(self, sid):
        if sid.endswith(':0'):
            return (sid[:-2], 0)
        elif sid.endswith(':1'):
            return (sid[:-2], 1)
        else:
            return (sid, 1)

    def _get_sids(self):
        rows = self.env.db_query("SELECT sid, authenticated FROM session")
        return ['%s:%d' % (sid, auth) for sid, auth in rows]

    def _get_list(self, sids):
        all_anon = 'anonymous' in sids or '*' in sids
        all_auth = 'authenticated' in sids or '*' in sids
        sids = set(self._split_sid(sid) for sid in sids
                   if sid not in ('anonymous', 'authenticated', '*'))
        rows = self.env.db_query("""
            SELECT DISTINCT s.sid, s.authenticated, s.last_visit,
                            n.value, e.value
            FROM session AS s
              LEFT JOIN session_attribute AS n
                ON (n.sid=s.sid AND n.authenticated=s.authenticated
                    AND n.name='name')
              LEFT JOIN session_attribute AS e
                ON (e.sid=s.sid AND e.authenticated=s.authenticated
                    AND e.name='email')
            ORDER BY s.sid, s.authenticated
            """)
        for sid, authenticated, last_visit, name, email in rows:
            if all_anon and not authenticated or all_auth and authenticated \
                    or (sid, authenticated) in sids:
                yield (sid, authenticated, last_visit, name, email)

    def _complete_list(self, args):
        all_sids = self._get_sids() + ['*', 'anonymous', 'authenticated']
        return set(all_sids) - set(args)

    def _complete_set(self, args):
        if len(args) == 1:
            return ['name', 'email']
        elif len(args) == 2:
            return self._get_sids()

    def _complete_delete(self, args):
        all_sids = self._get_sids() + ['anonymous']
        return set(all_sids) - set(args)

    def _do_list(self, *sids):
        if not sids:
            sids = ['*']
        print_table([(r[0], r[1], format_date(to_datetime(r[2]),
                                              console_date_format),
                      r[3], r[4])
                     for r in self._get_list(sids)],
                    [_('SID'), _('Auth'), _('Last Visit'), _('Name'),
                     _('Email')])

    def _do_add(self, sid, name=None, email=None):
        sid, authenticated = self._split_sid(sid)
        with self.env.db_transaction as db:
            try:
                db("INSERT INTO session VALUES (%s, %s, %s)",
                   (sid, authenticated, int(time.time())))
            except Exception:
                raise AdminCommandError(_("Session '%(sid)s' already exists",
                                          sid=sid))
            if name is not None:
                db("INSERT INTO session_attribute VALUES (%s,%s,'name',%s)",
                    (sid, authenticated, name))
            if email is not None:
                db("INSERT INTO session_attribute VALUES (%s,%s,'email',%s)",
                    (sid, authenticated, email))

    def _do_set(self, attr, sid, val):
        if attr not in ('name', 'email'):
            raise AdminCommandError(_("Invalid attribute '%(attr)s'",
                                      attr=attr))
        sid, authenticated = self._split_sid(sid)
        with self.env.db_transaction as db:
            if not db("""SELECT sid FROM session
                         WHERE sid=%s AND authenticated=%s""",
                         (sid, authenticated)):
                raise AdminCommandError(_("Session '%(sid)s' not found",
                                          sid=sid))
            db("""
                DELETE FROM session_attribute
                WHERE sid=%s AND authenticated=%s AND name=%s
                """, (sid, authenticated, attr))
            db("INSERT INTO session_attribute VALUES (%s, %s, %s, %s)",
               (sid, authenticated, attr, val))

    def _do_delete(self, *sids):
        with self.env.db_transaction as db:
            for sid in sids:
                sid, authenticated = self._split_sid(sid)
                if sid == 'anonymous':
                    db("DELETE FROM session WHERE authenticated=0")
                    db("DELETE FROM session_attribute WHERE authenticated=0")
                else:
                    db("""
                        DELETE FROM session
                        WHERE sid=%s AND authenticated=%s
                        """, (sid, authenticated))
                    db("""
                        DELETE FROM session_attribute
                        WHERE sid=%s AND authenticated=%s
                        """, (sid, authenticated))

    def _do_purge(self, age):
        when = parse_date(age)
        with self.env.db_transaction as db:
            ts = to_timestamp(when)
            db("""
                DELETE FROM session
                WHERE authenticated=0 AND last_visit<%s
                """, (ts,))
            db("""
                DELETE FROM session_attribute
                WHERE authenticated=0
                      AND sid NOT IN (SELECT sid FROM session
                                      WHERE authenticated=0)
                """)

########NEW FILE########
__FILENAME__ = standalone
#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005-2006 Matthew Good <trac@matt-good.net>
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Matthew Good <trac@matt-good.net>
#         Christopher Lenz <cmlenz@gmx.de>

import pkg_resources
import os
import socket
import select
import sys
from SocketServer import ThreadingMixIn

from trac import __version__ as VERSION
from trac.hooks import load_bootstrap_handler
from trac.util import autoreload, daemon
from trac.web.auth import BasicAuthentication, DigestAuthentication
from trac.web.main import dispatch_request
from trac.web.wsgi import WSGIServer, WSGIRequestHandler


class AuthenticationMiddleware(object):

    def __init__(self, application, auths, single_env_name=None):
        self.application = application
        self.auths = auths
        self.single_env_name = single_env_name
        if single_env_name:
            self.part = 0
        else:
            self.part = 1

    def __call__(self, environ, start_response):
        path_info = environ.get('PATH_INFO', '')
        path_parts = filter(None, path_info.split('/'))
        if len(path_parts) > self.part and path_parts[self.part] == 'login':
            env_name = self.single_env_name or path_parts[0]
            if env_name:
                auth = self.auths.get(env_name, self.auths.get('*'))
                if auth:
                    remote_user = auth.do_auth(environ, start_response)
                    if not remote_user:
                        return []
                    environ['REMOTE_USER'] = remote_user
        return self.application(environ, start_response)


class BootstrapAuthenticationMiddleware(AuthenticationMiddleware):
    """Authentication middleware for custom web bootstrap handlers
    """
    def __call__(self, environ, start_response):
        bootstrap_ep = os.getenv('TRAC_BOOTSTRAP_HANDLER')
        environ.setdefault('trac.bootstrap_handler', bootstrap_ep)

        # Preserve original environ and probe dispatching
        temp_environ = environ.copy()
        bootstrap = load_bootstrap_handler(bootstrap_ep)
        bootstrap.probe_environment(temp_environ)

        path_info = temp_environ.get('PATH_INFO', '')
        path_parts = filter(None, path_info.split('/'))
        env_name = temp_environ.get('trac.env_name')
        if path_parts and path_parts[0] == 'login' and env_name:
            auth = self.auths.get(env_name, self.auths.get('*'))
            if auth:
                remote_user = auth.do_auth(environ, start_response)
                if not remote_user:
                    return []
                environ['REMOTE_USER'] = remote_user
        return self.application(environ, start_response)


class BasePathMiddleware(object):

    def __init__(self, application, base_path):
        self.base_path = '/' + base_path.strip('/')
        self.application = application

    def __call__(self, environ, start_response):
        path = environ['SCRIPT_NAME'] + environ.get('PATH_INFO', '')
        environ['PATH_INFO'] = path[len(self.base_path):]
        environ['SCRIPT_NAME'] = self.base_path
        return self.application(environ, start_response)


class TracEnvironMiddleware(object):

    def __init__(self, application, env_parent_dir, env_paths, single_env):
        self.application = application
        self.environ = {}
        self.environ['trac.env_path'] = None
        if env_parent_dir:
            self.environ['trac.env_parent_dir'] = env_parent_dir
        elif single_env:
            self.environ['trac.env_path'] = env_paths[0]
        else:
            self.environ['trac.env_paths'] = env_paths

    def __call__(self, environ, start_response):
        for k, v in self.environ.iteritems():
            environ.setdefault(k, v)
        return self.application(environ, start_response)


class TracHTTPServer(ThreadingMixIn, WSGIServer):
    daemon_threads = True

    def __init__(self, server_address, application, env_parent_dir, env_paths,
                 use_http_11=False):
        request_handlers = (TracHTTPRequestHandler, TracHTTP11RequestHandler)
        WSGIServer.__init__(self, server_address, application,
                            request_handler=request_handlers[bool(use_http_11)])

    if sys.version_info < (2, 6):
        def serve_forever(self, poll_interval=0.5):
            while True:
                r, w, e = select.select([self], [], [], poll_interval)
                if self in r:
                    self.handle_request()


class TracHTTPRequestHandler(WSGIRequestHandler):

    server_version = 'tracd/' + VERSION

    def address_string(self):
        # Disable reverse name lookups
        return self.client_address[:2][0]


class TracHTTP11RequestHandler(TracHTTPRequestHandler):
    protocol_version = 'HTTP/1.1'

def main():
    from optparse import OptionParser, OptionValueError
    parser = OptionParser(usage='usage: %prog [options] [projenv] ...',
                          version='%%prog %s' % VERSION)

    auths = {}
    def _auth_callback(option, opt_str, value, parser, cls):
        info = value.split(',', 3)
        if len(info) != 3:
            raise OptionValueError("Incorrect number of parameters for %s"
                                   % option)

        env_name, filename, realm = info
        if env_name in auths:
            print >> sys.stderr, 'Ignoring duplicate authentication option ' \
                                 'for project: %s' % env_name
        else:
            auths[env_name] = cls(os.path.abspath(filename), realm)

    def _validate_callback(option, opt_str, value, parser, valid_values):
        if value not in valid_values:
            raise OptionValueError('%s must be one of: %s, not %s'
                                   % (opt_str, '|'.join(valid_values), value))
        setattr(parser.values, option.dest, value)

    def _octal(option, opt_str, value, parser):
        try:
            setattr(parser.values, option.dest, int(value, 8))
        except ValueError:
            raise OptionValueError('Invalid octal umask value: %r' % value)

    parser.add_option('-a', '--auth', action='callback', type='string',
                      metavar='DIGESTAUTH', callback=_auth_callback,
                      callback_args=(DigestAuthentication,),
                      help='[projectdir],[htdigest_file],[realm]')
    parser.add_option('--basic-auth', action='callback', type='string',
                      metavar='BASICAUTH', callback=_auth_callback,
                      callback_args=(BasicAuthentication,),
                      help='[projectdir],[htpasswd_file],[realm]')

    parser.add_option('-p', '--port', action='store', type='int', dest='port',
                      help='the port number to bind to')
    parser.add_option('-b', '--hostname', action='store', dest='hostname',
                      help='the host name or IP address to bind to')
    parser.add_option('--protocol', action='callback', type="string",
                      dest='protocol', callback=_validate_callback,
                      callback_args=(('http', 'scgi', 'ajp', 'fcgi'),),
                      help='http|scgi|ajp|fcgi')
    parser.add_option('-q', '--unquote', action='store_true',
                      dest='unquote',
                      help='unquote PATH_INFO (may be needed when using ajp)')
    parser.add_option('--http10', action='store_false', dest='http11',
                      help='use HTTP/1.0 protocol version instead of HTTP/1.1')
    parser.add_option('--http11', action='store_true', dest='http11',
                      help='use HTTP/1.1 protocol version (default)')
    parser.add_option('-e', '--env-parent-dir', action='store',
                      dest='env_parent_dir', metavar='PARENTDIR',
                      help='parent directory of the project environments')
    parser.add_option('--base-path', action='store', type='string', # XXX call this url_base_path?
                      dest='base_path',
                      help='the initial portion of the request URL\'s "path"')

    parser.add_option('-r', '--auto-reload', action='store_true',
                      dest='autoreload',
                      help='restart automatically when sources are modified')

    parser.add_option('-s', '--single-env', action='store_true',
                      dest='single_env', help='only serve a single '
                      'project without the project list', default=False)

    if os.name == 'posix':
        parser.add_option('-d', '--daemonize', action='store_true',
                          dest='daemonize',
                          help='run in the background as a daemon')
        parser.add_option('--pidfile', action='store',
                          dest='pidfile',
                          help='when daemonizing, file to which to write pid')
        parser.add_option('--umask', action='callback', type='string',
                          dest='umask', metavar='MASK', callback=_octal,
                          help='when daemonizing, file mode creation mask '
                          'to use, in octal notation (default 022)')

        try:
            import grp, pwd

            def _group(option, opt_str, value, parser):
                try:
                    value = int(value)
                except ValueError:
                    try:
                        value = grp.getgrnam(value)[2]
                    except KeyError:
                        raise OptionValueError('group not found: %r' % value)
                setattr(parser.values, option.dest, value)

            def _user(option, opt_str, value, parser):
                try:
                    value = int(value)
                except ValueError:
                    try:
                        value = pwd.getpwnam(value)[2]
                    except KeyError:
                        raise OptionValueError('user not found: %r' % value)
                setattr(parser.values, option.dest, value)

            parser.add_option('--group', action='callback', type='string',
                              dest='group', metavar='GROUP', callback=_group,
                              help='the group to run as')
            parser.add_option('--user', action='callback', type='string',
                              dest='user', metavar='USER', callback=_user,
                              help='the user to run as')
        except ImportError:
            pass

    parser.set_defaults(port=None, hostname='', base_path='', daemonize=False,
                        protocol='http', http11=True, umask=022, user=None,
                        group=None)
    options, args = parser.parse_args()

    if not args and not options.env_parent_dir:
        parser.error('either the --env-parent-dir option or at least one '
                     'environment must be specified')
    if options.single_env:
        if options.env_parent_dir:
            parser.error('the --single-env option cannot be used with '
                         '--env-parent-dir')
        elif len(args) > 1:
            parser.error('the --single-env option cannot be used with '
                         'more than one enviroment')
    if options.daemonize and options.autoreload:
        parser.error('the --auto-reload option cannot be used with '
                     '--daemonize')

    if options.port is None:
        options.port = {
            'http': 80,
            'scgi': 4000,
            'ajp': 8009,
            'fcgi': 8000,
        }[options.protocol]
    server_address = (options.hostname, options.port)

    # relative paths don't work when daemonized
    args = [os.path.abspath(a) for a in args]
    if options.env_parent_dir:
        options.env_parent_dir = os.path.abspath(options.env_parent_dir)
    if parser.has_option('pidfile') and options.pidfile:
        options.pidfile = os.path.abspath(options.pidfile)

    wsgi_app = dispatch_request

    if auths:
        if options.single_env:
            project_name = os.path.basename(args[0])
            wsgi_app = BootstrapAuthenticationMiddleware(wsgi_app, auths, project_name)
        else:
            wsgi_app = BootstrapAuthenticationMiddleware(wsgi_app, auths)

    wsgi_app = TracEnvironMiddleware(wsgi_app,
                                     options.env_parent_dir, args,
                                     options.single_env)

    base_path = options.base_path.strip('/')
    if base_path:
        wsgi_app = BasePathMiddleware(wsgi_app, base_path)

    if options.protocol == 'http':
        def serve():
            addr, port = server_address
            if not addr or addr == '0.0.0.0':
                loc = '0.0.0.0:%s view at http://127.0.0.1:%s/%s' \
                       % (port, port, base_path)
            else:
                loc = 'http://%s:%s/%s' % (addr, port, base_path)

            try:
                httpd = TracHTTPServer(server_address, wsgi_app,
                                       options.env_parent_dir, args,
                                       use_http_11=options.http11)
            except socket.error, e:
                print 'Error starting Trac server on %s' % loc
                print '[Errno %s] %s' % e.args
                sys.exit(1)

            print 'Server starting in PID %i.' % os.getpid()
            print 'Serving on %s' % loc
            if options.http11:
                print 'Using HTTP/1.1 protocol version'
            httpd.serve_forever()
    elif options.protocol in ('scgi', 'ajp', 'fcgi'):
        def serve():
            server_cls = __import__('flup.server.%s' % options.protocol,
                                    None, None, ['']).WSGIServer
            flup_app = wsgi_app
            if options.unquote:
                from trac.web.fcgi_frontend import FlupMiddleware
                flup_app = FlupMiddleware(flup_app)
            ret = server_cls(flup_app, bindAddress=server_address).run()
            sys.exit(42 if ret else 0) # if SIGHUP exit with status 42

    try:
        if options.daemonize:
            daemon.daemonize(pidfile=options.pidfile, progname='tracd',
                             umask=options.umask)
        if options.group is not None:
            os.setgid(options.group)
        if options.user is not None:
            os.setuid(options.user)

        if options.autoreload:
            def modification_callback(file):
                print >> sys.stderr, 'Detected modification of %s, ' \
                                     'restarting.' % file
            autoreload.main(serve, modification_callback)
        else:
            serve()

    except OSError, e:
        print >> sys.stderr, '%s: %s' % (e.__class__.__name__, e)
        sys.exit(1)
    except KeyboardInterrupt:
        pass


if __name__ == '__main__':
    pkg_resources.require('Trac==%s' % VERSION)
    main()

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-

from trac.test import Mock
from trac.web.api import Request, RequestDone, parse_arg_list

from StringIO import StringIO
import unittest


class RequestTestCase(unittest.TestCase):

    def _make_environ(self, scheme='http', server_name='example.org',
                      server_port=80, method='GET', script_name='/trac',
                      **kwargs):
        environ = {'wsgi.url_scheme': scheme, 'wsgi.input': StringIO(''),
                   'REQUEST_METHOD': method, 'SERVER_NAME': server_name,
                   'SERVER_PORT': server_port, 'SCRIPT_NAME': script_name}
        environ.update(kwargs)
        return environ

    def test_base_url(self):
        environ = self._make_environ()
        req = Request(environ, None)
        self.assertEqual('http://example.org/trac', req.base_url)

    def test_base_url_host(self):
        environ = self._make_environ(server_port=8080, HTTP_HOST='example.com')
        req = Request(environ, None)
        self.assertEqual('http://example.com/trac', req.base_url)

    def test_base_url_nondefaultport(self):
        environ = self._make_environ(server_port=8080)
        req = Request(environ, None)
        self.assertEqual('http://example.org:8080/trac', req.base_url)

    def test_base_url_https(self):
        environ = self._make_environ(scheme='https', server_port=443)
        req = Request(environ, None)
        self.assertEqual('https://example.org/trac', req.base_url)

    def test_base_url_https_host(self):
        environ = self._make_environ(scheme='https', server_port=443,
                                     HTTP_HOST='example.com')
        req = Request(environ, None)
        self.assertEqual('https://example.com/trac', req.base_url)

    def test_base_url_https_nondefaultport(self):
        environ = self._make_environ(scheme='https', server_port=8443)
        req = Request(environ, None)
        self.assertEqual('https://example.org:8443/trac', req.base_url)

    def test_base_url_proxy(self):
        environ = self._make_environ(HTTP_HOST='localhost',
                                     HTTP_X_FORWARDED_HOST='example.com')
        req = Request(environ, None)
        self.assertEqual('http://localhost/trac', req.base_url)

    def test_languages(self):
        environ = self._make_environ()
        environ['HTTP_ACCEPT_LANGUAGE'] = 'en-us,en;q=0.5'
        req = Request(environ, None)
        self.assertEqual(['en-us', 'en'], req.languages)

    def test_redirect(self):
        status_sent = []
        headers_sent = {}
        def start_response(status, headers):
            status_sent.append(status)
            headers_sent.update(dict(headers))
        environ = self._make_environ(method='HEAD')
        req = Request(environ, start_response)
        req.session = Mock(save=lambda: None)
        self.assertRaises(RequestDone, req.redirect, '/trac/test')
        self.assertEqual('302 Found', status_sent[0])
        self.assertEqual('http://example.org/trac/test',
                         headers_sent['Location'])

    def test_redirect_absolute(self):
        status_sent = []
        headers_sent = {}
        def start_response(status, headers):
            status_sent.append(status)
            headers_sent.update(dict(headers))
        environ = self._make_environ(method='HEAD')
        req = Request(environ, start_response,)
        req.session = Mock(save=lambda: None)
        self.assertRaises(RequestDone, req.redirect,
                          'http://example.com/trac/test')
        self.assertEqual('302 Found', status_sent[0])
        self.assertEqual('http://example.com/trac/test',
                         headers_sent['Location'])

    def test_write_unicode(self):
        buf = StringIO()
        def write(data):
            buf.write(data)
        def start_response(status, headers):
            return write
        environ = self._make_environ(method='HEAD')
        req = Request(environ, start_response)
        req.send_header('Content-Type', 'text/plain;charset=utf-8')
        # we didn't set Content-Length, so we get a RuntimeError for that
        self.assertRaises(RuntimeError, req.write, u'F')

        req = Request(environ, start_response)
        req.send_header('Content-Type', 'text/plain;charset=utf-8')
        req.send_header('Content-Length', 0)
        # anyway we're not supposed to send unicode, so we get a ValueError
        self.assertRaises(ValueError, req.write, u'F')

    def test_invalid_cookies(self):
        environ = self._make_environ(HTTP_COOKIE='bad:key=value;')
        req = Request(environ, None)
        self.assertEqual('', str(req.incookie))

    def test_multiple_cookies(self):
        environ = self._make_environ(HTTP_COOKIE='key=value1; key=value2;')
        req = Request(environ, None)
        self.assertEqual('Set-Cookie: key=value1',
                         str(req.incookie).rstrip(';'))

    def test_read(self):
        environ = self._make_environ(**{'wsgi.input': StringIO('test input')})
        req = Request(environ, None)
        self.assertEqual('test input', req.read())

    def test_read_size(self):
        environ = self._make_environ(**{'wsgi.input': StringIO('test input')})
        req = Request(environ, None)
        self.assertEqual('test', req.read(size=4))

    def test_qs_on_post(self):
        """Make sure req.args parsing is consistent even after the backwards
        incompatible change introduced in Python 2.6.
        """
        environ = self._make_environ(method='GET',
                                     **{'QUERY_STRING': 'action=foo'})
        req = Request(environ, None)
        self.assertEqual('foo', req.args['action'])
        environ = self._make_environ(method='POST',
                                     **{'wsgi.input': StringIO('action=bar'),
                                        'CONTENT_LENGTH': '10',
                                        'CONTENT_TYPE': 'application/x-www-form-urlencoded',
                                        'QUERY_STRING': 'action=foo'})
        req = Request(environ, None)
        self.assertEqual('bar', req.args['action'])


class ParseArgListTestCase(unittest.TestCase):

    def test_qs_str(self):
        args = parse_arg_list('k%C3%A9y=resum%C3%A9&r%C3%A9sum%C3%A9')
        self.assertTrue(unicode, type(args[0][0]))
        self.assertTrue(unicode, type(args[0][1]))
        self.assertEqual(u'ky', args[0][0])
        self.assertEqual(u'resum', args[0][1])
        self.assertTrue(unicode, type(args[1][0]))
        self.assertEqual(u'rsum', args[1][0])

    def test_qs_unicode(self):
        args = parse_arg_list(u'k%3Dy=re%26su=m&rsu%26m')
        self.assertTrue(unicode, type(args[0][0]))
        self.assertTrue(unicode, type(args[0][1]))
        self.assertEqual(u'k=y', args[0][0])
        self.assertEqual(u're&su=m', args[0][1])
        self.assertTrue(unicode, type(args[1][0]))
        self.assertEqual(u'rsu&m', args[1][0])


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(RequestTestCase, 'test'))
    suite.addTest(unittest.makeSuite(ParseArgListTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = auth
# -*- coding: utf-8 -*-

import os

from trac.core import TracError
from trac.test import EnvironmentStub, Mock
from trac.web.auth import BasicAuthentication, LoginModule
from trac.web.href import Href

from Cookie import SimpleCookie as Cookie
import unittest


class LoginModuleTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        self.module = LoginModule(self.env)

    def tearDown(self):
        self.env.reset_db()

    def test_anonymous_access(self):
        req = Mock(incookie=Cookie(), href=Href('/trac.cgi'),
                   remote_addr='127.0.0.1', remote_user=None,
                   base_path='/trac.cgi')
        self.assertEqual(None, self.module.authenticate(req))

    def test_unknown_cookie_access(self):
        incookie = Cookie()
        incookie['trac_auth'] = '123'
        req = Mock(cgi_location='/trac', href=Href('/trac.cgi'),
                   incookie=incookie, outcookie=Cookie(),
                   remote_addr='127.0.0.1', remote_user=None,
                   base_path='/trac.cgi')
        self.assertEqual(None, self.module.authenticate(req))

    def test_known_cookie_access(self):
        self.env.db_transaction("""
            INSERT INTO auth_cookie (cookie, name, ipnr)
            VALUES ('123', 'john', '127.0.0.1')""")
        incookie = Cookie()
        incookie['trac_auth'] = '123'
        outcookie = Cookie()
        req = Mock(incookie=incookie, outcookie=outcookie,
                   href=Href('/trac.cgi'), base_path='/trac.cgi',
                   remote_addr='127.0.0.1', remote_user=None)
        self.assertEqual('john', self.module.authenticate(req))
        self.failIf('auth_cookie' in req.outcookie)

    def test_known_cookie_ip_check_enabled(self):
        self.env.config.set('trac', 'check_auth_ip', 'yes')
        self.env.db_transaction("""
            INSERT INTO auth_cookie (cookie, name, ipnr)
            VALUES ('123', 'john', '127.0.0.1')""")
        incookie = Cookie()
        incookie['trac_auth'] = '123'
        outcookie = Cookie()
        req = Mock(cgi_location='/trac', href=Href('/trac.cgi'),
                   incookie=incookie, outcookie=outcookie,
                   remote_addr='192.168.0.100', remote_user=None,
                   base_path='/trac.cgi')
        self.assertEqual(None, self.module.authenticate(req))
        self.failIf('trac_auth' not in req.outcookie)

    def test_known_cookie_ip_check_disabled(self):
        self.env.config.set('trac', 'check_auth_ip', 'no')
        self.env.db_transaction("""
            INSERT INTO auth_cookie (cookie, name, ipnr)
            VALUES ('123', 'john', '127.0.0.1')""")
        incookie = Cookie()
        incookie['trac_auth'] = '123'
        outcookie = Cookie()
        req = Mock(incookie=incookie, outcookie=outcookie,
                   href=Href('/trac.cgi'), base_path='/trac.cgi',
                   remote_addr='192.168.0.100', remote_user=None)
        self.assertEqual('john', self.module.authenticate(req))
        self.failIf('auth_cookie' in req.outcookie)

    def test_login(self):
        outcookie = Cookie()
        # remote_user must be upper case to test that by default, case is
        # preserved.
        req = Mock(cgi_location='/trac', href=Href('/trac.cgi'),
                   incookie=Cookie(), outcookie=outcookie,
                   remote_addr='127.0.0.1', remote_user='john',
                   authname='john', base_path='/trac.cgi')
        self.module._do_login(req)

        assert outcookie.has_key('trac_auth'), '"trac_auth" Cookie not set'
        auth_cookie = outcookie['trac_auth'].value

        self.assertEquals([('john', '127.0.0.1')], self.env.db_query(
            "SELECT name, ipnr FROM auth_cookie WHERE cookie=%s",
            (auth_cookie,)))

    def test_login_ignore_case(self):
        """
        Test that login is succesful when the usernames differ in case, but case
        is ignored.
        """
        self.env.config.set('trac', 'ignore_auth_case', 'yes')

        outcookie = Cookie()
        req = Mock(cgi_location='/trac', href=Href('/trac.cgi'),
                   incookie=Cookie(), outcookie=outcookie,
                   remote_addr='127.0.0.1', remote_user='John',
                   authname='anonymous', base_path='/trac.cgi')
        self.module._do_login(req)

        assert outcookie.has_key('trac_auth'), '"trac_auth" Cookie not set'
        auth_cookie = outcookie['trac_auth'].value
        self.assertEquals([('john', '127.0.0.1')], self.env.db_query(
            "SELECT name, ipnr FROM auth_cookie WHERE cookie=%s",
            (auth_cookie,)))

    def test_login_no_username(self):
        req = Mock(incookie=Cookie(), href=Href('/trac.cgi'),
                   remote_addr='127.0.0.1', remote_user=None,
                   base_path='/trac.cgi')
        self.assertRaises(TracError, self.module._do_login, req)

    def test_already_logged_in_same_user(self):
        self.env.db_transaction("""
            INSERT INTO auth_cookie (cookie, name, ipnr)
            VALUES ('123', 'john', '127.0.0.1')""")
        incookie = Cookie()
        incookie['trac_auth'] = '123'
        req = Mock(incookie=incookie, outcookie=Cookie(),
                   href=Href('/trac.cgi'), base_path='/trac.cgi',
                   remote_addr='127.0.0.1', remote_user='john', authname='john')
        self.module._do_login(req) # this shouldn't raise an error

    def test_already_logged_in_different_user(self):
        self.env.db_transaction("""
            INSERT INTO auth_cookie (cookie, name, ipnr)
            VALUES ('123', 'john', '127.0.0.1')""")
        incookie = Cookie()
        incookie['trac_auth'] = '123'
        req = Mock(incookie=incookie, authname='john',
                   href=Href('/trac.cgi'), base_path='/trac.cgi',
                   remote_addr='127.0.0.1', remote_user='tom')
        self.assertRaises(AssertionError, self.module._do_login, req)

    def test_logout(self):
        self.env.db_transaction("""
            INSERT INTO auth_cookie (cookie, name, ipnr)
            VALUES ('123', 'john', '127.0.0.1')""")
        incookie = Cookie()
        incookie['trac_auth'] = '123'
        outcookie = Cookie()
        req = Mock(cgi_location='/trac', href=Href('/trac.cgi'),
                   incookie=incookie, outcookie=outcookie,
                   remote_addr='127.0.0.1', remote_user=None, authname='john',
                   base_path='/trac.cgi')
        self.module._do_logout(req)
        self.failIf('trac_auth' not in outcookie)
        self.failIf(self.env.db_query(
            "SELECT name, ipnr FROM auth_cookie WHERE name='john'"))

    def test_logout_not_logged_in(self):
        req = Mock(cgi_location='/trac', href=Href('/trac.cgi'),
                   incookie=Cookie(), outcookie=Cookie(),
                   remote_addr='127.0.0.1', remote_user=None,
                   authname='anonymous', base_path='/trac.cgi')
        self.module._do_logout(req) # this shouldn't raise an error


class BasicAuthenticationTestCase(unittest.TestCase):
    def setUp(self):
        filename = os.path.join(os.path.split(__file__)[0], 'htpasswd.txt')
        self.auth = BasicAuthentication(filename, 'realm')

    def tearDown(self):
        self.auth = None

    def test_crypt(self):
        self.assert_(self.auth.test('crypt', 'crypt'))
        self.assert_(not self.auth.test('crypt', 'other'))

    def test_md5(self):
        self.assert_(self.auth.test('md5', 'md5'))
        self.assert_(not self.auth.test('md5', 'other'))

    def test_sha(self):
        self.assert_(self.auth.test('sha', 'sha'))
        self.assert_(not self.auth.test('sha', 'other'))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(LoginModuleTestCase, 'test'))
    suite.addTest(unittest.makeSuite(BasicAuthenticationTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = cgi_frontend
#from trac.web.cgi_frontend import CGIRequest

import unittest


class CGIRequestTestCase(unittest.TestCase):
    pass


def suite():
    return unittest.makeSuite(CGIRequestTestCase, 'test')

if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = chrome
# -*- coding: utf-8 -*-
#
# Copyright (C) 2013 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from trac.core import Component, implements
from trac.test import EnvironmentStub
from trac.tests.contentgen import random_sentence
from trac.web.chrome import (
    Chrome, INavigationContributor, add_link, add_meta, add_notice, add_script,
    add_script_data, add_stylesheet, add_warning)
from trac.web.href import Href

import unittest

class Request(object):
    locale = None
    def __init__(self, **kwargs):
        self.chrome = {}
        for k, v in kwargs.items():
            setattr(self, k, v)

class ChromeTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        from trac.core import ComponentMeta
        self._old_registry = ComponentMeta._registry
        ComponentMeta._registry = {}

    def tearDown(self):
        from trac.core import ComponentMeta
        ComponentMeta._registry = self._old_registry

    def test_add_meta(self):
        req = Request(href=Href('/trac.cgi'))
        add_meta(req, 'Jim Smith', name='Author', scheme='test', lang='en-us')
        add_meta(req, 'Tue, 20 Aug 1996 14:25:27 GMT', http_equiv='Expires')
        metas = req.chrome['metas']
        self.assertEqual(2, len(metas))
        meta = metas[0]
        self.assertEqual('Jim Smith', meta['content'])
        self.assertEqual('Author', meta['name'])
        self.assertEqual('test', meta['scheme'])
        self.assertEqual('en-us', meta['lang'])
        self.assertEqual('en-us', meta['xml:lang'])
        meta = metas[1]
        self.assertEqual('Tue, 20 Aug 1996 14:25:27 GMT', meta['content'])
        self.assertEqual('Expires', meta['http-equiv'])

    def test_add_link_simple(self):
        req = Request(href=Href('/trac.cgi'))
        add_link(req, 'start', '/trac/wiki')
        self.assertEqual('/trac/wiki',
                         req.chrome['links']['start'][0]['href'])

    def test_add_link_advanced(self):
        req = Request(href=Href('/trac.cgi'))
        add_link(req, 'start', '/trac/wiki', 'Start page', 'text/html', 'home')
        link = req.chrome['links']['start'][0]
        self.assertEqual('/trac/wiki', link['href'])
        self.assertEqual('Start page', link['title'])
        self.assertEqual('text/html', link['type'])
        self.assertEqual('home', link['class'])

    def test_add_script(self):
        req = Request(base_path='/trac.cgi', href=Href('/trac.cgi'))
        add_script(req, 'common/js/trac.js')
        add_script(req, 'common/js/trac.js')
        add_script(req, 'http://example.com/trac.js')
        scripts = req.chrome['scripts']
        self.assertEqual(2, len(scripts))
        self.assertEqual('text/javascript', scripts[0]['type'])
        self.assertEqual('/trac.cgi/chrome/common/js/trac.js',
                         scripts[0]['href'])
        self.assertEqual('text/javascript', scripts[1]['type'])
        self.assertEqual('http://example.com/trac.js',
                         scripts[1]['href'])

    def test_add_script_data(self):
        req = Request(href=Href('/trac.cgi'))
        add_script_data(req, {'var1': 1, 'var2': 'Testing'})
        add_script_data(req, var2='More testing', var3=3)
        self.assertEqual({'var1': 1, 'var2': 'More testing', 'var3': 3},
                         req.chrome['script_data'])

    def test_add_stylesheet(self):
        req = Request(base_path='/trac.cgi', href=Href('/trac.cgi'))
        add_stylesheet(req, 'common/css/trac.css')
        add_stylesheet(req, 'common/css/trac.css')
        add_stylesheet(req, 'https://example.com/trac.css')
        links = req.chrome['links']['stylesheet']
        self.assertEqual(2, len(links))
        self.assertEqual('text/css', links[0]['type'])
        self.assertEqual('/trac.cgi/chrome/common/css/trac.css',
                         links[0]['href'])
        self.assertEqual('text/css', links[1]['type'])
        self.assertEqual('https://example.com/trac.css',
                         links[1]['href'])

    def test_add_stylesheet_media(self):
        req = Request(base_path='/trac.cgi', href=Href('/trac.cgi'))
        add_stylesheet(req, 'foo.css', media='print')
        links = req.chrome['links']['stylesheet']
        self.assertEqual(1, len(links))
        self.assertEqual('print', links[0]['media'])

    def test_add_warning_is_unique(self):
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), base_path='/trac.cgi',
                      path_info='',
                      add_redirect_listener=lambda listener: None)
        Chrome(self.env).prepare_request(req)
        message = random_sentence(5)
        add_warning(req, message)
        add_warning(req, message)
        self.assertEqual(1, len(req.chrome['warnings']))

    def test_add_notice_is_unique(self):
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), base_path='/trac.cgi',
                      path_info='',
                      add_redirect_listener=lambda listener: None)
        Chrome(self.env).prepare_request(req)
        message = random_sentence(5)
        add_notice(req, message)
        add_notice(req, message)
        self.assertEqual(1, len(req.chrome['notices']))

    def test_htdocs_location(self):
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), base_path='/trac.cgi',
                      path_info='',
                      add_redirect_listener=lambda listener: None)
        info = Chrome(self.env).prepare_request(req)
        self.assertEqual('/trac.cgi/chrome/common/', info['htdocs_location'])

    def test_logo(self):
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), base_path='/trac.cgi',
                      path_info='',
                      add_redirect_listener=lambda listener: None)

        # Verify that no logo data is put in the HDF if no logo is configured
        self.env.config.set('header_logo', 'src', '')
        info = Chrome(self.env).prepare_request(req)
        assert 'src' not in info['logo']
        assert 'src_abs' not in info['logo']

        # Test with a relative path to the logo image
        self.env.config.set('header_logo', 'src', 'foo.png')
        info = Chrome(self.env).prepare_request(req)
        self.assertEqual('/trac.cgi/chrome/common/foo.png', info['logo']['src'])
        self.assertEqual('http://example.org/trac.cgi/chrome/common/foo.png',
                    info['logo']['src_abs'])

        # Test with a location in project htdocs
        self.env.config.set('header_logo', 'src', 'site/foo.png')
        info = Chrome(self.env).prepare_request(req)
        self.assertEqual('/trac.cgi/chrome/site/foo.png', info['logo']['src'])
        self.assertEqual('http://example.org/trac.cgi/chrome/site/foo.png',
                    info['logo']['src_abs'])

        # Test with a server-relative path to the logo image
        self.env.config.set('header_logo', 'src', '/img/foo.png')
        info = Chrome(self.env).prepare_request(req)
        self.assertEqual('/img/foo.png', info['logo']['src'])
        self.assertEqual('/img/foo.png', info['logo']['src_abs'])

        # Test with an absolute path to the logo image
        self.env.config.set('header_logo', 'src',
                            'http://www.example.org/foo.png')
        info = Chrome(self.env).prepare_request(req)
        self.assertEqual('http://www.example.org/foo.png', info['logo']['src'])
        self.assertEqual('http://www.example.org/foo.png', info['logo']['src_abs'])

    def test_default_links(self):
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), base_path='/trac.cgi',
                      path_info='',
                      add_redirect_listener=lambda listener: None)
        links = Chrome(self.env).prepare_request(req)['links']
        self.assertEqual('/trac.cgi/wiki', links['start'][0]['href'])
        self.assertEqual('/trac.cgi/search', links['search'][0]['href'])
        self.assertEqual('/trac.cgi/wiki/TracGuide', links['help'][0]['href'])
        self.assertEqual('/trac.cgi/chrome/common/css/trac.css',
                         links['stylesheet'][0]['href'])

    def test_icon_links(self):
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), base_path='/trac.cgi',
                      path_info='',
                      add_redirect_listener=lambda listener: None)
        chrome = Chrome(self.env)

        # No icon set in config, so no icon links
        self.env.config.set('project', 'icon', '')
        links = chrome.prepare_request(req)['links']
        assert 'icon' not in links
        assert 'shortcut icon' not in links

        # Relative URL for icon config option
        self.env.config.set('project', 'icon', 'foo.ico')
        links = chrome.prepare_request(req)['links']
        self.assertEqual('/trac.cgi/chrome/common/foo.ico',
                         links['icon'][0]['href'])
        self.assertEqual('/trac.cgi/chrome/common/foo.ico',
                         links['shortcut icon'][0]['href'])

        # URL relative to the server root for icon config option
        self.env.config.set('project', 'icon', '/favicon.ico')
        links = chrome.prepare_request(req)['links']
        self.assertEqual('/favicon.ico', links['icon'][0]['href'])
        self.assertEqual('/favicon.ico', links['shortcut icon'][0]['href'])

        # Absolute URL for icon config option
        self.env.config.set('project', 'icon', 'http://example.com/favicon.ico')
        links = chrome.prepare_request(req)['links']
        self.assertEqual('http://example.com/favicon.ico',
                         links['icon'][0]['href'])
        self.assertEqual('http://example.com/favicon.ico',
                         links['shortcut icon'][0]['href'])

    def test_nav_contributor(self):
        class TestNavigationContributor(Component):
            implements(INavigationContributor)
            def get_active_navigation_item(self, req):
                return None
            def get_navigation_items(self, req):
                yield 'metanav', 'test', 'Test'
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), path_info='/',
                      base_path='/trac.cgi',
                      add_redirect_listener=lambda listener: None)
        nav = Chrome(self.env).prepare_request(req)['nav']
        self.assertEqual({'name': 'test', 'label': 'Test', 'active': False},
                         nav['metanav'][0])

    def test_nav_contributor_active(self):
        class TestNavigationContributor(Component):
            implements(INavigationContributor)
            def get_active_navigation_item(self, req):
                return 'test'
            def get_navigation_items(self, req):
                yield 'metanav', 'test', 'Test'
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), path_info='/',
                      base_path='/trac.cgi',
                      add_redirect_listener=lambda listener: None)
        handler = TestNavigationContributor(self.env)
        nav = Chrome(self.env).prepare_request(req, handler)['nav']
        self.assertEqual({'name': 'test', 'label': 'Test', 'active': True},
                         nav['metanav'][0])

    def test_nav_contributor_order(self):
        class TestNavigationContributor1(Component):
            implements(INavigationContributor)
            def get_active_navigation_item(self, req):
                return None
            def get_navigation_items(self, req):
                yield 'metanav', 'test1', 'Test 1'
        class TestNavigationContributor2(Component):
            implements(INavigationContributor)
            def get_active_navigation_item(self, req):
                return None
            def get_navigation_items(self, req):
                yield 'metanav', 'test2', 'Test 2'
        req = Request(abs_href=Href('http://example.org/trac.cgi'),
                      href=Href('/trac.cgi'), base_path='/trac.cgi',
                      path_info='/',
                      add_redirect_listener=lambda listener: None)
        chrome = Chrome(self.env)

        # Test with both items set in the order option
        self.env.config.set('trac', 'metanav', 'test2, test1')
        items = chrome.prepare_request(req)['nav']['metanav']
        self.assertEqual('test2', items[0]['name'])
        self.assertEqual('test1', items[1]['name'])

        # Test with only test1 in the order options
        self.env.config.set('trac', 'metanav', 'test1')
        items = chrome.prepare_request(req)['nav']['metanav']
        self.assertEqual('test1', items[0]['name'])
        self.assertEqual('test2', items[1]['name'])

        # Test with only test2 in the order options
        self.env.config.set('trac', 'metanav', 'test2')
        items = chrome.prepare_request(req)['nav']['metanav']
        self.assertEqual('test2', items[0]['name'])
        self.assertEqual('test1', items[1]['name'])

        # Test with none in the order options (order corresponds to
        # registration order)
        self.env.config.set('trac', 'metanav', 'foo, bar')
        items = chrome.prepare_request(req)['nav']['metanav']
        self.assertEqual('test1', items[0]['name'])
        self.assertEqual('test2', items[1]['name'])


def suite():
    return unittest.makeSuite(ChromeTestCase, 'test')

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = href
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2007 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import doctest
import unittest

import trac.web.href


class HrefTestCase(unittest.TestCase):
    """Unit tests for Href URL builder."""

    def test_non_empty_base(self):
        """Build URLs with a non-empty base."""
        href = trac.web.href.Href('/base')
        self.assertEqual('/base', href())
        self.assertEqual('/base', href('/'))
        self.assertEqual('/base/sub', href('sub'))
        self.assertEqual('/base/sub', href('/sub/'))
        self.assertEqual('/base/sub/other', href('sub', 'other'))
        self.assertEqual('/base/sub/other', href('sub', None, 'other'))
        self.assertEqual('/base/sub/other', href('sub', '', 'other'))
        self.assertEqual('/base/sub/other', href('sub', '', '', 'other'))
        self.assertEqual('/base/sub/other', href('', 'sub', 'other'))
        self.assertEqual('/base/sub/other/', href('sub', 'other', ''))
        self.assertEqual('/base/with%20special%26chars',
                         href('with special&chars'))
        assert href('page', param='value', other='other value', more=None) in [
            '/base/page?param=value&other=other+value',
            '/base/page?other=other+value&param=value']
        self.assertEqual('/base/page?param=multiple&param=values',
                         href('page', param=['multiple', 'values']))

        self.assertEqual('/base/path/to/file/', href + '/path/to/file/')
        self.assertEqual('/base/path/to/file', href + 'path/to/file')
        self.assertEqual('/base', href + '')

    def test_base_with_trailing_slash(self):
        """Build URLs with a base with a trailing slash."""
        href = trac.web.href.Href('/base/')
        self.assertEqual('/base', href())
        self.assertEqual('/base', href('/'))
        self.assertEqual('/base/sub', href('sub'))
        self.assertEqual('/base/sub', href('/sub/'))

        self.assertEqual('/base/path/to/file/', href + '/path/to/file/')
        self.assertEqual('/base/path/to/file', href + 'path/to/file')
        self.assertEqual('/base', href + '')

    def test_empty_base(self):
        """Build URLs with an empty base."""
        href = trac.web.href.Href('')
        self.assertEqual('/', href())
        self.assertEqual('/', href('/'))
        self.assertEqual('/sub', href('sub'))
        self.assertEqual('/sub', href('/sub/'))
        self.assertEqual('/sub/other', href('sub', 'other'))
        self.assertEqual('/sub/other', href('sub', None, 'other'))
        self.assertEqual('/sub/other', href('sub', '', 'other'))
        self.assertEqual('/sub/other', href('sub', '', '', 'other'))
        self.assertEqual('/sub/other', href('', 'sub', 'other'))
        self.assertEqual('/sub/other/', href('sub', 'other', ''))
        self.assertEqual('/with%20special%26chars',
                         href('with special&chars'))
        assert href('page', param='value', other='other value', more=None) in [
            '/page?param=value&other=other+value',
            '/page?other=other+value&param=value']
        self.assertEqual('/page?param=multiple&param=values',
                         href('page', param=['multiple', 'values']))

        self.assertEqual('/path/to/file/', href + '/path/to/file/')
        self.assertEqual('/path/to/file', href + 'path/to/file')
        self.assertEqual('/', href + '')

    def test_params_subclasses(self):
        """Parameters passed using subclasses of dict, list and tuple."""
        class MyDict(dict):
            pass
        class MyList(list):
            pass
        class MyTuple(tuple):
            pass
        href = trac.web.href.Href('/base')
        self.assertEqual('/base?param=test&param=other',
                         href(param=MyList(['test', 'other'])))
        self.assertEqual('/base?param=test&param=other',
                         href(param=MyTuple(['test', 'other'])))
        assert href(MyDict(param='value', other='other value')) in [
            '/base?param=value&other=other+value',
            '/base?other=other+value&param=value']
        self.assertEqual('/base?param=value&other=other+value',
                         href(MyList([('param', 'value'), ('other', 'other value')])))
        self.assertEqual('/base?param=value&other=other+value',
                         href(MyTuple([('param', 'value'), ('other', 'other value')])))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(doctest.DocTestSuite(trac.web.href))
    suite.addTest(unittest.makeSuite(HrefTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = main
# -*- coding: utf-8 -*-
#
# Copyright (C) 2010 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from trac.util import create_file
from trac.web.main import get_environments

import tempfile
import unittest
import os.path


class EnvironmentsTestCase(unittest.TestCase):

    dirs = ('mydir1', 'mydir2', '.hidden_dir')
    files = ('myfile1', 'myfile2', '.dot_file')

    def setUp(self):
        self.parent_dir = tempfile.mkdtemp(prefix='trac-')
        self.tracignore = os.path.join(self.parent_dir, '.tracignore')
        for dname in self.dirs:
            os.mkdir(os.path.join(self.parent_dir, dname))
        for fname in self.files:
            create_file(os.path.join(self.parent_dir, fname))
        self.environ = {
           'trac.env_paths': [],
           'trac.env_parent_dir': self.parent_dir,
        }

    def tearDown(self):
        for fname in self.files:
            os.unlink(os.path.join(self.parent_dir, fname))
        for dname in self.dirs:
            os.rmdir(os.path.join(self.parent_dir, dname))
        if os.path.exists(self.tracignore):
            os.unlink(self.tracignore)
        os.rmdir(self.parent_dir)

    def env_paths(self, projects):
        return dict((project, os.path.normpath(os.path.join(self.parent_dir,
                                                            project)))
                    for project in projects)

    def test_default_tracignore(self):
        self.assertEquals(self.env_paths(['mydir1', 'mydir2']),
                          get_environments(self.environ))

    def test_empty_tracignore(self):
        create_file(self.tracignore)
        self.assertEquals(self.env_paths(['mydir1', 'mydir2', '.hidden_dir']),
                          get_environments(self.environ))

    def test_qmark_pattern_tracignore(self):
        create_file(self.tracignore, 'mydir?')
        self.assertEquals(self.env_paths(['.hidden_dir']),
                          get_environments(self.environ))

    def test_star_pattern_tracignore(self):
        create_file(self.tracignore, 'my*\n.hidden_dir')
        self.assertEquals({}, get_environments(self.environ))

    def test_combined_tracignore(self):
        create_file(self.tracignore, 'my*i?1\n\n#mydir2')
        self.assertEquals(self.env_paths(['mydir2', '.hidden_dir']),
                          get_environments(self.environ))


def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(EnvironmentsTestCase, 'test'))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = session
from __future__ import with_statement

from Cookie import SimpleCookie as Cookie
import time
from datetime import datetime
import unittest

from trac.test import EnvironmentStub, Mock
from trac.web.session import DetachedSession, Session, PURGE_AGE, \
                             UPDATE_INTERVAL, SessionAdmin
from trac.core import TracError


def _prep_session_table(env, spread_visits=False):
    """ Populate the session table with known values.

    :return: a tuple of lists `(auth_list, anon_list, all_list)`
    :since 1.0: changed `db` input parameter to `env`
    """
    with env.db_transaction as db:
        db("DELETE FROM session")
        db("DELETE FROM session_attribute")
    last_visit_base = time.mktime(datetime(2010, 1, 1).timetuple())
    visit_delta = 86400 if spread_visits else 0
    auth_list, anon_list = [], []
    with env.db_transaction as db:
        for x in xrange(20):
            sid = 'name%02d' % x
            authenticated = int(x < 10)
            last_visit = last_visit_base + (visit_delta * x)
            val = 'val%02d' % x
            data = (sid, authenticated, last_visit, val, val)
            if authenticated:
                auth_list.append(data)
            else:
                anon_list.append(data)
            db("INSERT INTO session VALUES (%s, %s, %s)",
               (sid, authenticated, last_visit))
            db("INSERT INTO session_attribute VALUES (%s, %s, 'name', %s)",
               (sid, authenticated, val))
            db("INSERT INTO session_attribute VALUES (%s, %s, 'email', %s)",
               (sid, authenticated, val))
    all_list = auth_list + anon_list
    return (auth_list, anon_list, all_list)

def get_session_info(env, sid):
    """:since 1.0: changed `db` input parameter to `env`"""
    for row in env.db_query("""
            SELECT DISTINCT s.sid, n.value, e.value FROM session AS s
            LEFT JOIN session_attribute AS n ON (n.sid=s.sid AND n.name='name')
            LEFT JOIN session_attribute AS e ON (e.sid=s.sid AND e.name='email')
            WHERE s.sid=%s
            """, (sid,)):
        return row
    else:
        return (None, None, None)


class SessionTestCase(unittest.TestCase):
    """Unit tests for the persistent session support."""

    def setUp(self):
        self.env = EnvironmentStub()

    def tearDown(self):
        self.env.reset_db()

    def test_new_session(self):
        """
        Verify that a session cookie gets sent back to the client for a new
        session.
        """
        cookie = Cookie()
        req = Mock(incookie=Cookie(), outcookie=cookie, authname='anonymous',
                   base_path='/')
        session = Session(self.env, req)
        self.assertEqual(session.sid, cookie['trac_session'].value)
        self.assertEqual(0, self.env.db_query(
                "SELECT COUNT(*) FROM session")[0][0])

    def test_anonymous_session(self):
        """
        Verify that session variables are stored in the database.
        """
        incookie = Cookie()
        incookie['trac_session'] = '123456'
        outcookie = Cookie()
        req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                   outcookie=outcookie)
        session = Session(self.env, req)
        self.assertEquals('123456', session.sid)
        self.failIf(outcookie.has_key('trac_session'))

    def test_authenticated_session(self):
        """
        Verifies that a session cookie does not get used if the user is logged
        in, and that Trac expires the cookie.
        """
        incookie = Cookie()
        incookie['trac_session'] = '123456'
        outcookie = Cookie()
        req = Mock(authname='john', base_path='/', incookie=incookie,
                   outcookie=outcookie)
        session = Session(self.env, req)
        self.assertEqual('john', session.sid)
        session['foo'] = 'bar'
        session.save()
        self.assertEquals(0, outcookie['trac_session']['expires'])

    def test_session_promotion(self):
        """
        Verifies that an existing anonymous session gets promoted to an
        authenticated session when the user logs in.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('123456', 0, 0)")
            incookie = Cookie()
            incookie['trac_session'] = '123456'
            outcookie = Cookie()
            req = Mock(authname='john', base_path='/', incookie=incookie,
                       outcookie=outcookie)
            session = Session(self.env, req)
            self.assertEqual('john', session.sid)
            session.save()

        self.assertEqual([('john', 1)], self.env.db_query(
            "SELECT sid, authenticated FROM session"))

    def test_new_session_promotion(self):
        """
        Verifies that even without a preexisting anonymous session,
        an authenticated session will be created when the user logs in.
        (same test as above without the initial INSERT)
        """
        with self.env.db_transaction as db:
            incookie = Cookie()
            incookie['trac_session'] = '123456'
            outcookie = Cookie()
            req = Mock(authname='john', base_path='/', incookie=incookie,
                       outcookie=outcookie)
            session = Session(self.env, req)
            self.assertEqual('john', session.sid)
            session.save()

        self.assertEqual([('john', 1)], self.env.db_query(
                "SELECT sid, authenticated FROM session"))

    def test_add_anonymous_session_var(self):
        """
        Verify that new variables are inserted into the 'session' table in the
        database for an anonymous session.
        """
        incookie = Cookie()
        incookie['trac_session'] = '123456'
        req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                   outcookie=Cookie())
        session = Session(self.env, req)
        session['foo'] = 'bar'
        session.save()

        self.assertEqual('bar', self.env.db_query(
                "SELECT value FROM session_attribute WHERE sid='123456'")[0][0])

    def test_modify_anonymous_session_var(self):
        """
        Verify that modifying an existing variable updates the 'session' table
        accordingly for an anonymous session.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('123456', 0, 0)")
            db("""
                INSERT INTO session_attribute VALUES
                ('123456', 0, 'foo', 'bar')
                """)
            incookie = Cookie()
            incookie['trac_session'] = '123456'
            req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                       outcookie=Cookie())
            session = Session(self.env, req)
            self.assertEqual('bar', session['foo'])
            session['foo'] = 'baz'
            session.save()

        self.assertEqual('baz', self.env.db_query(
                "SELECT value FROM session_attribute WHERE sid='123456'")[0][0])

    def test_delete_anonymous_session_var(self):
        """
        Verify that modifying a variable updates the 'session' table accordingly
        for an anonymous session.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('123456', 0, 0)")
            db("""
                INSERT INTO session_attribute VALUES
                ('123456', 0, 'foo', 'bar')
                """)
            incookie = Cookie()
            incookie['trac_session'] = '123456'
            req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                       outcookie=Cookie())
            session = Session(self.env, req)
            self.assertEqual('bar', session['foo'])
            del session['foo']
            session.save()

        self.assertEqual(0, self.env.db_query("""
            SELECT COUNT(*) FROM session_attribute
            WHERE sid='123456' AND name='foo'
            """)[0][0])

    def test_purge_anonymous_session(self):
        """
        Verify that old sessions get purged.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('123456', 0, %s)", (0,))
            db("INSERT INTO session VALUES ('987654', 0, %s)",
               (int(time.time() - PURGE_AGE - 3600),))
            db("""
                INSERT INTO session_attribute
                VALUES ('987654', 0, 'foo', 'bar')
                """)

            # We need to modify a different session to trigger the purging
            incookie = Cookie()
            incookie['trac_session'] = '123456'
            req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                       outcookie=Cookie())
            session = Session(self.env, req)
            session['foo'] = 'bar'
            session.save()

        self.assertEqual(0, self.env.db_query("""
            SELECT COUNT(*) FROM session WHERE sid='987654' AND authenticated=0
            """)[0][0])

    def test_delete_empty_session(self):
        """
        Verify that a session gets deleted when it doesn't have any data except
        for the 'last_visit' timestamp.
        """
        now = time.time()

        # Make sure the session has data so that it doesn't get dropped
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('123456', 0, %s)",
               (int(now - UPDATE_INTERVAL - 3600),))
            db("""
                INSERT INTO session_attribute
                VALUES ('123456', 0, 'foo', 'bar')
                """)

            incookie = Cookie()
            incookie['trac_session'] = '123456'
            req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                       outcookie=Cookie())
            session = Session(self.env, req)
            del session['foo']
            session.save()

        self.assertEqual(0, self.env.db_query("""
            SELECT COUNT(*) FROM session WHERE sid='123456' AND authenticated=0
            """)[0][0])

    def test_change_anonymous_session(self):
        """
        Verify that changing from one anonymous session to an inexisting
        anonymous session creates the new session and doesn't carry over
        variables from the previous session.
        """

        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('123456', 0, 0)")
            db("""
                INSERT INTO session_attribute
                VALUES ('123456', 0, 'foo', 'bar')
                """)

        incookie = Cookie()
        incookie['trac_session'] = '123456'
        req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                   outcookie=Cookie())
        session = Session(self.env, req)
        self.assertEqual({'foo': 'bar'}, session)

        session.get_session('7890')
        session['baz'] = 'moo'
        session.save()
        self.assertEqual({'baz': 'moo'}, session)

        with self.env.db_query as db:
            self.assertEqual(1, db("""
                SELECT COUNT(*) FROM session
                WHERE sid='7890' AND authenticated=0
                """)[0][0])
            self.assertEqual([('baz', 'moo')], db("""
                SELECT name, value FROM session_attribute
                WHERE sid='7890' AND authenticated=0
                """))

    def test_add_authenticated_session_var(self):
        """
        Verify that new variables are inserted into the 'session' table in the
        database for an authenticated session.
        """
        req = Mock(authname='john', base_path='/', incookie=Cookie())
        session = Session(self.env, req)
        session['foo'] = 'bar'
        session.save()

        self.assertEqual('bar', self.env.db_query("""
            SELECT value FROM session_attribute WHERE sid='john' AND name='foo'
            """)[0][0])

    def test_modify_authenticated_session_var(self):
        """
        Verify that modifying an existing variable updates the 'session' table
        accordingly for an authenticated session.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('john', 1, 0)")
            db("INSERT INTO session_attribute VALUES ('john',1,'foo','bar')")

            req = Mock(authname='john', base_path='/', incookie=Cookie())
            session = Session(self.env, req)
            self.assertEqual('bar', session['foo'])
            session['foo'] = 'baz'
            session.save()

        self.assertEqual('baz', self.env.db_query("""
            SELECT value FROM session_attribute WHERE sid='john' AND name='foo'
            """)[0][0])

    def test_authenticated_session_independence_var(self):
        """
        Verify that an anonymous session with the same name as an authenticated
        session doesn't interfere with the latter.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('john', 1, 0)")
            db("INSERT INTO session_attribute VALUES ('john',1,'foo','bar')")

        self.assertEqual('bar', self.env.db_query("""
            SELECT value FROM session_attribute
            WHERE sid='john' AND authenticated=1 AND name='foo'
            """)[0][0])

        incookie = Cookie()
        incookie['trac_session'] = 'john'
        req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                   outcookie=Cookie())
        session = Session(self.env, req)
        self.assert_('foo' not in session)
        session['foo'] = 'baz'
        session.save()

        rows = self.env.db_query("""
            SELECT value FROM session_attribute
            WHERE sid='john' AND authenticated=1 AND name='foo'
            """)
        self.assertEqual(1, len(rows))
        self.assertEqual('bar', rows[0][0])
        rows = self.env.db_query("""
            SELECT value FROM session_attribute
            WHERE sid='john' AND authenticated=0 AND name='foo'
            """)
        self.assertEqual(1, len(rows))
        self.assertEqual('baz', rows[0][0])

    def test_delete_authenticated_session_var(self):
        """
        Verify that deleting a variable updates the 'session' table accordingly
        for an authenticated session.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('john', 1, 0)")
            db("INSERT INTO session_attribute VALUES ('john', 1, 'foo', 'bar')")

            req = Mock(authname='john', base_path='/', incookie=Cookie())
            session = Session(self.env, req)
            self.assertEqual('bar', session['foo'])
            del session['foo']
            session.save()

        self.assertEqual(0, self.env.db_query("""
            SELECT COUNT(*) FROM session_attribute
            WHERE sid='john' AND name='foo'
            """)[0][0])

    def test_update_session(self):
        """
        Verify that accessing a session after one day updates the sessions
        'last_visit' variable so that the session doesn't get purged.
        """
        now = time.time()

        # Make sure the session has data so that it doesn't get dropped
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('123456', 0, 1)")
            db("""
                INSERT INTO session_attribute
                VALUES ('123456', 0, 'foo', 'bar')
                """)

            incookie = Cookie()
            incookie['trac_session'] = '123456'
            outcookie = Cookie()
            req = Mock(authname='anonymous', base_path='/', incookie=incookie,
                       outcookie=outcookie)
            session = Session(self.env, req)
            session['modified'] = True
            session.save() # updating does require modifications

            self.assertEqual(PURGE_AGE, outcookie['trac_session']['expires'])

        self.assertAlmostEqual(now, int(self.env.db_query("""
            SELECT last_visit FROM session
            WHERE sid='123456' AND authenticated=0
            """)[0][0]), -1)

    def test_modify_detached_session(self):
        """
        Verify that modifying a variable in a session not associated with a
        request updates the database accordingly.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('john', 1, 0)")
            db("INSERT INTO session_attribute VALUES ('john', 1, 'foo', 'bar')")

            session = DetachedSession(self.env, 'john')
            self.assertEqual('bar', session['foo'])
            session['foo'] = 'baz'
            session.save()

        self.assertEqual('baz', self.env.db_query("""
            SELECT value FROM session_attribute WHERE sid='john' AND name='foo'
            """)[0][0])

    def test_delete_detached_session_var(self):
        """
        Verify that removing a variable in a session not associated with a
        request deletes the variable from the database.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('john', 1, 0)")
            db("INSERT INTO session_attribute VALUES ('john', 1, 'foo', 'bar')")

            session = DetachedSession(self.env, 'john')
            self.assertEqual('bar', session['foo'])
            del session['foo']
            session.save()

        self.assertEqual(0, self.env.db_query("""
            SELECT COUNT(*) FROM session_attribute
            WHERE sid='john' AND name='foo'
            """)[0][0])

    def test_session_set(self):
        """Verify that setting a variable in a session to the default value
        removes it from the session.
        """
        with self.env.db_transaction as db:
            db("INSERT INTO session VALUES ('john', 1, 0)")
            db("INSERT INTO session_attribute VALUES ('john', 1, 'foo', 'bar')")

        session = DetachedSession(self.env, 'john')
        self.assertEqual('bar', session['foo'])

        # Setting the variable to the default value removes the variable
        with self.env.db_transaction as db:
            session.set('foo', 'default', 'default')
            session.save()
        self.assertEqual(0, self.env.db_query("""
            SELECT COUNT(*) FROM session_attribute
            WHERE sid='john' AND name='foo'
            """)[0][0])

        # Setting the variable to a value different from the default sets it
        with self.env.db_transaction as db:
            session.set('foo', 'something', 'default')
            session.save()
        self.assertEqual('something', self.env.db_query("""
            SELECT value FROM session_attribute
            WHERE sid='john' AND name='foo'
            """)[0][0])

    def test_session_admin_list(self):
        auth_list, anon_list, all_list = _prep_session_table(self.env)
        sess_admin = SessionAdmin(self.env)

        # Verify the empty case
        self.assertRaises(StopIteration, sess_admin._get_list([]).next)

        self.assertEqual([i for i in sess_admin._get_list(['authenticated'])],
                         auth_list)
        self.assertEqual([i for i in sess_admin._get_list(['anonymous'])],
                         anon_list)
        self.assertEqual([i for i in sess_admin._get_list(['*'])], all_list)
        self.assertEqual([i for i in sess_admin._get_list(['name00'])][0],
                         auth_list[0])
        self.assertEqual([i for i in sess_admin._get_list(['name10:0'])][0],
                         anon_list[0])
        self.assertEqual([i for i in sess_admin._get_list(['name00', 'name01',
                                                           'name02'])],
                         all_list[:3])

    def test_session_admin_add(self):
        auth_list, anon_list, all_list = _prep_session_table(self.env)
        sess_admin = SessionAdmin(self.env)
        self.assertRaises(Exception, sess_admin._do_add, 'name00')
        sess_admin._do_add('john')
        result = get_session_info(self.env, 'john')
        self.assertEqual(result, ('john', None, None))
        sess_admin._do_add('john1', 'John1')
        result = get_session_info(self.env, 'john1')
        self.assertEqual(result, ('john1', 'John1', None))
        sess_admin._do_add('john2', 'John2', 'john2@example.org')
        result = get_session_info(self.env, 'john2')
        self.assertEqual(result, ('john2', 'John2', 'john2@example.org'))

    def test_session_admin_set(self):
        auth_list, anon_list, all_list = _prep_session_table(self.env)
        sess_admin = SessionAdmin(self.env)
        self.assertRaises(TracError, sess_admin._do_set, 'name', 'nothere',
                          'foo')
        sess_admin._do_set('name', 'name00', 'john')
        result = get_session_info(self.env, 'name00')
        self.assertEqual(result, ('name00', 'john', 'val00'))
        sess_admin._do_set('email', 'name00', 'john@example.org')
        result = get_session_info(self.env, 'name00')
        self.assertEqual(result, ('name00', 'john', 'john@example.org'))

    def test_session_admin_delete(self):
        auth_list, anon_list, all_list = _prep_session_table(self.env)
        sess_admin = SessionAdmin(self.env)
        sess_admin._do_delete('name00')
        result = get_session_info(self.env, 'name00')
        self.assertEqual(result, (None, None, None))
        sess_admin._do_delete('nothere')
        result = get_session_info(self.env, 'nothere')
        self.assertEqual(result, (None, None, None))
        auth_list, anon_list, all_list = _prep_session_table(self.env)
        sess_admin._do_delete('anonymous')
        result = [i for i in sess_admin._get_list(['*'])]
        self.assertEqual(result, auth_list)

    def test_session_admin_purge(self):
        sess_admin = SessionAdmin(self.env)

        auth_list, anon_list, all_list = \
            _prep_session_table(self.env, spread_visits=True)
        sess_admin._do_purge('2010-01-02')
        result = [i for i in sess_admin._get_list(['*'])]
        self.assertEqual(result, auth_list + anon_list)
        result = get_session_info(self.env, anon_list[0][0])
        self.assertEqual(result, ('name10', 'val10', 'val10'))
        result = get_session_info(self.env, anon_list[1][0])
        self.assertEqual(result, ('name11', 'val11', 'val11'))

        auth_list, anon_list, all_list = \
            _prep_session_table(self.env, spread_visits=True)
        sess_admin._do_purge('2010-01-12')
        result = [i for i in sess_admin._get_list(['*'])]
        self.assertEqual(result, auth_list + anon_list[1:])
        rows = self.env.db_query("""
            SELECT name, value FROM session_attribute WHERE sid = %s
            """, (anon_list[0][0],))
        self.assertEqual([], rows)
        result = get_session_info(self.env, anon_list[1][0])
        self.assertEqual(result, ('name11', 'val11', 'val11'))


def suite():
    return unittest.makeSuite(SessionTestCase, 'test')


if __name__ == '__main__':
    unittest.main()

########NEW FILE########
__FILENAME__ = wikisyntax
import unittest

from trac.wiki.tests import formatter

TEST_CASES = """
============================== htdocs: links resolver
htdocs:release-1.0.tar.gz

[htdocs:release-1.0.tar.gz Release 1.0]
------------------------------
<p>
<a href="/chrome/site/release-1.0.tar.gz">htdocs:release-1.0.tar.gz</a>
</p>
<p>
<a href="/chrome/site/release-1.0.tar.gz">Release 1.0</a>
</p>
------------------------------
"""

def suite():
    return formatter.suite(TEST_CASES, file=__file__)

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = wsgi
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

import errno
import socket
import sys
from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler
from SocketServer import ForkingMixIn, ThreadingMixIn
import urllib


class _ErrorsWrapper(object):

    def __init__(self, logfunc):
        self.logfunc = logfunc

    def flush(self):
        pass

    def write(self, msg):
        self.logfunc(msg)

    def writelines(self, seq):
        map(self.write, seq)


class _FileWrapper(object):
    """Wrapper for sending a file as response."""

    def __init__(self, fileobj, blocksize=None):
        self.fileobj = fileobj
        self.blocksize = blocksize
        self.read = self.fileobj.read
        if hasattr(fileobj, 'close'):
            self.close = fileobj.close

    def __iter__(self):
        return self

    def next(self):
        data = self.fileobj.read(self.blocksize)
        if not data:
            raise StopIteration
        return data


class WSGIGateway(object):
    """Abstract base class for WSGI servers or gateways."""

    wsgi_version = (1, 0)
    wsgi_multithread = True
    wsgi_multiprocess = True
    wsgi_run_once = False
    wsgi_file_wrapper = _FileWrapper

    def __init__(self, environ, stdin=sys.stdin, stderr=sys.stderr):
        """Initialize the gateway object."""
        environ['wsgi.version'] = self.wsgi_version
        environ['wsgi.url_scheme'] = 'http'
        if environ.get('HTTPS', '').lower() in ('yes', 'on', '1'):
            environ['wsgi.url_scheme'] = 'https'
        elif environ.get('HTTP_X_FORWARDED_PROTO', '').lower() == 'https':
            environ['wsgi.url_scheme'] = 'https'
        environ['wsgi.input'] = stdin
        environ['wsgi.errors'] = stderr
        environ['wsgi.multithread'] = self.wsgi_multithread
        environ['wsgi.multiprocess'] = self.wsgi_multiprocess
        environ['wsgi.run_once'] = self.wsgi_run_once
        if self.wsgi_file_wrapper is not None:
            environ['wsgi.file_wrapper'] = self.wsgi_file_wrapper
        self.environ = environ

        self.headers_set = []
        self.headers_sent = []

    def run(self, application):
        """Start the gateway with the given WSGI application."""
        response = application(self.environ, self._start_response)
        try:
            if self.wsgi_file_wrapper is not None \
                    and isinstance(response, self.wsgi_file_wrapper) \
                    and hasattr(self, '_sendfile'):
                self._sendfile(response.fileobj)
            else:
                for chunk in response:
                    if chunk:
                        self._write(chunk)
                if not self.headers_sent:
                    self._write('')
        finally:
            if hasattr(response, 'close'):
                response.close()

    def _start_response(self, status, headers, exc_info=None):
        """Callback for starting a HTTP response."""
        if exc_info:
            try:
                if self.headers_sent: # Re-raise original exception
                    raise exc_info[0], exc_info[1], exc_info[2]
            finally:
                exc_info = None # avoid dangling circular ref
        else:
            assert not self.headers_set, 'Response already started'

        self.headers_set = [status, headers]
        return self._write

    def _write(self, data):
        """Callback for writing data to the response.

        Concrete subclasses must implement this method."""
        raise NotImplementedError


class WSGIRequestHandler(BaseHTTPRequestHandler):

    def setup_environ(self):
        self.raw_requestline = self.rfile.readline()
        if (self.rfile.closed or              # disconnect
                not self.raw_requestline or   # empty request
                not self.parse_request()):    # invalid request
            self.close_connection = 1
            # note that in the latter case, an error code has already been sent
            return

        environ = self.server.environ.copy()
        environ['SERVER_PROTOCOL'] = self.request_version
        environ['REQUEST_METHOD'] = self.command

        if '?' in self.path:
            path_info, query_string = self.path.split('?', 1)
        else:
            path_info, query_string = self.path, ''
        environ['PATH_INFO'] = urllib.unquote(path_info)
        environ['QUERY_STRING'] = query_string

        host = self.address_string()
        if host != self.client_address[0]:
            environ['REMOTE_HOST'] = host
        environ['REMOTE_ADDR'] = self.client_address[0]

        if self.headers.typeheader is None:
            environ['CONTENT_TYPE'] = self.headers.type
        else:
            environ['CONTENT_TYPE'] = self.headers.typeheader

        length = self.headers.getheader('content-length')
        if length:
            environ['CONTENT_LENGTH'] = length

        for name, value in [header.split(':', 1) for header
                            in self.headers.headers]:
            name = name.replace('-', '_').upper()
            value = value.strip()
            if name in environ:
                # skip content length, type, etc.
                continue
            if 'HTTP_' + name in environ:
                # comma-separate multiple headers
                environ['HTTP_' + name] += ',' + value
            else:
                environ['HTTP_' + name] = value

        return environ

    def handle_one_request(self):
        try:
            environ = self.setup_environ()
        except (IOError, socket.error), e:
            environ = None
            if e.args[0] in (errno.EPIPE, errno.ECONNRESET, 10053, 10054):
                # client disconnect
                self.close_connection = 1
            else:
                raise
        if environ:
            gateway = self.server.gateway(self, environ)
            gateway.run(self.server.application)
        # else we had no request or a bad request: we simply exit (#3043)

    def finish(self):
        """We need to help the garbage collector a little."""
        BaseHTTPRequestHandler.finish(self)
        self.wfile = None
        self.rfile = None


class WSGIServerGateway(WSGIGateway):

    def __init__(self, handler, environ):
        WSGIGateway.__init__(self, environ, handler.rfile,
                             _ErrorsWrapper(lambda x: handler.log_error('%s', x)))
        self.handler = handler

    def _write(self, data):
        assert self.headers_set, 'Response not started'
        if self.handler.wfile.closed:
            return # don't write to an already closed file (fix for #1183)

        try:
            if not self.headers_sent:
                status, headers = self.headers_sent = self.headers_set
                self.handler.send_response(int(status[:3]))
                for name, value in headers:
                    self.handler.send_header(name, value)
                self.handler.end_headers()
            self.handler.wfile.write(data)
        except (IOError, socket.error), e:
            if e.args[0] in (errno.EPIPE, errno.ECONNRESET, 10053, 10054):
                # client disconnect
                self.handler.close_connection = 1
            else:
                raise


class WSGIServer(HTTPServer):

    def __init__(self, server_address, application, gateway=WSGIServerGateway,
                 request_handler=WSGIRequestHandler):
        HTTPServer.__init__(self, server_address, request_handler)

        self.application = application

        gateway.wsgi_multithread = isinstance(self, ThreadingMixIn)
        gateway.wsgi_multiprocess = isinstance(self, ForkingMixIn)
        self.gateway = gateway

        self.environ = {'SERVER_NAME': self.server_name,
                        'SERVER_PORT': str(self.server_port),
                        'SCRIPT_NAME': ''}

########NEW FILE########
__FILENAME__ = _fcgi
# -*- coding: iso-8859-1 -*-
#
# Copyright (c) 2002, 2003, 2005, 2006 Allan Saddi <allan@saddi.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Allan Saddi <allan@saddi.com>

"""
fcgi - a FastCGI/WSGI gateway.

For more information about FastCGI, see <http://www.fastcgi.com/>.

For more information about the Web Server Gateway Interface, see

<http://www.python.org/peps/pep-0333.html>.

Example usage:

  #!/usr/bin/env python
  from myapplication import app # Assume app is your WSGI application object
  from fcgi import WSGIServer
  WSGIServer(app).run()

See the documentation for WSGIServer/Server for more information.

On most platforms, fcgi will fallback to regular CGI behavior if run in a
non-FastCGI context. If you want to force CGI behavior, set the environment
variable FCGI_FORCE_CGI to "Y" or "y".
"""

__author__ = 'Allan Saddi <allan@saddi.com>'
__version__ = '$Revision: 2025 $'

import sys
import os
import signal
import struct
import cStringIO as StringIO
import select
import socket
import errno
import traceback

try:
    import thread
    import threading
    thread_available = True
except ImportError:
    import dummy_thread as thread
    import dummy_threading as threading
    thread_available = False

# Apparently 2.3 doesn't define SHUT_WR? Assume it is 1 in this case.
if not hasattr(socket, 'SHUT_WR'):
    socket.SHUT_WR = 1

__all__ = ['WSGIServer']

# Constants from the spec.
FCGI_LISTENSOCK_FILENO = 0

FCGI_HEADER_LEN = 8

FCGI_VERSION_1 = 1

FCGI_BEGIN_REQUEST = 1
FCGI_ABORT_REQUEST = 2
FCGI_END_REQUEST = 3
FCGI_PARAMS = 4
FCGI_STDIN = 5
FCGI_STDOUT = 6
FCGI_STDERR = 7
FCGI_DATA = 8
FCGI_GET_VALUES = 9
FCGI_GET_VALUES_RESULT = 10
FCGI_UNKNOWN_TYPE = 11
FCGI_MAXTYPE = FCGI_UNKNOWN_TYPE

FCGI_NULL_REQUEST_ID = 0

FCGI_KEEP_CONN = 1

FCGI_RESPONDER = 1
FCGI_AUTHORIZER = 2
FCGI_FILTER = 3

FCGI_REQUEST_COMPLETE = 0
FCGI_CANT_MPX_CONN = 1
FCGI_OVERLOADED = 2
FCGI_UNKNOWN_ROLE = 3

FCGI_MAX_CONNS = 'FCGI_MAX_CONNS'
FCGI_MAX_REQS = 'FCGI_MAX_REQS'
FCGI_MPXS_CONNS = 'FCGI_MPXS_CONNS'

FCGI_Header = '!BBHHBx'
FCGI_BeginRequestBody = '!HB5x'
FCGI_EndRequestBody = '!LB3x'
FCGI_UnknownTypeBody = '!B7x'

FCGI_EndRequestBody_LEN = struct.calcsize(FCGI_EndRequestBody)
FCGI_UnknownTypeBody_LEN = struct.calcsize(FCGI_UnknownTypeBody)

if __debug__:
    import time

    # Set non-zero to write debug output to a file.
    DEBUG = 0
    DEBUGLOG = '/tmp/fcgi.log'

    def _debug(level, msg):
        if DEBUG < level:
            return

        try:
            f = open(DEBUGLOG, 'a')
            f.write('%sfcgi: %s\n' % (time.ctime()[4:-4], msg))
            f.close()
        except:
            pass

class InputStream(object):
    """
    File-like object representing FastCGI input streams (FCGI_STDIN and
    FCGI_DATA). Supports the minimum methods required by WSGI spec.
    """
    def __init__(self, conn):
        self._conn = conn

        # See Server.
        self._shrinkThreshold = conn.server.inputStreamShrinkThreshold

        self._buf = ''
        self._bufList = []
        self._pos = 0 # Current read position.
        self._avail = 0 # Number of bytes currently available.

        self._eof = False # True when server has sent EOF notification.

    def _shrinkBuffer(self):
        """Gets rid of already read data (since we can't rewind)."""
        if self._pos >= self._shrinkThreshold:
            self._buf = self._buf[self._pos:]
            self._avail -= self._pos
            self._pos = 0

            assert self._avail >= 0

    def _waitForData(self):
        """Waits for more data to become available."""
        self._conn.process_input()

    def read(self, n=-1):
        if self._pos == self._avail and self._eof:
            return ''
        while True:
            if n < 0 or (self._avail - self._pos) < n:
                # Not enough data available.
                if self._eof:
                    # And there's no more coming.
                    newPos = self._avail
                    break
                else:
                    # Wait for more data.
                    self._waitForData()
                    continue
            else:
                newPos = self._pos + n
                break
        # Merge buffer list, if necessary.
        if self._bufList:
            self._buf += ''.join(self._bufList)
            self._bufList = []
        r = self._buf[self._pos:newPos]
        self._pos = newPos
        self._shrinkBuffer()
        return r

    def readline(self, length=None):
        if self._pos == self._avail and self._eof:
            return ''
        while True:
            # Unfortunately, we need to merge the buffer list early.
            if self._bufList:
                self._buf += ''.join(self._bufList)
                self._bufList = []
            # Find newline.
            i = self._buf.find('\n', self._pos)
            if i < 0:
                # Not found?
                if self._eof:
                    # No more data coming.
                    newPos = self._avail
                    break
                else:
                    # Wait for more to come.
                    self._waitForData()
                    continue
            else:
                newPos = i + 1
                break
        if length is not None:
            if self._pos + length < newPos:
                newPos = self._pos + length
        r = self._buf[self._pos:newPos]
        self._pos = newPos
        self._shrinkBuffer()
        return r

    def readlines(self, sizehint=0):
        total = 0
        lines = []
        line = self.readline()
        while line:
            lines.append(line)
            total += len(line)
            if 0 < sizehint <= total:
                break
            line = self.readline()
        return lines

    def __iter__(self):
        return self

    def next(self):
        r = self.readline()
        if not r:
            raise StopIteration
        return r

    def add_data(self, data):
        if not data:
            self._eof = True
        else:
            self._bufList.append(data)
            self._avail += len(data)

class MultiplexedInputStream(InputStream):
    """
    A version of InputStream meant to be used with MultiplexedConnections.
    Assumes the MultiplexedConnection (the producer) and the Request
    (the consumer) are running in different threads.
    """
    def __init__(self, conn):
        super(MultiplexedInputStream, self).__init__(conn)

        # Arbitrates access to this InputStream (it's used simultaneously
        # by a Request and its owning Connection object).
        lock = threading.RLock()

        # Notifies Request thread that there is new data available.
        self._lock = threading.Condition(lock)

    def _waitForData(self):
        # Wait for notification from add_data().
        self._lock.wait()

    def read(self, n=-1):
        self._lock.acquire()
        try:
            return super(MultiplexedInputStream, self).read(n)
        finally:
            self._lock.release()

    def readline(self, length=None):
        self._lock.acquire()
        try:
            return super(MultiplexedInputStream, self).readline(length)
        finally:
            self._lock.release()

    def add_data(self, data):
        self._lock.acquire()
        try:
            super(MultiplexedInputStream, self).add_data(data)
            self._lock.notify()
        finally:
            self._lock.release()

class OutputStream(object):
    """
    FastCGI output stream (FCGI_STDOUT/FCGI_STDERR). By default, calls to
    write() or writelines() immediately result in Records being sent back
    to the server. Buffering should be done in a higher level!
    """
    def __init__(self, conn, req, type, buffered=False):
        self._conn = conn
        self._req = req
        self._type = type
        self._buffered = buffered
        self._bufList = [] # Used if buffered is True
        self.dataWritten = False
        self.closed = False

    def _write(self, data):
        length = len(data)
        while length:
            toWrite = min(length, self._req.server.maxwrite - FCGI_HEADER_LEN)

            rec = Record(self._type, self._req.requestId)
            rec.contentLength = toWrite
            rec.contentData = data[:toWrite]
            self._conn.writeRecord(rec)

            data = data[toWrite:]
            length -= toWrite

    def write(self, data):
        assert not self.closed

        if not data:
            return

        self.dataWritten = True

        if self._buffered:
            self._bufList.append(data)
        else:
            self._write(data)

    def writelines(self, lines):
        assert not self.closed

        for line in lines:
            self.write(line)

    def flush(self):
        # Only need to flush if this OutputStream is actually buffered.
        if self._buffered:
            data = ''.join(self._bufList)
            self._bufList = []
            self._write(data)

    # Though available, the following should NOT be called by WSGI apps.
    def close(self):
        """Sends end-of-stream notification, if necessary."""
        if not self.closed and self.dataWritten:
            self.flush()
            rec = Record(self._type, self._req.requestId)
            self._conn.writeRecord(rec)
            self.closed = True

class TeeOutputStream(object):
    """
    Simple wrapper around two or more output file-like objects that copies
    written data to all streams.
    """
    def __init__(self, streamList):
        self._streamList = streamList

    def write(self, data):
        for f in self._streamList:
            f.write(data)

    def writelines(self, lines):
        for line in lines:
            self.write(line)

    def flush(self):
        for f in self._streamList:
            f.flush()

class StdoutWrapper(object):
    """
    Wrapper for sys.stdout so we know if data has actually been written.
    """
    def __init__(self, stdout):
        self._file = stdout
        self.dataWritten = False

    def write(self, data):
        if data:
            self.dataWritten = True
        self._file.write(data)

    def writelines(self, lines):
        for line in lines:
            self.write(line)

    def __getattr__(self, name):
        return getattr(self._file, name)

def decode_pair(s, pos=0):
    """
    Decodes a name/value pair.

    The number of bytes decoded as well as the name/value pair
    are returned.
    """
    nameLength = ord(s[pos])
    if nameLength & 128:
        nameLength = struct.unpack('!L', s[pos:pos+4])[0] & 0x7fffffff
        pos += 4
    else:
        pos += 1

    valueLength = ord(s[pos])
    if valueLength & 128:
        valueLength = struct.unpack('!L', s[pos:pos+4])[0] & 0x7fffffff
        pos += 4
    else:
        pos += 1

    name = s[pos:pos+nameLength]
    pos += nameLength
    value = s[pos:pos+valueLength]
    pos += valueLength

    return (pos, (name, value))

def encode_pair(name, value):
    """
    Encodes a name/value pair.

    The encoded string is returned.
    """
    nameLength = len(name)
    if nameLength < 128:
        s = chr(nameLength)
    else:
        s = struct.pack('!L', nameLength | 0x80000000L)

    valueLength = len(value)
    if valueLength < 128:
        s += chr(valueLength)
    else:
        s += struct.pack('!L', valueLength | 0x80000000L)

    return s + name + value

class Record(object):
    """
    A FastCGI Record.

    Used for encoding/decoding records.
    """
    def __init__(self, type=FCGI_UNKNOWN_TYPE, requestId=FCGI_NULL_REQUEST_ID):
        self.version = FCGI_VERSION_1
        self.type = type
        self.requestId = requestId
        self.contentLength = 0
        self.paddingLength = 0
        self.contentData = ''

    @staticmethod
    def _recvall(sock, length):
        """
        Attempts to receive length bytes from a socket, blocking if necessary.
        (Socket may be blocking or non-blocking.)
        """
        dataList = []
        recvLen = 0
        while length:
            try:
                data = sock.recv(length)
            except socket.error, e:
                if e[0] == errno.EAGAIN:
                    select.select([sock], [], [])
                    continue
                else:
                    raise
            if not data: # EOF
                break
            dataList.append(data)
            dataLen = len(data)
            recvLen += dataLen
            length -= dataLen
        return ''.join(dataList), recvLen

    def read(self, sock):
        """Read and decode a Record from a socket."""
        try:
            header, length = self._recvall(sock, FCGI_HEADER_LEN)
        except:
            raise EOFError

        if length < FCGI_HEADER_LEN:
            raise EOFError

        self.version, self.type, self.requestId, self.contentLength, \
                      self.paddingLength = struct.unpack(FCGI_Header, header)

        if __debug__: _debug(9, 'read: fd = %d, type = %d, requestId = %d, '
                             'contentLength = %d' %
                             (sock.fileno(), self.type, self.requestId,
                              self.contentLength))

        if self.contentLength:
            try:
                self.contentData, length = self._recvall(sock,
                                                         self.contentLength)
            except:
                raise EOFError

            if length < self.contentLength:
                raise EOFError

        if self.paddingLength:
            try:
                self._recvall(sock, self.paddingLength)
            except:
                raise EOFError

    @staticmethod
    def _sendall(sock, data):
        """
        Writes data to a socket and does not return until all the data is sent.
        """
        length = len(data)
        while length:
            try:
                sent = sock.send(data)
            except socket.error, e:
                if e[0] == errno.EAGAIN:
                    select.select([], [sock], [])
                    continue
                else:
                    raise
            data = data[sent:]
            length -= sent

    def write(self, sock):
        """Encode and write a Record to a socket."""
        self.paddingLength = -self.contentLength & 7

        if __debug__: _debug(9, 'write: fd = %d, type = %d, requestId = %d, '
                             'contentLength = %d' %
                             (sock.fileno(), self.type, self.requestId,
                              self.contentLength))

        header = struct.pack(FCGI_Header, self.version, self.type,
                             self.requestId, self.contentLength,
                             self.paddingLength)
        self._sendall(sock, header)
        if self.contentLength:
            self._sendall(sock, self.contentData)
        if self.paddingLength:
            self._sendall(sock, '\x00'*self.paddingLength)

class Request(object):
    """
    Represents a single FastCGI request.

    These objects are passed to your handler and is the main interface
    between your handler and the fcgi module. The methods should not
    be called by your handler. However, server, params, stdin, stdout,
    stderr, and data are free for your handler's use.
    """
    def __init__(self, conn, inputStreamClass):
        self._conn = conn

        self.server = conn.server
        self.params = {}
        self.stdin = inputStreamClass(conn)
        self.stdout = OutputStream(conn, self, FCGI_STDOUT)
        self.stderr = OutputStream(conn, self, FCGI_STDERR, buffered=True)
        self.data = inputStreamClass(conn)

    def run(self):
        """Runs the handler, flushes the streams, and ends the request."""
        try:
            protocolStatus, appStatus = self.server.handler(self)
        except:
            traceback.print_exc(file=self.stderr)
            self.stderr.flush()
            if not self.stdout.dataWritten:
                self.server.error(self)

            protocolStatus, appStatus = FCGI_REQUEST_COMPLETE, 0

        if __debug__: _debug(1, 'protocolStatus = %d, appStatus = %d' %
                             (protocolStatus, appStatus))

        try:
            self._flush()
            self._end(appStatus, protocolStatus)
        except socket.error, e:
            if e[0] != errno.EPIPE:
                raise

    def _end(self, appStatus=0L, protocolStatus=FCGI_REQUEST_COMPLETE):
        self._conn.end_request(self, appStatus, protocolStatus)

    def _flush(self):
        self.stdout.close()
        self.stderr.close()

class CGIRequest(Request):
    """A normal CGI request disguised as a FastCGI request."""
    def __init__(self, server):
        # These are normally filled in by Connection.
        self.requestId = 1
        self.role = FCGI_RESPONDER
        self.flags = 0
        self.aborted = False

        self.server = server
        self.params = dict(os.environ)
        self.stdin = sys.stdin
        self.stdout = StdoutWrapper(sys.stdout) # Oh, the humanity!
        self.stderr = sys.stderr
        self.data = StringIO.StringIO()

    def _end(self, appStatus=0L, protocolStatus=FCGI_REQUEST_COMPLETE):
        sys.exit(appStatus)

    def _flush(self):
        # Not buffered, do nothing.
        pass

class Connection(object):
    """
    A Connection with the web server.

    Each Connection is associated with a single socket (which is
    connected to the web server) and is responsible for handling all
    the FastCGI message processing for that socket.
    """
    _multiplexed = False
    _inputStreamClass = InputStream

    def __init__(self, sock, addr, server):
        self._sock = sock
        self._addr = addr
        self.server = server

        # Active Requests for this Connection, mapped by request ID.
        self._requests = {}

    def _cleanupSocket(self):
        """Close the Connection's socket."""
        try:
            self._sock.shutdown(socket.SHUT_WR)
        except:
            return
        try:
            while True:
                r, w, e = select.select([self._sock], [], [])
                if not r or not self._sock.recv(1024):
                    break
        except:
            pass
        self._sock.close()

    def run(self):
        """Begin processing data from the socket."""
        self._keepGoing = True
        while self._keepGoing:
            try:
                self.process_input()
            except EOFError:
                break
            except (select.error, socket.error), e:
                if e[0] == errno.EBADF: # Socket was closed by Request.
                    break
                raise

        self._cleanupSocket()

    def process_input(self):
        """Attempt to read a single Record from the socket and process it."""
        # Currently, any children Request threads notify this Connection
        # that it is no longer needed by closing the Connection's socket.
        # We need to put a timeout on select, otherwise we might get
        # stuck in it indefinitely... (I don't like this solution.)
        while self._keepGoing:
            try:
                r, w, e = select.select([self._sock], [], [], 1.0)
            except ValueError:
                # Sigh. ValueError gets thrown sometimes when passing select
                # a closed socket.
                raise EOFError
            if r: break
        if not self._keepGoing:
            return
        rec = Record()
        rec.read(self._sock)

        if rec.type == FCGI_GET_VALUES:
            self._do_get_values(rec)
        elif rec.type == FCGI_BEGIN_REQUEST:
            self._do_begin_request(rec)
        elif rec.type == FCGI_ABORT_REQUEST:
            self._do_abort_request(rec)
        elif rec.type == FCGI_PARAMS:
            self._do_params(rec)
        elif rec.type == FCGI_STDIN:
            self._do_stdin(rec)
        elif rec.type == FCGI_DATA:
            self._do_data(rec)
        elif rec.requestId == FCGI_NULL_REQUEST_ID:
            self._do_unknown_type(rec)
        else:
            # Need to complain about this.
            pass

    def writeRecord(self, rec):
        """
        Write a Record to the socket.
        """
        rec.write(self._sock)

    def end_request(self, req, appStatus=0L,
                    protocolStatus=FCGI_REQUEST_COMPLETE, remove=True):
        """
        End a Request.

        Called by Request objects. An FCGI_END_REQUEST Record is
        sent to the web server. If the web server no longer requires
        the connection, the socket is closed, thereby ending this
        Connection (run() returns).
        """
        rec = Record(FCGI_END_REQUEST, req.requestId)
        rec.contentData = struct.pack(FCGI_EndRequestBody, appStatus,
                                      protocolStatus)
        rec.contentLength = FCGI_EndRequestBody_LEN
        self.writeRecord(rec)

        if remove:
            del self._requests[req.requestId]

        if __debug__: _debug(2, 'end_request: flags = %d' % req.flags)

        if not (req.flags & FCGI_KEEP_CONN) and not self._requests:
            self._cleanupSocket()
            self._keepGoing = False

    def _do_get_values(self, inrec):
        """Handle an FCGI_GET_VALUES request from the web server."""
        outrec = Record(FCGI_GET_VALUES_RESULT)

        pos = 0
        while pos < inrec.contentLength:
            pos, (name, value) = decode_pair(inrec.contentData, pos)
            cap = self.server.capability.get(name)
            if cap is not None:
                outrec.contentData += encode_pair(name, str(cap))

        outrec.contentLength = len(outrec.contentData)
        self.writeRecord(outrec)

    def _do_begin_request(self, inrec):
        """Handle an FCGI_BEGIN_REQUEST from the web server."""
        role, flags = struct.unpack(FCGI_BeginRequestBody, inrec.contentData)

        req = self.server.request_class(self, self._inputStreamClass)
        req.requestId, req.role, req.flags = inrec.requestId, role, flags
        req.aborted = False

        if not self._multiplexed and self._requests:
            # Can't multiplex requests.
            self.end_request(req, 0L, FCGI_CANT_MPX_CONN, remove=False)
        else:
            self._requests[inrec.requestId] = req

    def _do_abort_request(self, inrec):
        """
        Handle an FCGI_ABORT_REQUEST from the web server.

        We just mark a flag in the associated Request.
        """
        req = self._requests.get(inrec.requestId)
        if req is not None:
            req.aborted = True

    def _start_request(self, req):
        """Run the request."""
        # Not multiplexed, so run it inline.
        req.run()

    def _do_params(self, inrec):
        """
        Handle an FCGI_PARAMS Record.

        If the last FCGI_PARAMS Record is received, start the request.
        """
        req = self._requests.get(inrec.requestId)
        if req is not None:
            if inrec.contentLength:
                pos = 0
                while pos < inrec.contentLength:
                    pos, (name, value) = decode_pair(inrec.contentData, pos)
                    req.params[name] = value
            else:
                self._start_request(req)

    def _do_stdin(self, inrec):
        """Handle the FCGI_STDIN stream."""
        req = self._requests.get(inrec.requestId)
        if req is not None:
            req.stdin.add_data(inrec.contentData)

    def _do_data(self, inrec):
        """Handle the FCGI_DATA stream."""
        req = self._requests.get(inrec.requestId)
        if req is not None:
            req.data.add_data(inrec.contentData)

    def _do_unknown_type(self, inrec):
        """Handle an unknown request type. Respond accordingly."""
        outrec = Record(FCGI_UNKNOWN_TYPE)
        outrec.contentData = struct.pack(FCGI_UnknownTypeBody, inrec.type)
        outrec.contentLength = FCGI_UnknownTypeBody_LEN
        self.writeRecord(outrec)

class MultiplexedConnection(Connection):
    """
    A version of Connection capable of handling multiple requests
    simultaneously.
    """
    _multiplexed = True
    _inputStreamClass = MultiplexedInputStream

    def __init__(self, sock, addr, server):
        super(MultiplexedConnection, self).__init__(sock, addr, server)

        # Used to arbitrate access to self._requests.
        lock = threading.RLock()

        # Notification is posted everytime a request completes, allowing us
        # to quit cleanly.
        self._lock = threading.Condition(lock)

    def _cleanupSocket(self):
        # Wait for any outstanding requests before closing the socket.
        self._lock.acquire()
        while self._requests:
            self._lock.wait()
        self._lock.release()

        super(MultiplexedConnection, self)._cleanupSocket()

    def writeRecord(self, rec):
        # Must use locking to prevent intermingling of Records from different
        # threads.
        self._lock.acquire()
        try:
            # Probably faster than calling super. ;)
            rec.write(self._sock)
        finally:
            self._lock.release()

    def end_request(self, req, appStatus=0L,
                    protocolStatus=FCGI_REQUEST_COMPLETE, remove=True):
        self._lock.acquire()
        try:
            super(MultiplexedConnection, self).end_request(req, appStatus,
                                                           protocolStatus,
                                                           remove)
            self._lock.notify()
        finally:
            self._lock.release()

    def _do_begin_request(self, inrec):
        self._lock.acquire()
        try:
            super(MultiplexedConnection, self)._do_begin_request(inrec)
        finally:
            self._lock.release()

    def _do_abort_request(self, inrec):
        self._lock.acquire()
        try:
            super(MultiplexedConnection, self)._do_abort_request(inrec)
        finally:
            self._lock.release()

    def _start_request(self, req):
        thread.start_new_thread(req.run, ())

    def _do_params(self, inrec):
        self._lock.acquire()
        try:
            super(MultiplexedConnection, self)._do_params(inrec)
        finally:
            self._lock.release()

    def _do_stdin(self, inrec):
        self._lock.acquire()
        try:
            super(MultiplexedConnection, self)._do_stdin(inrec)
        finally:
            self._lock.release()

    def _do_data(self, inrec):
        self._lock.acquire()
        try:
            super(MultiplexedConnection, self)._do_data(inrec)
        finally:
            self._lock.release()

class Server(object):
    """
    The FastCGI server.

    Waits for connections from the web server, processing each
    request.

    If run in a normal CGI context, it will instead instantiate a
    CGIRequest and run the handler through there.
    """
    request_class = Request
    cgirequest_class = CGIRequest

    # Limits the size of the InputStream's string buffer to this size + the
    # server's maximum Record size. Since the InputStream is not seekable,
    # we throw away already-read data once this certain amount has been read.
    inputStreamShrinkThreshold = 102400 - 8192

    def __init__(self, handler=None, maxwrite=8192, bindAddress=None,
                 umask=None, multiplexed=False):
        """
        handler, if present, must reference a function or method that
        takes one argument: a Request object. If handler is not
        specified at creation time, Server *must* be subclassed.
        (The handler method below is abstract.)

        maxwrite is the maximum number of bytes (per Record) to write
        to the server. I've noticed mod_fastcgi has a relatively small
        receive buffer (8K or so).

        bindAddress, if present, must either be a string or a 2-tuple. If
        present, run() will open its own listening socket. You would use
        this if you wanted to run your application as an 'external' FastCGI
        app. (i.e. the webserver would no longer be responsible for starting
        your app) If a string, it will be interpreted as a filename and a UNIX
        socket will be opened. If a tuple, the first element, a string,
        is the interface name/IP to bind to, and the second element (an int)
        is the port number.

        Set multiplexed to True if you want to handle multiple requests
        per connection. Some FastCGI backends (namely mod_fastcgi) don't
        multiplex requests at all, so by default this is off (which saves
        on thread creation/locking overhead). If threads aren't available,
        this keyword is ignored; it's not possible to multiplex requests
        at all.
        """
        if handler is not None:
            self.handler = handler
        self.maxwrite = maxwrite
        if thread_available:
            try:
                import resource
                # Attempt to glean the maximum number of connections
                # from the OS.
                maxConns = resource.getrlimit(resource.RLIMIT_NOFILE)[0]
            except (ImportError, AttributeError):
                maxConns = 100 # Just some made up number.
            maxReqs = maxConns
            if multiplexed:
                self._connectionClass = MultiplexedConnection
                maxReqs *= 5 # Another made up number.
            else:
                self._connectionClass = Connection
            self.capability = {
                FCGI_MAX_CONNS: maxConns,
                FCGI_MAX_REQS: maxReqs,
                FCGI_MPXS_CONNS: multiplexed and 1 or 0
                }
        else:
            self._connectionClass = Connection
            self.capability = {
                # If threads aren't available, these are pretty much correct.
                FCGI_MAX_CONNS: 1,
                FCGI_MAX_REQS: 1,
                FCGI_MPXS_CONNS: 0
                }
        self._bindAddress = bindAddress
        self._umask = umask

    def _setupSocket(self):
        if self._bindAddress is None: # Run as a normal FastCGI?
            isFCGI = True

            sock = socket.fromfd(FCGI_LISTENSOCK_FILENO, socket.AF_INET,
                                 socket.SOCK_STREAM)
            try:
                sock.getpeername()
            except socket.error, e:
                if e[0] == errno.ENOTSOCK:
                    # Not a socket, assume CGI context.
                    isFCGI = False
                elif e[0] != errno.ENOTCONN:
                    raise

            # FastCGI/CGI discrimination is broken on Mac OS X.
            # Set the environment variable FCGI_FORCE_CGI to "Y" or "y"
            # if you want to run your app as a simple CGI. (You can do
            # this with Apache's mod_env [not loaded by default in OS X
            # client, ha ha] and the SetEnv directive.)
            if not isFCGI or \
               os.environ.get('FCGI_FORCE_CGI', 'N').upper().startswith('Y'):
                req = self.cgirequest_class(self)
                req.run()
                sys.exit(0)
        else:
            # Run as a server
            oldUmask = None
            if type(self._bindAddress) is str:
                # Unix socket
                sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
                try:
                    os.unlink(self._bindAddress)
                except OSError:
                    pass
                if self._umask is not None:
                    oldUmask = os.umask(self._umask)
            else:
                # INET socket
                assert type(self._bindAddress) is tuple
                assert len(self._bindAddress) == 2
                sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)

            sock.bind(self._bindAddress)
            sock.listen(socket.SOMAXCONN)

            if oldUmask is not None:
                os.umask(oldUmask)

        return sock

    def _cleanupSocket(self, sock):
        """Closes the main socket."""
        sock.close()

    def _installSignalHandlers(self):
        self._oldSIGs = [(x,signal.getsignal(x)) for x in
                         (signal.SIGHUP, signal.SIGINT, signal.SIGTERM)]
        signal.signal(signal.SIGHUP, self._hupHandler)
        signal.signal(signal.SIGINT, self._intHandler)
        signal.signal(signal.SIGTERM, self._intHandler)

    def _restoreSignalHandlers(self):
        for signum,handler in self._oldSIGs:
            signal.signal(signum, handler)

    def _hupHandler(self, signum, frame):
        self._hupReceived = True
        self._keepGoing = False

    def _intHandler(self, signum, frame):
        self._keepGoing = False

    def run(self, timeout=1.0):
        """
        The main loop. Exits on SIGHUP, SIGINT, SIGTERM. Returns True if
        SIGHUP was received, False otherwise.
        """
        web_server_addrs = os.environ.get('FCGI_WEB_SERVER_ADDRS')
        if web_server_addrs is not None:
            web_server_addrs = map(lambda x: x.strip(),
                                   web_server_addrs.split(','))

        sock = self._setupSocket()

        self._keepGoing = True
        self._hupReceived = False

        # Install signal handlers.
        self._installSignalHandlers()

        while self._keepGoing:
            try:
                r, w, e = select.select([sock], [], [], timeout)
            except select.error, e:
                if e[0] == errno.EINTR:
                    continue
                raise

            if r:
                try:
                    clientSock, addr = sock.accept()
                except socket.error, e:
                    if e[0] in (errno.EINTR, errno.EAGAIN):
                        continue
                    raise

                if web_server_addrs and \
                       (len(addr) != 2 or addr[0] not in web_server_addrs):
                    clientSock.close()
                    continue

                # Instantiate a new Connection and begin processing FastCGI
                # messages (either in a new thread or this thread).
                conn = self._connectionClass(clientSock, addr, self)
                thread.start_new_thread(conn.run, ())

            self._mainloopPeriodic()

        # Restore signal handlers.
        self._restoreSignalHandlers()

        self._cleanupSocket(sock)

        return self._hupReceived

    def _mainloopPeriodic(self):
        """
        Called with just about each iteration of the main loop. Meant to
        be overridden.
        """
        pass

    def _exit(self, reload=False):
        """
        Protected convenience method for subclasses to force an exit. Not
        really thread-safe, which is why it isn't public.
        """
        if self._keepGoing:
            self._keepGoing = False
            self._hupReceived = reload

    def handler(self, req):
        """
        Default handler, which just raises an exception. Unless a handler
        is passed at initialization time, this must be implemented by
        a subclass.
        """
        raise NotImplementedError, self.__class__.__name__ + '.handler'

    def error(self, req):
        """
        Called by Request if an exception occurs within the handler. May and
        should be overridden.
        """
        import cgitb
        req.stdout.write('Content-Type: text/html\r\n\r\n' +
                         cgitb.html(sys.exc_info()))

class WSGIServer(Server):
    """
    FastCGI server that supports the Web Server Gateway Interface. See
    <http://www.python.org/peps/pep-0333.html>.
    """
    def __init__(self, application, environ=None,
                 multithreaded=True, **kw):
        """
        environ, if present, must be a dictionary-like object. Its
        contents will be copied into application's environ. Useful
        for passing application-specific variables.

        Set multithreaded to False if your application is not MT-safe.
        """
        if kw.has_key('handler'):
            del kw['handler'] # Doesn't make sense to let this through
        super(WSGIServer, self).__init__(**kw)

        if environ is None:
            environ = {}

        self.application = application
        self.environ = environ
        self.multithreaded = multithreaded

        # Used to force single-threadedness
        self._app_lock = thread.allocate_lock()

    def handler(self, req):
        """Special handler for WSGI."""
        if req.role != FCGI_RESPONDER:
            return FCGI_UNKNOWN_ROLE, 0

        # Mostly taken from example CGI gateway.
        environ = req.params
        environ.update(self.environ)

        environ['wsgi.version'] = (1,0)
        environ['wsgi.input'] = req.stdin
        if self._bindAddress is None:
            stderr = req.stderr
        else:
            stderr = TeeOutputStream((sys.stderr, req.stderr))
        environ['wsgi.errors'] = stderr
        environ['wsgi.multithread'] = not isinstance(req, CGIRequest) and \
                                      thread_available and self.multithreaded
        # Rationale for the following: If started by the web server
        # (self._bindAddress is None) in either FastCGI or CGI mode, the
        # possibility of being spawned multiple times simultaneously is quite
        # real. And, if started as an external server, multiple copies may be
        # spawned for load-balancing/redundancy. (Though I don't think
        # mod_fastcgi supports this?)
        environ['wsgi.multiprocess'] = True
        environ['wsgi.run_once'] = isinstance(req, CGIRequest)

        if environ.get('HTTPS', 'off') in ('on', '1'):
            environ['wsgi.url_scheme'] = 'https'
        else:
            environ['wsgi.url_scheme'] = 'http'

        self._sanitizeEnv(environ)

        headers_set = []
        headers_sent = []
        result = None

        def write(data):
            assert type(data) is str, 'write() argument must be string'
            assert headers_set, 'write() before start_response()'

            if not headers_sent:
                status, responseHeaders = headers_sent[:] = headers_set
                found = False
                for header,value in responseHeaders:
                    if header.lower() == 'content-length':
                        found = True
                        break
                if not found and result is not None:
                    try:
                        if len(result) == 1:
                            responseHeaders.append(('Content-Length',
                                                    str(len(data))))
                    except:
                        pass
                s = 'Status: %s\r\n' % status
                for header in responseHeaders:
                    s += '%s: %s\r\n' % header
                s += '\r\n'
                req.stdout.write(s)

            req.stdout.write(data)
            req.stdout.flush()

        def start_response(status, response_headers, exc_info=None):
            if exc_info:
                try:
                    if headers_sent:
                        # Re-raise if too late
                        raise exc_info[0], exc_info[1], exc_info[2]
                finally:
                    exc_info = None # avoid dangling circular ref
            else:
                assert not headers_set, 'Headers already set!'

            assert type(status) is str, 'Status must be a string'
            assert len(status) >= 4, 'Status must be at least 4 characters'
            assert int(status[:3]), 'Status must begin with 3-digit code'
            assert status[3] == ' ', 'Status must have a space after code'
            assert type(response_headers) is list, 'Headers must be a list'
            if __debug__:
                for name,val in response_headers:
                    assert type(name) is str, 'Header names must be strings'
                    assert type(val) is str, 'Header values must be strings'

            headers_set[:] = [status, response_headers]
            return write

        if not self.multithreaded:
            self._app_lock.acquire()
        try:
            try:
                result = self.application(environ, start_response)
                try:
                    for data in result:
                        if data:
                            write(data)
                    if not headers_sent:
                        write('') # in case body was empty
                finally:
                    if hasattr(result, 'close'):
                        result.close()
            except socket.error, e:
                if e[0] != errno.EPIPE:
                    raise # Don't let EPIPE propagate beyond server
        finally:
            if not self.multithreaded:
                self._app_lock.release()

        return FCGI_REQUEST_COMPLETE, 0

    def _sanitizeEnv(self, environ):
        """Ensure certain values are present, if required by WSGI."""
        if not environ.has_key('SCRIPT_NAME'):
            environ['SCRIPT_NAME'] = ''
        if not environ.has_key('PATH_INFO'):
            environ['PATH_INFO'] = ''

        # If any of these are missing, it probably signifies a broken
        # server...
        for name,default in [('REQUEST_METHOD', 'GET'),
                             ('SERVER_NAME', 'localhost'),
                             ('SERVER_PORT', '80'),
                             ('SERVER_PROTOCOL', 'HTTP/1.0')]:
            if not environ.has_key(name):
                environ['wsgi.errors'].write('%s: missing FastCGI param %s '
                                             'required by WSGI!\n' %
                                             (self.__class__.__name__, name))
                environ[name] = default

if __name__ == '__main__':
    def test_app(environ, start_response):
        """Probably not the most efficient example."""
        import cgi
        start_response('200 OK', [('Content-Type', 'text/html')])
        yield '<html><head><title>Hello World!</title></head>\n' \
              '<body>\n' \
              '<p>Hello World!</p>\n' \
              '<table border="1">'
        names = environ.keys()
        names.sort()
        for name in names:
            yield '<tr><td>%s</td><td>%s</td></tr>\n' % (
                name, cgi.escape(`environ[name]`))

        form = cgi.FieldStorage(fp=environ['wsgi.input'], environ=environ,
                                keep_blank_values=1)
        if form.list:
            yield '<tr><th colspan="2">Form data</th></tr>'

        for field in form.list:
            yield '<tr><td>%s</td><td>%s</td></tr>\n' % (
                field.name, field.value)

        yield '</table>\n' \
              '</body></html>\n'

    WSGIServer(test_app).run()

########NEW FILE########
__FILENAME__ = admin
# -*- coding: utf-8 -*-
#
# Copyright (C) 2008 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.com/license.html.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/.

from __future__ import with_statement

from datetime import datetime
import os.path
import pkg_resources
import sys

from trac.admin import *
from trac.core import *
from trac.wiki import model
from trac.wiki.api import WikiSystem, validate_page_name
from trac.util import read_file
from trac.util.datefmt import format_datetime, from_utimestamp, \
                              to_utimestamp, utc
from trac.util.text import path_to_unicode, print_table, printout, \
                           to_unicode, unicode_quote, unicode_unquote
from trac.util.translation import _


class WikiAdmin(Component):
    """trac-admin command provider for wiki administration."""

    implements(IAdminCommandProvider)

    # IAdminCommandProvider methods

    def get_admin_commands(self):
        yield ('wiki list', '',
               'List wiki pages',
               None, self._do_list)
        yield ('wiki rename', '<page> <new_name>',
               'Rename wiki page',
               self._complete_page, self._do_rename)
        yield ('wiki remove', '<page>',
               'Remove wiki page',
               self._complete_page, self._do_remove)
        yield ('wiki export', '<page> [file]',
               'Export wiki page to file or stdout',
               self._complete_import_export, self._do_export)
        yield ('wiki import', '<page> [file]',
               'Import wiki page from file or stdin',
               self._complete_import_export, self._do_import)
        yield ('wiki dump', '<directory> [page] [...]',
               """Export wiki pages to files named by title

               Individual wiki page names can be specified after the directory.
               A name ending with a * means that all wiki pages starting with
               that prefix should be dumped. If no name is specified, all wiki
               pages are dumped.""",
               self._complete_dump, self._do_dump)
        yield ('wiki load', '<path> [...]',
               """Import wiki pages from files

               If a given path is a file, it is imported as a page with the
               name of the file. If a path is a directory, all files in that
               directory are imported.""",
               self._complete_load_replace, self._do_load)
        yield ('wiki replace', '<path> [...]',
               """Replace the content of wiki pages from files (DANGEROUS!)

               This command replaces the content of the last version of one
               or more wiki pages with new content. The previous content is
               lost, and no new entry is created in the page history. The
               metadata of the page (time, author) is not changed either.

               If a given path is a file, it is imported as a page with the
               name of the file. If a path is a directory, all files in that
               directory are imported.

               WARNING: This operation results in the loss of the previous
               content and cannot be undone. It may be advisable to backup
               the current content using "wiki dump" beforehand.""",
               self._complete_load_replace, self._do_replace)
        yield ('wiki upgrade', '',
               'Upgrade default wiki pages to current version',
               None, self._do_upgrade)

    def get_wiki_list(self):
        return list(WikiSystem(self.env).get_pages())

    def export_page(self, page, filename, cursor=None):
        """
        :since 1.0: the `cursor` parameter is no longer needed and will be
        removed in version 1.1.1
        """
        for text, in self.env.db_query("""
                SELECT text FROM wiki WHERE name=%s
                ORDER BY version DESC LIMIT 1
                """, (page,)):
            if not filename:
                printout(text)
            else:
                if os.path.isfile(filename):
                    raise AdminCommandError(_("File '%(name)s' exists",
                                              name=path_to_unicode(filename)))
                with open(filename, 'w') as f:
                    f.write(text.encode('utf-8'))
            break
        else:
            raise AdminCommandError(_("Page '%(page)s' not found", page=page))

    def import_page(self, filename, title, create_only=[],
                    replace=False):
        if not validate_page_name(title):
            raise AdminCommandError(_("Invalid Wiki page name '%(name)s'",
                                      name=title))
        if filename:
            if not os.path.isfile(filename):
                raise AdminCommandError(_("'%(name)s' is not a file",
                                          name=path_to_unicode(filename)))
            data = read_file(filename)
        else:
            data = sys.stdin.read()
        data = to_unicode(data, 'utf-8')

        with self.env.db_transaction as db:
            # Make sure we don't insert the exact same page twice
            old = db("""SELECT text FROM wiki WHERE name=%s
                        ORDER BY version DESC LIMIT 1
                        """, (title,))
            if old and title in create_only:
                printout(_("  %(title)s already exists", title=title))
                return False
            if old and data == old[0][0]:
                printout(_("  %(title)s is already up to date", title=title))
                return False

            if replace and old:
                db("""UPDATE wiki SET text=%s
                      WHERE name=%s
                        AND version=(SELECT max(version) FROM wiki
                                     WHERE name=%s)
                      """, (data, title, title))
            else:
                db("""INSERT INTO wiki(version, name, time, author, ipnr, text)
                      SELECT 1 + COALESCE(max(version), 0), %s, %s, 'trac',
                             '127.0.0.1', %s FROM wiki WHERE name=%s
                      """, (title, to_utimestamp(datetime.now(utc)), data,
                            title))
            if not old:
                del WikiSystem(self.env).pages
        return True

    def load_pages(self, dir, ignore=[], create_only=[], replace=False):
        with self.env.db_transaction:
            for page in os.listdir(dir):
                if page in ignore:
                    continue
                filename = os.path.join(dir, page)
                page = unicode_unquote(page.encode('utf-8'))
                if os.path.isfile(filename):
                    if self.import_page(filename, page, create_only, replace):
                        printout(_("  %(page)s imported from %(filename)s",
                                   filename=path_to_unicode(filename),
                                   page=page))

    def _complete_page(self, args):
        if len(args) == 1:
            return self.get_wiki_list()

    def _complete_import_export(self, args):
        if len(args) == 1:
            return self.get_wiki_list()
        elif len(args) == 2:
            return get_dir_list(args[-1])

    def _complete_dump(self, args):
        if len(args) == 1:
            return get_dir_list(args[-1], dirs_only=True)
        elif len(args) >= 2:
            return self.get_wiki_list()

    def _complete_load_replace(self, args):
        if len(args) >= 1:
            return get_dir_list(args[-1])

    def _do_list(self):
        print_table(
            [(title, int(edits), format_datetime(from_utimestamp(modified),
                                                 console_datetime_format))
             for title, edits, modified in self.env.db_query("""
                    SELECT name, max(version), max(time)
                    FROM wiki GROUP BY name ORDER BY name""")
             ], [_("Title"), _("Edits"), _("Modified")])

    def _do_rename(self, name, new_name):
        if new_name == name:
            return
        if not new_name:
            raise AdminCommandError(_("A new name is mandatory for a rename."))
        if not validate_page_name(new_name):
            raise AdminCommandError(_("The new name is invalid."))
        with self.env.db_transaction:
            if model.WikiPage(self.env, new_name).exists:
                raise AdminCommandError(_("The page %(name)s already exists.",
                                          name=new_name))
            page = model.WikiPage(self.env, name)
            page.rename(new_name)

    def _do_remove(self, name):
        with self.env.db_transaction:
            if name.endswith('*'):
                pages = list(WikiSystem(self.env).get_pages(name.rstrip('*')
                                                            or None))
                for p in pages:
                    page = model.WikiPage(self.env, p)
                    page.delete()
                print_table(((p,) for p in pages), [_('Deleted pages')])
            else:
                page = model.WikiPage(self.env, name)
                page.delete()

    def _do_export(self, page, filename=None):
        self.export_page(page, filename)

    def _do_import(self, page, filename=None):
        self.import_page(filename, page)

    def _do_dump(self, directory, *names):
        if not names:
            names = ['*']
        pages = self.get_wiki_list()
        if not os.path.isdir(directory):
            if not os.path.exists(directory):
                os.mkdir(directory)
            else:
                raise AdminCommandError(_("'%(name)s' is not a directory",
                                          name=path_to_unicode(directory)))
        for p in pages:
            if any(p == name or (name.endswith('*')
                                 and p.startswith(name[:-1]))
                   for name in names):
                dst = os.path.join(directory, unicode_quote(p, ''))
                printout(' %s => %s' % (p, dst))
                self.export_page(p, dst)

    def _load_or_replace(self, paths, replace):
        with self.env.db_transaction:
            for path in paths:
                if os.path.isdir(path):
                    self.load_pages(path, replace=replace)
                else:
                    page = os.path.basename(path)
                    page = unicode_unquote(page.encode('utf-8'))
                    if self.import_page(path, page, replace=replace):
                        printout(_("  %(page)s imported from %(filename)s",
                                   filename=path_to_unicode(path), page=page))

    def _do_load(self, *paths):
        self._load_or_replace(paths, replace=False)

    def _do_replace(self, *paths):
        self._load_or_replace(paths, replace=True)

    def _do_upgrade(self):
        self.load_pages(pkg_resources.resource_filename('trac.wiki',
                                                        'default-pages'),
                        ignore=['WikiStart', 'checkwiki.py'],
                        create_only=['InterMapTxt'])

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

import re

from genshi.builder import tag

from trac.cache import cached
from trac.config import BoolOption, ListOption
from trac.core import *
from trac.resource import IResourceManager
from trac.util.text import unquote_label
from trac.util.translation import _

from .parser import WikiParser


class IWikiChangeListener(Interface):
    """Components that want to get notified about the creation,
    deletion and modification of wiki pages should implement that
    interface.
    """

    def wiki_page_added(page):
        """Called whenever a new Wiki page is added."""

    def wiki_page_changed(page, version, t, comment, author, ipnr):
        """Called when a page has been modified."""

    def wiki_page_deleted(page):
        """Called when a page has been deleted."""

    def wiki_page_version_deleted(page):
        """Called when a version of a page has been deleted."""

    def wiki_page_renamed(page, old_name):
        """Called when a page has been renamed."""


class IWikiPageManipulator(Interface):
    """Components that need to do specific pre- and post- processing of
    wiki page changes have to implement this interface.

    Unlike change listeners, a manipulator can reject changes being
    committed to the database.
    """

    def prepare_wiki_page(req, page, fields):
        """Validate a wiki page before rendering it.

        :param page: is the `WikiPage` being viewed.

        :param fields: is a dictionary which contains the wiki `text`
          of the page, initially identical to `page.text` but it can
          eventually be transformed in place before being used as
          input to the formatter.
        """

    def validate_wiki_page(req, page):
        """Validate a wiki page after it's been populated from user input.

        :param page: is the `WikiPage` being edited.

        :return: a list of `(field, message)` tuples, one for each
          problem detected. `field` can be `None` to indicate an
          overall problem with the page. Therefore, a return value of
          `[]` means everything is OK.
        """


class IWikiMacroProvider(Interface):
    """Augment the Wiki markup with new Wiki macros.

    .. versionchanged :: 0.12
       new Wiki processors can also be added that way.
    """

    def get_macros():
        """Return an iterable that provides the names of the provided macros.
        """

    def get_macro_description(name):
        """Return a tuple of a domain name to translate and plain text
        description of the macro or only the description with the specified
        name.

        .. versionchanged :: 1.0
           `get_macro_description` can return a domain to translate the
           description.
        """

    def render_macro(req, name, content):
        """Return the HTML output of the macro :deprecated:"""

    def is_inline(content):
        """Return `True` if the content generated is an inline XHTML element.

        .. versionadded :: 1.0
        """

    def expand_macro(formatter, name, content, args=None):
        """Called by the formatter when rendering the parsed wiki text.

        .. versionadded:: 0.11
          This form is preferred over `render_macro`, as
          you get the `formatter`, which knows the current `.context`
          (and the `.req`, but ideally you shouldn't use it in your
          macros).
        .. versionchanged:: 0.12
           added the `args` parameter

        :param formatter: the wiki `Formatter` currently processing
          the wiki markup

        :param name: is the name by which the macro has been called;
          remember that via `get_macros`, multiple names could be
          associated to this macros. Note that the macro names are
          case sensitive.

        :param content: is the content of the macro call. When called
          using macro syntax (`[[Macro(content)]]`), this is the
          string contained between parentheses, usually containing
          macro arguments. When called using wiki processor syntax
          (`{{{!#Macro ...}}}`), it is the content of the processor
          block, that is, the text starting on the line following the
          macro name.

        :param args: will be a dictionary containing the named
          parameters passed when using the Wiki processor syntax.

          The named parameters can be specified when calling the macro
          using the wiki processor syntax::

            {{{#!Macro arg1=value1 arg2="value 2"`
            ... some content ...
            }}}

          In this example, `args` will be
          `{'arg1': 'value1', 'arg2': 'value 2'}`
          and `content` will be `"... some content ..."`.

          If no named parameters are given like in::

            {{{#!Macro
            ...
            }}}

          then `args` will be `{}`. That makes it possible to
          differentiate the above situation from a call
          made using the macro syntax::

             [[Macro(arg1=value1, arg2="value 2", ... some content...)]]

          in which case `args` will always be `None`.  Here `content`
          will be the
          `"arg1=value1, arg2="value 2", ... some content..."` string.
          If like in this example, `content` is expected to contain
          some arguments and named parameters, one can use the
          `parse_args` function to conveniently extract them.
        """


class IWikiSyntaxProvider(Interface):
    """Enrich the Wiki syntax with new markup."""

    def get_wiki_syntax():
        """Return an iterable that provides additional wiki syntax.

        Additional wiki syntax correspond to a pair of `(regexp, cb)`,
        the `regexp` for the additional syntax and the callback `cb`
        which will be called if there's a match.  That function is of
        the form `cb(formatter, ns, match)`.
        """

    def get_link_resolvers():
        """Return an iterable over `(namespace, formatter)` tuples.

        Each formatter should be a function of the form::

          def format(formatter, ns, target, label, fullmatch=None):
              pass

        and should return some HTML fragment. The `label` is already
        HTML escaped, whereas the `target` is not. The `fullmatch`
        argument is optional, and is bound to the regexp match object
        for the link.
        """


def parse_args(args, strict=True):
    """Utility for parsing macro "content" and splitting them into arguments.

    The content is split along commas, unless they are escaped with a
    backquote (see example below).

    :param args: a string containing macros arguments
    :param strict: if `True`, only Python-like identifiers will be
                   recognized as keyword arguments

    Example usage::

      >>> parse_args('')
      ([], {})
      >>> parse_args('Some text')
      (['Some text'], {})
      >>> parse_args('Some text, mode= 3, some other arg\, with a comma.')
      (['Some text', ' some other arg, with a comma.'], {'mode': ' 3'})
      >>> parse_args('milestone=milestone1,status!=closed', strict=False)
      ([], {'status!': 'closed', 'milestone': 'milestone1'})

    """
    largs, kwargs = [], {}
    if args:
        for arg in re.split(r'(?<!\\),', args):
            arg = arg.replace(r'\,', ',')
            if strict:
                m = re.match(r'\s*[a-zA-Z_]\w+=', arg)
            else:
                m = re.match(r'\s*[^=]+=', arg)
            if m:
                kw = arg[:m.end()-1].strip()
                if strict:
                    kw = unicode(kw).encode('utf-8')
                kwargs[kw] = arg[m.end():]
            else:
                largs.append(arg)
    return largs, kwargs


def validate_page_name(pagename):
    """Utility for validating wiki page name.

    :param pagename: wiki page name to validate
    """
    return pagename and \
           all(part not in ('', '.', '..') for part in pagename.split('/'))


class WikiSystem(Component):
    """Wiki system manager."""

    implements(IWikiSyntaxProvider, IResourceManager)

    change_listeners = ExtensionPoint(IWikiChangeListener)
    macro_providers = ExtensionPoint(IWikiMacroProvider)
    syntax_providers = ExtensionPoint(IWikiSyntaxProvider)

    ignore_missing_pages = BoolOption('wiki', 'ignore_missing_pages', 'false',
        """Enable/disable highlighting CamelCase links to missing pages
        (''since 0.9'').""")

    split_page_names = BoolOption('wiki', 'split_page_names', 'false',
        """Enable/disable splitting the WikiPageNames with space characters
        (''since 0.10'').""")

    render_unsafe_content = BoolOption('wiki', 'render_unsafe_content', 'false',
        """Enable/disable the use of unsafe HTML tags such as `<script>` or
        `<embed>` with the HTML [wiki:WikiProcessors WikiProcessor]
        (''since 0.10.4'').

        For public sites where anonymous users can edit the wiki it is
        recommended to leave this option disabled (which is the default).""")

    safe_schemes = ListOption('wiki', 'safe_schemes',
        'cvs, file, ftp, git, irc, http, https, news, sftp, smb, ssh, svn, '
        'svn+ssh',
        doc="""List of URI schemes considered "safe", that will be rendered as
        external links even if `[wiki] render_unsafe_content` is `false`.
        (''since 0.11.8'')""")

    @cached
    def pages(self):
        """Return the names of all existing wiki pages."""
        return set(name for name, in
                   self.env.db_query("SELECT DISTINCT name FROM wiki"))

    # Public API

    def get_pages(self, prefix=None):
        """Iterate over the names of existing Wiki pages.

        :param prefix: if given, only names that start with that
          prefix are included.
        """
        for page in self.pages:
            if not prefix or page.startswith(prefix):
                yield page

    def has_page(self, pagename):
        """Whether a page with the specified name exists."""
        return pagename.rstrip('/') in self.pages

    # IWikiSyntaxProvider methods

    XML_NAME = r"[\w:](?<!\d)(?:[\w:.-]*[\w-])?"
    # See http://www.w3.org/TR/REC-xml/#id,
    # here adapted to exclude terminal "." and ":" characters

    PAGE_SPLIT_RE = re.compile(r"([a-z])([A-Z])(?=[a-z])")

    Lu = ''.join(unichr(c) for c in range(0, 0x10000) if unichr(c).isupper())
    Ll = ''.join(unichr(c) for c in range(0, 0x10000) if unichr(c).islower())

    def format_page_name(self, page, split=False):
        if split or self.split_page_names:
            return self.PAGE_SPLIT_RE.sub(r"\1 \2", page)
        return page

    def make_label_from_target(self, target):
        """Create a label from a wiki target.

        A trailing fragment and query string is stripped. Then, leading ./,
        ../ and / elements are stripped, except when this would lead to an
        empty label. Finally, if `split_page_names` is true, the label
        is split accordingly.
        """
        label = target.split('#', 1)[0].split('?', 1)[0]
        if not label:
            return target
        components = label.split('/')
        for i, comp in enumerate(components):
            if comp not in ('', '.', '..'):
                label = '/'.join(components[i:])
                break
        return self.format_page_name(label)

    def get_wiki_syntax(self):
        wiki_page_name = (
            r"(?:[%(upper)s](?:[%(lower)s])+/?){2,}" # wiki words
            r"(?:@[0-9]+)?"                          # optional version
            r"(?:#%(xml)s)?"                         # optional fragment id
            r"(?=:(?:\Z|\s)|[^:\w%(upper)s%(lower)s]|\s|\Z)"
            # what should follow it
            % {'upper': self.Lu, 'lower': self.Ll, 'xml': self.XML_NAME})

        # Regular WikiPageNames
        def wikipagename_link(formatter, match, fullmatch):
            return self._format_link(formatter, 'wiki', match,
                                     self.format_page_name(match),
                                     self.ignore_missing_pages, match)

        # Start after any non-word char except '/', with optional relative or
        # absolute prefix
        yield (r"!?(?<![\w/])(?:\.?\.?/)*"
               + wiki_page_name, wikipagename_link)

        # [WikiPageNames with label]
        def wikipagename_with_label_link(formatter, match, fullmatch):
            page = fullmatch.group('wiki_page')
            label = fullmatch.group('wiki_label')
            return self._format_link(formatter, 'wiki', page, label.strip(),
                                     self.ignore_missing_pages, match)
        yield (r"!?\[(?P<wiki_page>%s)\s+(?P<wiki_label>%s|[^\]]+)\]"
               % (wiki_page_name, WikiParser.QUOTED_STRING),
               wikipagename_with_label_link)

        # MoinMoin's ["internal free link"] and ["free link" with label]
        def internal_free_link(fmt, m, fullmatch):
            page = fullmatch.group('ifl_page')[1:-1]
            label = fullmatch.group('ifl_label')
            if label is None:
                label = self.make_label_from_target(page)
            return self._format_link(fmt, 'wiki', page, label.strip(), False)
        yield (r"!?\[(?P<ifl_page>%s)(?:\s+(?P<ifl_label>%s|[^\]]+))?\]"
               % (WikiParser.QUOTED_STRING, WikiParser.QUOTED_STRING),
               internal_free_link)

    def get_link_resolvers(self):
        def link_resolver(formatter, ns, target, label, fullmatch=None):
            if fullmatch is not None:
                # If no explicit label was specified for a [wiki:...] link,
                # generate a "nice" label instead of keeping the label
                # generated by the Formatter (usually the target itself).
                groups = fullmatch.groupdict()
                if groups.get('lns') and not groups.get('label'):
                    label = self.make_label_from_target(target)
            return self._format_link(formatter, ns, target, label, False)
        yield ('wiki', link_resolver)

    def _format_link(self, formatter, ns, pagename, label, ignore_missing,
                     original_label=None):
        pagename, query, fragment = formatter.split_link(pagename)
        version = None
        if '@' in pagename:
            pagename, version = pagename.split('@', 1)
        if version and query:
            query = '&' + query[1:]
        pagename = pagename.rstrip('/') or 'WikiStart'
        referrer = ''
        if formatter.resource and formatter.resource.realm == 'wiki':
            referrer = formatter.resource.id
        if pagename.startswith('/'):
            pagename = pagename.lstrip('/')
        elif pagename.startswith(('./', '../')) or pagename in ('.', '..'):
            pagename = self._resolve_relative_name(pagename, referrer)
        else:
            pagename = self._resolve_scoped_name(pagename, referrer)
        label = unquote_label(label)
        if 'WIKI_VIEW' in formatter.perm('wiki', pagename, version):
            href = formatter.href.wiki(pagename, version=version) + query \
                   + fragment
            if self.has_page(pagename):
                return tag.a(label, href=href, class_='wiki')
            else:
                if ignore_missing:
                    return original_label or label
                if 'WIKI_CREATE' in formatter.perm('wiki', pagename, version):
                    return tag.a(label + '?', class_='missing wiki',
                                 href=href, rel='nofollow')
                else:
                    return tag.a(label + '?', class_='missing wiki')
        elif ignore_missing and not self.has_page(pagename):
            return original_label or label
        else:
            return tag.a(label, class_='forbidden wiki',
                         title=_("no permission to view this wiki page"))

    def _resolve_relative_name(self, pagename, referrer):
        base = referrer.split('/')
        components = pagename.split('/')
        for i, comp in enumerate(components):
            if comp == '..':
                if base:
                    base.pop()
            elif comp and comp != '.':
                base.extend(components[i:])
                break
        return '/'.join(base)

    def _resolve_scoped_name(self, pagename, referrer):
        referrer = referrer.split('/')
        if len(referrer) == 1:           # Non-hierarchical referrer
            return pagename
        # Test for pages with same name, higher in the hierarchy
        for i in range(len(referrer) - 1, 0, -1):
            name = '/'.join(referrer[:i]) + '/' + pagename
            if self.has_page(name):
                return name
        if self.has_page(pagename):
            return pagename
        # If we are on First/Second/Third, and pagename is Second/Other,
        # resolve to First/Second/Other instead of First/Second/Second/Other
        # See http://trac.edgewall.org/ticket/4507#comment:12
        if '/' in pagename:
            (first, rest) = pagename.split('/', 1)
            for (i, part) in enumerate(referrer):
                if first == part:
                    anchor = '/'.join(referrer[:i + 1])
                    if self.has_page(anchor):
                        return anchor + '/' + rest
        # Assume the user wants a sibling of referrer
        return '/'.join(referrer[:-1]) + '/' + pagename

    # IResourceManager methods

    def get_resource_realms(self):
        yield 'wiki'

    def get_resource_description(self, resource, format, **kwargs):
        """
        >>> from trac.test import EnvironmentStub
        >>> from trac.resource import Resource, get_resource_description
        >>> env = EnvironmentStub()
        >>> main = Resource('wiki', 'WikiStart')
        >>> get_resource_description(env, main)
        'WikiStart'

        >>> get_resource_description(env, main(version=3))
        'WikiStart'

        >>> get_resource_description(env, main(version=3), format='summary')
        'WikiStart'

        >>> env.config['wiki'].set('split_page_names', 'true')
        >>> get_resource_description(env, main(version=3))
        'Wiki Start'
        """
        return self.format_page_name(resource.id)

    def resource_exists(self, resource):
        """
        >>> from trac.test import EnvironmentStub
        >>> from trac.resource import Resource, resource_exists
        >>> env = EnvironmentStub()

        >>> resource_exists(env, Resource('wiki', 'WikiStart'))
        False

        >>> from trac.wiki.model import WikiPage
        >>> main = WikiPage(env, 'WikiStart')
        >>> main.text = 'some content'
        >>> main.save('author', 'no comment', '::1')
        >>> resource_exists(env, main.resource)
        True
        """
        if resource.version is None:
            return resource.id in self.pages
        return bool(self.env.db_query(
            "SELECT name FROM wiki WHERE name=%s AND version=%s",
            (resource.id, resource.version)))

########NEW FILE########
__FILENAME__ = formatter
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>
#         Christian Boos <cboos@edgewall.org>

import re
import os

from StringIO import StringIO

from genshi.builder import tag, Element
from genshi.core import Stream, Markup, escape
from genshi.input import HTMLParser, ParseError
from genshi.util import plaintext

from trac.core import *
from trac.mimeview import *
from trac.resource import get_relative_resource, get_resource_url
from trac.util import arity
from trac.util.text import exception_to_unicode, shorten_line, to_unicode, \
                           unicode_quote, unicode_quote_plus, unquote_label
from trac.util.html import TracHTMLSanitizer
from trac.util.translation import _
from trac.wiki.api import WikiSystem, parse_args
from trac.wiki.parser import WikiParser, parse_processor_args

__all__ = ['wiki_to_html', 'wiki_to_oneliner', 'wiki_to_outline',
           'Formatter', 'format_to', 'format_to_html', 'format_to_oneliner',
           'extract_link', 'split_url_into_path_query_fragment',
           'concat_path_query_fragment']


def system_message(msg, text=None):
    return tag.div(tag.strong(msg), text and tag.pre(text),
                   class_="system-message")


def split_url_into_path_query_fragment(target):
    """Split a target along `?` and `#` in `(path, query, fragment)`.

    >>> split_url_into_path_query_fragment('http://path?a=1&b=2#frag?ment')
    ('http://path', '?a=1&b=2', '#frag?ment')
    >>> split_url_into_path_query_fragment('http://path#frag?ment')
    ('http://path', '', '#frag?ment')
    >>> split_url_into_path_query_fragment('http://path?a=1&b=2')
    ('http://path', '?a=1&b=2', '')
    >>> split_url_into_path_query_fragment('http://path')
    ('http://path', '', '')
    """
    query = fragment = ''
    idx = target.find('#')
    if idx >= 0:
        target, fragment = target[:idx], target[idx:]
    idx = target.find('?')
    if idx >= 0:
        target, query = target[:idx], target[idx:]
    return (target, query, fragment)

def concat_path_query_fragment(path, query, fragment=None):
    """Assemble `path`, `query` and `fragment` into a proper URL.

    Can be used to re-assemble an URL decomposed using
    `split_url_into_path_query_fragment` after modification.

    >>> concat_path_query_fragment('/wiki/page', '?version=1')
    '/wiki/page?version=1'
    >>> concat_path_query_fragment('/wiki/page#a', '?version=1', '#b')
    '/wiki/page?version=1#b'
    >>> concat_path_query_fragment('/wiki/page?version=1#a', '?format=txt')
    '/wiki/page?version=1&format=txt#a'
    >>> concat_path_query_fragment('/wiki/page?version=1', '&format=txt')
    '/wiki/page?version=1&format=txt'
    >>> concat_path_query_fragment('/wiki/page?version=1', 'format=txt')
    '/wiki/page?version=1&format=txt'
    >>> concat_path_query_fragment('/wiki/page?version=1#a', '?format=txt', '#')
    '/wiki/page?version=1&format=txt'
    """
    p, q, f = split_url_into_path_query_fragment(path)
    if query:
        q += ('&' if q else '?') + query.lstrip('?&')
    if fragment:
        f = fragment
    return p + q + ('' if f == '#' else f)

def _markup_to_unicode(markup):
    stream = None
    if isinstance(markup, Element):
        stream = markup.generate()
    elif isinstance(markup, Stream):
        stream = markup
    if stream:
        markup = stream.render('xhtml', encoding=None, strip_whitespace=False)
    return to_unicode(markup)


class ProcessorError(TracError):
    pass


class WikiProcessor(object):

    _code_block_re = re.compile('^<div(?:\s+class="([^"]+)")?>(.*)</div>$')
    _block_elem_re = re.compile(r'^\s*<(?:div|table)(?:\s+[^>]+)?>',
                                re.I | re.M)

    def __init__(self, formatter, name, args=None):
        """Find the processor by name

        :param formatter: the formatter embedding a call for this processor
        :param name: the name of the processor
        :param args: extra parameters for the processor

        (since 0.11)
        """
        self.formatter = formatter
        self.env = formatter.env
        self.name = name
        self.args = args
        self.error = None
        self.macro_provider = None

        # FIXME: move these tables outside of __init__
        builtin_processors = {'html': self._html_processor,
                              'htmlcomment': self._htmlcomment_processor,
                              'default': self._default_processor,
                              'comment': self._comment_processor,
                              'div': self._div_processor,
                              'rtl': self._rtl_processor,
                              'span': self._span_processor,
                              'Span': self._span_processor,
                              'td': self._td_processor,
                              'th': self._th_processor,
                              'tr': self._tr_processor,
                              'table': self._table_processor,
                              }

        self.inline_check = {'html': self._html_is_inline,
                                'htmlcomment': True, 'comment': True,
                                'span': True, 'Span': True,
                                }.get(name)

        self._sanitizer = TracHTMLSanitizer(formatter.wiki.safe_schemes)

        self.processor = builtin_processors.get(name)
        if not self.processor:
            # Find a matching wiki macro
            for macro_provider in WikiSystem(self.env).macro_providers:
                for macro_name in macro_provider.get_macros() or []:
                    if self.name == macro_name:
                        if hasattr(macro_provider, 'expand_macro'):
                            self.processor = self._macro_processor
                        else:
                            self.processor = self._legacy_macro_processor
                        self.macro_provider = macro_provider
                        self.inline_check = getattr(macro_provider, 'is_inline',
                                                    False)
                        break
        if not self.processor:
            # Find a matching mimeview renderer
            from trac.mimeview.api import Mimeview
            mimeview = Mimeview(formatter.env)
            for renderer in mimeview.renderers:
                if renderer.get_quality_ratio(self.name) > 1:
                    self.processor = self._mimeview_processor
                    break
            if not self.processor:
                mimetype = mimeview.get_mimetype(self.name)
                if mimetype:
                    self.name = mimetype
                    self.processor = self._mimeview_processor
        if not self.processor:
            self.processor = self._default_processor
            self.error = "No macro or processor named '%s' found" % name

    # inline checks

    def _html_is_inline(self, text):
        if text:
            tag = text[1:].lstrip()
            idx = tag.find(' ')
            if idx > -1:
                tag = tag[:idx]
            return tag.lower() in ('a', 'span', 'bdo', 'img',
                                   'big', 'small', 'font',
                                   'tt', 'i', 'b', 'u', 's', 'strike',
                                   'em', 'strong', 'dfn', 'code', 'q',
                                   'samp', 'kbd', 'var', 'cite', 'abbr',
                                   'acronym', 'sub', 'sup')
    # builtin processors

    def _comment_processor(self, text):
        return ''

    def _default_processor(self, text):
        return tag.pre(text, class_="wiki")

    def _html_processor(self, text):
        if WikiSystem(self.env).render_unsafe_content:
            return Markup(text)
        try:
            stream = Stream(HTMLParser(StringIO(text)))
            return (stream | self._sanitizer).render('xhtml', encoding=None)
        except ParseError, e:
            self.env.log.warn(e)
            line = unicode(text).splitlines()[e.lineno - 1].strip()
            return system_message(_('HTML parsing error: %(message)s',
                                    message=escape(e.msg)), line)

    def _htmlcomment_processor(self, text):
        if "--" in text:
            return system_message(_('Error: Forbidden character sequence '
                                    '"--" in htmlcomment wiki code block'))
        return Markup('<!--\n%s-->\n' % text)

    def _elt_processor(self, eltname, format_to, text):
        # Note: as long as _processor_param_re is not re.UNICODE, **args is OK.
        # Also, parse_args is using strict mode when processing [[span(...)]].
        elt = getattr(tag, eltname)(**(self.args or {}))
        if not WikiSystem(self.env).render_unsafe_content:
            sanitized_elt = getattr(tag, eltname)
            for (k, data, pos) in (Stream(elt) | self._sanitizer):
                sanitized_elt.attrib = data[1]
                break # only look at START (elt,attrs)
            elt = sanitized_elt
        elt.append(format_to(self.env, self.formatter.context, text))
        return elt

    def _div_processor(self, text):
        if not self.args:
            self.args = {}
        self.args.setdefault('class', 'wikipage')
        return self._elt_processor('div', format_to_html, text)

    def _rtl_processor(self, text):
        if not self.args:
            self.args = {}
        self.args['class'] = ('rtl ' + self.args.get('class', '')).rstrip()
        return self._elt_processor('div', format_to_html, text)

    def _span_processor(self, text):
        if self.args is None:
            args, self.args = parse_args(text, strict=True)
            text = ', '.join(args)
        return self._elt_processor('span', format_to_oneliner, text)

    def _td_processor(self, text):
        return self._tablecell_processor('td', text)

    def _th_processor(self, text):
        return self._tablecell_processor('th', text)

    def _tr_processor(self, text):
        try:
            elt = self._elt_processor('tr', self._format_row, text)
            self.formatter.open_table()
            return elt
        except ProcessorError, e:
            return system_message(e)

    def _table_processor(self, text):
        if not self.args:
            self.args = {}
        self.args.setdefault('class', 'wiki')
        try:
            return self._elt_processor('table', self._format_table, text)
        except ProcessorError, e:
            return system_message(e)

    def _tablecell_processor(self, eltname, text):
        self.formatter.open_table_row()
        return self._elt_processor(eltname, format_to_html, text)

    _has_multiple_tables_re = re.compile(r"</table>.*?<table",
                                         re.MULTILINE | re.DOTALL)

    _inner_table_re = re.compile(r"""\s*
      <table[^>]*>\s*
        ((?:<tr[^>]*>)?
          (.*?)
        (?:</tr>)?)\s*
      </table>\s*$
      """, re.MULTILINE | re.DOTALL | re.VERBOSE)

    # Note: the need for "parsing" that crude way the formatted content
    #       will go away as soon as we have a WikiDOM to manipulate...

    def _parse_inner_table(self, text):
        if self._has_multiple_tables_re.search(text):
            raise ProcessorError(_("!#%(name)s must contain at most one table",
                                   name=self.name))
        match = self._inner_table_re.match(text)
        if not match:
            raise ProcessorError(_("!#%(name)s must contain at least one table"
                                   " cell (and table cells only)",
                                   name=self.name))
        return Markup(match.group(1 if self.name == 'table' else 2))

    def _format_row(self, env, context, text):
        if text:
            out = StringIO()
            Formatter(env, context).format(text, out)
            text = self._parse_inner_table(out.getvalue())
        return text

    def _format_table(self, env, context, text):
        if text:
            out = StringIO()
            Formatter(env, context).format(text, out)
            text = self._parse_inner_table(out.getvalue())
        return text

    # generic processors

    def _legacy_macro_processor(self, text): # TODO: remove in 0.12
        self.env.log.warning('Executing pre-0.11 Wiki macro %s by provider %s'
                             % (self.name, self.macro_provider))
        return self.macro_provider.render_macro(self.formatter.req, self.name,
                                                text)

    def _macro_processor(self, text):
        self.env.log.debug('Executing Wiki macro %s by provider %s'
                           % (self.name, self.macro_provider))
        if arity(self.macro_provider.expand_macro) == 4:
            return self.macro_provider.expand_macro(self.formatter, self.name,
                                                    text, self.args)
        else:
            return self.macro_provider.expand_macro(self.formatter, self.name,
                                                    text)

    def _mimeview_processor(self, text):
        return Mimeview(self.env).render(self.formatter.context,
                                         self.name, text)
    # TODO: use convert('text/html') instead of render

    def process(self, text, in_paragraph=False):
        if self.error:
            text = system_message(tag('Error: Failed to load processor ',
                                      tag.code(self.name)),
                                  self.error)
        else:
            text = self.processor(text)
        return text or ''

    def is_inline(self, text):
        if callable(self.inline_check):
            return self.inline_check(text)
        else:
            return self.inline_check

    def ensure_inline(self, text):
        content_for_span = None
        interrupt_paragraph = False
        if isinstance(text, Element):
            tagname = text.tag.lower()
            if tagname == 'div':
                class_ = text.attrib.get('class', '')
                if class_ and 'code' in class_:
                    content_for_span = text.children
                else:
                    interrupt_paragraph = True
            elif tagname == 'table':
                interrupt_paragraph = True
        else:
            # FIXME: do something smarter for Streams
            text = _markup_to_unicode(text)
            match = re.match(self._code_block_re, text)
            if match:
                if match.group(1) and 'code' in match.group(1):
                    content_for_span = match.group(2)
                else:
                    interrupt_paragraph = True
            elif re.match(self._block_elem_re, text):
                interrupt_paragraph = True
        if content_for_span:
            text = tag.span(class_='code-block')(*content_for_span)
        elif interrupt_paragraph:
            text = "</p>%s<p>" % _markup_to_unicode(text)
        return text


class Formatter(object):
    """Base Wiki formatter.

    Parses and formats wiki text, in a given `Context`.
    """

    flavor = 'default'

    # 0.10 compatibility
    INTERTRAC_SCHEME = WikiParser.INTERTRAC_SCHEME
    QUOTED_STRING = WikiParser.QUOTED_STRING
    LINK_SCHEME = WikiParser.LINK_SCHEME

    def __init__(self, env, context):
        """Note: `req` is still temporarily used."""
        self.env = env
        self.context = context.child()
        self.context.set_hints(disable_warnings=True)
        self.req = context.req
        self.href = context.href
        self.resource = context.resource
        self.perm = context.perm
        self.wiki = WikiSystem(self.env)
        self.wikiparser = WikiParser(self.env)
        self._anchors = {}
        self._open_tags = []
        self._safe_schemes = None
        if not self.wiki.render_unsafe_content:
            self._safe_schemes = set(self.wiki.safe_schemes)


    def split_link(self, target):
        return split_url_into_path_query_fragment(target)

    # -- Pre- IWikiSyntaxProvider rules (Font styles)

    _indirect_tags = {
        'MM_BOLD': ('<strong>', '</strong>'),
        'WC_BOLD': ('<strong>', '</strong>'),
        'MM_ITALIC': ('<em>', '</em>'),
        'WC_ITALIC': ('<em>', '</em>'),
        'MM_UNDERLINE': ('<span class="underline">', '</span>'),
        'MM_STRIKE': ('<del>', '</del>'),
        'MM_SUBSCRIPT': ('<sub>', '</sub>'),
        'MM_SUPERSCRIPT': ('<sup>', '</sup>'),
        }

    def _get_open_tag(self, tag):
        """Retrieve opening tag for direct or indirect `tag`."""
        if not isinstance(tag, tuple):
            tag = self._indirect_tags[tag]
        return tag[0]

    def _get_close_tag(self, tag):
        """Retrieve closing tag for direct or indirect `tag`."""
        if not isinstance(tag, tuple):
            tag = self._indirect_tags[tag]
        return tag[1]

    def tag_open_p(self, tag):
        """Do we currently have any open tag with `tag` as end-tag?"""
        return tag in self._open_tags

    def flush_tags(self):
        while self._open_tags != []:
            self.out.write(self._get_close_tag(self._open_tags.pop()))

    def open_tag(self, tag_open, tag_close=None):
        """Open an inline style tag.

        If `tag_close` is not specified, `tag_open` is an indirect tag (0.12)
        """
        if tag_close:
            self._open_tags.append((tag_open, tag_close))
        else:
            self._open_tags.append(tag_open)
            tag_open = self._get_open_tag(tag_open)
        return tag_open

    def close_tag(self, open_tag, close_tag=None):
        """Open a inline style tag.

        If `close_tag` is not specified, it's an indirect tag (0.12)
        """
        tmp =  ''
        for i in xrange(len(self._open_tags) - 1, -1, -1):
            tag = self._open_tags[i]
            tmp += self._get_close_tag(tag)
            if (open_tag == tag,
                (open_tag, close_tag) == tag)[bool(close_tag)]:
                del self._open_tags[i]
                for j in xrange(i, len(self._open_tags)):
                    tmp += self._get_open_tag(self._open_tags[j])
                break
        return tmp

    def _indirect_tag_handler(self, match, tag):
        """Handle binary inline style tags (indirect way, 0.12)"""
        if self.tag_open_p(tag):
            return self.close_tag(tag)
        else:
            return self.open_tag(tag)

    def _bolditalic_formatter(self, match, fullmatch):
        italic_open = self.tag_open_p('MM_ITALIC')
        tmp = ''
        if italic_open:
            tmp += self._get_close_tag('MM_ITALIC')
            self.close_tag('MM_ITALIC')
        tmp += self._bold_formatter(match, fullmatch)
        if not italic_open:
            tmp += self.open_tag('MM_ITALIC')
        return tmp

    def _bold_formatter(self, match, fullmatch):
        return self._indirect_tag_handler(match, 'MM_BOLD')

    def _bold_wc_formatter(self, match, fullmatch):
        return self._indirect_tag_handler(match, 'WC_BOLD')

    def _italic_formatter(self, match, fullmatch):
        return self._indirect_tag_handler(match, 'MM_ITALIC')

    def _italic_wc_formatter(self, match, fullmatch):
        return self._indirect_tag_handler(match, 'WC_ITALIC')

    def _underline_formatter(self, match, fullmatch):
        return self._indirect_tag_handler(match, 'MM_UNDERLINE')

    def _strike_formatter(self, match, fullmatch):
        return self._indirect_tag_handler(match, 'MM_STRIKE')

    def _subscript_formatter(self, match, fullmatch):
        return self._indirect_tag_handler(match, 'MM_SUBSCRIPT')

    def _superscript_formatter(self, match, fullmatch):
        return self._indirect_tag_handler(match, 'MM_SUPERSCRIPT')

    def _inlinecode_formatter(self, match, fullmatch):
        return tag.tt(fullmatch.group('inline'))

    def _inlinecode2_formatter(self, match, fullmatch):
        return tag.tt(fullmatch.group('inline2'))

    # pre-0.12 public API (no longer used by Trac itself but kept for plugins)

    def simple_tag_handler(self, match, open_tag, close_tag):
        """Generic handler for simple binary style tags"""
        if self.tag_open_p((open_tag, close_tag)):
            return self.close_tag(open_tag, close_tag)
        else:
            self.open_tag(open_tag, close_tag)
        return open_tag

    # -- Post- IWikiSyntaxProvider rules

    # WikiCreole line brekas

    def _linebreak_wc_formatter(self, match, fullmatch):
        return '<br />'

    # E-mails

    def _email_formatter(self, match, fullmatch):
        from trac.web.chrome import Chrome
        omatch = Chrome(self.env).format_emails(self.context, match)
        if omatch == match: # not obfuscated, make a link
            return self._make_mail_link('mailto:'+match, match)
        else:
            return omatch

    # HTML escape of &, < and >

    def _htmlescape_formatter(self, match, fullmatch):
        return "&amp;" if match == "&" else "&lt;" if match == "<" else "&gt;"

    # Short form (shref) and long form (lhref) of TracLinks

    def _shrefbr_formatter(self, match, fullmatch):
        ns = fullmatch.group('snsbr')
        target = unquote_label(fullmatch.group('stgtbr'))
        match = match[1:-1]
        return '&lt;%s&gt;' % \
                self._make_link(ns, target, match, match, fullmatch)

    def _shref_formatter(self, match, fullmatch):
        ns = fullmatch.group('sns')
        target = unquote_label(fullmatch.group('stgt'))
        return self._make_link(ns, target, match, match, fullmatch)

    def _lhref_formatter(self, match, fullmatch):
        rel = fullmatch.group('rel')
        ns = fullmatch.group('lns')
        target = unquote_label(fullmatch.group('ltgt'))
        label = fullmatch.group('label')
        return self._make_lhref_link(match, fullmatch, rel, ns, target, label)

    def _make_lhref_link(self, match, fullmatch, rel, ns, target, label):
        if not label: # e.g. `[http://target]` or `[wiki:target]`
            if target:
                if target.startswith('//'):     # for `[http://target]`
                    label = ns + ':' + target   #  use `http://target`
                else:                           # for `wiki:target`
                    label = target.lstrip('/')  #  use only `target`
            else: # e.g. `[search:]`
                label = ns
        else:
            label = unquote_label(label)
        if rel:
            if not label:
                label = self.wiki.make_label_from_target(rel)
            path, query, fragment = self.split_link(rel)
            if path.startswith('//'):
                path = '/' + path.lstrip('/')
            elif path.startswith('/'):
                path = self.href + path
            else:
                resource = get_relative_resource(self.resource, path)
                path = get_resource_url(self.env, resource, self.href)
                if resource.id:
                    target = concat_path_query_fragment(unicode(resource.id),
                                                        query, fragment)
                    if resource.realm == 'wiki':
                        target = '/' + target   # Avoid wiki page scoping
                    return self._make_link(resource.realm, target, match,
                                           label, fullmatch)
            return tag.a(label,
                         href=concat_path_query_fragment(path, query, fragment))
        else:
            return self._make_link(ns or 'wiki', target or '', match, label,
                                   fullmatch)

    def _make_link(self, ns, target, match, label, fullmatch):
        # first check for an alias defined in trac.ini
        ns = self.env.config['intertrac'].get(ns, ns)
        if ns in self.wikiparser.link_resolvers:
            resolver = self.wikiparser.link_resolvers[ns]
            if arity(resolver) == 5:
                return resolver(self, ns, target, escape(label, False),
                                fullmatch)
            else:
                return resolver(self, ns, target, escape(label, False))
        elif ns == "mailto":
            from trac.web.chrome import Chrome
            chrome = Chrome(self.env)
            if chrome.never_obfuscate_mailto:
                otarget, olabel = target, label
            else:
                otarget = chrome.format_emails(self.context, target)
                olabel = chrome.format_emails(self.context, label)
            if (otarget, olabel) == (target, label):
                return self._make_mail_link('mailto:'+target, label)
            else:
                return olabel or otarget
        elif target.startswith('//'):
            if self._safe_schemes is None or ns in self._safe_schemes:
                return self._make_ext_link(ns + ':' + target, label)
            else:
                return escape(match)
        else:
            return self._make_intertrac_link(ns, target, label) or \
                   self._make_interwiki_link(ns, target, label) or \
                   escape(match)

    def _make_intertrac_link(self, ns, target, label):
        res = self.get_intertrac_url(ns, target)
        if res:
            return self._make_ext_link(res[0], label, res[1])

    def get_intertrac_url(self, ns, target):
        intertrac = self.env.config['intertrac']
        url = intertrac.get(ns + '.url')
        if not url and ns == 'trac':
            url = 'http://trac.edgewall.org'
        if url:
            name = intertrac.get(ns + '.title', 'Trac project %s' % ns)
            compat = intertrac.getbool(ns + '.compat', 'false')
            # set `compat` default to False now that 0.10 is widely used
            # TODO: remove compatibility code completely for 1.0 release
            if compat:
                sep = target.find(':')
                if sep != -1:
                    url = '%s/%s/%s' % (url, target[:sep], target[sep + 1:])
                else:
                    url = '%s/search?q=%s' % (url, unicode_quote_plus(target))
            else:
                url = '%s/intertrac/%s' % (url, unicode_quote(target))
            if target:
                title = _('%(target)s in %(name)s', target=target, name=name)
            else:
                title = name
            return (url, title)

    def shorthand_intertrac_helper(self, ns, target, label, fullmatch):
        if fullmatch: # short form
            it_group = fullmatch.groupdict().get('it_' + ns)
            if it_group:
                alias = it_group.strip()
                intertrac = self.env.config['intertrac']
                target = '%s:%s' % (ns, target[len(it_group):])
                return self._make_intertrac_link(intertrac.get(alias, alias),
                                                 target, label) or label

    def _make_interwiki_link(self, ns, target, label):
        from trac.wiki.interwiki import InterWikiMap
        interwiki = InterWikiMap(self.env)
        if ns in interwiki:
            url, title = interwiki.url(ns, target)
            return self._make_ext_link(url, label, title)

    def _make_ext_link(self, url, text, title=''):
        local_url = self.env.project_url or \
                    (self.req or self.env).abs_href.base
        if not url.startswith(local_url):
            return tag.a(tag.span(u'\u200b', class_="icon"), text,
                         class_="ext-link", href=url, title=title or None)
        else:
            return tag.a(text, href=url, title=title or None)

    def _make_mail_link(self, url, text, title=''):
        return tag.a(tag.span(u'\u200b', class_="icon"), text,
                     class_="mail-link", href=url, title=title or None)

    # Anchors

    def _anchor_formatter(self, match, fullmatch):
        anchor = fullmatch.group('anchorname')
        label = fullmatch.group('anchorlabel') or ''
        if label:
            label = format_to_oneliner(self.env, self.context, label)
        return '<span class="wikianchor" id="%s">%s</span>' % (anchor, label)

    # WikiMacros or WikiCreole links

    def _macrolink_formatter(self, match, fullmatch):
        # check for a known [[macro]]
        macro_or_link = match[2:-2]
        if macro_or_link.startswith('=#'):
            fullmatch = WikiParser._set_anchor_wc_re.match(macro_or_link)
            if fullmatch:
                return self._anchor_formatter(macro_or_link, fullmatch)
        fullmatch = WikiParser._macro_re.match(macro_or_link)
        if fullmatch:
            name = fullmatch.group('macroname')
            args = fullmatch.group('macroargs')
            macro = False # not a macro
            macrolist = name[-1] == '?'
            if name.lower() == 'br' or name == '?':
                macro = None
            else:
                macro = WikiProcessor(self, (name, name[:-1])[macrolist])
                if macro.error:
                    macro = False
            if macro is not False:
                if macrolist:
                    macro = WikiProcessor(self, 'MacroList')
                return self._macro_formatter(match, fullmatch, macro)
        fullmatch = WikiParser._creolelink_re.match(macro_or_link)
        return self._lhref_formatter(match, fullmatch)

    def _macro_formatter(self, match, fullmatch, macro, only_inline=False):
        name = fullmatch.group('macroname')
        if name.lower() == 'br':
            return '<br />'
        if name and name[-1] == '?': # Macro?() shortcut for MacroList(Macro)
            args = name[:-1] or '*'
        else:
            args = fullmatch.group('macroargs')
        try:
            return macro.ensure_inline(macro.process(args))
        except Exception, e:
            self.env.log.error('Macro %s(%s) failed: %s' %
                    (name, args, exception_to_unicode(e, traceback=True)))
            return system_message('Error: Macro %s(%s) failed' % (name, args),
                                  e)

    # Headings

    def _parse_heading(self, match, fullmatch, shorten):
        match = match.strip()

        hdepth = fullmatch.group('hdepth')
        depth = len(hdepth)
        anchor = fullmatch.group('hanchor') or ''
        htext = fullmatch.group('htext').strip()
        if htext.endswith(hdepth):
            htext = htext[:-depth]
        heading = format_to_oneliner(self.env, self.context, htext, False)
        if anchor:
            anchor = anchor[1:]
        else:
            sans_markup = plaintext(heading, keeplinebreaks=False)
            anchor = WikiParser._anchor_re.sub('', sans_markup)
            if not anchor or anchor[0].isdigit() or anchor[0] in '.-':
                # an ID must start with a Name-start character in XHTML
                anchor = 'a' + anchor # keeping 'a' for backward compat
        i = 1
        anchor_base = anchor
        while anchor in self._anchors:
            anchor = anchor_base + str(i)
            i += 1
        self._anchors[anchor] = True
        if shorten:
            heading = format_to_oneliner(self.env, self.context, htext, True)
        return (depth, heading, anchor)

    def _heading_formatter(self, match, fullmatch):
        self.close_table()
        self.close_paragraph()
        self.close_indentation()
        self.close_list()
        self.close_def_list()
        depth, heading, anchor = self._parse_heading(match, fullmatch, False)
        self.out.write('<h%d id="%s">%s</h%d>' %
                       (depth, anchor, heading, depth))

    # Generic indentation (as defined by lists and quotes)

    def _set_tab(self, depth):
        """Append a new tab if needed and truncate tabs deeper than `depth`

        given:       -*-----*--*---*--
        setting:              *
        results in:  -*-----*-*-------
        """
        tabstops = []
        for ts in self._tabstops:
            if ts >= depth:
                break
            tabstops.append(ts)
        tabstops.append(depth)
        self._tabstops = tabstops

    # Lists

    def _list_formatter(self, match, fullmatch):
        ldepth = len(fullmatch.group('ldepth'))
        listid = match[ldepth]
        self.in_list_item = True
        class_ = start = None
        if listid in WikiParser.BULLET_CHARS:
            type_ = 'ul'
        else:
            type_ = 'ol'
            lstart = fullmatch.group('lstart')
            start = None
            idx = '0iI'.find(listid)
            if idx > -1:
                class_ = ('arabiczero', 'lowerroman', 'upperroman')[idx]
            elif listid.isdigit():
                start = lstart != '1' and int(lstart)
            elif listid.islower():
                class_ = 'loweralpha'
                if len(lstart) == 1 and lstart != 'a':
                    start = ord(lstart) - ord('a') + 1
            elif listid.isupper():
                class_ = 'upperalpha'
                if len(lstart) == 1 and lstart != 'A':
                    start = ord(lstart) - ord('A') + 1
        self._set_list_depth(ldepth, type_, class_, start)
        return ''

    def _get_list_depth(self):
        """Return the space offset associated to the deepest opened list."""
        if self._list_stack:
            return self._list_stack[-1][1]
        return -1

    def _set_list_depth(self, depth, new_type=None, lclass=None, start=None):
        def open_list():
            self.close_table()
            self.close_paragraph()
            self.close_indentation() # FIXME: why not lists in quotes?
            self._list_stack.append((new_type, depth))
            self._set_tab(depth)
            class_attr = ' class="%s"' % lclass if lclass else ''
            start_attr = ' start="%s"' % start if start else ''
            self.out.write('<' + new_type + class_attr + start_attr + '><li>')
        def close_item():
            self.flush_tags()
            self.out.write('</li>')
        def close_list(tp):
            self._list_stack.pop()
            close_item()
            self.out.write('</%s>' % tp)

        # depending on the indent/dedent, open or close lists
        if depth > self._get_list_depth():
            open_list()
        else:
            while self._list_stack:
                deepest_type, deepest_offset = self._list_stack[-1]
                if depth >= deepest_offset:
                    break
                close_list(deepest_type)
            if new_type and depth >= 0:
                if self._list_stack:
                    old_type, old_offset = self._list_stack[-1]
                    if new_type and old_type != new_type:
                        close_list(old_type)
                        open_list()
                    else:
                        if old_offset != depth: # adjust last depth
                            self._list_stack[-1] = (old_type, depth)
                        close_item()
                        self.out.write('<li>')
                else:
                    open_list()

    def close_list(self, depth=-1):
        self._set_list_depth(depth)

    # Definition Lists

    def _definition_formatter(self, match, fullmatch):
        tmp = '</dd>' if self.in_def_list else '<dl class="wiki">'
        definition = match[:match.find('::')]
        tmp += '<dt>%s</dt><dd>' % format_to_oneliner(self.env, self.context,
                                                      definition)
        self.in_def_list = True
        return tmp

    def close_def_list(self):
        if self.in_def_list:
            self.out.write('</dd></dl>\n')
        self.in_def_list = False

    # Blockquote

    def _indent_formatter(self, match, fullmatch):
        idepth = len(fullmatch.group('idepth'))
        if self._list_stack:
            ltype, ldepth = self._list_stack[-1]
            if idepth < ldepth:
                for _, ldepth in self._list_stack:
                    if idepth > ldepth:
                        self.in_list_item = True
                        self._set_list_depth(idepth)
                        return ''
            elif idepth <= ldepth + (3 if ltype == 'ol' else 2):
                self.in_list_item = True
                return ''
        if not self.in_def_list:
            self._set_quote_depth(idepth)
        return ''

    def close_indentation(self):
        self._set_quote_depth(0)

    def _get_quote_depth(self):
        """Return the space offset associated to the deepest opened quote."""
        return self._quote_stack[-1] if self._quote_stack else 0

    def _set_quote_depth(self, depth, citation=False):
        def open_quote(depth):
            self.close_table()
            self.close_paragraph()
            self.close_list()
            def open_one_quote(d):
                self._quote_stack.append(d)
                self._set_tab(d)
                class_attr = ' class="citation"' if citation else ''
                self.out.write('<blockquote%s>' % class_attr + os.linesep)
            if citation:
                for d in range(quote_depth+1, depth+1):
                    open_one_quote(d)
            else:
                open_one_quote(depth)
        def close_quote():
            self.close_table()
            self.close_paragraph()
            self._quote_stack.pop()
            self.out.write('</blockquote>' + os.linesep)
        quote_depth = self._get_quote_depth()
        if depth > quote_depth:
            self._set_tab(depth)
            tabstops = self._tabstops[::-1]
            while tabstops:
                tab = tabstops.pop()
                if tab > quote_depth:
                    open_quote(tab)
        else:
            while self._quote_stack:
                deepest_offset = self._quote_stack[-1]
                if depth >= deepest_offset:
                    break
                close_quote()
            if not citation and depth > 0:
                if self._quote_stack:
                    old_offset = self._quote_stack[-1]
                    if old_offset != depth: # adjust last depth
                        self._quote_stack[-1] = depth
                else:
                    open_quote(depth)
        if depth > 0:
            self.in_quote = True

    # Table

    def _table_cell_formatter(self, match, fullmatch):
        self.open_table()
        self.open_table_row()
        self.continue_table = 1
        separator = fullmatch.group('table_cell_sep')
        is_last = fullmatch.group('table_cell_last')
        numpipes = len(separator)
        cell = 'td'
        if separator[0] == '=':
            numpipes -= 1
        if separator[-1] == '=':
            numpipes -= 1
            cell = 'th'
        colspan = numpipes/2
        if is_last is not None:
            if is_last and is_last[-1] == '\\':
                self.continue_table_row = 1
            colspan -= 1
            if not colspan:
                return ''
        attrs = ''
        if colspan > 1:
            attrs = ' colspan="%d"' % int(colspan)
        # alignment: ||left || right||default|| default ||  center  ||
        after_sep = fullmatch.end('table_cell_sep')
        alignleft = after_sep < len(self.line) and self.line[after_sep] != ' '
        # lookahead next || (FIXME: this fails on ` || ` inside the cell)
        next_sep = re.search(r'([^!])=?\|\|', self.line[after_sep:])
        alignright = next_sep and next_sep.group(1) != ' '
        textalign = None
        if alignleft:
            if not alignright:
                textalign = 'left'
        elif alignright:
            textalign = 'right'
        elif next_sep: # check for the extra spaces specifying a center align
            first_extra = after_sep + 1
            last_extra = after_sep + next_sep.start() - 1
            if first_extra < last_extra and \
                   self.line[first_extra] == self.line[last_extra] == ' ':
                textalign = 'center'
        if textalign:
            attrs += ' style="text-align: %s"' % textalign
        td = '<%s%s>' % (cell, attrs)
        if self.in_table_cell:
            td = '</%s>' % self.in_table_cell + td
        self.in_table_cell = cell
        return td

    def _table_row_sep_formatter(self, match, fullmatch):
        self.open_table()
        self.close_table_row(force=True)
        params = fullmatch.group('table_row_params')
        if params:
            tr = WikiProcessor(self, 'tr', self.parse_processor_args(params))
            processed = _markup_to_unicode(tr.process(''))
            params = processed[3:processed.find('>')]
        self.open_table_row(params or '')
        self.continue_table = 1
        self.continue_table_row = 1

    def open_table(self):
        if not self.in_table:
            self.close_paragraph()
            self.close_list()
            self.close_def_list()
            self.in_table = 1
            self.out.write('<table class="wiki">' + os.linesep)

    def open_table_row(self, params=''):
        if not self.in_table_row:
            self.open_table()
            self.in_table_row = 1
            self.out.write('<tr%s>' % params)

    def close_table_row(self, force=False):
        if self.in_table_row and (not self.continue_table_row or force):
            self.in_table_row = 0
            if self.in_table_cell:
                self.out.write('</%s>' % self.in_table_cell)
                self.in_table_cell = ''
            self.out.write('</tr>')
        self.continue_table_row = 0

    def close_table(self):
        if self.in_table:
            self.close_table_row(force=True)
            self.out.write('</table>' + os.linesep)
            self.in_table = 0

    # Paragraphs

    def open_paragraph(self):
        if not self.paragraph_open:
            self.out.write('<p>' + os.linesep)
            self.paragraph_open = 1

    def close_paragraph(self):
        self.flush_tags()
        if self.paragraph_open:
            self.out.write('</p>' + os.linesep)
            self.paragraph_open = 0

    # Code blocks

    def parse_processor_args(self, line):
        return parse_processor_args(line)

    def handle_code_block(self, line, startmatch=None):
        if startmatch:
            self.in_code_block += 1
            if self.in_code_block == 1:
                name = startmatch.group(2)
                if name:
                    args = parse_processor_args(line[startmatch.end():])
                    self.code_processor = WikiProcessor(self, name, args)
                else:
                    self.code_processor = None
                self.code_buf = []
                self.code_prefix = line[:line.find(WikiParser.STARTBLOCK)]
            else:
                self.code_buf.append(line)
                if not self.code_processor:
                    self.code_processor = WikiProcessor(self, 'default')
        elif line.strip() == WikiParser.ENDBLOCK:
            self.in_code_block -= 1
            if self.in_code_block == 0 and self.code_processor:
                if self.code_processor.name not in ('th', 'td', 'tr'):
                    self.close_table()
                self.close_paragraph()
                if self.code_buf:
                    if self.code_prefix and all(not l or
                                                l.startswith(self.code_prefix)
                                                for l in self.code_buf):
                        code_indent = len(self.code_prefix)
                        self.code_buf = [l[code_indent:]
                                         for l in self.code_buf]
                    self.code_buf.append('')
                code_text = os.linesep.join(self.code_buf)
                processed = self.code_processor.process(code_text)
                self.out.write(_markup_to_unicode(processed))
            else:
                self.code_buf.append(line)
        elif not self.code_processor:
            match = WikiParser._processor_re.match(line)
            if match:
                self.code_prefix = match.group(1)
                name = match.group(2)
                args = parse_processor_args(line[match.end():])
                self.code_processor = WikiProcessor(self, name, args)
            else:
                self.code_buf.append(line)
                self.code_processor = WikiProcessor(self, 'default')
        else:
            self.code_buf.append(line)

    def close_code_blocks(self):
        while self.in_code_block > 0:
            self.handle_code_block(WikiParser.ENDBLOCK)

    # > quotes

    def handle_quote_block(self, line):
        self.close_paragraph()
        depth = line.find('>')
        # Close lists up to current level:
        #
        #  - first level item
        #    - second level item
        #    > citation part of first level item
        #
        #  (depth == 3, _list_stack == [1, 3])
        if not self._quote_buffer and depth < self._get_list_depth():
            self.close_list(depth)
        self._quote_buffer.append(line[depth + 1:])

    def close_quote_block(self, escape_newlines):
        if self._quote_buffer:
            # avoid an extra <blockquote> when there's consistently one space
            # after the '>'
            if all(not line or line[0] in '> ' for line in self._quote_buffer):
                self._quote_buffer = [line[bool(line and line[0] == ' '):]
                                      for line in self._quote_buffer]
            self.out.write('<blockquote class="citation">\n')
            Formatter(self.env, self.context).format(self._quote_buffer,
                                                     self.out, escape_newlines)
            self.out.write('</blockquote>\n')
            self._quote_buffer = []

    # -- Wiki engine

    def handle_match(self, fullmatch):
        for itype, match in fullmatch.groupdict().items():
            if match and not itype in self.wikiparser.helper_patterns:
                # Check for preceding escape character '!'
                if match[0] == '!':
                    return escape(match[1:])
                if itype in self.wikiparser.external_handlers:
                    external_handler = self.wikiparser.external_handlers[itype]
                    return external_handler(self, match, fullmatch)
                else:
                    internal_handler = getattr(self, '_%s_formatter' % itype)
                    return internal_handler(match, fullmatch)

    def replace(self, fullmatch):
        """Replace one match with its corresponding expansion"""
        replacement = self.handle_match(fullmatch)
        if replacement:
            return _markup_to_unicode(replacement)

    _normalize_re = re.compile(r'[\v\f]', re.UNICODE)

    def reset(self, source, out=None):
        if isinstance(source, basestring):
            source = re.sub(self._normalize_re, ' ', source)
        self.source = source
        class NullOut(object):
            def write(self, data):
                pass
        self.out = out or NullOut()
        self._open_tags = []
        self._list_stack = []
        self._quote_stack = []
        self._tabstops = []
        self._quote_buffer = []

        self.in_code_block = 0
        self.in_table = 0
        self.in_def_list = 0
        self.in_table_row = 0
        self.continue_table = 0
        self.continue_table_row = 0
        self.in_table_cell = ''
        self.paragraph_open = 0
        return source


    def format(self, text, out=None, escape_newlines=False):
        text = self.reset(text, out)
        if isinstance(text, basestring):
            text = text.splitlines()

        for line in text:
            # Detect start of code block (new block or embedded block)
            block_start_match = None
            if WikiParser.ENDBLOCK not in line:
                block_start_match = WikiParser._startblock_re.match(line)
            # Handle content or end of code block
            if self.in_code_block:
                self.handle_code_block(line, block_start_match)
                continue
            # Handle citation quotes '> ...'
            if line.strip().startswith('>'):
                self.handle_quote_block(line)
                continue
            # Handle end of citation quotes
            self.close_quote_block(escape_newlines)
            # Handle start of a new block
            if block_start_match:
                self.handle_code_block(line, block_start_match)
                continue
            # Handle Horizontal ruler
            if line[0:4] == '----':
                self.close_table()
                self.close_paragraph()
                self.close_indentation()
                self.close_list()
                self.close_def_list()
                self.out.write('<hr />' + os.linesep)
                continue
            # Handle new paragraph
            if line == '':
                self.close_table()
                self.close_paragraph()
                self.close_indentation()
                self.close_list()
                self.close_def_list()
                continue

            # Tab expansion and clear tabstops if no indent
            line = line.replace('\t', ' '*8)
            if not line.startswith(' '):
                self._tabstops = []

            self.in_list_item = False
            self.in_quote = False
            # Throw a bunch of regexps on the problem
            self.line = line
            result = re.sub(self.wikiparser.rules, self.replace, line)

            if not self.in_list_item:
                self.close_list()

            if not self.in_quote:
                self.close_indentation()

            if self.in_def_list and not line.startswith(' '):
                self.close_def_list()

            if self.in_table and not self.continue_table:
                self.close_table()
            self.continue_table = 0

            sep = os.linesep
            if not(self.in_list_item or self.in_def_list or self.in_table):
                if len(result):
                    self.open_paragraph()
                if escape_newlines and self.paragraph_open and \
                       not result.rstrip().endswith('<br />'):
                    sep = '<br />' + sep
            self.out.write(result + sep)
            self.close_table_row()

        self.close_code_blocks()
        self.close_quote_block(escape_newlines)
        self.close_table()
        self.close_paragraph()
        self.close_indentation()
        self.close_list()
        self.close_def_list()


class OneLinerFormatter(Formatter):
    """
    A special version of the wiki formatter that only implement a
    subset of the wiki formatting functions. This version is useful
    for rendering short wiki-formatted messages on a single line
    """
    flavor = 'oneliner'

    # Override a few formatters to disable some wiki syntax in "oneliner"-mode
    def _list_formatter(self, match, fullmatch):
        return match
    def _indent_formatter(self, match, fullmatch):
        return match
    def _citation_formatter(self, match, fullmatch):
        return escape(match, False)
    def _heading_formatter(self, match, fullmatch):
        return escape(match, False)
    def _definition_formatter(self, match, fullmatch):
        return escape(match, False)
    def _table_cell_formatter(self, match, fullmatch):
        return match
    def _table_row_sep_formatter(self, match, fullmatch):
        return ''

    def _linebreak_wc_formatter(self, match, fullmatch):
        return ' '

    def _macro_formatter(self, match, fullmatch, macro):
        name = fullmatch.group('macroname')
        if name.lower() == 'br':
            return ' '
        args = fullmatch.group('macroargs')
        if macro.is_inline(args):
            return Formatter._macro_formatter(self, match, fullmatch, macro)
        else:
            return '[[%s%s]]' % (name, '(...)' if args else '')

    def format(self, text, out, shorten=False):
        if not text:
            return
        text = self.reset(text, out)

        # Simplify code blocks
        in_code_block = 0
        processor = None
        buf = StringIO()
        for line in text.strip().splitlines():
            if WikiParser.ENDBLOCK not in line and \
                   WikiParser._startblock_re.match(line):
                in_code_block += 1
            elif line.strip() == WikiParser.ENDBLOCK:
                if in_code_block:
                    in_code_block -= 1
                    if in_code_block == 0:
                        if processor != 'comment':
                            buf.write(' [...]' + os.linesep)
                        processor = None
            elif in_code_block:
                if not processor:
                    if line.startswith('#!'):
                        processor = line[2:].strip()
            else:
                buf.write(line + os.linesep)
        result = buf.getvalue()[:-len(os.linesep)]

        if shorten:
            result = shorten_line(result)

        result = re.sub(self.wikiparser.rules, self.replace, result)
        result = result.replace('[...]', u'[\u2026]')
        if result.endswith('...'):
            result = result[:-3] + u'\u2026'

        self.out.write(result)
        # Close all open 'one line'-tags
        self.flush_tags()
        # Flush unterminated code blocks
        if in_code_block > 0:
            self.out.write(u'[\u2026]')


class OutlineFormatter(Formatter):
    """Special formatter that generates an outline of all the headings."""
    flavor = 'outline'

    # Avoid the possible side-effects of rendering WikiProcessors
    def _macro_formatter(self, match, fullmatch, macro):
        name = fullmatch.group('macroname')
        if name.lower() == 'br':
            return ' '
        args = fullmatch.group('macroargs')
        if macro.is_inline(args):
            return Formatter._macro_formatter(self, match, fullmatch, macro)
        return ''

    def handle_code_block(self, line, startmatch=None):
        if WikiParser.ENDBLOCK not in line and \
               WikiParser._startblock_re.match(line):
            self.in_code_block += 1
        elif line.strip() == WikiParser.ENDBLOCK:
            self.in_code_block -= 1

    def format(self, text, out, max_depth=6, min_depth=1, shorten=True):
        self.shorten = shorten
        whitespace_indent = '  '
        self.outline = []
        Formatter.format(self, text)

        if min_depth > max_depth:
            min_depth, max_depth = max_depth, min_depth
        max_depth = min(6, max_depth)
        min_depth = max(1, min_depth)

        curr_depth = min_depth - 1
        out.write('\n')
        for depth, anchor, text in self.outline:
            if depth < min_depth or depth > max_depth:
                continue
            if depth > curr_depth: # Deeper indent
                for i in range(curr_depth, depth):
                    out.write(whitespace_indent * (2*i) + '<ol>\n' +
                              whitespace_indent * (2*i+1) + '<li>\n')
            elif depth < curr_depth: # Shallower indent
                for i in range(curr_depth-1, depth-1, -1):
                    out.write(whitespace_indent * (2*i+1) + '</li>\n' +
                              whitespace_indent * (2*i) + '</ol>\n')
                out.write(whitespace_indent * (2*depth-1) + '</li>\n' +
                          whitespace_indent * (2*depth-1) + '<li>\n')
            else: # Same indent
                out.write( whitespace_indent * (2*depth-1) + '</li>\n' +
                           whitespace_indent * (2*depth-1) + '<li>\n')
            curr_depth = depth
            out.write(whitespace_indent * (2*depth) +
                      '<a href="#%s">%s</a>\n' % (anchor, text))
        # Close out all indentation
        for i in range(curr_depth-1, min_depth-2, -1):
            out.write(whitespace_indent * (2*i+1) + '</li>\n' +
                      whitespace_indent * (2*i) + '</ol>\n')

    def _heading_formatter(self, match, fullmatch):
        depth, heading, anchor = self._parse_heading(match, fullmatch,
                                                     self.shorten)
        heading = re.sub(r'</?a(?: .*?)?>', '', heading) # Strip out link tags
        self.outline.append((depth, anchor, heading))


class LinkFormatter(OutlineFormatter):
    """Special formatter that focuses on TracLinks."""
    flavor = 'link'

    def _heading_formatter(self, match, fullmatch):
        return ''

    def match(self, wikitext):
        """Return the Wiki match found at the beginning of the `wikitext`"""
        wikitext = self.reset(wikitext)
        self.line = wikitext
        match = re.match(self.wikiparser.rules, wikitext)
        if match:
            return self.handle_match(match)


# Pure Wiki Formatter

class HtmlFormatter(object):
    """Format parsed wiki text to HTML"""

    flavor = 'default'

    def __init__(self, env, context, wikidom):
        self.env = env
        self.context = context
        if isinstance(wikidom, basestring):
            wikidom = WikiParser(env).parse(wikidom)
        self.wikidom = wikidom

    def generate(self, escape_newlines=False):
        """Generate HTML elements.

        newlines in the wikidom will be preserved if `escape_newlines` is set.
        """
        # FIXME: compatibility code only for now
        out = StringIO()
        Formatter(self.env, self.context).format(self.wikidom, out,
                                                 escape_newlines)
        return Markup(out.getvalue())


class InlineHtmlFormatter(object):
    """Format parsed wiki text to inline elements HTML.

    Block level content will be disguarded or compacted.
    """

    flavor = 'oneliner'

    def __init__(self, env, context, wikidom):
        self.env = env
        self.context = context
        if isinstance(wikidom, basestring):
            wikidom = WikiParser(env).parse(wikidom)
        self.wikidom = wikidom

    def generate(self, shorten=False):
        """Generate HTML inline elements.

        If `shorten` is set, the generation will stop once enough characters
        have been emitted.
        """
        # FIXME: compatibility code only for now
        out = StringIO()
        OneLinerFormatter(self.env, self.context).format(self.wikidom, out,
                                                         shorten)
        return Markup(out.getvalue())


def format_to(env, flavor, context, wikidom, **options):
    if flavor is None:
        flavor = context.get_hint('wiki_flavor', 'html')
    if flavor == 'oneliner':
        return format_to_oneliner(env, context, wikidom, **options)
    else:
        return format_to_html(env, context, wikidom, **options)

def format_to_html(env, context, wikidom, escape_newlines=None):
    if not wikidom:
        return Markup()
    if escape_newlines is None:
        escape_newlines = context.get_hint('preserve_newlines', False)
    return HtmlFormatter(env, context, wikidom).generate(escape_newlines)

def format_to_oneliner(env, context, wikidom, shorten=None):
    if not wikidom:
        return Markup()
    if shorten is None:
        shorten = context.get_hint('shorten_lines', False)
    return InlineHtmlFormatter(env, context, wikidom).generate(shorten)

def extract_link(env, context, wikidom):
    if not wikidom:
        return Markup()
    return LinkFormatter(env, context).match(wikidom)


# pre-0.11 wiki text to Markup compatibility methods

def wiki_to_html(wikitext, env, req, db=None,
                 absurls=False, escape_newlines=False):
    """deprecated in favor of format_to_html (will be removed in 1.0)"""
    if not wikitext:
        return Markup()
    abs_ref, href = (req or env).abs_href, (req or env).href
    from trac.web.chrome import web_context
    context = web_context(req, absurls=absurls)
    out = StringIO()
    Formatter(env, context).format(wikitext, out, escape_newlines)
    return Markup(out.getvalue())

def wiki_to_oneliner(wikitext, env, db=None, shorten=False, absurls=False,
                     req=None):
    """:deprecated: in favor of format_to_oneliner (will be removed in 1.0)"""
    if not wikitext:
        return Markup()
    abs_ref, href = (req or env).abs_href, (req or env).href
    from trac.web.chrome import web_context
    context = web_context(req, absurls=absurls)
    out = StringIO()
    OneLinerFormatter(env, context).format(wikitext, out, shorten)
    return Markup(out.getvalue())

def wiki_to_outline(wikitext, env, db=None,
                    absurls=False, max_depth=None, min_depth=None, req=None):
    """:deprecated: will be removed in 1.0 and replaced by something else"""
    if not wikitext:
        return Markup()
    abs_ref, href = (req or env).abs_href, (req or env).href
    from trac.web.chrome import web_context
    context = web_context(req, absurls=absurls)
    out = StringIO()
    OutlineFormatter(env, context).format(wikitext, out, max_depth, min_depth)
    return Markup(out.getvalue())

########NEW FILE########
__FILENAME__ = intertrac
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christian Boos <cboos@edgewall.org>

import re

from genshi.builder import Element, Fragment, tag

from trac.config import ConfigSection
from trac.core import *
from trac.perm import PermissionError
from trac.util.html import find_element
from trac.util.translation import _, N_
from trac.web.api import IRequestHandler
from trac.wiki.api import IWikiMacroProvider
from trac.wiki.formatter import extract_link


class InterTracDispatcher(Component):
    """InterTrac dispatcher."""

    implements(IRequestHandler, IWikiMacroProvider)

    intertrac_section = ConfigSection('intertrac',
        """This section configures InterTrac prefixes. Options in this section
        whose name contain a "." define aspects of the InterTrac prefix
        corresponding to the option name up to the ".". Options whose name
        don't contain a "." define an alias.

        The `.url` is mandatory and is used for locating the other Trac.
        This can be a relative URL in case that Trac environment is located
        on the same server.

        The `.title` information is used for providing a useful tooltip when
        moving the cursor over an InterTrac link.

        The `.compat` option can be used to activate or disable a
        ''compatibility'' mode:
         * If the targeted Trac is running a version below
           [trac:milestone:0.10 0.10] ([trac:r3526 r3526] to be precise), then
           it doesn't know how to dispatch an InterTrac link, and it's up to
           the local Trac to prepare the correct link. Not all links will work
           that way, but the most common do. This is called the compatibility
           mode, and is `true` by default.
         * If you know that the remote Trac knows how to dispatch InterTrac
           links, you can explicitly disable this compatibility mode and then
           ''any'' TracLinks can become InterTrac links.

        Example configuration:
        {{{
        [intertrac]
        # -- Example of setting up an alias:
        t = trac

        # -- Link to an external Trac:
        trac.title = Edgewall's Trac for Trac
        trac.url = http://trac.edgewall.org
        }}}
        """)

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'^/intertrac/(.*)', req.path_info)
        if match:
            if match.group(1):
                req.args['link'] = match.group(1)
            return True

    def process_request(self, req):
        link = req.args.get('link', '')
        parts = link.split(':', 1)
        if len(parts) > 1:
            resolver, target = parts
            if target[:1] + target[-1:] not in ('""', "''"):
                link = '%s:"%s"' % (resolver, target)
        from trac.web.chrome import web_context
        link_frag = extract_link(self.env, web_context(req), link)
        if isinstance(link_frag, (Element, Fragment)):
            elt = find_element(link_frag, 'href')
            if elt is None: # most probably no permissions to view
                raise PermissionError(_("Can't view %(link)s:", link=link))
            href = elt.attrib.get('href')
        else:
            href = req.href(link.rstrip(':'))
        req.redirect(href)

    # IWikiMacroProvider methods

    def get_macros(self):
        yield 'InterTrac'

    def get_macro_description(self, name):
        return 'messages', N_("Provide a list of known InterTrac prefixes.")

    def expand_macro(self, formatter, name, content):
        intertracs = {}
        for key, value in self.intertrac_section.options():
            idx = key.rfind('.')
            if idx > 0: # 0 itself doesn't help much: .xxx = ...
                prefix, attribute = key[:idx], key[idx+1:]
                intertrac = intertracs.setdefault(prefix, {})
                intertrac[attribute] = value
            else:
                intertracs[key] = value # alias
        if 'trac' not in intertracs:
            intertracs['trac'] = {'title': _('The Trac Project'),
                                  'url': 'http://trac.edgewall.org'}

        def generate_prefix(prefix):
            intertrac = intertracs[prefix]
            if isinstance(intertrac, basestring):
                yield tag.tr(tag.td(tag.b(prefix)),
                             tag.td('Alias for ', tag.b(intertrac)))
            else:
                url = intertrac.get('url', '')
                if url:
                    title = intertrac.get('title', url)
                    yield tag.tr(tag.td(tag.a(tag.b(prefix),
                                              href=url + '/timeline')),
                                 tag.td(tag.a(title, href=url)))

        return tag.table(class_="wiki intertrac")(
            tag.tr(tag.th(tag.em('Prefix')), tag.th(tag.em('Trac Site'))),
            [generate_prefix(p) for p in sorted(intertracs.keys())])

########NEW FILE########
__FILENAME__ = interwiki
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005-2006 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christian Boos <cboos@edgewall.org>

import re

from genshi.builder import tag

from trac.cache import cached
from trac.config import ConfigSection
from trac.core import *
from trac.util.translation import _, N_
from trac.wiki.api import IWikiChangeListener, IWikiMacroProvider
from trac.wiki.parser import WikiParser
from trac.wiki.formatter import split_url_into_path_query_fragment


class InterWikiMap(Component):
    """InterWiki map manager."""

    implements(IWikiChangeListener, IWikiMacroProvider)

    interwiki_section = ConfigSection('interwiki',
        """Every option in the `[interwiki]` section defines one InterWiki
        prefix. The option name defines the prefix. The option value defines
        the URL, optionally followed by a description separated from the URL
        by whitespace. Parametric URLs are supported as well.

        '''Example:'''
        {{{
        [interwiki]
        MeatBall = http://www.usemod.com/cgi-bin/mb.pl?
        PEP = http://www.python.org/peps/pep-$1.html Python Enhancement Proposal $1
        tsvn = tsvn: Interact with TortoiseSvn
        }}}
        """)

    _page_name = 'InterMapTxt'
    _interwiki_re = re.compile(r"(%s)[ \t]+([^ \t]+)(?:[ \t]+#(.*))?" %
                               WikiParser.LINK_SCHEME, re.UNICODE)
    _argspec_re = re.compile(r"\$\d")

    # The component itself behaves as a read-only map

    def __contains__(self, ns):
        return ns.upper() in self.interwiki_map

    def __getitem__(self, ns):
        return self.interwiki_map[ns.upper()]

    def keys(self):
        return self.interwiki_map.keys()

    # Expansion of positional arguments ($1, $2, ...) in URL and title
    def _expand(self, txt, args):
        """Replace "$1" by the first args, "$2" by the second, etc."""
        def setarg(match):
            num = int(match.group()[1:])
            return args[num - 1] if 0 < num <= len(args) else ''
        return re.sub(InterWikiMap._argspec_re, setarg, txt)

    def _expand_or_append(self, txt, args):
        """Like expand, but also append first arg if there's no "$"."""
        if not args:
            return txt
        expanded = self._expand(txt, args)
        return txt + args[0] if expanded == txt else expanded

    def url(self, ns, target):
        """Return `(url, title)` for the given InterWiki `ns`.

        Expand the colon-separated `target` arguments.
        """
        ns, url, title = self[ns]
        maxargnum = max([0] + [int(a[1:]) for a in
                               re.findall(InterWikiMap._argspec_re, url)])
        target, query, fragment = split_url_into_path_query_fragment(target)
        if maxargnum > 0:
            args = target.split(':', (maxargnum - 1))
        else:
            args = [target]
        url = self._expand_or_append(url, args)
        ntarget, nquery, nfragment = split_url_into_path_query_fragment(url)
        if query and nquery:
            nquery = '%s&%s' % (nquery, query[1:])
        else:
            nquery = nquery or query
        nfragment = fragment or nfragment # user provided takes precedence
        expanded_url = ntarget + nquery + nfragment
        expanded_title = self._expand(title, args)
        if expanded_title == title:
            expanded_title = _("%(target)s in %(name)s",
                               target=target, name=title)
        return expanded_url, expanded_title

    # IWikiChangeListener methods

    def wiki_page_added(self, page):
        if page.name == InterWikiMap._page_name:
            del self.interwiki_map

    def wiki_page_changed(self, page, version, t, comment, author, ipnr):
        if page.name == InterWikiMap._page_name:
            del self.interwiki_map

    def wiki_page_deleted(self, page):
        if page.name == InterWikiMap._page_name:
            del self.interwiki_map

    def wiki_page_version_deleted(self, page):
        if page.name == InterWikiMap._page_name:
            del self.interwiki_map

    @cached
    def interwiki_map(self, db):
        """Map from upper-cased namespaces to (namespace, prefix, title)
        values.
        """
        from trac.wiki.model import WikiPage
        map = {}
        content = WikiPage(self.env, InterWikiMap._page_name, db=db).text
        in_map = False
        for line in content.split('\n'):
            if in_map:
                if line.startswith('----'):
                    in_map = False
                else:
                    m = re.match(InterWikiMap._interwiki_re, line)
                    if m:
                        prefix, url, title = m.groups()
                        url = url.strip()
                        title = title.strip() if title else prefix
                        map[prefix.upper()] = (prefix, url, title)
            elif line.startswith('----'):
                in_map = True
        for prefix, value in self.interwiki_section.options():
            value = value.split(None, 1)
            if value:
                url = value[0].strip()
                title = value[1].strip() if len(value) > 1 else prefix
                map[prefix.upper()] = (prefix, url, title)
        return map

    # IWikiMacroProvider methods

    def get_macros(self):
        yield 'InterWiki'

    def get_macro_description(self, name):
        return 'messages', \
               N_("Provide a description list for the known InterWiki "
                  "prefixes.")

    def expand_macro(self, formatter, name, content):
        interwikis = []
        for k in sorted(self.keys()):
            prefix, url, title = self[k]
            interwikis.append({
                'prefix': prefix, 'url': url, 'title': title,
                'rc_url': self._expand_or_append(url, ['RecentChanges']),
                'description': url if title == prefix else title})

        return tag.table(tag.tr(tag.th(tag.em("Prefix")),
                                tag.th(tag.em("Site"))),
                         [tag.tr(tag.td(tag.a(w['prefix'], href=w['rc_url'])),
                                 tag.td(tag.a(w['description'],
                                              href=w['url'])))
                          for w in interwikis ],
                         class_="wiki interwiki")

########NEW FILE########
__FILENAME__ = macros
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2012 Edgewall Software
# Copyright (C) 2005-2006 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from fnmatch import fnmatchcase
from itertools import groupby
import inspect
import os
import re
from StringIO import StringIO

from genshi.builder import tag
from genshi.core import Markup

from trac.core import *
from trac.resource import (
    Resource, ResourceNotFound, get_resource_name, get_resource_summary,
    get_resource_url
)
from trac.util.datefmt import format_date, from_utimestamp, user_time
from trac.util.html import escape, find_element
from trac.util.presentation import separated
from trac.util.text import unicode_quote, to_unicode, stripws
from trac.util.translation import _, dgettext, cleandoc_
from trac.wiki.api import IWikiMacroProvider, WikiSystem, parse_args
from trac.wiki.formatter import (
    format_to_html, format_to_oneliner, extract_link, OutlineFormatter
)


class WikiMacroBase(Component):
    """Abstract base class for wiki macros."""

    implements(IWikiMacroProvider)
    abstract = True

    #: A gettext domain to translate the macro description
    _domain = None

    #: A macro description
    _description = None

    def get_macros(self):
        """Yield the name of the macro based on the class name."""
        name = self.__class__.__name__
        if name.endswith('Macro'):
            name = name[:-5]
        yield name

    def get_macro_description(self, name):
        """Return the subclass's gettext domain and macro description"""
        domain, description = self._domain, self._description
        if description:
            return (domain, description) if domain else description
        # For pre-0.12 compatibility
        doc = inspect.getdoc(self.__class__)
        return to_unicode(doc) if doc else ''

    def parse_macro(self, parser, name, content):
        raise NotImplementedError

    def expand_macro(self, formatter, name, content):
        raise NotImplementedError(
            "pre-0.11 Wiki macro %s by provider %s no longer supported" %
            (name, self.__class__))



class TitleIndexMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Insert an alphabetic list of all wiki pages into the output.

    Accepts a prefix string as parameter: if provided, only pages with names
    that start with the prefix are included in the resulting list. If this
    parameter is omitted, all pages are listed.
    If the prefix is specified, a second argument of value `hideprefix`
    can be given as well, in order to remove that prefix from the output.

    Alternate `format` and `depth` named parameters can be specified:
     - `format=compact`: The pages are displayed as comma-separated links.
     - `format=group`: The list of pages will be structured in groups
       according to common prefix. This format also supports a `min=n`
       argument, where `n` is the minimal number of pages for a group.
     - `format=hierarchy`: The list of pages will be structured according
       to the page name path hierarchy. This format also supports a `min=n`
       argument, where higher `n` flatten the display hierarchy
     - `depth=n`: limit the depth of the pages to list. If set to 0,
       only toplevel pages will be shown, if set to 1, only immediate
       children pages will be shown, etc. If not set, or set to -1,
       all pages in the hierarchy will be shown.
     - `include=page1:page*2`: include only pages that match an item in the
       colon-separated list of pages. If the list is empty, or if no `include`
       argument is given, include all pages.
     - `exclude=page1:page*2`: exclude pages that match an item in the colon-
       separated list of pages.

    The `include` and `exclude` lists accept shell-style patterns.
    """)

    SPLIT_RE = re.compile(r"(/| )")
    NUM_SPLIT_RE = re.compile(r"([0-9.]+)")

    def expand_macro(self, formatter, name, content):
        args, kw = parse_args(content)
        prefix = args[0].strip() if args else None
        hideprefix = args and len(args) > 1 and args[1].strip() == 'hideprefix'
        minsize = max(int(kw.get('min', 1)), 1)
        minsize_group = max(minsize, 2)
        depth = int(kw.get('depth', -1))
        start = prefix.count('/') if prefix else 0
        format = kw.get('format', '')

        def parse_list(name):
            return [inc.strip() for inc in kw.get(name, '').split(':')
                    if inc.strip()]

        includes = parse_list('include') or ['*']
        excludes = parse_list('exclude')

        if hideprefix:
            omitprefix = lambda page: page[len(prefix):]
        else:
            omitprefix = lambda page: page

        wiki = formatter.wiki

        pages = sorted(page for page in wiki.get_pages(prefix)
                       if (depth < 0 or depth >= page.count('/') - start)
                       and 'WIKI_VIEW' in formatter.perm('wiki', page)
                       and any(fnmatchcase(page, inc) for inc in includes)
                       and not any(fnmatchcase(page, exc) for exc in excludes))

        if format == 'compact':
            return tag(
                separated((tag.a(wiki.format_page_name(omitprefix(p)),
                                 href=formatter.href.wiki(p)) for p in pages),
                          ', '))

        # the function definitions for the different format styles

        # the different page split formats, each corresponding to its rendering
        def split_pages_group(pages):
            """Return a list of (path elements, page_name) pairs,
            where path elements correspond to the page name (without prefix)
            splitted at Camel Case word boundaries, numbers and '/'.
            """
            page_paths = []
            for page in pages:
                path = [elt.strip() for elt in self.SPLIT_RE.split(
                        self.NUM_SPLIT_RE.sub(r" \1 ",
                        wiki.format_page_name(omitprefix(page), split=True)))]
                page_paths.append(([elt for elt in path if elt], page))
            return page_paths

        def split_pages_hierarchy(pages):
            """Return a list of (path elements, page_name) pairs,
            where path elements correspond to the page name (without prefix)
            splitted according to the '/' hierarchy.
            """
            return [(wiki.format_page_name(omitprefix(page)).split("/"), page)
                    for page in pages]

        # the different tree structures, each corresponding to its rendering
        def tree_group(entries):
            """Transform a flat list of entries into a tree structure.

            `entries` is a list of `(path_elements, page_name)` pairs

            Return a list organized in a tree structure, in which:
              - a leaf is a page name
              - a node is a `(key, nodes)` pairs, where:
                - `key` is the leftmost of the path elements, common to the
                  grouped (path element, page_name) entries
                - `nodes` is a list of nodes or leaves
            """
            groups = []

            for key, grouper in groupby(entries, lambda (elts, name):
                                                    elts[0] if elts else ''):
                # remove key from path_elements in grouped entries for further
                # grouping
                grouped_entries = [(path_elements[1:], page_name)
                                   for path_elements, page_name in grouper]

                if key and len(grouped_entries) >= minsize_group:
                    subnodes = tree_group(sorted(grouped_entries))
                    if len(subnodes) == 1:
                        subkey, subnodes = subnodes[0]
                        node = (key + subkey, subnodes)
                        groups.append(node)
                    elif self.SPLIT_RE.match(key):
                        for elt in subnodes:
                            if isinstance(elt, tuple):
                                subkey, subnodes = elt
                                elt = (key + subkey, subnodes)
                            groups.append(elt)
                    else:
                        node = (key, subnodes)
                        groups.append(node)
                else:
                    for path_elements, page_name in grouped_entries:
                        groups.append(page_name)
            return groups

        def tree_hierarchy(entries):
            """Transform a flat list of entries into a tree structure.

            `entries` is a list of `(path_elements, page_name)` pairs

            Return a list organized in a tree structure, in which:
              - a leaf is a `(rest, page)` pair, where:
                - `rest` is the rest of the path to be shown
                - `page` is a page name
              - a node is a `(key, nodes, page)` pair, where:
                - `key` is the leftmost of the path elements, common to the
                  grouped (path element, page_name) entries
                - `page` is a page name (if one exists for that node)
                - `nodes` is a list of nodes or leaves
            """
            groups = []

            for key, grouper in groupby(entries, lambda (elts, name):
                                                    elts[0] if elts else ''):
                grouped_entries  = [e for e in grouper]
                sub_entries  = [e for e in grouped_entries if len(e[0]) > 1]
                key_entries  = [e for e in grouped_entries if len(e[0]) == 1]
                key_entry = key_entries[0] if key_entries else None
                key_page = key_entry[1] if key_entries else None

                if key and len(sub_entries) >= minsize:
                    # remove key from path_elements in grouped entries for
                    # further grouping
                    sub_entries = [(path_elements[1:], page)
                                   for path_elements, page in sub_entries]

                    subnodes = tree_hierarchy(sorted(sub_entries))
                    node = (key, key_page, subnodes)
                    groups.append(node)
                else:
                    if key_entry:
                        groups.append(key_entry)
                    groups.extend(sub_entries)
            return groups

        # the different rendering formats
        def render_group(group):
            return tag.ul(
                tag.li(tag(tag.strong(elt[0].strip('/')), render_group(elt[1]))
                       if isinstance(elt, tuple) else
                       tag.a(wiki.format_page_name(omitprefix(elt)),
                             href=formatter.href.wiki(elt)))
                for elt in group)

        def render_hierarchy(group):
            return tag.ul(
                tag.li(tag(tag.a(elt[0], href=formatter.href.wiki(elt[1]))
                           if elt[1] else tag(elt[0]),
                           render_hierarchy(elt[2]))
                       if len(elt) == 3 else
                       tag.a('/'.join(elt[0]),
                             href=formatter.href.wiki(elt[1])))
                for elt in group)

        transform = {
            'group': lambda p: render_group(tree_group(split_pages_group(p))),
            'hierarchy': lambda p: render_hierarchy(
                                    tree_hierarchy(split_pages_hierarchy(p))),
            }.get(format, None)

        if transform:
            titleindex = transform(pages)
        else:
            titleindex = tag.ul(
                tag.li(tag.a(wiki.format_page_name(omitprefix(page)),
                             href=formatter.href.wiki(page)))
                for page in pages)

        return tag.div(titleindex, class_='titleindex')


class RecentChangesMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """List all pages that have recently been modified, ordered by the
    time they were last modified.

    This macro accepts two ordered arguments and a named argument. The named
    argument can be placed in any position within the argument list.

    The first parameter is a prefix string: if provided, only pages with names
    that start with the prefix are included in the resulting list. If this
    parameter is omitted, all pages are included in the list.

    The second parameter is the maximum number of pages to include in the
    list.

    The `group` parameter determines how the list is presented:
      `group=date` :: The pages are presented in bulleted lists that are
        grouped by date (default).
      `group=none` :: The pages are presented in a single bulleted list.

    Tip: if you only want to specify a maximum number of entries and
    don't want to filter by prefix, specify an empty first parameter,
    e.g. `[[RecentChanges(,10,group=none)]]`.
    """)

    def expand_macro(self, formatter, name, content):
        args, kw = parse_args(content)
        prefix = args[0].strip() if args else None
        limit = int(args[1].strip()) if len(args) > 1 else None
        group = kw.get('group', 'date')

        sql = """SELECT name, max(version) AS max_version,
                        max(time) AS max_time FROM wiki"""
        args = []
        if prefix:
            sql += " WHERE name LIKE %s"
            args.append(prefix + '%')
        sql += " GROUP BY name ORDER BY max_time DESC"
        if limit:
            sql += " LIMIT %s"
            args.append(limit)

        entries_per_date = []
        prevdate = None
        for name, version, ts in self.env.db_query(sql, args):
            if not 'WIKI_VIEW' in formatter.perm('wiki', name, version):
                continue
            req = formatter.req
            date = user_time(req, format_date, from_utimestamp(ts))
            if date != prevdate:
                prevdate = date
                entries_per_date.append((date, []))
            version = int(version)
            diff_href = None
            if version > 1:
                diff_href = formatter.href.wiki(name, action='diff',
                                                version=version)
            page_name = formatter.wiki.format_page_name(name)
            entries_per_date[-1][1].append((page_name, name, version,
                                            diff_href))

        items_per_date = (
            (date, (tag.li(tag.a(page, href=formatter.href.wiki(name)),
                           tag.small(' (', tag.a('diff', href=diff_href), ')')
                           if diff_href else None, '\n')
                    for page, name, version, diff_href in entries))
            for date, entries in entries_per_date)

        if group == 'date':
            out = ((tag.h3(date), tag.ul(entries))
                   for date, entries in items_per_date)
        else:
            out = tag.ul((entries)
                         for date, entries in items_per_date)
        return tag.div(out)


class PageOutlineMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Display a structural outline of the current wiki page, each item in the
    outline being a link to the corresponding heading.

    This macro accepts four optional parameters:

     * The first is a number or range that allows configuring the minimum and
       maximum level of headings that should be included in the outline. For
       example, specifying "1" here will result in only the top-level headings
       being included in the outline. Specifying "2-3" will make the outline
       include all headings of level 2 and 3, as a nested list. The default is
       to include all heading levels.
     * The second parameter can be used to specify a custom title (the default
       is no title).
     * The third parameter selects the style of the outline. This can be
       either `inline` or `pullout` (the latter being the default). The
       `inline` style renders the outline as normal part of the content, while
       `pullout` causes the outline to be rendered in a box that is by default
       floated to the right side of the other content.
     * The fourth parameter specifies whether the outline is numbered or not.
       It can be either `numbered` or `unnumbered` (the former being the
       default). This parameter only has an effect in `inline` style.
    """)

    def expand_macro(self, formatter, name, content):
        min_depth, max_depth = 1, 6
        title = None
        inline = False
        numbered = True
        if content:
            argv = [arg.strip() for arg in content.split(',')]
            if len(argv) > 0:
                depth = argv[0]
                if '-' in depth:
                    min_depth, max_depth = [int(d)
                                            for d in depth.split('-', 1)]
                else:
                    min_depth = max_depth = int(depth)
                if len(argv) > 1:
                    title = argv[1].strip()
                    for arg in argv[2:]:
                        arg = arg.strip().lower()
                        if arg == 'inline':
                            inline = True
                        elif arg == 'unnumbered':
                            numbered = False

        # TODO: - integrate the rest of the OutlineFormatter directly here
        #       - use formatter.wikidom instead of formatter.source
        out = StringIO()
        oformatter = OutlineFormatter(self.env, formatter.context)
        oformatter.format(formatter.source, out, max_depth, min_depth,
                          shorten=not inline)
        outline = Markup(out.getvalue())

        if title:
            outline = tag.h4(title) + outline
        if not inline:
            outline = tag.div(outline, class_='wiki-toc')
        elif not numbered:
            outline = tag.div(outline, class_='wiki-toc-un')
        return outline


class ImageMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Embed an image in wiki-formatted text.

    The first argument is the file specification. The file specification may
    reference attachments in three ways:
     * `module:id:file`, where module can be either '''wiki''' or '''ticket''',
       to refer to the attachment named ''file'' of the specified wiki page or
       ticket.
     * `id:file`: same as above, but id is either a ticket shorthand or a Wiki
       page name.
     * `file` to refer to a local attachment named 'file'. This only works from
       within that wiki page or a ticket.

    Also, the file specification may refer to repository files, using the
    `source:file` syntax (`source:file@rev` works also).

    Files can also be accessed with a direct URLs; `/file` for a
    project-relative, `//file` for a server-relative, or `http://server/file`
    for absolute location of the file.

    The remaining arguments are optional and allow configuring the attributes
    and style of the rendered `<img>` element:
     * digits and unit are interpreted as the size (ex. 120, 25%)
       for the image
     * `right`, `left`, `center`, `top`, `bottom` and `middle` are interpreted
       as the alignment for the image (alternatively, the first three can be
       specified using `align=...` and the last three using `valign=...`)
     * `link=some TracLinks...` replaces the link to the image source by the
       one specified using a TracLinks. If no value is specified, the link is
       simply removed.
     * `nolink` means without link to image source (deprecated, use `link=`)
     * `key=value` style are interpreted as HTML attributes or CSS style
       indications for the image. Valid keys are:
        * align, valign, border, width, height, alt, title, longdesc, class,
          margin, margin-(left,right,top,bottom), id and usemap
        * `border`, `margin`, and `margin-`* can only be a single number
        * `margin` is superseded by `center` which uses auto margins

    Examples:
    {{{
        [[Image(photo.jpg)]]                           # simplest
        [[Image(photo.jpg, 120px)]]                    # with image width size
        [[Image(photo.jpg, right)]]                    # aligned by keyword
        [[Image(photo.jpg, nolink)]]                   # without link to source
        [[Image(photo.jpg, align=right)]]              # aligned by attribute
    }}}

    You can use image from other page, other ticket or other module.
    {{{
        [[Image(OtherPage:foo.bmp)]]    # if current module is wiki
        [[Image(base/sub:bar.bmp)]]     # from hierarchical wiki page
        [[Image(#3:baz.bmp)]]           # if in a ticket, point to #3
        [[Image(ticket:36:boo.jpg)]]
        [[Image(source:/images/bee.jpg)]] # straight from the repository!
        [[Image(htdocs:foo/bar.png)]]   # image file in project htdocs dir.
    }}}

    ''Adapted from the Image.py macro created by Shun-ichi Goto
    <gotoh@taiyo.co.jp>''
    """)

    def is_inline(self, content):
        return True

    def expand_macro(self, formatter, name, content):
        # args will be null if the macro is called without parenthesis.
        if not content:
            return ''
        # parse arguments
        # we expect the 1st argument to be a filename (filespec)
        args = content.split(',')
        if len(args) == 0:
            raise Exception("No argument.")
        # strip unicode white-spaces and ZWSPs are copied from attachments
        # section (#10668)
        filespec = stripws(args.pop(0))

        # style information
        size_re = re.compile('[0-9]+(%|px)?$')
        attr_re = re.compile('(align|valign|border|width|height|alt'
                             '|margin(?:-(?:left|right|top|bottom))?'
                             '|title|longdesc|class|id|usemap)=(.+)')
        quoted_re = re.compile("(?:[\"'])(.*)(?:[\"'])$")
        attr = {}
        style = {}
        link = ''
        # helper for the special case `source:`
        #
        from trac.versioncontrol.web_ui import BrowserModule
        # FIXME: somehow use ResourceSystem.get_known_realms()
        #        ... or directly trac.wiki.extract_link
        try:
            browser_links = [res[0] for res in
                             BrowserModule(self.env).get_link_resolvers()]
        except Exception:
            browser_links = []
        while args:
            arg = args.pop(0).strip()
            if size_re.match(arg):
                # 'width' keyword
                attr['width'] = arg
            elif arg == 'nolink':
                link = None
            elif arg.startswith('link='):
                val = arg.split('=', 1)[1]
                elt = extract_link(self.env, formatter.context, val.strip())
                elt = find_element(elt, 'href')
                link = None
                if elt is not None:
                    link = elt.attrib.get('href')
            elif arg in ('left', 'right'):
                style['float'] = arg
            elif arg == 'center':
                style['margin-left'] = style['margin-right'] = 'auto'
                style['display'] = 'block'
                style.pop('margin', '')
            elif arg in ('top', 'bottom', 'middle'):
                style['vertical-align'] = arg
            else:
                match = attr_re.match(arg)
                if match:
                    key, val = match.groups()
                    if (key == 'align' and
                            val in ('left', 'right', 'center')) or \
                        (key == 'valign' and \
                            val in ('top', 'middle', 'bottom')):
                        args.append(val)
                    elif key in ('margin-top', 'margin-bottom'):
                        style[key] = ' %dpx' % int(val)
                    elif key in ('margin', 'margin-left', 'margin-right') \
                             and 'display' not in style:
                        style[key] = ' %dpx' % int(val)
                    elif key == 'border':
                        style['border'] = ' %dpx solid' % int(val)
                    else:
                        m = quoted_re.search(val) # unquote "..." and '...'
                        if m:
                            val = m.group(1)
                        attr[str(key)] = val # will be used as a __call__ kwd

        # parse filespec argument to get realm and id if contained.
        parts = filespec.split(':')
        url = raw_url = desc = None
        attachment = None
        if (parts and parts[0] in ('http', 'https', 'ftp')): # absolute
            raw_url = url = filespec
            desc = url.rsplit('?')[0]
        elif filespec.startswith('//'):       # server-relative
            raw_url = url = filespec[1:]
            desc = url.rsplit('?')[0]
        elif filespec.startswith('/'):        # project-relative
            params = ''
            if '?' in filespec:
                filespec, params = filespec.rsplit('?', 1)
            url = formatter.href(filespec)
            if params:
                url += '?' + params
            raw_url, desc = url, filespec
        elif len(parts) == 3:                 # realm:id:attachment-filename
            #                                 # or intertrac:realm:id
            realm, id, filename = parts
            intertrac_target = "%s:%s" % (id, filename)
            it = formatter.get_intertrac_url(realm, intertrac_target)
            if it:
                url, desc = it
                raw_url = url + unicode_quote('?format=raw')
            else:
                attachment = Resource(realm, id).child('attachment', filename)
        elif len(parts) == 2:
            realm, filename = parts
            if realm in browser_links:   # source:path
                # TODO: use context here as well
                rev = None
                if '@' in filename:
                    filename, rev = filename.rsplit('@', 1)
                url = formatter.href.browser(filename, rev=rev)
                raw_url = formatter.href.browser(filename, rev=rev,
                                                 format='raw')
                desc = filespec
            else: # #ticket:attachment or WikiPage:attachment
                # FIXME: do something generic about shorthand forms...
                realm = None
                id, filename = parts
                if id and id[0] == '#':
                    realm = 'ticket'
                    id = id[1:]
                elif id == 'htdocs':
                    raw_url = url = formatter.href.chrome('site', filename)
                    desc = os.path.basename(filename)
                else:
                    realm = 'wiki'
                if realm:
                    attachment = Resource(realm, id).child('attachment',
                                                           filename)
        elif len(parts) == 1: # it's an attachment of the current resource
            attachment = formatter.resource.child('attachment', filespec)
        else:
            raise TracError('No filespec given')
        if attachment and 'ATTACHMENT_VIEW' in formatter.perm(attachment):
            url = get_resource_url(self.env, attachment, formatter.href)
            raw_url = get_resource_url(self.env, attachment, formatter.href,
                                       format='raw')
            try:
                desc = get_resource_summary(self.env, attachment)
            except ResourceNotFound, e:
                raw_url = formatter.href.chrome('common/attachment.png')
                desc = _('No image "%(id)s" attached to %(parent)s',
                         id=attachment.id,
                         parent=get_resource_name(self.env, attachment.parent))
        for key in ('title', 'alt'):
            if desc and not key in attr:
                attr[key] = desc
        if style:
            attr['style'] = '; '.join('%s:%s' % (k, escape(v))
                                      for k, v in style.iteritems())
        result = tag.img(src=raw_url, **attr)
        if link is not None:
            result = tag.a(result, href=link or url,
                           style='padding:0; border:none')
        return result


class MacroListMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Display a list of all installed Wiki macros, including documentation if
    available.

    Optionally, the name of a specific macro can be provided as an argument. In
    that case, only the documentation for that macro will be rendered.

    Note that this macro will not be able to display the documentation of
    macros if the `PythonOptimize` option is enabled for mod_python!
    """)

    def expand_macro(self, formatter, name, content):
        from trac.wiki.formatter import system_message

        content = content.strip() if content else ''
        name_filter = content.strip('*')

        def get_macro_descr():
            for macro_provider in formatter.wiki.macro_providers:
                names = list(macro_provider.get_macros() or [])
                if name_filter and not any(name.startswith(name_filter)
                                           for name in names):
                    continue
                try:
                    name_descriptions = [
                        (name, macro_provider.get_macro_description(name))
                        for name in names]
                except Exception, e:
                    yield system_message(
                        _("Error: Can't get description for macro %(name)s",
                          name=names[0]), e), names
                else:
                    for descr, pairs in groupby(name_descriptions,
                                                key=lambda p: p[1]):
                        if descr:
                            if isinstance(descr, (tuple, list)):
                                descr = dgettext(descr[0],
                                                 to_unicode(descr[1])) \
                                        if descr[1] else ''
                            else:
                                descr = to_unicode(descr) or ''
                            if content == '*':
                                descr = format_to_oneliner(
                                    self.env, formatter.context, descr,
                                    shorten=True)
                            else:
                                descr = format_to_html(
                                    self.env, formatter.context, descr)
                        yield descr, [name for name, descr in pairs]

        return tag.div(class_='trac-macrolist')(
            (tag.h3(tag.code('[[', names[0], ']]'), id='%s-macro' % names[0]),
             len(names) > 1 and tag.p(tag.strong(_("Aliases:")),
                                      [tag.code(' [[', alias, ']]')
                                       for alias in names[1:]]) or None,
             description or tag.em(_("Sorry, no documentation found")))
            for description, names in sorted(get_macro_descr(),
                                             key=lambda item: item[1][0]))


class TracIniMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Produce documentation for the Trac configuration file.

    Typically, this will be used in the TracIni page.
    Optional arguments are a configuration section filter,
    and a configuration option name filter: only the configuration
    options whose section and name start with the filters are output.
    """)

    def expand_macro(self, formatter, name, args):
        from trac.config import ConfigSection, Option
        section_filter = key_filter = ''
        args, kw = parse_args(args)
        if args:
            section_filter = args.pop(0).strip()
        if args:
            key_filter = args.pop(0).strip()

        def getdoc(option_or_section):
            doc = to_unicode(option_or_section.__doc__)
            if doc:
                doc = dgettext(option_or_section.doc_domain, doc)
            return doc

        registry = ConfigSection.get_registry(self.compmgr)
        sections = dict((name, getdoc(section))
                        for name, section in registry.iteritems()
                        if name.startswith(section_filter))

        registry = Option.get_registry(self.compmgr)
        options = {}
        for (section, key), option in registry.iteritems():
            if section.startswith(section_filter):
                options.setdefault(section, {})[key] = option
                sections.setdefault(section, '')

        def default_cell(option):
            default = option.default
            if default is True:
                default = 'true'
            elif default is False:
                default = 'false'
            elif default == 0:
                default = '0.0' if isinstance(default, float) else '0'
            elif default:
                default = ', '.join(to_unicode(val) for val in default) \
                          if isinstance(default, (list, tuple)) \
                          else to_unicode(default)
            else:
                return tag.td(_("(no default)"), class_='nodefault')
            return tag.td(tag.code(default), class_='default')

        return tag.div(class_='tracini')(
            (tag.h3(tag.code('[%s]' % section), id='%s-section' % section),
             format_to_html(self.env, formatter.context, section_doc),
             tag.table(class_='wiki')(tag.tbody(
                 tag.tr(tag.td(tag.tt(option.name)),
                        tag.td(format_to_oneliner(
                            self.env, formatter.context, getdoc(option))),
                        default_cell(option))
                 for option in sorted(options.get(section, {}).itervalues(),
                                      key=lambda o: o.name)
                 if option.name.startswith(key_filter))))
            for section, section_doc in sorted(sections.iteritems()))



class KnownMimeTypesMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """List all known mime-types which can be used as WikiProcessors.

    Can be given an optional argument which is interpreted as mime-type filter.
    """)

    def expand_macro(self, formatter, name, args):
        from trac.mimeview.api import Mimeview
        mime_map = Mimeview(self.env).mime_map
        mime_type_filter = ''
        args, kw = parse_args(args)
        if args:
            mime_type_filter = args.pop(0).strip().rstrip('*')

        mime_types = {}
        for key, mime_type in mime_map.iteritems():
            if (not mime_type_filter or
                mime_type.startswith(mime_type_filter)) and key != mime_type:
                mime_types.setdefault(mime_type, []).append(key)

        return tag.div(class_='mimetypes')(
            tag.table(class_='wiki')(
                tag.thead(tag.tr(
                    tag.th(_("MIME Types")), # always use plural
                    tag.th(tag.a("WikiProcessors",
                                 href=formatter.context.href.wiki(
                                     'WikiProcessors'))))),
                tag.tbody(
                    tag.tr(tag.th(tag.tt(mime_type),
                                  style="text-align: left"),
                           tag.td(tag.code(
                               ' '.join(sorted(mime_types[mime_type])))))
                    for mime_type in sorted(mime_types.keys()))))



class TracGuideTocMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Display a table of content for the Trac guide.

    This macro shows a quick and dirty way to make a table-of-contents
    for the Help/Guide. The table of contents will contain the Trac* and
    WikiFormatting pages, and can't be customized. Search for TocMacro for a
    a more customizable table of contents.
    """)

    TOC = [('TracGuide',                    'Index'),
           ('TracInstall',                  'Installation'),
           ('TracInterfaceCustomization',   'Customization'),
           ('TracPlugins',                  'Plugins'),
           ('TracUpgrade',                  'Upgrading'),
           ('TracIni',                      'Configuration'),
           ('TracAdmin',                    'Administration'),
           ('TracBackup',                   'Backup'),
           ('TracLogging',                  'Logging'),
           ('TracPermissions' ,             'Permissions'),
           ('TracWiki',                     'The Wiki'),
           ('WikiFormatting',               'Wiki Formatting'),
           ('TracTimeline',                 'Timeline'),
           ('TracBrowser',                  'Repository Browser'),
           ('TracRevisionLog',              'Revision Log'),
           ('TracChangeset',                'Changesets'),
           ('TracTickets',                  'Tickets'),
           ('TracWorkflow',                 'Workflow'),
           ('TracRoadmap',                  'Roadmap'),
           ('TracQuery',                    'Ticket Queries'),
           ('TracBatchModify',              'Batch Modify'),
           ('TracReports',                  'Reports'),
           ('TracRss',                      'RSS Support'),
           ('TracNotification',             'Notification'),
          ]

    def expand_macro(self, formatter, name, args):
        curpage = formatter.resource.id

        # scoped TOC (e.g. TranslateRu/TracGuide or 0.11/TracGuide ...)
        prefix = ''
        idx = curpage.find('/')
        if idx > 0:
            prefix = curpage[:idx+1]

        ws = WikiSystem(self.env)
        return tag.div(
            tag.h4(_('Table of Contents')),
            tag.ul([tag.li(tag.a(title, href=formatter.href.wiki(prefix+ref),
                                 class_=(not ws.has_page(prefix+ref) and
                                         'missing')),
                           class_=(prefix+ref == curpage and 'active'))
                    for ref, title in self.TOC]),
            class_='wiki-toc')

########NEW FILE########
__FILENAME__ = model
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

from datetime import datetime

from trac.core import *
from trac.resource import Resource, ResourceSystem
from trac.util.datefmt import from_utimestamp, to_utimestamp, utc
from trac.util.translation import _
from trac.wiki.api import WikiSystem, validate_page_name


class WikiPage(object):
    """Represents a wiki page (new or existing)."""

    realm = 'wiki'

    def __init__(self, env, name=None, version=None, db=None):
        self.env = env
        if isinstance(name, Resource):
            self.resource = name
            name = self.resource.id
        else:
            if version:
                version = int(version) # must be a number or None
            self.resource = Resource('wiki', name, version)
        self.name = name
        if name:
            self._fetch(name, version, db)
        else:
            self.version = 0
            self.text = self.comment = self.author = ''
            self.time = None
            self.readonly = 0
        self.old_text = self.text
        self.old_readonly = self.readonly

    def _fetch(self, name, version=None, db=None):
        if version is not None:
            sql = """SELECT version, time, author, text, comment, readonly
                     FROM wiki WHERE name=%s AND version=%s"""
            args = (name, int(version))
        else:
            sql = """SELECT version, time, author, text, comment, readonly
                     FROM wiki WHERE name=%s ORDER BY version DESC LIMIT 1"""
            args = (name,)
        for version, time, author, text, comment, readonly in \
                self.env.db_query(sql, args):
            self.version = int(version)
            self.author = author
            self.time = from_utimestamp(time)
            self.text = text
            self.comment = comment
            self.readonly = int(readonly) if readonly else 0
            break
        else:
            self.version = 0
            self.text = self.comment = self.author = ''
            self.time = None
            self.readonly = 0

    exists = property(lambda self: self.version > 0)

    def delete(self, version=None, db=None):
        """Delete one or all versions of a page.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        assert self.exists, "Cannot delete non-existent page"

        with self.env.db_transaction as db:
            if version is None:
                # Delete a wiki page completely
                db("DELETE FROM wiki WHERE name=%s", (self.name,))
                self.env.log.info("Deleted page %s", self.name)
            else:
                # Delete only a specific page version
                db("DELETE FROM wiki WHERE name=%s and version=%s",
                   (self.name, version))
                self.env.log.info("Deleted version %d of page %s", version,
                                  self.name)

            if version is None or version == self.version:
                self._fetch(self.name, None)

            if not self.exists:
                # Invalidate page name cache
                del WikiSystem(self.env).pages
                # Delete orphaned attachments
                from trac.attachment import Attachment
                Attachment.delete_all(self.env, 'wiki', self.name)

        # Let change listeners know about the deletion
        if not self.exists:
            for listener in WikiSystem(self.env).change_listeners:
                listener.wiki_page_deleted(self)
            ResourceSystem(self.env).resource_deleted(self)
        else:
            for listener in WikiSystem(self.env).change_listeners:
                if hasattr(listener, 'wiki_page_version_deleted'):
                    listener.wiki_page_version_deleted(self)
            ResourceSystem(self.env).resource_version_deleted(self)

    def save(self, author, comment, remote_addr, t=None, db=None):
        """Save a new version of a page.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        if not validate_page_name(self.name):
            raise TracError(_("Invalid Wiki page name '%(name)s'",
                              name=self.name))

        new_text = self.text != self.old_text
        if not new_text and self.readonly == self.old_readonly:
            raise TracError(_("Page not modified"))
        t = t or datetime.now(utc)

        with self.env.db_transaction as db:
            if new_text:
                db("""INSERT INTO wiki (name, version, time, author, ipnr,
                                        text, comment, readonly)
                      VALUES (%s,%s,%s,%s,%s,%s,%s,%s)
                      """, (self.name, self.version + 1, to_utimestamp(t),
                            author, remote_addr, self.text, comment,
                            self.readonly))
                self.version += 1
                self.resource = self.resource(version=self.version)
            else:
                db("UPDATE wiki SET readonly=%s WHERE name=%s",
                   (self.readonly, self.name))
            if self.version == 1:
                # Invalidate page name cache
                del WikiSystem(self.env).pages

        self.author = author
        self.comment = comment
        self.time = t

        for listener in WikiSystem(self.env).change_listeners:
            if self.version == 1:
                listener.wiki_page_added(self)
            else:
                listener.wiki_page_changed(self, self.version, t, comment,
                                           author, remote_addr)
        context=dict(
            version=self.version,
            time=t,
            comment=comment,
            author=author,
            remote_addr=remote_addr)
        if self.version == 1:
            ResourceSystem(self.env).resource_created(self, context)
        else:
            old_values = dict()
            if self.readonly != self.old_readonly:
                old_values["readonly"] = self.old_readonly
            if self.text != self.old_text:
                old_values["text"] = self.old_text
            ResourceSystem(self.env).resource_changed(
                self,
                old_values,
                context)

        self.old_readonly = self.readonly
        self.old_text = self.text

    def rename(self, new_name):
        """Rename wiki page in-place, keeping the history intact.
        Renaming a page this way will eventually leave dangling references
        to the old page - which litterally doesn't exist anymore.
        """
        assert self.exists, "Cannot rename non-existent page"

        if not validate_page_name(new_name):
            raise TracError(_("Invalid Wiki page name '%(name)s'",
                              name=new_name))
        old_name = self.name

        with self.env.db_transaction as db:
            new_page = WikiPage(self.env, new_name)
            if new_page.exists:
                raise TracError(_("Can't rename to existing %(name)s page.",
                                  name=new_name))

            db("UPDATE wiki SET name=%s WHERE name=%s", (new_name, old_name))
            # Invalidate page name cache
            del WikiSystem(self.env).pages
            # Reparent attachments
            from trac.attachment import Attachment
            Attachment.reparent_all(self.env, 'wiki', old_name, 'wiki',
                                    new_name)

        self.name = new_name
        self.env.log.info('Renamed page %s to %s', old_name, new_name)

        for listener in WikiSystem(self.env).change_listeners:
            if hasattr(listener, 'wiki_page_renamed'):
                listener.wiki_page_renamed(self, old_name)

        ResourceSystem(self.env).resource_changed(
            self,
            dict(name=old_name)
        )

    def get_history(self, db=None):
        """Retrieve the edit history of a wiki page.

        :since 1.0: the `db` parameter is no longer needed and will be removed
        in version 1.1.1
        """
        for version, ts, author, comment, ipnr in self.env.db_query("""
                SELECT version, time, author, comment, ipnr FROM wiki
                WHERE name=%s AND version<=%s ORDER BY version DESC
                """, (self.name, self.version)):
            yield version, from_utimestamp(ts), author, comment, ipnr

########NEW FILE########
__FILENAME__ = parser
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2003-2006 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2006 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>
#         Christian Boos <cboos@edgewall.org>

import re

from trac.core import *
from trac.notification import EMAIL_LOOKALIKE_PATTERN

class WikiParser(Component):
    """Wiki text parser."""

    # Some constants used for clarifying the Wiki regexps:

    BOLDITALIC_TOKEN = "'''''"
    BOLD_TOKEN = "'''"
    BOLD_TOKEN_WIKICREOLE = r"\*\*"
    ITALIC_TOKEN = "''"
    ITALIC_TOKEN_WIKICREOLE = "//"
    UNDERLINE_TOKEN = "__"
    STRIKE_TOKEN = "~~"
    SUBSCRIPT_TOKEN = ",,"
    SUPERSCRIPT_TOKEN = r"\^"
    INLINE_TOKEN = "`" # must be a single char (see P<definition> below)
    STARTBLOCK_TOKEN = r"\{\{\{"
    STARTBLOCK = "{{{"
    ENDBLOCK_TOKEN = r"\}\}\}"
    ENDBLOCK = "}}}"
    BULLET_CHARS = u"-*\u2022"

    LINK_SCHEME = r"[a-zA-Z][-a-zA-Z0-9+._]*" # as per RFC 2396 + '_'
    INTERTRAC_SCHEME = r"[a-zA-Z.+-]*?" # no digits (for shorthand links)

    QUOTED_STRING = r"'[^']+'|\"[^\"]+\""

    SHREF_TARGET_FIRST = r"[\w/?!#@](?<!_)" # we don't want "_"
    SHREF_TARGET_MIDDLE = r"(?:\|(?=[^|\s])|[^|<>\s])"
    SHREF_TARGET_LAST = r"[\w/=](?<!_)" # we don't want "_"

    def _lhref_relative_target(sep):
        return r"[/\?#][^%s\]]*|\.\.?(?:[/\?#][^%s\]]*)?" % (sep, sep)

    LHREF_RELATIVE_TARGET = _lhref_relative_target(r'\s')

    XML_NAME = r"[\w:](?<!\d)[\w:.-]*?" # See http://www.w3.org/TR/REC-xml/#id

    PROCESSOR = r"(\s*)#\!([\w+-][\w+-/]*)"
    PROCESSOR_PARAM = r'''(?P<proc_pname>\w+)=(?P<proc_pval>".*?"|'.*?'|\w+)'''

    def _set_anchor(name, sep):
        return r'=#(?P<anchorname>%s)(?:%s(?P<anchorlabel>[^\]]*))?' % \
               (name, sep)

    # Sequence of regexps used by the engine

    _pre_rules = [
        # Font styles
        r"(?P<bolditalic>!?%s)" % BOLDITALIC_TOKEN,
        r"(?P<bold>!?%s)" % BOLD_TOKEN,
        r"(?P<bold_wc>!?%s)" % BOLD_TOKEN_WIKICREOLE,
        r"(?P<italic>!?%s)" % ITALIC_TOKEN,
        r"(?P<italic_wc>!?%s)" % ITALIC_TOKEN_WIKICREOLE,
        r"(?P<underline>!?%s)" % UNDERLINE_TOKEN,
        r"(?P<strike>!?%s)" % STRIKE_TOKEN,
        r"(?P<subscript>!?%s)" % SUBSCRIPT_TOKEN,
        r"(?P<superscript>!?%s)" % SUPERSCRIPT_TOKEN,
        r"(?P<inlinecode>!?%s(?P<inline>.*?)%s)" \
        % (STARTBLOCK_TOKEN, ENDBLOCK_TOKEN),
        r"(?P<inlinecode2>!?%s(?P<inline2>.*?)%s)" \
        % (INLINE_TOKEN, INLINE_TOKEN),
        ]

    # Rules provided by IWikiSyntaxProviders will be inserted here

    _post_rules = [
        # WikiCreole line breaks
        r"(?P<linebreak_wc>!?\\\\)",
        # e-mails
        r"(?P<email>!?%s)" % EMAIL_LOOKALIKE_PATTERN,
        # <wiki:Trac bracket links>
        r"(?P<shrefbr>!?<(?P<snsbr>%s):(?P<stgtbr>[^>]+)>)" % LINK_SCHEME,
        # &, < and > to &amp;, &lt; and &gt;
        r"(?P<htmlescape>[&<>])",
        # wiki:TracLinks or intertrac:wiki:TracLinks
        r"(?P<shref>!?((?P<sns>%s):(?P<stgt>%s:(?:%s)|%s|%s(?:%s*%s)?)))" \
        % (LINK_SCHEME, LINK_SCHEME, QUOTED_STRING, QUOTED_STRING,
           SHREF_TARGET_FIRST, SHREF_TARGET_MIDDLE, SHREF_TARGET_LAST),
        # [wiki:TracLinks with optional label] or [/relative label]
        (r"(?P<lhref>!?\[(?:"
         r"(?P<rel>%s)|" % LHREF_RELATIVE_TARGET + # ./... or /...
         r"(?P<lns>%s):(?P<ltgt>%s:(?:%s)|%s|[^\]\s\%s]*))" % \
         (LINK_SCHEME, LINK_SCHEME, QUOTED_STRING, QUOTED_STRING, u'\u200b') +
         # wiki:TracLinks or wiki:"trac links" or intertrac:wiki:"trac links"
         r"(?:[\s%s]+(?P<label>%s|[^\]]*))?\])" % \
         (u'\u200b', QUOTED_STRING)), # trailing space, optional label
        # [=#anchor] creation
        r"(?P<anchor>!?\[%s\])" % _set_anchor(XML_NAME, r'\s+'),
        # [[macro]] call or [[WikiCreole link]]
        (r"(?P<macrolink>!?\[\[(?:[^]]|][^]])+\]\])"),
        # == heading == #hanchor
        r"(?P<heading>^\s*(?P<hdepth>={1,6})\s(?P<htext>.*?)"
        r"(?P<hanchor>#%s)?\s*$)" % XML_NAME,
        #  * list
        r"(?P<list>^(?P<ldepth>\s*)"
        ur"(?:[%s]|(?P<lstart>[0-9]+|[a-zA-Z]|[ivxIVX]{1,5})\.)\s)"
        % (BULLET_CHARS),
        # definition::
        r"(?P<definition>^\s+"
        r"((?:%s[^%s]*%s|%s(?:%s{,2}[^%s])*?%s|[^%s%s:]|:[^:])+::)(?:\s+|$))"
        % (INLINE_TOKEN, INLINE_TOKEN, INLINE_TOKEN,
           STARTBLOCK_TOKEN, ENDBLOCK[0], ENDBLOCK[0], ENDBLOCK_TOKEN,
           INLINE_TOKEN, STARTBLOCK[0]),
        # |- row separator
        r"(?P<table_row_sep>!?\s*\|-+\s*"
        r"(?P<table_row_params>%s\s*)*)" % PROCESSOR_PARAM,
        # (leading space)
        r"(?P<indent>^(?P<idepth>\s+)(?=\S))",
        # || table ||
        r"(?P<table_cell>!?(?P<table_cell_sep>=?(?:\|\|)+=?)"
        r"(?P<table_cell_last>\s*\\?$)?)",
        ]

    _processor_re = re.compile(PROCESSOR)
    _startblock_re = re.compile(r"\s*%s(?:%s|\s*$)" %
                                (STARTBLOCK, PROCESSOR))
    _processor_param_re = re.compile(PROCESSOR_PARAM)
    _anchor_re = re.compile(r'[^\w:.-]+', re.UNICODE)

    _macro_re = re.compile(r'''
        (?P<macroname> [\w/+-]+ \?? | \? )     # macro, macro? or ?
          (?: \( (?P<macroargs> .*? ) \) )? $  # optional arguments within ()
    ''', re.VERBOSE)

    _creolelink_re = re.compile(r'''
        (?:
          (?P<rel> %(rel)s )                # rel is "./..." or "/..."
        | (?: (?P<lns> %(scheme)s ) : )?    # lns is the optional "scheme:"
            (?P<ltgt>                       # ltgt is the optional target
              %(scheme)s : (?:%(quoted)s)   #   - "scheme:'...quoted..'"
            | %(quoted)s                    #   - "'...quoted...'"
            | [^|]+                         #   - anything but a '|'
            )?
        )
        \s* (?: \| (?P<label> .* ) )?       # optional label after a '|'
        $
        ''' % {'rel': _lhref_relative_target(r'|'),
               'scheme': LINK_SCHEME,
               'quoted': QUOTED_STRING}, re.VERBOSE)

    _set_anchor_wc_re = re.compile(_set_anchor(XML_NAME, r'\|\s*') + r'$')

    def __init__(self):
        self._compiled_rules = None
        self._link_resolvers = None
        self._helper_patterns = None
        self._external_handlers = None

    @property
    def rules(self):
        self._prepare_rules()
        return self._compiled_rules

    @property
    def helper_patterns(self):
        self._prepare_rules()
        return self._helper_patterns

    @property
    def external_handlers(self):
        self._prepare_rules()
        return self._external_handlers

    def _prepare_rules(self):
        from trac.wiki.api import WikiSystem
        if not self._compiled_rules:
            helpers = []
            handlers = {}
            syntax = self._pre_rules[:]
            i = 0
            for resolver in WikiSystem(self.env).syntax_providers:
                for regexp, handler in resolver.get_wiki_syntax() or []:
                    handlers['i' + str(i)] = handler
                    syntax.append('(?P<i%d>%s)' % (i, regexp))
                    i += 1
            syntax += self._post_rules[:]
            helper_re = re.compile(r'\?P<([a-z\d_]+)>')
            for rule in syntax:
                helpers += helper_re.findall(rule)[1:]
            rules = re.compile('(?:' + '|'.join(syntax) + ')', re.UNICODE)
            self._external_handlers = handlers
            self._helper_patterns = helpers
            self._compiled_rules = rules

    @property
    def link_resolvers(self):
        if not self._link_resolvers:
            from trac.wiki.api import WikiSystem
            resolvers = {}
            for resolver in WikiSystem(self.env).syntax_providers:
                for namespace, handler in resolver.get_link_resolvers() or []:
                    resolvers[namespace] = handler
            self._link_resolvers = resolvers
        return self._link_resolvers

    def parse(self, wikitext):
        """Parse `wikitext` and produce a WikiDOM tree."""
        # obviously still some work to do here ;)
        return wikitext


def parse_processor_args(processor_args):
    """Parse a string containing parameter assignments,
    and return the corresponding dictionary.

    Isolated keywords are interpreted as `bool` flags, `False` if the keyword
    is prefixed with "-", `True` otherwise.

    >>> parse_processor_args('ab="c de -f gh=ij" -')
    {'ab': 'c de -f gh=ij'}

    >>> sorted(parse_processor_args('ab=c de -f gh="ij klmn"').items())
    [('ab', 'c'), ('de', True), ('f', False), ('gh', 'ij klmn')]
    """
    args = WikiParser._processor_param_re.split(processor_args)
    keys = [str(k) for k in args[1::3]] # used as keyword parameters
    values = [v[1:-1] if v[:1] + v[-1:] in ('""', "''") else v
              for v in args[2::3]]
    for flags in args[::3]:
        for flag in flags.strip().split():
            if re.match(r'-?\w+$', flag):
                if flag[0] == '-':
                    if len(flag) > 1:
                        keys.append(str(flag[1:]))
                        values.append(False)
                else:
                    keys.append(str(flag))
                    values.append(True)
    return dict(zip(keys, values))

########NEW FILE########
__FILENAME__ = formatter
import difflib
import os
import re
import unittest

# Python 2.7 `assertMultiLineEqual` calls `safe_repr(..., short=True)`
# which breaks our custom failure display in WikiTestCase.

try:
    from unittest.util import safe_repr
    unittest.case.safe_repr = lambda obj, short=False: safe_repr(obj, False)
except ImportError:
    pass

from datetime import datetime

from trac.core import *
from trac.test import Mock, MockPerm, EnvironmentStub, locale_en
from trac.util.datefmt import utc
from trac.util.html import html
from trac.util.text import strip_line_ws, to_unicode
from trac.web.chrome import web_context
from trac.web.href import Href
from trac.wiki.api import IWikiSyntaxProvider
from trac.wiki.formatter import (HtmlFormatter, InlineHtmlFormatter,
                                 OutlineFormatter)
from trac.wiki.macros import WikiMacroBase
from trac.wiki.model import WikiPage


# We need to supply our own macro because the real macros
# can not be loaded using our 'fake' environment.

class HelloWorldMacro(WikiMacroBase):
    """A dummy macro used by the unit test."""

    def expand_macro(self, formatter, name, content):
        return 'Hello World, args = ' + content

class DivHelloWorldMacro(WikiMacroBase):
    """A dummy macro returning a div block, used by the unit test."""

    def expand_macro(self, formatter, name, content):
        return '<div>Hello World, args = %s</div>' % content

class TableHelloWorldMacro(WikiMacroBase):
    """A dummy macro returning a table block, used by the unit test."""

    def expand_macro(self, formatter, name, content):
        return """
        <table><tr><th>Hello World</th><td>%s</td></tr></table>
        """ % content

class DivCodeMacro(WikiMacroBase):
    """A dummy macro returning a div block, used by the unit test."""

    def expand_macro(self, formatter, name, content):
        return '<div class="code">Hello World, args = %s</div>' % content

class DivCodeElementMacro(WikiMacroBase):
    """A dummy macro returning a Genshi Element, used by the unit test."""

    def expand_macro(self, formatter, name, content):
        return html.DIV('Hello World, args = ', content, class_="code")

class DivCodeStreamMacro(WikiMacroBase):
    """A dummy macro returning a Genshi Stream, used by the unit test."""

    def expand_macro(self, formatter, name, content):
        from genshi.template import MarkupTemplate
        tmpl = MarkupTemplate("""
        <div>Hello World, args = $args</div>
        """)
        return tmpl.generate(args=content)

class NoneMacro(WikiMacroBase):
    """A dummy macro returning `None`, used by the unit test."""

    def expand_macro(self, formatter, name, content):
        return None

class WikiProcessorSampleMacro(WikiMacroBase):
    def expand_macro(self, formatter, name, content, args):
        if args is None:
            return 'Called as a macro: ' + content
        else:
            return 'Called as a processor with params: <dl>%s</dl>' % \
                ''.join('<dt>%s</dt><dd>%s</dd>' % kv for kv in args.items()) \
                + content

class SampleResolver(Component):
    """A dummy macro returning a div block, used by the unit test."""

    implements(IWikiSyntaxProvider)

    def get_wiki_syntax(self):
        return []

    def get_link_resolvers(self):
        yield ('link', self._format_link)

    def _format_link(self, formatter, ns, target, label):
        kind, module = 'text', 'stuff'
        try:
            kind = 'odd' if int(target) % 2 else 'even'
            module = 'thing'
        except ValueError:
            pass
        return html.A(label, class_='%s resolver' % kind,
                      href=formatter.href(module, target))


class WikiTestCase(unittest.TestCase):

    generate_opts = {}

    def __init__(self, title, input, correct, file, line, setup=None,
                 teardown=None, context=None):
        unittest.TestCase.__init__(self, 'test')
        self.title = title
        self.input = input
        self.correct = correct
        self.file = file
        self.line = line
        self._setup = setup
        self._teardown = teardown

        req = Mock(href=Href('/'), abs_href=Href('http://www.example.com/'),
                   authname='anonymous', perm=MockPerm(), tz=utc, args={},
                   locale=locale_en, lc_time=locale_en)
        if context:
            if isinstance(context, tuple):
                context = web_context(req, *context)
        else:
            context = web_context(req, 'wiki', 'WikiStart')
        self.context = context

        all_test_components = [
                HelloWorldMacro, DivHelloWorldMacro, TableHelloWorldMacro,
                DivCodeMacro, DivCodeElementMacro, DivCodeStreamMacro,
                NoneMacro, WikiProcessorSampleMacro, SampleResolver]
        self.env = EnvironmentStub(enable=['trac.*'] + all_test_components)
        # -- macros support
        self.env.path = ''
        # -- intertrac support
        self.env.config.set('intertrac', 'trac.title', "Trac's Trac")
        self.env.config.set('intertrac', 'trac.url',
                            "http://trac.edgewall.org")
        self.env.config.set('intertrac', 't', 'trac')
        self.env.config.set('intertrac', 'th.title', "Trac Hacks")
        self.env.config.set('intertrac', 'th.url',
                            "http://trac-hacks.org")
        self.env.config.set('intertrac', 'th.compat', 'false')
        # -- safe schemes
        self.env.config.set('wiki', 'safe_schemes',
                            'file,ftp,http,https,svn,svn+ssh,'
                            'rfc-2396.compatible,rfc-2396+under_score')

        # TODO: remove the following lines in order to discover
        #       all the places were we should use the req.href
        #       instead of env.href
        self.env.href = req.href
        self.env.abs_href = req.abs_href

    def setUp(self):
        wiki = WikiPage(self.env)
        wiki.name = 'WikiStart'
        wiki.text = '--'
        wiki.save('joe', 'Entry page', '::1', datetime.now(utc))
        if self._setup:
            self._setup(self)

    def tearDown(self):
        self.env.reset_db()
        if self._teardown:
            self._teardown(self)

    def test(self):
        """Testing WikiFormatter"""
        formatter = self.formatter()
        v = unicode(formatter.generate(**self.generate_opts))
        v = v.replace('\r', '').replace(u'\u200b', '') # FIXME: keep ZWSP
        v = strip_line_ws(v, leading=False)
        try:
            self.assertEquals(self.correct, v)
        except AssertionError, e:
            msg = to_unicode(e)
            match = re.match(r"u?'(.*)' != u?'(.*)'", msg)
            if match:
                g1 = ["%s\n" % x for x in match.group(1).split(r'\n')]
                g2 = ["%s\n" % x for x in match.group(2).split(r'\n')]
                expected = ''.join(g1)
                actual = ''.join(g2)
                wiki = repr(self.input).replace(r'\n', '\n')
                diff = ''.join(list(difflib.unified_diff(g1, g2, 'expected',
                                                         'actual')))
                # Tip: sometimes, 'expected' and 'actual' differ only by
                #      whitespace, so it can be useful to visualize them, e.g.
                # expected = expected.replace(' ', '.')
                # actual = actual.replace(' ', '.')
                def info(*args):
                    return '\n========== %s: ==========\n%s' % args
                msg = info('expected', expected)
                msg += info('actual', actual)
                msg += info('wiki', ''.join(wiki))
                msg += info('diff', diff)
            raise AssertionError( # See below for details
                '%s\n\n%s:%s: "%s" (%s flavor)' \
                % (msg, self.file, self.line, self.title, formatter.flavor))

    def formatter(self):
        return HtmlFormatter(self.env, self.context, self.input)

    def shortDescription(self):
        return 'Test ' + self.title


class OneLinerTestCase(WikiTestCase):
    def formatter(self):
        return InlineHtmlFormatter(self.env, self.context, self.input)

class EscapeNewLinesTestCase(WikiTestCase):
    generate_opts = {'escape_newlines': True}
    def formatter(self):
        return HtmlFormatter(self.env, self.context, self.input)

class OutlineTestCase(WikiTestCase):
    def formatter(self):
        from StringIO import StringIO
        class Outliner(object):
            flavor = 'outliner'
            def __init__(self, env, context, input):
                self.outliner = OutlineFormatter(env, context)
                self.input = input
            def generate(self):
                out = StringIO()
                self.outliner.format(self.input, out)
                return out.getvalue()
        return Outliner(self.env, self.context, self.input)


def suite(data=None, setup=None, file=__file__, teardown=None, context=None):
    suite = unittest.TestSuite()
    def add_test_cases(data, filename):
        tests = re.compile('^(%s.*)$' % ('=' * 30), re.MULTILINE).split(data)
        next_line = 1
        line = 0
        for title, test in zip(tests[1::2], tests[2::2]):
            title = title.lstrip('=').strip()
            if line != next_line:
                line = next_line
            if not test or test == '\n':
                continue
            next_line += len(test.split('\n')) - 1
            if 'SKIP' in title or 'WONTFIX' in title:
                continue
            blocks = test.split('-' * 30 + '\n')
            if len(blocks) < 5:
                blocks.extend([None,] * (5 - len(blocks)))
            input, page, oneliner, page_escape_nl, outline = blocks[:5]
            if page:
                page = WikiTestCase(
                    title, input, page, filename, line, setup,
                    teardown, context)
            if oneliner:
                oneliner = OneLinerTestCase(
                    title, input, oneliner[:-1], filename, line, setup,
                    teardown, context)
            if page_escape_nl:
                page_escape_nl = EscapeNewLinesTestCase(
                    title, input, page_escape_nl, filename, line, setup,
                    teardown, context)
            if outline:
                outline = OutlineTestCase(
                    title, input, outline, filename, line, setup,
                    teardown, context)
            for tc in [page, oneliner, page_escape_nl, outline]:
                if tc:
                    suite.addTest(tc)
    if data:
        add_test_cases(data, file)
    else:
        for f in ('wiki-tests.txt', 'wikicreole-tests.txt'):
            testfile = os.path.join(os.path.split(file)[0], f)
            if os.path.exists(testfile):
                data = open(testfile, 'r').read().decode('utf-8')
                add_test_cases(data, testfile)
            else:
                print 'no ', testfile
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = functional
#!/usr/bin/python
from trac.tests.functional import *
from trac.mimeview.rst import has_docutils
from trac.util import get_pkginfo

class TestWiki(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Create a wiki page and attach a file"""
        # TODO: this should be split into multiple tests
        pagename = random_unique_camel()
        self._tester.create_wiki_page(pagename)
        self._tester.attach_file_to_wiki(pagename)


class TestWikiRename(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for simple wiki rename"""
        pagename = random_unique_camel()
        self._tester.create_wiki_page(pagename)
        attachment = self._tester.attach_file_to_wiki(pagename)
        base_url = self._tester.url
        page_url = base_url + "/wiki/" + pagename

        def click_rename():
            tc.formvalue('rename', 'action', 'rename')
            tc.submit()
            tc.url(page_url + r'\?action=rename')
            tc.find("New name:")

        tc.go(page_url)
        tc.find("Rename page")
        click_rename()
        # attempt to give an empty new name
        tc.formvalue('rename-form', 'new_name', '')
        tc.submit('submit')
        tc.url(page_url)
        tc.find("A new name is mandatory for a rename")
        # attempt to rename the page to an invalid page name
        tc.formvalue('rename-form', 'new_name', '../WikiStart')
        tc.submit('submit')
        tc.url(page_url)
        tc.find("The new name is invalid")
        # attempt to rename the page to the current page name
        tc.formvalue('rename-form', 'new_name', pagename)
        tc.submit('submit')
        tc.url(page_url)
        tc.find("The new name must be different from the old name")
        # attempt to rename the page to an existing page name
        tc.formvalue('rename-form', 'new_name', 'WikiStart')
        tc.submit('submit')
        tc.url(page_url)
        tc.find("The page WikiStart already exists")
        # correct rename to new page name (old page replaced by a redirection)
        tc.go(page_url)
        click_rename()
        newpagename = pagename + 'Renamed'
        tc.formvalue('rename-form', 'new_name', newpagename)
        tc.formvalue('rename-form', 'redirect', True)
        tc.submit('submit')
        # check redirection page
        tc.url(page_url)
        tc.find("See.*/wiki/" + newpagename)
        # check whether attachment exists on the new page but not on old page
        tc.go(base_url + '/attachment/wiki/' + newpagename + '/' + attachment)
        tc.notfind("Error: Invalid Attachment")
        tc.go(base_url + '/attachment/wiki/' + pagename + '/' + attachment)
        tc.find("Error: Invalid Attachment")
        # rename again to another new page name (this time, no redirection)
        tc.go(page_url)
        click_rename()
        newpagename = pagename + 'RenamedAgain'
        tc.formvalue('rename-form', 'new_name', newpagename)
        tc.formvalue('rename-form', 'redirect', False)
        tc.submit('submit')
        tc.url(base_url + "/wiki/" + newpagename)
        # this time, the original page is gone
        tc.go(page_url)
        tc.url(page_url)
        tc.find("The page %s does not exist" % pagename)


class RegressionTestTicket4812(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/4812"""
        pagename = random_unique_camel() + '/' + random_unique_camel()
        self._tester.create_wiki_page(pagename)
        self._tester.attach_file_to_wiki(pagename)
        tc.notfind('does not exist')


class ReStructuredTextWikiTest(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Render reStructured text using a wikiprocessor"""
        pagename = random_unique_camel()
        self._tester.create_wiki_page(pagename, content="""
{{{
#!rst
Hello
=====

.. trac:: wiki:WikiStart Some Link
}}}
                                     """)
        self._tester.go_to_wiki(pagename)
        tc.find("Some Link")
        tc.find(r'<h1[^>]*>Hello')
        tc.notfind("wiki:WikiStart")
        tc.follow("Some Link")
        tc.url(self._tester.url + "/wiki/WikiStart")


class ReStructuredTextCodeBlockTest(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Render reStructured code block"""
        pagename = random_unique_camel()
        self._tester.create_wiki_page(pagename, content="""
{{{
#!rst
.. code-block:: python

    print "123"
}}}
""")
        self._tester.go_to_wiki(pagename)
        tc.notfind("code-block")
        tc.find('print')
        tc.find('"123"')


class RegressionTestTicket10274(FunctionalTwillTestCaseSetup):
    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/10274"""
        self._tester.go_to_wiki('WikiStart/..')
        tc.find("Invalid Wiki page name 'WikiStart/..'")
        self._tester.go_to_wiki('../WikiStart')
        tc.find("Invalid Wiki page name '../WikiStart'")
        self._tester.go_to_wiki('WikiStart/./SubPage')
        tc.find("Invalid Wiki page name 'WikiStart/./SubPage'")


class RegressionTestTicket10850(FunctionalTwillTestCaseSetup):

    def runTest(self):
        """Test for regression of http://trac.edgewall.org/ticket/10850"""
        pagename = random_unique_camel()
        self._tester.create_wiki_page(pagename)
        # colon characters
        attachment = self._tester.attach_file_to_wiki(
            pagename, tempfilename='2012-09-11_15:36:40-test.tbz2')
        base_url = self._tester.url
        tc.go(base_url + '/attachment/wiki/' + pagename +
              '/2012-09-11_15:36:40-test.tbz2')
        tc.notfind('Error: Invalid Attachment')
        # backslash characters
        attachment = self._tester.attach_file_to_wiki(
            pagename, tempfilename=r'/tmp/back\slash.txt')
        base_url = self._tester.url
        tc.go(base_url + '/attachment/wiki/' + pagename + r'/back\slash.txt')
        tc.notfind('Error: Invalid Attachment')
        # Windows full path
        attachment = self._tester.attach_file_to_wiki(
            pagename, tempfilename=r'z:\tmp\windows:path.txt')
        base_url = self._tester.url
        tc.go(base_url + '/attachment/wiki/' + pagename + r'/windows:path.txt')
        tc.notfind('Error: Invalid Attachment')
        # Windows share folder path
        attachment = self._tester.attach_file_to_wiki(
            pagename, tempfilename=r'\\server\share\file:name.txt')
        base_url = self._tester.url
        tc.go(base_url + '/attachment/wiki/' + pagename + r'/file:name.txt')
        tc.notfind('Error: Invalid Attachment')


def functionalSuite(suite=None):
    if not suite:
        import trac.tests.functional.testcases
        suite = trac.tests.functional.testcases.functionalSuite()
    suite.addTest(TestWiki())
    suite.addTest(TestWikiRename())
    suite.addTest(RegressionTestTicket4812())
    suite.addTest(RegressionTestTicket10274())
    suite.addTest(RegressionTestTicket10850())
    if has_docutils:
        import docutils
        if get_pkginfo(docutils):
            suite.addTest(ReStructuredTextWikiTest())
            suite.addTest(ReStructuredTextCodeBlockTest())
        else:
            print "SKIP: reST wiki tests (docutils has no setuptools metadata)"
    else:
        print "SKIP: reST wiki tests (no docutils)"
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='functionalSuite')

########NEW FILE########
__FILENAME__ = macros
# -*- coding: utf-8 -*-
from datetime import datetime
import unittest

from trac.config import Option
from trac.test import locale_en
from trac.util.datefmt import format_date, utc
from trac.wiki.model import WikiPage
from trac.wiki.tests import formatter

# == [[Image]]

# Note: using ` test` string in the following tests for checking
#       unicode robustness and whitespace support (first space is
#       normal ASCII SPACE, second is Unicode NO-BREAK SPACE).

IMAGE_MACRO_TEST_CASES = u"""
============================== source: Image, no other arguments
[[Image(source: test.png)]]
------------------------------
<p>
<a style="padding:0; border:none" href="/browser/%C2%AB%20test%C2%A0%C2%BB.png"><img src="/browser/%C2%AB%20test%C2%A0%C2%BB.png?format=raw" alt="source: test.png" title="source: test.png" /></a>
</p>
------------------------------
<a style="padding:0; border:none" href="/browser/%C2%AB%20test%C2%A0%C2%BB.png"><img src="/browser/%C2%AB%20test%C2%A0%C2%BB.png?format=raw" alt="source: test.png" title="source: test.png" /></a>
============================== intertrac:source: Image, no other arguments
[[Image(trac:source:/trunk/doc/images/bkgnd_pattern_ test.png)]]
------------------------------
<p>
<a style="padding:0; border:none" href="http://trac.edgewall.org/intertrac/source%3A/trunk/doc/images/bkgnd_pattern_%C2%AB%20test%C2%A0%C2%BB.png"><img src="http://trac.edgewall.org/intertrac/source%3A/trunk/doc/images/bkgnd_pattern_%C2%AB%20test%C2%A0%C2%BB.png%3Fformat%3Draw" alt="source:/trunk/doc/images/bkgnd_pattern_ test.png in Trac's Trac" title="source:/trunk/doc/images/bkgnd_pattern_ test.png in Trac's Trac" /></a>
</p>
------------------------------
<a style="padding:0; border:none" href="http://trac.edgewall.org/intertrac/source%3A/trunk/doc/images/bkgnd_pattern_%C2%AB%20test%C2%A0%C2%BB.png"><img src="http://trac.edgewall.org/intertrac/source%3A/trunk/doc/images/bkgnd_pattern_%C2%AB%20test%C2%A0%C2%BB.png%3Fformat%3Draw" alt="source:/trunk/doc/images/bkgnd_pattern_ test.png in Trac's Trac" title="source:/trunk/doc/images/bkgnd_pattern_ test.png in Trac's Trac" /></a>
============================== source: Image, nolink
[[Image(source: test, nolink)]]
------------------------------
<p>
<img src="/browser/%C2%AB%20test%C2%A0%C2%BB?format=raw" alt="source: test" title="source: test" />
</p>
------------------------------
<img src="/browser/%C2%AB%20test%C2%A0%C2%BB?format=raw" alt="source: test" title="source: test" />
============================== source: Image, normal args
[[Image(source: test, align=left, title=Test)]]
------------------------------
<p>
<a style="padding:0; border:none" href="/browser/%C2%AB%20test%C2%A0%C2%BB"><img src="/browser/%C2%AB%20test%C2%A0%C2%BB?format=raw" alt="source: test" style="float:left" title="Test" /></a>
</p>
------------------------------
<a style="padding:0; border:none" href="/browser/%C2%AB%20test%C2%A0%C2%BB"><img src="/browser/%C2%AB%20test%C2%A0%C2%BB?format=raw" alt="source: test" style="float:left" title="Test" /></a>
============================== source: Image, size arg
[[Image(source: test, 30%)]]
------------------------------
<p>
<a style="padding:0; border:none" href="/browser/%C2%AB%20test%C2%A0%C2%BB"><img width="30%" alt="source: test" title="source: test" src="/browser/%C2%AB%20test%C2%A0%C2%BB?format=raw" /></a>
</p>
------------------------------
============================== source: Image, keyword alignment
[[Image(source: test, right)]]
------------------------------
<p>
<a style="padding:0; border:none" href="/browser/%C2%AB%20test%C2%A0%C2%BB"><img src="/browser/%C2%AB%20test%C2%A0%C2%BB?format=raw" alt="source: test" style="float:right" title="source: test" /></a>
</p>
------------------------------
============================== http: Image, nolink
[[Image(http://www.edgewall.com/gfx/shredder_ test.png, nolink)]]
------------------------------
<p>
<img src="http://www.edgewall.com/gfx/shredder_ test.png" alt="http://www.edgewall.com/gfx/shredder_ test.png" title="http://www.edgewall.com/gfx/shredder_ test.png" />
</p>
------------------------------
============================== http: Image, absolute, many ':'
[[Image(http://chart.apis.google.com:80/chart?cht=p3&chd=s:hW&chs=250x100&chl=Hllo|Wrld, title=Google & Charting, link=)]]
------------------------------
<p>
<img src="http://chart.apis.google.com:80/chart?cht=p3&amp;chd=s:hW&amp;chs=250x100&amp;chl=Hllo|Wrld" alt="http://chart.apis.google.com:80/chart" title="Google &amp; Charting" />
</p>
------------------------------
============================== // Image, server-relative
[[Image(//browser/ test?format=raw, link=)]]
------------------------------
<p>
<img src="/browser/ test?format=raw" alt="/browser/ test" title="/browser/ test" />
</p>
------------------------------
============================== / Image, project-relative, link to WikiStart
[[Image(/browser/ test?format=raw, link=wiki:WikiStart)]]
------------------------------
<p>
<a style="padding:0; border:none" href="/wiki/WikiStart"><img src="/browser/%C2%AB%20test%C2%A0%C2%BB?format=raw" alt="/browser/ test" title="/browser/ test" /></a>
</p>
------------------------------
<a style="padding:0; border:none" href="/wiki/WikiStart"><img src="/browser/%C2%AB%20test%C2%A0%C2%BB?format=raw" alt="/browser/ test" title="/browser/ test" /></a>
============================== Strip unicode white-spaces and ZWSPs (#10668)
[[Image( source: test.png , nolink)]]
------------------------------
<p>
<img src="/browser/%C2%AB%20test%C2%A0%C2%BB.png?format=raw" alt="source: test.png" title="source: test.png" />
</p>
------------------------------
<img src="/browser/%C2%AB%20test%C2%A0%C2%BB.png?format=raw" alt="source: test.png" title="source: test.png" />
------------------------------
"""

# Note: in the <img> src attribute above, the Unicode characters
#       within the URI sometimes come out as %-encoded, sometimes raw
#       (server-relative case). Both forms are valid (at least
#       according to the W3C XHTML validator).



# == [[TitleIndex]]

def add_pages(tc, names):
    now = datetime.now(utc)
    for name in names:
        w = WikiPage(tc.env)
        w.name = name
        w.text = '--'
        w.save('joe', 'the page ' + name, '::1', now)

def titleindex_teardown(tc):
    tc.env.reset_db()



TITLEINDEX1_MACRO_TEST_CASES = u"""
============================== TitleIndex, default format
[[TitleIndex()]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><a href="/wiki/WikiStart">WikiStart</a></li></ul></div><p>
</p>
------------------------------
[[TitleIndex]]
============================== TitleIndex, compact format
[[TitleIndex(format=compact)]]
------------------------------
<p>
<a href="/wiki/WikiStart">WikiStart</a>
</p>
------------------------------
[[TitleIndex(...)]]
"""

TITLEINDEX2_MACRO_TEST_CASES = u"""
============================== TitleIndex, default format
[[TitleIndex()]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><a href="/wiki/WikiEnd">WikiEnd</a></li><li><a href="/wiki/WikiStart">WikiStart</a></li></ul></div><p>
</p>
------------------------------
[[TitleIndex]]
============================== TitleIndex, compact format
[[TitleIndex(format=compact)]]
------------------------------
<p>
<a href="/wiki/WikiEnd">WikiEnd</a>, <a href="/wiki/WikiStart">WikiStart</a>
</p>
------------------------------
[[TitleIndex(...)]]
============================== TitleIndex, default format with prefix
[[TitleIndex(Wiki)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><a href="/wiki/WikiEnd">WikiEnd</a></li><li><a href="/wiki/WikiStart">WikiStart</a></li></ul></div><p>
</p>
------------------------------
[[TitleIndex(...)]]
============================== TitleIndex, compact format with prefix
[[TitleIndex(Wiki,format=compact)]]
------------------------------
<p>
<a href="/wiki/WikiEnd">WikiEnd</a>, <a href="/wiki/WikiStart">WikiStart</a>
</p>
------------------------------
[[TitleIndex(...)]]
============================== TitleIndex, default format with prefix hidden
[[TitleIndex(Wiki,hideprefix)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><a href="/wiki/WikiEnd">End</a></li><li><a href="/wiki/WikiStart">Start</a></li></ul></div><p>
</p>
------------------------------
[[TitleIndex(...)]]
============================== TitleIndex, compact format with prefix hidden
[[TitleIndex(Wiki,hideprefix,format=compact)]]
------------------------------
<p>
<a href="/wiki/WikiEnd">End</a>, <a href="/wiki/WikiStart">Start</a>
</p>
------------------------------
[[TitleIndex(...)]]
"""

def titleindex2_setup(tc):
    add_pages(tc, ['WikiEnd'])


TITLEINDEX3_MACRO_TEST_CASES = u"""
============================== TitleIndex, group format
[[TitleIndex(Wiki,format=group)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><strong>Wiki</strong><ul><li><strong>End</strong><ul><li><a href="/wiki/WikiEnd/First">WikiEnd/First</a></li><li><a href="/wiki/WikiEnd/Second">WikiEnd/Second</a></li></ul></li><li><strong>Start</strong><ul><li><a href="/wiki/WikiStart">WikiStart</a></li><li><a href="/wiki/WikiStart/First">WikiStart/First</a></li><li><a href="/wiki/WikiStart/Second">WikiStart/Second</a></li><li><a href="/wiki/WikiStart/Third">WikiStart/Third</a></li></ul></li></ul></li></ul></div><p>
</p>
------------------------------
============================== TitleIndex, hierarchy format
[[TitleIndex(WikiStart/, format=hierarchy)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li>WikiStart<ul><li><a href="/wiki/WikiStart/First">First</a></li><li><a href="/wiki/WikiStart/Second">Second</a></li><li><a href="/wiki/WikiStart/Third">Third</a></li></ul></li></ul></div><p>
</p>
------------------------------
============================== TitleIndex, group format, prefix hidden
[[TitleIndex(Wiki,hideprefix,format=group)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><strong>End</strong><ul><li><a href="/wiki/WikiEnd/First">End/First</a></li><li><a href="/wiki/WikiEnd/Second">End/Second</a></li></ul></li><li><strong>Start</strong><ul><li><a href="/wiki/WikiStart">Start</a></li><li><a href="/wiki/WikiStart/First">Start/First</a></li><li><a href="/wiki/WikiStart/Second">Start/Second</a></li><li><a href="/wiki/WikiStart/Third">Start/Third</a></li></ul></li></ul></div><p>
</p>
------------------------------
============================== TitleIndex, hierarchy format, prefix hidden
[[TitleIndex(WikiStart/,hideprefix,format=hierarchy)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><a href="/wiki/WikiStart/First">First</a></li><li><a href="/wiki/WikiStart/Second">Second</a></li><li><a href="/wiki/WikiStart/Third">Third</a></li></ul></div><p>
</p>
------------------------------
"""

def titleindex3_setup(tc):
    add_pages(tc, [
        'WikiStart/First',
        'WikiStart/Second',
        'WikiStart/Third',
        'WikiEnd/First',
        'WikiEnd/Second',
        ])


TITLEINDEX4_MACRO_TEST_CASES = u"""
============================== TitleIndex group and page with numbers (#7919)
[[TitleIndex(format=group)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><strong>0.11</strong><ul><li><strong>Group</strong><ul><li><a href="/wiki/0.11/GroupOne">0.11/GroupOne</a></li><li><a href="/wiki/0.11/GroupTwo">0.11/GroupTwo</a></li></ul></li><li><a href="/wiki/0.11/Test">0.11/Test</a></li></ul></li><li><strong>Test</strong><ul><li><strong>0.11</strong><ul><li><a href="/wiki/Test0.11/Abc">Test0.11/Abc</a></li><li><a href="/wiki/Test0.11Abc">Test0.11Abc</a></li></ul></li><li><strong>0.12</strong><ul><li><a href="/wiki/Test0.12Def">Test0.12Def</a></li><li><a href="/wiki/Test0.12Ijk">Test0.12Ijk</a></li></ul></li><li><strong>0.13</strong><ul><li><a href="/wiki/Test0.13alpha">Test0.13alpha</a></li><li><a href="/wiki/Test0.13beta">Test0.13beta</a></li></ul></li><li><a href="/wiki/Test0.131">Test0.131</a></li><li><a href="/wiki/Test2">Test2</a></li><li><a href="/wiki/TestTest">TestTest</a></li><li><a href="/wiki/TestThing">TestThing</a></li></ul></li><li><a href="/wiki/WikiStart">WikiStart</a></li></ul></div><p>
</p>
------------------------------
============================== TitleIndex, compact format with prefix hidden, including Test0.13*
[[TitleIndex(Test,format=compact,include=*0.13*)]]
------------------------------
<p>
<a href="/wiki/Test0.131">Test0.131</a>, <a href="/wiki/Test0.13alpha">Test0.13alpha</a>, <a href="/wiki/Test0.13beta">Test0.13beta</a>
</p>
------------------------------
============================== TitleIndex, compact format with prefix hidden, including Test0.13* but excluding Test0.131
[[TitleIndex(Test,format=compact,include=*0.13*,exclude=*1)]]
------------------------------
<p>
<a href="/wiki/Test0.13alpha">Test0.13alpha</a>, <a href="/wiki/Test0.13beta">Test0.13beta</a>
</p>
------------------------------
============================== TitleIndex, compact format, excluding various topics
[[TitleIndex(Test,format=compact,exclude=Test0.13*:*0.11*:Test2:Test*i*)]]
------------------------------
<p>
<a href="/wiki/Test0.12Def">Test0.12Def</a>, <a href="/wiki/Test0.12Ijk">Test0.12Ijk</a>, <a href="/wiki/TestTest">TestTest</a>
</p>
------------------------------
============================== TitleIndex, compact format, including and excluding various topics
[[TitleIndex(format=compact,include=*Group*:test2,exclude=*One)]]
------------------------------
<p>
<a href="/wiki/0.11/GroupTwo">0.11/GroupTwo</a>
</p>
------------------------------
"""

def titleindex4_setup(tc):
    add_pages(tc, [
        'TestTest',
        'TestThing',
        'Test2',
        'Test0.11Abc',
        'Test0.11/Abc',
        'Test0.12Def',
        'Test0.12Ijk',
        'Test0.13alpha',
        'Test0.13beta',
        'Test0.131',
        '0.11/Test',
        '0.11/GroupOne',
        '0.11/GroupTwo',
        ])


TITLEINDEX5_MACRO_TEST_CASES = u"""
============================== TitleIndex, hierarchy format with complex hierarchy
[[TitleIndex(format=hierarchy)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><a href="/wiki/TracDev">TracDev</a><ul><li><a href="/wiki/TracDev/ApiChanges">ApiChanges</a><ul><li><a href="/wiki/TracDev/ApiChanges/0.10">0.10</a></li><li><a href="/wiki/TracDev/ApiChanges/0.11">0.11</a></li><li><a href="/wiki/TracDev/ApiChanges/0.12">0.12</a><ul><li>Missing<ul><li><a href="/wiki/TracDev/ApiChanges/0.12/Missing/Exists">Exists</a></li></ul></li></ul></li></ul></li></ul></li><li><a href="/wiki/WikiStart">WikiStart</a></li></ul></div><p>
</p>
------------------------------
============================== TitleIndex, hierarchy format with complex hierarchy (and min=5)
[[TitleIndex(format=hierarchy,min=5)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><a href="/wiki/TracDev">TracDev</a><ul><li><a href="/wiki/TracDev/ApiChanges">ApiChanges</a></li><li><a href="/wiki/TracDev/ApiChanges/0.10">ApiChanges/0.10</a></li><li><a href="/wiki/TracDev/ApiChanges/0.11">ApiChanges/0.11</a></li><li><a href="/wiki/TracDev/ApiChanges/0.12">ApiChanges/0.12</a></li><li><a href="/wiki/TracDev/ApiChanges/0.12/Missing/Exists">ApiChanges/0.12/Missing/Exists</a></li></ul></li><li><a href="/wiki/WikiStart">WikiStart</a></li></ul></div><p>
</p>
------------------------------
============================== TitleIndex, group format with complex hierarchy
[[TitleIndex(format=group)]]
------------------------------
<p>
</p><div class="titleindex"><ul><li><strong>TracDev</strong><ul><li><a href="/wiki/TracDev">TracDev</a></li><li><strong>ApiChanges</strong><ul><li><a href="/wiki/TracDev/ApiChanges">TracDev/ApiChanges</a></li><li><a href="/wiki/TracDev/ApiChanges/0.10">TracDev/ApiChanges/0.10</a></li><li><a href="/wiki/TracDev/ApiChanges/0.11">TracDev/ApiChanges/0.11</a></li><li><strong>0.12</strong><ul><li><a href="/wiki/TracDev/ApiChanges/0.12">TracDev/ApiChanges/0.12</a></li><li><a href="/wiki/TracDev/ApiChanges/0.12/Missing/Exists">TracDev/ApiChanges/0.12/Missing/Exists</a></li></ul></li></ul></li></ul></li><li><a href="/wiki/WikiStart">WikiStart</a></li></ul></div><p>
</p>
------------------------------
"""

def titleindex5_setup(tc):
    add_pages(tc, [
        'TracDev',
        'TracDev/ApiChanges',
        'TracDev/ApiChanges/0.10',
        'TracDev/ApiChanges/0.11',
        'TracDev/ApiChanges/0.12',
        'TracDev/ApiChanges/0.12/Missing/Exists',
        ])


RECENTCHANGES_MACRO_TEST_CASES = u""""
============================== RecentChanges, group option
[[RecentChanges()]]
[[RecentChanges(group=date)]]
[[RecentChanges(group=none)]]
[[RecentChanges(,2,group=none)]]
[[RecentChanges(Wiki,group=none)]]
[[RecentChanges(Wiki,1,group=none)]]
------------------------------
<p>
</p><div><h3>%(date)s</h3><ul><li><a href="/wiki/WikiEnd">WikiEnd</a>
</li><li><a href="/wiki/WikiMid">WikiMid</a>
</li><li><a href="/wiki/WikiStart">WikiStart</a>
</li></ul></div><p>
</p><div><h3>%(date)s</h3><ul><li><a href="/wiki/WikiEnd">WikiEnd</a>
</li><li><a href="/wiki/WikiMid">WikiMid</a>
</li><li><a href="/wiki/WikiStart">WikiStart</a>
</li></ul></div><p>
</p><div><ul><li><a href="/wiki/WikiEnd">WikiEnd</a>
</li><li><a href="/wiki/WikiMid">WikiMid</a>
</li><li><a href="/wiki/WikiStart">WikiStart</a>
</li></ul></div><p>
</p><div><ul><li><a href="/wiki/WikiEnd">WikiEnd</a>
</li><li><a href="/wiki/WikiMid">WikiMid</a>
</li></ul></div><p>
</p><div><ul><li><a href="/wiki/WikiEnd">WikiEnd</a>
</li><li><a href="/wiki/WikiMid">WikiMid</a>
</li><li><a href="/wiki/WikiStart">WikiStart</a>
</li></ul></div><p>
</p><div><ul><li><a href="/wiki/WikiEnd">WikiEnd</a>
</li></ul></div><p>
</p>
------------------------------
"""

def recentchanges_setup(tc):
    def add_pages(tc, names):
        for name in names:
            now = datetime.now(utc)
            w = WikiPage(tc.env)
            w.name = name
            w.text = '--'
            w.save('joe', 'the page ' + name, '::1', now)
    add_pages(tc, [
        'WikiMid',
        'WikiEnd',
        ])
    tc.correct = tc.correct % {'date': format_date(tzinfo=utc,
                                                   locale=locale_en)}

def recentchanges_teardown(tc):
    tc.env.reset_db()


TRACINI_MACRO_TEST_CASES = u"""\
============================== TracIni, option with empty doc (#10940)
[[TracIni(section-42)]]
------------------------------
<p>
</p><div class="tracini">\
<h3 id="section-42-section"><code>[section-42]</code></h3>\
<table class="wiki"><tbody>\
<tr><td><tt>option1</tt></td><td></td><td class="default"><code>value</code></td></tr>\
<tr><td><tt>option2</tt></td><td>blah</td><td class="default"><code>value</code></td></tr>\
</tbody></table>\
</div><p>
</p>
------------------------------
"""

def tracini_setup(tc):
    tc._orig_registry = Option.registry
    class Foo(object):
        option_a1 = (Option)('section-42', 'option1', 'value', doc='')
        option_a2 = (Option)('section-42', 'option2', 'value', doc='blah')

def tracini_teardown(tc):
    Option.registry = tc._orig_registry


def suite():
    suite = unittest.TestSuite()
    suite.addTest(formatter.suite(IMAGE_MACRO_TEST_CASES, file=__file__))
    suite.addTest(formatter.suite(TITLEINDEX1_MACRO_TEST_CASES, file=__file__))
    suite.addTest(formatter.suite(TITLEINDEX2_MACRO_TEST_CASES, file=__file__,
                                  setup=titleindex2_setup,
                                  teardown=titleindex_teardown))
    suite.addTest(formatter.suite(TITLEINDEX3_MACRO_TEST_CASES, file=__file__,
                                  setup=titleindex3_setup,
                                  teardown=titleindex_teardown))
    suite.addTest(formatter.suite(TITLEINDEX4_MACRO_TEST_CASES, file=__file__,
                                  setup=titleindex4_setup,
                                  teardown=titleindex_teardown))
    suite.addTest(formatter.suite(TITLEINDEX5_MACRO_TEST_CASES, file=__file__,
                                  setup=titleindex5_setup,
                                  teardown=titleindex_teardown))
    suite.addTest(formatter.suite(RECENTCHANGES_MACRO_TEST_CASES, file=__file__,
                                  setup=recentchanges_setup,
                                  teardown=recentchanges_teardown))
    suite.addTest(formatter.suite(TRACINI_MACRO_TEST_CASES, file=__file__,
                                  setup=tracini_setup,
                                  teardown=tracini_teardown))
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = model
# -*- coding: utf-8 -*-

from __future__ import with_statement

from datetime import datetime
import os.path
import shutil
from StringIO import StringIO
import tempfile
import unittest

from trac.attachment import Attachment
from trac.core import *
from trac.test import EnvironmentStub
from trac.tests.resource import TestResourceChangeListener
from trac.util.datefmt import utc, to_utimestamp
from trac.wiki import WikiPage, IWikiChangeListener


class TestWikiChangeListener(Component):

    implements(IWikiChangeListener)

    def __init__(self):
        self.added = []
        self.changed = []
        self.deleted = []
        self.deleted_version = []
        self.renamed = []

    def wiki_page_added(self, page):
        self.added.append(page)

    def wiki_page_changed(self, page, version, t, comment, author, ipnr):
        self.changed.append((page, version, t, comment, author, ipnr))

    def wiki_page_deleted(self, page):
        self.deleted.append(page)

    def wiki_page_version_deleted(self, page):
        self.deleted_version.append(page)

    def wiki_page_renamed(self, page, old_name):
        self.renamed.append((page, old_name))


class WikiPageTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        self.env.path = os.path.join(tempfile.gettempdir(), 'trac-tempenv')
        os.mkdir(self.env.path)

    def tearDown(self):
        shutil.rmtree(self.env.path)
        self.env.reset_db()

    def test_new_page(self):
        page = WikiPage(self.env)
        self.assertEqual(False, page.exists)
        self.assertEqual(None, page.name)
        self.assertEqual(0, page.version)
        self.assertEqual('', page.text)
        self.assertEqual(0, page.readonly)
        self.assertEqual('', page.author)
        self.assertEqual('', page.comment)
        self.assertEqual(None, page.time)

    def test_existing_page(self):
        t = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        self.env.db_transaction(
            "INSERT INTO wiki VALUES(%s,%s,%s,%s,%s,%s,%s,%s)",
            ('TestPage', 1, to_utimestamp(t), 'joe', '::1', 'Bla bla',
             'Testing', 0))

        page = WikiPage(self.env, 'TestPage')
        self.assertEqual(True, page.exists)
        self.assertEqual('TestPage', page.name)
        self.assertEqual(1, page.version)
        self.assertEqual(None, page.resource.version)   # FIXME: Intentional?
        self.assertEqual('Bla bla', page.text)
        self.assertEqual(0, page.readonly)
        self.assertEqual('joe', page.author)
        self.assertEqual('Testing', page.comment)
        self.assertEqual(t, page.time)

        history = list(page.get_history())
        self.assertEqual(1, len(history))
        self.assertEqual((1, t, 'joe', 'Testing', '::1'), history[0])

        page = WikiPage(self.env, 'TestPage', 1)
        self.assertEqual(1, page.resource.version)

    def test_create_page(self):
        page = WikiPage(self.env)
        page.name = 'TestPage'
        page.text = 'Bla bla'
        t = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        page.save('joe', 'Testing', '::1', t)

        self.assertEqual(True, page.exists)
        self.assertEqual(1, page.version)
        self.assertEqual(1, page.resource.version)
        self.assertEqual(0, page.readonly)
        self.assertEqual('joe', page.author)
        self.assertEqual('Testing', page.comment)
        self.assertEqual(t, page.time)

        self.assertEqual(
            [(1, to_utimestamp(t), 'joe', '::1', 'Bla bla', 'Testing', 0)],
            self.env.db_query("""
                SELECT version, time, author, ipnr, text, comment, readonly
                FROM wiki WHERE name=%s
                """, ('TestPage',)))

        listener = TestWikiChangeListener(self.env)
        self.assertEqual(page, listener.added[0])

    def test_update_page(self):
        t = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        t2 = datetime(2002, 1, 1, 1, 1, 1, 0, utc)
        self.env.db_transaction(
            "INSERT INTO wiki VALUES(%s,%s,%s,%s,%s,%s,%s,%s)",
            ('TestPage', 1, to_utimestamp(t), 'joe', '::1', 'Bla bla',
             'Testing', 0))

        page = WikiPage(self.env, 'TestPage')
        page.text = 'Bla'
        page.save('kate', 'Changing', '192.168.0.101', t2)

        self.assertEqual(2, page.version)
        self.assertEqual(2, page.resource.version)
        self.assertEqual(0, page.readonly)
        self.assertEqual('kate', page.author)
        self.assertEqual('Changing', page.comment)
        self.assertEqual(t2, page.time)

        with self.env.db_query as db:
            rows = db("""
               SELECT version, time, author, ipnr, text, comment, readonly
               FROM wiki WHERE name=%s
               """, ('TestPage',))
            self.assertEqual(2, len(rows))
            self.assertEqual((1, to_utimestamp(t), 'joe', '::1', 'Bla bla',
                              'Testing', 0), rows[0])
            self.assertEqual((2, to_utimestamp(t2), 'kate', '192.168.0.101',
                              'Bla', 'Changing', 0), rows[1])

        listener = TestWikiChangeListener(self.env)
        self.assertEqual((page, 2, t2, 'Changing', 'kate', '192.168.0.101'),
                         listener.changed[0])

        page = WikiPage(self.env, 'TestPage')
        history = list(page.get_history())
        self.assertEqual(2, len(history))
        self.assertEqual((2, t2, 'kate', 'Changing', '192.168.0.101'),
                         history[0])
        self.assertEqual((1, t, 'joe', 'Testing', '::1'), history[1])

    def test_delete_page(self):
        self.env.db_transaction(
            "INSERT INTO wiki VALUES(%s,%s,%s,%s,%s,%s,%s,%s)",
            ('TestPage', 1, 42, 'joe', '::1', 'Bla bla', 'Testing', 0))

        page = WikiPage(self.env, 'TestPage')
        page.delete()

        self.assertEqual(False, page.exists)

        self.assertEqual([], self.env.db_query("""
            SELECT version, time, author, ipnr, text, comment, readonly
            FROM wiki WHERE name=%s
            """, ('TestPage',)))

        listener = TestWikiChangeListener(self.env)
        self.assertEqual(page, listener.deleted[0])

    def test_delete_page_version(self):
        self.env.db_transaction.executemany(
            "INSERT INTO wiki VALUES(%s,%s,%s,%s,%s,%s,%s,%s)",
            [('TestPage', 1, 42, 'joe', '::1', 'Bla bla', 'Testing', 0),
             ('TestPage', 2, 43, 'kate', '192.168.0.11', 'Bla', 'Changing', 0)])

        page = WikiPage(self.env, 'TestPage')
        page.delete(version=2)

        self.assertEqual(True, page.exists)
        self.assertEqual(
            [(1, 42, 'joe', '::1', 'Bla bla', 'Testing', 0)],
            self.env.db_query("""
                SELECT version, time, author, ipnr, text, comment, readonly
                FROM wiki WHERE name=%s
                """, ('TestPage',)))

        listener = TestWikiChangeListener(self.env)
        self.assertEqual(page, listener.deleted_version[0])

    def test_delete_page_last_version(self):
        self.env.db_transaction(
            "INSERT INTO wiki VALUES(%s,%s,%s,%s,%s,%s,%s,%s)",
            ('TestPage', 1, 42, 'joe', '::1', 'Bla bla', 'Testing', 0))

        page = WikiPage(self.env, 'TestPage')
        page.delete(version=1)

        self.assertEqual(False, page.exists)

        self.assertEqual([], self.env.db_query("""
            SELECT version, time, author, ipnr, text, comment, readonly
            FROM wiki WHERE name=%s
            """, ('TestPage',)))

        listener = TestWikiChangeListener(self.env)
        self.assertEqual(page, listener.deleted[0])

    def test_rename_page(self):
        data = (1, 42, 'joe', '::1', 'Bla bla', 'Testing', 0)
        self.env.db_transaction(
            "INSERT INTO wiki VALUES(%s,%s,%s,%s,%s,%s,%s,%s)",
            ('TestPage',) + data)
        attachment = Attachment(self.env, 'wiki', 'TestPage')
        attachment.insert('foo.txt', StringIO(), 0, 1)

        page = WikiPage(self.env, 'TestPage')
        page.rename('PageRenamed')
        self.assertEqual('PageRenamed', page.name)

        self.assertEqual([data], self.env.db_query("""
            SELECT version, time, author, ipnr, text, comment, readonly
            FROM wiki WHERE name=%s
            """, ('PageRenamed',)))

        attachments = Attachment.select(self.env, 'wiki', 'PageRenamed')
        self.assertEqual('foo.txt', attachments.next().filename)
        self.assertRaises(StopIteration, attachments.next)
        Attachment.delete_all(self.env, 'wiki', 'PageRenamed')

        old_page = WikiPage(self.env, 'TestPage')
        self.assertEqual(False, old_page.exists)


        self.assertEqual([], self.env.db_query("""
            SELECT version, time, author, ipnr, text, comment, readonly
            FROM wiki WHERE name=%s
            """, ('TestPage',)))

        listener = TestWikiChangeListener(self.env)
        self.assertEqual((page, 'TestPage'), listener.renamed[0])

    def test_invalid_page_name(self):
        invalid_names = ('../Page', 'Page/..', 'Page/////SubPage',
                         'Page/./SubPage', '/PagePrefix', 'PageSuffix/')

        for name in invalid_names:
            page = WikiPage(self.env)
            page.name = name
            page.text = 'Bla bla'
            t = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
            self.assertRaises(TracError, page.save, 'joe', 'Testing', '::1', t)

        page = WikiPage(self.env)
        page.name = 'TestPage'
        page.text = 'Bla bla'
        t = datetime(2001, 1, 1, 1, 1, 1, 0, utc)
        page.save('joe', 'Testing', '::1', t)
        for name in invalid_names:
            page = WikiPage(self.env, 'TestPage')
            self.assertRaises(TracError, page.rename, name)

class WikiResourceChangeListenerTestCase(unittest.TestCase):
    INITIAL_NAME = "Wiki page 1"
    INITIAL_TEXT = "some text"
    INITIAL_AUTHOR = "anAuthor"
    INITIAL_COMMENT = "some comment"
    INITIAL_REMOTE_ADDRESS = "::1"

    def setUp(self):
        self.env = EnvironmentStub(default_data=True)
        self.listener = TestResourceChangeListener(self.env)
        self.listener.resource_type = WikiPage
        self.listener.callback = self.listener_callback

    def tearDown(self):
        self.env.reset_db()

    def test_change_listener_created(self):
        self._create_wiki_page(self.INITIAL_NAME)
        self.assertEqual('created', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, WikiPage))
        self.assertEqual(self.INITIAL_NAME, self.wiki_name)
        self.assertEqual(self.INITIAL_TEXT, self.wiki_text)

    def test_change_listener_text_changed(self):
        wiki_page = self._create_wiki_page(self.INITIAL_NAME)
        CHANGED_TEXT = "some other text"
        wiki_page.text = CHANGED_TEXT
        wiki_page.save("author1", "renamed_comment", "::2")
        self.assertEqual('changed', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, WikiPage))
        self.assertEqual(self.INITIAL_NAME, self.wiki_name)
        self.assertEqual(CHANGED_TEXT, self.wiki_text)
        self.assertEqual({"text":self.INITIAL_TEXT}, self.listener.old_values)

    def test_change_listener_renamed(self):
        wiki_page = self._create_wiki_page(self.INITIAL_NAME)
        CHANGED_NAME = "NewWikiName"
        wiki_page.rename(CHANGED_NAME)
        self.assertEqual('changed', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, WikiPage))
        self.assertEqual(CHANGED_NAME, self.wiki_name)
        self.assertEqual(self.INITIAL_TEXT, self.wiki_text)
        self.assertEqual({"name":self.INITIAL_NAME}, self.listener.old_values)

    def test_change_listener_deleted(self):
        wiki_page = self._create_wiki_page(self.INITIAL_NAME)
        wiki_page.delete()
        self.assertEqual('deleted', self.listener.action)
        self.assertTrue(isinstance(self.listener.resource, WikiPage))
        self.assertEqual(self.INITIAL_NAME, self.wiki_name)

    def _create_wiki_page(self, name=None):
        name = name or self.INITIAL_NAME
        wiki_page = WikiPage(self.env, name)
        wiki_page.text = self.INITIAL_TEXT
        wiki_page.save(
            self.INITIAL_AUTHOR,
            self.INITIAL_COMMENT,
            self.INITIAL_REMOTE_ADDRESS)
        return wiki_page

    def listener_callback(self, action, resource, context, old_values = None):
        self.wiki_name = resource.name
        self.wiki_text = resource.text

def suite():
    suite = unittest.TestSuite()
    suite.addTest(unittest.makeSuite(WikiPageTestCase, 'test'))
    suite.addTest(unittest.makeSuite(
        WikiResourceChangeListenerTestCase, 'test'))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = wikisyntax
# -*- coding: utf-8 -*-

from datetime import datetime
import unittest

from trac.util.datefmt import utc
from trac.wiki.model import WikiPage
from trac.wiki.tests import formatter

TEST_CASES = u"""
============================== wiki: link resolver
wiki:TestPage
wiki:TestPage/
wiki:/TestPage
[wiki:/TestPage]
[wiki:/TestPage ]
[wiki:/TestPage\u200B]
[wiki:/TestPage /TestPage]
wiki:"Space 1 23"
wiki:"C'est l'\xe9t\xe9"
wiki:MissingPage
wiki:12
wiki:abc
------------------------------
<p>
<a class="wiki" href="/wiki/TestPage">wiki:TestPage</a>
<a class="wiki" href="/wiki/TestPage">wiki:TestPage/</a>
<a class="wiki" href="/wiki/TestPage">wiki:/TestPage</a>
<a class="wiki" href="/wiki/TestPage">TestPage</a>
<a class="wiki" href="/wiki/TestPage">TestPage</a>
<a class="wiki" href="/wiki/TestPage">TestPage</a>
<a class="wiki" href="/wiki/TestPage">/TestPage</a>
<a class="wiki" href="/wiki/Space%201%2023">wiki:"Space 1 23"</a>
<a class="wiki" href="/wiki/C'est%20l'%C3%A9t%C3%A9">wiki:"C'est l'\xe9t\xe9"</a>
<a class="missing wiki" href="/wiki/MissingPage" rel="nofollow">wiki:MissingPage?</a>
<a class="missing wiki" href="/wiki/12" rel="nofollow">wiki:12?</a>
<a class="missing wiki" href="/wiki/abc" rel="nofollow">wiki:abc?</a>
</p>
------------------------------
============================== wiki: link resolver + query and fragment
wiki:TestPage?format=txt
wiki:TestPage/?version=12
wiki:TestPage/?action=diff&version=12
wiki:"Space 1 23#heading"
------------------------------
<p>
<a class="wiki" href="/wiki/TestPage?format=txt">wiki:TestPage?format=txt</a>
<a class="wiki" href="/wiki/TestPage?version=12">wiki:TestPage/?version=12</a>
<a class="wiki" href="/wiki/TestPage?action=diff&amp;version=12">wiki:TestPage/?action=diff&amp;version=12</a>
<a class="wiki" href="/wiki/Space%201%2023#heading">wiki:"Space 1 23#heading"</a>
</p>
------------------------------
============================== WikiPageNames conformance
CamelCase AlabamA ABc AlaBamA FooBar
------------------------------
<p>
<a class="missing wiki" href="/wiki/CamelCase" rel="nofollow">CamelCase?</a> AlabamA ABc AlaBamA <a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>
</p>
------------------------------
============================== WikiPageNames conformance (unicode)
Smogstore should produce a link
and so should wiki:berflssigkeitsTheorie
------------------------------
<p>
<a class="missing wiki" href="/wiki/Sm%C3%85ogstore" rel="nofollow">Smogstore?</a> should produce a link
and so should <a class="missing wiki" href="/wiki/%C3%9Cberfl%C3%BCssigkeitsTheorie" rel="nofollow">wiki:berflssigkeitsTheorie?</a>
</p>
------------------------------
============================== More WikiPageNames conformance
CamelCase,CamelCase.CamelCase: CamelCase
But not CamelCase2
nor CamelCase_
------------------------------
<p>
<a class="missing wiki" href="/wiki/CamelCase" rel="nofollow">CamelCase?</a>,<a class="missing wiki" href="/wiki/CamelCase" rel="nofollow">CamelCase?</a>.<a class="missing wiki" href="/wiki/CamelCase" rel="nofollow">CamelCase?</a>: <a class="missing wiki" href="/wiki/CamelCase" rel="nofollow">CamelCase?</a>
But not CamelCase2
nor CamelCase_
</p>
------------------------------
============================== Escaping WikiPageNames
!CamelCase
------------------------------
<p>
CamelCase
</p>
------------------------------
============================== WikiPageNames endings
foo (FooBar )
foo FooBar: something
foo FooBar.
FooBar, foo
foo FooBar;
foo FooBar!
foo FooBar?
foo (FooBar)
foo {FooBar}
foo 'FooBar'
foo "FooBar"
foo [FooBar]
------------------------------
<p>
foo (<a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a> )
foo <a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>: something
foo <a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>.
<a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>, foo
foo <a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>;
foo <a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>!
foo <a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>?
foo (<a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>)
foo {<a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>}
foo '<a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>'
foo "<a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>"
foo [<a class="missing wiki" href="/wiki/FooBar" rel="nofollow">FooBar?</a>]
</p>
------------------------------
============================== WikiPageNames counter examples
A0B1, ST62T53C6, IR32V1H000
------------------------------
<p>
A0B1, ST62T53C6, IR32V1H000
</p>
------------------------------
============================== WikiPageNames with fragment identifier
SandBox#heading-fixed-id

wiki:TracSubversion#TracandSubversion1.3.1. etc.
TracSubversion#TracandSubversion1.3.1. etc.
------------------------------
<p>
<a class="missing wiki" href="/wiki/SandBox#heading-fixed-id" rel="nofollow">SandBox#heading-fixed-id?</a>
</p>
<p>
<a class="missing wiki" href="/wiki/TracSubversion#TracandSubversion1.3.1" rel="nofollow">wiki:TracSubversion#TracandSubversion1.3.1?</a>. etc.
<a class="missing wiki" href="/wiki/TracSubversion#TracandSubversion1.3.1" rel="nofollow">TracSubversion#TracandSubversion1.3.1?</a>. etc.
</p>
------------------------------
============================== WikiPageNames with fragment id (performance test)
BillOfMaterials#get_bill_of_materials_from_room_xml(fpxml=nil)

[BillOfMaterials#get_bill_of_materials_from_room_xml(fpxml=nil)]

[BillOfMaterials#get_bill_of_materials_from_room_xml(fpxml=nil) speed]
------------------------------
<p>
<a class="missing wiki" href="/wiki/BillOfMaterials#get_bill_of_materials_from_room_xml" rel="nofollow">BillOfMaterials#get_bill_of_materials_from_room_xml?</a>(fpxml=nil)
</p>
<p>
[<a class="missing wiki" href="/wiki/BillOfMaterials#get_bill_of_materials_from_room_xml" rel="nofollow">BillOfMaterials#get_bill_of_materials_from_room_xml?</a>(fpxml=nil)]
</p>
<p>
[<a class="missing wiki" href="/wiki/BillOfMaterials#get_bill_of_materials_from_room_xml" rel="nofollow">BillOfMaterials#get_bill_of_materials_from_room_xml?</a>(fpxml=nil) speed]
</p>
------------------------------
============================== WikiPageNames counter examples (paths)
/absolute/path/is/NotWiki and relative/path/is/NotWiki and ../higher/is/NotWiki
but ThisIs/SubWiki and now This/Also
and ../Relative/Camel or /Absolute/Camel as well
------------------------------
<p>
/absolute/path/is/NotWiki and relative/path/is/NotWiki and ../higher/is/NotWiki
but <a class="missing wiki" href="/wiki/ThisIs/SubWiki" rel="nofollow">ThisIs/SubWiki?</a> and now <a class="missing wiki" href="/wiki/This/Also" rel="nofollow">This/Also?</a>
and <a class="missing wiki" href="/wiki/Relative/Camel" rel="nofollow">../Relative/Camel?</a> or <a class="missing wiki" href="/wiki/Absolute/Camel" rel="nofollow">/Absolute/Camel?</a> as well
</p>
------------------------------
============================== WikiPageNames counter examples (numbers)
8FjBpOmy
anotherWikiPageName
------------------------------
<p>
8FjBpOmy
anotherWikiPageName
</p>
------------------------------
8FjBpOmy
anotherWikiPageName
============================== WikiPageNames counter examples (unicode)
Smbokstaver should not produce a link
neither should AbAb nor AbAbb
------------------------------
<p>
Smbokstaver should not produce a link
neither should AbAb nor AbAbb
</p>
------------------------------
Smbokstaver should not produce a link
neither should AbAb nor AbAbb
============================== not a WikiPageNames at all (#9025 regression)
[]------------------------------
<p>
[]
</p>
------------------------------
[]
============================== MoinMoin style forced links
This is a ["Wiki"] page link.
This is a ["Wiki" wiki page] link with label.
This is a ["Wiki?param=1#fragment"] page link with query and fragment.
------------------------------
<p>
This is a <a class="missing wiki" href="/wiki/Wiki" rel="nofollow">Wiki?</a> page link.
This is a <a class="missing wiki" href="/wiki/Wiki" rel="nofollow">wiki page?</a> link with label.
This is a <a class="missing wiki" href="/wiki/Wiki?param=1#fragment" rel="nofollow">Wiki?</a> page link with query and fragment.
</p>
------------------------------
============================== Wiki links with @version
wiki:page@12
WikiStart@12
WikiStart@12#heading
[WikiStart@12]
[WikiStart@12#heading]
This is a ["Wiki@12"] page link.
[wiki:WikiStart@12?format=txt v12 as text]
------------------------------
<p>
<a class="missing wiki" href="/wiki/page?version=12" rel="nofollow">wiki:page@12?</a>
<a class="wiki" href="/wiki/WikiStart?version=12">WikiStart@12</a>
<a class="wiki" href="/wiki/WikiStart?version=12#heading">WikiStart@12#heading</a>
[<a class="wiki" href="/wiki/WikiStart?version=12">WikiStart@12</a>]
[<a class="wiki" href="/wiki/WikiStart?version=12#heading">WikiStart@12#heading</a>]
This is a <a class="missing wiki" href="/wiki/Wiki?version=12" rel="nofollow">Wiki@12?</a> page link.
<a class="wiki" href="/wiki/WikiStart?version=12&amp;format=txt">v12 as text</a>
</p>
------------------------------
============================== WikiPageName with label
See details of the [WikiPageNames wiki page name] syntax.
Here's a [BadExample\fbad] example with special whitespace.
We can also [WikiLabels '"use [quotes]"']
or [WikiLabels "'use [quotes]'"]
------------------------------
<p>
See details of the <a class="missing wiki" href="/wiki/WikiPageNames" rel="nofollow">wiki page name?</a> syntax.
Here's a <a class="missing wiki" href="/wiki/BadExample" rel="nofollow">bad?</a> example with special whitespace.
We can also <a class="missing wiki" href="/wiki/WikiLabels" rel="nofollow">"use [quotes]"?</a>
or <a class="missing wiki" href="/wiki/WikiLabels" rel="nofollow">'use [quotes]'?</a>
</p>
------------------------------
============================== WikiPageName with label should be strict...
new_channel_name [, '''integer''' handle [, '''boolean''' test]]
------------------------------
<p>
new_channel_name [, <strong>integer</strong> handle [, <strong>boolean</strong> test]]
</p>
------------------------------
============================== InterTrac for wiki
t:wiki:InterTrac
trac:wiki:InterTrac
[t:wiki:InterTrac intertrac]
[trac:wiki:InterTrac intertrac]
[trac:wiki:JonasBorgstrm jonas]
------------------------------
<p>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/wiki%3AInterTrac" title="wiki:InterTrac in Trac's Trac"><span class="icon"></span>t:wiki:InterTrac</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/wiki%3AInterTrac" title="wiki:InterTrac in Trac's Trac"><span class="icon"></span>trac:wiki:InterTrac</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/wiki%3AInterTrac" title="wiki:InterTrac in Trac's Trac"><span class="icon"></span>intertrac</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/wiki%3AInterTrac" title="wiki:InterTrac in Trac's Trac"><span class="icon"></span>intertrac</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/wiki%3AJonasBorgstr%C3%B6m" title="wiki:JonasBorgstrm in Trac's Trac"><span class="icon"></span>jonas</a>
</p>
------------------------------
============================== Wiki InterTrac shorthands
t:InterTrac
trac:InterTrac
[t:InterTrac intertrac]
[trac:InterTrac intertrac]
[trac:JonasBorgstrm jonas]
------------------------------
<p>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/InterTrac" title="InterTrac in Trac's Trac"><span class="icon"></span>t:InterTrac</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/InterTrac" title="InterTrac in Trac's Trac"><span class="icon"></span>trac:InterTrac</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/InterTrac" title="InterTrac in Trac's Trac"><span class="icon"></span>intertrac</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/InterTrac" title="InterTrac in Trac's Trac"><span class="icon"></span>intertrac</a>
<a class="ext-link" href="http://trac.edgewall.org/intertrac/JonasBorgstr%C3%B6m" title="JonasBorgstrm in Trac's Trac"><span class="icon"></span>jonas</a>
</p>
------------------------------
============================== InterWiki links
This is the original MeatBall:InterMapTxt wiki page.
Checkout the [tsvn:http://svn.edgewall.com/repos/trac Trac Repository].

complex link complex:a:test with positional arguments
complex link complex:a (not enough arguments)
complex link complex:a:test:more (too many arguments)

in trac.ini inter:b:resource
in trac.ini over:c:something overrides wiki

NoLink:ignored
NoLink:
NoLink: ...
------------------------------
<p>
This is the original <a class="ext-link" href="http://www.usemod.com/cgi-bin/mb.pl?InterMapTxt" title="InterMapTxt in MeatBall..."><span class="icon"></span>MeatBall:InterMapTxt</a> wiki page.
Checkout the <a class="ext-link" href="tsvn:http://svn.edgewall.com/repos/trac" title="http://svn.edgewall.com/repos/trac in tsvn"><span class="icon"></span>Trac Repository</a>.
</p>
<p>
complex link <a class="ext-link" href="http://server/a/page/test?format=txt" title="resource test in a"><span class="icon"></span>complex:a:test</a> with positional arguments
complex link <a class="ext-link" href="http://server/a/page/?format=txt" title="resource  in a"><span class="icon"></span>complex:a</a> (not enough arguments)
complex link <a class="ext-link" href="http://server/a/page/test:more?format=txt" title="resource test:more in a"><span class="icon"></span>complex:a:test:more</a> (too many arguments)
</p>
<p>
in trac.ini <a class="ext-link" href="http://inter/b/page/resource" title="Resource resource in b"><span class="icon"></span>inter:b:resource</a>
in trac.ini <a class="ext-link" href="http://over/c/page/something" title="c:something in over"><span class="icon"></span>over:c:something</a> overrides wiki
</p>
<p>
NoLink:ignored
<a class="missing wiki" href="/wiki/NoLink" rel="nofollow">NoLink?</a>:
<a class="missing wiki" href="/wiki/NoLink" rel="nofollow">NoLink?</a>: ...
</p>
------------------------------
============================== InterWiki links with parameters and fragment
See also MeatBall:InterMapTxt#there wiki page
and MeatBall:InterMapTxt?format=txt#there wiki page.

complex link complex:a:test?go#there with positional arguments
------------------------------
<p>
See also <a class="ext-link" href="http://www.usemod.com/cgi-bin/mb.pl?InterMapTxt#there" title="InterMapTxt in MeatBall..."><span class="icon"></span>MeatBall:InterMapTxt#there</a> wiki page
and <a class="ext-link" href="http://www.usemod.com/cgi-bin/mb.pl?InterMapTxt&amp;format=txt#there" title="InterMapTxt in MeatBall..."><span class="icon"></span>MeatBall:InterMapTxt?format=txt#there</a> wiki page.
</p>
<p>
complex link <a class="ext-link" href="http://server/a/page/test?format=txt&amp;go#there" title="resource test in a"><span class="icon"></span>complex:a:test?go#there</a> with positional arguments
</p>
------------------------------
============================== Regression for #9712
This is not a link: x,://localhost
------------------------------
<p>
This is not a link: x,:<em>localhost
</em></p>
------------------------------
============================== Wiki links with @version using unicode digits
WikiStart@
WikiStart@#heading
[WikiStart@]
[WikiStart@#heading]
------------------------------
<p>
<a class="wiki" href="/wiki/WikiStart">WikiStart</a>@
<a class="wiki" href="/wiki/WikiStart">WikiStart</a>@#heading
[<a class="wiki" href="/wiki/WikiStart">WikiStart</a>@]
[<a class="wiki" href="/wiki/WikiStart">WikiStart</a>@#heading]
</p>
------------------------------
""" #" Emacs likes it that way better


RELATIVE_LINKS_TESTS = u"""
============================== Relative to the project url
[//docs Documentation]
[//docs?param=1#fragment Documentation]
[//docs]
[//docs //docs]
[//docs?param=1#fragment]
[// Home]
[//]
[//?param=1#fragment]
------------------------------
<p>
<a href="/docs">Documentation</a>
<a href="/docs?param=1#fragment">Documentation</a>
<a href="/docs">docs</a>
<a href="/docs">//docs</a>
<a href="/docs?param=1#fragment">docs</a>
<a href="/">Home</a>
<a href="/">//</a>
<a href="/?param=1#fragment">//</a>
</p>
------------------------------
============================== Relative to the base url
[/newticket?priority=high#fragment bug]
[/newticket?priority=high#fragment]
[/newticket]
[/newticket /newticket]
[/ Project]
[/]
[/?param=1#fragment]
------------------------------
<p>
<a href="/newticket?priority=high#fragment">bug</a>
<a href="/newticket?priority=high#fragment">newticket</a>
<a href="/newticket">newticket</a>
<a href="/newticket">/newticket</a>
<a href="/">Project</a>
<a href="/">/</a>
<a href="/?param=1#fragment">/</a>
</p>
------------------------------
============================== Relative to the current page
[.]
[./]
[..]
[../]
[./../.]
[. this page]
[./Detail see detail]
[./Detail]
[./Detail ./Detail]
[.. see parent]
[../Other see other]
[../Other]
[../Other ../Other]
[.././../Other]
------------------------------
<p>
<a class="wiki" href="/wiki/Main/Sub">.</a>
<a class="wiki" href="/wiki/Main/Sub">./</a>
<a class="missing wiki" href="/wiki/Main" rel="nofollow">..?</a>
<a class="missing wiki" href="/wiki/Main" rel="nofollow">../?</a>
<a class="missing wiki" href="/wiki/Main" rel="nofollow">./../.?</a>
<a class="wiki" href="/wiki/Main/Sub">this page</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail" rel="nofollow">see detail?</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail" rel="nofollow">Detail?</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail" rel="nofollow">./Detail?</a>
<a class="missing wiki" href="/wiki/Main" rel="nofollow">see parent?</a>
<a class="missing wiki" href="/wiki/Main/Other" rel="nofollow">see other?</a>
<a class="missing wiki" href="/wiki/Main/Other" rel="nofollow">Other?</a>
<a class="missing wiki" href="/wiki/Main/Other" rel="nofollow">../Other?</a>
<a class="missing wiki" href="/wiki/Other" rel="nofollow">Other?</a>
</p>
------------------------------
============================== Relative to the current page, in wiki realm
[wiki:. this page]
[wiki:./Detail]
[wiki:"./Detail"]
[wiki:./Detail ./Detail]
[wiki:./Detail see detail]
[wiki:.. see parent]
[wiki:../Other see other]
[wiki:.././../Other]
["."]
[".?param=1#fragment"]
["./Detail"]
["./Detail?param=1#fragment"]
[".."]
["..?param=1#fragment"]
["../Other"]
["../Other?param=1#fragment"]
[".././../Other"]
------------------------------
<p>
<a class="wiki" href="/wiki/Main/Sub">this page</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail" rel="nofollow">Detail?</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail" rel="nofollow">Detail?</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail" rel="nofollow">./Detail?</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail" rel="nofollow">see detail?</a>
<a class="missing wiki" href="/wiki/Main" rel="nofollow">see parent?</a>
<a class="missing wiki" href="/wiki/Main/Other" rel="nofollow">see other?</a>
<a class="missing wiki" href="/wiki/Other" rel="nofollow">Other?</a>
<a class="wiki" href="/wiki/Main/Sub">.</a>
<a class="wiki" href="/wiki/Main/Sub?param=1#fragment">.</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail" rel="nofollow">Detail?</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail?param=1#fragment" rel="nofollow">Detail?</a>
<a class="missing wiki" href="/wiki/Main" rel="nofollow">..?</a>
<a class="missing wiki" href="/wiki/Main?param=1#fragment" rel="nofollow">..?</a>
<a class="missing wiki" href="/wiki/Main/Other" rel="nofollow">Other?</a>
<a class="missing wiki" href="/wiki/Main/Other?param=1#fragment" rel="nofollow">Other?</a>
<a class="missing wiki" href="/wiki/Other" rel="nofollow">Other?</a>
</p>
------------------------------
============================== Relative to the current page, as CamelCase
OnePage/SubPage
./SubPage
../SiblingPage
.././../HigherPage
/TopPage
------------------------------
<p>
<a class="missing wiki" href="/wiki/Main/OnePage/SubPage" rel="nofollow">OnePage/SubPage?</a>
<a class="missing wiki" href="/wiki/Main/Sub/SubPage" rel="nofollow">./SubPage?</a>
<a class="missing wiki" href="/wiki/Main/SiblingPage" rel="nofollow">../SiblingPage?</a>
<a class="missing wiki" href="/wiki/HigherPage" rel="nofollow">.././../HigherPage?</a>
<a class="missing wiki" href="/wiki/TopPage" rel="nofollow">/TopPage?</a>
</p>
------------------------------
============================== Relative to the current page with query strings and fragments
[#topic see topic]
[?param=1#topic see topic]
[.#topic see topic]
[.?param=1#topic see topic]
[./#topic see topic]
[./?param=1#topic see topic]
[./Detail#topic see detail]
[./Detail?param=1#topic see detail]
[./Detail?param=1#topic]
[..#topic see parent]
[..?param=1#topic see parent]
[../#topic see parent]
[../?param=1#topic see parent]
[../Other#topic see other]
[../Other?param=1#topic see other]
[../Other?param=1#topic]
[../Other/#topic see other]
[../Other/?param=1#topic see other]
------------------------------
<p>
<a class="wiki" href="/wiki/Main/Sub#topic">see topic</a>
<a class="wiki" href="/wiki/Main/Sub?param=1#topic">see topic</a>
<a class="wiki" href="/wiki/Main/Sub#topic">see topic</a>
<a class="wiki" href="/wiki/Main/Sub?param=1#topic">see topic</a>
<a class="wiki" href="/wiki/Main/Sub#topic">see topic</a>
<a class="wiki" href="/wiki/Main/Sub?param=1#topic">see topic</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail#topic" rel="nofollow">see detail?</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail?param=1#topic" rel="nofollow">see detail?</a>
<a class="missing wiki" href="/wiki/Main/Sub/Detail?param=1#topic" rel="nofollow">Detail?</a>
<a class="missing wiki" href="/wiki/Main#topic" rel="nofollow">see parent?</a>
<a class="missing wiki" href="/wiki/Main?param=1#topic" rel="nofollow">see parent?</a>
<a class="missing wiki" href="/wiki/Main#topic" rel="nofollow">see parent?</a>
<a class="missing wiki" href="/wiki/Main?param=1#topic" rel="nofollow">see parent?</a>
<a class="missing wiki" href="/wiki/Main/Other#topic" rel="nofollow">see other?</a>
<a class="missing wiki" href="/wiki/Main/Other?param=1#topic" rel="nofollow">see other?</a>
<a class="missing wiki" href="/wiki/Main/Other?param=1#topic" rel="nofollow">Other?</a>
<a class="missing wiki" href="/wiki/Main/Other#topic" rel="nofollow">see other?</a>
<a class="missing wiki" href="/wiki/Main/Other?param=1#topic" rel="nofollow">see other?</a>
</p>
------------------------------
""" # "


SPLIT_PAGE_NAMES_TESTS = u"""
============================== Splitting relative links
[//WikiPage]
[/WikiPage]
[./WikiPage]
[../WikiPage]
[//WikiPage?param=1#fragment]
[/WikiPage?param=1#fragment]
[./WikiPage?param=1#fragment]
[../WikiPage?param=1#fragment]
But not [./wiki_page]
And not [../WikiPage WikiPage]
------------------------------
<p>
<a href="/WikiPage">Wiki Page</a>
<a href="/WikiPage">Wiki Page</a>
<a class="missing wiki" href="/wiki/Main/Sub/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">Wiki Page?</a>
<a href="/WikiPage?param=1#fragment">Wiki Page</a>
<a href="/WikiPage?param=1#fragment">Wiki Page</a>
<a class="missing wiki" href="/wiki/Main/Sub/WikiPage?param=1#fragment" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage?param=1#fragment" rel="nofollow">Wiki Page?</a>
But not <a class="missing wiki" href="/wiki/Main/Sub/wiki_page" rel="nofollow">wiki_page?</a>
And not <a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">WikiPage?</a>
</p>
------------------------------
============================== Splitting scoped links
[wiki:WikiPage]
[wiki:./WikiPage]
[wiki:../WikiPage]
[wiki:./.././WikiPage]
[wiki:"./.././WikiPage"]
[wiki:WikiPage?param=1#fragment]
[wiki:./WikiPage?param=1#fragment]
[wiki:../WikiPage?param=1#fragment]
But not [wiki:./wiki_page]
And not [wiki:../WikiPage WikiPage]
------------------------------
<p>
<a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/Sub/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage?param=1#fragment" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/Sub/WikiPage?param=1#fragment" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage?param=1#fragment" rel="nofollow">Wiki Page?</a>
But not <a class="missing wiki" href="/wiki/Main/Sub/wiki_page" rel="nofollow">wiki_page?</a>
And not <a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">WikiPage?</a>
</p>
------------------------------
============================== Splitting internal free links
["WikiPage"]
["./WikiPage"]
["../WikiPage"]
["./.././WikiPage"]
["WikiPage?param=1#fragment"]
["./WikiPage?param=1#fragment"]
["../WikiPage?param=1#fragment"]
But not ["./wiki_page"]
And not ["../WikiPage" WikiPage]
------------------------------
<p>
<a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/Sub/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage?param=1#fragment" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/Sub/WikiPage?param=1#fragment" rel="nofollow">Wiki Page?</a>
<a class="missing wiki" href="/wiki/Main/WikiPage?param=1#fragment" rel="nofollow">Wiki Page?</a>
But not <a class="missing wiki" href="/wiki/Main/Sub/wiki_page" rel="nofollow">wiki_page?</a>
And not <a class="missing wiki" href="/wiki/Main/WikiPage" rel="nofollow">WikiPage?</a>
</p>
------------------------------
""" # "


SCOPED_LINKS_TESTS = u"""
============================== Scoped links for hierarchical pages
ThirdLevel
[wiki:ThirdLevel]
OtherThirdLevel
[wiki:OtherThirdLevel]
SecondLevel/OtherThirdLevel
[wiki:SecondLevel/OtherThirdLevel]
SecondLevel
[wiki:SecondLevel]
FirstLevel
[wiki:FirstLevel]
TestPage
[wiki:TestPage]
MissingPage
[wiki:MissingPage]
FirstLevel/MissingPage
[wiki:FirstLevel/MissingPage]
SecondLevel/MissingPage
[wiki:SecondLevel/MissingPage]
MissingFirstLevel/MissingPage
[wiki:MissingFirstLevel/MissingPage]
["/OtherThirdLevel"]
[wiki:/OtherThirdLevel]
[wiki:/OtherThirdLevel /OtherThirdLevel]
------------------------------
<p>
<a class="wiki" href="/wiki/FirstLevel/SecondLevel/ThirdLevel">ThirdLevel</a>
<a class="wiki" href="/wiki/FirstLevel/SecondLevel/ThirdLevel">ThirdLevel</a>
<a class="wiki" href="/wiki/FirstLevel/SecondLevel/OtherThirdLevel">OtherThirdLevel</a>
<a class="wiki" href="/wiki/FirstLevel/SecondLevel/OtherThirdLevel">OtherThirdLevel</a>
<a class="wiki" href="/wiki/FirstLevel/SecondLevel/OtherThirdLevel">SecondLevel/OtherThirdLevel</a>
<a class="wiki" href="/wiki/FirstLevel/SecondLevel/OtherThirdLevel">SecondLevel/OtherThirdLevel</a>
<a class="wiki" href="/wiki/FirstLevel/SecondLevel">SecondLevel</a>
<a class="wiki" href="/wiki/FirstLevel/SecondLevel">SecondLevel</a>
<a class="wiki" href="/wiki/FirstLevel">FirstLevel</a>
<a class="wiki" href="/wiki/FirstLevel">FirstLevel</a>
<a class="wiki" href="/wiki/TestPage">TestPage</a>
<a class="wiki" href="/wiki/TestPage">TestPage</a>
<a class="missing wiki" href="/wiki/FirstLevel/SecondLevel/MissingPage" rel="nofollow">MissingPage?</a>
<a class="missing wiki" href="/wiki/FirstLevel/SecondLevel/MissingPage" rel="nofollow">MissingPage?</a>
<a class="missing wiki" href="/wiki/FirstLevel/MissingPage" rel="nofollow">FirstLevel/MissingPage?</a>
<a class="missing wiki" href="/wiki/FirstLevel/MissingPage" rel="nofollow">FirstLevel/MissingPage?</a>
<a class="missing wiki" href="/wiki/FirstLevel/SecondLevel/MissingPage" rel="nofollow">SecondLevel/MissingPage?</a>
<a class="missing wiki" href="/wiki/FirstLevel/SecondLevel/MissingPage" rel="nofollow">SecondLevel/MissingPage?</a>
<a class="missing wiki" href="/wiki/FirstLevel/SecondLevel/MissingFirstLevel/MissingPage" rel="nofollow">MissingFirstLevel/MissingPage?</a>
<a class="missing wiki" href="/wiki/FirstLevel/SecondLevel/MissingFirstLevel/MissingPage" rel="nofollow">MissingFirstLevel/MissingPage?</a>
<a class="missing wiki" href="/wiki/OtherThirdLevel" rel="nofollow">OtherThirdLevel?</a>
<a class="missing wiki" href="/wiki/OtherThirdLevel" rel="nofollow">OtherThirdLevel?</a>
<a class="missing wiki" href="/wiki/OtherThirdLevel" rel="nofollow">/OtherThirdLevel?</a>
</p>
------------------------------
""" # "


def wiki_setup(tc):
    tc.env.config.set('wiki', 'render_unsafe_content', True) # for #9712
    now = datetime.now(utc)
    wiki0 = WikiPage(tc.env)
    wiki0.name = 'Main/Sub'
    wiki0.text = '--'
    wiki0.save('joe', 'subpage', '::1', now)

    wiki1 = WikiPage(tc.env)
    wiki1.name = 'TestPage'
    wiki1.text = '--'
    wiki1.save('joe', 'normal WikiPageNames', '::1', now)

    wiki2 = WikiPage(tc.env)
    wiki2.name = 'Space 1 23'
    wiki2.text = '--'
    wiki2.save('joe', 'not a WikiPageNames', '::1', now)

    wiki3 = WikiPage(tc.env)
    wiki3.name = u"C'est l'\xe9t\xe9"
    wiki3.text = '--'
    wiki3.save('joe', 'unicode WikiPageNames', '::1', now)

    imt = WikiPage(tc.env)
    imt.name = u"InterMapTxt"
    imt.text = """
This is the InterMapTxt
----
{{{
MeatBall 	http://www.usemod.com/cgi-bin/mb.pl? # $1 in MeatBall...
tsvn            tsvn:
complex         http://server/$1/page/$2?format=txt  # resource $2 in $1
over        http://unused/? # Overridden in trac.ini
}}}
----
{{{
nolink          http://noweb
}}}
"""
    imt.save('joe', 'test InterWiki links', '::1', now)
    tc.env.config.set('interwiki', 'inter',
                      'http://inter/$1/page/$2 Resource $2 in $1')
    tc.env.config.set('interwiki', 'over',
                      'http://over/$1/page/$2')

    w = WikiPage(tc.env)
    w.name = 'FirstLevel'
    w.text = '--'
    w.save('joe', 'first level of hierarchy', '::1', now)

    w = WikiPage(tc.env)
    w.name = 'FirstLevel/SecondLevel'
    w.text = '--'
    w.save('joe', 'second level of hierarchy', '::1', now)

    w = WikiPage(tc.env)
    w.name = 'FirstLevel/SecondLevel/ThirdLevel'
    w.text = '--'
    w.save('joe', 'third level of hierarchy', '::1', now)

    w = WikiPage(tc.env)
    w.name = 'FirstLevel/SecondLevel/OtherThirdLevel'
    w.text = '--'
    w.save('joe', 'other third level of hierarchy', '::1', now)


def wiki_teardown(tc):
    tc.env.reset_db()


def wiki_setup_split(tc):
    tc.env.config.set('wiki', 'split_page_names', 'true')
    wiki_setup(tc)


def suite():
    suite = unittest.TestSuite()
    suite.addTest(formatter.suite(TEST_CASES, wiki_setup, __file__,
                                  wiki_teardown))
    suite.addTest(formatter.suite(RELATIVE_LINKS_TESTS, wiki_setup, __file__,
                                  wiki_teardown,
                                  context=('wiki', 'Main/Sub')))
    suite.addTest(formatter.suite(SPLIT_PAGE_NAMES_TESTS, wiki_setup_split,
                                  __file__, wiki_teardown,
                                  context=('wiki', 'Main/Sub')))
    suite.addTest(formatter.suite(SCOPED_LINKS_TESTS, wiki_setup, __file__,
                                  wiki_teardown,
                                  context=('wiki',
                                      'FirstLevel/SecondLevel/ThirdLevel')))
    return suite

if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = web_api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from trac.core import *
from trac.resource import Resource
from trac.util import as_int
from trac.web.api import IRequestHandler
from trac.web.chrome import web_context
from trac.wiki.formatter import format_to


class WikiRenderer(Component):
    """Wiki text renderer."""

    implements(IRequestHandler)

    # IRequestHandler methods

    def match_request(self, req):
        return req.path_info == '/wiki_render'

    def process_request(self, req):
        # Allow all POST requests (with a valid __FORM_TOKEN, ensuring that
        # the client has at least some permission). Additionally, allow GET
        # requests from TRAC_ADMIN for testing purposes.
        if req.method != 'POST':
            req.perm.require('TRAC_ADMIN')
        realm = req.args.get('realm', 'wiki')
        id = req.args.get('id')
        version = as_int(req.args.get('version'), None)
        text = req.args.get('text', '')
        flavor = req.args.get('flavor')
        options = {}
        if 'escape_newlines' in req.args:
            options['escape_newlines'] = bool(int(req.args['escape_newlines']
                                                  or 0))
        if 'shorten' in req.args:
            options['shorten'] = bool(int(req.args['shorten'] or 0))

        resource = Resource(realm, id=id, version=version)
        context = web_context(req, resource)
        rendered = format_to(self.env, flavor, context, text, **options)
        req.send(rendered.encode('utf-8'))

########NEW FILE########
__FILENAME__ = web_ui
# -*- coding: utf-8 -*-
#
# Copyright (C) 2003-2009 Edgewall Software
# Copyright (C) 2003-2005 Jonas Borgstrm <jonas@edgewall.com>
# Copyright (C) 2004-2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Jonas Borgstrm <jonas@edgewall.com>
#         Christopher Lenz <cmlenz@gmx.de>

from __future__ import with_statement

import pkg_resources
import re

from genshi.builder import tag

from trac.attachment import AttachmentModule
from trac.config import IntOption
from trac.core import *
from trac.mimeview.api import IContentConverter, Mimeview
from trac.perm import IPermissionRequestor
from trac.resource import *
from trac.search import ISearchSource, search_to_sql, shorten_result
from trac.timeline.api import ITimelineEventProvider
from trac.util import get_reporter_id
from trac.util.datefmt import from_utimestamp, to_utimestamp
from trac.util.text import shorten_line
from trac.util.translation import _, tag_
from trac.versioncontrol.diff import get_diff_options, diff_blocks
from trac.web.api import IRequestHandler
from trac.web.chrome import (Chrome, INavigationContributor, ITemplateProvider,
                             add_ctxtnav, add_link, add_notice, add_script,
                             add_stylesheet, add_warning, prevnext_nav,
                             web_context)
from trac.wiki.api import IWikiPageManipulator, WikiSystem, validate_page_name
from trac.wiki.formatter import format_to, OneLinerFormatter
from trac.wiki.model import WikiPage


class InvalidWikiPage(TracError):
    """Exception raised when a Wiki page fails validation.

    :deprecated: Not used anymore since 0.11
    """


class WikiModule(Component):

    implements(IContentConverter, INavigationContributor, IPermissionRequestor,
               IRequestHandler, ITimelineEventProvider, ISearchSource,
               ITemplateProvider)

    page_manipulators = ExtensionPoint(IWikiPageManipulator)

    max_size = IntOption('wiki', 'max_size', 262144,
        """Maximum allowed wiki page size in bytes. (''since 0.11.2'')""")

    PAGE_TEMPLATES_PREFIX = 'PageTemplates/'
    DEFAULT_PAGE_TEMPLATE = 'DefaultPage'

    # IContentConverter methods

    def get_supported_conversions(self):
        yield ('txt', _('Plain Text'), 'txt', 'text/x-trac-wiki', 'text/plain',
               9)

    def convert_content(self, req, mimetype, content, key):
        return (content, 'text/plain;charset=utf-8')

    # INavigationContributor methods

    def get_active_navigation_item(self, req):
        return 'wiki'

    def get_navigation_items(self, req):
        if 'WIKI_VIEW' in req.perm('wiki'):
            yield ('mainnav', 'wiki',
                   tag.a(_('Wiki'), href=req.href.wiki(), accesskey=1))
            yield ('metanav', 'help',
                   tag.a(_('Help/Guide'), href=req.href.wiki('TracGuide'),
                         accesskey=6))

    # IPermissionRequestor methods

    def get_permission_actions(self):
        actions = ['WIKI_CREATE', 'WIKI_DELETE', 'WIKI_MODIFY', 'WIKI_RENAME',
                   'WIKI_VIEW']
        return actions + [('WIKI_ADMIN', actions)]

    # IRequestHandler methods

    def match_request(self, req):
        match = re.match(r'/wiki(?:/(.+))?$', req.path_info)
        if match:
            if match.group(1):
                req.args['page'] = match.group(1)
            return 1

    def process_request(self, req):
        action = req.args.get('action', 'view')
        pagename = req.args.get('page', 'WikiStart')
        version = req.args.get('version')
        old_version = req.args.get('old_version')

        if pagename.startswith('/') or pagename.endswith('/') or \
                '//' in pagename:
            pagename = re.sub(r'/{2,}', '/', pagename.strip('/'))
            req.redirect(req.href.wiki(pagename))
        if not validate_page_name(pagename):
            raise TracError(_("Invalid Wiki page name '%(name)s'",
                              name=pagename))

        page = WikiPage(self.env, pagename)
        versioned_page = WikiPage(self.env, pagename, version=version)

        req.perm(page.resource).require('WIKI_VIEW')
        req.perm(versioned_page.resource).require('WIKI_VIEW')

        if version and versioned_page.version != int(version):
            raise ResourceNotFound(
                _('No version "%(num)s" for Wiki page "%(name)s"',
                  num=version, name=page.name))

        add_stylesheet(req, 'common/css/wiki.css')

        if req.method == 'POST':
            if action == 'edit':
                if 'cancel' in req.args:
                    req.redirect(req.href.wiki(page.name))

                has_collision = int(version) != page.version
                for a in ('preview', 'diff', 'merge'):
                    if a in req.args:
                        action = a
                        break
                versioned_page.text = req.args.get('text')
                valid = self._validate(req, versioned_page)
                if action == 'edit' and not has_collision and valid:
                    return self._do_save(req, versioned_page)
                else:
                    return self._render_editor(req, page, action, has_collision)
            elif action == 'delete':
                self._do_delete(req, versioned_page)
            elif action == 'rename':
                return self._do_rename(req, page)
            elif action == 'diff':
                style, options, diff_data = get_diff_options(req)
                contextall = diff_data['options']['contextall']
                req.redirect(req.href.wiki(versioned_page.name, action='diff',
                                           old_version=old_version,
                                           version=version,
                                           contextall=contextall or None))
        elif action == 'delete':
            return self._render_confirm_delete(req, page)
        elif action == 'rename':
            return self._render_confirm_rename(req, page)
        elif action == 'edit':
            return self._render_editor(req, page)
        elif action == 'diff':
            return self._render_diff(req, versioned_page)
        elif action == 'history':
            return self._render_history(req, versioned_page)
        else:
            format = req.args.get('format')
            if format:
                Mimeview(self.env).send_converted(req, 'text/x-trac-wiki',
                                                  versioned_page.text,
                                                  format, versioned_page.name)
            return self._render_view(req, versioned_page)

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        return [pkg_resources.resource_filename('trac.wiki', 'templates')]

    # Internal methods

    def _validate(self, req, page):
        valid = True

        # Validate page size
        if len(req.args.get('text', '')) > self.max_size:
            add_warning(req, _('The wiki page is too long (must be less '
                               'than %(num)s characters)',
                               num=self.max_size))
            valid = False

        # Give the manipulators a pass at post-processing the page
        for manipulator in self.page_manipulators:
            for field, message in manipulator.validate_wiki_page(req, page):
                valid = False
                if field:
                    add_warning(req, _("The Wiki page field '%(field)s' is "
                                       "invalid: %(message)s",
                                       field=field, message=message))
                else:
                    add_warning(req, _("Invalid Wiki page: %(message)s",
                                       message=message))
        return valid

    def _page_data(self, req, page, action=''):
        title = get_resource_summary(self.env, page.resource)
        if action:
            title += ' (%s)' % action
        return {'page': page, 'action': action, 'title': title}

    def _prepare_diff(self, req, page, old_text, new_text,
                      old_version, new_version):
        diff_style, diff_options, diff_data = get_diff_options(req)
        diff_context = 3
        for option in diff_options:
            if option.startswith('-U'):
                diff_context = int(option[2:])
                break
        if diff_context < 0:
            diff_context = None
        diffs = diff_blocks(old_text, new_text, context=diff_context,
                            ignore_blank_lines='-B' in diff_options,
                            ignore_case='-i' in diff_options,
                            ignore_space_changes='-b' in diff_options)
        def version_info(v, last=0):
            return {'path': get_resource_name(self.env, page.resource),
                    # TRANSLATOR: wiki page
                    'rev': v or _('currently edited'),
                    'shortrev': v or last + 1,
                    'href': req.href.wiki(page.name, version=v) if v else None}
        changes = [{'diffs': diffs, 'props': [],
                    'new': version_info(new_version, old_version),
                    'old': version_info(old_version)}]

        add_stylesheet(req, 'common/css/diff.css')
        add_script(req, 'common/js/diff.js')
        return diff_data, changes

    def _do_delete(self, req, page):
        if page.readonly:
            req.perm(page.resource).require('WIKI_ADMIN')
        else:
            req.perm(page.resource).require('WIKI_DELETE')

        if 'cancel' in req.args:
            req.redirect(get_resource_url(self.env, page.resource, req.href))

        version = int(req.args.get('version', 0)) or None
        old_version = int(req.args.get('old_version', 0)) or version

        with self.env.db_transaction as db:
            if version and old_version and version > old_version:
                # delete from `old_version` exclusive to `version` inclusive:
                for v in range(old_version, version):
                    page.delete(v + 1, db)
            else:
                # only delete that `version`, or the whole page if `None`
                page.delete(version, db)

        if not page.exists:
            add_notice(req, _("The page %(name)s has been deleted.",
                              name=page.name))
            req.redirect(req.href.wiki())
        else:
            if version and old_version and version > old_version + 1:
                add_notice(req, _('The versions %(from_)d to %(to)d of the '
                                  'page %(name)s have been deleted.',
                            from_=old_version + 1, to=version, name=page.name))
            else:
                add_notice(req, _('The version %(version)d of the page '
                                  '%(name)s has been deleted.',
                                  version=version, name=page.name))
            req.redirect(req.href.wiki(page.name))

    def _do_rename(self, req, page):
        if page.readonly:
            req.perm(page.resource).require('WIKI_ADMIN')
        else:
            req.perm(page.resource).require('WIKI_RENAME')

        if 'cancel' in req.args:
            req.redirect(get_resource_url(self.env, page.resource, req.href))

        old_name, old_version = page.name, page.version
        new_name = req.args.get('new_name', '')
        new_name = re.sub(r'/{2,}', '/', new_name.strip('/'))
        redirect = req.args.get('redirect')

        # verify input parameters
        warn = None
        if not new_name:
            warn = _("A new name is mandatory for a rename.")
        elif not validate_page_name(new_name):
            warn = _("The new name is invalid (a name which is separated "
                     "with slashes cannot be '.' or '..').")
        elif new_name == old_name:
            warn = _("The new name must be different from the old name.")
        elif WikiPage(self.env, new_name).exists:
            warn = _("The page %(name)s already exists.", name=new_name)
        if warn:
            add_warning(req, warn)
            return self._render_confirm_rename(req, page, new_name)

        with self.env.db_transaction as db:
            page.rename(new_name)
            if redirect:
                redirection = WikiPage(self.env, old_name, db=db)
                redirection.text = _('See [wiki:"%(name)s"].', name=new_name)
                author = get_reporter_id(req)
                comment = u'[wiki:"%s@%d" %s] \u2192 [wiki:"%s"].' % (
                          new_name, old_version, old_name, new_name)
                redirection.save(author, comment, req.remote_addr)

        req.redirect(req.href.wiki(old_name if redirect else new_name))

    def _do_save(self, req, page):
        if page.readonly:
            req.perm(page.resource).require('WIKI_ADMIN')
        elif not page.exists:
            req.perm(page.resource).require('WIKI_CREATE')
        else:
            req.perm(page.resource).require('WIKI_MODIFY')

        if 'WIKI_ADMIN' in req.perm(page.resource):
            # Modify the read-only flag if it has been changed and the user is
            # WIKI_ADMIN
            page.readonly = int('readonly' in req.args)

        try:
            page.save(get_reporter_id(req, 'author'), req.args.get('comment'),
                      req.remote_addr)
            add_notice(req, _("Your changes have been saved in version "
                              "%(version)s.", version=page.version))
            req.redirect(get_resource_url(self.env, page.resource, req.href,
                                          version=None))
        except TracError:
            add_warning(req, _("Page not modified, showing latest version."))
            return self._render_view(req, page)

    def _render_confirm_delete(self, req, page):
        if page.readonly:
            req.perm(page.resource).require('WIKI_ADMIN')
        else:
            req.perm(page.resource).require('WIKI_DELETE')

        version = None
        if 'delete_version' in req.args:
            version = int(req.args.get('version', 0))
        old_version = int(req.args.get('old_version') or 0) or version

        what = 'multiple' if version and old_version \
                             and version - old_version > 1 \
               else 'single' if version else 'page'

        num_versions = 0
        new_date = None
        old_date = None
        for v, t, author, comment, ipnr in page.get_history():
            if (v <= version or what == 'page') and new_date is None:
                new_date = t
            if (v <= old_version and what == 'multiple' or
                num_versions > 1 and what == 'single'):
                break
            num_versions += 1
            old_date = t

        data = self._page_data(req, page, 'delete')
        data.update({'what': what, 'new_version': None, 'old_version': None,
                     'num_versions': num_versions, 'new_date': new_date,
                     'old_date': old_date})
        if version is not None:
            data.update({'new_version': version, 'old_version': old_version})
        self._wiki_ctxtnav(req, page)
        return 'wiki_delete.html', data, None

    def _render_confirm_rename(self, req, page, new_name=None):
        if page.readonly:
            req.perm(page.resource).require('WIKI_ADMIN')
        else:
            req.perm(page.resource).require('WIKI_RENAME')

        data = self._page_data(req, page, 'rename')
        data['new_name'] = new_name if new_name is not None else page.name
        self._wiki_ctxtnav(req, page)
        return 'wiki_rename.html', data, None

    def _render_diff(self, req, page):
        if not page.exists:
            raise TracError(_('Version %(num)s of page "%(name)s" does not '
                              'exist',
                              num=req.args.get('version'), name=page.name))

        old_version = req.args.get('old_version')
        if old_version:
            old_version = int(old_version)
            if old_version == page.version:
                old_version = None
            elif old_version > page.version:
                # FIXME: what about reverse diffs?
                old_version = page.resource.version
                page = WikiPage(self.env, page.name, version=old_version)
                req.perm(page.resource).require('WIKI_VIEW')
        latest_page = WikiPage(self.env, page.name, version=None)
        req.perm(latest_page.resource).require('WIKI_VIEW')
        new_version = int(page.version)

        date = author = comment = ipnr = None
        num_changes = 0
        prev_version = next_version = None
        for version, t, a, c, i in latest_page.get_history():
            if version == new_version:
                date = t
                author = a or 'anonymous'
                comment = c or '--'
                ipnr = i or ''
            else:
                if version < new_version:
                    num_changes += 1
                    if not prev_version:
                        prev_version = version
                    if old_version is None or version == old_version:
                        old_version = version
                        break
                else:
                    next_version = version
        if not old_version:
            old_version = 0
        old_page = WikiPage(self.env, page.name, old_version)
        req.perm(old_page.resource).require('WIKI_VIEW')

        # -- text diffs
        old_text = old_page.text.splitlines()
        new_text = page.text.splitlines()
        diff_data, changes = self._prepare_diff(req, page, old_text, new_text,
                                                old_version, new_version)

        # -- prev/up/next links
        if prev_version:
            add_link(req, 'prev', req.href.wiki(page.name, action='diff',
                                                version=prev_version),
                     _('Version %(num)s', num=prev_version))
        add_link(req, 'up', req.href.wiki(page.name, action='history'),
                 _('Page history'))
        if next_version:
            add_link(req, 'next', req.href.wiki(page.name, action='diff',
                                                version=next_version),
                     _('Version %(num)s', num=next_version))

        data = self._page_data(req, page, 'diff')
        data.update({
            'change': {'date': date, 'author': author, 'ipnr': ipnr,
                       'comment': comment},
            'new_version': new_version, 'old_version': old_version,
            'latest_version': latest_page.version,
            'num_changes': num_changes,
            'longcol': 'Version', 'shortcol': 'v',
            'changes': changes,
            'diff': diff_data,
        })
        prevnext_nav(req, _('Previous Change'), _('Next Change'),
                     _('Wiki History'))
        return 'wiki_diff.html', data, None

    def _render_editor(self, req, page, action='edit', has_collision=False):
        if has_collision:
            if action == 'merge':
                page = WikiPage(self.env, page.name, version=None)
                req.perm(page.resource).require('WIKI_VIEW')
            else:
                action = 'collision'

        if page.readonly:
            req.perm(page.resource).require('WIKI_ADMIN')
        else:
            req.perm(page.resource).require('WIKI_MODIFY')
        original_text = page.text
        comment = req.args.get('comment', '')
        if 'text' in req.args:
            page.text = req.args.get('text')
        elif 'template' in req.args:
            template = self.PAGE_TEMPLATES_PREFIX + req.args.get('template')
            template_page = WikiPage(self.env, template)
            if template_page and template_page.exists and \
                   'WIKI_VIEW' in req.perm(template_page.resource):
                page.text = template_page.text
        elif 'version' in req.args:
            old_page = WikiPage(self.env, page.name,
                                version=int(req.args['version']))
            req.perm(page.resource).require('WIKI_VIEW')
            page.text = old_page.text
            comment = _("Reverted to version %(version)s.",
                        version=req.args['version'])
        if action in ('preview', 'diff'):
            page.readonly = 'readonly' in req.args

        author = get_reporter_id(req, 'author')
        defaults = {'editrows': 20}
        prefs = dict((key, req.session.get('wiki_%s' % key, defaults.get(key)))
                     for key in ('editrows', 'sidebyside'))

        if 'from_editor' in req.args:
            sidebyside = req.args.get('sidebyside') or None
            if sidebyside != prefs['sidebyside']:
                req.session.set('wiki_sidebyside', int(bool(sidebyside)), 0)
        else:
            sidebyside = prefs['sidebyside']

        if sidebyside:
            editrows = max(int(prefs['editrows']),
                           len(page.text.splitlines()) + 1)
        else:
            editrows = req.args.get('editrows')
            if editrows:
                if editrows != prefs['editrows']:
                    req.session.set('wiki_editrows', editrows,
                                    defaults['editrows'])
            else:
                editrows = prefs['editrows']

        data = self._page_data(req, page, action)
        context = web_context(req, page.resource)
        data.update({
            'author': author,
            'comment': comment,
            'edit_rows': editrows, 'sidebyside': sidebyside,
            'scroll_bar_pos': req.args.get('scroll_bar_pos', ''),
            'diff': None,
            'attachments': AttachmentModule(self.env).attachment_data(context),
        })
        if action in ('diff', 'merge'):
            old_text = original_text.splitlines() if original_text else []
            new_text = page.text.splitlines() if page.text else []
            diff_data, changes = self._prepare_diff(
                req, page, old_text, new_text, page.version, '')
            data.update({'diff': diff_data, 'changes': changes,
                         'action': 'preview', 'merge': action == 'merge',
                         'longcol': 'Version', 'shortcol': 'v'})
        elif sidebyside and action != 'collision':
            data['action'] = 'preview'

        self._wiki_ctxtnav(req, page)
        Chrome(self.env).add_wiki_toolbars(req)
        Chrome(self.env).add_auto_preview(req)
        add_script(req, 'common/js/folding.js')
        return 'wiki_edit.html', data, None

    def _render_history(self, req, page):
        """Extract the complete history for a given page.

        This information is used to present a changelog/history for a given
        page.
        """
        if not page.exists:
            raise TracError(_("Page %(name)s does not exist", name=page.name))

        data = self._page_data(req, page, 'history')

        history = []
        for version, date, author, comment, ipnr in page.get_history():
            history.append({
                'version': version,
                'date': date,
                'author': author,
                'comment': comment,
                'ipnr': ipnr
            })
        data.update({'history': history, 'resource': page.resource})
        add_ctxtnav(req, _("Back to %(wikipage)s", wikipage=page.name),
                           req.href.wiki(page.name))
        return 'history_view.html', data, None

    def _render_view(self, req, page):
        version = page.resource.version

        # Add registered converters
        if page.exists:
            for conversion in Mimeview(self.env).get_supported_conversions(
                                                 'text/x-trac-wiki'):
                conversion_href = req.href.wiki(page.name, version=version,
                                                format=conversion[0])
                # or...
                conversion_href = get_resource_url(self.env, page.resource,
                                                req.href, format=conversion[0])
                add_link(req, 'alternate', conversion_href, conversion[1],
                         conversion[3])

        data = self._page_data(req, page)
        if page.name == 'WikiStart':
            data['title'] = ''

        ws = WikiSystem(self.env)
        context = web_context(req, page.resource)
        higher, related = [], []
        if not page.exists:
            if 'WIKI_CREATE' not in req.perm(page.resource):
                raise ResourceNotFound(_('Page %(name)s not found',
                                         name=page.name))
            formatter = OneLinerFormatter(self.env, context)
            if '/' in page.name:
                parts = page.name.split('/')
                for i in range(len(parts) - 2, -1, -1):
                    name = '/'.join(parts[:i] + [parts[-1]])
                    if not ws.has_page(name):
                        higher.append(ws._format_link(formatter, 'wiki',
                                                    '/' + name, name, False))
            else:
                name = page.name
            name = name.lower()
            related = [each for each in ws.pages
                       if name in each.lower()
                          and 'WIKI_VIEW' in req.perm('wiki', each)]
            related.sort()
            related = [ws._format_link(formatter, 'wiki', '/' + each, each,
                                       False)
                       for each in related]

        latest_page = WikiPage(self.env, page.name, version=None)
        req.perm(latest_page.resource).require('WIKI_VIEW')

        prev_version = next_version = None
        if version:
            try:
                version = int(version)
                for hist in latest_page.get_history():
                    v = hist[0]
                    if v != version:
                        if v < version:
                            if not prev_version:
                                prev_version = v
                                break
                        else:
                            next_version = v
            except ValueError:
                version = None

        prefix = self.PAGE_TEMPLATES_PREFIX
        templates = [template[len(prefix):]
                     for template in ws.get_pages(prefix)
                     if 'WIKI_VIEW' in req.perm('wiki', template)]

        # -- prev/up/next links
        if prev_version:
            add_link(req, 'prev',
                     req.href.wiki(page.name, version=prev_version),
                     _('Version %(num)s', num=prev_version))

        parent = None
        if version:
            add_link(req, 'up', req.href.wiki(page.name, version=None),
                     _('View latest version'))
        elif '/' in page.name:
            parent = page.name[:page.name.rindex('/')]
            add_link(req, 'up', req.href.wiki(parent, version=None),
                     _("View parent page"))

        if next_version:
            add_link(req, 'next',
                     req.href.wiki(page.name, version=next_version),
                     _('Version %(num)s', num=next_version))

        # Add ctxtnav entries
        if version:
            prevnext_nav(req, _('Previous Version'), _('Next Version'),
                         _('View Latest Version'))
        else:
            if parent:
                add_ctxtnav(req, _('Up'), req.href.wiki(parent))
            self._wiki_ctxtnav(req, page)

        # Plugin content validation
        fields = {'text': page.text}
        for manipulator in self.page_manipulators:
            manipulator.prepare_wiki_page(req, page, fields)
        text = fields.get('text', '')

        data.update({
            'context': context,
            'text': text,
            'latest_version': latest_page.version,
            'attachments': AttachmentModule(self.env).attachment_data(context),
            'default_template': self.DEFAULT_PAGE_TEMPLATE,
            'templates': templates,
            'version': version,
            'higher': higher, 'related': related,
            'resourcepath_template': 'wiki_page_path.html',
        })
        add_script(req, 'common/js/folding.js')
        return 'wiki_view.html', data, None

    def _wiki_ctxtnav(self, req, page):
        """Add the normal wiki ctxtnav entries."""
        add_ctxtnav(req, _('Start Page'), req.href.wiki('WikiStart'))
        add_ctxtnav(req, _('Index'), req.href.wiki('TitleIndex'))
        if page.exists:
            add_ctxtnav(req, _('History'), req.href.wiki(page.name,
                                                         action='history'))

    # ITimelineEventProvider methods

    def get_timeline_filters(self, req):
        if 'WIKI_VIEW' in req.perm:
            yield ('wiki', _('Wiki changes'))

    def get_timeline_events(self, req, start, stop, filters):
        if 'wiki' in filters:
            wiki_realm = Resource('wiki')
            for ts, name, comment, author, version in self.env.db_query("""
                    SELECT time, name, comment, author, version FROM wiki
                    WHERE time>=%s AND time<=%s
                    """, (to_utimestamp(start), to_utimestamp(stop))):
                wiki_page = wiki_realm(id=name, version=version)
                if 'WIKI_VIEW' not in req.perm(wiki_page):
                    continue
                yield ('wiki', from_utimestamp(ts), author,
                       (wiki_page, comment))

            # Attachments
            for event in AttachmentModule(self.env).get_timeline_events(
                req, wiki_realm, start, stop):
                yield event

    def render_timeline_event(self, context, field, event):
        wiki_page, comment = event[3]
        if field == 'url':
            return context.href.wiki(wiki_page.id, version=wiki_page.version)
        elif field == 'title':
            name = tag.em(get_resource_name(self.env, wiki_page))
            if wiki_page.version > 1:
                return tag_('%(page)s edited', page=name)
            else:
                return tag_('%(page)s created', page=name)
        elif field == 'description':
            markup = format_to(self.env, None,
                               context.child(resource=wiki_page), comment)
            if wiki_page.version > 1:
                diff_href = context.href.wiki(
                    wiki_page.id, version=wiki_page.version, action='diff')
                markup = tag(markup,
                             ' (', tag.a(_('diff'), href=diff_href), ')')
            return markup

    # ISearchSource methods

    def get_search_filters(self, req):
        if 'WIKI_VIEW' in req.perm:
            yield ('wiki', _('Wiki'))

    def get_search_results(self, req, terms, filters):
        if not 'wiki' in filters:
            return
        with self.env.db_query as db:
            sql_query, args = search_to_sql(db, ['w1.name', 'w1.author',
                                                 'w1.text'], terms)
            wiki_realm = Resource('wiki')
            for name, ts, author, text in db("""
                    SELECT w1.name, w1.time, w1.author, w1.text
                    FROM wiki w1,(SELECT name, max(version) AS ver
                                  FROM wiki GROUP BY name) w2
                    WHERE w1.version = w2.ver AND w1.name = w2.name
                    AND """ + sql_query, args):
                page = wiki_realm(id=name)
                if 'WIKI_VIEW' in req.perm(page):
                    yield (get_resource_url(self.env, page, req.href),
                           '%s: %s' % (name, shorten_line(text)),
                           from_utimestamp(ts), author,
                           shorten_result(text, terms))

        # Attachments
        for result in AttachmentModule(self.env).get_search_results(
            req, wiki_realm, terms):
            yield result

########NEW FILE########
__FILENAME__ = enscript
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004 Daniel Lundin <daniel@edgewall.com>
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>

from genshi.core import Markup

from trac.config import Option, ListOption
from trac.core import *
from trac.mimeview.api import IHTMLPreviewRenderer, Mimeview
from trac.util import NaivePopen
from trac.util.html import Deuglifier

__all__ = ['EnscriptRenderer']

types = {
    'application/xhtml+xml':    ('html', 2),
    'application/postscript':   ('postscript', 2),
    'application/x-csh':        ('csh', 2),
    'application/x-javascript': ('javascript', 2),
    'application/x-troff':      ('nroff', 2),
    'text/html':                ('html', 2),
    'text/x-ada':               ('ada', 2),
    'text/x-asm':               ('asm', 2),
    'text/x-awk':               ('awk', 2),
    'text/x-c++src':            ('cpp', 2),
    'text/x-c++hdr':            ('cpp', 2),
    'text/x-chdr':              ('c', 2),
    'text/x-csh':               ('csh', 2),
    'text/x-csrc':              ('c', 2),
    'text/x-diff':              ('diffu', 2), # Assume unified diff (works otherwise)
    'text/x-eiffel':            ('eiffel', 2),
    'text/x-elisp':             ('elisp', 2),
    'text/x-fortran':           ('fortran', 2),
    'text/x-haskell':           ('haskell', 2),
    'text/x-idl':               ('idl', 2),
    'text/x-inf':               ('inf', 2),
    'text/x-java':              ('java', 2),
    'text/x-javascript':        ('javascript', 2),
    'text/x-ksh':               ('ksh', 2),
    'text/x-lua':               ('lua', 2),
    'text/x-m4':                ('m4', 2),
    'text/x-makefile':          ('makefile', 2),
    'text/x-mail':              ('mail', 2),
    'text/x-matlab':            ('matlab', 2),
    'text/x-objc':              ('objc', 2),
    'text/x-pascal':            ('pascal', 2),
    'text/x-perl':              ('perl', 2),
    'text/x-pyrex':             ('pyrex', 2),
    'text/x-python':            ('python', 2),
    'text/x-rfc':               ('rfc', 2),
    'text/x-ruby':              ('ruby', 2),
    'text/x-sh':                ('sh', 2),
    'text/x-scheme':            ('scheme', 2),
    'text/x-sql':               ('sql', 2),
    'text/x-tcl':               ('tcl', 2),
    'text/x-tex':               ('tex', 2),
    'text/x-vba':               ('vba', 2),
    'text/x-verilog':           ('verilog', 2),
    'text/x-vhdl':              ('vhdl', 2),
    'model/vrml':               ('vrml', 2),
    'application/x-sh':         ('sh', 2),
    'text/x-zsh':               ('zsh', 2),
    'text/vnd.wap.wmlscript':   ('wmlscript', 2),
}


class EnscriptDeuglifier(Deuglifier):
    @classmethod
    def rules(cls):
        return [
            r'(?P<comment><FONT COLOR="#B22222">)',
            r'(?P<keyword><FONT COLOR="#5F9EA0">)',
            r'(?P<type><FONT COLOR="#228B22">)',
            r'(?P<string><FONT COLOR="#BC8F8F">)',
            r'(?P<func><FONT COLOR="#0000FF">)',
            r'(?P<prep><FONT COLOR="#B8860B">)',
            r'(?P<lang><FONT COLOR="#A020F0">)',
            r'(?P<var><FONT COLOR="#DA70D6">)',
            r'(?P<font><FONT.*?>)',
            r'(?P<endfont></FONT>)'
        ]


class EnscriptRenderer(Component):
    """Syntax highlighter using GNU Enscript."""

    implements(IHTMLPreviewRenderer)

    expand_tabs = True
    returns_source = True

    path = Option('mimeviewer', 'enscript_path', 'enscript',
        """Path to the Enscript executable.""")

    enscript_modes = ListOption('mimeviewer', 'enscript_modes',
        'text/x-dylan:dylan:4', doc=
        """List of additional MIME types known by Enscript.
        For each, a tuple `mimetype:mode:quality` has to be
        specified, where `mimetype` is the MIME type,
        `mode` is the corresponding Enscript mode to be used
        for the conversion and `quality` is the quality ratio
        associated to this conversion.
        That can also be used to override the default
        quality ratio used by the Enscript render, which is 2
        (''since 0.10'').""")

    def __init__(self):
        self._types = None

    # IHTMLPreviewRenderer methods

    def get_quality_ratio(self, mimetype):
        # Extend default MIME type to mode mappings with configured ones
        if not self._types:
            self._types = {}
            self._types.update(types)
            self._types.update(
                Mimeview(self.env).configured_modes_mapping('enscript'))
        return self._types.get(mimetype, (None, 0))[1]

    def render(self, context, mimetype, content, filename=None, rev=None):
        cmdline = self.path
        mimetype = mimetype.split(';', 1)[0] # strip off charset
        mode = self._types[mimetype][0]
        cmdline += ' --color -h -q --language=html -p - -E%s' % mode
        self.log.debug("Enscript command line: %s" % cmdline)

        np = NaivePopen(cmdline, content.encode('utf-8'), capturestderr=1)
        if np.errorlevel or np.err:
            self.env.disable_component(self)
            err = "Running enscript failed with (%s, %s), disabling " \
                  "EnscriptRenderer (command: '%s')" \
                  % (np.errorlevel, np.err.strip(), cmdline)
            raise Exception(err)
        odata = np.out

        # Strip header and footer
        i = odata.find('<PRE>')
        beg = i > 0 and i + 6
        i = odata.rfind('</PRE>')
        end = i if i > 0 else len(odata)

        odata = EnscriptDeuglifier().format(odata[beg:end].decode('utf-8'))
        return [Markup(line) for line in odata.splitlines()]

########NEW FILE########
__FILENAME__ = php
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005 Christian Boos <cboos@bct-technology.com>
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christian Boos <cboos@bct-technology.com>
#         Christopher Lenz <cmlenz@gmx.de>

import os
import re

from genshi.core import Markup

from trac.core import *
from trac.config import Option
from trac.mimeview.api import IHTMLPreviewRenderer, content_to_unicode
from trac.util import NaivePopen
from trac.util.html import Deuglifier
from trac.util.translation import _

__all__ = ['PHPRenderer']

php_types = ('text/x-php', 'application/x-httpd-php',
             'application/x-httpd-php4', 'application/x-httpd-php1')


class PhpDeuglifier(Deuglifier):

    def format(self, indata):
        # The PHP highlighter produces the end-span tags on the next line
        # instead of the line they actually apply to, which causes
        # Trac to produce lots of (useless) open-and-immediately-close
        # spans beginning each line.  This tries to curtail by bubbling
        # the first span after a set of 1+ "<br />" to before them.
        r_fixeol = re.compile(r"((?:<br />)+)(</(?:font|span)>)")
        indata = r_fixeol.sub(lambda m: m.group(2) + m.group(1), indata)

        # Now call superclass implementation that handles the dirty work
        # of applying css classes.
        return Deuglifier.format(self, indata)

    @classmethod
    def rules(cls):
        colors = dict(comment='FF8000', lang='0000BB', keyword='007700',
                      string='DD0000')
        # rules check for <font> for PHP 4 or <span> for PHP 5
        return [r'(?P<%s><(?:font color="|span style="color: )#%s">)' % c
                for c in colors.items()
                ] + [r'(?P<font><font.*?>)', r'(?P<endfont></font>)']


class PHPRenderer(Component):
    """Syntax highlighter using the PHP executable."""

    implements(IHTMLPreviewRenderer)

    path = Option('mimeviewer', 'php_path', 'php',
        """Path to the PHP executable (''since 0.9'').""")

    returns_source = True

    # IHTMLPreviewRenderer methods

    def get_quality_ratio(self, mimetype):
        if mimetype in php_types:
            return 5
        return 0

    def render(self, context, mimetype, content, filename=None, rev=None):
        # -n to ignore php.ini so we're using default colors
        cmdline = '%s -sn' % self.path
        self.log.debug("PHP command line: %s" % cmdline)

        content = content_to_unicode(self.env, content, mimetype)
        content = content.encode('utf-8')
        np = NaivePopen(cmdline, content, capturestderr=1)
        if (os.name != 'nt' and np.errorlevel) or np.err:
            msg = 'Running (%s) failed: %s, %s.' % (cmdline,
                                                    np.errorlevel,
                                                    np.err)
            raise Exception(msg)

        odata = ''.join(np.out.splitlines()[1:-1])
        if odata.startswith('X-Powered-By:') or \
                odata.startswith('Content-type:'):
            raise TracError(_('You appear to be using the PHP CGI '
                              'binary. Trac requires the CLI version '
                              'for syntax highlighting.'))

        epilogues = ["</span>", "</font>"]
        for e in epilogues:
            if odata.endswith(e):
                odata = odata[:-len(e)]
                break

        html = PhpDeuglifier().format(odata.decode('utf-8'))

        # PHP generates _way_ too many non-breaking spaces...
        # We don't need them anyway, so replace them by normal spaces
        return [Markup(line.replace('&nbsp;', ' '))
                for line in html.split('<br />')]

########NEW FILE########
__FILENAME__ = silvercity
# -*- coding: utf-8 -*-
#
# Copyright (C) 2004-2009 Edgewall Software
# Copyright (C) 2004 Daniel Lundin <daniel@edgewall.com>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Daniel Lundin <daniel@edgewall.com>

"""Syntax highlighting module, based on the SilverCity module.

Get it at: http://silvercity.sourceforge.net/
"""

import re
from StringIO import StringIO

from genshi.core import Markup

from trac.core import *
from trac.config import ListOption
from trac.env import ISystemInfoProvider
from trac.mimeview.api import IHTMLPreviewRenderer, Mimeview
from trac.util import get_pkginfo

try:
    import SilverCity
    have_silvercity = True
except ImportError:
    have_silvercity = False


__all__ = ['SilverCityRenderer']

types = {
    'text/css':                 ('CSS', 3),
    'text/html':                ('HyperText', 3, {'asp.default.language':1}),
    'application/xml':          ('XML', 3),
    'application/xhtml+xml':    ('HyperText', 3, {'asp.default.language':1}),
    'application/rss+xml':      ('HyperText', 3, {'asp.default.language':1}),
    'application/x-yaml':       ('YAML', 3),
    'text/x-yaml':              ('YAML', 3),
    'application/x-javascript': ('CPP', 3), # Kludgy.
    'text/x-asp':               ('HyperText', 3, {'asp.default.language':2}),
    'text/x-c++hdr':            ('CPP', 3),
    'text/x-c++src':            ('CPP', 3),
    'text/x-chdr':              ('CPP', 3),
    'text/x-csrc':              ('CPP', 3),
    'text/x-perl':              ('Perl', 3),
    'text/x-php':               ('HyperText', 3, {'asp.default.language': 4}),
    'application/x-httpd-php':  ('HyperText', 3, {'asp.default.language': 4}),
    'application/x-httpd-php4': ('HyperText', 3, {'asp.default.language': 4}),
    'application/x-httpd-php3': ('HyperText', 3, {'asp.default.language': 4}),
    'text/x-java':              ('Java', 3),
    'text/x-javascript':        ('CPP', 3), # Kludgy.
    'text/x-psp':               ('HyperText', 3, {'asp.default.language': 3}),
    'text/x-python':            ('Python', 3),
    'text/x-ruby':              ('Ruby', 3),
    'text/x-sql':               ('SQL', 3),
    'text/x-verilog':           ('Verilog', 3),
    'text/xml':                 ('XML', 3),
    'text/xslt':                ('XSLT', 3),
    'image/svg+xml':            ('XML', 3)
}

CRLF_RE = re.compile('\r$', re.MULTILINE)


class SilverCityRenderer(Component):
    """Syntax highlighting based on SilverCity."""

    implements(ISystemInfoProvider, IHTMLPreviewRenderer)

    silvercity_modes = ListOption('mimeviewer', 'silvercity_modes',
        '', doc=
        """List of additional MIME types known by SilverCity.
        For each, a tuple `mimetype:mode:quality` has to be
        specified, where `mimetype` is the MIME type,
        `mode` is the corresponding SilverCity mode to be used
        for the conversion and `quality` is the quality ratio
        associated to this conversion.
        That can also be used to override the default
        quality ratio used by the SilverCity render, which is 3
        (''since 0.10'').""")

    expand_tabs = True
    returns_source = True

    def __init__(self):
        self._types = None

    # ISystemInfoProvider methods

    def get_system_info(self):
        if have_silvercity:
            yield 'SilverCity', get_pkginfo(SilverCity).get('version', '?')
            # TODO: the above works only if setuptools was used to build
            # SilverCity, which is not yet the case by default for 0.9.7.
            # I've not been able to find an alternative way to get version.

    # IHTMLPreviewRenderer methods

    def get_quality_ratio(self, mimetype):
        # Extend default MIME type to mode mappings with configured ones
        if not have_silvercity:
            return 0
        if not self._types:
            self._types = {}
            self._types.update(types)
            self._types.update(
                Mimeview(self.env).configured_modes_mapping('silvercity'))
        return self._types.get(mimetype, (None, 0))[1]

    def render(self, context, mimetype, content, filename=None, rev=None):
        try:
            mimetype = mimetype.split(';', 1)[0]
            typelang = self._types[mimetype]
            lang = typelang[0]
            module = getattr(SilverCity, lang)
            generator = getattr(module, lang + "HTMLGenerator")
            try:
                allprops = typelang[2]
                propset = SilverCity.PropertySet()
                for p in allprops.keys():
                    propset[p] = allprops[p]
            except IndexError:
                pass
        except (KeyError, AttributeError):
            err = "No SilverCity lexer found for mime-type '%s'." % mimetype
            raise Exception, err

        # SilverCity does not like unicode strings
        content = content.encode('utf-8')

        # SilverCity generates extra empty line against some types of
        # the line such as comment or #include with CRLF. So we
        # standardize to LF end-of-line style before call.
        content = CRLF_RE.sub('', content)

        buf = StringIO()
        generator().generate_html(buf, content)

        br_re = re.compile(r'<br\s*/?>$', re.MULTILINE)
        span_default_re = re.compile(r'<span class="\w+_default">(.*?)</span>',
                                     re.DOTALL)
        html = span_default_re.sub(r'\1', br_re.sub('', buf.getvalue()))

        # Convert the output back to a unicode string
        html = html.decode('utf-8')

        # SilverCity generates _way_ too many non-breaking spaces...
        # We don't need them anyway, so replace them by normal spaces
        return [Markup(line)
                for line in html.replace('&nbsp;', ' ').splitlines()]

########NEW FILE########
__FILENAME__ = php
# -*- coding: utf-8 -*-
#
# Copyright (C)2006-2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from StringIO import StringIO
import unittest

from trac.mimeview.api import Mimeview
from trac.test import EnvironmentStub, locate
from tracopt.mimeview.php import PhpDeuglifier, PHPRenderer


class PhpDeuglifierTestCase(unittest.TestCase):

    def test_nomarkup(self):
        self.assertEqual('asd', PhpDeuglifier().format('asd'))

    def test_rewrite_span(self):
        self.assertEqual('<span class="code-comment">asd</span>',
            PhpDeuglifier().format('<span style="color: #FF8000">asd</span>'))
        self.assertEqual('<span class="code-lang">asd</span>',
            PhpDeuglifier().format('<span style="color: #0000BB">asd</span>'))
        self.assertEqual('<span class="code-keyword">asd</span>',
            PhpDeuglifier().format('<span style="color: #007700">asd</span>'))
        self.assertEqual('<span class="code-string">asd</span>',
            PhpDeuglifier().format('<span style="color: #DD0000">asd</span>'))

    def test_rewrite_font(self):
        self.assertEqual('<span class="code-comment">asd</span>',
            PhpDeuglifier().format('<font color="#FF8000">asd</font>'))
        self.assertEqual('<span class="code-lang">asd</span>',
            PhpDeuglifier().format('<font color="#0000BB">asd</font>'))
        self.assertEqual('<span class="code-keyword">asd</span>',
            PhpDeuglifier().format('<font color="#007700">asd</font>'))
        self.assertEqual('<span class="code-string">asd</span>',
            PhpDeuglifier().format('<font color="#DD0000">asd</font>'))

    def test_reorder_br(self):
        """
        Regression test for #3326 point 2 (close tags after line break)
        """
        self.assertEqual('<span class="code-lang"></span><br />',
            PhpDeuglifier().format(
                '<span style="color: #0000BB"><br /></span>'))
        self.assertEqual('<span class="code-lang"></span><br /><br />',
            PhpDeuglifier().format(
                '<span style="color: #0000BB"><br /><br /></span>'))


class PhpRendererTestCase(unittest.TestCase):

    def _test_render(self, stuff, type="string"):
        env = EnvironmentStub(enable=[PHPRenderer])
        m = Mimeview(env)
        r = m.renderers[0]
        if type == "string":
            s = stuff
        elif type == "file":
            s = StringIO(stuff)
        else:
            raise NotImplementedException(
                "Pass either type=file or type=string")
        result = list(r.render(None, None, s))
        return result

    def test_boring_string(self):
        """
        Simple regression test for #3624 (php chops off the last line)
        """
        result = self._test_render('asd')
        self.assertEqual('asd', result[0])
        self.assertEqual(1, len(result))

    def test_boring_filelike(self):
        """
        Regression test for #3261 (treats content as string) # FIXME see #3332
        """
        result = self._test_render('asd', 'file')
        self.assertEqual('asd', result[0])
        self.assertEqual(1, len(result))

    def test_simple_string(self):
        result = self._test_render('<?php\n?>')
        self.assertEqual('<span class="code-lang">&lt;?php', result[0])
        self.assertEqual('?&gt;</span>', result[1])
        self.assertEqual(2, len(result))

    def test_simple_unicode(self):
        result = self._test_render(u'<?php echo "\u00e9"; ?>')
        self.assertEqual(u'<span class="code-lang">&lt;?php </span>'
                         u'<span class="code-keyword">echo </span>'
                         u'<span class="code-string">""</span>'
                         u'<span class="code-keyword">; </span>'
                         u'<span class="code-lang">?&gt;</span>', result[0])
        self.assertEqual(1, len(result))

    def test_way_too_many_nbsp(self):
        """
        Regression test for a tiny part of #1676
        """
        result = self._test_render('<?php\n    ?>')
        self.assertEqual('<span class="code-lang">&lt;?php', result[0])
        self.assertEqual('    ?&gt;</span>', result[1])
        self.assertEqual(2, len(result))

    def test_deuglified_reorder_br(self):
        """
        If the reordering of <br /> and the subsequent orphan </span>
        isn't working, the </span> appears at the beginning of the third
        line instead of the end of the second.
        """
        result = self._test_render('<?php\n$x="asd";\n?>')
        self.assertEqual('<span class="code-lang">&lt;?php', result[0])
        self.assertEqual('$x</span><span class="code-keyword">=</span>'
            '<span class="code-string">"asd"</span>'
            '<span class="code-keyword">;</span>', result[1])
        self.assertEqual('<span class="code-lang">?&gt;</span>', result[2])
        self.assertEqual(3, len(result))

    def test_keeps_last_line(self):
        """
        More complex regression test for #3624 (php chops off the last line)
        """
        result = self._test_render('<p />\n<p />')
        self.assertEqual('&lt;p /&gt;', result[0])
        self.assertEqual('&lt;p /&gt;', result[1])
        self.assertEqual(2, len(result))


def suite():
    suite = unittest.TestSuite()
    php = locate("php")
    if php:
        suite.addTest(unittest.makeSuite(PhpDeuglifierTestCase, 'test'))
        suite.addTest(unittest.makeSuite(PhpRendererTestCase, 'test'))
    else:
        print("SKIP: tracopt/mimeview/tests/php.py (php cli binary, 'php', "
              "not found)")
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = authz_policy
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2009 Edgewall Software
# Copyright (C) 2007 Alec Thomas <alec@swapoff.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Alec Thomas <alec@swapoff.org>

from fnmatch import fnmatch
from itertools import groupby
import os

from trac.core import *
from trac.config import Option
from trac.perm import PermissionSystem, IPermissionPolicy

ConfigObj = None
try:
    from configobj import ConfigObj
except ImportError:
    pass


class AuthzPolicy(Component):
    """Permission policy using an authz-like configuration file.

    Refer to SVN documentation for syntax of the authz file. Groups are
    supported.

    As the fine-grained permissions brought by this permission policy are
    often used in complement of the other pemission policies (like the
    `DefaultPermissionPolicy`), there's no need to redefine all the
    permissions here. Only additional rights or restrictions should be added.

    === Installation ===
    Note that this plugin requires the `configobj` package:

        http://www.voidspace.org.uk/python/configobj.html

    You should be able to install it by doing a simple `easy_install configobj`

    Enabling this policy requires listing it in `trac.ini:
    {{{
    [trac]
    permission_policies = AuthzPolicy, DefaultPermissionPolicy

    [authz_policy]
    authz_file = conf/authzpolicy.conf
    }}}

    This means that the `AuthzPolicy` permissions will be checked first, and
    only if no rule is found will the `DefaultPermissionPolicy` be used.


    === Configuration ===
    The `authzpolicy.conf` file is a `.ini` style configuration file.

     - Each section of the config is a glob pattern used to match against a
       Trac resource descriptor. These descriptors are in the form:
       {{{
       <realm>:<id>@<version>[/<realm>:<id>@<version> ...]
       }}}
       Resources are ordered left to right, from parent to child. If any
       component is inapplicable, `*` is substituted. If the version pattern is
       not specified explicitely, all versions (`@*`) is added implicitly

       Example: Match the WikiStart page
       {{{
       [wiki:*]
       [wiki:WikiStart*]
       [wiki:WikiStart@*]
       [wiki:WikiStart]
       }}}

       Example: Match the attachment `wiki:WikiStart@117/attachment/FOO.JPG@*`
       on WikiStart
       {{{
       [wiki:*]
       [wiki:WikiStart*]
       [wiki:WikiStart@*]
       [wiki:WikiStart@*/attachment/*]
       [wiki:WikiStart@117/attachment/FOO.JPG]
       }}}

     - Sections are checked against the current Trac resource '''IN ORDER''' of
       appearance in the configuration file. '''ORDER IS CRITICAL'''.

     - Once a section matches, the current username is matched, '''IN ORDER''',
       against the keys of the section. If a key is prefixed with a `@`, it is
       treated as a group. If a key is prefixed with a `!`, the permission is
       denied rather than granted. The username will match any of 'anonymous',
       'authenticated', <username> or '*', using normal Trac permission rules.

    Example configuration:
    {{{
    [groups]
    administrators = athomas

    [*/attachment:*]
    * = WIKI_VIEW, TICKET_VIEW

    [wiki:WikiStart@*]
    @administrators = WIKI_ADMIN
    anonymous = WIKI_VIEW
    * = WIKI_VIEW

    # Deny access to page templates
    [wiki:PageTemplates/*]
    * =

    # Match everything else
    [*]
    @administrators = TRAC_ADMIN
    anonymous = BROWSER_VIEW, CHANGESET_VIEW, FILE_VIEW, LOG_VIEW,
        MILESTONE_VIEW, POLL_VIEW, REPORT_SQL_VIEW, REPORT_VIEW, ROADMAP_VIEW,
        SEARCH_VIEW, TICKET_CREATE, TICKET_MODIFY, TICKET_VIEW, TIMELINE_VIEW,
        WIKI_CREATE, WIKI_MODIFY, WIKI_VIEW
    # Give authenticated users some extra permissions
    authenticated = REPO_SEARCH, XML_RPC
    }}}
    """
    implements(IPermissionPolicy)

    authz_file = Option('authz_policy', 'authz_file', '',
                        'Location of authz policy configuration file.')

    authz = None
    authz_mtime = None

    # IPermissionPolicy methods

    def check_permission(self, action, username, resource, perm):
        if ConfigObj is None:
            self.log.error('configobj package not found')
            return None

        if self.authz_file and not self.authz_mtime or \
                os.path.getmtime(self.get_authz_file()) > self.authz_mtime:
            self.parse_authz()
        resource_key = self.normalise_resource(resource)
        self.log.debug('Checking %s on %s', action, resource_key)
        permissions = self.authz_permissions(resource_key, username)
        if permissions is None:
            return None                 # no match, can't decide
        elif permissions == ['']:
            return False                # all actions are denied

        # FIXME: expand all permissions once for all
        ps = PermissionSystem(self.env)
        for deny, perms in groupby(permissions,
                                   key=lambda p: p.startswith('!')):
            if deny and action in ps.expand_actions([p[1:] for p in perms]):
                return False            # action is explicitly denied
            elif action in ps.expand_actions(perms):
                return True            # action is explicitly granted

        return None                    # no match for action, can't decide

    # Internal methods

    def get_authz_file(self):
        f = self.authz_file
        return f if os.path.isabs(f) else os.path.join(self.env.path, f)

    def parse_authz(self):
        self.log.debug('Parsing authz security policy %s',
                       self.get_authz_file())
        self.authz = ConfigObj(self.get_authz_file(), encoding='utf8')
        groups = {}
        for group, users in self.authz.get('groups', {}).iteritems():
            if isinstance(users, basestring):
                users = [users]
            groups[group] = users

        self.groups_by_user = {}

        def add_items(group, items):
            for item in items:
                if item.startswith('@'):
                    add_items(group, groups[item[1:]])
                else:
                    self.groups_by_user.setdefault(item, set()).add(group)

        for group, users in groups.iteritems():
            add_items('@' + group, users)

        self.authz_mtime = os.path.getmtime(self.get_authz_file())

    def normalise_resource(self, resource):
        def flatten(resource):
            if not resource:
                return ['*:*@*']
            if not (resource.realm or resource.id):
                return ['%s:%s@%s' % (resource.realm or '*',
                                      resource.id or '*',
                                      resource.version or '*')]
            # XXX Due to the mixed functionality in resource we can end up with
            # ticket, ticket:1, ticket:1@10. This code naively collapses all
            # subsets of the parent resource into one. eg. ticket:1@10
            parent = resource.parent
            while parent and (resource.realm == parent.realm or
                              (resource.realm == parent.realm and
                               resource.id == parent.id)):
                parent = parent.parent
            if parent:
                parent = flatten(parent)
            else:
                parent = []
            return parent + ['%s:%s@%s' % (resource.realm or '*',
                                           resource.id or '*',
                                           resource.version or '*')]
        return '/'.join(flatten(resource))

    def authz_permissions(self, resource_key, username):
        # TODO: Handle permission negation in sections. eg. "if in this
        # ticket, remove TICKET_MODIFY"
        if username and username != 'anonymous':
            valid_users = ['*', 'authenticated', username]
        else:
            valid_users = ['*', 'anonymous']
        for resource_section in [a for a in self.authz.sections
                                 if a != 'groups']:
            resource_glob = resource_section
            if '@' not in resource_glob:
                resource_glob += '@*'

            if fnmatch(resource_key, resource_glob):
                section = self.authz[resource_section]
                for who, permissions in section.iteritems():
                    if who in valid_users or \
                            who in self.groups_by_user.get(username, []):
                        self.log.debug('%s matched section %s for user %s',
                                       resource_key, resource_glob, username)
                        if isinstance(permissions, basestring):
                            return [permissions]
                        else:
                            return permissions
        return None

########NEW FILE########
__FILENAME__ = config_perm_provider
# -*- coding: utf-8 -*-
#
# Copyright (C) 2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from trac.core import *
from trac.config import ConfigSection
from trac.perm import IPermissionRequestor


class ExtraPermissionsProvider(Component):
    """Extra permission provider."""

    implements(IPermissionRequestor)

    extra_permissions_section = ConfigSection('extra-permissions',
        doc="""This section provides a way to add arbitrary permissions to a
        Trac environment. This can be useful for adding new permissions to use
        for workflow actions, for example.

        To add new permissions, create a new section `[extra-permissions]` in
        your `trac.ini`. Every entry in that section defines a meta-permission
        and a comma-separated list of permissions. For example:
        {{{
        [extra-permissions]
        extra_admin = extra_view, extra_modify, extra_delete
        }}}
        This entry will define three new permissions `EXTRA_VIEW`,
        `EXTRA_MODIFY` and `EXTRA_DELETE`, as well as a meta-permissions
        `EXTRA_ADMIN` that grants all three permissions.

        If you don't want a meta-permission, start the meta-name with an
        underscore (`_`):
        {{{
        [extra-permissions]
        _perms = extra_view, extra_modify
        }}}
        """)

    def get_permission_actions(self):
        permissions = {}
        for meta, perms in self.extra_permissions_section.options():
            perms = [each.strip().upper() for each in perms.split(',')]
            for perm in perms:
                permissions.setdefault(perm, [])
            meta = meta.strip().upper()
            if meta and not meta.startswith('_'):
                permissions.setdefault(meta, []).extend(perms)
        return [(k, v) if v else k for k, v in permissions.iteritems()]

########NEW FILE########
__FILENAME__ = authz_policy
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os
import tempfile
import unittest
try:
    from configobj import ConfigObj
except ImportError:
    ConfigObj = None

from trac.resource import Resource
from trac.test import EnvironmentStub
from trac.util import create_file
from tracopt.perm.authz_policy import AuthzPolicy


class AuthzPolicyTestCase(unittest.TestCase):

    def setUp(self):
        tmpdir = os.path.realpath(tempfile.gettempdir())
        self.authz_file = os.path.join(tmpdir, 'trac-authz-policy')
        create_file(self.authz_file, """\
# Unicode user names
[groups]
administrators = at

[wiki:WikiStart]
non = WIKI_VIEW
@administrators = WIKI_VIEW
* =

# Unicode page names
[wiki:rsum]
non =
@administrators = WIKI_VIEW
* =
""")
        self.env = EnvironmentStub(enable=[AuthzPolicy])
        self.env.config.set('authz_policy', 'authz_file', self.authz_file)
        self.authz_policy = AuthzPolicy(self.env)

    def tearDown(self):
        self.env.reset_db()
        os.remove(self.authz_file)

    def check_permission(self, action, user, resource, perm):
        return self.authz_policy.check_permission(action, user, resource, perm)

    def test_unicode_username(self):
        resource = Resource('wiki', 'WikiStart')
        self.assertEqual(
            False,
            self.check_permission('WIKI_VIEW', 'anonymous', resource, None))
        self.assertEqual(
            True,
            self.check_permission('WIKI_VIEW', u'non', resource, None))

    def test_unicode_resource_name(self):
        resource = Resource('wiki', u'rsum')
        self.assertEqual(
            False,
            self.check_permission('WIKI_VIEW', 'anonymous', resource, None))
        self.assertEqual(
            False,
            self.check_permission('WIKI_VIEW', u'non', resource, None))
        self.assertEqual(
            True,
            self.check_permission('WIKI_VIEW', u'at', resource, None))


def suite():
    suite = unittest.TestSuite()
    if ConfigObj:
        suite.addTest(unittest.makeSuite(AuthzPolicyTestCase, 'test'))
    else:
        print "SKIP: tracopt/perm/tests/authz_policy.py (no configobj " + \
              "installed)"
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = clone
# -*- coding: utf-8 -*-
#
# Copyright (C) 2011 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from genshi.builder import tag
from genshi.filters import Transformer

from trac.core import Component, implements
from trac.web.api import ITemplateStreamFilter
from trac.util.presentation import captioned_button
from trac.util.translation import _


class TicketCloneButton(Component):
    """Add a 'Clone' button to the ticket box.

    This button is located next to the 'Reply' to description button,
    and pressing it will send a request for creating a new ticket
    which will be based on the cloned one.
    """

    implements(ITemplateStreamFilter)

    # ITemplateStreamFilter methods

    def filter_stream(self, req, method, filename, stream, data):
        if filename == 'ticket.html':
            ticket = data.get('ticket')
            if ticket and ticket.exists and \
                    'TICKET_ADMIN' in req.perm(ticket.resource):
                filter = Transformer('//h3[@id="comment:description"]')
                stream |= filter.after(self._clone_form(req, ticket, data))
        return stream

    def _clone_form(self, req, ticket, data):
        fields = {}
        for f in data.get('fields', []):
            name = f['name']
            if name == 'summary':
                fields['summary'] = _("%(summary)s (cloned)",
                                      summary=ticket['summary'])
            elif name == 'description':
                fields['description'] = \
                    _("Cloned from #%(id)s:\n----\n%(description)s",
                      id=ticket.id, description=ticket['description'])
            else:
                fields[name] = ticket[name]
        return tag.form(
            tag.div(
                tag.input(type="submit", name="clone",
                          value=captioned_button(req, '+#', _("Clone")),
                          title=_("Create a copy of this ticket")),
                [tag.input(type="hidden", name='field_' + n, value=v)
                 for n, v in fields.iteritems()],
                tag.input(type="hidden", name='preview', value=''),
                class_="inlinebuttons"),
            method="post", action=req.href.newticket())

########NEW FILE########
__FILENAME__ = commit_updater
# -*- coding: utf-8 -*-
#
# Copyright (C) 2009 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

# This plugin was based on the contrib/trac-post-commit-hook script, which
# had the following copyright notice:
# ----------------------------------------------------------------------------
# Copyright (c) 2004 Stephen Hansen
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to
# deal in the Software without restriction, including without limitation the
# rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
# sell copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
#   The above copyright notice and this permission notice shall be included in
#   all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
# IN THE SOFTWARE.
# ----------------------------------------------------------------------------

from __future__ import with_statement

from datetime import datetime
import re

from genshi.builder import tag

from trac.config import BoolOption, Option
from trac.core import Component, implements
from trac.perm import PermissionCache
from trac.resource import Resource
from trac.ticket import Ticket
from trac.ticket.notification import TicketNotifyEmail
from trac.util.datefmt import utc
from trac.util.text import exception_to_unicode
from trac.util.translation import cleandoc_
from trac.versioncontrol import IRepositoryChangeListener, RepositoryManager
from trac.versioncontrol.web_ui.changeset import ChangesetModule
from trac.wiki.formatter import format_to_html
from trac.wiki.macros import WikiMacroBase


class CommitTicketUpdater(Component):
    """Update tickets based on commit messages.

    This component hooks into changeset notifications and searches commit
    messages for text in the form of:
    {{{
    command #1
    command #1, #2
    command #1 & #2
    command #1 and #2
    }}}

    Instead of the short-hand syntax "#1", "ticket:1" can be used as well,
    e.g.:
    {{{
    command ticket:1
    command ticket:1, ticket:2
    command ticket:1 & ticket:2
    command ticket:1 and ticket:2
    }}}

    In addition, the ':' character can be omitted and issue or bug can be used
    instead of ticket.

    You can have more than one command in a message. The following commands
    are supported. There is more than one spelling for each command, to make
    this as user-friendly as possible.

      close, closed, closes, fix, fixed, fixes::
        The specified tickets are closed, and the commit message is added to
        them as a comment.

      references, refs, addresses, re, see::
        The specified tickets are left in their current status, and the commit
        message is added to them as a comment.

    A fairly complicated example of what you can do is with a commit message
    of:

        Changed blah and foo to do this or that. Fixes #10 and #12,
        and refs #12.

    This will close #10 and #12, and add a note to #12.
    """

    implements(IRepositoryChangeListener)

    envelope = Option('ticket', 'commit_ticket_update_envelope', '',
        """Require commands to be enclosed in an envelope.

        Must be empty or contain two characters. For example, if set to "[]",
        then commands must be in the form of [closes #4].""")

    commands_close = Option('ticket', 'commit_ticket_update_commands.close',
        'close closed closes fix fixed fixes',
        """Commands that close tickets, as a space-separated list.""")

    commands_refs = Option('ticket', 'commit_ticket_update_commands.refs',
        'addresses re references refs see',
        """Commands that add a reference, as a space-separated list.

        If set to the special value <ALL>, all tickets referenced by the
        message will get a reference to the changeset.""")

    check_perms = BoolOption('ticket', 'commit_ticket_update_check_perms',
        'true',
        """Check that the committer has permission to perform the requested
        operations on the referenced tickets.

        This requires that the user names be the same for Trac and repository
        operations.""")

    notify = BoolOption('ticket', 'commit_ticket_update_notify', 'true',
        """Send ticket change notification when updating a ticket.""")

    ticket_prefix = '(?:#|(?:ticket|issue|bug)[: ]?)'
    ticket_reference = ticket_prefix + '[0-9]+'
    ticket_command = (r'(?P<action>[A-Za-z]*)\s*.?\s*'
                      r'(?P<ticket>%s(?:(?:[, &]*|[ ]?and[ ]?)%s)*)' %
                      (ticket_reference, ticket_reference))

    @property
    def command_re(self):
        (begin, end) = (re.escape(self.envelope[0:1]),
                        re.escape(self.envelope[1:2]))
        return re.compile(begin + self.ticket_command + end)

    ticket_re = re.compile(ticket_prefix + '([0-9]+)')

    _last_cset_id = None

    # IRepositoryChangeListener methods

    def changeset_added(self, repos, changeset):
        if self._is_duplicate(changeset):
            return
        tickets = self._parse_message(changeset.message)
        comment = self.make_ticket_comment(repos, changeset)
        self._update_tickets(tickets, changeset, comment,
                             datetime.now(utc))

    def changeset_modified(self, repos, changeset, old_changeset):
        if self._is_duplicate(changeset):
            return
        tickets = self._parse_message(changeset.message)
        old_tickets = {}
        if old_changeset is not None:
            old_tickets = self._parse_message(old_changeset.message)
        tickets = dict(each for each in tickets.iteritems()
                       if each[0] not in old_tickets)
        comment = self.make_ticket_comment(repos, changeset)
        self._update_tickets(tickets, changeset, comment,
                             datetime.now(utc))

    def _is_duplicate(self, changeset):
        # Avoid duplicate changes with multiple scoped repositories
        cset_id = (changeset.rev, changeset.message, changeset.author,
                   changeset.date)
        if cset_id != self._last_cset_id:
            self._last_cset_id = cset_id
            return False
        return True

    def _parse_message(self, message):
        """Parse the commit message and return the ticket references."""
        cmd_groups = self.command_re.findall(message)
        functions = self._get_functions()
        tickets = {}
        for cmd, tkts in cmd_groups:
            func = functions.get(cmd.lower())
            if not func and self.commands_refs.strip() == '<ALL>':
                func = self.cmd_refs
            if func:
                for tkt_id in self.ticket_re.findall(tkts):
                    tickets.setdefault(int(tkt_id), []).append(func)
        return tickets

    def make_ticket_comment(self, repos, changeset):
        """Create the ticket comment from the changeset data."""
        revstring = str(changeset.rev)
        if repos.reponame:
            revstring += '/' + repos.reponame
        return """\
In [changeset:"%s"]:
{{{
#!CommitTicketReference repository="%s" revision="%s"
%s
}}}""" % (revstring, repos.reponame, changeset.rev, changeset.message.strip())

    def _update_tickets(self, tickets, changeset, comment, date):
        """Update the tickets with the given comment."""
        perm = PermissionCache(self.env, changeset.author)
        for tkt_id, cmds in tickets.iteritems():
            try:
                self.log.debug("Updating ticket #%d", tkt_id)
                save = False
                with self.env.db_transaction:
                    ticket = Ticket(self.env, tkt_id)
                    ticket_perm = perm(ticket.resource)
                    for cmd in cmds:
                        if cmd(ticket, changeset, ticket_perm) is not False:
                            save = True
                    if save:
                        ticket.save_changes(changeset.author, comment, date)
                if save:
                    self._notify(ticket, date)
            except Exception, e:
                self.log.error("Unexpected error while processing ticket "
                               "#%s: %s", tkt_id, exception_to_unicode(e))

    def _notify(self, ticket, date):
        """Send a ticket update notification."""
        if not self.notify:
            return
        try:
            tn = TicketNotifyEmail(self.env)
            tn.notify(ticket, newticket=False, modtime=date)
        except Exception, e:
            self.log.error("Failure sending notification on change to "
                           "ticket #%s: %s", ticket.id,
                           exception_to_unicode(e))

    def _get_functions(self):
        """Create a mapping from commands to command functions."""
        functions = {}
        for each in dir(self):
            if not each.startswith('cmd_'):
                continue
            func = getattr(self, each)
            for cmd in getattr(self, 'commands_' + each[4:], '').split():
                functions[cmd] = func
        return functions

    # Command-specific behavior
    # The ticket isn't updated if all extracted commands return False.

    def cmd_close(self, ticket, changeset, perm):
        if self.check_perms and not 'TICKET_MODIFY' in perm:
            self.log.info("%s doesn't have TICKET_MODIFY permission for #%d",
                          changeset.author, ticket.id)
            return False
        ticket['status'] = 'closed'
        ticket['resolution'] = 'fixed'
        if not ticket['owner']:
            ticket['owner'] = changeset.author

    def cmd_refs(self, ticket, changeset, perm):
        if self.check_perms and not 'TICKET_APPEND' in perm:
            self.log.info("%s doesn't have TICKET_APPEND permission for #%d",
                          changeset.author, ticket.id)
            return False


class CommitTicketReferenceMacro(WikiMacroBase):
    _domain = 'messages'
    _description = cleandoc_(
    """Insert a changeset message into the output.

    This macro must be called using wiki processor syntax as follows:
    {{{
    {{{
    #!CommitTicketReference repository="reponame" revision="rev"
    }}}
    }}}
    where the arguments are the following:
     - `repository`: the repository containing the changeset
     - `revision`: the revision of the desired changeset
    """)

    def expand_macro(self, formatter, name, content, args={}):
        reponame = args.get('repository') or ''
        rev = args.get('revision')
        repos = RepositoryManager(self.env).get_repository(reponame)
        try:
            changeset = repos.get_changeset(rev)
            message = changeset.message
            rev = changeset.rev
            resource = repos.resource
        except Exception:
            message = content
            resource = Resource('repository', reponame)
        if formatter.context.resource.realm == 'ticket':
            ticket_re = CommitTicketUpdater.ticket_re
            if not any(int(tkt_id) == int(formatter.context.resource.id)
                       for tkt_id in ticket_re.findall(message)):
                return tag.p("(The changeset message doesn't reference this "
                             "ticket)", class_='hint')
        if ChangesetModule(self.env).wiki_format_messages:
            return tag.div(format_to_html(self.env,
                formatter.context.child('changeset', rev, parent=resource),
                message, escape_newlines=True), class_='message')
        else:
            return tag.pre(message, class_='message')

########NEW FILE########
__FILENAME__ = deleter
# -*- coding: utf-8 -*-
#
# Copyright (C) 2010 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from genshi.builder import tag
from genshi.filters import Transformer
from genshi.filters.transform import StreamBuffer

from trac.core import Component, TracError, implements
from trac.ticket.model import Ticket
from trac.ticket.web_ui import TicketModule
from trac.util import get_reporter_id
from trac.util.datefmt import from_utimestamp
from trac.util.presentation import captioned_button
from trac.util.translation import _
from trac.web.api import IRequestFilter, IRequestHandler, ITemplateStreamFilter
from trac.web.chrome import ITemplateProvider, add_notice, add_stylesheet


class TicketDeleter(Component):
    """Ticket and ticket comment deleter.

    This component allows deleting ticket comments and complete tickets. For
    users having `TICKET_ADMIN` permission, it adds a "Delete" button next to
    each "Reply" button on the page. The button in the ticket description
    requests deletion of the complete ticket, and the buttons in the change
    history request deletion of a single comment.

    '''Comment and ticket deletion are irreversible (and therefore
    ''dangerous'') operations.''' For that reason, a confirmation step is
    requested. The confirmation page shows the ticket box (in the case of a
    ticket deletion) or the ticket change (in the case of a comment deletion).
    """

    implements(ITemplateProvider, ITemplateStreamFilter, IRequestFilter,
               IRequestHandler)

    # ITemplateProvider methods

    def get_htdocs_dirs(self):
        return []

    def get_templates_dirs(self):
        from pkg_resources import resource_filename
        return [resource_filename(__name__, 'templates')]

    # ITemplateStreamFilter methods

    def filter_stream(self, req, method, filename, stream, data):
        if filename not in ('ticket.html', 'ticket_preview.html'):
            return stream
        ticket = data.get('ticket')
        if not (ticket and ticket.exists
                and 'TICKET_ADMIN' in req.perm(ticket.resource)):
            return stream

        # Insert "Delete" buttons for ticket description and each comment
        def delete_ticket():
            return tag.form(
                tag.div(
                    tag.input(type='hidden', name='action', value='delete'),
                    tag.input(type='submit',
                              value=captioned_button(req, u'', # 'EN DASH'
                                                     _("Delete")),
                              title=_('Delete ticket'),
                              class_="trac-delete"),
                    class_="inlinebuttons"),
                action='#', method='get')

        def delete_comment():
            for event in buffer:
                cnum, cdate = event[1][1].get('id')[12:].split('-', 1)
                return tag.form(
                    tag.div(
                        tag.input(type='hidden', name='action',
                                  value='delete-comment'),
                        tag.input(type='hidden', name='cnum', value=cnum),
                        tag.input(type='hidden', name='cdate', value=cdate),
                        tag.input(type='submit',
                                  value=captioned_button(req, u'', # 'EN DASH'
                                                         _("Delete")),
                                  title=_('Delete comment %(num)s', num=cnum),
                                  class_="trac-delete"),
                        class_="inlinebuttons"),
                    action='#', method='get')

        buffer = StreamBuffer()
        return stream | Transformer('//div[@class="description"]'
                                    '/h3[@id="comment:description"]') \
            .after(delete_ticket).end() \
            .select('//div[starts-with(@class, "change")]/@id') \
            .copy(buffer).end() \
            .select('//div[starts-with(@class, "change") and @id]'
                    '/div[@class="trac-ticket-buttons"]') \
            .prepend(delete_comment)

    # IRequestFilter methods

    def pre_process_request(self, req, handler):
        if handler is not TicketModule(self.env):
            return handler
        action = req.args.get('action')
        if action in ('delete', 'delete-comment'):
            return self
        else:
            return handler

    def post_process_request(self, req, template, data, content_type):
        return template, data, content_type

    # IRequestHandler methods

    def match_request(self, req):
        return False

    def process_request(self, req):
        id = int(req.args.get('id'))
        req.perm('ticket', id).require('TICKET_ADMIN')
        ticket = Ticket(self.env, id)
        action = req.args['action']
        cnum = req.args.get('cnum')
        if req.method == 'POST':
            if 'cancel' in req.args:
                href = req.href.ticket(id)
                if action == 'delete-comment':
                    href += '#comment:%s' % cnum
                req.redirect(href)

            if action == 'delete':
                ticket.delete()
                add_notice(req, _('The ticket #%(id)s has been deleted.',
                                  id=ticket.id))
                req.redirect(req.href())

            elif action == 'delete-comment':
                cdate = from_utimestamp(long(req.args.get('cdate')))
                ticket.delete_change(cdate=cdate)
                add_notice(req, _('The ticket comment %(num)s on ticket '
                                  '#%(id)s has been deleted.',
                                  num=cnum, id=ticket.id))
                req.redirect(req.href.ticket(id))

        tm = TicketModule(self.env)
        data = tm._prepare_data(req, ticket)
        tm._insert_ticket_data(req, ticket, data,
                               get_reporter_id(req, 'author'), {})
        data.update(action=action, cdate=None)

        if action == 'delete-comment':
            data['cdate'] = req.args.get('cdate')
            cdate = from_utimestamp(long(data['cdate']))
            for change in data['changes']:
                if change.get('date') == cdate:
                    data['change'] = change
                    data['cnum'] = change.get('cnum')
                    break
            else:
                raise TracError(_('Comment %(num)s not found', num=cnum))

        add_stylesheet(req, 'common/css/ticket.css')
        return 'ticket_delete.html', data, None

########NEW FILE########
__FILENAME__ = git_fs
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Edgewall Software
# Copyright (C) 2006-2011, Herbert Valerio Riedel <hvr@gnu.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from __future__ import with_statement

from datetime import datetime
import os
import sys

from genshi.builder import tag

from trac.config import BoolOption, IntOption, PathOption, Option
from trac.core import *
from trac.util import TracError, shorten_line
from trac.util.datefmt import FixedOffset, to_timestamp, format_datetime
from trac.util.text import to_unicode
from trac.versioncontrol.api import Changeset, Node, Repository, \
                                    IRepositoryConnector, NoSuchChangeset, \
                                    NoSuchNode, IRepositoryProvider
from trac.versioncontrol.cache import CachedRepository, CachedChangeset
from trac.versioncontrol.web_ui import IPropertyRenderer
from trac.web.chrome import Chrome
from trac.wiki import IWikiSyntaxProvider

from tracopt.versioncontrol.git import PyGIT


class GitCachedRepository(CachedRepository):
    """Git-specific cached repository.

    Passes through {display,short,normalize}_rev
    """

    def display_rev(self, rev):
        return self.short_rev(rev)

    def short_rev(self, path):
        return self.repos.short_rev(path)

    def normalize_rev(self, rev):
        if not rev:
            return self.repos.get_youngest_rev()
        normrev = self.repos.git.verifyrev(rev)
        if normrev is None:
            raise NoSuchChangeset(rev)
        return normrev

    def get_changeset(self, rev):
        return GitCachedChangeset(self, self.normalize_rev(rev), self.env)


class GitCachedChangeset(CachedChangeset):
    """Git-specific cached changeset.

    Handles get_branches()
    """
    def get_branches(self):
        _rev = self.rev

        return [(k, v == _rev) for k, v in
                 self.repos.repos.git.get_branch_contains(_rev, resolve=True)]


def _last_iterable(iterable):
    """helper for detecting last iteration in for-loop"""
    i = iter(iterable)
    v = i.next()
    for nextv in i:
        yield False, v
        v = nextv
    yield True, v

def intersperse(sep, iterable):
    """The 'intersperse' generator takes an element and an iterable and
    intersperses that element between the elements of the iterable.

    inspired by Haskell's ``Data.List.intersperse``
    """

    for i, item in enumerate(iterable):
        if i: yield sep
        yield item

# helper
def _parse_user_time(s):
    """Parse author or committer attribute lines and return
    corresponding ``(user, timestamp)`` pair.
    """

    user, time, tz_str = s.rsplit(None, 2)
    tz = FixedOffset((int(tz_str) * 6) / 10, tz_str)
    time = datetime.fromtimestamp(float(time), tz)
    return user, time


class GitConnector(Component):

    implements(IRepositoryConnector, IWikiSyntaxProvider)

    def __init__(self):
        self._version = None

        try:
            self._version = PyGIT.Storage.git_version(git_bin=self.git_bin)
        except PyGIT.GitError, e:
            self.log.error("GitError: " + str(e))

        if self._version:
            self.log.info("detected GIT version %s" % self._version['v_str'])
            self.env.systeminfo.append(('GIT', self._version['v_str']))
            if not self._version['v_compatible']:
                self.log.error("GIT version %s installed not compatible"
                               "(need >= %s)" %
                               (self._version['v_str'],
                                self._version['v_min_str']))

    # IWikiSyntaxProvider methods

    def _format_sha_link(self, formatter, sha, label):
        # FIXME: this function needs serious rethinking...

        reponame = ''

        context = formatter.context
        while context:
            if context.resource.realm in ('source', 'changeset'):
                reponame = context.resource.parent.id
                break
            context = context.parent

        try:
            repos = self.env.get_repository(reponame)

            if not repos:
                raise Exception("Repository '%s' not found" % reponame)

            sha = repos.normalize_rev(sha) # in case it was abbreviated
            changeset = repos.get_changeset(sha)
            return tag.a(label, class_='changeset',
                         title=shorten_line(changeset.message),
                         href=formatter.href.changeset(sha, repos.reponame))
        except Exception, e:
            return tag.a(label, class_='missing changeset',
                         title=to_unicode(e), rel='nofollow')

    def get_wiki_syntax(self):
        yield (r'(?:\b|!)r?[0-9a-fA-F]{%d,40}\b' % self.wiki_shortrev_len,
               lambda fmt, sha, match:
                    self._format_sha_link(fmt, sha.startswith('r')
                                          and sha[1:] or sha, sha))

    def get_link_resolvers(self):
        yield ('sha', lambda fmt, _, sha, label, match=None:
                        self._format_sha_link(fmt, sha, label))

    # IRepositoryConnector methods

    persistent_cache = BoolOption('git', 'persistent_cache', 'false',
        """Enable persistent caching of commit tree.""")

    cached_repository = BoolOption('git', 'cached_repository', 'false',
        """Wrap `GitRepository` in `CachedRepository`.""")

    shortrev_len = IntOption('git', 'shortrev_len', 7,
        """The length at which a sha1 should be abbreviated to (must
        be >= 4 and <= 40).
        """)

    wiki_shortrev_len = IntOption('git', 'wikishortrev_len', 40,
        """The minimum length of an hex-string for which
        auto-detection as sha1 is performed (must be >= 4 and <= 40).
        """)

    trac_user_rlookup = BoolOption('git', 'trac_user_rlookup', 'false',
        """Enable reverse mapping of git email addresses to trac user ids
        (costly if you have many users).""")

    use_committer_id = BoolOption('git', 'use_committer_id', 'true',
        """Use git-committer id instead of git-author id for the
        changeset ''Author'' field.
        """)

    use_committer_time = BoolOption('git', 'use_committer_time', 'true',
        """Use git-committer timestamp instead of git-author timestamp
        for the changeset ''Timestamp'' field.
        """)

    git_fs_encoding = Option('git', 'git_fs_encoding', 'utf-8',
        """Define charset encoding of paths within git repositories.""")

    git_bin = Option('git', 'git_bin', 'git',
        """Path to the git executable.""")


    def get_supported_types(self):
        yield ('git', 8)

    def get_repository(self, type, dir, params):
        """GitRepository factory method"""
        assert type == 'git'

        if not (4 <= self.shortrev_len <= 40):
            raise TracError("[git] shortrev_len setting must be within [4..40]")

        if not (4 <= self.wiki_shortrev_len <= 40):
            raise TracError("[git] wikishortrev_len must be within [4..40]")

        if not self._version:
            raise TracError("GIT backend not available")
        elif not self._version['v_compatible']:
            raise TracError("GIT version %s installed not compatible"
                            "(need >= %s)" %
                            (self._version['v_str'],
                             self._version['v_min_str']))

        if self.trac_user_rlookup:
            def rlookup_uid(email):
                """Reverse map 'real name <user@domain.tld>' addresses to trac
                user ids.

                :return: `None` if lookup failed
                """

                try:
                    _, email = email.rsplit('<', 1)
                    email, _ = email.split('>', 1)
                    email = email.lower()
                except Exception:
                    return None

                for _uid, _name, _email in self.env.get_known_users():
                    try:
                        if email == _email.lower():
                            return _uid
                    except Exception:
                        continue

        else:
            def rlookup_uid(_):
                return None

        repos = GitRepository(dir, params, self.log,
                              persistent_cache=self.persistent_cache,
                              git_bin=self.git_bin,
                              git_fs_encoding=self.git_fs_encoding,
                              shortrev_len=self.shortrev_len,
                              rlookup_uid=rlookup_uid,
                              use_committer_id=self.use_committer_id,
                              use_committer_time=self.use_committer_time,
                              )

        if self.cached_repository:
            repos = GitCachedRepository(self.env, repos, self.log)
            self.log.debug("enabled CachedRepository for '%s'" % dir)
        else:
            self.log.debug("disabled CachedRepository for '%s'" % dir)

        return repos


class CsetPropertyRenderer(Component):

    implements(IPropertyRenderer)

    # relied upon by GitChangeset
    def match_property(self, name, mode):
        # default renderer has priority 1
        return (name in ('Parents',
                         'Children',
                         'Branches',
                         'git-committer',
                         'git-author',
                         ) and mode == 'revprop') and 4 or 0

    def render_property(self, name, mode, context, props):

        def sha_link(sha, label=None):
            # sha is assumed to be a non-abbreviated 40-chars sha id
            try:
                reponame = context.resource.parent.id
                repos = self.env.get_repository(reponame)
                cset = repos.get_changeset(sha)
                if label is None:
                    label = repos.display_rev(sha)

                return tag.a(label, class_='changeset',
                             title=shorten_line(cset.message),
                             href=context.href.changeset(sha, repos.reponame))

            except Exception, e:
                return tag.a(sha, class_='missing changeset',
                             title=to_unicode(e), rel='nofollow')

        if name == 'Branches':
            branches = props[name]

            # simple non-merge commit
            return tag(*intersperse(', ', (sha_link(rev, label)
                                           for label, rev in branches)))

        elif name in ('Parents', 'Children'):
            revs = props[name] # list of commit ids

            if name == 'Parents' and len(revs) > 1:
                # we got a merge...
                current_sha = context.resource.id
                reponame = context.resource.parent.id

                parent_links = intersperse(', ', \
                    ((sha_link(rev),
                      ' (',
                      tag.a('diff',
                            title="Diff against this parent (show the " \
                                  "changes merged from the other parents)",
                            href=context.href.changeset(current_sha, reponame,
                                                        old=rev)),
                      ')')
                     for rev in revs))

                return tag(list(parent_links),
                           tag.br(),
                           tag.span(tag("Note: this is a ",
                                        tag.strong("merge"), " changeset, "
                                        "the changes displayed below "
                                        "correspond to the merge itself."),
                                    class_='hint'),
                           tag.br(),
                           tag.span(tag("Use the ", tag.tt("(diff)"),
                                        " links above to see all the changes "
                                        "relative to each parent."),
                                    class_='hint'))

            # simple non-merge commit
            return tag(*intersperse(', ', map(sha_link, revs)))

        elif name in ('git-committer', 'git-author'):
            user_, time_ = props[name]
            _str = "%s (%s)" % (
                Chrome(self.env).format_author(context.req, user_),
                format_datetime(time_, tzinfo=context.req.tz))
            return unicode(_str)

        raise TracError("Internal error")


class GitRepository(Repository):
    """Git repository"""

    def __init__(self, path, params, log,
                 persistent_cache=False,
                 git_bin='git',
                 git_fs_encoding='utf-8',
                 shortrev_len=7,
                 rlookup_uid=lambda _: None,
                 use_committer_id=False,
                 use_committer_time=False,
                 ):

        self.logger = log
        self.gitrepo = path
        self.params = params
        self.shortrev_len = max(4, min(shortrev_len, 40))
        self.rlookup_uid = rlookup_uid
        self.use_committer_time = use_committer_time
        self.use_committer_id = use_committer_id

        try:
            self.git = PyGIT.StorageFactory(path, log, not persistent_cache,
                                            git_bin=git_bin,
                                            git_fs_encoding=git_fs_encoding) \
                            .getInstance()
        except PyGIT.GitError, e:
            raise TracError("%s does not appear to be a Git "
                            "repository." % path)

        Repository.__init__(self, 'git:'+path, self.params, log)

    def close(self):
        self.git = None

    def get_youngest_rev(self):
        return self.git.youngest_rev()

    def get_oldest_rev(self):
        return self.git.oldest_rev()

    def normalize_path(self, path):
        return path and path.strip('/') or '/'

    def normalize_rev(self, rev):
        if not rev:
            return self.get_youngest_rev()
        normrev = self.git.verifyrev(rev)
        if normrev is None:
            raise NoSuchChangeset(rev)
        return normrev

    def display_rev(self, rev):
        return self.short_rev(rev)

    def short_rev(self, rev):
        return self.git.shortrev(self.normalize_rev(rev),
                                 min_len=self.shortrev_len)

    def get_node(self, path, rev=None, historian=None):
        return GitNode(self, path, rev, self.log, None, historian)

    def get_quickjump_entries(self, rev):
        for bname, bsha in self.git.get_branches():
            yield 'branches', bname, '/', bsha
        for t in self.git.get_tags():
            yield 'tags', t, '/', t

    def get_path_url(self, path, rev):
        return self.params.get('url')

    def get_changesets(self, start, stop):
        for rev in self.git.history_timerange(to_timestamp(start),
                                              to_timestamp(stop)):
            yield self.get_changeset(rev)

    def get_changeset(self, rev):
        """GitChangeset factory method"""
        return GitChangeset(self, rev)

    def get_changes(self, old_path, old_rev, new_path, new_rev,
                    ignore_ancestry=0):
        # TODO: handle renames/copies, ignore_ancestry
        if old_path != new_path:
            raise TracError("not supported in git_fs")

        with self.git.get_historian(old_rev,
                                    old_path.strip('/')) as old_historian:
            with self.git.get_historian(new_rev,
                                        new_path.strip('/')) as new_historian:
                for chg in self.git.diff_tree(old_rev, new_rev,
                                              self.normalize_path(new_path)):
                    mode1, mode2, obj1, obj2, action, path, path2 = chg

                    kind = Node.FILE
                    if mode2.startswith('04') or mode1.startswith('04'):
                        kind = Node.DIRECTORY

                    change = GitChangeset.action_map[action]

                    old_node = None
                    new_node = None

                    if change != Changeset.ADD:
                        old_node = self.get_node(path, old_rev, old_historian)
                    if change != Changeset.DELETE:
                        new_node = self.get_node(path, new_rev, new_historian)

                    yield old_node, new_node, kind, change

    def next_rev(self, rev, path=''):
        return self.git.hist_next_revision(rev)

    def previous_rev(self, rev, path=''):
        return self.git.hist_prev_revision(rev)

    def parent_revs(self, rev):
        return self.git.parents(rev)

    def child_revs(self, rev):
        return self.git.children(rev)

    def rev_older_than(self, rev1, rev2):
        rc = self.git.rev_is_anchestor_of(rev1, rev2)
        return rc

    # def clear(self, youngest_rev=None):
    #     self.youngest = None
    #     if youngest_rev is not None:
    #         self.youngest = self.normalize_rev(youngest_rev)
    #     self.oldest = None

    def clear(self, youngest_rev=None):
        self.sync()

    def sync(self, rev_callback=None, clean=None):
        if rev_callback:
            revs = set(self.git.all_revs())

        if not self.git.sync():
            return None # nothing expected to change

        if rev_callback:
            revs = set(self.git.all_revs()) - revs
            for rev in revs:
                rev_callback(rev)


class GitNode(Node):

    def __init__(self, repos, path, rev, log, ls_tree_info=None,
                 historian=None):
        self.log = log
        self.repos = repos
        self.fs_sha = None # points to either tree or blobs
        self.fs_perm = None
        self.fs_size = None
        rev = rev and str(rev) or 'HEAD'

        kind = Node.DIRECTORY
        p = path.strip('/')
        if p: # ie. not the root-tree
            if not ls_tree_info:
                ls_tree_info = repos.git.ls_tree(rev, p) or None
                if ls_tree_info:
                    [ls_tree_info] = ls_tree_info

            if not ls_tree_info:
                raise NoSuchNode(path, rev)

            self.fs_perm, k, self.fs_sha, self.fs_size, _ = ls_tree_info

            # fix-up to the last commit-rev that touched this node
            rev = repos.git.last_change(rev, p, historian)

            if k == 'tree':
                pass
            elif k == 'commit':
                # FIXME: this is a workaround for missing git submodule
                #        support in the plugin
                pass
            elif k == 'blob':
                kind = Node.FILE
            else:
                raise TracError("Internal error (got unexpected object " \
                                "kind '%s')" % k)

        self.created_path = path
        self.created_rev = rev

        Node.__init__(self, repos, path, rev, kind)

    def __git_path(self):
        """return path as expected by PyGIT"""
        p = self.path.strip('/')
        if self.isfile:
            assert p
            return p
        if self.isdir:
            return p and (p + '/')

        raise TracError("internal error")

    def get_content(self):
        if not self.isfile:
            return None

        return self.repos.git.get_file(self.fs_sha)

    def get_properties(self):
        return self.fs_perm and {'mode': self.fs_perm } or {}

    def get_annotations(self):
        if not self.isfile:
            return

        return [rev for rev, lineno in \
                self.repos.git.blame(self.rev,self.__git_path())]

    def get_entries(self):
        if not self.isdir:
            return

        with self.repos.git.get_historian(self.rev,
                                          self.path.strip('/')) as historian:
            for ent in self.repos.git.ls_tree(self.rev, self.__git_path()):
                yield GitNode(self.repos, ent[-1], self.rev, self.log, ent,
                              historian)

    def get_content_type(self):
        if self.isdir:
            return None

        return ''

    def get_content_length(self):
        if not self.isfile:
            return None

        if self.fs_size is None:
            self.fs_size = self.repos.git.get_obj_size(self.fs_sha)

        return self.fs_size

    def get_history(self, limit=None):
        # TODO: find a way to follow renames/copies
        for is_last, rev in _last_iterable(self.repos.git.history(self.rev,
                                                self.__git_path(), limit)):
            yield (self.path, rev, Changeset.EDIT if not is_last else
                                   Changeset.ADD)

    def get_last_modified(self):
        if not self.isfile:
            return None

        try:
            msg, props = self.repos.git.read_commit(self.rev)
            user, ts = _parse_user_time(props['committer'][0])
        except:
            self.log.error("internal error (could not get timestamp from "
                           "commit '%s')" % self.rev)
            return None

        return ts


class GitChangeset(Changeset):
    """A Git changeset in the Git repository.

    Corresponds to a Git commit blob.
    """

    action_map = { # see also git-diff-tree(1) --diff-filter
        'A': Changeset.ADD,
        'M': Changeset.EDIT, # modified
        'T': Changeset.EDIT, # file type (mode) change
        'D': Changeset.DELETE,
        'R': Changeset.MOVE, # renamed
        'C': Changeset.COPY
        } # TODO: U, X, B

    def __init__(self, repos, sha):
        if sha is None:
            raise NoSuchChangeset(sha)

        try:
            msg, props = repos.git.read_commit(sha)
        except PyGIT.GitErrorSha:
            raise NoSuchChangeset(sha)

        self.props = props

        assert 'children' not in props
        _children = list(repos.git.children(sha))
        if _children:
            props['children'] = _children

        committer, author = self._get_committer_and_author()
        # use 1st author/committer as changeset owner/timestamp
        c_user = a_user = c_time = a_time = None
        if committer:
            c_user, c_time = _parse_user_time(committer)
        if author:
            a_user, a_time = _parse_user_time(author)

        if repos.use_committer_time:
            time = c_time or a_time
        else:
            time = a_time or c_time

        if repos.use_committer_id:
            user = c_user or a_user
        else:
            user = a_user or c_user

        # try to resolve email address to trac uid
        user = repos.rlookup_uid(user) or user

        Changeset.__init__(self, repos, rev=sha, message=msg, author=user,
                           date=time)

    def _get_committer_and_author(self):
        committer = author = None
        if 'committer' in self.props:
            committer = self.props['committer'][0]
        if 'author' in self.props:
            author = self.props['author'][0]
        return committer, author

    def get_properties(self):
        properties = {}

        if 'parent' in self.props:
            properties['Parents'] = self.props['parent']

        if 'children' in self.props:
            properties['Children'] = self.props['children']

        committer, author = self._get_committer_and_author()
        if author != committer:
            properties['git-committer'] = _parse_user_time(committer)
            properties['git-author'] = _parse_user_time(author)

        branches = list(self.repos.git.get_branch_contains(self.rev,
                                                           resolve=True))
        if branches:
            properties['Branches'] = branches

        return properties

    def get_changes(self):
        paths_seen = set()
        for parent in self.props.get('parent', [None]):
            for mode1, mode2, obj1, obj2, action, path1, path2 in \
                    self.repos.git.diff_tree(parent, self.rev,
                                             find_renames=True):
                path = path2 or path1
                p_path, p_rev = path1, parent

                kind = Node.FILE
                if mode2.startswith('04') or mode1.startswith('04'):
                    kind = Node.DIRECTORY

                action = GitChangeset.action_map[action[0]]

                if action == Changeset.ADD:
                    p_path = ''
                    p_rev = None

                # CachedRepository expects unique (rev, path, change_type) key
                # this is only an issue in case of merges where files required
                # editing
                if path in paths_seen:
                    continue

                paths_seen.add(path)

                yield path, kind, action, p_path, p_rev


    def get_branches(self):
        _rev = self.rev

        return [(k, v == _rev)
                for k, v in self.repos.git.get_branch_contains(_rev,
                                                               resolve=True)]


class GitwebProjectsRepositoryProvider(Component):

    implements(IRepositoryProvider)

    projects_list = PathOption('git', 'projects_list', doc=
        """Path to a gitweb-formatted projects.list""")

    projects_base = PathOption('git', 'projects_base', doc=
        """Path to the base of your git projects""")

    projects_url = Option('git', 'projects_url', doc=
        """Template for project URLs. %s will be replaced with the repo
        name""")

    def get_repositories(self):
        if not self.projects_list:
            return

        for line in open(self.projects_list):
            line = line.strip()
            name = line
            if name.endswith('.git'):
                name = name[:-4]
            repo = {
                'dir': os.path.join(self.projects_base, line),
                'type': 'git',
            }
            description_path = os.path.join(repo['dir'], 'description')
            if os.path.exists(description_path):
                repo['description'] = open(description_path).read().strip()
            if self.projects_url:
                repo['url'] = self.projects_url % name
            yield name, repo

########NEW FILE########
__FILENAME__ = PyGIT
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Edgewall Software
# Copyright (C) 2006-2011, Herbert Valerio Riedel <hvr@gnu.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

from __future__ import with_statement

import os
import codecs
from collections import deque
from contextlib import contextmanager
import cStringIO
from functools import partial
from operator import itemgetter
import re
from subprocess import Popen, PIPE
import sys
from threading import Lock
import time
import weakref


__all__ = ['GitError', 'GitErrorSha', 'Storage', 'StorageFactory']


def terminate(process):
    """Python 2.5 compatibility method.
    os.kill is not available on Windows before Python 2.7.
    In Python 2.6 subprocess.Popen has a terminate method.
    (It also seems to have some issues on Windows though.)
    """

    def terminate_win(process):
        import ctypes
        PROCESS_TERMINATE = 1
        handle = ctypes.windll.kernel32.OpenProcess(PROCESS_TERMINATE,
                                                    False,
                                                    process.pid)
        ctypes.windll.kernel32.TerminateProcess(handle, -1)
        ctypes.windll.kernel32.CloseHandle(handle)

    def terminate_nix(process):
        import os
        import signal
        return os.kill(process.pid, signal.SIGTERM)

    if sys.platform == 'win32':
        return terminate_win(process)
    return terminate_nix(process)


class GitError(Exception):
    pass

class GitErrorSha(GitError):
    pass

# Helper functions

def parse_commit(raw):
    """Parse the raw content of a commit (as given by `git cat-file -p <rev>`).

    Return the commit message and a dict of properties.
    """
    if not raw:
        raise GitErrorSha
    lines = raw.splitlines()
    if not lines:
        raise GitErrorSha
    line = lines.pop(0)
    props = {}
    multiline = multiline_key = None
    while line:
        if line[0] == ' ':
            if not multiline:
                multiline_key = key
                multiline = [props[multiline_key][-1]]
            multiline.append(line[1:])
        else:
            key, value = line.split(None, 1)
            props.setdefault(key, []).append(value.strip())
        line = lines.pop(0)
        if multiline and (not line or key != multiline_key):
            props[multiline_key][-1] = '\n'.join(multiline)
            multiline = None
    return '\n'.join(lines), props


class GitCore(object):
    """Low-level wrapper around git executable"""

    def __init__(self, git_dir=None, git_bin='git'):
        self.__git_bin = git_bin
        self.__git_dir = git_dir

    def __repr__(self):
        return '<GitCore bin="%s" dir="%s">' % (self.__git_bin,
                                                self.__git_dir)

    def __build_git_cmd(self, gitcmd, *args):
        """construct command tuple for git call suitable for Popen()"""

        cmd = [self.__git_bin]
        if self.__git_dir:
            cmd.append('--git-dir=%s' % self.__git_dir)
        cmd.append(gitcmd)
        cmd.extend(args)

        return cmd

    def __pipe(self, git_cmd, *cmd_args, **kw):
        if sys.platform == 'win32':
            return Popen(self.__build_git_cmd(git_cmd, *cmd_args), **kw)
        else:
            return Popen(self.__build_git_cmd(git_cmd, *cmd_args),
                         close_fds=True, **kw)

    def __execute(self, git_cmd, *cmd_args):
        """execute git command and return file-like object of stdout"""

        #print >>sys.stderr, "DEBUG:", git_cmd, cmd_args

        p = self.__pipe(git_cmd, stdout=PIPE, stderr=PIPE, *cmd_args)

        stdout_data, stderr_data = p.communicate()
        #TODO, do something with p.returncode, e.g. raise exception

        return stdout_data

    def cat_file_batch(self):
        return self.__pipe('cat-file', '--batch', stdin=PIPE, stdout=PIPE)

    def log_pipe(self, *cmd_args):
        return self.__pipe('log', stdout=PIPE, *cmd_args)

    def __getattr__(self, name):
        if name[0] == '_' or name in ['cat_file_batch', 'log_pipe']:
            raise AttributeError, name
        return partial(self.__execute, name.replace('_','-'))

    __is_sha_pat = re.compile(r'[0-9A-Fa-f]*$')

    @classmethod
    def is_sha(cls, sha):
        """returns whether sha is a potential sha id
        (i.e. proper hexstring between 4 and 40 characters)
        """

        # quick test before starting up regexp matcher
        if not (4 <= len(sha) <= 40):
            return False

        return bool(cls.__is_sha_pat.match(sha))


class SizedDict(dict):
    """Size-bounded dictionary with FIFO replacement strategy"""

    def __init__(self, max_size=0):
        dict.__init__(self)
        self.__max_size = max_size
        self.__key_fifo = deque()
        self.__lock = Lock()

    def __setitem__(self, name, value):
        with self.__lock:
            assert len(self) == len(self.__key_fifo) # invariant

            if not self.__contains__(name):
                self.__key_fifo.append(name)

            rc = dict.__setitem__(self, name, value)

            while len(self.__key_fifo) > self.__max_size:
                self.__delitem__(self.__key_fifo.popleft())

            assert len(self) == len(self.__key_fifo) # invariant

            return rc

    def setdefault(self, *_):
        raise NotImplemented("SizedDict has no setdefault() method")


class StorageFactory(object):
    __dict = weakref.WeakValueDictionary()
    __dict_nonweak = dict()
    __dict_lock = Lock()

    def __init__(self, repo, log, weak=True, git_bin='git',
                 git_fs_encoding=None):
        self.logger = log

        with StorageFactory.__dict_lock:
            try:
                i = StorageFactory.__dict[repo]
            except KeyError:
                i = Storage(repo, log, git_bin, git_fs_encoding)
                StorageFactory.__dict[repo] = i

                # create or remove additional reference depending on 'weak'
                # argument
                if weak:
                    try:
                        del StorageFactory.__dict_nonweak[repo]
                    except KeyError:
                        pass
                else:
                    StorageFactory.__dict_nonweak[repo] = i

        self.__inst = i
        self.__repo = repo

    def getInstance(self):
        is_weak = self.__repo not in StorageFactory.__dict_nonweak
        self.logger.debug("requested %sPyGIT.Storage instance %d for '%s'"
                          % (("","weak ")[is_weak], id(self.__inst),
                             self.__repo))
        return self.__inst


class Storage(object):
    """High-level wrapper around GitCore with in-memory caching"""

    __SREV_MIN = 4 # minimum short-rev length


    class RevCache(tuple):
        """RevCache(youngest_rev, oldest_rev, rev_dict, tag_set, srev_dict,
                    branch_dict)

        In Python 2.7 this class could be defined by:
            from collections import namedtuple
            RevCache = namedtuple('RevCache', 'youngest_rev oldest_rev '
                                              'rev_dict tag_set srev_dict '
                                              'branch_dict')
        This implementation is what that code generator would produce.
        """

        __slots__ = ()

        _fields = ('youngest_rev', 'oldest_rev', 'rev_dict', 'tag_set',
                   'srev_dict', 'branch_dict')

        def __new__(cls, youngest_rev, oldest_rev, rev_dict, tag_set,
                    srev_dict, branch_dict):
            return tuple.__new__(cls, (youngest_rev, oldest_rev, rev_dict,
                                 tag_set, srev_dict, branch_dict))

        @classmethod
        def _make(cls, iterable, new=tuple.__new__, len=len):
            """Make a new RevCache object from a sequence or iterable"""
            result = new(cls, iterable)
            if len(result) != 6:
                raise TypeError('Expected 6 arguments, got %d' % len(result))
            return result

        def __repr__(self):
            return 'RevCache(youngest_rev=%r, oldest_rev=%r, rev_dict=%r, ' \
                   'tag_set=%r, srev_dict=%r, branch_dict=%r)' % self

        def _asdict(t):
            """Return a new dict which maps field names to their values"""
            return {'youngest_rev': t[0], 'oldest_rev': t[1],
                    'rev_dict': t[2], 'tag_set': t[3], 'srev_dict': t[4],
                    'branch_dict': t[5]}

        def _replace(self, **kwds):
            """Return a new RevCache object replacing specified fields with
            new values
            """
            result = self._make(map(kwds.pop, ('youngest_rev', 'oldest_rev',
                'rev_dict', 'tag_set', 'srev_dict', 'branch_dict'), self))
            if kwds:
                raise ValueError("Got unexpected field names: %r"
                                 % kwds.keys())
            return result

        def __getnewargs__(self):
            return tuple(self)

        youngest_rev = property(itemgetter(0))
        oldest_rev = property(itemgetter(1))
        rev_dict = property(itemgetter(2))
        tag_set = property(itemgetter(3))
        srev_dict = property(itemgetter(4))
        branch_dict = property(itemgetter(5))


    @staticmethod
    def __rev_key(rev):
        assert len(rev) >= 4
        #assert GitCore.is_sha(rev)
        srev_key = int(rev[:4], 16)
        assert srev_key >= 0 and srev_key <= 0xffff
        return srev_key

    @staticmethod
    def git_version(git_bin='git'):
        GIT_VERSION_MIN_REQUIRED = (1, 5, 6)
        try:
            g = GitCore(git_bin=git_bin)
            [v] = g.version().splitlines()
            version = v.strip().split()[2]
            # 'version' has usually at least 3 numeric version
            # components, e.g.::
            #  1.5.4.2
            #  1.5.4.3.230.g2db511
            #  1.5.4.GIT

            def try_int(s):
                try:
                    return int(s)
                except ValueError:
                    return s

            split_version = tuple(map(try_int, version.split('.')))

            result = {}
            result['v_str'] = version
            result['v_tuple'] = split_version
            result['v_min_tuple'] = GIT_VERSION_MIN_REQUIRED
            result['v_min_str'] = ".".join(map(str, GIT_VERSION_MIN_REQUIRED))
            result['v_compatible'] = split_version >= GIT_VERSION_MIN_REQUIRED
            return result

        except Exception, e:
            raise GitError("Could not retrieve GIT version (tried to "
                           "execute/parse '%s --version' but got %s)"
                           % (git_bin, repr(e)))

    def __init__(self, git_dir, log, git_bin='git', git_fs_encoding=None):
        """Initialize PyGit.Storage instance

        `git_dir`: path to .git folder;
                this setting is not affected by the `git_fs_encoding` setting

        `log`: logger instance

        `git_bin`: path to executable
                this setting is not affected by the `git_fs_encoding` setting

        `git_fs_encoding`: encoding used for paths stored in git repository;
                if `None`, no implicit decoding/encoding to/from
                unicode objects is performed, and bytestrings are
                returned instead
        """

        self.logger = log

        self.commit_encoding = None

        # caches
        self.__rev_cache = None
        self.__rev_cache_lock = Lock()

        # cache the last 200 commit messages
        self.__commit_msg_cache = SizedDict(200)
        self.__commit_msg_lock = Lock()

        self.__cat_file_pipe = None
        self.__cat_file_pipe_lock = Lock()

        if git_fs_encoding is not None:
            # validate encoding name
            codecs.lookup(git_fs_encoding)

            # setup conversion functions
            self._fs_to_unicode = lambda s: s.decode(git_fs_encoding)
            self._fs_from_unicode = lambda s: s.encode(git_fs_encoding)
        else:
            # pass bytestrings as-is w/o any conversion
            self._fs_to_unicode = self._fs_from_unicode = lambda s: s

        # simple sanity checking
        __git_file_path = partial(os.path.join, git_dir)
        if not all(map(os.path.exists,
                       map(__git_file_path,
                           ['HEAD','objects','refs']))):
            self.logger.error("GIT control files missing in '%s'" % git_dir)
            if os.path.exists(__git_file_path('.git')):
                self.logger.error("entry '.git' found in '%s'"
                                  " -- maybe use that folder instead..."
                                  % git_dir)
            raise GitError("GIT control files not found, maybe wrong "
                           "directory?")

        self.repo = GitCore(git_dir, git_bin=git_bin)

        self.logger.debug("PyGIT.Storage instance %d constructed" % id(self))

    def __del__(self):
        with self.__cat_file_pipe_lock:
            if self.__cat_file_pipe is not None:
                self.__cat_file_pipe.stdin.close()
                terminate(self.__cat_file_pipe)
                self.__cat_file_pipe.wait()

    #
    # cache handling
    #

    # called by Storage.sync()
    def __rev_cache_sync(self, youngest_rev=None):
        """invalidates revision db cache if necessary"""

        with self.__rev_cache_lock:
            need_update = False
            if self.__rev_cache:
                last_youngest_rev = self.__rev_cache.youngest_rev
                if last_youngest_rev != youngest_rev:
                    self.logger.debug("invalidated caches (%s != %s)"
                                      % (last_youngest_rev, youngest_rev))
                    need_update = True
            else:
                need_update = True # almost NOOP

            if need_update:
                self.__rev_cache = None

            return need_update

    def get_rev_cache(self):
        """Retrieve revision cache

        may rebuild cache on the fly if required

        returns RevCache tuple
        """

        with self.__rev_cache_lock:
            if self.__rev_cache is None:
                # can be cleared by Storage.__rev_cache_sync()
                self.logger.debug("triggered rebuild of commit tree db "
                                  "for %d" % id(self))
                ts0 = time.time()

                youngest = None
                oldest = None
                new_db = {} # db
                new_sdb = {} # short_rev db

                # helper for reusing strings
                __rev_seen = {}
                def __rev_reuse(rev):
                    rev = str(rev)
                    return __rev_seen.setdefault(rev, rev)

                new_tags = set(__rev_reuse(rev.strip())
                               for rev in self.repo.rev_parse('--tags')
                                                   .splitlines())

                new_branches = [(k, __rev_reuse(v))
                                for k, v in self._get_branches()]
                head_revs = set(v for _, v in new_branches)

                rev = ord_rev = 0
                for ord_rev, revs in enumerate(
                                        self.repo.rev_list('--parents',
                                                           '--topo-order',
                                                           '--all')
                                                 .splitlines()):
                    revs = map(__rev_reuse, revs.strip().split())

                    rev = revs[0]

                    # first rev seen is assumed to be the youngest one
                    if not ord_rev:
                        youngest = rev

                    # shortrev "hash" map
                    srev_key = self.__rev_key(rev)
                    new_sdb.setdefault(srev_key, []).append(rev)

                    # parents
                    parents = tuple(revs[1:])

                    # new_db[rev] = (children(rev), parents(rev),
                    #                ordinal_id(rev), rheads(rev))
                    if rev in new_db:
                        # (incomplete) entry was already created by children
                        _children, _parents, _ord_rev, _rheads = new_db[rev]
                        assert _children
                        assert not _parents
                        assert _ord_rev == 0

                        if rev in head_revs and rev not in _rheads:
                            _rheads.append(rev)

                    else: # new entry
                        _children = []
                        _rheads = [rev] if rev in head_revs else []

                    # create/update entry
                    # transform lists into tuples since entry will be final
                    new_db[rev] = tuple(_children), tuple(parents), \
                                  ord_rev + 1, tuple(_rheads)

                    # update parents(rev)s
                    for parent in parents:
                        # by default, a dummy ordinal_id is used
                        # for the mean-time
                        _children, _parents, _ord_rev, _rheads2 = \
                            new_db.setdefault(parent, ([], [], 0, []))

                        # update parent(rev)'s children
                        if rev not in _children:
                            _children.append(rev)

                        # update parent(rev)'s rheads
                        for rev in _rheads:
                            if rev not in _rheads2:
                                _rheads2.append(rev)

                # last rev seen is assumed to be the oldest
                # one (with highest ord_rev)
                oldest = rev

                __rev_seen = None

                # convert sdb either to dict or array depending on size
                tmp = [()]*(max(new_sdb.keys())+1) \
                      if len(new_sdb) > 5000 else {}

                try:
                    while True:
                        k, v = new_sdb.popitem()
                        tmp[k] = tuple(v)
                except KeyError:
                    pass

                assert len(new_sdb) == 0
                new_sdb = tmp

                # atomically update self.__rev_cache
                self.__rev_cache = Storage.RevCache(youngest, oldest, new_db,
                                                    new_tags, new_sdb,
                                                    new_branches)
                ts1 = time.time()
                self.logger.debug("rebuilt commit tree db for %d with %d "
                                  "entries (took %.1f ms)"
                                  % (id(self), len(new_db), 1000*(ts1-ts0)))

            assert all(e is not None for e in self.__rev_cache) \
                   or not any(self.__rev_cache)

            return self.__rev_cache
        # with self.__rev_cache_lock

    # see RevCache namedtuple
    rev_cache = property(get_rev_cache)

    def _get_branches(self):
        """returns list of (local) branches, with active (= HEAD) one being
        the first item
        """

        result = []
        for e in self.repo.branch('-v', '--no-abbrev').splitlines():
            bname, bsha = e[1:].strip().split()[:2]
            if e.startswith('*'):
                result.insert(0, (bname, bsha))
            else:
                result.append((bname, bsha))

        return result

    def get_branches(self):
        """returns list of (local) branches, with active (= HEAD) one being
        the first item
        """
        return ((self._fs_to_unicode(name), sha)
                for name, sha in self.rev_cache.branch_dict)

    def get_commits(self):
        return self.rev_cache.rev_dict

    def oldest_rev(self):
        return self.rev_cache.oldest_rev

    def youngest_rev(self):
        return self.rev_cache.youngest_rev

    def get_branch_contains(self, sha, resolve=False):
        """return list of reachable head sha ids or (names, sha) pairs if
        resolve is true

        see also get_branches()
        """

        _rev_cache = self.rev_cache

        try:
            rheads = _rev_cache.rev_dict[sha][3]
        except KeyError:
            return []

        if resolve:
            return ((self._fs_to_unicode(k), v)
                    for k, v in _rev_cache.branch_dict if v in rheads)

        return rheads

    def history_relative_rev(self, sha, rel_pos):
        db = self.get_commits()

        if sha not in db:
            raise GitErrorSha()

        if rel_pos == 0:
            return sha

        lin_rev = db[sha][2] + rel_pos

        if lin_rev < 1 or lin_rev > len(db):
            return None

        for k, v in db.iteritems():
            if v[2] == lin_rev:
                return k

        # should never be reached if db is consistent
        raise GitError("internal inconsistency detected")

    def hist_next_revision(self, sha):
        return self.history_relative_rev(sha, -1)

    def hist_prev_revision(self, sha):
        return self.history_relative_rev(sha, +1)

    def get_commit_encoding(self):
        if self.commit_encoding is None:
            self.commit_encoding = \
                self.repo.repo_config("--get", "i18n.commitEncoding") \
                    .strip() or 'utf-8'

        return self.commit_encoding

    def head(self):
        """get current HEAD commit id"""
        return self.verifyrev('HEAD')

    def cat_file(self, kind, sha):
        with self.__cat_file_pipe_lock:
            if self.__cat_file_pipe is None:
                self.__cat_file_pipe = self.repo.cat_file_batch()

            try:
                self.__cat_file_pipe.stdin.write(sha + '\n')
                self.__cat_file_pipe.stdin.flush()

                split_stdout_line = self.__cat_file_pipe.stdout.readline() \
                                                               .split()
                if len(split_stdout_line) != 3:
                    raise GitError("internal error (could not split line "
                                   "'%s')" % (split_stdout_line,))

                _sha, _type, _size = split_stdout_line

                if _type != kind:
                    raise GitError("internal error (got unexpected object "
                                   "kind '%s', expected '%s')"
                                   % (_type, kind))

                size = int(_size)
                return self.__cat_file_pipe.stdout.read(size + 1)[:size]
            except:
                # There was an error, we should close the pipe to get to a
                # consistent state (Otherwise it happens that next time we
                # call cat_file we get payload from previous call)
                self.logger.debug("closing cat_file pipe")
                self.__cat_file_pipe.stdin.close()
                terminate(self.__cat_file_pipe)
                self.__cat_file_pipe.wait()
                self.__cat_file_pipe = None

    def verifyrev(self, rev):
        """verify/lookup given revision object and return a sha id or None
        if lookup failed
        """
        rev = self._fs_from_unicode(rev)

        _rev_cache = self.rev_cache

        if GitCore.is_sha(rev):
            # maybe it's a short or full rev
            fullrev = self.fullrev(rev)
            if fullrev:
                return fullrev

        # fall back to external git calls
        rc = self.repo.rev_parse('--verify', rev).strip()
        if not rc:
            return None

        if rc in _rev_cache.rev_dict:
            return rc

        if rc in _rev_cache.tag_set:
            sha = self.cat_file('tag', rc).split(None, 2)[:2]
            if sha[0] != 'object':
                self.logger.debug("unexpected result from 'git-cat-file tag "
                                  "%s'" % rc)
                return None
            return sha[1]

        return None

    def shortrev(self, rev, min_len=7):
        """try to shorten sha id"""
        #try to emulate the following:
        #return self.repo.rev_parse("--short", str(rev)).strip()
        rev = str(rev)

        if min_len < self.__SREV_MIN:
            min_len = self.__SREV_MIN

        _rev_cache = self.rev_cache

        if rev not in _rev_cache.rev_dict:
            return None

        srev = rev[:min_len]
        srevs = set(_rev_cache.srev_dict[self.__rev_key(rev)])

        if len(srevs) == 1:
            return srev # we already got a unique id

        # find a shortened id for which rev doesn't conflict with
        # the other ones from srevs
        crevs = srevs - set([rev])

        for l in range(min_len+1, 40):
            srev = rev[:l]
            if srev not in [ r[:l] for r in crevs ]:
                return srev

        return rev # worst-case, all except the last character match

    def fullrev(self, srev):
        """try to reverse shortrev()"""
        srev = str(srev)

        _rev_cache = self.rev_cache

        # short-cut
        if len(srev) == 40 and srev in _rev_cache.rev_dict:
            return srev

        if not GitCore.is_sha(srev):
            return None

        try:
            srevs = _rev_cache.srev_dict[self.__rev_key(srev)]
        except KeyError:
            return None

        srevs = filter(lambda s: s.startswith(srev), srevs)
        if len(srevs) == 1:
            return srevs[0]

        return None

    def get_tags(self):
        return (self._fs_to_unicode(e.strip())
                for e in self.repo.tag('-l').splitlines())

    def ls_tree(self, rev, path=''):
        rev = rev and str(rev) or 'HEAD' # paranoia

        path = self._fs_from_unicode(path)

        if path.startswith('/'):
            path = path[1:]

        tree = self.repo.ls_tree('-z', '-l', rev, '--', path).split('\0')

        def split_ls_tree_line(l):
            """split according to '<mode> <type> <sha> <size>\t<fname>'"""

            meta, fname = l.split('\t', 1)
            _mode, _type, _sha, _size = meta.split()

            if _size == '-':
                _size = None
            else:
                _size = int(_size)

            return _mode, _type, _sha, _size, self._fs_to_unicode(fname)

        return [ split_ls_tree_line(e) for e in tree if e ]

    def read_commit(self, commit_id):
        if not commit_id:
            raise GitError("read_commit called with empty commit_id")

        commit_id, commit_id_orig = self.fullrev(commit_id), commit_id

        db = self.get_commits()
        if commit_id not in db:
            self.logger.info("read_commit failed for '%s' ('%s')" %
                             (commit_id, commit_id_orig))
            raise GitErrorSha

        with self.__commit_msg_lock:
            if self.__commit_msg_cache.has_key(commit_id):
                # cache hit
                result = self.__commit_msg_cache[commit_id]
                return result[0], dict(result[1])

            # cache miss
            raw = self.cat_file('commit', commit_id)
            raw = unicode(raw, self.get_commit_encoding(), 'replace')
            result = parse_commit(raw)

            self.__commit_msg_cache[commit_id] = result

            return result[0], dict(result[1])

    def get_file(self, sha):
        return cStringIO.StringIO(self.cat_file('blob', str(sha)))

    def get_obj_size(self, sha):
        sha = str(sha)

        try:
            obj_size = int(self.repo.cat_file('-s', sha).strip())
        except ValueError:
            raise GitErrorSha("object '%s' not found" % sha)

        return obj_size

    def children(self, sha):
        db = self.get_commits()

        try:
            return list(db[sha][0])
        except KeyError:
            return []

    def children_recursive(self, sha, rev_dict=None):
        """Recursively traverse children in breadth-first order"""

        if rev_dict is None:
            rev_dict = self.get_commits()

        work_list = deque()
        seen = set()

        seen.update(rev_dict[sha][0])
        work_list.extend(rev_dict[sha][0])

        while work_list:
            p = work_list.popleft()
            yield p

            _children = set(rev_dict[p][0]) - seen

            seen.update(_children)
            work_list.extend(_children)

        assert len(work_list) == 0

    def parents(self, sha):
        db = self.get_commits()

        try:
            return list(db[sha][1])
        except KeyError:
            return []

    def all_revs(self):
        return self.get_commits().iterkeys()

    def sync(self):
        rev = self.repo.rev_list('--max-count=1', '--topo-order', '--all') \
                       .strip()
        return self.__rev_cache_sync(rev)

    @contextmanager
    def get_historian(self, sha, base_path):
        p = []
        change = {}
        next_path = []

        def name_status_gen():
            p[:] = [self.repo.log_pipe('--pretty=format:%n%H',
                                       '--name-status', sha, '--', base_path)]
            f = p[0].stdout
            for l in f:
                if l == '\n':
                    continue
                old_sha = l.rstrip('\n')
                for l in f:
                    if l == '\n':
                        break
                    _, path = l.rstrip('\n').split('\t', 1)
                    while path not in change:
                        change[path] = old_sha
                        if next_path == [path]:
                            yield old_sha
                        try:
                            path, _ = path.rsplit('/', 1)
                        except ValueError:
                            break
            f.close()
            terminate(p[0])
            p[0].wait()
            p[:] = []
            while True:
                yield None
        gen = name_status_gen()

        def historian(path):
            try:
                return change[path]
            except KeyError:
                next_path[:] = [path]
                return gen.next()
        yield historian

        if p:
            p[0].stdout.close()
            terminate(p[0])
            p[0].wait()

    def last_change(self, sha, path, historian=None):
        if historian is not None:
            return historian(path)
        return self.repo.rev_list('--max-count=1',
                                  sha, '--',
                                  self._fs_from_unicode(path)).strip() or None

    def history(self, sha, path, limit=None):
        if limit is None:
            limit = -1

        tmp = self.repo.rev_list('--max-count=%d' % limit, str(sha), '--',
                                 self._fs_from_unicode(path))

        return [ rev.strip() for rev in tmp.splitlines() ]

    def history_timerange(self, start, stop):
        return [ rev.strip() for rev in \
                     self.repo.rev_list('--reverse',
                                        '--max-age=%d' % start,
                                        '--min-age=%d' % stop,
                                        '--all').splitlines() ]

    def rev_is_anchestor_of(self, rev1, rev2):
        """return True if rev2 is successor of rev1"""

        rev1 = rev1.strip()
        rev2 = rev2.strip()

        rev_dict = self.get_commits()

        return (rev2 in rev_dict and
                rev2 in self.children_recursive(rev1, rev_dict))

    def blame(self, commit_sha, path):
        in_metadata = False

        path = self._fs_from_unicode(path)

        for line in self.repo.blame('-p', '--', path, str(commit_sha)) \
                             .splitlines():
            assert line
            if in_metadata:
                in_metadata = not line.startswith('\t')
            else:
                split_line = line.split()
                if len(split_line) == 4:
                    (sha, orig_lineno, lineno, group_size) = split_line
                else:
                    (sha, orig_lineno, lineno) = split_line

                assert len(sha) == 40
                yield (sha, lineno)
                in_metadata = True

        assert not in_metadata

    def diff_tree(self, tree1, tree2, path='', find_renames=False):
        """calls `git diff-tree` and returns tuples of the kind
        (mode1,mode2,obj1,obj2,action,path1,path2)"""

        # diff-tree returns records with the following structure:
        # :<old-mode> <new-mode> <old-sha> <new-sha> <change> NUL <old-path> NUL [ <new-path> NUL ]

        path = self._fs_from_unicode(path).strip('/')
        diff_tree_args = ['-z', '-r']
        if find_renames:
            diff_tree_args.append('-M')
        diff_tree_args.extend([str(tree1) if tree1 else '--root',
                               str(tree2),
                               '--', path])

        lines = self.repo.diff_tree(*diff_tree_args).split('\0')

        assert lines[-1] == ''
        del lines[-1]

        if tree1 is None and lines:
            # if only one tree-sha is given on commandline,
            # the first line is just the redundant tree-sha itself...
            assert not lines[0].startswith(':')
            del lines[0]

        # FIXME: the following code is ugly, needs rewrite

        chg = None

        def __chg_tuple():
            if len(chg) == 6:
                chg.append(None)
            else:
                chg[6] = self._fs_to_unicode(chg[6])
            chg[5] = self._fs_to_unicode(chg[5])

            assert len(chg) == 7
            return tuple(chg)

        for line in lines:
            if line.startswith(':'):
                if chg:
                    yield __chg_tuple()

                chg = line[1:].split()
                assert len(chg) == 5
            else:
                chg.append(line)

        # handle left-over chg entry
        if chg:
            yield __chg_tuple()

########NEW FILE########
__FILENAME__ = PyGIT
# -*- coding: utf-8 -*-
#
# Copyright (C) 2012 Edgewall Software
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.

import os
import shutil
import tempfile
import unittest
from subprocess import Popen, PIPE

from trac.test import locate, EnvironmentStub
from trac.util import create_file
from trac.util.compat import close_fds
from tracopt.versioncontrol.git.PyGIT import GitCore, Storage, parse_commit


class GitTestCase(unittest.TestCase):

    def test_is_sha(self):
        self.assertTrue(not GitCore.is_sha('123'))
        self.assertTrue(GitCore.is_sha('1a3f'))
        self.assertTrue(GitCore.is_sha('f' * 40))
        self.assertTrue(not GitCore.is_sha('x' + 'f' * 39))
        self.assertTrue(not GitCore.is_sha('f' * 41))

    def test_git_version(self):
        v = Storage.git_version()
        self.assertTrue(v)
        self.assertTrue(v['v_compatible'])


class TestParseCommit(unittest.TestCase):
    # The ''' ''' lines are intended to keep lines with trailing whitespace
    commit2240a7b = '''\
tree b19535236cfb6c64b798745dd3917dafc27bcd0a
parent 30aaca4582eac20a52ac7b2ec35bdb908133e5b1
parent 5a0dc7365c240795bf190766eba7a27600be3b3e
author Linus Torvalds <torvalds@linux-foundation.org> 1323915958 -0800
committer Linus Torvalds <torvalds@linux-foundation.org> 1323915958 -0800
mergetag object 5a0dc7365c240795bf190766eba7a27600be3b3e
 type commit
 tag tytso-for-linus-20111214A
 tagger Theodore Ts'o <tytso@mit.edu> 1323890113 -0500
 ''' '''
 tytso-for-linus-20111214
 -----BEGIN PGP SIGNATURE-----
 Version: GnuPG v1.4.10 (GNU/Linux)
 ''' '''
 iQIcBAABCAAGBQJO6PXBAAoJENNvdpvBGATwpuEP/2RCxmdWYZ8/6Z6pmTh3hHN5
 fx6HckTdvLQOvbQs72wzVW0JKyc25QmW2mQc5z3MjSymjf/RbEKihPUITRNbHrTD
 T2sP/lWu09AKLioEg4ucAKn/A7Do3UDIkXTszvVVP/t2psVPzLeJ1njQKra14Nyz
 o0+gSlnwuGx9WaxfR+7MYNs2ikdSkXIeYsiFAOY4YOxwwC99J/lZ0YaNkbI7UBtC
 yu2XLIvPboa5JZXANq2G3VhVIETMmOyRTCC76OAXjqkdp9nLFWDG0ydqQh0vVZwL
 xQGOmAj+l3BNTE0QmMni1w7A0SBU3N6xBA5HN6Y49RlbsMYG27aN54Fy5K2R41I3
 QXVhBL53VD6b0KaITcoz7jIGIy6qk9Wx+2WcCYtQBSIjL2YwlaJq0PL07+vRamex
 sqHGDejcNY87i6AV0DP6SNuCFCi9xFYoAoMi9Wu5E9+T+Vck0okFzW/luk/FvsSP
 YA5Dh+vISyBeCnWQvcnBmsUQyf8d9MaNnejZ48ath+GiiMfY8USAZ29RAG4VuRtS
 9DAyTTIBA73dKpnvEV9u4i8Lwd8hRVMOnPyOO785NwEXk3Ng08pPSSbMklW6UfCY
 4nr5UNB13ZPbXx4uoAvATMpCpYxMaLEdxmeMvgXpkekl0hHBzpVDey1Vu9fb/a5n
 dQpo6WWG9HIJ23hOGAGR
 =n3Lm
 -----END PGP SIGNATURE-----

Merge tag 'tytso-for-linus-20111214' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4

* tag 'tytso-for-linus-20111214' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4:
  ext4: handle EOF correctly in ext4_bio_write_page()
  ext4: remove a wrong BUG_ON in ext4_ext_convert_to_initialized
  ext4: correctly handle pages w/o buffers in ext4_discard_partial_buffers()
  ext4: avoid potential hang in mpage_submit_io() when blocksize < pagesize
  ext4: avoid hangs in ext4_da_should_update_i_disksize()
  ext4: display the correct mount option in /proc/mounts for [no]init_itable
  ext4: Fix crash due to getting bogus eh_depth value on big-endian systems
  ext4: fix ext4_end_io_dio() racing against fsync()

.. using the new signed tag merge of git that now verifies the gpg
signature automatically.  Yay.  The branchname was just 'dev', which is
prettier.  I'll tell Ted to use nicer tag names for future cases.
'''

    def test_parse(self):
        msg, props = parse_commit(self.commit2240a7b)
        self.assertTrue(msg)
        self.assertTrue(props)
        self.assertEquals(
            ['30aaca4582eac20a52ac7b2ec35bdb908133e5b1',
             '5a0dc7365c240795bf190766eba7a27600be3b3e'],
            props['parent'])
        self.assertEquals(
            ['Linus Torvalds <torvalds@linux-foundation.org> 1323915958 -0800'],
            props['author'])
        self.assertEquals(props['author'], props['committer'])

        # Merge tag
        self.assertEquals(['''\
object 5a0dc7365c240795bf190766eba7a27600be3b3e
type commit
tag tytso-for-linus-20111214A
tagger Theodore Ts\'o <tytso@mit.edu> 1323890113 -0500

tytso-for-linus-20111214
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.10 (GNU/Linux)

iQIcBAABCAAGBQJO6PXBAAoJENNvdpvBGATwpuEP/2RCxmdWYZ8/6Z6pmTh3hHN5
fx6HckTdvLQOvbQs72wzVW0JKyc25QmW2mQc5z3MjSymjf/RbEKihPUITRNbHrTD
T2sP/lWu09AKLioEg4ucAKn/A7Do3UDIkXTszvVVP/t2psVPzLeJ1njQKra14Nyz
o0+gSlnwuGx9WaxfR+7MYNs2ikdSkXIeYsiFAOY4YOxwwC99J/lZ0YaNkbI7UBtC
yu2XLIvPboa5JZXANq2G3VhVIETMmOyRTCC76OAXjqkdp9nLFWDG0ydqQh0vVZwL
xQGOmAj+l3BNTE0QmMni1w7A0SBU3N6xBA5HN6Y49RlbsMYG27aN54Fy5K2R41I3
QXVhBL53VD6b0KaITcoz7jIGIy6qk9Wx+2WcCYtQBSIjL2YwlaJq0PL07+vRamex
sqHGDejcNY87i6AV0DP6SNuCFCi9xFYoAoMi9Wu5E9+T+Vck0okFzW/luk/FvsSP
YA5Dh+vISyBeCnWQvcnBmsUQyf8d9MaNnejZ48ath+GiiMfY8USAZ29RAG4VuRtS
9DAyTTIBA73dKpnvEV9u4i8Lwd8hRVMOnPyOO785NwEXk3Ng08pPSSbMklW6UfCY
4nr5UNB13ZPbXx4uoAvATMpCpYxMaLEdxmeMvgXpkekl0hHBzpVDey1Vu9fb/a5n
dQpo6WWG9HIJ23hOGAGR
=n3Lm
-----END PGP SIGNATURE-----'''], props['mergetag'])

        # Message
        self.assertEquals("""Merge tag 'tytso-for-linus-20111214' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4

* tag 'tytso-for-linus-20111214' of git://git.kernel.org/pub/scm/linux/kernel/git/tytso/ext4:
  ext4: handle EOF correctly in ext4_bio_write_page()
  ext4: remove a wrong BUG_ON in ext4_ext_convert_to_initialized
  ext4: correctly handle pages w/o buffers in ext4_discard_partial_buffers()
  ext4: avoid potential hang in mpage_submit_io() when blocksize < pagesize
  ext4: avoid hangs in ext4_da_should_update_i_disksize()
  ext4: display the correct mount option in /proc/mounts for [no]init_itable
  ext4: Fix crash due to getting bogus eh_depth value on big-endian systems
  ext4: fix ext4_end_io_dio() racing against fsync()

.. using the new signed tag merge of git that now verifies the gpg
signature automatically.  Yay.  The branchname was just 'dev', which is
prettier.  I'll tell Ted to use nicer tag names for future cases.""", msg)


class UnicodeNameTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        self.repos_path = tempfile.mkdtemp(prefix='trac-gitrepos')
        self.git_bin = locate('git')
        # create git repository and master branch
        self._git('init', self.repos_path)
        create_file(os.path.join(self.repos_path, '.gitignore'))
        self._git('add', '.gitignore')
        self._git('commit', '-a', '-m', 'test')

    def tearDown(self):
        if os.path.isdir(self.repos_path):
            shutil.rmtree(self.repos_path)

    def _git(self, *args):
        args = [self.git_bin] + list(args)
        proc = Popen(args, stdout=PIPE, stderr=PIPE, close_fds=close_fds,
                     cwd=self.repos_path)
        proc.wait()
        assert proc.returncode == 0
        return proc

    def _storage(self):
        path = os.path.join(self.repos_path, '.git')
        return Storage(path, self.env.log, self.git_bin, 'utf-8')

    def test_unicode_verifyrev(self):
        storage = self._storage()
        self.assertNotEqual(None, storage.verifyrev(u'master'))
        self.assertEquals(None, storage.verifyrev(u'tt'))

    def test_unicode_filename(self):
        create_file(os.path.join(self.repos_path, 'tickt.txt'))
        self._git('add', 'tickt.txt')
        self._git('commit', '-m', 'unicode-filename')
        storage = self._storage()
        filenames = sorted(fname for mode, type, sha, size, fname
                                 in storage.ls_tree('HEAD'))
        self.assertEquals(unicode, type(filenames[0]))
        self.assertEquals(unicode, type(filenames[1]))
        self.assertEquals(u'.gitignore', filenames[0])
        self.assertEquals(u'tickt.txt', filenames[1])

    def test_unicode_branches(self):
        self._git('checkout', '-b', 'tickt10980', 'master')
        storage = self._storage()
        branches = sorted(storage.get_branches())
        self.assertEquals(unicode, type(branches[0][0]))
        self.assertEquals(unicode, type(branches[1][0]))
        self.assertEquals(u'master', branches[0][0])
        self.assertEquals(u'tickt10980', branches[1][0])

        contains = sorted(storage.get_branch_contains(branches[1][1],
                                                      resolve=True))
        self.assertEquals(unicode, type(contains[0][0]))
        self.assertEquals(unicode, type(contains[1][0]))
        self.assertEquals(u'master', contains[0][0])
        self.assertEquals(u'tickt10980', contains[1][0])

    def test_unicode_tags(self):
        self._git('tag', 'tg-t10980', 'master')
        storage = self._storage()
        tags = tuple(storage.get_tags())
        self.assertEquals(unicode, type(tags[0]))
        self.assertEquals(u'tg-t10980', tags[0])
        self.assertNotEqual(None, storage.verifyrev(u'tg-t10980'))


#class GitPerformanceTestCase(unittest.TestCase):
#    """Performance test. Not really a unit test.
#    Not self-contained: Needs a git repository and prints performance result
#    instead of testing anything.
#    TODO: Move to a profiling script?"""
#
#    def test_performance(self):
#        import logging
#        import timeit
#
#        g = Storage(path_to_repo, logging) # Need a git repository path here
#        revs = g.get_commits().keys()
#
#        def shortrev_test():
#            for i in revs:
#                i = str(i)
#                s = g.shortrev(i, min_len=4)
#                self.assertTrue(i.startswith(s))
#                self.assertEquals(g.fullrev(s), i)
#
#        iters = 1
#        t = timeit.Timer("shortrev_test()",
#                         "from __main__ import shortrev_test")
#        usec_per_rev = (1000000 * t.timeit(number=iters)/len(revs))
#        print "%.2f usec/rev" % usec_per_rev # Print instead of testing

#class GitMemoryUsageTestCase(unittest.TestCase):
#    """Memory test. Not really a unit test.
#    Not self-contained: Needs a git repository and prints memory usage
#    instead of testing anything.
#    TODO: Move to a profiling script?"""
#
#    def test_memory_usage(self):
#        import logging
#        import sys
#
#        # custom linux hack reading `/proc/<PID>/statm`
#        if sys.platform == 'linux2':
#            __pagesize = os.sysconf('SC_PAGESIZE')
#
#            def proc_statm(pid = os.getpid()):
#                __proc_statm = '/proc/%d/statm' % pid
#                try:
#                    t = open(__proc_statm)
#                    result = t.read().split()
#                    t.close()
#                    assert len(result) == 7
#                    return tuple([ __pagesize*int(p) for p in result ])
#                except:
#                    raise RuntimeError("failed to get memory stats")
#
#        else: # not linux2
#            print "WARNING - meminfo.proc_statm() not available"
#            def proc_statm():
#                return (0,)*7
#
#        print "statm =", proc_statm()
#        __data_size = proc_statm()[5]
#        __data_size_last = [__data_size]
#
#        def print_data_usage():
#            __tmp = proc_statm()[5]
#            print "DATA: %6d %+6d" % (__tmp - __data_size,
#                                    __tmp - __data_size_last[0])
#            __data_size_last[0] = __tmp
#
#        print_data_usage()
#
#        g = Storage(path_to_repo, logging) # Need a git repository path here
#
#        print_data_usage()
#
#        print "[%s]" % g.head()
#        print g.ls_tree(g.head())
#        print "--------------"
#        print_data_usage()
#        print g.read_commit(g.head())
#        print "--------------"
#        print_data_usage()
#        p = g.parents(g.head())
#        print list(p)
#        print "--------------"
#        print list(g.children(list(p)[0]))
#        print list(g.children(list(p)[0]))
#        print "--------------"
#        print g.get_commit_encoding()
#        print "--------------"
#        print g.get_branches()
#        print "--------------"
#        print g.hist_prev_revision(g.oldest_rev()), g.oldest_rev(), \
#                                g.hist_next_revision(g.oldest_rev())
#        print_data_usage()
#        print "--------------"
#        p = g.youngest_rev()
#        print g.hist_prev_revision(p), p, g.hist_next_revision(p)
#        print "--------------"
#
#        p = g.head()
#        for i in range(-5, 5):
#            print i, g.history_relative_rev(p, i)
#
#        # check for loops
#        def check4loops(head):
#            print "check4loops", head
#            seen = set([head])
#            for _sha in g.children_recursive(head):
#                if _sha in seen:
#                    print "dupe detected :-/", _sha, len(seen)
#                seen.add(_sha)
#            return seen
#
#        print len(check4loops(g.parents(g.head())[0]))
#
#        #p = g.head()
#        #revs = [ g.history_relative_rev(p, i) for i in range(0,10) ]
#        print_data_usage()
#        revs = g.get_commits().keys()
#        print_data_usage()
#
#        #print len(check4loops(g.oldest_rev()))
#        #print len(list(g.children_recursive(g.oldest_rev())))
#
#        print_data_usage()
#
#        # perform typical trac operations:
#
#        if 1:
#            print "--------------"
#            rev = g.head()
#            for mode, _type, sha, _size, name in g.ls_tree(rev):
#                [last_rev] = g.history(rev, name, limit=1)
#                s = g.get_obj_size(sha) if _type == 'blob' else 0
#                msg = g.read_commit(last_rev)
#
#                print "%s %s %10d [%s]" % (_type, last_rev, s, name)
#
#        print "allocating 2nd instance"
#        print_data_usage()
#        g2 = Storage(path_to_repo, logging) # Need a git repository path here
#        g2.head()
#        print_data_usage()
#
#        print "allocating 3rd instance"
#        g3 = Storage(path_to_repo, logging) # Need a git repository path here
#        g3.head()
#        print_data_usage()


def suite():
    suite = unittest.TestSuite()
    git = locate("git")
    if git:
        suite.addTest(unittest.makeSuite(GitTestCase, 'test'))
        suite.addTest(unittest.makeSuite(TestParseCommit, 'test'))
        if os.name != 'nt':
            # Popen doesn't accept unicode path and arguments on Windows
            suite.addTest(unittest.makeSuite(UnicodeNameTestCase, 'test'))
    else:
        print("SKIP: tracopt/versioncontrol/git/tests/PyGIT.py (git cli "
              "binary, 'git', not found)")
    return suite


if __name__ == '__main__':
    unittest.main(defaultTest='suite')

########NEW FILE########
__FILENAME__ = svn_fs
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2011 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>
#         Christian Boos <cboos@edgewall.org>

"""

Note about Unicode
------------------

The Subversion bindings are not unicode-aware and they expect to
receive UTF-8 encoded `string` parameters,

On the other hand, all paths manipulated by Trac are `unicode`
objects.

Therefore:

 * before being handed out to SVN, the Trac paths have to be encoded
   to UTF-8, using `_to_svn()`

 * before being handed out to Trac, a SVN path has to be decoded from
   UTF-8, using `_from_svn()`

Whenever a value has to be stored as utf8, we explicitly mark the
variable name with "_utf8", in order to avoid any possible confusion.

Warning:
  `SubversionNode.get_content()` returns an object from which one can
  read a stream of bytes. NO guarantees can be given about what that
  stream of bytes represents. It might be some text, encoded in some
  way or another.  SVN properties *might* give some hints about the
  content, but they actually only reflect the beliefs of whomever set
  those properties...
"""

import os.path
import weakref
import posixpath

from trac.config import ListOption
from trac.core import *
from trac.env import ISystemInfoProvider
from trac.versioncontrol import Changeset, Node, Repository, \
                                IRepositoryConnector, \
                                NoSuchChangeset, NoSuchNode
from trac.versioncontrol.cache import CachedRepository
from trac.util import embedded_numbers
from trac.util.text import exception_to_unicode, to_unicode
from trac.util.translation import _
from trac.util.datefmt import from_utimestamp


application_pool = None


def _import_svn():
    global fs, repos, core, delta, _kindmap
    from svn import fs, repos, core, delta
    _kindmap = {core.svn_node_dir: Node.DIRECTORY,
                core.svn_node_file: Node.FILE}
    # Protect svn.core methods from GC
    Pool.apr_pool_clear = staticmethod(core.apr_pool_clear)
    Pool.apr_pool_destroy = staticmethod(core.apr_pool_destroy)

def _to_svn(pool, *args):
    """Expect a pool and a list of `unicode` path components.

    Returns an UTF-8 encoded string suitable for the Subversion python
    bindings (the returned path never starts with a leading "/")
    """
    return core.svn_path_canonicalize('/'.join(args).lstrip('/')
                                                    .encode('utf-8'),
                                      pool)

def _from_svn(path):
    """Expect an UTF-8 encoded string and transform it to an `unicode` object

    But Subversion repositories built from conversion utilities can have
    non-UTF-8 byte strings, so we have to convert using `to_unicode`.
    """
    return path and to_unicode(path, 'utf-8')

# The following 3 helpers deal with unicode paths

def _normalize_path(path):
    """Remove leading "/", except for the root."""
    return path and path.strip('/') or '/'

def _path_within_scope(scope, fullpath):
    """Remove the leading scope from repository paths.

    Return `None` if the path is not is scope.
    """
    if fullpath is not None:
        fullpath = fullpath.lstrip('/')
        if scope == '/':
            return _normalize_path(fullpath)
        scope = scope.strip('/')
        if (fullpath + '/').startswith(scope + '/'):
            return fullpath[len(scope) + 1:] or '/'

def _is_path_within_scope(scope, fullpath):
    """Check whether the given `fullpath` is within the given `scope`"""
    if scope == '/':
        return fullpath is not None
    fullpath = fullpath.lstrip('/') if fullpath else ''
    scope = scope.strip('/')
    return (fullpath + '/').startswith(scope + '/')

# svn_opt_revision_t helpers

def _svn_rev(num):
    value = core.svn_opt_revision_value_t()
    value.number = num
    revision = core.svn_opt_revision_t()
    revision.kind = core.svn_opt_revision_number
    revision.value = value
    return revision

def _svn_head():
    revision = core.svn_opt_revision_t()
    revision.kind = core.svn_opt_revision_head
    return revision

# apr_pool_t helpers

def _mark_weakpool_invalid(weakpool):
    if weakpool():
        weakpool()._mark_invalid()


class Pool(object):
    """A Pythonic memory pool object"""

    def __init__(self, parent_pool=None):
        """Create a new memory pool"""

        global application_pool
        self._parent_pool = parent_pool or application_pool

        # Create pool
        if self._parent_pool:
            self._pool = core.svn_pool_create(self._parent_pool())
        else:
            # If we are an application-level pool,
            # then initialize APR and set this pool
            # to be the application-level pool
            core.apr_initialize()
            application_pool = self

            self._pool = core.svn_pool_create(None)
        self._mark_valid()

    def __call__(self):
        return self._pool

    def valid(self):
        """Check whether this memory pool and its parents
        are still valid"""
        return hasattr(self,"_is_valid")

    def assert_valid(self):
        """Assert that this memory_pool is still valid."""
        assert self.valid()

    def clear(self):
        """Clear embedded memory pool. Invalidate all subpools."""
        self.apr_pool_clear(self._pool)
        self._mark_valid()

    def destroy(self):
        """Destroy embedded memory pool. If you do not destroy
        the memory pool manually, Python will destroy it
        automatically."""

        global application_pool

        self.assert_valid()

        # Destroy pool
        self.apr_pool_destroy(self._pool)

        # Clear application pool and terminate APR if necessary
        if not self._parent_pool:
            application_pool = None

        self._mark_invalid()

    def __del__(self):
        """Automatically destroy memory pools, if necessary"""
        if self.valid():
            self.destroy()

    def _mark_valid(self):
        """Mark pool as valid"""
        if self._parent_pool:
            # Refer to self using a weakreference so that we don't
            # create a reference cycle
            weakself = weakref.ref(self)

            # Set up callbacks to mark pool as invalid when parents
            # are destroyed
            self._weakref = weakref.ref(self._parent_pool._is_valid,
                                        lambda x: \
                                        _mark_weakpool_invalid(weakself))

        # mark pool as valid
        self._is_valid = lambda: 1

    def _mark_invalid(self):
        """Mark pool as invalid"""
        if self.valid():
            # Mark invalid
            del self._is_valid

            # Free up memory
            del self._parent_pool
            if hasattr(self, "_weakref"):
                del self._weakref


class SvnCachedRepository(CachedRepository):
    """Subversion-specific cached repository, zero-pads revision numbers
    in the cache tables.
    """
    has_linear_changesets = True

    def db_rev(self, rev):
        return '%010d' % rev

    def rev_db(self, rev):
        return int(rev or 0)


class SubversionConnector(Component):

    implements(ISystemInfoProvider, IRepositoryConnector)

    branches = ListOption('svn', 'branches', 'trunk, branches/*', doc=
        """Comma separated list of paths categorized as branches.
        If a path ends with '*', then all the directory entries found below
        that path will be included.
        Example: `/trunk, /branches/*, /projectAlpha/trunk, /sandbox/*`
        """)

    tags = ListOption('svn', 'tags', 'tags/*', doc=
        """Comma separated list of paths categorized as tags.

        If a path ends with '*', then all the directory entries found below
        that path will be included.
        Example: `/tags/*, /projectAlpha/tags/A-1.0, /projectAlpha/tags/A-v1.1`
        """)

    error = None

    def __init__(self):
        self._version = None
        try:
            _import_svn()
            self.log.debug('Subversion bindings imported')
        except ImportError, e:
            self.error = e
            self.log.info('Failed to load Subversion bindings', exc_info=True)
        else:
            version = (core.SVN_VER_MAJOR, core.SVN_VER_MINOR,
                       core.SVN_VER_MICRO)
            self._version = '%d.%d.%d' % version + core.SVN_VER_TAG
            if version[0] < 1:
                self.error = _("Subversion >= 1.0 required, found %(version)s",
                               version=self._version)
            Pool()

    # ISystemInfoProvider methods

    def get_system_info(self):
        if self._version is not None:
            yield 'Subversion', self._version

    # IRepositoryConnector methods

    def get_supported_types(self):
        prio = 1
        if self.error:
            prio = -1
        yield ("direct-svnfs", prio * 4)
        yield ("svnfs", prio * 4)
        yield ("svn", prio * 2)

    def get_repository(self, type, dir, params):
        """Return a `SubversionRepository`.

        The repository is wrapped in a `CachedRepository`, unless `type` is
        'direct-svnfs'.
        """
        params.update(tags=self.tags, branches=self.branches)
        repos = SubversionRepository(dir, params, self.log)
        if type != 'direct-svnfs':
            repos = SvnCachedRepository(self.env, repos, self.log)
        return repos


class SubversionRepository(Repository):
    """Repository implementation based on the svn.fs API."""

    has_linear_changesets = True

    def __init__(self, path, params, log):
        self.log = log
        self.pool = Pool()

        # Remove any trailing slash or else subversion might abort
        if isinstance(path, unicode):
            path_utf8 = path.encode('utf-8')
        else: # note that this should usually not happen (unicode arg expected)
            path_utf8 = to_unicode(path).encode('utf-8')

        path_utf8 = os.path.normpath(path_utf8).replace('\\', '/')
        self.path = path_utf8.decode('utf-8')

        root_path_utf8 = repos.svn_repos_find_root_path(path_utf8, self.pool())
        if root_path_utf8 is None:
            raise TracError(_("%(path)s does not appear to be a Subversion "
                              "repository.", path=to_unicode(path_utf8)))

        try:
            self.repos = repos.svn_repos_open(root_path_utf8, self.pool())
        except core.SubversionException, e:
            raise TracError(_("Couldn't open Subversion repository %(path)s: "
                              "%(svn_error)s", path=to_unicode(path_utf8),
                              svn_error=exception_to_unicode(e)))
        self.fs_ptr = repos.svn_repos_fs(self.repos)

        self.uuid = fs.get_uuid(self.fs_ptr, self.pool())
        self.base = 'svn:%s:%s' % (self.uuid, _from_svn(root_path_utf8))
        name = 'svn:%s:%s' % (self.uuid, self.path)

        Repository.__init__(self, name, params, log)

        # if root_path_utf8 is shorter than the path_utf8, the difference is
        # this scope (which always starts with a '/')
        if root_path_utf8 != path_utf8:
            self.scope = path_utf8[len(root_path_utf8):].decode('utf-8')
            if not self.scope[-1] == '/':
                self.scope += '/'
        else:
            self.scope = '/'
        assert self.scope[0] == '/'
        # we keep root_path_utf8 for  RA
        ra_prefix = 'file:///' if os.name == 'nt' else 'file://'
        self.ra_url_utf8 = ra_prefix + root_path_utf8
        self.clear()

    def clear(self, youngest_rev=None):
        """Reset notion of `youngest` and `oldest`"""
        self.youngest = None
        if youngest_rev is not None:
            self.youngest = self.normalize_rev(youngest_rev)
        self.oldest = None

    def __del__(self):
        self.close()

    def has_node(self, path, rev=None, pool=None):
        """Check if `path` exists at `rev` (or latest if unspecified)"""
        if not pool:
            pool = self.pool
        rev = self.normalize_rev(rev)
        rev_root = fs.revision_root(self.fs_ptr, rev, pool())
        node_type = fs.check_path(rev_root, _to_svn(pool(), self.scope, path),
                                  pool())
        return node_type in _kindmap

    def normalize_path(self, path):
        """Take any path specification and produce a path suitable for
        the rest of the API
        """
        return _normalize_path(path)

    def normalize_rev(self, rev):
        """Take any revision specification and produce a revision suitable
        for the rest of the API
        """
        if rev is None or isinstance(rev, basestring) and \
               rev.lower() in ('', 'head', 'latest', 'youngest'):
            return self.youngest_rev
        else:
            try:
                rev = int(rev)
                if rev <= self.youngest_rev:
                    return rev
            except (ValueError, TypeError):
                pass
            raise NoSuchChangeset(rev)

    def close(self):
        """Dispose of low-level resources associated to this repository."""
        if self.pool:
            self.pool.destroy()
        self.repos = self.fs_ptr = self.pool = None

    def get_base(self):
        """Retrieve the base path corresponding to the Subversion
        repository itself.

        This is the same as the `.path` property minus the
        intra-repository scope, if one was specified.
        """
        return self.base

    def _get_tags_or_branches(self, paths):
        """Retrieve known branches or tags."""
        for path in self.params.get(paths, []):
            if path.endswith('*'):
                folder = posixpath.dirname(path)
                try:
                    entries = [n for n in self.get_node(folder).get_entries()]
                    for node in sorted(entries, key=lambda n:
                                       embedded_numbers(n.path.lower())):
                        if node.kind == Node.DIRECTORY:
                            yield node
                except Exception: # no right (TODO: use a specific Exception)
                    pass
            else:
                try:
                    yield self.get_node(path)
                except Exception: # no right
                    pass

    def get_quickjump_entries(self, rev):
        """Retrieve known branches, as (name, id) pairs.

        Purposedly ignores `rev` and always takes the last revision.
        """
        for n in self._get_tags_or_branches('branches'):
            yield 'branches', n.path, n.path, None
        for n in self._get_tags_or_branches('tags'):
            yield 'tags', n.path, n.created_path, n.created_rev

    def get_path_url(self, path, rev):
        """Retrieve the "native" URL from which this repository is reachable
        from Subversion clients.
        """
        url = self.params.get('url', '').rstrip('/')
        if url:
            if not path or path == '/':
                return url
            return url + '/' + path.lstrip('/')

    def get_changeset(self, rev):
        """Produce a `SubversionChangeset` from given revision
        specification"""
        rev = self.normalize_rev(rev)
        return SubversionChangeset(self, rev, self.scope, self.pool)

    def get_changeset_uid(self, rev):
        """Build a value identifying the `rev` in this repository."""
        return (self.uuid, rev)

    def get_node(self, path, rev=None):
        """Produce a `SubversionNode` from given path and optionally revision
        specifications. No revision given means use the latest.
        """
        path = path or ''
        if path and path[-1] == '/':
            path = path[:-1]
        rev = self.normalize_rev(rev) or self.youngest_rev
        return SubversionNode(path, rev, self, self.pool)

    def _get_node_revs(self, path, last=None, first=None):
        """Return the revisions affecting `path` between `first` and `last`
        revs. If `first` is not given, it goes down to the revision in which
        the branch was created.
        """
        node = self.get_node(path, last)
        revs = []
        for (p, r, chg) in node.get_history():
            if p != path or (first and r < first):
                break
            revs.append(r)
        return revs

    def _history(self, path, start, end, pool):
        """`path` is a unicode path in the scope.

        Generator yielding `(path, rev)` pairs, where `path` is an `unicode`
        object. Must start with `(path, created rev)`.

        (wraps ``fs.node_history``)
        """
        path_utf8 = _to_svn(pool(), self.scope, path)
        if start < end:
            start, end = end, start
        if (start, end) == (1, 0): # only happens for empty repos
            return
        root = fs.revision_root(self.fs_ptr, start, pool())
        # fs.node_history leaks when path doesn't exist (#6588)
        if fs.check_path(root, path_utf8, pool()) == core.svn_node_none:
            return
        tmp1 = Pool(pool)
        tmp2 = Pool(pool)
        history_ptr = fs.node_history(root, path_utf8, tmp1())
        cross_copies = 1
        while history_ptr:
            history_ptr = fs.history_prev(history_ptr, cross_copies, tmp2())
            tmp1.clear()
            tmp1, tmp2 = tmp2, tmp1
            if history_ptr:
                path_utf8, rev = fs.history_location(history_ptr, tmp2())
                tmp2.clear()
                if rev < end:
                    break
                path = _from_svn(path_utf8)
                yield path, rev
        del tmp1
        del tmp2

    def _previous_rev(self, rev, path='', pool=None):
        if rev > 1: # don't use oldest here, as it's too expensive
            for _, prev in self._history(path, 1, rev-1, pool or self.pool):
                return prev
        return None


    def get_oldest_rev(self):
        """Gives an approximation of the oldest revision."""
        if self.oldest is None:
            self.oldest = 1
            # trying to figure out the oldest rev for scoped repository
            # is too expensive and uncovers a big memory leak (#5213)
            # if self.scope != '/':
            #    self.oldest = self.next_rev(0, find_initial_rev=True)
        return self.oldest

    def get_youngest_rev(self):
        """Retrieve the latest revision in the repository.

        (wraps ``fs.youngest_rev``)
        """
        if not self.youngest:
            self.youngest = fs.youngest_rev(self.fs_ptr, self.pool())
            if self.scope != '/':
                for path, rev in self._history('', 1, self.youngest, self.pool):
                    self.youngest = rev
                    break
        return self.youngest

    def previous_rev(self, rev, path=''):
        """Return revision immediately preceeding `rev`, eventually below
        given `path` or globally.
        """
        # FIXME optimize for non-scoped
        rev = self.normalize_rev(rev)
        return self._previous_rev(rev, path)

    def next_rev(self, rev, path='', find_initial_rev=False):
        """Return revision immediately following `rev`, eventually below
        given `path` or globally.
        """
        rev = self.normalize_rev(rev)
        next = rev + 1
        youngest = self.youngest_rev
        subpool = Pool(self.pool)
        while next <= youngest:
            subpool.clear()
            for _, next in self._history(path, rev+1, next, subpool):
                return next
            else:
                if not find_initial_rev and \
                         not self.has_node(path, next, subpool):
                    return next # a 'delete' event is also interesting...
            next += 1
        return None

    def rev_older_than(self, rev1, rev2):
        """Check relative order between two revision specifications."""
        return self.normalize_rev(rev1) < self.normalize_rev(rev2)

    def get_path_history(self, path, rev=None, limit=None):
        """Retrieve creation and deletion events that happened on
        given `path`.
        """
        path = self.normalize_path(path)
        rev = self.normalize_rev(rev)
        expect_deletion = False
        subpool = Pool(self.pool)
        numrevs = 0
        while rev and (not limit or numrevs < limit):
            subpool.clear()
            if self.has_node(path, rev, subpool):
                if expect_deletion:
                    # it was missing, now it's there again:
                    #  rev+1 must be a delete
                    numrevs += 1
                    yield path, rev+1, Changeset.DELETE
                newer = None # 'newer' is the previously seen history tuple
                older = None # 'older' is the currently examined history tuple
                for p, r in self._history(path, 1, rev, subpool):
                    older = (_path_within_scope(self.scope, p), r,
                             Changeset.ADD)
                    rev = self._previous_rev(r, pool=subpool)
                    if newer:
                        numrevs += 1
                        if older[0] == path:
                            # still on the path: 'newer' was an edit
                            yield newer[0], newer[1], Changeset.EDIT
                        else:
                            # the path changed: 'newer' was a copy
                            rev = self._previous_rev(newer[1], pool=subpool)
                            # restart before the copy op
                            yield newer[0], newer[1], Changeset.COPY
                            older = (older[0], older[1], 'unknown')
                            break
                    newer = older
                if older:
                    # either a real ADD or the source of a COPY
                    numrevs += 1
                    yield older
            else:
                expect_deletion = True
                rev = self._previous_rev(rev, pool=subpool)

    def get_changes(self, old_path, old_rev, new_path, new_rev,
                    ignore_ancestry=0):
        """Determine differences between two arbitrary pairs of paths
        and revisions.

        (wraps ``repos.svn_repos_dir_delta``)
        """
        def key(value):
            return value[1].path if value[1] is not None else value[0].path
        return iter(sorted(self._get_changes(old_path, old_rev, new_path,
                                             new_rev, ignore_ancestry),
                           key=key))

    def _get_changes(self, old_path, old_rev, new_path, new_rev,
                     ignore_ancestry):
        old_node = new_node = None
        old_rev = self.normalize_rev(old_rev)
        new_rev = self.normalize_rev(new_rev)
        if self.has_node(old_path, old_rev):
            old_node = self.get_node(old_path, old_rev)
        else:
            raise NoSuchNode(old_path, old_rev, 'The Base for Diff is invalid')
        if self.has_node(new_path, new_rev):
            new_node = self.get_node(new_path, new_rev)
        else:
            raise NoSuchNode(new_path, new_rev,
                             'The Target for Diff is invalid')
        if new_node.kind != old_node.kind:
            raise TracError(_('Diff mismatch: Base is a %(oldnode)s '
                              '(%(oldpath)s in revision %(oldrev)s) and '
                              'Target is a %(newnode)s (%(newpath)s in '
                              'revision %(newrev)s).', oldnode=old_node.kind,
                              oldpath=old_path, oldrev=old_rev,
                              newnode=new_node.kind, newpath=new_path,
                              newrev=new_rev))
        subpool = Pool(self.pool)
        if new_node.isdir:
            editor = DiffChangeEditor()
            e_ptr, e_baton = delta.make_editor(editor, subpool())
            old_root = fs.revision_root(self.fs_ptr, old_rev, subpool())
            new_root = fs.revision_root(self.fs_ptr, new_rev, subpool())
            def authz_cb(root, path, pool):
                return 1
            text_deltas = 0 # as this is anyway re-done in Diff.py...
            entry_props = 0 # "... typically used only for working copy updates"
            repos.svn_repos_dir_delta(old_root,
                                      _to_svn(subpool(), self.scope, old_path),
                                      '', new_root,
                                      _to_svn(subpool(), self.scope, new_path),
                                      e_ptr, e_baton, authz_cb,
                                      text_deltas,
                                      1, # directory
                                      entry_props,
                                      ignore_ancestry,
                                      subpool())
            for path, kind, change in editor.deltas:
                path = _from_svn(path)
                old_node = new_node = None
                if change != Changeset.ADD:
                    old_node = self.get_node(posixpath.join(old_path, path),
                                             old_rev)
                if change != Changeset.DELETE:
                    new_node = self.get_node(posixpath.join(new_path, path),
                                             new_rev)
                else:
                    kind = _kindmap[fs.check_path(old_root,
                                                  _to_svn(subpool(),
                                                          self.scope,
                                                          old_node.path),
                                                  subpool())]
                yield  (old_node, new_node, kind, change)
        else:
            old_root = fs.revision_root(self.fs_ptr, old_rev, subpool())
            new_root = fs.revision_root(self.fs_ptr, new_rev, subpool())
            if fs.contents_changed(old_root,
                                   _to_svn(subpool(), self.scope, old_path),
                                   new_root,
                                   _to_svn(subpool(), self.scope, new_path),
                                   subpool()):
                yield (old_node, new_node, Node.FILE, Changeset.EDIT)


class SubversionNode(Node):

    def __init__(self, path, rev, repos, pool=None, parent_root=None):
        self.fs_ptr = repos.fs_ptr
        self.scope = repos.scope
        self.pool = Pool(pool)
        pool = self.pool()
        self._scoped_path_utf8 = _to_svn(pool, self.scope, path)

        if parent_root:
            self.root = parent_root
        else:
            self.root = fs.revision_root(self.fs_ptr, rev, pool)
        node_type = fs.check_path(self.root, self._scoped_path_utf8, pool)
        if not node_type in _kindmap:
            raise NoSuchNode(path, rev)
        cp_utf8 = fs.node_created_path(self.root, self._scoped_path_utf8, pool)
        cp = _from_svn(cp_utf8)
        cr = fs.node_created_rev(self.root, self._scoped_path_utf8, pool)
        # Note: `cp` differs from `path` if the last change was a copy,
        #        In that case, `path` doesn't even exist at `cr`.
        #        The only guarantees are:
        #          * this node exists at (path,rev)
        #          * the node existed at (created_path,created_rev)
        # Also, `cp` might well be out of the scope of the repository,
        # in this case, we _don't_ use the ''create'' information.
        if _is_path_within_scope(self.scope, cp):
            self.created_rev = cr
            self.created_path = _path_within_scope(self.scope, cp)
        else:
            self.created_rev, self.created_path = rev, path
        # TODO: check node id
        Node.__init__(self, repos, path, rev, _kindmap[node_type])

    def get_content(self):
        """Retrieve raw content as a "read()"able object."""
        if self.isdir:
            return None
        pool = Pool(self.pool)
        s = core.Stream(fs.file_contents(self.root, self._scoped_path_utf8,
                                         pool()))
        # The stream object needs to reference the pool to make sure the pool
        # is not destroyed before the former.
        s._pool = pool
        return s

    def get_entries(self):
        """Yield `SubversionNode` corresponding to entries in this directory.

        (wraps ``fs.dir_entries``)
        """
        if self.isfile:
            return
        pool = Pool(self.pool)
        entries = fs.dir_entries(self.root, self._scoped_path_utf8, pool())
        for item in entries.keys():
            path = posixpath.join(self.path, _from_svn(item))
            yield SubversionNode(path, self.rev, self.repos, self.pool,
                                 self.root)

    def get_history(self, limit=None):
        """Yield change events that happened on this path"""
        newer = None # 'newer' is the previously seen history tuple
        older = None # 'older' is the currently examined history tuple
        pool = Pool(self.pool)
        numrevs = 0
        for path, rev in self.repos._history(self.path, 1, self.rev, pool):
            path = _path_within_scope(self.scope, path)
            if rev > 0 and path:
                older = (path, rev, Changeset.ADD)
                if newer:
                    if newer[0] == older[0]: # stay on same path
                        change = Changeset.EDIT
                    else:
                        change = Changeset.COPY
                    newer = (newer[0], newer[1], change)
                    numrevs += 1
                    yield newer
                newer = older
            if limit and numrevs >= limit:
                break
        if newer and (not limit or numrevs < limit):
            yield newer

    def get_annotations(self):
        """Return a list the last changed revision for each line.
        (wraps ``client.blame2``)
        """
        annotations = []
        if self.isfile:
            def blame_receiver(line_no, revision, author, date, line, pool):
                annotations.append(revision)
            try:
                rev = _svn_rev(self.rev)
                start = _svn_rev(0)
                file_url_utf8 = posixpath.join(self.repos.ra_url_utf8,
                                               self._scoped_path_utf8)
                self.repos.log.info('opening ra_local session to %r',
                                    file_url_utf8)
                from svn import client
                client.blame2(file_url_utf8, rev, start, rev, blame_receiver,
                              client.create_context(), self.pool())
            except (core.SubversionException, AttributeError), e:
                # svn thinks file is a binary or blame not supported
                raise TracError(_('svn blame failed on %(path)s: %(error)s',
                                  path=self.path, error=to_unicode(e)))
        return annotations

#    def get_previous(self):
#        # FIXME: redo it with fs.node_history

    def get_properties(self):
        """Return `dict` of node properties at current revision.

        (wraps ``fs.node_proplist``)
        """
        props = fs.node_proplist(self.root, self._scoped_path_utf8, self.pool())
        for name, value in props.items():
            # Note that property values can be arbitrary binary values
            # so we can't assume they are UTF-8 strings...
            props[_from_svn(name)] = to_unicode(value)
        return props

    def get_content_length(self):
        """Retrieve byte size of a file.

        Return `None` for a folder. (wraps ``fs.file_length``)
        """
        if self.isdir:
            return None
        return fs.file_length(self.root, self._scoped_path_utf8, self.pool())

    def get_content_type(self):
        """Retrieve mime-type property of a file.

        Return `None` for a folder. (wraps ``fs.revision_prop``)
        """
        if self.isdir:
            return None
        return self._get_prop(core.SVN_PROP_MIME_TYPE)

    def get_last_modified(self):
        """Retrieve timestamp of last modification, in micro-seconds.

        (wraps ``fs.revision_prop``)
        """
        _date = fs.revision_prop(self.fs_ptr, self.created_rev,
                                 core.SVN_PROP_REVISION_DATE, self.pool())
        if not _date:
            return None
        return from_utimestamp(core.svn_time_from_cstring(_date, self.pool()))

    def _get_prop(self, name):
        return fs.node_prop(self.root, self._scoped_path_utf8, name,
                            self.pool())

    def get_branch_origin(self):
        """Return the revision in which the node's path was created.

        (wraps ``fs.revision_root_revision(fs.closest_copy)``)
        """
        root_and_path = fs.closest_copy(self.root, self._scoped_path_utf8)
        if root_and_path:
            return fs.revision_root_revision(root_and_path[0])

    def get_copy_ancestry(self):
        """Retrieve the list of `(path,rev)` copy ancestors of this node.
        Most recent ancestor first. Each ancestor `(path, rev)` corresponds
        to the path and revision of the source at the time the copy or move
        operation was performed.
        """
        ancestors = []
        previous = (self._scoped_path_utf8, self.rev, self.root)
        while previous:
            (previous_path, previous_rev, previous_root) = previous
            previous = None
            root_path = fs.closest_copy(previous_root, previous_path)
            if root_path:
                (root, path) = root_path
                path = path.lstrip('/')
                rev = fs.revision_root_revision(root)
                relpath = None
                if path != previous_path:
                    # `previous_path` is a subfolder of `path` and didn't
                    # change since `path` was copied
                    relpath = previous_path[len(path):].strip('/')
                copied_from = fs.copied_from(root, path)
                if copied_from:
                    (rev, path) = copied_from
                    path = path.lstrip('/')
                    root = fs.revision_root(self.fs_ptr, rev, self.pool())
                    if relpath:
                        path += '/' + relpath
                    ui_path = _path_within_scope(self.scope, _from_svn(path))
                    if ui_path:
                        ancestors.append((ui_path, rev))
                    previous = (path, rev, root)
        return ancestors


class SubversionChangeset(Changeset):

    def __init__(self, repos, rev, scope, pool=None):
        self.rev = rev
        self.scope = scope
        self.fs_ptr = repos.fs_ptr
        self.pool = Pool(pool)
        try:
            message = self._get_prop(core.SVN_PROP_REVISION_LOG)
        except core.SubversionException:
            raise NoSuchChangeset(rev)
        author = self._get_prop(core.SVN_PROP_REVISION_AUTHOR)
        # we _hope_ it's UTF-8, but can't be 100% sure (#4321)
        message = message and to_unicode(message, 'utf-8')
        author = author and to_unicode(author, 'utf-8')
        _date = self._get_prop(core.SVN_PROP_REVISION_DATE)
        if _date:
            ts = core.svn_time_from_cstring(_date, self.pool())
            date = from_utimestamp(ts)
        else:
            date = None
        Changeset.__init__(self, repos, rev, message, author, date)

    def get_properties(self):
        """Retrieve `dict` of Subversion properties for this revision
        (revprops)
        """
        props = fs.revision_proplist(self.fs_ptr, self.rev, self.pool())
        properties = {}
        for k, v in props.iteritems():
            if k not in (core.SVN_PROP_REVISION_LOG,
                         core.SVN_PROP_REVISION_AUTHOR,
                         core.SVN_PROP_REVISION_DATE):
                properties[k] = to_unicode(v)
                # Note: the above `to_unicode` has a small probability
                # to mess-up binary properties, like icons.
        return properties

    def get_changes(self):
        """Retrieve file changes for a given revision.

        (wraps ``repos.svn_repos_replay``)
        """
        pool = Pool(self.pool)
        tmp = Pool(pool)
        root = fs.revision_root(self.fs_ptr, self.rev, pool())
        editor = repos.RevisionChangeCollector(self.fs_ptr, self.rev, pool())
        e_ptr, e_baton = delta.make_editor(editor, pool())
        repos.svn_repos_replay(root, e_ptr, e_baton, pool())

        idx = 0
        copies, deletions = {}, {}
        changes = []
        revroots = {}
        for path_utf8, change in editor.changes.items():
            new_path = _from_svn(path_utf8)

            # Filtering on `path`
            if not _is_path_within_scope(self.scope, new_path):
                continue

            path_utf8 = change.path
            base_path_utf8 = change.base_path
            path = _from_svn(path_utf8)
            base_path = _from_svn(base_path_utf8)
            base_rev = change.base_rev
            change_action = getattr(change, 'action', None)

            # Ensure `base_path` is within the scope
            if not _is_path_within_scope(self.scope, base_path):
                base_path, base_rev = None, -1

            # Determine the action
            if not path and not new_path and self.scope == '/':
                action = Changeset.EDIT # root property change
            elif not path or (change_action is not None
                              and change_action == repos.CHANGE_ACTION_DELETE):
                if new_path:            # deletion
                    action = Changeset.DELETE
                    deletions[new_path.lstrip('/')] = idx
                else:                   # deletion outside of scope, ignore
                    continue
            elif change.added or not base_path: # add or copy
                action = Changeset.ADD
                if base_path and base_rev:
                    action = Changeset.COPY
                    copies[base_path.lstrip('/')] = idx
            else:
                action = Changeset.EDIT
                # identify the most interesting base_path/base_rev
                # in terms of last changed information (see r2562)
                if revroots.has_key(base_rev):
                    b_root = revroots[base_rev]
                else:
                    b_root = fs.revision_root(self.fs_ptr, base_rev, pool())
                    revroots[base_rev] = b_root
                tmp.clear()
                cbase_path_utf8 = fs.node_created_path(b_root, base_path_utf8,
                                                       tmp())
                cbase_path = _from_svn(cbase_path_utf8)
                cbase_rev = fs.node_created_rev(b_root, base_path_utf8, tmp())
                # give up if the created path is outside the scope
                if _is_path_within_scope(self.scope, cbase_path):
                    base_path, base_rev = cbase_path, cbase_rev

            kind = _kindmap[change.item_kind]
            path = _path_within_scope(self.scope, new_path or base_path)
            base_path = _path_within_scope(self.scope, base_path)
            changes.append([path, kind, action, base_path, base_rev])
            idx += 1

        moves = []
        # a MOVE is a COPY whose `base_path` corresponds to a `new_path`
        # which has been deleted
        for k, v in copies.items():
            if k in deletions:
                changes[v][2] = Changeset.MOVE
                moves.append(deletions[k])
        offset = 0
        moves.sort()
        for i in moves:
            del changes[i - offset]
            offset += 1

        changes.sort()
        for change in changes:
            yield tuple(change)

    def _get_prop(self, name):
        return fs.revision_prop(self.fs_ptr, self.rev, name, self.pool())


#
# Delta editor for diffs between arbitrary nodes
#
# Note 1: the 'copyfrom_path' and 'copyfrom_rev' information is not used
#         because 'repos.svn_repos_dir_delta' *doesn't* provide it.
#
# Note 2: the 'dir_baton' is the path of the parent directory
#


def DiffChangeEditor():

    class DiffChangeEditor(delta.Editor):

        def __init__(self):
            self.deltas = []

        # -- svn.delta.Editor callbacks

        def open_root(self, base_revision, dir_pool):
            return ('/', Changeset.EDIT)

        def add_directory(self, path, dir_baton, copyfrom_path, copyfrom_rev,
                          dir_pool):
            self.deltas.append((path, Node.DIRECTORY, Changeset.ADD))
            return (path, Changeset.ADD)

        def open_directory(self, path, dir_baton, base_revision, dir_pool):
            return (path, dir_baton[1])

        def change_dir_prop(self, dir_baton, name, value, pool):
            path, change = dir_baton
            if change != Changeset.ADD:
                self.deltas.append((path, Node.DIRECTORY, change))

        def delete_entry(self, path, revision, dir_baton, pool):
            self.deltas.append((path, None, Changeset.DELETE))

        def add_file(self, path, dir_baton, copyfrom_path, copyfrom_revision,
                     dir_pool):
            self.deltas.append((path, Node.FILE, Changeset.ADD))

        def open_file(self, path, dir_baton, dummy_rev, file_pool):
            self.deltas.append((path, Node.FILE, Changeset.EDIT))

    return DiffChangeEditor()


########NEW FILE########
__FILENAME__ = svn_prop
# -*- coding: utf-8 -*-
#
# Copyright (C) 2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# Copyright (C) 2005-2007 Christian Boos <cboos@edgewall.org>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>
#         Christian Boos <cboos@edgewall.org>

import posixpath

from genshi.builder import tag

from trac.config import ConfigSection
from trac.core import *
from trac.versioncontrol.api import NoSuchNode, RepositoryManager
from trac.versioncontrol.web_ui.browser import IPropertyRenderer
from trac.versioncontrol.web_ui.changeset import IPropertyDiffRenderer
from trac.util import Ranges, to_ranges
from trac.util.translation import _, tag_
from tracopt.versioncontrol.svn.svn_fs import _path_within_scope


class SubversionPropertyRenderer(Component):

    implements(IPropertyRenderer)

    svn_externals_section = ConfigSection('svn:externals',
        """The TracBrowser for Subversion can interpret the `svn:externals`
        property of folders. By default, it only turns the URLs into links as
        Trac can't browse remote repositories.

        However, if you have another Trac instance (or an other repository
        browser like [http://www.viewvc.org/ ViewVC]) configured to browse the
        target repository, then you can instruct Trac which other repository
        browser to use for which external URL. This mapping is done in the
        `[svn:externals]` section of the TracIni.

        Example:
        {{{
        [svn:externals]
        1 = svn://server/repos1                       http://trac/proj1/browser/$path?rev=$rev
        2 = svn://server/repos2                       http://trac/proj2/browser/$path?rev=$rev
        3 = http://theirserver.org/svn/eng-soft       http://ourserver/viewvc/svn/$path/?pathrev=25914
        4 = svn://anotherserver.com/tools_repository  http://ourserver/tracs/tools/browser/$path?rev=$rev
        }}}
        With the above, the
        `svn://anotherserver.com/tools_repository/tags/1.1/tools` external will
        be mapped to `http://ourserver/tracs/tools/browser/tags/1.1/tools?rev=`
        (and `rev` will be set to the appropriate revision number if the
        external additionally specifies a revision, see the
        [http://svnbook.red-bean.com/en/1.4/svn.advanced.externals.html SVN Book on externals]
        for more details).

        Note that the number used as a key in the above section is purely used
        as a place holder, as the URLs themselves can't be used as a key due to
        various limitations in the configuration file parser.

        Finally, the relative URLs introduced in
        [http://subversion.apache.org/docs/release-notes/1.5.html#externals Subversion 1.5]
        are not yet supported.

        (''since 0.11'')""")

    def __init__(self):
        self._externals_map = {}

    # IPropertyRenderer methods

    def match_property(self, name, mode):
        if name in ('svn:externals', 'svn:needs-lock'):
            return 4
        return 2 if name in ('svn:mergeinfo', 'svnmerge-blocked',
                             'svnmerge-integrated') else 0

    def render_property(self, name, mode, context, props):
        if name == 'svn:externals':
            return self._render_externals(props[name])
        elif name == 'svn:needs-lock':
            return self._render_needslock(context)
        elif name == 'svn:mergeinfo' or name.startswith('svnmerge-'):
            return self._render_mergeinfo(name, mode, context, props)

    def _render_externals(self, prop):
        if not self._externals_map:
            for dummykey, value in self.svn_externals_section.options():
                value = value.split()
                if len(value) != 2:
                    self.log.warn("svn:externals entry %s doesn't contain "
                            "a space-separated key value pair, skipping.",
                            dummykey)
                    continue
                key, value = value
                self._externals_map[key] = value.replace('%', '%%') \
                                           .replace('$path', '%(path)s') \
                                           .replace('$rev', '%(rev)s')
        externals = []
        for external in prop.splitlines():
            elements = external.split()
            if not elements:
                continue
            localpath, rev, url = elements[0], '', elements[-1]
            if localpath.startswith('#'):
                externals.append((external, None, None, None, None))
                continue
            if len(elements) == 3:
                rev = elements[1]
                rev = rev.replace('-r', '')
            # retrieve a matching entry in the externals map
            prefix = []
            base_url = url
            while base_url:
                if base_url in self._externals_map or base_url == u'/':
                    break
                base_url, pref = posixpath.split(base_url)
                prefix.append(pref)
            href = self._externals_map.get(base_url)
            revstr = ' at revision ' + rev if rev else ''
            if not href and (url.startswith('http://') or
                             url.startswith('https://')):
                href = url.replace('%', '%%')
            if href:
                remotepath = ''
                if prefix:
                    remotepath = posixpath.join(*reversed(prefix))
                externals.append((localpath, revstr, base_url, remotepath,
                                  href % {'path': remotepath, 'rev': rev}))
            else:
                externals.append((localpath, revstr, url, None, None))
        externals_data = []
        for localpath, rev, url, remotepath, href in externals:
            label = localpath
            if url is None:
                title = ''
            elif href:
                if url:
                    url = ' in ' + url
                label += rev + url
                title = ''.join((remotepath, rev, url))
            else:
                title = _('No svn:externals configured in trac.ini')
            externals_data.append((label, href, title))
        return tag.ul([tag.li(tag.a(label, href=href, title=title))
                       for label, href, title in externals_data])

    def _render_needslock(self, context):
        return tag.img(src=context.href.chrome('common/lock-locked.png'),
                       alt="needs lock", title="needs lock")

    def _render_mergeinfo(self, name, mode, context, props):
        rows = []
        for row in props[name].splitlines():
            try:
                (path, revs) = row.rsplit(':', 1)
                rows.append([tag.td(path),
                             tag.td(revs.replace(',', u',\u200b'))])
            except ValueError:
                rows.append(tag.td(row, colspan=2))
        return tag.table(tag.tbody([tag.tr(row) for row in rows]),
                         class_='props')


class SubversionMergePropertyRenderer(Component):
    implements(IPropertyRenderer)

    # IPropertyRenderer methods

    def match_property(self, name, mode):
        return 4 if name in ('svn:mergeinfo', 'svnmerge-blocked',
                             'svnmerge-integrated') else 0

    def render_property(self, name, mode, context, props):
        """Parse svn:mergeinfo and svnmerge-* properties, converting branch
        names to links and providing links to the revision log for merged
        and eligible revisions.
        """
        has_eligible = name in ('svnmerge-integrated', 'svn:mergeinfo')
        revs_label = _('blocked') if name.endswith('blocked') else _('merged')
        revs_cols = 2 if has_eligible else None
        reponame = context.resource.parent.id
        target_path = context.resource.id
        repos = RepositoryManager(self.env).get_repository(reponame)
        target_rev = context.resource.version
        if has_eligible:
            node = repos.get_node(target_path, target_rev)
            branch_starts = {}
            for path, rev in node.get_copy_ancestry():
                if path not in branch_starts:
                    branch_starts[path] = rev + 1
        rows = []
        if name.startswith('svnmerge-'):
            sources = props[name].split()
        else:
            sources = props[name].splitlines()
        for line in sources:
            path, revs = line.split(':', 1)
            spath = _path_within_scope(repos.scope, path)
            if spath is None:
                continue
            revs = revs.strip()
            inheritable, non_inheritable = _partition_inheritable(revs)
            revs = ','.join(inheritable)
            deleted = False
            try:
                node = repos.get_node(spath, target_rev)
                resource = context.resource.parent.child('source', spath)
                if 'LOG_VIEW' in context.perm(resource):
                    row = [_get_source_link(spath, context),
                           _get_revs_link(revs_label, context, spath, revs)]
                    if non_inheritable:
                        non_inheritable = ','.join(non_inheritable)
                        row.append(_get_revs_link(_('non-inheritable'), context,
                                                  spath, non_inheritable,
                                                  _('merged on the directory '
                                                    'itself but not below')))
                    if has_eligible:
                        first_rev = branch_starts.get(spath)
                        if not first_rev:
                            first_rev = node.get_branch_origin()
                        eligible = set(xrange(first_rev or 1, target_rev + 1))
                        eligible -= set(Ranges(revs))
                        blocked = _get_blocked_revs(props, name, spath)
                        if blocked:
                            eligible -= set(Ranges(blocked))
                        if eligible:
                            nrevs = repos._get_node_revs(spath, max(eligible),
                                                         min(eligible))
                            eligible &= set(nrevs)
                        eligible = to_ranges(eligible)
                        row.append(_get_revs_link(_('eligible'), context,
                                                  spath, eligible))
                    rows.append((False, spath, [tag.td(each) for each in row]))
                    continue
            except NoSuchNode:
                deleted = True
            revs = revs.replace(',', u',\u200b')
            rows.append((deleted, spath,
                         [tag.td('/' + spath),
                          tag.td(revs, colspan=revs_cols)]))
        if not rows:
            return None
        rows.sort()
        has_deleted = rows[-1][0] if rows else None
        return tag(has_deleted and tag.a(_('(toggle deleted branches)'),
                                         class_='trac-toggledeleted',
                                         href='#'),
                   tag.table(tag.tbody(
                       [tag.tr(row, class_='trac-deleted' if deleted else None)
                        for deleted, spath, row in rows]), class_='props'))


def _partition_inheritable(revs):
    """Non-inheritable revision ranges are marked with a trailing '*'."""
    inheritable, non_inheritable = [], []
    for r in revs.split(','):
        if r and r[-1] == '*':
            non_inheritable.append(r[:-1])
        else:
            inheritable.append(r)
    return inheritable, non_inheritable

def _get_blocked_revs(props, name, path):
    """Return the revisions blocked from merging for the given property
    name and path.
    """
    if name == 'svnmerge-integrated':
        prop = props.get('svnmerge-blocked', '')
    else:
        return ""
    for line in prop.splitlines():
        try:
            p, revs = line.split(':', 1)
            if p.strip('/') == path:
                return revs
        except Exception:
            pass
    return ""

def _get_source_link(spath, context):
    """Return a link to a merge source."""
    reponame = context.resource.parent.id
    return tag.a('/' + spath, title=_('View merge source'),
                 href=context.href.browser(reponame or None, spath,
                                           rev=context.resource.version))

def _get_revs_link(label, context, spath, revs, title=None):
    """Return a link to the revision log when more than one revision is
    given, to the revision itself for a single revision, or a `<span>`
    with "no revision" for none.
    """
    reponame = context.resource.parent.id
    if not revs:
        return tag.span(label, title=_('No revisions'))
    elif ',' in revs or '-' in revs:
        revs_href = context.href.log(reponame or None, spath, revs=revs)
    else:
        revs_href = context.href.changeset(revs, reponame or None, spath)
    revs = revs.replace(',', ', ')
    if title:
        title = _("%(title)s: %(revs)s", title=title, revs=revs)
    else:
        title = revs
    return tag.a(label, title=title, href=revs_href)


class SubversionMergePropertyDiffRenderer(Component):
    implements(IPropertyDiffRenderer)

    # IPropertyDiffRenderer methods

    def match_property_diff(self, name):
        return 4 if name in ('svn:mergeinfo', 'svnmerge-blocked',
                             'svnmerge-integrated') else 0

    def render_property_diff(self, name, old_context, old_props,
                             new_context, new_props, options):
        # Build 5 columns table showing modifications on merge sources
        # || source || added || removed || added (ni) || removed (ni) ||
        # || source || removed                                        ||
        rm = RepositoryManager(self.env)
        repos = rm.get_repository(old_context.resource.parent.id)
        def parse_sources(props):
            sources = {}
            for line in props[name].splitlines():
                path, revs = line.split(':', 1)
                spath = _path_within_scope(repos.scope, path)
                if spath is not None:
                    inheritable, non_inheritable = _partition_inheritable(revs)
                    sources[spath] = (set(Ranges(inheritable)),
                                      set(Ranges(non_inheritable)))
            return sources
        old_sources = parse_sources(old_props)
        new_sources = parse_sources(new_props)
        # Go through new sources, detect modified ones or added ones
        blocked = name.endswith('blocked')
        added_label = [_("merged: "), _("blocked: ")][blocked]
        removed_label = [_("reverse-merged: "), _("un-blocked: ")][blocked]
        added_ni_label = _("marked as non-inheritable: ")
        removed_ni_label = _("unmarked as non-inheritable: ")
        def revs_link(revs, context):
            if revs:
                revs = to_ranges(revs)
                return _get_revs_link(revs.replace(',', u',\u200b'),
                                      context, spath, revs)
        modified_sources = []
        for spath, (new_revs, new_revs_ni) in new_sources.iteritems():
            if spath in old_sources:
                (old_revs, old_revs_ni), status = old_sources.pop(spath), None
            else:
                old_revs = old_revs_ni = set()
                status = _(' (added)')
            added = new_revs - old_revs
            removed = old_revs - new_revs
            added_ni = new_revs_ni - old_revs_ni
            removed_ni = old_revs_ni - new_revs_ni
            try:
                all_revs = set(repos._get_node_revs(spath))
                # TODO: also pass first_rev here, for getting smaller a set
                #       (this is an optmization fix, result is already correct)
                added &= all_revs
                removed &= all_revs
                added_ni &= all_revs
                removed_ni &= all_revs
            except NoSuchNode:
                pass
            if added or removed:
                modified_sources.append((
                    spath, [_get_source_link(spath, new_context), status],
                    added and tag(added_label, revs_link(added, new_context)),
                    removed and tag(removed_label,
                                    revs_link(removed, old_context)),
                    added_ni and tag(added_ni_label,
                                     revs_link(added_ni, new_context)),
                    removed_ni and tag(removed_ni_label,
                                       revs_link(removed_ni, old_context))
                    ))
        # Go through remaining old sources, those were deleted
        removed_sources = []
        for spath, old_revs in old_sources.iteritems():
            removed_sources.append((spath,
                                    _get_source_link(spath, old_context)))
        if modified_sources or removed_sources:
            modified_sources.sort()
            removed_sources.sort()
            changes = tag.table(tag.tbody(
                [tag.tr(tag.td(c) for c in cols[1:])
                 for cols in modified_sources],
                [tag.tr(tag.td(src), tag.td(_('removed'), colspan=4))
                 for spath, src in removed_sources]), class_='props')
        else:
            changes = tag.em(_(' (with no actual effect on merging)'))
        return tag.li(tag_('Property %(prop)s changed', prop=tag.strong(name)),
                      changes)

########NEW FILE########
__FILENAME__ = svn_fs
# -*- coding: utf-8 -*-
#
# Copyright (C)2005-2009 Edgewall Software
# Copyright (C) 2005 Christopher Lenz <cmlenz@gmx.de>
# All rights reserved.
#
# This software is licensed as described in the file COPYING, which
# you should have received as part of this distribution. The terms
# are also available at http://trac.edgewall.org/wiki/TracLicense.
#
# This software consists of voluntary contributions made by many
# individuals. For the exact contribution history, see the revision
# history and logs, available at http://trac.edgewall.org/log/.
#
# Author: Christopher Lenz <cmlenz@gmx.de>

from datetime import datetime
import new
import os.path
import stat
import shutil
import tempfile
import unittest

from StringIO import StringIO

try:
    from svn import core, repos
    has_svn = True
except ImportError:
    has_svn = False

from trac.test import EnvironmentStub, TestSetup
from trac.core import TracError
from trac.resource import Resource, resource_exists
from trac.util.concurrency import get_thread_id
from trac.util.datefmt import utc
from trac.versioncontrol import DbRepositoryProvider, Changeset, Node, \
                                NoSuchChangeset
from tracopt.versioncontrol.svn import svn_fs

REPOS_PATH = os.path.join(tempfile.gettempdir(), 'trac-svnrepos')
REPOS_NAME = 'repo'

HEAD = 22
TETE = 21


class SubversionRepositoryTestSetup(TestSetup):

    def setUp(self):
        dumpfile = open(os.path.join(os.path.split(__file__)[0],
                                     'svnrepos.dump'))

        svn_fs._import_svn()
        core.apr_initialize()
        pool = core.svn_pool_create(None)
        dumpstream = None
        try:
            if os.path.exists(REPOS_PATH):
                print 'trouble ahead with db/rep-cache.db... see #8278'
            r = repos.svn_repos_create(REPOS_PATH, '', '', None, None, pool)
            if hasattr(repos, 'svn_repos_load_fs2'):
                repos.svn_repos_load_fs2(r, dumpfile, StringIO(),
                                        repos.svn_repos_load_uuid_default, '',
                                        0, 0, None, pool)
            else:
                dumpstream = core.svn_stream_from_aprfile(dumpfile, pool)
                repos.svn_repos_load_fs(r, dumpstream, None,
                                        repos.svn_repos_load_uuid_default, '',
                                        None, None, pool)
        finally:
            if dumpstream:
                core.svn_stream_close(dumpstream)
            core.svn_pool_destroy(pool)
            core.apr_terminate()

    def tearDown(self):
        repos.svn_repos_delete(REPOS_PATH)


# -- Re-usable test mixins

class NormalTests(object):

    def test_resource_exists(self):
        repos = Resource('repository', REPOS_NAME)
        self.assertEqual(True, resource_exists(self.env, repos))
        self.assertEqual(False, resource_exists(self.env, repos(id='xxx')))
        node = repos.child('source', u'tte')
        self.assertEqual(True, resource_exists(self.env, node))
        self.assertEqual(False, resource_exists(self.env, node(id='xxx')))
        cset = repos.child('changeset', HEAD)
        self.assertEqual(True, resource_exists(self.env, cset))
        self.assertEqual(False, resource_exists(self.env, cset(id=123456)))

    def test_repos_normalize_path(self):
        self.assertEqual('/', self.repos.normalize_path('/'))
        self.assertEqual('/', self.repos.normalize_path(''))
        self.assertEqual('/', self.repos.normalize_path(None))
        self.assertEqual(u'tte', self.repos.normalize_path(u'tte'))
        self.assertEqual(u'tte', self.repos.normalize_path(u'/tte'))
        self.assertEqual(u'tte', self.repos.normalize_path(u'tte/'))
        self.assertEqual(u'tte', self.repos.normalize_path(u'/tte/'))

    def test_repos_normalize_rev(self):
        self.assertEqual(HEAD, self.repos.normalize_rev('latest'))
        self.assertEqual(HEAD, self.repos.normalize_rev('head'))
        self.assertEqual(HEAD, self.repos.normalize_rev(''))
        self.assertRaises(NoSuchChangeset,
                          self.repos.normalize_rev, 'something else')
        self.assertEqual(HEAD, self.repos.normalize_rev(None))
        self.assertEqual(11, self.repos.normalize_rev('11'))
        self.assertEqual(11, self.repos.normalize_rev(11))

    def test_rev_navigation(self):
        self.assertEqual(1, self.repos.oldest_rev)
        self.assertEqual(None, self.repos.previous_rev(0))
        self.assertEqual(None, self.repos.previous_rev(1))
        self.assertEqual(HEAD, self.repos.youngest_rev)
        self.assertEqual(6, self.repos.next_rev(5))
        self.assertEqual(7, self.repos.next_rev(6))
        # ...
        self.assertEqual(None, self.repos.next_rev(HEAD))
        self.assertRaises(NoSuchChangeset, self.repos.normalize_rev, HEAD + 1)

    def test_rev_path_navigation(self):
        self.assertEqual(1, self.repos.oldest_rev)
        self.assertEqual(None, self.repos.previous_rev(0, u'tte'))
        self.assertEqual(None, self.repos.previous_rev(1, u'tte'))
        self.assertEqual(HEAD, self.repos.youngest_rev)
        self.assertEqual(6, self.repos.next_rev(5, u'tte'))
        self.assertEqual(13, self.repos.next_rev(6, u'tte'))
        # ...
        self.assertEqual(None, self.repos.next_rev(HEAD, u'tte'))
        # test accentuated characters
        self.assertEqual(None,
                         self.repos.previous_rev(17, u'tte/R\xe9sum\xe9.txt'))
        self.assertEqual(17, self.repos.next_rev(16, u'tte/R\xe9sum\xe9.txt'))

    def test_has_node(self):
        self.assertEqual(False, self.repos.has_node(u'/tte/dir1', 3))
        self.assertEqual(True, self.repos.has_node(u'/tte/dir1', 4))
        self.assertEqual(True, self.repos.has_node(u'/tte/dir1'))

    def test_get_node(self):
        node = self.repos.get_node(u'/tte')
        self.assertEqual(u'tte', node.name)
        self.assertEqual(u'/tte', node.path)
        self.assertEqual(Node.DIRECTORY, node.kind)
        self.assertEqual(HEAD, node.rev)
        self.assertEqual(TETE, node.created_rev)
        self.assertEqual(datetime(2007, 4, 30, 17, 45, 26, 234375, utc),
                         node.last_modified)
        node = self.repos.get_node(u'/tte/README.txt')
        self.assertEqual('README.txt', node.name)
        self.assertEqual(u'/tte/README.txt', node.path)
        self.assertEqual(Node.FILE, node.kind)
        self.assertEqual(HEAD, node.rev)
        self.assertEqual(3, node.created_rev)
        self.assertEqual(datetime(2005, 4, 1, 13, 24, 58, 234643, utc),
                         node.last_modified)

    def test_get_node_specific_rev(self):
        node = self.repos.get_node(u'/tte', 1)
        self.assertEqual(u'tte', node.name)
        self.assertEqual(u'/tte', node.path)
        self.assertEqual(Node.DIRECTORY, node.kind)
        self.assertEqual(1, node.rev)
        self.assertEqual(datetime(2005, 4, 1, 10, 0, 52, 353248, utc),
                         node.last_modified)
        node = self.repos.get_node(u'/tte/README.txt', 2)
        self.assertEqual('README.txt', node.name)
        self.assertEqual(u'/tte/README.txt', node.path)
        self.assertEqual(Node.FILE, node.kind)
        self.assertEqual(2, node.rev)
        self.assertEqual(datetime(2005, 4, 1, 13, 12, 18, 216267, utc),
                         node.last_modified)

    def test_get_dir_entries(self):
        node = self.repos.get_node(u'/tte')
        entries = node.get_entries()
        self.assertEqual('dir1', entries.next().name)
        self.assertEqual('mpp_proc', entries.next().name)
        self.assertEqual('v2', entries.next().name)
        self.assertEqual('README3.txt', entries.next().name)
        self.assertEqual(u'R\xe9sum\xe9.txt', entries.next().name)
        self.assertEqual('README.txt', entries.next().name)
        self.assertRaises(StopIteration, entries.next)

    def test_get_file_entries(self):
        node = self.repos.get_node(u'/tte/README.txt')
        entries = node.get_entries()
        self.assertRaises(StopIteration, entries.next)

    def test_get_dir_content(self):
        node = self.repos.get_node(u'/tte')
        self.assertEqual(None, node.content_length)
        self.assertEqual(None, node.content_type)
        self.assertEqual(None, node.get_content())

    def test_get_file_content(self):
        node = self.repos.get_node(u'/tte/README.txt')
        self.assertEqual(8, node.content_length)
        self.assertEqual('text/plain', node.content_type)
        self.assertEqual('A test.\n', node.get_content().read())

    def test_get_dir_properties(self):
        f = self.repos.get_node(u'/tte')
        props = f.get_properties()
        self.assertEqual(1, len(props))

    def test_get_file_properties(self):
        f = self.repos.get_node(u'/tte/README.txt')
        props = f.get_properties()
        self.assertEqual('native', props['svn:eol-style'])
        self.assertEqual('text/plain', props['svn:mime-type'])

    def test_created_path_rev(self):
        node = self.repos.get_node(u'/tte/README3.txt', 15)
        self.assertEqual(15, node.rev)
        self.assertEqual(u'/tte/README3.txt', node.path)
        self.assertEqual(14, node.created_rev)
        self.assertEqual(u'tte/README3.txt', node.created_path)

    def test_created_path_rev_parent_copy(self):
        node = self.repos.get_node('/tags/v1/README.txt', 15)
        self.assertEqual(15, node.rev)
        self.assertEqual('/tags/v1/README.txt', node.path)
        self.assertEqual(3, node.created_rev)
        self.assertEqual(u'tte/README.txt', node.created_path)

    # Revision Log / node history

    def test_get_node_history(self):
        node = self.repos.get_node(u'/tte/README3.txt')
        history = node.get_history()
        self.assertEqual((u'tte/README3.txt', 14, 'copy'), history.next())
        self.assertEqual((u'tte/README2.txt', 6, 'copy'), history.next())
        self.assertEqual((u'tte/README.txt', 3, 'edit'), history.next())
        self.assertEqual((u'tte/README.txt', 2, 'add'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_node_history_limit(self):
        node = self.repos.get_node(u'/tte/README3.txt')
        history = node.get_history(2)
        self.assertEqual((u'tte/README3.txt', 14, 'copy'), history.next())
        self.assertEqual((u'tte/README2.txt', 6, 'copy'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_node_history_follow_copy(self):
        node = self.repos.get_node('/tags/v1/README.txt')
        history = node.get_history()
        self.assertEqual(('tags/v1/README.txt', 7, 'copy'), history.next())
        self.assertEqual((u'tte/README.txt', 3, 'edit'), history.next())
        self.assertEqual((u'tte/README.txt', 2, 'add'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_copy_ancestry(self):
        node = self.repos.get_node('/tags/v1/README.txt')
        ancestry = node.get_copy_ancestry()
        self.assertEqual([(u'tte/README.txt', 6)], ancestry)
        for path, rev in ancestry:
            self.repos.get_node(path, rev) # shouldn't raise NoSuchNode

        node = self.repos.get_node(u'/tte/README3.txt')
        ancestry = node.get_copy_ancestry()
        self.assertEqual([(u'tte/README2.txt', 13),
                          (u'tte/README.txt', 3)], ancestry)
        for path, rev in ancestry:
            self.repos.get_node(path, rev) # shouldn't raise NoSuchNode

        node = self.repos.get_node('/branches/v1x')
        ancestry = node.get_copy_ancestry()
        self.assertEqual([(u'tags/v1.1', 11),
                          (u'branches/v1x', 9),
                          (u'tags/v1', 7),
                          (u'tte', 6)], ancestry)
        for path, rev in ancestry:
            self.repos.get_node(path, rev) # shouldn't raise NoSuchNode

    def test_get_copy_ancestry_for_move(self):
        node = self.repos.get_node(u'/tte/dir1/dir2', 5)
        ancestry = node.get_copy_ancestry()
        self.assertEqual([(u'tte/dir2', 4)], ancestry)
        for path, rev in ancestry:
            self.repos.get_node(path, rev) # shouldn't raise NoSuchNode

    def test_get_branch_origin(self):
        node = self.repos.get_node('/tags/v1/README.txt')
        self.assertEqual(7, node.get_branch_origin())
        node = self.repos.get_node(u'/tte/README3.txt')
        self.assertEqual(14, node.get_branch_origin())
        node = self.repos.get_node('/branches/v1x')
        self.assertEqual(12, node.get_branch_origin())
        node = self.repos.get_node(u'/tte/dir1/dir2', 5)
        self.assertEqual(5, node.get_branch_origin())

    # Revision Log / path history

    def test_get_path_history(self):
        history = self.repos.get_path_history(u'/tte/README2.txt', None)
        self.assertEqual((u'tte/README2.txt', 14, 'delete'), history.next())
        self.assertEqual((u'tte/README2.txt', 6, 'copy'), history.next())
        self.assertEqual((u'tte/README.txt', 3, 'unknown'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_path_history_copied_file(self):
        history = self.repos.get_path_history('/tags/v1/README.txt', None)
        self.assertEqual(('tags/v1/README.txt', 7, 'copy'), history.next())
        self.assertEqual((u'tte/README.txt', 3, 'unknown'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_path_history_copied_dir(self):
        history = self.repos.get_path_history('/branches/v1x', None)
        self.assertEqual(('branches/v1x', 12, 'copy'), history.next())
        self.assertEqual(('tags/v1.1', 10, 'unknown'), history.next())
        self.assertEqual(('branches/v1x', 11, 'delete'), history.next())
        self.assertEqual(('branches/v1x', 9, 'edit'), history.next())
        self.assertEqual(('branches/v1x', 8, 'copy'), history.next())
        self.assertEqual(('tags/v1', 7, 'unknown'), history.next())
        self.assertRaises(StopIteration, history.next)

    # Diffs

    def _cmp_diff(self, expected, got):
        if expected[0]:
            old = self.repos.get_node(*expected[0])
            self.assertEqual((old.path, old.rev), (got[0].path, got[0].rev))
        if expected[1]:
            new = self.repos.get_node(*expected[1])
            self.assertEqual((new.path, new.rev), (got[1].path, got[1].rev))
        self.assertEqual(expected[2], (got[2], got[3]))

    def test_diff_file_different_revs(self):
        diffs = self.repos.get_changes(u'tte/README.txt', 2,
                                       u'tte/README.txt', 3)
        self._cmp_diff(((u'tte/README.txt', 2),
                        (u'tte/README.txt', 3),
                        (Node.FILE, Changeset.EDIT)), diffs.next())
        self.assertRaises(StopIteration, diffs.next)

    def test_diff_file_different_files(self):
        diffs = self.repos.get_changes('branches/v1x/README.txt', 12,
                                      'branches/v1x/README2.txt', 12)
        self._cmp_diff((('branches/v1x/README.txt', 12),
                        ('branches/v1x/README2.txt', 12),
                        (Node.FILE, Changeset.EDIT)), diffs.next())
        self.assertRaises(StopIteration, diffs.next)

    def test_diff_file_no_change(self):
        diffs = self.repos.get_changes(u'tte/README.txt', 7,
                                      'tags/v1/README.txt', 7)
        self.assertRaises(StopIteration, diffs.next)

    def test_diff_dir_different_revs(self):
        diffs = self.repos.get_changes(u'tte', 4, u'tte', 8)
        self._cmp_diff((None, (u'tte/README2.txt', 8),
                        (Node.FILE, Changeset.ADD)), diffs.next())
        self._cmp_diff((None, (u'tte/dir1/dir2', 8),
                        (Node.DIRECTORY, Changeset.ADD)), diffs.next())
        self._cmp_diff((None, (u'tte/dir1/dir3', 8),
                        (Node.DIRECTORY, Changeset.ADD)), diffs.next())
        self._cmp_diff(((u'tte/dir2', 4), None,
                        (Node.DIRECTORY, Changeset.DELETE)), diffs.next())
        self._cmp_diff(((u'tte/dir3', 4), None,
                        (Node.DIRECTORY, Changeset.DELETE)), diffs.next())
        self.assertRaises(StopIteration, diffs.next)

    def test_diff_dir_different_dirs(self):
        diffs = self.repos.get_changes(u'tte', 1, 'branches/v1x', 12)
        self._cmp_diff((None, ('branches/v1x/README.txt', 12),
                        (Node.FILE, Changeset.ADD)), diffs.next())
        self._cmp_diff((None, ('branches/v1x/README2.txt', 12),
                        (Node.FILE, Changeset.ADD)), diffs.next())
        self._cmp_diff((None, ('branches/v1x/dir1', 12),
                        (Node.DIRECTORY, Changeset.ADD)), diffs.next())
        self._cmp_diff((None, ('branches/v1x/dir1/dir2', 12),
                        (Node.DIRECTORY, Changeset.ADD)), diffs.next())
        self._cmp_diff((None, ('branches/v1x/dir1/dir3', 12),
                        (Node.DIRECTORY, Changeset.ADD)), diffs.next())
        self.assertRaises(StopIteration, diffs.next)

    def test_diff_dir_no_change(self):
        diffs = self.repos.get_changes(u'tte', 7,
                                      'tags/v1', 7)
        self.assertRaises(StopIteration, diffs.next)

    # Changesets

    def test_changeset_repos_creation(self):
        chgset = self.repos.get_changeset(0)
        self.assertEqual(0, chgset.rev)
        self.assertEqual('', chgset.message)
        self.assertEqual('', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 9, 57, 41, 312767, utc),
                         chgset.date)
        self.assertRaises(StopIteration, chgset.get_changes().next)

    def test_changeset_added_dirs(self):
        chgset = self.repos.get_changeset(1)
        self.assertEqual(1, chgset.rev)
        self.assertEqual('Initial directory layout.', chgset.message)
        self.assertEqual('john', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 10, 0, 52, 353248, utc),
                         chgset.date)

        changes = chgset.get_changes()
        self.assertEqual(('branches', Node.DIRECTORY, Changeset.ADD, None, -1),
                         changes.next())
        self.assertEqual(('tags', Node.DIRECTORY, Changeset.ADD, None, -1),
                         changes.next())
        self.assertEqual((u'tte', Node.DIRECTORY, Changeset.ADD, None, -1),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_file_edit(self):
        chgset = self.repos.get_changeset(3)
        self.assertEqual(3, chgset.rev)
        self.assertEqual('Fixed README.\n', chgset.message)
        self.assertEqual('kate', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 13, 24, 58, 234643, utc),
                         chgset.date)

        changes = chgset.get_changes()
        self.assertEqual((u'tte/README.txt', Node.FILE, Changeset.EDIT,
                          u'tte/README.txt', 2), changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_dir_moves(self):
        chgset = self.repos.get_changeset(5)
        self.assertEqual(5, chgset.rev)
        self.assertEqual('Moved directories.', chgset.message)
        self.assertEqual('kate', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 16, 25, 39, 658099, utc),
                         chgset.date)

        changes = chgset.get_changes()
        self.assertEqual((u'tte/dir1/dir2', Node.DIRECTORY, Changeset.MOVE,
                          u'tte/dir2', 4), changes.next())
        self.assertEqual((u'tte/dir1/dir3', Node.DIRECTORY, Changeset.MOVE,
                          u'tte/dir3', 4), changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_file_copy(self):
        chgset = self.repos.get_changeset(6)
        self.assertEqual(6, chgset.rev)
        self.assertEqual('More things to read', chgset.message)
        self.assertEqual('john', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 18, 56, 46, 985846, utc),
                         chgset.date)

        changes = chgset.get_changes()
        self.assertEqual((u'tte/README2.txt', Node.FILE, Changeset.COPY,
                          u'tte/README.txt', 3), changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_root_propset(self):
        chgset = self.repos.get_changeset(13)
        self.assertEqual(13, chgset.rev)
        self.assertEqual('Setting property on the repository_dir root',
                         chgset.message)
        changes = chgset.get_changes()
        self.assertEqual(('/', Node.DIRECTORY, Changeset.EDIT, '/', 12),
                         changes.next())
        self.assertEqual((u'tte', Node.DIRECTORY, Changeset.EDIT, u'tte', 6),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_base_path_rev(self):
        chgset = self.repos.get_changeset(9)
        self.assertEqual(9, chgset.rev)
        changes = chgset.get_changes()
        self.assertEqual(('branches/v1x/README.txt', Node.FILE,
                          Changeset.EDIT, u'tte/README.txt', 3),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_rename_and_edit(self):
        chgset = self.repos.get_changeset(14)
        self.assertEqual(14, chgset.rev)
        changes = chgset.get_changes()
        self.assertEqual((u'tte/README3.txt', Node.FILE,
                          Changeset.MOVE, u'tte/README2.txt', 13),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_edit_after_wc2wc_copy__original_deleted(self):
        chgset = self.repos.get_changeset(16)
        self.assertEqual(16, chgset.rev)
        changes = chgset.get_changes()
        self.assertEqual(('branches/v2', Node.DIRECTORY, Changeset.COPY,
                          'tags/v1.1', 14),
                         changes.next())
        self.assertEqual(('branches/v2/README2.txt', Node.FILE,
                          Changeset.EDIT, u'tte/README2.txt', 6),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_fancy_rename_double_delete(self):
        chgset = self.repos.get_changeset(19)
        self.assertEqual(19, chgset.rev)
        changes = chgset.get_changes()
        self.assertEqual((u'tte/mpp_proc', Node.DIRECTORY,
                          Changeset.MOVE, u'tte/Xprimary_proc', 18),
                         changes.next())
        self.assertEqual((u'tte/mpp_proc/Xprimary_pkg.vhd',
                          Node.FILE, Changeset.DELETE,
                          u'tte/Xprimary_proc/Xprimary_pkg.vhd', 18),
                         changes.next())
        self.assertEqual((u'tte/mpp_proc/Xprimary_proc', Node.DIRECTORY,
                          Changeset.COPY, u'tte/Xprimary_proc', 18),
                         changes.next())
        self.assertEqual((u'tte/mpp_proc/Xprimary_proc/Xprimary_pkg.vhd',
                          Node.FILE, Changeset.DELETE,
                          u'tte/Xprimary_proc/Xprimary_pkg.vhd', 18),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_copy_with_deletions_below_copy(self):
        """Regression test for #4900."""
        chgset = self.repos.get_changeset(22)
        self.assertEqual(22, chgset.rev)
        changes = chgset.get_changes()
        self.assertEqual((u'branches/v3', 'dir', 'copy',
                          u'tte', 21), changes.next())
        self.assertEqual((u'branches/v3/dir1', 'dir', 'delete',
                          u'tte/dir1', 21), changes.next())
        self.assertEqual((u'branches/v3/mpp_proc', 'dir', 'delete',
                          u'tte/mpp_proc', 21), changes.next())
        self.assertEqual((u'branches/v3/v2', 'dir', 'delete',
                          u'tte/v2', 21), changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_utf_8(self):
        chgset = self.repos.get_changeset(20)
        self.assertEqual(20, chgset.rev)
        self.assertEqual(u'Chez moi a marche\n', chgset.message)
        self.assertEqual(u'Jonas Borgstrm', chgset.author)



class ScopedTests(object):

    def test_repos_normalize_path(self):
        self.assertEqual('/', self.repos.normalize_path('/'))
        self.assertEqual('/', self.repos.normalize_path(''))
        self.assertEqual('/', self.repos.normalize_path(None))
        self.assertEqual('dir1', self.repos.normalize_path('dir1'))
        self.assertEqual('dir1', self.repos.normalize_path('/dir1'))
        self.assertEqual('dir1', self.repos.normalize_path('dir1/'))
        self.assertEqual('dir1', self.repos.normalize_path('/dir1/'))

    def test_repos_normalize_rev(self):
        self.assertEqual(TETE, self.repos.normalize_rev('latest'))
        self.assertEqual(TETE, self.repos.normalize_rev('head'))
        self.assertEqual(TETE, self.repos.normalize_rev(''))
        self.assertEqual(TETE, self.repos.normalize_rev(None))
        self.assertEqual(5, self.repos.normalize_rev('5'))
        self.assertEqual(5, self.repos.normalize_rev(5))

    def test_rev_navigation(self):
        self.assertEqual(1, self.repos.oldest_rev)
        self.assertEqual(None, self.repos.previous_rev(0))
        self.assertEqual(1, self.repos.previous_rev(2))
        self.assertEqual(TETE, self.repos.youngest_rev)
        self.assertEqual(2, self.repos.next_rev(1))
        self.assertEqual(3, self.repos.next_rev(2))
        # ...
        self.assertEqual(None, self.repos.next_rev(TETE))

    def test_has_node(self):
        self.assertEqual(False, self.repos.has_node('/dir1', 3))
        self.assertEqual(True, self.repos.has_node('/dir1', 4))

    def test_get_node(self):
        node = self.repos.get_node('/dir1')
        self.assertEqual('dir1', node.name)
        self.assertEqual('/dir1', node.path)
        self.assertEqual(Node.DIRECTORY, node.kind)
        self.assertEqual(TETE, node.rev)
        self.assertEqual(5, node.created_rev)
        self.assertEqual(datetime(2005, 4, 1, 16, 25, 39, 658099, utc),
                         node.last_modified)
        node = self.repos.get_node('/README.txt')
        self.assertEqual('README.txt', node.name)
        self.assertEqual('/README.txt', node.path)
        self.assertEqual(Node.FILE, node.kind)
        self.assertEqual(TETE, node.rev)
        self.assertEqual(3, node.created_rev)
        self.assertEqual(datetime(2005, 4, 1, 13, 24, 58, 234643, utc),
                         node.last_modified)

    def test_get_node_specific_rev(self):
        node = self.repos.get_node('/dir1', 4)
        self.assertEqual('dir1', node.name)
        self.assertEqual('/dir1', node.path)
        self.assertEqual(Node.DIRECTORY, node.kind)
        self.assertEqual(4, node.rev)
        self.assertEqual(datetime(2005, 4, 1, 15, 42, 35, 450595, utc),
                         node.last_modified)
        node = self.repos.get_node('/README.txt', 2)
        self.assertEqual('README.txt', node.name)
        self.assertEqual('/README.txt', node.path)
        self.assertEqual(Node.FILE, node.kind)
        self.assertEqual(2, node.rev)
        self.assertEqual(datetime(2005, 4, 1, 13, 12, 18, 216267, utc),
                         node.last_modified)

    def test_get_dir_entries(self):
        node = self.repos.get_node('/')
        entries = node.get_entries()
        self.assertEqual('dir1', entries.next().name)
        self.assertEqual('mpp_proc', entries.next().name)
        self.assertEqual('v2', entries.next().name)
        self.assertEqual('README3.txt', entries.next().name)
        self.assertEqual(u'R\xe9sum\xe9.txt', entries.next().name)
        self.assertEqual('README.txt', entries.next().name)
        self.assertRaises(StopIteration, entries.next)

    def test_get_file_entries(self):
        node = self.repos.get_node('/README.txt')
        entries = node.get_entries()
        self.assertRaises(StopIteration, entries.next)

    def test_get_dir_content(self):
        node = self.repos.get_node('/dir1')
        self.assertEqual(None, node.content_length)
        self.assertEqual(None, node.content_type)
        self.assertEqual(None, node.get_content())

    def test_get_file_content(self):
        node = self.repos.get_node('/README.txt')
        self.assertEqual(8, node.content_length)
        self.assertEqual('text/plain', node.content_type)
        self.assertEqual('A test.\n', node.get_content().read())

    def test_get_dir_properties(self):
        f = self.repos.get_node('/dir1')
        props = f.get_properties()
        self.assertEqual(0, len(props))

    def test_get_file_properties(self):
        f = self.repos.get_node('/README.txt')
        props = f.get_properties()
        self.assertEqual('native', props['svn:eol-style'])
        self.assertEqual('text/plain', props['svn:mime-type'])

    # Revision Log / node history

    def test_get_history_scope(self):
        """Regression test for #9504"""
        node = self.repos.get_node('/')
        history = list(node.get_history())
        self.assertEqual(('/', 1, 'add'), history[-1])
        initial_cset = self.repos.get_changeset(history[-1][1])
        self.assertEqual(1, initial_cset.rev)

    def test_get_node_history(self):
        node = self.repos.get_node('/README3.txt')
        history = node.get_history()
        self.assertEqual(('README3.txt', 14, 'copy'), history.next())
        self.assertEqual(('README2.txt', 6, 'copy'), history.next())
        self.assertEqual(('README.txt', 3, 'edit'), history.next())
        self.assertEqual(('README.txt', 2, 'add'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_node_history_follow_copy(self):
        node = self.repos.get_node('dir1/dir3', )
        history = node.get_history()
        self.assertEqual(('dir1/dir3', 5, 'copy'), history.next())
        self.assertEqual(('dir3', 4, 'add'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_copy_ancestry(self):
        node = self.repos.get_node(u'/README3.txt')
        ancestry = node.get_copy_ancestry()
        self.assertEqual([(u'README2.txt', 13),
                          (u'README.txt', 3)], ancestry)
        for path, rev in ancestry:
            self.repos.get_node(path, rev) # shouldn't raise NoSuchNode

    def test_get_copy_ancestry_for_move(self):
        node = self.repos.get_node(u'/dir1/dir2', 5)
        ancestry = node.get_copy_ancestry()
        self.assertEqual([(u'dir2', 4)], ancestry)
        for path, rev in ancestry:
            self.repos.get_node(path, rev) # shouldn't raise NoSuchNode

    def test_get_branch_origin(self):
        node = self.repos.get_node(u'/README3.txt')
        self.assertEqual(14, node.get_branch_origin())
        node = self.repos.get_node(u'/dir1/dir2', 5)
        self.assertEqual(5, node.get_branch_origin())

    # Revision Log / path history

    def test_get_path_history(self):
        history = self.repos.get_path_history('dir3', None)
        self.assertEqual(('dir3', 5, 'delete'), history.next())
        self.assertEqual(('dir3', 4, 'add'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_path_history_copied_file(self):
        history = self.repos.get_path_history('README3.txt', None)
        self.assertEqual(('README3.txt', 14, 'copy'), history.next())
        self.assertEqual(('README2.txt', 6, 'unknown'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_get_path_history_copied_dir(self):
        history = self.repos.get_path_history('dir1/dir3', None)
        self.assertEqual(('dir1/dir3', 5, 'copy'), history.next())
        self.assertEqual(('dir3', 4, 'unknown'), history.next())
        self.assertRaises(StopIteration, history.next)

    def test_changeset_repos_creation(self):
        chgset = self.repos.get_changeset(0)
        self.assertEqual(0, chgset.rev)
        self.assertEqual('', chgset.message)
        self.assertEqual('', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 9, 57, 41, 312767, utc),
                         chgset.date)
        self.assertRaises(StopIteration, chgset.get_changes().next)

    def test_changeset_added_dirs(self):
        chgset = self.repos.get_changeset(4)
        self.assertEqual(4, chgset.rev)
        self.assertEqual('More directories.', chgset.message)
        self.assertEqual('john', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 15, 42, 35, 450595, utc),
                         chgset.date)

        changes = chgset.get_changes()
        self.assertEqual(('dir1', Node.DIRECTORY, 'add', None, -1),
                         changes.next())
        self.assertEqual(('dir2', Node.DIRECTORY, 'add', None, -1),
                         changes.next())
        self.assertEqual(('dir3', Node.DIRECTORY, 'add', None, -1),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_file_edit(self):
        chgset = self.repos.get_changeset(3)
        self.assertEqual(3, chgset.rev)
        self.assertEqual('Fixed README.\n', chgset.message)
        self.assertEqual('kate', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 13, 24, 58, 234643, utc),
                         chgset.date)

        changes = chgset.get_changes()
        self.assertEqual(('README.txt', Node.FILE, Changeset.EDIT,
                          'README.txt', 2), changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_dir_moves(self):
        chgset = self.repos.get_changeset(5)
        self.assertEqual(5, chgset.rev)
        self.assertEqual('Moved directories.', chgset.message)
        self.assertEqual('kate', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 16, 25, 39, 658099, utc),
                         chgset.date)

        changes = chgset.get_changes()
        self.assertEqual(('dir1/dir2', Node.DIRECTORY, Changeset.MOVE,
                          'dir2', 4), changes.next())
        self.assertEqual(('dir1/dir3', Node.DIRECTORY, Changeset.MOVE,
                          'dir3', 4), changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_file_copy(self):
        chgset = self.repos.get_changeset(6)
        self.assertEqual(6, chgset.rev)
        self.assertEqual('More things to read', chgset.message)
        self.assertEqual('john', chgset.author)
        self.assertEqual(datetime(2005, 4, 1, 18, 56, 46, 985846, utc),
                         chgset.date)

        changes = chgset.get_changes()
        self.assertEqual(('README2.txt', Node.FILE, Changeset.COPY,
                          'README.txt', 3), changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_root_propset(self):
        chgset = self.repos.get_changeset(13)
        self.assertEqual(13, chgset.rev)
        self.assertEqual('Setting property on the repository_dir root',
                         chgset.message)
        changes = chgset.get_changes()
        self.assertEqual(('/', Node.DIRECTORY, Changeset.EDIT, '/', 6),
                         changes.next())
        self.assertRaises(StopIteration, changes.next)

    def test_changeset_copy_from_outside_and_delete(self):
        chgset = self.repos.get_changeset(21)
        self.assertEqual(21, chgset.rev)
        self.assertEqual('copy from outside of the scope + delete',
                         chgset.message)
        changes = chgset.get_changes()
        self.assertEqual(('v2', Node.DIRECTORY, Changeset.ADD, None, -1),
                         changes.next())
        self.assertEqual(('v2/README2.txt', Node.FILE, Changeset.DELETE,
                          None, -1), changes.next())
        self.assertEqual(('v2/dir1', Node.DIRECTORY, Changeset.DELETE,
                          None, -1), changes.next())
        self.assertRaises(StopIteration, changes.next)


class RecentPathScopedTests(object):

    def test_rev_navigation(self):
        self.assertEqual(False, self.repos.has_node('/', 1))
        self.assertEqual(False, self.repos.has_node('/', 2))
        self.assertEqual(False, self.repos.has_node('/', 3))
        self.assertEqual(True, self.repos.has_node('/', 4))
        # We can't make this work anymore because of #5213.
        # self.assertEqual(4, self.repos.oldest_rev)
        self.assertEqual(1, self.repos.oldest_rev) # should really be 4...
        self.assertEqual(None, self.repos.previous_rev(4))


class NonSelfContainedScopedTests(object):

    def test_mixed_changeset(self):
        chgset = self.repos.get_changeset(7)
        self.assertEqual(7, chgset.rev)
        changes = chgset.get_changes()
        self.assertEqual(('/', Node.DIRECTORY, Changeset.ADD, None, -1),
                         changes.next())
        self.assertRaises(TracError, lambda: self.repos.get_node(None, 6))


class AnotherNonSelfContainedScopedTests(object):

    def test_mixed_changeset_with_edit(self):
        chgset = self.repos.get_changeset(9)
        self.assertEqual(9, chgset.rev)
        changes = chgset.get_changes()
        self.assertEqual(('v1x/README.txt', Node.FILE, Changeset.EDIT,
                          'v1x/README.txt', 8),
                         changes.next())


# -- Test cases for SubversionRepository

class SubversionRepositoryTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        repositories = self.env.config['repositories']
        DbRepositoryProvider(self.env).add_repository(REPOS_NAME, self.path,
                                                      'direct-svnfs')
        self.repos = self.env.get_repository(REPOS_NAME)

    def tearDown(self):
        self.env.reset_db()
        # needed to avoid issue with 'WindowsError: The process cannot access
        # the file ... being used by another process: ...\rep-cache.db'
        self.env.shutdown(get_thread_id())


# -- Test cases for SvnCachedRepository

class SvnCachedRepositoryTestCase(unittest.TestCase):

    def setUp(self):
        self.env = EnvironmentStub()
        DbRepositoryProvider(self.env).add_repository(REPOS_NAME, self.path,
                                                      'svn')
        self.repos = self.env.get_repository(REPOS_NAME)
        self.repos.sync()

    def tearDown(self):
        self.env.reset_db()
        self.repos.close()
        self.repos = None


def suite():
    suite = unittest.TestSuite()
    if has_svn:
        tests = [(NormalTests, ''),
                 (ScopedTests, u'/tte'),
                 (RecentPathScopedTests, u'/tte/dir1'),
                 (NonSelfContainedScopedTests, '/tags/v1'),
                 (AnotherNonSelfContainedScopedTests, '/branches'),
                 ]
        skipped = {
            'SvnCachedRepositoryNormalTests': [
                'test_changeset_repos_creation',
                ],
            'SvnCachedRepositoryScopedTests': [
                'test_changeset_repos_creation',
                'test_rev_navigation',
                ],
            }
        for test, scope in tests:
            tc = new.classobj('SubversionRepository' + test.__name__,
                              (SubversionRepositoryTestCase, test),
                              {'path': REPOS_PATH + scope})
            suite.addTest(unittest.makeSuite(
                tc, 'test', suiteClass=SubversionRepositoryTestSetup))
            tc = new.classobj('SvnCachedRepository' + test.__name__,
                              (SvnCachedRepositoryTestCase, test),
                              {'path': REPOS_PATH + scope})
            for skip in skipped.get(tc.__name__, []):
                setattr(tc, skip, lambda self: None) # no skip, so we cheat...
            suite.addTest(unittest.makeSuite(
                tc, 'test', suiteClass=SubversionRepositoryTestSetup))
    else:
        print("SKIP: tracopt/versioncontrol/svn/tests/svn_fs.py (no svn "
              "bindings)")
    return suite

if __name__ == '__main__':
    runner = unittest.TextTestRunner()
    runner.run(suite())

########NEW FILE########
