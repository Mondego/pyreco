Action Bar 是几乎每个App都有东西，大概样子就是：  
![action_bar](http://foofish.qiniudn.com/actionbar-actions.png)

这个ActionBar仅支持Android3.0(API level11)以上的版本。因此你设置`AndroidManifest.xml`：  
    
    <manifest ... >
        <uses-sdk android:minSdkVersion="11" ... />
        ...
    </manifest>

所有action按钮和items定义在res/menu目录下面， 


###Android应用的组成部分
**Activities**：应用的展示层，应用的UI由一个或多个Activity类构建而成，Activities使用Fragements和Views来布局和显示信息，响应用户的动作，和桌面应用开发对比，Activities等效于窗体。  
**Services**：应用中不可见的worker，这个组件不需要UI就能运行，用于更新数据源和Activities，触发通知和广播Intents。通常用在执行长期运行的任务场景中。  
**Content Providers**：这是一个可共享的持久化数据存储，它管理和持久化应用的数据，通常是与SQL数据库交互。  
**Intents**：一个强大的消息传递框架，可以使用Intents开启或者停止Acitivities和Services，或者是请求一个动作。  
**Broadcast Receivers**：Intent监听器。  
**Widgets**：可视化的应用组件，通常是放在设备的主屏幕上。  
**Notification**：Notification可以在不打断当前Activity的同时提醒用户。 
###Android应用的生命周期
默认情况下，Android应用运行在自己的进程中，每个进程是一个独立的Dalvik实例。
 

1. 下载Android SDK
2. 安装ADT插件(Eclipse)
3. 下载最新的SDK工具和平台用于SDK管理

直接下载[SDK ADT Bundle](https://dl.google.com/android/adt/22.6.2/adt-bundle-windows-x86_64-20140321.zip)，这是一个工具包含有了所有开发所需要的工具，包括（Android SDK组件，Eclipse IDE和内建的ADT（android developer tools）

下载解压完成后，创建第一个Android应用，直接点下一步直到最后完成就可以了。  

创建完成后，项目的目录结构如下：

![](http://foofish.qiniudn.com/layout1.png)
####AndroidManifest.xml
每个Android project都会有一个manifest文件，AdnroidManifest.xml，位于工程的根目录下面，manifest文件定义了app的结构和元数据以及所需组件和一些requirements。包括了组成应用的每个Activities，Services，Content Providers和Broacast Receivers节点，使用Intent Filter和Permission来决定如何与其它应用交互。 元数据如icon，版本号，主题。  

其中`<uses-sdk>`元素用来兼容Android的版本信息的。你应该这样设置：  

    <manifest xmlns:android="http://schemas.android.com/apk/res/android" ... >
        <uses-sdk android:minSdkVersion="8" android:targetSdkVersion="19" />
        ...
    </manifest>

####在模拟器上运行
在模拟器上运行app，首先需要创建一个AVD(Android Virtual Device)，这是一个Android模拟器的设备配置，他能模仿不同的设备。  
![](http://foofish.qiniudn.com/avd.png)

设置好AVD参数后，点击 Start--〉Launch，然后就能看到一个虚拟的Android设备了，看到下面的图要等很久。  
![](http://foofish.qiniudn.com/emulator.png)

接下来打开AndroidManifest.xml，然后选择Eclipse工具栏中的Run---〉Run As---〉Android Application，这样你的app就安装到了模拟器中去了。

在真机上运行的话只要把手机调为DEBUG模式就可以了。  


###构建一个简单的UI









Download the Android SDK.
Install the ADT plugin for Eclipse (if you’ll use the Eclipse IDE).
Download the latest SDK tools and platforms using the SDK Manager.


####构建一个简单的UI

Android的GUI由View和ViewGroup对象构成，View指的就是那些Button，Textfield等等。ViewGroup就是指view容器。  

Android可以直接通过XML配置文件来定义UI。  

![viewgroup](http://foofish.qiniudn.com/viewgroup.png)

####创建一个Linear布局
打开res/layout/framgment_main.xml，删掉`<RelativeLayout>`换成`<LinearLayout>`：  

    <LinearLayout xmlns:android="http://schemas.android.com/apk/res/android"
        xmlns:tools="http://schemas.android.com/tools"
        android:layout_width="match_parent"
        android:layout_height="match_parent"
        android:orientation="horizontal" >
    </LinearLayout>

LinearLayout 就是一个view group，在<LinearLayout>添加一个View：  

    <EditText android:id="@+id/edit_message"
            android:layout_width="wrap_content"
            android:layout_height="wrap_content"
            android:hint="@string/edit_message" />

android:id 是这个view的唯一标识符，可以在代码中通过这个id来操作这个对象。  

`wrap_content` 就是指view的宽度和高度根据view的内容填充大小。 如果是用"match_parent"就是跟父对象的大小一样。  

android:hint 指view的内容为空的时候的指，此时你的edit_message还没定义，因此会报错   

####添加String Resources
String resources可以在一个单独的地方管理所有UI文本，这样更易查找和更新文本。默认情况下project的string resource文件在res/values/strings.xml下面。现在添加一个新的字符串"edit_message"设置为"输入消息".  

    <?xml version="1.0" encoding="utf-8"?>
    <resources>
    
        <string name="app_name">defish</string>
        <string name="dummy_button">Dummy Button</string>
        <string name="dummy_content">DUMMY\nCONTENT</string>
        <string name="edit_message">输入消息</string>
    
    </resources>
    

格式更好的布局  

    <EditText
        android:id="@+id/edit_message"
        android:layout_width="0dp"
        android:layout_height="wrap_content"
        android:layout_weight="1"
        android:hint="@string/edit_message" />
    <Button
        android:layout_width="wrap_content"
        android:layout_height="wrap_content"
        android:text="@string/button_send" />

    

Android常用命令
==================

    adb devices             #列出所有设备  
    adb [ -s 设备id] shell  #远程登录到设备 
    


通过点击按钮进入到一个新的activity  

####添加按钮响应事件

`android:onClick`

    <Button
        android:layout_width="wrap_content"
        android:layout_height="wrap_content"
        android:text="@string/button_send"
        android:onClick="sendMessage" />
    
sendMessage是activity里面的方法名，当用户点击此按钮的时候系统会调用该方法。  
貌似在这个方法里面输出syso，没有任何消息输出。 更新：有输出， 在logcat里面可以看到   

####构建一个Intent
Intent的意思就是"intent to do something"，打算去做某事。通常用来启动另一个activity。  

现在在sendMessage方法中创建一个Intent来启动一个叫DisplayMessasgeActivity。  

    Intent intent = new Intent(this, DisplayMessageActivity.class);

this 是 Context对象，Activity是Context的一个子类。 完整代码：  

    public void sendMessage(View view){
    		Intent itent = new Intent(this, DislapyMessageActivity.class);
    		EditText et = (EditText)findViewById(R.id.edit_message);
    		itent.putExtra(EXTRA_MESSAGE, et.getText().toString());
    		startActivity(itent);  //关键步骤
    	}

接下来是写`DisplayMessasgeActivity`，直接new Activity，继承ActionBarActivity。然后覆盖onCreate()方法       

	@Override
	protected void onCreate(Bundle savedInstanceState) {
		super.onCreate(savedInstanceState);
		
		
		Intent intent = getIntent();
		String message = intent.getStringExtra(MainActivity.EXTRA_MESSAGE);
		
		TextView textview = new TextView(this);
		textview.setText(message);
		setContentView(textview);
		
	}



Android应用程序中的主要组件：  

Activity：一个窗口或者一个对话框表示一个Activity。


findViewById()方法要在setContentView()之后调用，否者是找不到view的。  

####Tree
对于大量的数据，线性表的访问速度太慢，

         A
        / \ 
       /   \
      B     C
     / \   / \  
    D   E  F  G 
中序遍历：它首先遍历左子树，然后访问根节点，最后遍历右子树（左根右），上图按中序遍历的结果是：**DBEAFCG**  

后序遍历：首先遍历左子树，然后遍历右子树，最后遍历根节点（左右根），上图按后序遍历的结果是：**DEBFGCA**  

前序遍历：首先访问根节点，然后遍历左子树，最后遍历右子树（根左右），上图按前序遍历的结果是：**ABDECFG**  

前中后主要看根节点，根节点在中间就是中序遍历，依此类推。  

####术语
节点的度：一个节点含有的子树的个数称为该节点的度，例如A节点的度为：2  
树的度：一颗树中，最大节点的度称为树的度，最大节点的度为2，所以上图树的度为2  
树的深度/高度：树的层数称为树的高度，根节点的层次为1，上图树的高度为3  

#####二叉树
二叉树的每个节点至多有两颗子树，（即二叉树中不存在度大于2的节点）。因此二叉树有如下几种型情。  
+ 空二叉树
+ 仅有根节点的二叉树
+ 右子树为空的二叉树
+ 左子树为空的二叉树
+ 左右子树均非空的二叉树
#####二叉树的性质
1. 在二叉树的第i层，至多有2的(i-1)次方个节点
2. 深度为k的二叉树至多有2的k次方-1个节点
3. 任意一颗二叉树T，如果终端节点数为n，度为2的节点数为m，那么n = m+1

深度为k且有2的k次方-1个节点的二叉树称为**满二叉树**，它的特点是每一层上的非叶子节点都有2个节点  
**完全二叉树**：深度为k的，有n个节点的二叉树，当且仅当每一个节点都与深度为k的满二叉树中编号从1至n的节点一一对应时，称之为完全二叉树  



斐波那契数列(Fibonacci)递归与非递归的性能对比
===============================================
费波那契数列由0和1开始，之后的数就由之前的两数相加 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987, 1597, 2584,……….  
####递归算法
用递归算法来求值,非常好理解.伪代码:  

    f(n) = 0                (n=0)
    f(n) = 1                (n=1)
    f(n) = f(n-1) + f(n-2)  (n>1)
实现:  

    def f(n):
        if n==0:
            return 0
        elif n==1:
            return 1
        elif n>1:
            return f(n-1) + f(n-2)

####非递归算法

    def f(n):
        if n == 0:
            return 0
        if n == 1:
            return 1
        if n>1:

            prev = 1    #第n-1项的值
            p_prev = 0  #第n-2项的值
            result = 1  #第n项的值

            for i in range(1,n):
               result = prev+p_prev 
               p_prev = prev
               prev = result
            return result

功能实现了,但是代码比较冗长,函数是要对前两项做特殊判断.现在优化一下,如何才能更通用,即使是第0个和第1个也能运用到for循环呢?假设在 0, 1, 1, 2, 3, 5, 8, 13... 之前还有两项, 是-1和1, 即: -1, 1, 0, 1, 1, 2, 3, 5, 8, 13, 21, 34,这样就通用了:  

    def f(n):
        prev = 1
        p_prev = -1
        result = 0
        for i in range(n+1):
            result = prev+p_prev
            p_prev = prev
            prev = result
        return result

现在评估一下他们的性能:  写一个性能装饰器.  

    def perfromce_profile(func):
        def wrapper(*args, **kwargs):
            start = time.time()
            rtn = func(*args, **kwargs)
            end = time.time()
            print end-start
            return rtn
        return wrapper
他不能用在递归方法中. 所以最终还是写了这么个方法:  

    import time
    
    def f0(n):
        if n==0:
            return 0
        elif n==1:
            return 1
        elif n>1:
            return f(n-1) + f(n-2)
    
    def f(n):
          prev = 1
          p_prev = -1
          result = 0
          for i in range(n+1):
              result = prev+p_prev
              p_prev = prev
              prev = result
          return result   
    
    def perfromce_profile():
        start = time.time()
        f0(1000000)
        end = time.time()
        print end-start
        start = time.time()
        f(1000000)
        print time.time()-start
    
    
    
    if __name__ == '__main__':
        perfromce_profile() 

看出性能对比了吧:  

    54.2904469967
    27.7642970085

所以用递归弊端还是不少

git 常用命令解析
 ==================
###git merge 合并分支
merge 的功能就是做分支合并，假如分支结构如下：  

                               master
                              /
     C0 ---- C1 ---- C2 ---- C4
                         \
                         C3 ---- C5
                                  \
                                   issueFix

切换到master分支  

    $git checkout master

把issueFix分支的内容合并（merge）到当前分支（master）  

    $git merge issueFix

 统计代码行数

    git ls-files | xargs wc -l
统计python代码行数

    git ls-files | grep .py | xargs wc -l

http://blog.csdn.net/robinblog/article/details/17967991

hg pull
hg branch 查看当前分支
hg branches 列出分支

hg update branch_name 切换分支

hg commit 

hg push

hg branch newbranch 创建分支，新创建的分支下次commit的时候才能生成

分支合并：  
hg update 将要关闭的分支
hg commit --close-branch 
hg update default
hg merge 将要关闭的分支

今天无意中看到据说是[史上最简单的Git教程](http://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000)，看完后又学到了不少新东西，把自己学到东西总结并记录下，否则总觉得少了些什么东西。  

下面用一张图来说明工作区（working directory）、版本库（Repository）、暂存区（stage），以及分支的概念。  
![git](../resource/image/git.jpg)

下面解释不是完全严谨，请结合上图来理解下面四个概念。  
**工作区（working dicrectory）**：包含.git目录的父目录一般就是工作区，就是我们的工程目录。新创建的文件都处于工作区，此时还没有加入到后面要解释的的暂缓区。  

**版本库（Repository）**：.git目录就是版本库，版本管理的相关文件都在此目录下。  

**暂缓区（stage）**：对于曾经加入了版本控制的文件作了修改后，执行`git add `后的文件就进入暂缓区。  

**分支**：git初始会默认创建一个master分支，执行`git commit`后，暂缓区的文件就到了分支里面。  

如下有一个readme.rst文件是已经加入了版本库的，现在对内容进行修改后，查看下状态  

    E:\Users\liuzhijun\workspace\blog>git status

    # On branch master
    # Your branch is ahead of 'origin/master' by 4 commits.
    #   (use "git push" to publish your local commits)
    #
    # Changes not staged for commit:
    #   (use "git add <file>..." to update what will be committed)
    #   (use "git checkout -- <file>..." to discard changes in working d
    #
    #       modified:   README.rst
    #
    no changes added to commit (use "git add" and/or "git commit -a")


git提示README.rst已经修改了，但还不是暂缓区的文件（not staged），待commit。接着还告诉你可以进行怎么的操作，`checkout`指撤销本次修改，注意后面有`--`，如果不带这个字符，checkout又是另外一层意思了。  

####退回到指定版本
退回到指定版本使用命令`git reset --hard <version>`， HEAD始终指向当前版本，HEAD^^表示上一个版本。如果想退回到上一个版本就可以使用：

    git reset --hard HEAD^^  
如果想退回到指定的某个版本呢？可以使用`git log`查看获取commit 版本号：  

    commit 33b351ae746edaf3fd5a56a0318235096b6ed1ce
    Author: liuzhijun <lzjun567@gmail.com>
    Date:   Sat Mar 15 11:43:56 2014 +0800
        commit many files

    commit 86eefaaea5251fa5707ecd02009c893c098ab6cd
    Author: liuzhijun <lzjun567@gmai..com>
    Date:   Thu Mar 14 03:20:27 2013 +0800
    
        add author myself

commit 后面的那串就是版本号， 一般只要选择前面几位就可以了。git会自动去查找。  
    
    git reset --hard 86eefa
执行上面的命令就是退回到指定的版本，如果现在我又反悔了，想恢复到最近的那个版本怎么办？只要你还记得这个最近的版本号的话直接执行如上的命令就好了，但是谁会去记这个号啊？那么还有一个办法是使用`git reflog`查看，这个指令记录了每次的操作。  

    E:\Users\liuzhijun\workspace\blog>git reflog
    a11c917 HEAD@{0}: reset: moving to a11c
            HEAD@{1}: reset: moving to HEAD^
            HEAD@{2}: reset: moving to a11c917430050a94549e48d205ef01cacc82c1cf
            HEAD@{3}: reset: moving to HEAD^

上面的allc...就是我最近的一次修改。

####修改（change）
这里的**修改**不是动词，而是名词，只要文件发生了变化就表示修改，包括对文件内容的更改或者新创建的一个文件或者删除一个文件都叫一个修改。 git跟踪（track）的就是修改，而不是文件本身。   

####撤销（checkout）
撤销是指文件修改后，还没有添加到暂缓区（还没有执行git add）过程中的修改撤销掉，如果已经添加到了暂缓区，但是还没有commit到分支中去，又做了修改后又想撤销，那么这里的撤销就是撤销到暂缓区的状态。比如现在对文件添加内容"add some to file":    

    E:\Users\liuzhijun\workspace\blog>git status
    # On branch master
    # Your branch is ahead of 'origin/master' by 4 commits.
    #   (use "git push" to publish your local commits)
    #
    # Changes not staged for commit:
    #   (use "git add <file>..." to update what will be committed)
    #   (use "git checkout -- <file>..." to discard changes in working directory)
    #
    #       modified:   README.rst

然后把它添加到暂缓区：  
    
    git add README.rst

再添加内容 "add some again to file"，撤销后，你会发现第一次添加的内容保留了，第二次添加的内容撤销了。  

    E:\Users\liuzhijun\workspace\blog>git checkout -- README.rst
        
    E:\Users\liuzhijun\workspace\blog>git status
    # On branch master
    # Your branch is ahead of 'origin/master' by 4 commits.
    #   (use "git push" to publish your local commits)
    #
    # Changes to be committed:
    #   (use "git reset HEAD <file>..." to unstage)
    #
    #       modified:   README.rst
    
####分支管理
开发一个新功能时，可能需要几周的时间才能完成，那么可以创建一个分支，在分支上做开发，而不影响主分支的功能。  
**创建分支**：  
![git](../resource/image/c_branch.png)

    git branch dev
    git checkout dev
或者合并成一条命令：  

    git checkout -b dev
创建dev分支切换后，HEAD指针就从原来的master转移指向dev分支，`git branch`可以查看有哪些分支，并且当前是在哪个分支上。  

    E:\Users\liuzhijun\workspace\blog>git branch
    * dev
      master
星号就代表当前的所在的分支。    

**切换分支**：  
![git](../resource/image/s_branch.png)

    git checkout master

**合并分支**：  
切换分支后，dev分支上做的修改在master分支看不到，如果dev分支的功能开发完成后，就可以考虑合并分支了，合并后还可以删除dev分支，因为此时dev分支对于我们来说没有多大意义了。  
![git](../resource/image/m_branch.png)

    git merge dev
合并分支就是把master执行dev分支，接着还可以删除分支  
    
    git branch -d dev

git鼓励大家使用分支，因此大家记得多用啊，只有多用才是熟练掌握。  

####冲突
如果不同的人对同一个文件的同一个地方做了修改，那么提交后就会遇到冲突，或者在不同的分支上修改了同一个文件的同一个地方也会出现冲突，当出现冲突了，就必须手动把有冲突的地方修改后再提交才能解决冲突。  

创建分支dev，然后添加内容"add new branch dev"，commit后切换到master分支，在同一行添加内容"may be here is conflict"，commit后合并。  

    git checkout -b dev
    git add README.rst
    git commit -m "add new branch"
    git checkout master
    git add README.rst
    git commit -m "add new line"
    git merge dev
    
    #出现错误
    Auto-merging README.rst
    CONFLICT (content): Merge conflict in README.rst
    Automatic merge failed; fix conflicts and then commit the result.

README.rst内容出现了如下情况：  

    <<<<<<< HEAD
    may be here is conflict
    =======
    add new branch dev 
    >>>>>>> dev
   
\<<<<<<< 到=======\表示当前分支的内容， >>>>>表示dev里面的内容。手动修改里面的内容后再提交。那么master就是最新的文件了。当然dev还是停留在上次commit的状态。此时你可能会想，我想在dev分支上与master保持同样的最新状态，那么你可以这样：    

    git checkout dev
    git rebase master

相当于快速的把dev分支指向master。  
![git](../resource/image/rebase2.png)

####分支策略
开发过程中，都应该按照以下方式来管理分支。  
**主分支**：代码库应该有且只有一个主分支master，master分支的代码是稳定的，仅用于正式版本发布使用。  

**开发分支**：日常开发工作应该在开发分支dev上完成，待某个时间dev分支的功能完善了就可以考虑merge到master分支上去。  

**自己的分支**：每个人在dev分支上建立自己的分支。  
默认情况下，git合并使用"fast forward”模式，相当于直接把master分支指向dev分支。删除分支后，分支信息也随即丢失。  
![git](../resource/image/ff.png)

在合并的时候附上参数 `--no-ff`就可以禁用fast-forward合并模式。这样在master上能生成一个新的节点，意味着master保留的分支信息，而这种合并方式我们希望采用的。  
    
    git merge --no-ff dev

![git](../resource/image/nff.png)


注：为了更好理解本文，请结合原文阅读  
####JDBC批处理Select语句

在网络上开销最昂贵的资源就是客户端与服务器往返的请求与响应，JDBC中类似的一种情况就是对数据库的调用，如果你在做数据插入、更新、删除操作，你可以使用executeBatch()方法减少数据库调用次数，如：  

    Statement pstmt = conn.createStatement();
    pstmt.addBatch("insert into settings values(3,'liu')");
    pstmt.addBatch("insert into settings values(4,'zhi')");
    pstmt.addBatch("insert into settings values(5,'jun')");
    pstmt.executeBatch();

但不幸的是对于批量查询，JDBC并没有内建（built-in）的方法，而且JDBC执行批处理的时候也不能有SELECT语句，如：  

    Statement pstmt = conn.createStatement();
	pstmt.addBatch("select * from settings");
	pstmt.executeBatch();

会抛出异常：  

    Exception in thread "main" java.sql.BatchUpdateException: Can not issue SELECT via executeUpdate().
    	at com.mysql.jdbc.Statement.executeBatch(Statement.java:961)
    	at test.SelectBatchTest.test2(SelectBatchTest.java:49)
    	at test.SelectBatchTest.main(SelectBatchTest.java:12)

假设你想从一系列指定的id列表中获取名字，逻辑上，我们要做的事情看起来应该是：  

    PreparedStatement stmt = conn.prepareStatement(
        "select id, name from users where id in (?)");
    stmt.setString("1,2,3");

但是这样做并不能得到预期的结果，JDBC只允许你用单个的字面值来替换“？” JDBC之所以这么做是有必要的，因为如果SQL自身可以改变的话，JDBC驱动就没法预编译SQL语句了，另一方面它还能防止SQL注入攻击。  

但有四种可替代的实现方法可供选择：  

1. 分别对每个id做查询  
2. 一个查询做完所有事  
3. 使用存储过程  
4. 选择批处理 

#####方法一： 分别对每个id做查询

假设有100个id，那么就有100次数据库调用：  

    PreparedStatement stmt = conn.prepareStatement(
        "select id, name from users where id = ?");
    for ( int i=0; i < 100; i++ ) {
      stmt.setInt(i);  // or whatever values you are trying to query by

      // execute statement and get result
    }
这种方法写起来非常简单，但是性能非常慢，数据库往返要处理100次。  

#####方法二：一个查询完成所有事  

在运行时，你可以使用一个循环来构建如下SQL语句：  

    PreparedStatement stmt = conn.prepareStatement(
        "select id, name from users where id in (?, ?, ?)");
    stmt.setInt(1);
    stmt.setInt(2);
    stmt.setInt(3);

这种方案从代码相比第一种方法算是第二简单的，它解决了来回多次请求数据库的问题，但是如果每次请求参数的个数不一样时预处理语句就必须重新编译，由于每次SQL字面值不匹配，因此如果分别用10个id、3个id、100个，这样会在缓存中产生三个预处理语句。除了重新编译预处理语句之外，先前缓存池中的预处理语句将被移除（受限于缓存池大小），进而导致重新编译已编译过的语句。最后，这种查询方式在内存溢出或磁盘分页操作时查询会占用很长时间。  

该方案的另一种变体就是在SQL语句中硬编码：

    PreparedStatement stmt = conn.prepareStatement(
    "select id, name from users where id in (1, 2, 3)");

这样方式甚至更差，而且没有任何机会对SQL语句重用，至少用“？”还可以对使用相同数量参数的SQL语句进行重用。  

    PreparedStatement stmt = conn.prepareStatement(
       "select id, name from users where id in (?) ; "   
       + "select id, name from users where id in (?); "
       + "select id, name from users where id in (?)");
    stmt.setInt(1);
    stmt.setInt(2);
    stmt.setInt(3);

这种方法的优点就是每次查询模版语句都一样，数据库不需要每次计算执行路径。然而，从数据库驱动的角度来说SQL每次都不一样，预处理语句每次必须预处理保存在缓存中。而且不是所有数据库系统都支持分号间隔的多个SQL语句的  

#####方法三：使用存储过程  
存储过程执行在数据库系统中，因此它可以做很多查询而不需要太多网络负载，存储过程可以收集所有结果一次性返回。这是一种速度很快的解决方案。但是它对数据库的依赖比较强，不能随意的切换数据库系统，否则需要重写存储过程而且需要你分离应用服务器与数据库服务器之间的逻辑。如果应用架构已经使用了存储过程，无疑这是只最佳方案。  

#####方法四：批量查询

批量查询是方案一和方案二的折衷选择，它预先确定一批查询参数的常量，然后用这些参数构建一批查询。因为这只会涉及到有限个查询，所以它有预处理语句的优势（预编译不会与缓存中的预处理发生碰撞）。批处理多个值在相同的查询保留了服务器来回请求最小化的优势。最后你可以通过控制批处理的上限来避免大查询的内存问题。如果你有很关键的查询对性能方面有要求又不想用存储过程，那么这是一种很好的解决办法，现在我们通过一个例子说明：  

    public static final int SINGLE_BATCH = 1;
    public static final int SMALL_BATCH = 4;
    public static final int MEDIUM_BATCH = 11;
    public static final int LARGE_BATCH = 51;

第一件要做的事是你要衡量有多少批处理以及每个批处理的大小。（注意：在真实的代码中，这些值应该写在一个配置文件中而不是采取硬编码的形式，也就是说，你可以在运行时试验并改变批处理的大小）不管真正的批处理大小是多大，你总需要一个单个的批处理---大小为1的批处理（SINGLE_BATTCH）。这样如果有人请求的就是一个值或者在一个很大的查询中最后有遗留下来的单个值都能派上用场。对于批处理的大小，使用素数会更好些。换句话说，大小不应该可以相互的整除或者被相同的数整除。请求数的最大值将有最少的服务器往返。批处理的大小的数量和真正的大小是基于配置变化的。需要注意的是：大的批处理大小不应该太大否则你将遇到内存麻烦。同时最小批处理的大小应该很小，你可能会使用这个来做很多次的查询。  

    while ( totalNumberOfValuesLeftToBatch > 0 ) {

按如下方式重复操作直到推出循环。  

    int batchSize = SINGLE_BATCH;
    if ( totalNumberOfValuesLeftToBatch >= LARGE_BATCH ) {
      batchSize = LARGE_BATCH;
    } else if ( totalNumberOfValuesLeftToBatch >= MEDIUM_BATCH ) {
      batchSize = MEDIUM_BATCH;
    } else if ( totalNumberOfValuesLeftToBatch >= SMALL_BATCH ) {
      batchSize = SMALL_BATCH;
    }
    totalNumberOfValuesLeftToBatch -= batchSize; 

这种方案在这里是查找到最大的批处理大小，可能这个最大值比我们实际要查询的值稍大。举例说明：假设查询有75个参数，那么首先选择51个元素（LARGE_BATCH），现在还剩24个待查询，然后接着用11个元素的查询（MEDIUM_BATCH）。现在还有13个值，因为仍然大于11，再做一次11个元素的查询，现在只剩下2个值，它少于那个最小的批处理4（SMALL_BATCH），所以做两次单查询。总共5次往返用了3次预处理在缓存中。这是一个很重要的改进比单独地坐75次单查询。  


    StringBuilder inClause = new StringBuilder();
    boolean firstValue = true;
    for (int i=0; i < batchSize; i++) {
      inClause.append('?');
      if ( firstValue ) {
        firstValue = false;
      } else {
        inClause.append(',');
      }
    }
    PreparedStatement stmt = conn.prepareStatement(
        "select id, name from users where id in (" + inClause.toString() + ')');

现在已经构建了一个真实的预处理语句，由于一直用相同的方式构建的查询，驱动注意到SQL是相同的。（注意：如果你还没有用Java5，使用StringBuffer替换StringBuilder才能正常编译），返回id很重要这样有利于查找哪个名字对应哪个id。  

    for (int i=0; i < batchSize; i++) {
      stmt.setInt(i);  // or whatever values you are trying to query by
    }

设置合适的值数量去查询，包括其他搜索条件查询。仅仅只要把这些参数在之举参数之后。在这种情况你可以最终当前的索引。  

从这点来看，你仅仅只是执行查询返回了结果，在第一次尝试的时候，你应该关注一下性能的提升，根据具体情况调整优化批处理的大小（batch size）。  

*正如那句名言所说：“过早的优化是万恶之源”，批处理应该是用于解决性能问题。*

原文：[Batching Select Statements in JDBC](http://www.javaranch.com/journal/200510/Journal200510.jsp#a2)

http://www.codeinstructions.com/2009/01/busting-javalangstringintern-myths.html

理解类在JVM中什么时候被加载和初始化是Java编程语言中的基础概念，正因为有了Java语言规范，我们才可以清晰的记录和解释这个问题，但是很多Java程序员仍然不知道什么时候类被加载什么时候类被初始化，类加载和初始化好像让人很困惑，对初学者难以理解，在这篇教程中我们将看看类加载什么时候发生，类和接口是如何被初始化的，我并不会拘泥于类加载器的细节或者说类加载器的工作方式。仅仅使这篇文章更加专注和简结。  

#####类什么时候加载
类的加载是通过类加载器（Classloader）完成的，它既可以是饿汉式[eagerly load]（只要有其它类引用了它就加载）加载类，也可以是懒加载[lazy load]（等到类初始化发生的时候才加载）。不过我相信这跟不同的JVM实现有关，然而他又是受JLS保证的（当有静态初始化需求的时候才被加载）。  

####类什么时候初始化
加载完类后，类的初始化就会发生，意味着它会初始化所有类静态成员，以下情况一个类被初始化：  

1. 实例通过使用new()关键字创建或者使用class.forName()反射，但它有可能导致ClassNotFoundException。  
2. 类的静态方法被调用
3. 类的静态域被赋值
4. 静态域被访问，而且它不是常量
5. 在顶层类中执行assert语句

反射同样可以使类初始化，比如java.lang.reflect包下面的某些方法，JLS严格的说明：一个类不会被任何除以上之外的原因初始化。  

####类是如何被初始化的
现在我们知道什么时候触发类的初始化了，他精确地写在Java语言规范中。但理清域（fields，静态的还是非静态的）、块（block静态的还是非静态的）、不同类（之类和超类）和不同的接口（子接口，实现类和超接口）的初始化顺序也很重要类。事实上很多核心Java面试题和SCJP问题都是基于这些概念，下面是类初始化的一些规则：  

1. 类从顶至底的顺序初始化，所以声明在顶部的字段的早于底部的字段初始化
2. 超类早于子类和衍生类的初始化
3. 如果类的初始化是由于访问静态域而触发，那么只有声明静态域的类才被初始化，而不会触发超类的初始化或者子类的初始化即使静态域被子类或子接口或者它的实现类所引用。  
4. 接口初始化不会导致父接口的初始化。
5. 静态域的初始化是在类的静态初始化期间，非静态域的初始化时在类的实例创建期间。这意味这静态域初始化在非静态域之前。  
6. 非静态域通过构造器初始化，子类在做任何初始化之前构造器会隐含地调用父类的构造器，他保证了非静态或实例变量（父类）初始化早于子类

#####初始化例子
这是一个有关类被初始化的例子，你可以看到哪个类被初始化  

    /**
     * Java program to demonstrate class loading and initialization in Java.
     */
    public class ClassInitializationTest {
    
        public static void main(String args[]) throws InterruptedException {
      
            NotUsed o = null; //this class is not used, should not be initialized
            Child t = new Child(); //initializing sub class, should trigger super class initialization
            System.out.println((Object)o == (Object)t);
        }
    }
    
    /**
     * Super class to demonstrate that Super class is loaded and initialized before Subclass.
     */
    class Parent {
        static { System.out.println("static block of Super class is initialized"); }
        {System.out.println("non static blocks in super class is initialized");}
    }
    
    /**
     * Java class which is not used in this program, consequently not loaded by JVM
     */
    class NotUsed {
        static { System.out.println("NotUsed Class is initialized "); }
    }
    
    /**
     * Sub class of Parent, demonstrate when exactly sub class loading and initialization occurs.
     */
    class Child extends Parent {
        static { System.out.println("static block of Sub class is initialized in Java "); }
        {System.out.println("non static blocks in sub class is initialized");}
    }
    
    Output:
    static block of Super class is initialized
    static block of Sub class is initialized in Java
    non static blocks in super class is initialized
    non static blocks in sub class is initialized
    false

从上面结果可以看出：  

1. 超类初始化早于子类
2. 静态变量或代码块初始化早于非静态块和域
3. 没使用的类根本不会被初始化，因为他没有被使用

再来看一个例子：  

    /**
     * Another Java program example to demonstrate class initialization and loading in Java.
     */
    
    public class ClassInitializationTest {
    
        public static void main(String args[]) throws InterruptedException {
      
           //accessing static field of Parent through child, should only initialize Parent
           System.out.println(Child.familyName);
        }
    }
    
    class Parent {
        //compile time constant, accessing this will not trigger class initialization
        //protected static final String familyName = "Lawson";
      
        protected static String familyName = "Lawson";
      
        static { System.out.println("static block of Super class is initialized"); }
        {System.out.println("non static blocks in super class is initialized");}
    }
    
    Output:
    static block of Super class is initialized
    Lawson

分析：  

1. 这里的初始化发生是因为有静态域被访问，而且不一个编译时常量。如果声明的"familyName"是使用final关键字修饰的编译时常量使用（就是上面的注释代码块部分）超类的初始化就不会发生。
2. 尽管静态与被子类所引用但是也仅仅是超类被初始化

还有另外一个例子与接口相关的，JLS清晰地解释子接口的初始化不会触发父接口的初始化。强烈推荐阅读JLS14.4理解类加载和初始化细节。以上所有就是有关类被初始化和加载的全部内容。  




细说finally
===============
在网上有一个热议的微薄[大家觉得这段代码返回值是什么？为什么？](http://weibo.com/1970145123/AD5uLyBUm),代码如下:  

    int x = 0;
    try{
        return x;
    }
    finally{
        x++;
        System.out.println(x);  // Prints new value of x
    }

回答地一个问题, finally代码块会不会执行, 如果会执行那么返回值是1还是0 



在没有泛型前，从集合中读取的元素都必须进行强制转换，比如：

    List foos = new ArrayList();
    foos.add(new Foo());
    Foo = (Foo)foos.get(0);  //必须强制转换

否则连编译没法通过，但是有了泛型之后，编译器可以在插入数据的时候自动帮你转换，编译时告知是否插入了错误类型。  

    List<Foo> foos = new ArrayList<Foo>();
    foos.add(new Foo());
    Foo = foos.get(0);  //无需转换

####使用泛型的需要注意的陷进

首先需要知道几个术语：

+ **泛型**：声明的时候，拥有一个或多个类型参数的类或者接口，称之为泛型类或泛型接口，两者又统称为泛型（generic type） 如：List<String>就声明了一个String类型的参数 

+ **参数化类型（parameterized type）**：参数化类型包含一个类或者接口名称C，以及实际的类型参数列表<T1,...Tn>

+ **原生类型（raw type）**：原生类型是满足以下条件之一：   
    1. 使用的泛型类型声明的名称，而没有任何伴随的实际类型的参数  
    2. 元素的类型为原生类型的数组类型  
    3. 原生类型R的任何非静态类型成员，且它不是从R的超类或者超接口派生而来的  

举例：  

    public class MyType<E> {
        class Inner { }
        static class Nested { }
    
        public static void main(String[] args) {
            MyType mt;          // warning: MyType is a raw type
            MyType.Inner inn;   // warning: MyType.Inner is a raw type
    
            MyType.Nested nest; // no warning: not parameterized type
            MyType<Object> mt1; // no warning: type parameter given
            MyType<?> mt2;      // no warning: type parameter given (wildcard OK!)
        }
    }
这里，`mt`和`inn`就是原生类型的，而`ntst`不是，因为他是静态类型成员，`mt1`和`mt2`属于参数化类型。  

####陷进一：  不要使用原生态类型
本质上，原生类型的行为方法和泛型没什么两样，就像如下代码：  

    List names = new ArrayList(); // warning: raw type!
    names.add("John");
    names.add("Mary");
    names.add(Boolean.FALSE); // not a compilation error!

代码没有任何问题，但是，  

    for (Object o : names) {
        String name = (String) o;
        System.out.println(name);
    } // throws ClassCastException!
      //    java.lang.Boolean cannot be cast to java.lang.String


如上代码在运行的时候，就会抛出`ClassCastException`的异常。  

有了泛型，编译器就能帮你完成类型检测的工作.

    List<String> names = new ArrayList<String>();
    names.add("John");
    names.add("Mary");
    names.add(Boolean.FALSE); // compilation error!

####原生类型List与List<Object>参数化类型的区别  

原生类型List躲避了泛型检查，参数化类型List<Object>告知编译器，它能装任意类型的对象，虽然你可以将List<String>传递给类型List的参数，但是不能将它传递给类型List<Object>的参数。为什么呢？这是子类型化（subtyping）的规则。

####子类型化（subtyping）

常规类中，如果类B继承A，那么类B就是类A的子类，但是这条规则并不能适用于泛型中。

    class A {}
    class B extends A {}

    List<B> lb = new ArrayList<>();
    List<A> la = lb;  //compile-time error
[generics-listParent.gif]
尽管Integer是Number的子类，但是List<Integer>并不是List<Number>的子类，两者没有任何关系，而他两的共同父类是List<?>.  

为了通过List<Integer>的元素来访问Number的方法，可以使用向上通配符：  
    
    List<? extends Integer> intList = new ArrayList<>();
    List<? extends Number> numList = intList  //Ok，List<? extends Integer> is a subtype of List<? extends Number>



http://stackoverflow.com/questions/2770321/what-is-a-raw-type-and-why-shouldnt-we-use-it
http://docs.oracle.com/javase/specs/jls/se7/html/jls-4.html#jls-4.8
http://docs.oracle.com/javase/tutorial/java/generics/subtyping.html


如何生成一个合适的hashcode方法
------------------------------
Hashcode在基于key-value的集合如：HashMap、LinkedHashMap中扮演很重要的角色。此外在HashSet集合中也会运用到，使用合适的hashcode方法在检索操作时的时间复杂度最好的是 O(1).  

一个差劲的hashcode算法不仅会降低基于哈希集合的性能，而且会导致异常结果。Java应用中有多种不同的方式来生成hashcode。  

####Effective Java
Josh Bloch在他的书籍《Effective Java》告诉我们重写hashcode方法的最佳实践方式。  

一个好的hashcode方法通常最好是不相等的对象产生不相等的hash值，理想情况下，hashcode方法应该把集合中不相等的实例均匀分布到所有可能的hash值上面。  

1. 把某个非0的常数值，比如17，保存在一个名为result的int类型的变量中。
2. 对于对象中的每个域，做如下操作：  

    * 为该域计算int类型的哈希值c：  
            
        *  如果该域是boolean类型，则计算(f?1:0)
        *  如果该域是byte、char、short或者int类型，则计算(int)f
        *  如果该域是long类型，则计算(int)(f^(f>>>32))
        *  如果该域是float类型，则计算Float.floatToIntBits(f)
        *  如果该域是double类型，则计算Double.doubleToLongBits(f)，然后重复第三个步骤。
        *  如果该域是一个对象引用，并且该类的equals方法通过递归调用equals方法来比较这个域，同样为这个域递归的调用hashCode，如果这个域为null，则返回0。
        *  如果该域是数组，则要把每一个元素当作单独的域来处理，递归的运用上述规则，如果数组域中的每个元素都很重要，那么可以使用Arrays.hashCode方法。

把上面计算得到的hash值c合并到result中  

    result = 31*result + c 

####String中的Hashcode方法
String的hashcode的算法就充分利用了字符串内部字符数组的所有字符。生成hash码的算法的在string类中看起来像如下所示，注意“s“是那个字符数组，n是字符串的长度。  

    s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]

####Hashcode使用Eclipse IDE
现代IDE通过点击右键上下文菜单可以自动生成hashcode方法，通过Eclipse IDE 生成的hashcode像：  

    public int hashCode() {
        final int prime = 31;
        int result = 1;
        result = prime * result + a;
        return result;
    }

但是并不推荐如上代码使用在企业级代码中，最好使用第三方库如Apache commons来生成hashocde方法。  

####Apache commons HashcodeBuilder
我们可以用Apache Commons hashcode builder来生成代码，使用这样一个第三方库的优势是可以反复验证尝试代码。下面代码显示了如何使用Apache Commons hash code 为一个自定义类构建生成hash code 。  

    public int hashCode(){
           HashCodeBuilder builder = new HashCodeBuilder();
           builder.append(mostSignificantMemberVariable);
       ........................
       builder.append(leastSignificantMemberVariable);
           return builder.toHashCode();
       }

如上面代码显示的，最重要的签名成员变量应该首先传递然后跟随的是没那么重要的成员变量。  

Apache Commons库同样为自定义的类提供了构建生成equals的方法，使用equals构建器的代码看起来非常像上面的代码。事实上传递给成员变量从最重要的签名到最不重要的签名一样的规则，同样应用于equals构建器中。  


鉴于我是C/C++出身，有件事一直让我很不爽，就是Java缺乏一种方法去如何计算一个对象到底使用了多少内存。C++的sizeof方法可以清楚到查到原生类型或者类对象的内存大小。这个操作在C和C++的指针运算拷贝内存及IO非常实用。  

Java中没有相应的操作，事实上Java不需要，原生类型的大小定义在Java语言规范中，而C和C++依赖与操作系统。Java有自己的基础围绕序列化，指针运算和内存拷贝不会使用，因为Java中没有指针。  

但是每个Java程序员在某个时候想知道一个Java对象占用了多少内存，这个答案，结果证明没那么简单。  

第一个区别就是



类的内存结构  没有实例属性

在Sun JVM中，每个对象（除了数组）有2个字的头，第一个字包含对象唯一哈希码加一些标志象锁状态和年龄，第二个字包含类对象的引用，同时，任何对象。


http://www.codeinstructions.com/2008/12/java-objects-memory-structure.html
http://blog.csdn.net/kp034/article/details/7077757

####Java中的枚举
枚举（enum）类型是由固定常量集构成的一种类型

Singleton Design Pattern – An Introspection w/ Best Practices[http://java.dzone.com/articles/singleton-design-pattern-%E2%80%93]
http://javarevisited.blogspot.com/2011/03/10-interview-questions-on-singleton.html

[原文](http://javarevisited.blogspot.com/2012/01/improve-performance-java-database.html)

JDBC性能小贴士
================
本文收集了一些用于提升JDBC性能的方法。Java应用或者JavaEE Web应用的性能是很重要的，尤其是数据库后端对应用的性能影响。不知你是否经历过Java、JavaEE web应用非常慢的案例没有（处理一个简单的请求都要花上好几秒的时间用于数据库访问，分页、排序等）。下面这些贴士也许能提升Java应用的性能。它们非常简单同时还可以应用于其它编程语言，如果是用数据库作为后端存储的话。  

这几个JDBC性能贴示不见得有多酷或者有些你从没听说过，虽然讲的很基础但是在实践中上很多程序员经常忽略它们，当然你可能把标题称为数据库性能提示。

####JDBC性能贴士一：使用缓存  
查出应用中有 *多少数据库调用* ，然后把它们减到最少，不管你信不信性能问题大多数情况下罪魁祸首是访问数据库的那些代码。因为连接到数据库需要准备好连接（connections），还有往返的网络传输和数据库系统后端的处理。如果你可以把数据缓存下来的话这是减少数据库调用最好的方式，即使你的应用有完全动态的数据，短暂的缓存可以节省很大的数据苦往返的传输。加速Java应用后至少能减少20-50%的数据库调用，如果想找出数据库调用，那么仅仅把DAO层的每个db调用中记录到日志中就行，如果记录好每个线程进入和退出数据库访问的时间更好，它能告诉你一个调用究竟花了多少时间。  

####JDBC性能贴士二：使用数据库索引
检查数据库列上（columns）是否有索引，如果你正做查询发现所花的时间比预想的要长，那么首先想到的是检查在列上（正在查询的where子句中的那列）是否做了索引。程序员中常犯这个错误，有索引和没有索引在做查询时有巨大的差异。这条贴士在性能上至少能提速100%，当然合适的索引更重要，太多的索引反而会减慢数据的插入和更新操作。因此使用索引的时候要小心，象id、类别（category）、类（class）等字段上做索引是经常使用的。  

####JDBC性能贴士三：使用PreparedStatement
使用PreparedStatement或者存储过程（Stored Procedure）执行查询时PreparedStatement（预处理语句）比普通的Statement对象要快。因为数据库可以对查询语句做预处理何查询缓存计划。 因此总是使用 ** 参数化形式的预处理语句** 如` SELECT * FROM table WHERE id=?`,而不要使用`SELECT * FROM table WHERE id='"+id "'`,虽然后者仍是一个预处理语句但不是参数化的。使用第二种查询方式在性能上没有任何优势，更多参考可以查下看[JDBC为什么要使用PreparedStatement而不是Statement](http://www.importnew.com/5006.html)  

####JDBC性能贴士四：使用数据库连接池
连接池用来存放数据库连接（Connection），创建数据库连接是个比较慢的过程而且会耗很长时间。所以如果每个请求都要创建一个连接，那么显然响应时间将会更长。用连接池根据上游的流量及并发请求数创建适当数量的连接。即使连接池在开始的请求中创建连接、缓存连接会比较慢，但总体还是能减不少开销。   

####JDBC性能贴士五：使用JDBC批量更新
使用JDBC批量更新操作能显著提升Java数据库应用的性能。你应该始终用批量处理来执行插入和更新操作。通过使用Statment或者PreparedStatement做批量查询。用executeBatch（）方法做批量查询。  

####JDBC性能贴士六：取消自动提交
查询时设置`setAutoCommit(false)`，默认JDBC连接自动提交模式是打开的，意味着每个独立的SQL语句都将在自己的事务中执行。然而你可以把SQL语句按组归到一个逻辑事务中去，这样通过调用`commit()`或`rollback()`要么提交要么回滚。试着运行相同数量的查询次数对比一下使用自动提交和不使用自动提交时的性能区别有多大的差异性。  

这些Java数据库应用性能小提示看起来非常简单，很多高级Java程序员能熟练运用在生产级代码中，但我还看到很多Java程序员并没有在乎这些，直到他们发现Java应用变得很慢时。所以对于新手来说有必要记住它使用它。同时你还可以使用这些Java性能小提示作为代码审查机制的一个参考，在你写的Java应用是使用数据库作为后端存储的时候。  

以上就是关于如何改善Java应用程序的性能的贴士，如果你有什么更好的提示不妨给我留言。  

Shiro走马观花
================
Shiro如其官方介绍的一样，功能齐全易用的Java安全框架，功能包括认证、授权、加密、会话管理。  

###Authentication认证

**Subject**：安全里面具体的“用户"，这个用户既可以指人也可以第三方程序或者是一个用来连接你的程序的程序。简单来说subject就是和应用通信的对象。  
**Pricipals**：Subject的标识属性，如果Subject一个User类的话，那么Pricipals可以是username或者是email，总之就是能唯一标识这个Subject的属性。  
**Credentials**：用来验证的私密数据，简单理解就是密码。  
**Realms**：一种认证方式，比如LDAP，或者JDBC等等。

###Shiro认证流程
1. 收集Subject的Pricipals和Credentials.
    
        UsernamePasswordToken token = new UsernamePasswordToken( username, password );

    token对象是对Pricipals和Credentials的简单封装。
2. 提交Pricipals和Credentials给认证系统

    封装好的token会提交到认证系统中去，认证系统就是Realms，Shiro通过封装后认证的步骤简单至极。

        Subject currentUser = SecurityUtils.getSubject()
        currentUser.login(token)
    login就是认证方法，为什么要获取currentUser呢？currentUser就是subject，前面说过subject即可指人或者一个进程等，在Shiro里面当前的执行线程中一直会有一个subject实例可用。

3. 允许访问或者重新认证或者禁止访问

        try {
            currentUser.login(token);
        } catch ( UnknownAccountException uae ) { ...
                //为注册账户
        } catch ( IncorrectCredentialsException ice ) { ...
                //密码错误
        } catch ( LockedAccountException lae ) { ...
                //被限制账户
        } catch ( ExcessiveAttemptsException eae ) { ...
                //超出登录次数
        } ... catch your own ...
        } catch ( AuthenticationException ae ) {
                //其他异常
            //unexpected error?
        }
        //No problems, show authenticated view…
    





###单例模式

单例模式在设计模式中属于最基本的设计模式之一，相信每个写过面向对象程序的程序员都知道：“**单例模式必须确保单例类在JVM中只能有一个实例存在。**”，这个老生常谈的问题为什么还要搬到这里来讨论呢？笔者试着以初学者的心态来重新认识单例模式，如果你是初、中级初学者（尼玛，初学者还分三六九等啊）不妨跟着我来重新学习一遍，不保证干活，但绝非软文。高级初学者可以不要往下看了。  

####为什么要创建单例类
+ 频繁创建对象，浪费创建时间，尤其是重量级的对象，使用单例可以减轻GC压力
+ 内存中只有一个对象，节省内存空间  
+ 全局可访问
+ 避免对共享资源的多重占用

####如何创建单例类

创建单例类难吗？真的很简单，看：  

    public class Foo{
        private static Foo INSTANCE;
        Private Foo(){}
        public static Foo getInstance(){
            if (INSTANCE==null){
                INSTANCE = new Foo();
            }
            return INSTANCE;
        }
    }

几行代码轻松搞定，借用我们老师的话来说就是“这个简单得要死”（你妹的，当时我心里就在骂他，你写了十几年程序和我们连HelloWorld都写不出的屌丝说这话），跑题了，快回来。  
结合代码，我们来总结一下创建单例模式的思路：1.一个类必须而且只能构建一个对象。2.获取该对象的方法（必须是静态的，为什么？）3.构造函数必须为私有方法（为什么？）  
那么这个程序真的能保证创建的实例唯一吗？我们用代码测试一下就知道：  

测试一：  

    public static void main(String[] args) {
    		Foo foo1 = Foo.getInstance();
    		Foo foo2 = Foo.getInstance();
    		System.out.println(foo1 == foo2);
    }

程序输入出：True  
看起来这个单例没什么问题，那么再来看看另外一种测试方法：  

    public static void main(String[] args) {
    		//线程一
    		Thread thread1 = new Thread(new Runnable() {
    			@Override
    			public void run() {	
    				Foo foo1 = Foo.getInstance();
    				System.out.println(foo1);
    			}
    		});
    		
    		//线程二
    		Thread thread2 = new Thread(new Runnable() {
    			@Override
    			public void run() {
    				Foo foo2 = Foo.getInstance();
    				System.out.println(foo2);
    			}
    		});
    		thread1.start();
    		thread2.start();
    }

程序输出：  

    Foo@5f186fab
    Foo@3d4b7453
原来还真是两个不同的对象，（如果你测试的结果不是我说期待的，那么说明你的运气还差点了，你可以多试试几次，再不行也没关系，我们在代码中做点小动作）：  

    public class Foo {
    	
    	private static  Foo foo;
    	private Foo(){}
    	public static Foo getInstance(){
    		
    		if (foo==null){
    			//人工干预
    			try {
    				Thread.sleep(100);
    			} catch (InterruptedException e) {}
    			foo = new Foo();
    		}
    		return foo;
    	}
    	
    	public static void main(String[] args) throws Exception {
    		
    		//线程一
    		final Thread thread1 = new Thread(new Runnable() {
    			@Override
    			public void run() {	
    				Foo foo1 = Foo.getInstance();
    				System.out.println(foo1);
    			}
    		});
    		
    		//线程二
    		Thread thread2 = new Thread(new Runnable() {
    			@Override
    			public void run() {
    				Foo foo2 = Foo.getInstance();
    				System.out.println(foo2);
    			}
    		});
    		thread1.start();
    		//人工干预
    		try {
    			Thread.sleep(1);  //主线程（main）暂停一毫秒
    		} catch (InterruptedException e) {/*为了代码简洁忽略异常，实际编码一般别这么干，除非你能驾驭异常*/}
    		thread2.start();
    	}
    }

改编后，新增的两处人工干预的代码，多线程环境下，CPU的时间片非常短，所以如果不采用人工干预，就有可能当一个线程执行完`foo=new Foo()`的时候第二个线程才运行到`if (foo==null)`语句，因此，启动thread1的时候，主线程暂停一毫秒，让thread1先执行到`if (foo==null)`语句处，然后等着thread2也跑起来，thread2执行到`if(foo==null)`的时候，发现`foo`实例（严格来说是引用）还没有创建，因此两个线程都进入了if条件语句，因此两个线程就创建的两个不同的对象。  

啰啰嗦嗦就是想说明这个最简单的单例创建方式在多线程并发环境下会违反实例单一原则的。









使用枚举:  

    public enum Foo{
        INSTANCE
    }



3.这样在其他地方就无法通过调用该类的构造方法来实例化这个类。
http://stackoverflow.com/questions/70689/what-is-an-efficient-way-to-implement-a-singleton-pattern-in-java

http://zh.wikipedia.org/wiki/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F

http://stackoverflow.com/questions/2832297/java-singleton-pattern

http://stackoverflow.com/questions/2832297/java-singleton-pattern

http://balan.iteye.com/blog/164873
http://www.blogjava.net/dreamstone/archive/2006/11/04/79026.aspx
http://stackoverflow.com/questions/228164/on-design-patterns-when-to-use-the-singleton

####基本概念
在Solr中，文档(Document)是搜索和索引的基本单元，一个索引由一个或多个文档构成，而一个文档是由一个或者多个字段(Field)组成的。文档对应于数据库中表的一行，而字段对应的是表中的某一列。  

#####Schema
给Solr添加文档前，需要指定schema，schema的表现形式就是文件schema.xml，在文档已经添加到索引中去了以后则不建议再去修改该文件。  

schema中声明有：

* 有哪些类型的字段
* 哪种字段应该作为主键/唯一键
* 哪些字段是必须的
* 如何索引和搜索每个字段

#####字段类型
在Solr中，每个字段都有一个类型，Solr队Lucene中的字段进行了扩展，Solr中基本的数据类型包括：  

* float
* long
* double
* date
* text
同时Solr还允许你自定义字段类型，只需要绑定好filters和tokenizers。例如：  

    <fieldtype name="phonetic" stored="false" indexed="true" class="solr.TextField" >
      <analyzer>
        <tokenizer class="solr.StandardTokenizerFactory"/>
        <filter class="solr.DoubleMetaphoneFilterFactory" inject="false"/>
      </analyzer>
    </fieldtype>

####定义字段
声明一个字段时，如下所示：

    <field name="id" type="text" indexed="true" stored="true" multiValued="true"/>
* name：字段的名称
* type：字段的类型
* indexed：这个字段是否假如到索引中
* sotred：这个字段的值是否被存储
* multiValued：这个字段是否可以有多个值

####分析
数据添加到Solr中后，在添加到索引前需要进过一系列的转换，这个步骤叫做词法分析，词法分析包括大小写转换，删除词根等等，分析的结果是一系列的tokens将加入到索引中，tokens不是原始的文本，是当你执行搜索查询的你说收到的文本。    

indexed字段是一个将会被加入到索引中的字段，如果不是indexed字段，也就不会被搜索到。  

####Term Storage
所显示给用户的搜索结果通常就是原始文档，而不是机器处理过的tokens（当然tokens与原始文档有相似之处）这个就是stored属性的作用，告诉Solr在索引的时候保存原始文档。有时，有些字段没有被搜索，但是需要显示在搜索结果中，那么就要设置stored=true,indexed=false。为什么不能存储所有字段呢？考虑到存储字段是需要增加索引的容量的，索引越大，搜索越缓慢，因为大的索引需要花更多的时间磁盘查找。










上篇文章提到有配置文件schema.xml，这在Solr中是个非常重要的文件，这篇文章就来详细的了解这个文件的作用。  

Solr把schema.xml文档翻译成Lucene索引，Solr提供了copy field和 dynamic fields。Copy fields提供了一种方式去


Lucene是一个高性能的java全文检索工具包，它使用的是倒排文件索引结构。该结构及相应的生成算法如下：    
0）设有两篇文章1和2   
文章1的内容为：Tom lives in Guangzhou,I live in Guangzhou too.  
文章2的内容为：He once lived in Shanghai.    
1)由于lucene是基于关键词索引和查询的，首先我们要取得这两篇文章的关键词，通常我们需要如下处理措施
 
* 我们现在有的是文章内容，即一个字符串，我们先要找出字符串中的所有单词，即分词。英文单词由于用空格分隔，比较好处理。中文单词间是连在一起的需要特殊的分词处理。 
* 文章中的”in”, “once” “too”等词没有什么实际意义，中文中的“的”“是”等字通常也无具体含义，这些不代表概念的词可以过滤掉 
* 用户通常希望查“He”时能把含“he”，“HE”的文章也找出来，所以所有单词需要统一大小写。 
* 用户通常希望查“live”时能把含“lives”，“lived”的文章也找出来，所以需要把“lives”，“lived”还原成“live” 
* 文章中的标点符号通常不表示某种概念，也可以过滤掉 
在lucene中以上措施由Analyzer类完成

[Lucene倒排索引](http://wenku.baidu.com/view/e1bff3150b4e767f5acfcef3.html)  
[Lucene评分算法](http://ericbao.blog.sohu.com/203348366.html)  
[Lucene/Solr修改评分规则](http://www.cnblogs.com/tq03/p/3615517.html)  
[Lunece大牛，全文检索的基本原理](http://www.cnblogs.com/forfuture1978/archive/2009/12/14/1623594.html)


* tf:表示词条(term)在文档中出现的词频
* idf：表示词条(term)在几个文档中出现过


###索引创建过程
原始文档：  
文件一：Students should be allowed to go out with their friends, but not allowed to drink beer.  
文件二：My friend Jerry went to school to see his students but found them drunk which is not allowed.  

####一：原始文档传分词组件(Tokenizer)
分词组件(Tokenizer)会做以下几件事情(这个过程称为：Tokenize)  

1. 将文档分成一个一个单独的单词
2. 去除标点符号
3. 去除停词(stop word)

    所谓停词(Stop word)就是一种语言中最普通的一些单词，由于没有特别的意义，因而大多数情况下不能成为搜索的关键词，因而创建索引时，这种词会被去掉而减少索引的大小。英语中停词(Stop word)如：“the”,“a”，“this”等。

对于每一种语言的分词组件(Tokenizer)，都有一个停词(stop word)集合。经过分词(Tokenizer)后得到的结果称为词元(Token)。上例子中，便得到以下词元(Token)：

    “Students”，“allowed”，“go”，“their”，“friends”，“allowed”，“drink”，“beer”，“My”，“friend”，“Jerry”，“went”，“school”，“see”，“his”，“students”，“found”，“them”，“drunk”，“allowed”

####二：词元(Token)传给语言处理组件(Linguistic Processor)
语言处理组件(linguistic processor)主要是对得到的词元(Token)做一些同语言相关的处理。对于英语，语言处理组件(Linguistic Processor)一般做以下几点：

1. 变为小写(Lowercase)。
2. 将单词缩减为词根形式，如“cars”到“car”等。这种操作称为：stemming。
3. 将单词转变为词根形式，如“drove”到“drive”等。这种操作称为：lemmatization。
    
**Stemming 和 lemmatization的异同：**  

* 相同之处：
    1. Stemming和lemmatization都要使词汇成为词根形式。  
* 两者的方式不同：  
    1. Stemming采用的是“缩减”的方式：“cars”到“car”，“driving”到“drive”。
    2. Lemmatization采用的是“转变”的方式：“drove”到“drove”，“driving”到“drive”。
* 两者的算法不同：
    1. Stemming主要是采取某种固定的算法来做这种缩减，如去除“s”，去除“ing”加“e”，将“ational”变为“ate”，将“tional”变为“tion”。
    2. Lemmatization主要是采用保存某种字典的方式做这种转变。比如字典中有“driving”到“drive”，“drove”到“drive”，“am, is, are”到“be”的映射，做转变时，只要查字典就可以了。
    3. Stemming和lemmatization不是互斥关系，是有交集的，有的词利用这两种方式都能达到相同的转换。

**语言处理组件(linguistic processor)的结果称为词(Term)**  

在我们的例子中，经过语言处理，得到的词(Term)如下：

    “student”，“allow”，“go”，“their”，“friend”，“allow”，“drink”，“beer”，“my”，“friend”，“jerry”，“go”，“school”，“see”，“his”，“student”，“find”，“them”，“drink”，“allow”。
也正是因为有语言处理的步骤，搜索drive时drove也能被搜索出来。

####三：得到的词(Term)传递给索引组件(Indexer)
1. 利用得到的词(Term)创建一个字典

        Term	Document ID
        student	    1
        allow	    1
        go	        1
        their	    1
        friend	    1
        allow	    1
        drink	    1
        beer	    1
        my	        2
        friend	    2
        jerry	    2
        go	        2
        school	    2
        see	        2
        his	        2
        student	    2
        find	    2
        them	    2
        drink	    2
        allow	    2
2. 对字典按字母顺序排序：

        Term	Document ID
        allow	    1
        allow	    1
        allow	    2
        beer	    1
        drink	    1
        drink	    2
        find	    2
        friend	    1
        friend	    2
        go	        1
        go	        2
        his	        2
        jerry	    2
        my	        2
        school	    2
        see	        2
        student	    1
        student	    2
        their	    1
        them	    2 
3. 合并相同的词(Term)成为文档倒排(Posting List)链表
![postlist](../resource/image/postinglist.jpg)
    * Document Frequency：文档频次，表示多少文档出现过此词(Term)
    * Frequency：词频，表示某个文档中该词(Term)出现过几次

    对词(Term) “allow”来讲，总共有两篇文档包含此词(Term)，词(Term)后面的文档链表总共有两项，第一项表示包含“allow”的第一篇文档，即1号文档，此文档中，“allow”出现了2次，第二项表示包含“allow”的第二个文档，是2号文档，此文档中，“allow”出现了1次

到此索引创建完成，搜索“drive”，“driving”，“drove”，“driven”也能够被搜到。因为在索引中，“driving”，“drove”，“driven”都会经过语言处理而变成“drive”，在搜索时，如果您输入“driving”，输入的查询语句同样经过一二步骤，变为查询“drive”，从而可以搜索到想要的文档。

###搜索步骤
搜索"microsoft job"，用户的目的是希望在微软找一份工作，如果搜出来的结果是:“Microsoft does a good job at software industry…”，这就与用户的期望偏离太远了。如何进行合理有效的搜索，搜索出用户最想要得结果呢？搜索主要有如下步骤：  

####一：
    


如果你和我一样是Solr新手，那么就和我一起来入门吧！本教程以solr4.8作为测试环境，jdk版本需要1.7及以上版本。  
####准备
下载解压缩solr，在example目录有start.jar文件，启动：  
    
    java -jar start.jar
浏览器访问：[http://localhost:8983/solr/](http://localhost:8983/solr/)，你看到的就是solr的管理界面

####索引数据
服务启动后，目前你看到的界面没有任何数据，你可以通过POSTing命令向Solr中添加（更新）文档，删除文档，在exampledocs目录包含一些示例文件，运行命令：
    
    java -jar post.jar solr.xml monitor.xml
上面的命令是向solr添加了两份文档，打开这两个文件看看里面是什么内容，solr.xml里面的内容是：

    <add>
    <doc>
      <field name="id">SOLR1000</field>
      <field name="name">Solr, the Enterprise Search Server</field>
      <field name="manu">Apache Software Foundation</field>
      <field name="cat">software</field>
      <field name="cat">search</field>
      <field name="features">Advanced Full-Text Search Capabilities using Lucene</field>
      <field name="features">Optimized for High Volume Web Traffic</field>
      <field name="features">Standards Based Open Interfaces - XML and HTTP</field>
      <field name="features">Comprehensive HTML Administration Interfaces</field>
      <field name="features">Scalability - Efficient Replication to other Solr Search Servers</field>
      <field name="features">Flexible and Adaptable with XML configuration and Schema</field>
      <field name="features">Good unicode support: h&#xE9;llo (hello with an accent over the e)</field>
      <field name="price">0</field>
      <field name="popularity">10</field>
      <field name="inStock">true</field>
      <field name="incubationdate_dt">2006-01-17T00:00:00.000Z</field>
    </doc>
    </add>

文档就是用来搜索的数据源，现在就可以通过管理界面搜索关键字"solr"，具体步骤是：
![solr](../resource/image/solr.png)
点击页面下的`Execute Query`后右侧就会显示查询结果，这个结果就是刚才导入进去的solr.xml的json格式的展示结果。solr支持丰富的查询语法，比如：现在想搜索字段`name`里面的关键字`Search`就可以用语法`name:search`，当然如果你搜索`name:xxx`就没有返回结果了，因为文档中没有这样的内容。    

####数据导入
导入数据到Solr的方式也是多种多样的：  

* 可以使用DIH(以后介绍)从数据库导入数据
* 支持CSV文件导入，因此Excel中数据也能轻松导入
* 支持JSON格式文档
* 二进制文档比如：Word、PDF
* 还可以通过SolrJ以编程的方式来自定义导入

####更新数据
如果同一份文档solr.xml重复导入会出现什么情况呢？实际上solr会根据文档的字段`id`来唯一标识文档，如果导入的文档的`id`已经存在solr中，那么这份文档就被最新导入的同`id`的文档自动替换。你可以自己尝试试验一下，观察替换前后管理界面的几个参数：`Num Docs`，`Max Doc`，`Deleted Docs`的变化。  

* numDocs：当前系统中的文档数量，它有可能大于xml文件个数，因为一个xml文件可能有多个`<doc>`标签。
* maxDoc：maxDoc有可能比numDocs的值要大，比如重复post同一份文件后，maxDoc值就增大了。
* deletedDocs：重复post的文件会替换掉老的文档，同时deltedDocs的值也会加1，不过这只是逻辑上的删除，并没有真正从索引中移除掉

####删除数据
通过id删除指定的文档，或者通过一个查询来删除匹配的文档

    java -Ddata=args -jar post.jar "<delete><id>SOLR1000</id></delete>"
    java -Ddata=args -jar post.jar "<delete><query>name:DDR</query></delete>"

此时`solr.xml`文档从索引中删除了，再次搜"solr"时不再返回结果。当然solr也有数据库中的事务，执行删除命令的时候事务自动提交了，文档就会立即从索引中删除。你也可以把commit设置为false，手动提交事务。  

    java -Ddata=args  -Dcommit=false -jar post.jar "<delete><id>3007WFP</id></delete>"
执行完上面的命令是文档并没有真正删除，还是可以继续搜索相关结果，最后可以通过命令：  

    java -jar post.jar -
强制提交事务。现在把刚刚删除的文件重新导入Solr中来，继续我们的学习。  

####查询数据
查询数据都是通过HTTP的GET请求获取的，搜索关键字用参数`q`指定，另外还可以指定很多可选的参数来控制信息的返回，例如：用`fl`指定返回的字段，比如`f1=name`，那么返回的数据就只包括name字段的内容

    http://localhost:8983/solr/collection1/select?q=solr&fl=name&wt=json&indent=true

* 排序
    Solr提供排序的功能，通过参数`sort`来指定，它支持正序、倒序，或者多个字段排序
    * q=video&sort=price desc
    * q=video&sort=price asc
    * q=video&sort=inStock asc, price desc
    默认条件下，Solr根据`socre` 倒序排列，socre是一条搜索记录根据相关度计算出来的一个分数。
* 高亮
    
    网页搜索中，为了突出搜索结果，可能会对匹配的关键字高亮出来，Solr提供了很好的支持，只要指定参数：
    * hl=true  #开启高亮功能
    * hl.fl=name #指定需要高亮的字段 

            http://localhost:8983/solr/collection1/select?q=Search&wt=json&indent=true&hl=true&hl.fl=features

        返回的内容中包含：

                "highlighting":{
                       "SOLR1000":{
                           "features":["Advanced Full-Text <em>Search</em> Capabilities using Lucene"]
                       }
                }

####文本分析
文本字段通过把文本分割成单词以及运用各种转换方法（如：大小写、复数移除、词干提取）后被索引，schema.xml文件中定义了字段在索引中，这些字段将作用于其中.  
默认情况下搜索"power-shot"是不能匹配"powershot"的，通过修改schema.xml文件(solr/example/solr/collection1/conf目录)，把features和text字段替换成"text_en_splitting"类型，就能索引到了。  

    <field name="features" type="text_en_splitting" indexed="true" stored="true" multiValued="true"/>
    ...
    <field name="text" type="text_en_splitting" indexed="true" stored="false" multiValued="true"/>
修改完后重启solr，然后重新导入文档  

    java -jar post.jar *.xml

现在就可以匹配了

* power-shot--->Powershot
* features:recharing--->Rechargeable 
* 1 gigabyte  --> 1G

####总结
作为入门文章，本文没有引入太多概念。安装到部署，文档更新，对solr有了初步感性的认识，接下来逐步深入学习。  



Spring MVC 前端控制器是DispatcherServlet .应用控制器拆分为处理映射器(Handler Mapping)进行处理器管理和 视图解析器(View Resolver)进行视图管理.    



####安装配置Maven
添加M2_HOME环境变量  
windows平台：   

    M2_HOME ---> C:\Program Files\Apache Software Foundation\apache-maven-3.2.1
    PATH  ---> PATH+%M2_HOME%\bin
Linux平台：

    export M2_HOME=/usr/local/apache-maven/apache-maven-3.2.1
    export M2=$M2_HOME/bin
    export PATH=$M2:$PATH

试运行`mvn  --version`：   

    C:\Users\liuzhijun>mvn --version
    Apache Maven 3.2.1 (ea8b2b07643dbb1b84b6d16e1f08391b666bc1e9; 2014-02-15T01:37:52+08:00)
    Maven home: E:\Java\apache-maven-3.2.1
    Java version: 1.6.0_41, vendor: Sun Microsystems Inc.
    Java home: E:\Java\jdk1.6.0_41\jre
    Default locale: zh_CN, platform encoding: GBK
    OS name: "windows 7", version: "6.2", arch: "amd64", family: "windows"

[安装m2e](http://download.eclipse.org/technology/m2e/releases)  
安装个m2e真是折腾人，直接安装发现eclipse需要访问sourceforge，下载相关东西，你知道的，这网站是需要番羽墙的。因此我在Eclipse上使用代理安装。  

安装失败:  
    Cannot complete the install because one or more required items could not be found.
      Software being installed: m2e - slf4j over logback logging (Optional) 1.4.0.20130601-0317 (org.eclipse.m2e.logback.feature.feature.group 1.4.0.20130601-0317)
        Missing requirement: m2e logback configuration 1.4.0.20130601-0317 (org.eclipse.m2e.logback.configuration 1.4.0.20130601-0317) requires 'bundle org.slf4j.api 1.6.2' but it could not be found
          Cannot satisfy dependency:
              From: m2e - slf4j over logback logging (Optional) 1.4.0.20130601-0317 (org.eclipse.m2e.logback.feature.feature.group 1.4.0.20130601-0317)
                  To: org.eclipse.m2e.logback.configuration [1.4.0.20130601-0317]



需要下载slf4j.jar包，于是[下载](http://www.slf4j.org/download.html)解压把该jar包放入eclipse的plugin目录下，继续上面的安装，等待若干分钟后安装完成。



Java虚拟机中，内存分为三个代：分别是：新生代（new）、老生代（Old）、永久代（Perm）。  
新生代：新建的对象都存放在这个地方  
老生代：存放从新生代中迁移过来的生命周期较久的对象，new和old共同组成堆内存。  
永久代：非堆内存，

OutOfMemoryError:Java heap space异常：所名Java虚拟机堆内存不够，主要原因：
Java 虚拟机的堆内存设置不够，通过参数-Xms  -Xmx来调整。  
代码中创建了大量大对象，长时间不能被垃圾收集器收集（存在被引用）。

OutOfMemoryError:PermGen space,Java虚拟机对永久代Perm内存设置不够。
这种情况出现可能是程序启动需要加载大量第三方jar包。

配置：
JAVA_OPTS="-server -Xms768m -Xmx768m -XX:PermSize=768m -XX:MaxPermSize=768m -XX:NewSize=256m -XX:MaxNewSize=512m"


应用占用CPU很高：两种可能：计算密集性应用，或者是死循环了。

ps -m 显示所有执行者
ps -p 进程识别码



调用jdk工具jps查看当前的java进程  

####JDBC为什么要使用PreparedStatement而不是Statement

**PreparedStatement**是用来执行SQL查询语句的API之一，Java提供了 **Statement** , **PreparedStatement** 和 **CallableStatement** 三种方式来执行查询语句，其中 **Statement** 用于通用查询， **PreparedStatement** 用于执行参数化查询，而 **CallableStatement** 则是用于存储过程。同时PreparedStatement还经常会在Java面试被提及，譬如：Statement与PreparedStatement的区别以及如何避免SQL注入式攻击？这篇教程中我们会讨论为什么要用PreparedStatement？使用PreparedStatement有什么样的优势？PreparedStatement又是如何避免SQL注入攻击的？  

####PreparedStatement是什么？
PreparedStatement是java.sql包下面的一个接口，用来执行SQL语句查询，通过调用connection.preparedStatement(sql)方法可以获得PreparedStatment对象。数据库系统会对sql语句进行预编译处理（如果JDBC驱动支持的话），预处理语句将被预先编译好，这条预编译的sql查询语句能在将来的查询中重用，这样一来，它比Statement对象生成的查询速度更快。下面是一个例子：  

    public class PreparedStmtExample {
    
        public static void main(String args[]) throws SQLException {
            Connection conn = DriverManager.getConnection("mysql:\\localhost:1520", "root", "root");
            PreparedStatement preStatement = conn.prepareStatement("select distinct loan_type from loan where bank=?");
            preStatement.setString(1, "Citibank");
        
            ResultSet result = preStatement.executeQuery();
          
            while(result.next()){
                System.out.println("Loan Type: " + result.getString("loan_type"));
            }       
        }
    } 
    Output:
    Loan Type: Personal Loan
    Loan Type: Auto Loan
    Loan Type: Home Loan
    Loan Type: Gold Loan

这个例子中，如果还是用 **PreparedStatement** 做同样的查询，哪怕参数值不一样，比如："Standard Chated" 或者"HSBC"作为参数值，数据库系统还是会去调用之前编译器编译好的执行语句（系统库系统初次会对查询语句做最大的性能优化）。默认会返回"TYPE_FORWARD_ONLY"类型的结果集（ **ResultSet** ）,当然你也可以使用preparedstatment()的重载方法返回不同类型的结果集。  

####预处理语句的优势

**PreparedStatement**提供了诸多好处，企业级应用开发中强烈推荐使用PreparedStatement来做SQL查询，下面列出PreparedStatement的几点优势。  

1. **PreparedStatement**可以写动态参数化的查询  
    用PreparedStatement你可以写带参数的sql查询语句，通过使用相同的sql语句和不同的参数值来做查询比创建一个不同的查询语句要好，下面是一个参数化查询：  

        SELECT interest_rate FROM loan WHERE loan_type=?  

    现在你可以使用任何一种loan类型如："personal loan","home loan" 或者"gold loan"来查询，这个例子叫做参数化查询，因为它可以用不同的参数调用它，这里的"?"就是参数的占位符。  

2. **PreparedStatement**比 **Statement** 更快  
    使用 **PreparedStatement** 最重要的一点好处是它拥有更佳的性能优势，SQL语句会预编译在数据库系统中。执行计划同样会被缓存起来，它允许数据库做参数化查询。使用预处理语句比普通的查询更快，因为它做的工作更少（数据库对SQL语句的分析，编译，优化已经在第一次查询前完成了）。为了减少数据库的负载，生产环境中德JDBC代码你应该总是使用 **PreparedStatement** 。值得注意的一点是：为了获得性能上的优势，应该使用参数化sql查询而不是字符串追加的方式。下面两个SELECT 查询，第一个SELECT查询就没有任何性能优势。  
    SQL Query 1:字符串追加形式的PreparedStatement  

        String loanType = getLoanType();
        PreparedStatement prestmt = conn.prepareStatement("select banks from loan where loan_type=" + loanType);

    SQL Query 2：使用参数化查询的PreparedStatement  

        PreparedStatement prestmt = conn.prepareStatement("select banks from loan where loan_type=?");
        prestmt.setString(1,loanType);  
    第二个查询就是正确使用PreparedStatement的查询，它比SQL1能获得更好的性能。  

3. **PreparedStatement**可以防止SQL注入式攻击  
    如果你是做Java web应用开发的，那么必须熟悉那声名狼藉的SQL注入式攻击。去年Sony就遭受了SQL注入攻击，被盗用了一些Sony play station（PS机）用户的数据。在SQL注入攻击里，恶意用户通过SQL元数据绑定输入，比如：某个网站的登录验证SQL查询代码为：  

        strSQL = "SELECT * FROM users WHERE name = '" + userName + "' and pw = '"+ passWord +"';"
    恶意填入：  
    
        userName = "1' OR '1'='1";
        passWord = "1' OR '1'='1";
    那么最终SQL语句变成了：
    
        strSQL = "SELECT * FROM users WHERE name = '1' OR '1'='1' and pw = '1' OR '1'='1';"
    因为WHERE条件恒为真，这就相当于执行： 
    
        strSQL = "SELECT * FROM users;"
    因此可以达到无账号密码亦可登录网站。如果恶意用户要是更坏一点，用户填入：
    
        passWord = ';DROP TABLE users 
    SQL语句变成了：
    
        strSQL = "SELECT * FROM users WHERE name = 'any_value' and pw = ''; DROP TABLE users"
    这样一来，虽然没有登录，但是数据表都被删除了。  

    然而使用PreparedStatement的参数化的查询可以阻止大部分的SQL注入。在使用参数化查询的情况下，数据库系统（eg:MySQL）不会将参数的内容视为SQL指令的一部分来处理，而是在数据库完成SQL指令的编译后，才套用参数运行，因此就算参数中含有破坏性的指令，也不会被数据库所运行。  
    补充：避免SQL注入的第二种方式：  
    在组合SQL字符串的时候，先对所传入的参数做字符取代（将单引号字符取代为连续2个单引号字符，因为连续2个单引号字符在SQL数据库中会视为字符中的一个单引号字符，譬如：

        strSQL = "SELECT * FROM users WHERE name = '" + userName + "';"
    传入字符串：

        userName  = " 1' OR 1=1 " 
    把userName做字符替换后变成：  
    
        userName = " 1'' OR 1=1"
    最后生成的SQL查询语句为：  
    
        strSQL = "SELECT * FROM users WHERE name = '1'' OR 1=1'  
    这样数据库就会去系统查找name为“1' ' OR 1=1”的记录，而避免了SQL注入。  

4. 比起凌乱的字符串追加似的查询，PreparedStatement查询可读性更好、更安全。 

####PreparedStatement的局限性
尽管PreparedStatement非常实用，但是它仍有一定的限制。  
1. 为了防止SQL注入攻击，PreparedStatement不允许一个占位符（？）有多个值，在执行有**IN**子句查询的时候这个问题变得棘手起来。下面这个SQL查询使用PreparedStatement就不会返回任何结果  

    SELECT * FROM loan WHERE loan_type IN (?)
    preparedSatement.setString(1, "'personal loan', 'home loan', 'gold loan'");
那如何解决这个问题呢？请你继续关注本博客，下期告诉你答案。


####不算总结的总结 
关于PreparedStatement接口，需要重点记住的是：   
1. PreparedStatement可以写参数化查询，比Statement能获得更好的性能。  
2. 对于PreparedStatement来说，数据库可以使用已经编译过及定义好的执行计划，这种预处理语句查询比普通的查询运行速度更快。  
3. PreparedStatement可以阻止常见的SQL注入式攻击。  
4. PreparedStatement可以写动态查询语句  
5. PreparedStatement与java.sql.Connection对象是关联的，一旦你关闭了connection，PreparedStatement也没法使用了。  
6. "?" 叫做占位符。  
7. PreparedStatement查询默认返回FORWARD_ONLY的ResultSet，你只能往一个方向移动结果集的游标。当然你还可以设定为其他类型的值如："CONCUR_READ_ONLY"。   
8. 不支持预编译SQL查询的JDBC驱动，在调用connection.prepareStatement(sql)的时候，它不会把SQL查询语句发送给数据库做预处理，而是等到执行查询动作的时候（调用executeQuery()方法时）才把查询语句发送个数据库，这种情况和使用Statement是一样的。  
9. 占位符的索引位置从1开始而不是0，如果填入0会导致*java.sql.SQLException invalid column index*异常。所以如果PreparedStatement有两个占位符，那么第一个参数的索引时1，第二个参数的索引是2.  

以上就是为什么要使用PreparedStatement的全部理由，不过你仍然可以使用Statement对象用来做做测试。但是在生产环境下你一定要考虑使用 **PreparedStatement** 。  

原文：[Why use PreparedStatement in Java JDBC](http://javarevisited.blogspot.com/2012/03/why-use-preparedstatement-in-java-jdbc.html#ixzz2YjEhPIis)  
更多参考：  
[SQL注入攻击](http://zh.wikipedia.org/wiki/SQL%E8%B3%87%E6%96%99%E9%9A%B1%E7%A2%BC%E6%94%BB%E6%93%8A)  
[参数化查询](http://zh.wikipedia.org/wiki/%E5%8F%83%E6%95%B8%E5%8C%96%E6%9F%A5%E8%A9%A2)  
[预处理语句与存储过程](http://php.net/manual/zh/pdo.prepared-statements.php)  

###Java为什么需要Lambda表达式（-）

Lambda表达式即将出现在Java8中，但似乎还是遇到了些阻力，并不是所有Java 开发者都愿意买账，他们觉得添加函数式编程（[参考](http://www.ruanyifeng.com/blog/2012/04/functional_programming.html) ）的特性到Java中本身就是一种错误，因为这样不得不在Java所擅长的面向对象和指令式编程（[参考](http://zh.wikipedia.org/wiki/%E6%8C%87%E4%BB%A4%E5%BC%8F%E7%B7%A8%E7%A8%8B) ）中做出妥协。这篇文章的目的就是希望能用一些直白的例子来明确阐述Lambda的必要性以及打消部分开发者的顾虑---作为一门流行大众化编程语言支持Lambda表达式的的必要性。  

####外部与内部迭代  
先来看一个简单的例子：  

    List<Interger> numbers = Arrays.asList(1,2,3,4,5,6);

迭代所有元素并打印结果：  

    for (int number : numbers){
        System.out.println(number);
    }
（此处省略68字，俺实在是不知道作者说的啥，如果你看明白了，不妨在评论里告诉我，谢谢！）下面是作者与他两岁的女儿在玩玩具后的一段对话：  

>我：“Sofia，我们把完全收好吧，地上还有玩具吗？”
>Sofia：“好的，还有一个球”
>我：“嗯，把球放到盒子里去，还有其它东西吗？”
>Sofia：“有，还有我的洋娃娃”
>我：“好吧，把洋娃娃也放进盒子里，还有吗？”
>Sofia：“还有一本书”
>我：“把书也放进去，还有吗”
>Sofia：“没有了”
>我：“非常好，任务完成了”

这是我们天用着Java集合做的事情，但我们已不是两岁的小孩了，从外部迭代集合，逐个取出来处理，如果这样告诉Sofia：“把所有的玩具放进盒子里”，这种方式会更好。另外两个原因，为什么内部迭代更好呢？首先，Sofia可以同时选择一手拿娃娃，一手拿球，第二，他可以优先把最近的玩具放进盒子里。同理，使用内部迭代，[JIT编译器](http://zh.wikipedia.org/wiki/%E5%8D%B3%E6%99%82%E7%B7%A8%E8%AD%AF)可以并行处理元素达到优化或者按照不同的顺序处理。这些优化效果要是放在外部迭代那是没法实现的。   

为什么不在内部迭代？我认为这仅仅只是糟糕的心理习惯在作祟，Java集合框架中缺乏这样的支持。在Java8预览版中可以创建匿名内部类，如下：

    numbers.forEach(new Consumer<Interger>(){
        public void accept(Integer value){
            System.out.print(value);
        }
    });

重点来了....  

事实上，forEach方法和Consumer接口已经添加到Java8中来了，但是你可以在Java5+中使用类似guava或者lambdaj做一些类似的操作，然而lambda表达试可以用更少的代码和易读的方式实现相同的结果：  
    
    numbers.forEach((Integer value) -> System.out.println(value));

lambda表达式由两部份组成，箭头左边是参数部分右边是函数体，在这个例子中编译器自动计算出lambda表达式有相同的签名唯一没有实现的接口consumer（这就叫函数结果的原因），即使声称的直接骂可以潜在不同，类型声明lambda表达式参数可以，最大的部分  

    numbers.forEach(value -> System.out.println(value))；

但我们可以重写写它，最后一条语句甚至可以更简洁地使用方法引用，Java8中另一个特性：可以使用**::**操作符引用一个静态或实例方法：
      
    numbers.forEach(System.out::println);

以这种方式，函数式编程因[eta扩展](http://hongjiang.info/tag/java8/)而闻名。方法的名字被编译器expaned被编译器。

####不仅仅传递值，还有行为
我们看到前面些例子主要可能的原因为什么lambda表达式如此有用，传递一个lambda表达式给另一个方法，允许我们传递的不仅仅是值，还包括行为，这使得戏剧性的上升到我们抽象的级别，更加泛型，灵活可用的API，让我们看一个更深的例子：  

    List<Integer> numbers = Arrays.asList(1, 2, 3, 4, 5, 6);
我们请求些一个方法，所有整数的和：  

    public int sumAll(List<Integer> numbers) {
        int total = 0;
        for (int number : numbers) {
            total += number;
        }
        return total;
    }

没过几天，经理跑过来告诉我们说，因业务需求还需要要一个函数求偶数项的和，因此什么样的方法是最快的呢？很简单，只要拷贝粘贴前面那个方法就行了：

    public int sumAllEven(List<Integer> numbers) {
        int total = 0;
        for (int number : numbers) {
            if (number % 2 == 0) {
                total += number;
            }
        }
        return total;
    }
    
又有一天，另外一个需求来了，这次他们需要求和只对大于3的数求和。那怎么做呢？我们再一次拷贝粘贴代码调整条件，但是这样感觉代码很乱，不是吗？现在，我们可以“First write，Second Copy，ThirdRefactor"原则，式时候考虑一个更聪明的更通用的方法去处理了。在这个例子中实现了一个更高顺序函数接受列表，还有断言（另一个函数式接口java8中出现的），定义了如何过滤。

    public int sumAll(List<Integer> numbers, Predicate<Integer> p) {
        int total = 0;
        for (int number : numbers) {
            if (p.test(number)) {
                total += number;
            }
        }
        return total;
    }

换句话说，我们传递方法不仅仅是这些数据，而且还有行为，定义如何使用他们。这样方法我们可以满足所有3种需求用一个更通用可重用的方法  

    sumAll(numbers, n -> true);
    sumAll(numbers, n -> n % 2 == 0);
    sumAll(numbers, n -> n > 3);

在第二篇文章中，我将展示更多例子说明lambda可以使我们的Java代码更可度更简洁。









https://jdk8.java.net/lambda/

Main方法是学习Java编程语言时知道的第一个方法，你是否曾经想过为什么main方法是public、static、void的。当然，很多人首先学的是C和C++，但是在Java中main方法与前者有些细微的不同，它不会返回任何值，**为什么main方式是public、static、void** ，这篇文章尝试去找到一些答案。  

Main方法是Java程序的入口，记住，我们这里不会讨论Servlet、MIDlet和其他任何容器管理的java程序，在java核心编程中，JVM会查找类中的**public static void main(String[] args)**，如果找不到该方法就抛出错误**NoSuchMethodError:main** 程序终止。  
Main方法必须严格遵循它的语法，方法签名必须是public static void，参数是字符串数组类型，如果是Java1.5及以后的版本也可以使用可变参数：**public static void main(String... args)**  

####为什么main方法是静态的（static）
1. 因为main方法是静态的，JVM调用这个方法不需要创建任何包含这个main方法的实例。  
2. 因为C和C++同样有类似的main方法作为程序执行的入口。
3. 如果main方法不声明为静态的，JVM就必须创建main类的实例，因为构造器可以被重载，JVM没法确定找哪个main方法。  
4. 静态方法和静态数据加载到内存就可以直接调用而不需要像实例方法一样创建了实例才能调用，如果main方法是静态的，那么它就会被加载到JVM上下文中成为可执行的方法。  
####为什么main方法是公有的（public）
Java指定了一些可访问的修饰符如：private、protected、public，任何方法或变量都可以声明为public，Java可以从该类之外的地方访问。因为main方法是公共的，JVM就可以轻松的访问执行它。  
####为什么main方法没有返回值（Void）
因为main方法不应该返回任何值，因此void意味着main不会返回任何值  

####总结

1. main方法必须声明为public、static、void，否则JVM没法运行程序
2. 如果JVM找不到main方法就跑出NoSuchMethodException:main异常，例如：如果你运行命令：`java HelloWrold`，JVM就会在HelloWorld.class文件中搜索public static void main (String[] args) 放法
3. main方式是程序的入口，程序执行的开始处。
4. main方法被一个特定的线程"main"运行，程序会一直运行直到main线程结束或者non-daemon线程终止。
5. 当你看到“Exception in Thread main”如：**Excpetion in Thread main:Java.lang.NullPointedException** ,意味着异常来自于main线程
6. 你可以声明main方法使用java1.5的可变参数的方式如：  

        public static void main(String... args)
7. 除了static、void、和public，你可以使用final，synchronized、和strictfp修饰符在main方法的签名中，如：  

        public strictfp  final synchronized static void main(String[] args)

8. main方法在Java可以像其他方法一样被重载，但是JVM只会调用上面这种签名规范的main方法。  
9. 你可以使用throws子句在方法签名中，可以抛出任何checked和unchecked异常
10. 静态初始化块在JVM调用main方法前被执行，它们在类被JVM加载到内存的时候就被执行了。


[javavisited](http://javarevisited.blogspot.com/2011/12/main-public-static-java-void-method-why.html)

虚拟网络（Virtual Networking）
在linux host  server中，switch做为网络接口显示
virbr0 相当于虚拟交换机
NAT；网络地址转换（Network Address Translation）默认虚拟交换机virbr0使用NAT模式（IP欺骗而不是SNAT或DNAT），NAT通过使用iptables规则来设置
DNS&DHCP：虚拟交换机通过DHCP的方式提供ip给guest使用
libvirt使用dnsmasq

其他虚拟交换机路由转发类型
路由模型（Routed mode）
host扮演路由器的角色，外界可以直接和虚拟机通信，public.xml
isolated 模型

###参考:
1. [libvirt archnetwork](http://libvirt.org/archnetwork.html)
2. [libvirt formatnetwork](http://libvirt.org/formatnetwork.html)
3. [libvirt formatnwfilter](http://libvirt.org/formatnwfilter.html)
4. [libvirt Networking](http://wiki.libvirt.org/page/Networking)
5. [libvirt 网络管理](http://wenku.baidu.com/view/3957ac3a376baf1ffc4fad9b.html)
6. [libvirt 的使用（0.2）](http://itxx.sinaapp.com/blog/content/86)
7. [NAT](https://zh.wikipedia.org/wiki/%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2)

Linux 命令之du----查看磁盘空间使用情况
---------------------------
du的全称为disk usage，意为磁盘空间使用情况，du素有磁盘管理三剑客之一的称号，它的功能是**统计目录和文件所占磁盘空间大小**.

1. block：记录文件真实内容的地方，文件太打时，占用多个block
2. inode：记录文件的属性（文件权限rwx，文件拥有者，群组，时间参数等）和到文件所在block的索引号。一个文件占用一个inode，
3. superblock：记录文件系统的整体信息，包括inode/block的总量，使用量，剩余量以及文件系统格式相关的信息。

4. inode和block的数量于大小在系统格式化时就已经固定了的。每个inode大小均为128字节，block的大小于1k，2k和4k之分。inode记录一个block需要4个字节
5. 目录对应的block保存的是该目录下的文件名于该文件名占用的inode号码

###日志式文件系统（journaling filesystem）

更新文件的步骤  
1. 准备阶段：系统写入文件时，现在日志记录区块中记录某个文件准备要写入的信息。
2. 实际写入：开始写入文件的权限和数据，更近metadata数据
3. 结束： 完成数据与metadata的更新后，在日志记录区块中完成该文件的记录。

五种I/O模型
========================
程序的输入操作有两个步骤：  
1. 等待有数据可以读
2. 将数据从系统内核中拷贝到程序的数据区
###阻塞IO
阻塞IO是当调用函数recvfrom时，程序会一直阻塞直到系统内核有数据可读。  
![bio](..\resource\image\io\bio.png)
###非阻塞IO
非阻塞IO相当于告诉系统内核："当我请求的IO操作不能马上完成时，想让我的进程进行休眠等待的时候，不要这么干，请马上返回一个错误给我"。  

应用程序不停的轮询(polling)检查是否IO操作已经就绪，这个很浪费CPU资源。这种模式不常用。  
![nbio](..\resource\image\io\nbio.png)

###IO多路复用
使用IO多路技术，是调用select()和poll()函数，这两个函数是阻塞的，这样就不是调用recvfrom的时候阻塞。  
这种多路复用需要调用两个函数，先调用select或poll()，才进行真正的读写。那么它的优势在于：它能同时等待多个文件描述符。其中的任意一个进入读就绪状态select()函数就可以返回。  


####memcached分布式
计算hash: 公式:  h = Hash(key)%n  
n:memcached服务器的节点数量  
hash函数是一个从字符串到整数的转换函数.  
优点: 简单, key分布均匀  
缺点:  扩展性不好,容错性也不好, 如果有一台服务器宕机了

实验:  abc...xyz 二十六个字母代表26个key,需要分布在n0,n1,n2缓存上去.

    keys = [chr(i) for i in range(97,97+26)]
    result = {}
    for key in keys:
         k = hash(key)%3
         if k not in result:
             result[k] = [key,]
         else:
             result.get(k).append(key)

result:

    {
        0: ['v', 'x', 'z'], 
        1: ['b', 'd', 'f', 'h', 'j', 'l', 'n', 'p', 'r', 't', 'w', 'y'], 
        2: ['a', 'c', 'e', 'g', 'i', 'k', 'm', 'o', 'q', 's', 'u']
    }

新增一个节点后, 命中率降到了原来的 10/26

    {
        0: ['a', 'e', 'i', 'm', 'q', 'u', 'y'], 
        1: ['d', 'h', 'l', 'p', 't', 'x'], 
        2: ['c', 'g', 'k', 'o', 's', 'w'], 
        3: ['b', 'f', 'j', 'n', 'r', 'v', 'z']
    }

一致性哈希具有良好的单调性,不会应为节点的增加或者减少而影响哈希的重新定位.  
http://amix.dk/blog/post/19367
http://blog.codinglabs.org/articles/consistent-hashing.html
https://www.adayinthelifeof.nl/2011/02/06/memcache-internals/

memcachedΪܵķֲʽϵͳûTwitterFlickrWikipediaweiboȵȣﵽһĳ̶ʹãþͨݿѯݿʴ߶̬WebӦõٶȡӦӣ÷I/Oʵ֣ͻ˵Ҳǳ򵥣õķҲsetgetdeletereplace  
####װ
1. :[libevent](https://github.com/downloads/libevent/libevent/libevent-2.0.21-stable.tar.gz)
2. :[memcached](https://memcached.googlecode.com/files/memcached-1.4.15.tar.gz)
3. װ

        #װlibevent
        ./configure --prefix=/usr
        make
        sudo make install

        #װmemcached
        ./configure --with-libevent=/usr
        make
        sudo make install

4. memcache:

         memcached -d -m 1024 -u root -l 192.168.0.200 -p 11211 -c 1024 -P /tmp/memcached.pid
         
         memcached -p 11211 -m 64m -d

- -d Ϊػ(daemon)ں̨  
- -u memcacheû  
- -p Сд, TCP˿ڣĬ11211  

- -m ʹڴ棬Ĭ64MmemcachedǻڴĻϵͳ  
- -c 󲢷  
- -l ķIPַ  
- -P memcachepidļ  

####memcached

- -v    error/warning
- -vv   Ӧ
- -vvv  ڲ״̬ 

ʹ÷IOڴпһռ䣬һHashTableMemcached̹ЩHashTable  

####memcachedPythonͻˣ  
- [pylibmc](http://sendapatch.se/projects/pylibmc/)Ƕ[libemcached](http://libmemcached.org/libMemcached.html)һװgithub forkġȻlibemcachedô[libmemecached](https://launchpad.net/libmemcached/1.0/1.0.17/+download/libmemcached-1.0.17.tar.gz)   
 pylibmcʱ쳣

        ImportError: libmemcached.so.11: cannot open shared object file: No such file or directory
- [python-libmemcached](http://code.google.com/p/python-libmemcached/)־֪ҲǶlibmemcachedķװpylibmcͬҪPyrex   
- [cmemcache](http://gijsbert.org/cmemcache/)   
- [python-memcache](http://www.tummy.com/software/python-memcached/)ǴpythonʵֵĿͻˣ  


¾python-memcacheװ   

    pip install python-memcache

ʱѧϰԴ:[memcache.py](https://github.com/linsomniac/python-memcached/blob/master/memcache.py)  

ʹ÷  

    import memcache
        mc = memcache.Client(['127.0.0.1:11211'], debug=0)
    
        mc.set("some_key", "Some value")
        #setиĬϵĹʱΪ0,ʾûйʱ,ֵ60*60*24*30 Ҳһ
        value = mc.get("some_key")
    
        mc.set("another_key", 3)
        mc.delete("another_key")
    
        mc.set("key", "1")   # note that the key used for incr/decr must be a string.
        mc.incr("key")
        mc.decr("key")       #decr0Ͳ¼
    
    The standard way to use memcache with a database is like this::
    
        key = derive_key(obj)
        obj = mc.get(key)
        if not obj:
            obj = backend_api.get(...)
            mc.set(key, obj)
    
        # we now have obj, and future passes through this code
        # will use the object from the cache.

Clientmemcache servers أӹ췽յһͿԿһpool  

key ֵǣ  
1. 򵥵Ĺϡͣstring,integerȣ  
2. 

ķԻΪһ¼飺  
ã`__init__`, set_servers, forget_dead_hosts, disconnect_all, debuglog  
룺set, add, replace, set_muti  
ȡget, get_multi  
incr, decr  
Ƴdelete, delete_multi  
####pyramid_beaker
BeakerPyramidĺsessionͬҲǻ  
#####װ

    pip install pyramid_beaker
    #Ҳsetup.pyrequiresмpyramid_beaker
#####
`__init__.py`ļм

    config = Configurator()
    config.inlucde('pyramid_beaker')

ο:  
http://returnfoo.com/2012/02/memcached-memory-allocation-and-optimization-2/
http://www.adayinthelifeof.nl/2011/02/06/memcache-internals/



安装成功后, 确认一下memcached进程是否启动, 如下显示memecached进程已经存在.  

    lzjun@lzjun:~/workspace/note/note/memcached$ ps -eaf | grep memcached
    lzjun    10892  3749  0 11:48 ?        00:00:00 memcached -d

使用`telnet`连接Memcached, 格式:  

    telnet <hostname> <port>

默认端口是11211  

    telnet localhost 11211

####存储相关命令
**set/add/replace/append/prepend/cas**  

**set**

    set <key> <flags> <exptime> <bytes> \r\n <value> \r\n

* key:      key就是你要存储数据的键值, 数据通过key来获取
* flags:   无符号的32位整型,客户端提供的参数,用于标识数据格式,比如使用MEMCACHE_COMPRESSED表示数据压缩存储.还有json, xml等.对服务端而言,这个参数并不知道是做什么用的.
* exptime: 写入缓存失效的时间, 单位是秒, 0表示数据永久不过期, 除非当前内存不够用了使用LRU算法来回收该段内存.
* bytes:   用来缓存value的数据块的字节数, `<value>`的大小不能超过此`<bytes>` 
* \r\n:    表示回车换行
* value:   表示要缓存的数据


    set name 0 100 3
    liu
    STORED
    get name
    VALUE name 0 3
    liu
    END

如果bytes指定的值过小,而实际存储的值偏大的话,就会有Error,偏小也不行,必须相等,: 

    set name 0 100 3
    liuzhijun
    CLIENT_ERROR bad data chunk
    ERROR

**add** 只能添加不存在的key, 如果已经存在就不再存储  

    add length 0 0 4
    liuz
    STORED
    add length 0 0 4
    zjun
    NOT_STORED

**replace** 只能对已经存在的key进行替换  

    replace xxx 0 0 4
    junz
    NOT_STORED
    replace length 0 0 4
    junz
    STORED
    get length
    VALUE length 0 4
    junz
    END
**cas** : check and set , 只有版本号匹配的才能存储, 下面的6是版本号  

    cas length 0 0 4 6
    hell
    EXISTS
    gets length
    VALUE length 0 4 7
    lzju
    END
因为length的版本号是7, 而cas指定的是6,  直接返回了EXISTS    

    cas length 0 0 4 7
    hell
    STORED
    gets length
    VALUE length 0 4 8
    hell
    END
这样设计的目的是多个客户端修改同一个记录时, 防止使用改变过了key/value.  


####读取命令
**get/gets**  

    get/gets <key>

gets返回带版本信息的数据, 返回格式:  

    VALUE <key> <flags> <bytes> [versions] \r\n
    <datablock>\r\n
如:  

    gets length
    VALUE length 0 4 7
    lzju
    END
    get length name   #获取多个值 
    VALUE length 0 4
    lzju
    VALUE name 0 3
    liu
    END

####删除命令
格式:`delete <key>`  
####计数命令
格式: `incr/decr <key> <int>`, key必须存在, value必须是数字  

    set size 0 0 1
    1
    STORED
    incr size 10
    11
    decr size 5
    6

####统计命令
stats/settings/items/sizes/slabs
####工具
[memcached-tool](https://github.com/memcached/memcached/blob/master/scripts/memcached-tool) : a stats/management tool for memcached




####memcached协议
从第二篇介绍来看, memcached的[协议](https://github.com/memcached/memcached/blob/master/doc/protocol.txt)非常简单, 没有采用xml,json等数据格式, 就是简单的**文本行**(直接telnet就可以完成数据的存取操作)和**非结构化数据**.文本行总是以\r\n结尾, 非结构化数据同样也是以\r\n结尾  
####内存分配机制
slab是memcached用来存放item的机制., 如图:  
![](../resource/image/slab.png)

**item**:需要存储的数据, 包括item结构体, key和value  
**slab class**:相当于一个容器, 没有大小概念, 由page组成, page默认大小是1MB,也就是说slab是装有page的容器.  
**page**:page会分解成多个大小一样的chunk,chunk是存储item的最小单元.在不同的class里面,chunk的size也是不一样的.每个slab class有一个或者多个pages  
参数-I可以指定page大小的大小.  
**增长因子factor**:默认是1.25  , 启动的时候可以使用参数 -f 指定, 参数值越大class就越少.  
参数-n可以指定chunk的大小, 

当一个对象需要存储的时候, 对象的大小决定它存储在什么位置, 如果一个对象的大小90kb, 那么就会存储在100kb的slab class中去.这样会浪费掉10kb的空间   

    memcached -d -m 128 -vv
    slab class   1: chunk size        80 perslab   13107
    slab class   2: chunk size       104 perslab   10082
    slab class   3: chunk size       136 perslab    7710
    slab class   4: chunk size       176 perslab    5957
    slab class   5: chunk size       224 perslab    4681
    ...............
    ...............
    ...............
    slab class  38: chunk size    367192 perslab       2
    slab class  39: chunk size    458992 perslab       2
    slab class  40: chunk size    573744 perslab       1
    slab class  41: chunk size    717184 perslab       1
    slab class  42: chunk size   1048576 perslab       1

当然这是memcache的内存分配策略, 此时还没有真正分配内存, 可以使用free前后对比一下就知道.会随着需求逐步分配给各个slab  
**分配策略**:


####item数据格式
双向链表结构
![](../resource/image/memcached-item.png)


####MySQL索引
索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。更通俗的说，数据库索引好比是一本书前面的目录，能加快数据库的查询速度。在没有索引的情况下，做查询操作的时候数据库会遍历全部数据后选择符合条件的；而有索引之后，数据库会直接在索引中查找符合条件的选项。如果SQL语句换SELECT * FROM article WHERE id=2000000”，那么在没有索引时（注：一般数据库默认都会为主键生成索引）数据库按照顺序读取完200万行数据。  
####查看索引

    show index from TABLE_NAME
    比如:
    show index from blog_blog;
    返回:
    +-----------+------------+--------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+
    | Table     | Non_unique | Key_name           | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type |
    +-----------+------------+--------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+
    | blog_blog |          0 | PRIMARY            |            1 | id          | A         |           5 |     NULL | NULL   |      | BTREE      |
    | blog_blog |          0 | title              |            1 | title       | A         |           5 |     NULL | NULL   |      | BTREE      |
    | blog_blog |          1 | blog_blog_6f33f001 |            1 | category_id | A         |        NULL |     NULL | NULL   |      | BTREE      |
    | blog_blog |          1 | blog_blog_e969df21 |            1 | author_id   | A         |        NULL |     NULL | NULL   |      | BTREE      |
    +-----------+------------+--------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+

####创建索引
首先我们使用[代码](xxx)创建一个my_user表,表结构如下, 里面有10万条数据, 其中name是值是随机长度的  

    mysql> show create table my_user;
    +---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
    | Table   | Create Table                                                                                                                                                                    |
    +---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
    | my_user | CREATE TABLE `my_user` (
      `id` int(11) NOT NULL AUTO_INCREMENT,
      `name` varchar(50) NOT NULL,
      PRIMARY KEY (`id`)
    ) ENGINE=MyISAM AUTO_INCREMENT=200001 DEFAULT CHARSET=utf8 |
    +---------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
    1 row in set (0.02 sec)

my_user数据表相关的文件:  

    root@lzjun:/var/lib/mysql/django_blog# ll -h my_user.*
    -rw-rw---- 1 mysql mysql  8.4K  3月 13 15:11 my_user.frm
    -rw-rw---- 1 mysql mysql  2.5M  3月 13 15:17 my_user.MYD
    -rw-rw---- 1 mysql mysql 1005K  3月 13 15:17 my_user.MYI

在name没有创建索引时,查询一条数据的时间是:0.12s  

    mysql> select * from my_user where name like 'pkhavwcrybsjoimztnq';
    +--------+---------------------+
    | id     | name                |
    +--------+---------------------+
    | 100093 | pkhavwcrybsjoimztnq |
    +--------+---------------------+
    1 row in set (0.12 sec)

#####普通索引
1. 方式一:  

        CREATE INDEX index_name on TABLE_NAME(Column_name)

        mysql> create index i_name on my_user(name);
        Query OK, 100000 rows affected (0.84 sec)
        Records: 100000  Duplicates: 0  Warnings: 0

2. 方式二:  

        ALTER  TABLE  表名  ADD   [ UNIQUE | FULLTEXT | SPATIAL ]   INDEX  
        索引名（属性名  [ (长度) ]  [ ASC | DESC]）; 

        mysql> alter table my_user add index i_name  (name);
        Query OK, 100000 rows affected (0.51 sec)
        Records: 100000  Duplicates: 0  Warnings: 0
3. 方式三:  
    直接在创建表的时候创建索引.  
    
        CREATE TABLE my_user2 ( 
                id int not null primary key auto_increment, 
                name varchar(50), 
                index iname (name));

创建索引后,相应的索引文件也增大了不少.  

#####唯一索引
普通索引允许被索引的列包含重复的值, 比如人的名字. 如果这列的值都是唯一的那么就可以使用唯一索引.他能改善查询的效率.另外一点是在有新数据插入的时候, 会自动检查新记录的字段的值是否已经存在了,如果存在MySQL会拒绝插入.因此很多场合,唯一索引的另一个目的是避免数据重复插入.  

    ALTER TABLE my_user ADD UNIQUE INDEX i_name (name);

或者是创建表的时候指定:  

    CREATE TABLE my_user(
        id int not null PRIMARY key AUTO_INCREMENT,
        name varchar(50),
        code varchar(50),
        UNIQUE KEY ui_name_code (name,code)
    )
主键与唯一索引的区别是:PRIMARY KEY is equivalent to UNIQUE NOT NULL,也就是说唯一索引的字段可以是重复的NULL.   






####设计索引原则
1. 适合做索引的列一般是WHERE字句中出现的列,或者连接子句中的列,或者ORDERBY排序子句中.而不是要查询的列.   
2. 

mysqldump备份恢复数据库
=======================
mysqldump程序可以用来备份和恢复数据库,默认情况mysqldump会创建drop table, create table,和insert into的sql语句.  

语法  

    > mysqldump [options] db_name [tbl_name ...]
    > mysqldump [options] --databases db_name ...
    > mysqldump [options] --all-databases

备份指定数据库  

    mysqldump -uroot -p[passwd] db1 > dumpfilename.sql

备份多个数据库   

    mysqldump -uroot -p[passwd] --databases db1 db2 > dumpfilename.sql
备份所有数据库  

    mysqldump -uroot -p[passwd] --all-databases > dumpfile.sql

备份指定表  

    mysqldump -uroot -p[passwd] db1 table1 > db1_table1.sql

只备份表结构  
    
    mysqldump -uroot -p[passwd] -d db1 > dumpfile.sql

如果不想要drop table, 附上参数`--compact`  

    mysqldump -uroot -p[passwd] --compact db1 > dumpfile.sql

还原  
    
    mysql -uroot -ppassword db1 < dumpfile.sql


如果存储引擎是MYISAM,还可以使用`mysqlhotcopy`  

    mysqlhotcopy -u root -p passwd db1 备份目录

注意,-u后面有个空格, mysqlhotcopy相当于把数据库文件拷贝到新的目录. 恢复的方法就是把该备份目录拷贝到mysql数据目录下面. 

慢查询日志是由一些SQL语句构成的，当查询时间超过了`long_query_time`的值时会生成慢查询日志，long_query_time的最小值是1s，默认值是10s。  

检查MySQL慢查询是否开启：  

    mysql> show variables like '%slow%';
    +---------------------+----------------------------------------------------------+
    | Variable_name       | Value                                                    |
    +---------------------+----------------------------------------------------------+
    | slow_launch_time    | 2                                                        |
    | slow_query_log      | OFF                                                      |
    | slow_query_log_file | E:\Program Files\mysql-5.6.10-winx64\data\lzjun-slow.log |
    +---------------------+----------------------------------------------------------+
    3 rows in set (0.00 sec)

默认MySQL的slow_query_log是OFF，开启的方法有：  

 1. 启动MySQL的时候开启：

        mysqld  --slow_query_log=[{0|1}]   #MySQL5.5及以上版本
    不指定值或者1表示开启，0表示关闭
        mysqld --slow_query_log_file=file_name
    指定日志文件的保存的地方，如果指定，那么默认是保存在存放数据目录的`homename-slow.log`文件中。  

        mysqld  --log-slow-queries[=file_name]  #MySQL5.1及以下版本

 2. MySQL启动后设置

        set global slow_query_log=[1|0|ON|OFF]
        set global slow_query_log_file=[file_name]

 3. my.ini中配置

        slow_query_log=1
        slow_query_log_file=/var/log/mysql_slow.log

一般long_query_time的值不宜设置过大，默认值10秒就显得不合适，通常2-5秒是理想值。当然慢查询日志会对MySQL性能有影响。如果是主从结构打开一台专门用来监控慢查询好了。


###二叉树
[二叉树](http://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8F%89%E6%A0%91)是每个节点最多有两个子树的数结构  
![btree](../resource/image/Binary_tree.png)
###树的遍历
[树的遍历](http://zh.wikipedia.org/wiki/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86#.E4.B8.AD.E5.BA.8F.E9.81.8D.E5.8E.86)是通过一种方法按照一定的顺序访问一颗树的过程，二叉树的便利方式常见的有三种：先序遍历、中序遍历、后续遍历。  
**先序遍历**：首先访问根节点然后遍历左子树，最后遍历右子树。假单记作**根左右**，上图按照先序遍历为：6 3 2 5 7 8  
**中序遍历**：先遍历左子树，然后访问根节点，再遍历右子树。简单记住**左根右**，上图按照中序遍历的结果就是：2 3 5 6 7 8  
**后续遍历**：先遍历左子树，然后遍历右子树，最后遍历访问根节点，简单记住**左右根**，上图按照后续遍历的结果是：2 5 3 7 8 6  
从中可以看出一点规律是**前中后**都是相对于根节点而言的，然后左右顺序是不变的，变得只是根节点的位置。  
###二叉查找树
二叉查找树中，左子树的值总是小于根的值，右子树的值总是大于根的值，满足这样条件的二叉树就是二叉查找树，它又称为有序二叉树。上图就是一颗二叉查找树。  

对于上图中的二叉查找树，如果想查找值为7的节点，先从根节点找，6 > 7，然后往右子树查找，第二次就找到了，而如果按照从小到大的顺序找的话，要找5次才能找到。但是二叉查找树是可以有不同构建方式的，比如下图也是一个二叉查找树：  
![phtree](../resource/image/pinghengtree.png)  
然而对于这样的二叉查找树，它的查询效率就比较前面那种要低了，前面的平均查找时间为(1+2+2+3+3+3)/6=2.3，而后面那种二叉查找树的平均查找时间为：(1+2+3+4+5+5)/6=3.16，因此要想查询效率高效就要尽可能使得二叉查找树能均匀的分布，这就有了平衡二叉树。  

###平衡二叉树
平衡二叉树是在满足二叉查找树的条件下，任何节点的左右两个子树的高度差不能大于1，比如上图中，节点5的右子树高度是2，左子树没有，他们的高度差为2，显然就不满足平衡二叉树的条件。  





####配置
#####全局配置指令
user ：worker_processes 执行的用户，group忽略时，和user是一样的  
worker_processes：
error_log
pid:
==================

    # we want nginx to run as user 'www'
    user www;

    # the load is CPU-bound and we have 12 cores
    worker_processes 12;

    # explicitly specifying the path to the mandatory error log
    error_log /var/log/nginx/error.log;

    # also explicitly specifying the path to the pid file
    pid   /var/run/nginx.pid;

    # sets up a new configuration context for the 'events' module
    events {

        # we're on a Solaris-based system and have determined that nginx
        # will stop responding to new requests over time with the default
        # connection-processing mechanism, so we switch to the second-best
        use /dev/poll;

        # the product of this number and the number of worker_processes
        # indicates how many simultaneous connections per IP:port pair are
        # accepted
        worker_connections 2048;
    }
    
这个配置文件应处于nginx.conf文件的最顶部.  

使用include指令

测试：
nginx -t -c <path-to-nginx.conf>
测试include的语法有没有错误

####HTTP server 块
这是最常用的模块,位于全部配置的下面


####数据持久层
数据库: MySQL, 缓存:Memecache  

####应用层
使用Mako作为模板语言, Web框架:Pyramid, ORM:SQLAlchemy,WSGI服务器是Gunicorn.Nginx作为代理.项目部署使用Fabric.搜索服务:Sphinx.静态文件托管在又拍云 ,邮件服务使用的是MailGun.   

####前端
jQuery  




#Django 测试指南

对绝大部分人来说，测试Django应用感觉很神秘，他们只是听说代码必须要测试，但是经常找不到线索如何入手。当他们看了Django的[测试文档](http://docs.djangoproject.com/en/1.3/topics/testing/)，他们找到深入的哪些功能是可用的，但是如果实现没有任何指导。  

这是本博客系列的第一篇，尝试帮助大家减轻压力，使得每个人在测试潮流。假设你从来没有做过任何测试，但是对Python&Django很熟悉了。  

我们将贯穿添加测试到perennial [教程](https://docs.djangoproject.com/en/1.3/intro/tutorial01/)，为了更好的关注，我上传了代码到[Github](https://github.com/toastdriven/guide-to-testing-in-django)，标签有主要的步骤显示代码是如何改变的。  

在我们深入代码前，我们先介绍一些基本的概念，讨论如何think/go 关于测试。  

####为什么必须要测试代码

*Code without tests is broken by design*  --[jacob](http://jacobian.org/)  

为代码提供自动化测试是重复确定最小化开发者努力，你写的代码处理任务.我喜欢特车作为我的保险策略。他们经常能让我远离破坏已存在的代码。再去看看其他愚蠢额人们，他们同样证明代码工作正确。没有证明，你有得是一堆代码工作起来正确，一旦你的机器你又要手工测试一遍又一遍在将来。  

当你第一次开始，谢测试是一个提心吊胆的任务，听起来就象是额外的工作。但是简单测试非常易于编写，有一些测试总比没有测试好。你添加的新的测试后，你的套件货跟着增长。  

这不是说有了测试后就能解决任何问题，软件中bug总是有的，也是测试忽略了代码深度或者用户将使用一些意外之事的方法，不是测试给你信心，一个安全的网络。  

####测试的种类
有很多种不同的测试类型，比较突出的在这个系类中将涵盖 **但愿测试** 和 **几层测试** 。  

**单元测试** 覆盖面非常小，高度专一域的代码。通常相关作用和其他域的软件。这个风格的测试在危机的时候非常有帮助，复杂的组件，例如验证，倒入或者方法复杂的业务逻辑。  
**继承测试** 这种测试通常覆盖很多不同的面使得应用工作一起产生一个结果，他们确保数据流失正确的，经常处理多个用户交互。  

这两种方式主要的不同不是工具而是方法，你选择哪种去测试。非常普遍是事混合交叉使用适度的。  

#####工具

在Python世界里，有各式各样的工具去测试你的代码，一些主流的可选项包括：  

- unittest/unittest2
- doctest
- nose
这份指南不会深入doctests和nose测试，坚持unittest，这是因为用uninitest写测试运行更快当你在测试Django应用的时候（感谢一些有趣的）。我鼓励你去投资其他选项，只要扩展你的知识。  

你应该不会疑惑 uniitest（库）用于单元测试（连续代码块小测试的方法），你通常使用unittest库用于单元测试和集成测试。  

####什么东西应该测试

另一个常见的挫折对于开发者或者设计者来说测试“那些东西应该测试哪些东西不应该测试”。当没有很困难快速的规则这里应用与任何地方，有一些通用的指导方针我可以提供在做决定的时候。  

- 如果代码在问题中是内建的Python函数或库，不需要测试。例如datetime库
- 如果代码是内建在Django中，不需要测试，例如Model中的字段（field）或者测试如果再见template.Node渲染，包括标签。
- 

- 如果你的模型由自定义的方法，你应该测试，通常是单元测试
- 自定义的视图，表单，模版标签，上下文处理器，中间件，管理命令等，如果你实现业务逻辑，你因该测试代码的各方面。  

令一个上游的问题时“how far down do you go",还是一样，没有正确的答案。保存为”哪里我最舒服“，如果你开始含糊”sdfldsfjs"在你呼吸  大师傅大师傅。  

#### 什么时候做测试




[原文](http://toastdriven.com/blog/2011/apr/10/guide-to-testing-in-django/)

使用django-simple-captcha遇到的坑
=============================
一站点[gongshare.com](http://gongshare.com)在做注册功能时验证码采用的[django-simple-captcha](https://django-simple-captcha.readthedocs.org/en/latest/index.html)，因为笔者开发环境采用的Windows 64bit系统，结果安装使用的时候接二连三遇到好几个坑。  

django-simple-captcha需要依赖django1.3+、PIL1.1.7+或者Pillow2.0+，根据[文档](https://django-simple-captcha.readthedocs.org/en/latest/usage.html)安装后开始使用时，最开始报如下错：  

    TypeError: function takes at most 4 arguments (6 given)

这个错误在stackoverflow找到了[答案](http://stackoverflow.com/questions/16365462/when-i-run-django-simple-captcha-test-throw-2-errors)，把PIL替换成Pillow就行，Pillow是从PIL fork过来的一个版本，至于为什么会有Pillow这么个东西，pillow的作者对它做了最好的[解释](https://github.com/python-imaging/Pillow)，大概意思就是对PIL的安装方式和Bug修复问题感到不满。窃以为替换了PIL后就没问题，于是接着问题又来了：  

    IOError: encoder zip not available
还是在stackoverflow找[答案](http://stackoverflow.com/questions/16990852/how-to-correctly-use-pil-with-python-under-windows)，目测还是PIL的问题，我很纳闷，PIL卸载了（使用命令`pip uninstall PIL`)，Pillow重新安装了，为啥还是不行，结果跑到控制面板查看已安装的程序，发现还有个64位的PIL，因为笔者之前安装过一次二进制的PIL.exe，另外发现自己的Python版本也是64位的Python2.7.4，于是乎，手动卸载控制面板中出现的那个PIL，又重新安装了遍Pillow，未果，跑到[这个网站](http://www.lfd.uci.edu/~gohlke/pythonlibs/)下了个安装版的Pillow-2.1.0.win-amd64-py2.7.exe，新的错误出现了：  
    
    The _imaging C module is not installed
此时快要崩溃了，但还是不死心啊，于是把64位的python2.7.4也卸载掉，换成了32位的python2.7.5，此时此刻激动人心的一刻出现了。自己去感受一下吧。  

总结：  
+ 在条件允许的情况下，尽可能在Linux或Mac上做开发，这样遇到的坑比较少。  
+ 把Python换成32位的安装包，其他第三方的也跟着用32位的  











Celery-----分布式任务队列
=======================
如果你是windows用户，首先现在安装[redis](https://github.com/MSOpenTech/redis/blob/2.6/bin/release/redisbin64.zip)，

安装celery  

    pip install celery-with-redis
默认会安装好celery最新版本



Python/Django编程实践指南
=========================
####Python/Django代码风格
PEP8是Python官方推荐的代码风格指南标准。  

* 使用4个空格作为缩进
* 最外层函数和类使用两个空行分隔
* 类中的方法使用一个空行分隔

PEP8建议按如下三种方式分组导入包  
* 标准库导入
* 第三方相关包导入
* 本地应用或库导入

比如：一个Django项目，包导入看起来应该是：  

    #标准库
    from math import sqrt
    from os.path import abspath
    
    #Django导入
    from django.db import models
    from django.utils.translation import ugettext_lazy as _
    
    #第三方应用导入
    from django_extensions.db.models import TimeStampedModel
    
    #导入自己的应用
    from splits.models import BananaSplit

（当然这里的注释只是对本例的说明，实际代码中并不需要写这些注释）  


####使用相对导入
使用相对导入，更易于app的移植、重用、重命名。比如：下面的cones app，在view中使用硬编码使用cones 包，

    # cones/views.py
    # Hard coding of package name
    from django.views.generic import CreateView
    # DON’T DO THIS: Hardcoding of the 'cones' package
    from cones.models import WaffleCone
    from cones.forms import WaffleConeForm
    class WaffleConeCreateView(CreateView):
        model = WaffleCone
        form_class = WaffleConeForm 

* 现在假如你想在其他project重用这个cones app，但是刚好这个project中已经有一个叫cones 的app了，这样就会造成名字的冲突。  
* 如果想像把cones改名，你又得在多次更改cones。  

推荐的方式应该是：  

    # cones/views.py
    from django.views.generic import CreateView
    # Hard coding of the 'cones' package
    from .models import WaffleCone
    from .forms import WaffleConeForm
    class WaffleConeCreateView(CreateView):
        model = WaffleCone
        form_class = WaffleConeForm 


####避免使用 import  *
在99%的情况下都因该明确import具体的模块名字

    from django import forms
    from django.db import models
绝对不要这样干：  

    from django.form import *
    from django.db.models import *
不要这样做的原因是避免隐含的加载其他Python模块的locals把当前的模块的命名空间覆盖了。那样做可能导致不可预见性灾难。  

比如Django Froms 和 Django Models 包中都含有一个类叫CharField，隐含地加载两个库，Models库将覆盖Forms版本的CharField。  

#####Django风格
在URL pattern名字中使用下划线"_"而不是破折号"-"，注意只是指的是url()的name参数，而不是真正的URL地址，破折号在URL没问题。  
使用下划线而不是破折号在模版 block 名字中。  

####Python/Django最佳环境配置
本地测试环境和线上生产环境使用同样的数据库  
有些童鞋喜欢在本地用SQLite作为测试数据库，生产环境才使用正式的数据库如MySQL/PostgreSQL，然而不同的数据库有不同的数据类型和约束，很多问题一旦跑到线上问题就来了。  

#####使用Pip 和 Virtualenv
Pip 是 python 包安装管理工具，比easy_install更强大。  
Virtualenv是用来创建完全独立的、隔离的Python环境的工具，这就意味着你可以在A 项目中使用Django1.4，B项目中使用1.5成为可能，互不影响。Virtualenvwrapper如其名就像咖啡伴侣，它为virtualenv提供了更便捷的操作。  

使用virtualenv激活某个虚拟环境：  

    source ~/.virtualenvs/myproject/bin/activate
而使用virtualenvwrapper可以简单为：  

    workon myproject
####使用版本控制系统
Git 和 Mercurial 是 Django开发中最流行的版本控制工具，它不仅能使用你在本地有一份拷贝，而且还能使用代码托管服务用来备份，更重要的是可以多人协助编程。推荐大家使用 GitHub 或者 Bitbucket，后者可以建立免费的私有仓库。  

####Django项目代码布局
运行：  

    $ django-admin.py startproject mysite
    $ cd mysite
    $ django-admin.py startapp my_app

Django1.5的默认布局：  

    mysite/
        manage.py
        my_app/
            __init__.py
            models.py
            tests.py
            views.py
        mysite/
            __init__.py
            settings.py
            urls.py
            wsgi.py    

比较常用的一种布局格式是：  

    gongshare_project/   #<repository_root>/
        .gitignore
        Makefile
        docs/
        requirements.txt
        gongshare/          #<django_project_root>/
            manage.py
            media/
            products/
            profiles/
            ratings/
            static/
            templates/
            gongshare/      #<configuration_root>/
                __init__.py
                settings/
                urls.py
                wsgi.py

这是一个三层结构的布局：  
顶层是仓库根目录，它包含了第二层目录外还包括一些如：**README, doc/** 目录，**.gitignore** 、**requirements** 文件。  

第二层是django项目的根目录，这层是通过 django-admin.py startproject 命令生成的。这个目录包含了第三层目录外还有mdedia、static（css，js等）、templates（模版）目录和app目录（比如：profiles、ratings、products）  

第三层同样是通过django-admin.py startproject 生成，除了一个基础的URLConf（urls.py)外还有settings模块，settings模块方式不同环境下的项目配置文件。  


####配置文件和必要文件
* 所有配置文件都应该有版本控制。
* 遵循DRP原则

collections 学习笔记
==========================
collections模块集结了Python中的高性能的容器数据类型，这些数据类型主要包括：namedtuple()、deque、Counter、OrderedDiect、defaultdict。他们作为替换内建（built-in）容器数据类型dict、list、set、tuple的可选方案。  

####namedtuple()  
快速,轻量级的attribute-style方式访问tuple.举例:  
假设你有一个元组包含用户名和密码,访问用户名和密码需要通过元组的索引如:  

    credential = ('zhangsan', '123456') 
    print ('username:'+ credential[0])
    print ('password:'+credential[1])
这段代码没有任何错误,但是你想理解元组的含义你就必须读文档查看这两个参数的具体含义,那么这个时候namedtuple就可以派上用场了.   

    import collections
    Credential = collections.namedtuple('Credential', 'username, password')
    credential = Credential(username='zhangsan', password='123456')
    print ('username:'+credential.username)
    print ('password:'+credential.password)

namedtuple是在python2.6中开始出现的,在collections模块下面,它扩展的基础的tuple数据结构,tuple的每个索引位置被一个名字来代替,这样就可以通过名字来访问tuple中的元素了,同时你仍然还是可以通过索引来访问元素.它的好处就是可读性更强一些.另外只需更少的内存.  

语法是这样的:  

    collections.namedtuple(typename, filed_names[, verbose])
地一个参数指定新类型的名字,第二个参数是字符串(用空格或者逗号隔开)它构成了这个类型的域. 如果verbose等于True.那么就会打印出类生成信息.  

    >>> People = namedtuple("People",'age name', True)
    class People(tuple):
        'People(age, name)'
    
        __slots__ = ()
    
        _fields = ('age', 'name')
    
        def __new__(_cls, age, name):
            'Create new instance of People(age, name)'
            return _tuple.__new__(_cls, (age, name))
    
        @classmethod
        def _make(cls, iterable, new=tuple.__new__, len=len):
            'Make a new People object from a sequence or iterable'
            result = new(cls, iterable)
            if len(result) != 2:
                raise TypeError('Expected 2 arguments, got %d' % len(result))
            return result
    
        def __repr__(self):
            'Return a nicely formatted representation string'
            return 'People(age=%r, name=%r)' % self
    
        def _asdict(self):
            'Return a new OrderedDict which maps field names to their values'
            return OrderedDict(zip(self._fields, self))
    
        def _replace(_self, **kwds):
            'Return a new People object replacing specified fields with new values'
            result = _self._make(map(kwds.pop, ('age', 'name'), _self))
            if kwds:
                raise ValueError('Got unexpected field names: %r' % kwds.keys())
            return result
    
        def __getnewargs__(self):
            'Return self as a plain tuple.  Used by copy and pickle.'
            return tuple(self)
    
        __dict__ = _property(_asdict)
    
        def __getstate__(self):
            'Exclude the OrderedDict from pickling'
            pass
    
        age = _property(_itemgetter(0), doc='Alias for field number 0')
    
        name = _property(_itemgetter(1), doc='Alias for field number 1')
    
    
    >>> 
    >>> 
    >>> 
    >>> p = People(22,'zhsan')
    >>> p[0]
    22
    >>> p.age
    22
    >>> 

类方法`_make`可以创建一个新实例  
    
    People._make(30, 'lisi')



http://stackoverflow.com/questions/2970608/what-are-named-tuples-in-python
http://docs.python.org/2/library/collections.html?highlight=collections#collections.namedtuple


协程不同于线程，线程是抢占式的调度，而协程是协同是的调度，协程需要自己做调度。  

协程没有线程的安全问题，一个进程可以同时存在多个协程，但是只有一个协程是激活的，而且协程的激活和休眠又程序员通过编程来控制，而不是操作系统控制的，

协程氏用户空间线程，操作系统其存在一无所知，所以需要用户自己去调度，用来执行协程多任务非常合适。  



####Python's functions are objects
####Python函数是对象  
To understand decorators, you must first understand that functions are objects in Python. This has important consequences. Let's see why with a simple example :  
为了理解装饰器，首先需要明白函数在Python中也是对象，理解这一点很重要，下面用一个例子来说明：  

    def shout(word="yes"):
        return word.capitalize()+"!"
    
    print shout()
    # 输出 : 'Yes!'
    
    # As an object, you can assign the function to a variable like any
    # other object 
    #函数作为对象，你可以象其他对象一样赋值给变量 
    scream = shout
    
    # Notice we don't use parentheses: we are not calling the function, we are
    # putting the function "shout" into the variable "scream". 
    # It means you can then call "shout" from "scream":
    # 注意：这里我们没有使用圆括号去调用函数，仅仅是把函数"shout"赋值给变量"scream"
    #也就是说你可以通过"scream"来调用"shout"
    print scream()
    # 输出 : 'Yes!'
    
    # More than that, it means you can remove the old name 'shout', and
    # the function will still be accessible from 'scream'
    # 不仅如此，你还可以删除'shout'，该函数仍然可以通过'scream'来访问。
    
    del shout
    try:
        print shout()
    except NameError, e:
        print e
        #输出: "name 'shout' is not defined"
    
    print scream()
    # 输出: 'Yes!'
OK, keep that in mind, we are going back to it soon. Another interesting property of Python functions is they can be defined... inside another function!  
好了，先记住上面规则，稍后再回到这里来，Python另一个有意思的特点是函数可以定义在另一个函数里面。  

    def talk():
    
        # You can define a function on the fly in "talk" ...
        # 你可以直接在"talk"中定义函数
        def whisper(word="yes"):
            return word.lower()+"..."
    
        # ... and use it right away!
        # ... 立马就可以在这里使用 
        print whisper()
    
    # You call "talk", that defines "whisper" EVERY TIME you call it, then
    # "whisper" is called in "talk". 
    # 每次调用"talk"时，"whipser"将被"talk"调用
    talk()
    # 输出: 
    # "yes..."
    
    # But "whisper" DOES NOT EXIST outside "talk":
    # 注意："whisper"在函数"talk"外面是不可见的 
    try:
        print whisper()
    except NameError, e:
        print e
        #输出 : "name 'whisper' is not defined"*

####Functions references
OK, still here? Now the fun part, you've seen that functions are objects and therefore:  
OK，你已经知道函数是对象了：  

+ can be assigned to a variable;  
+ 它可以赋值给变量   
+ can be defined in another function.  
+ 可以定义在另外的函数中  

Well, that means that a function can return another function :-) Have a look:  

也就是意味着一个函数可以返回另一个函数:-)，请看下面：  

    def getTalk(type="shout"):
    
        # We define functions on the fly
        # 直接在函数中定义函数
        def shout(word="yes"):
            return word.capitalize()+"!"
    
        def whisper(word="yes") :
            return word.lower()+"...";
    
        # Then we return one of them
        # 返回其中的一个函数
        if type == "shout":
            # We don't use "()", we are not calling the function,
            # 这里没有使用"()"，我们不是调用这个函数，而是返回这个函数对象
            # we are returning the function object
            return shout  
        else:
            return whisper
    
    # How do you use this strange beast?
    # 怎么使用这个奇怪的东东呢？
    # Get the function and assign it to a variable
    # 获取函数并赋值给变量
    talk = getTalk()      
    
    # You can see that "talk" is here a function object:
      "talk"在这儿就是一个函数对象
    print talk
    #输出: <function shout at 0xb7ea817c>
    
    # The object is the one returned by the function:
      这个对象就是由一个函数返回的 
    print talk()
    #输出 : Yes!
    
    # And you can even use it directly if you feel wild:
    你甚至能直接使用它
    print getTalk("whisper")()
    #输出 : yes...

But wait, there is more. If you can return a function, then you can pass one as a parameter:  
等等，还有呢，如果能返回一个函数，那么这个函数还可以作为参数传递    

    def doSomethingBefore(func): 
        print "I do something before then I call the function you gave me"
        print func()
    
    doSomethingBefore(scream)
    #输出: 
    #I do something before then I call the function you gave me
    #Yes!

Well, you just have everything needed to understand decorators. You see, decorators are wrappers which means that they let you execute code before and after the function they decorate without the need to modify the function itself.  
好啦，终于可以开始理解装饰器了，你瞧，装饰器就是对函数进行一层包裹，能在函数运行前或运行后执行额外的代码，而不需要修改函数本身。  

####Handcrafted decorators
####纯手工装饰器
How you would do it manually:
你可以用手工方式如下实现：  

# A decorator is a function that expects ANOTHER function as parameter  
# 装饰器是一个接受另一个函数作为参数的函数

    def my_shiny_new_decorator(a_function_to_decorate):
    
        # Inside, the decorator defines a function on the fly: the wrapper.
        # This function is going to be wrapped around the original function
        # so it can execute code before and after it.
        # 
        # 装饰器内定义了一个函数，该函数包裹原始函数，可以在原始函数前后执行代码
        def the_wrapper_around_the_original_function():
    
            # Put here the code you want to be executed BEFORE the original 
            # function is called
            #在原始函数调用前执行代码
            print "Before the function runs"
    
            # Call the function here (using parentheses)
            #调用函数（注意这里带括号）
            a_function_to_decorate()
    
            # Put here the code you want to be executed AFTER the original 
            # function is called
            #调用完原始函数后执行代码
            print "After the function runs"
    
        # At this point, "a_function_to_decorate" HAS NEVER BEEN EXECUTED.
        # We return the wrapper function we have just created.
        # The wrapper contains the function and the code to execute before
        # and after. It's ready to use!
        # 在这个地方，" a_function_to_decorate"函数从来没有被执行
        #而是返回这个刚刚创建的包裹函数，该函数包含了函数的代码及前后代码段，这样准备使用了
        return the_wrapper_around_the_original_function
    
    # Now imagine you create a function you don't want to ever touch again.
    # 现在假设你创建一个函数，而且又不想做任何修改了
    def a_stand_alone_function():
        print "I am a stand alone function, don't you dare modify me"
    
    a_stand_alone_function() 
    #outputs: I am a stand alone function, don't you dare modify me
    #输出：I am a stand alone function, don't you dare modify me
    
    # Well, you can decorate it to extend its behavior.
    # Just pass it to the decorator, it will wrap it dynamically in 
    # any code you want and return you a new function ready to be used:

    #嗯，你可以装饰这个函数扩展其行为
    
    a_stand_alone_function_decorated = my_shiny_new_decorator(a_stand_alone_function)
    a_stand_alone_function_decorated()
    #outputs:
    #输出：
    #Before the function runs
    #I am a stand alone function, don't you dare modify me
    #After the function runs

Now, you probably want that every time you call a_stand_alone_function, a_stand_alone_function_decorated is called instead. That's easy, just overwrite a_stand_alone_function with the function returned by my_shiny_new_decorator:  

现在，你可能每次想每次调用*a_stand_alone_function*的时候，*a_stand_alone_function_decorated*就被调用，这很简单，只需重写*a_stand_alone_function*函数，通过*my_shiny_new_decorator*  

    a_stand_alone_function = my_shiny_new_decorator(a_stand_alone_function)
    a_stand_alone_function()
    #输出:
    #Before the function runs
    #I am a stand alone function, don't you dare modify me
    #After the function runs
    
    # And guess what? That's EXACTLY what decorators do!

####Decorators demystified
####装饰器揭秘

The previous example, using the decorator syntax:  
前面的例子，使用装饰器语法如下：  

    @my_shiny_new_decorator
    def another_stand_alone_function():
        print "Leave me alone"
    
    another_stand_alone_function()  
    #输出:  
    #Before the function runs
    #Leave me alone
    #After the function runs

Yes, that's all, it's that simple. @decorator is just a shortcut to:  
没错，就这么简单，@装饰器 是下面代码的快捷方式：  

    another_stand_alone_function = my_shiny_new_decorator(another_stand_alone_function)

Decorators are just a pythonic variant of the decorator design pattern. There are several classic design patterns embedded in Python to ease development, like iterators.  

装饰器是装饰器模式的一种pythonic方式，还有很多经典设计模式嵌在Python中简化开发，比如迭代器  

Of course, you can cumulate decorators:  
当然，你也可以累积装饰器  

    def bread(func):
        def wrapper():
            print "</''''''\>"
            func()
            print "<\______/>"
        return wrapper
    
    def ingredients(func):
        def wrapper():
            print "#tomatoes#"
            func()
            print "~salad~"
        return wrapper
    
    def sandwich(food="--ham--"):
        print food
    
    sandwich()
    #outputs: --ham--
    sandwich = bread(ingredients(sandwich))
    sandwich()
    #outputs:
    #</''''''\>
    # #tomatoes#
    # --ham--
    # ~salad~
    #<\______/>
Using the Python decorator syntax:

@bread
@ingredients
def sandwich(food="--ham--"):
    print food

sandwich()
#outputs:
#</''''''\>
# #tomatoes#
# --ham--
# ~salad~
#<\______/>
The order you set the decorators MATTERS:

@ingredients
@bread
def strange_sandwich(food="--ham--"):
    print food

strange_sandwich()
#outputs:
##tomatoes#
#</''''''\>
# --ham--
#<\______/>
# ~salad~
Eventually answering the question
As a conclusion, you can easily see how to answer the question:

# The decorator to make it bold
def makebold(fn):
    # The new function the decorator returns
    def wrapper():
        # Insertion of some code before and after
        return "<b>" + fn() + "</b>"
    return wrapper

# The decorator to make it italic
def makeitalic(fn):
    # The new function the decorator returns
    def wrapper():
        # Insertion of some code before and after
        return "<i>" + fn() + "</i>"
    return wrapper

@makebold
@makeitalic
def say():
    return "hello"

print say() 
#outputs: <b><i>hello</i></b>

# This is the exact equivalent to 
def say():
    return "hello"
say = makebold(makeitalic(say))

print say() 
#outputs: <b><i>hello</i></b>
You can now just leave happy, or burn your brain a little bit more and see advanced uses of decorators.

Passing arguments to the decorated function
# It's not black magic, you just have to let the wrapper 
# pass the argument:

def a_decorator_passing_arguments(function_to_decorate):
    def a_wrapper_accepting_arguments(arg1, arg2):
        print "I got args! Look:", arg1, arg2
        function_to_decorate(arg1, arg2)
    return a_wrapper_accepting_arguments

# Since when you are calling the function returned by the decorator, you are
# calling the wrapper, passing arguments to the wrapper will let it pass them to 
# the decorated function

@a_decorator_passing_arguments
def print_full_name(first_name, last_name):
    print "My name is", first_name, last_name

print_full_name("Peter", "Venkman")
# outputs:
#I got args! Look: Peter Venkman
#My name is Peter Venkman
Decorating methods
What's great with Python is that methods and functions are really the same, except methods expect their first parameter to be a reference to the current object (self). It means you can build a decorator for methods the same way, just remember to take self in consideration:

def method_friendly_decorator(method_to_decorate):
    def wrapper(self, lie):
        lie = lie - 3 # very friendly, decrease age even more :-)
        return method_to_decorate(self, lie)
    return wrapper


class Lucy(object):

    def __init__(self):
        self.age = 32

    @method_friendly_decorator
    def sayYourAge(self, lie):
        print "I am %s, what did you think?" % (self.age + lie)

l = Lucy()
l.sayYourAge(-3)
#outputs: I am 26, what did you think?
Of course, if you make a very general decorator and want to apply it to any function or method, no matter its arguments, then just use *args, **kwargs:

def a_decorator_passing_arbitrary_arguments(function_to_decorate):
    # The wrapper accepts any arguments
    def a_wrapper_accepting_arbitrary_arguments(*args, **kwargs):
        print "Do I have args?:"
        print args
        print kwargs
        # Then you unpack the arguments, here *args, **kwargs
        # If you are not familiar with unpacking, check:
        # http://www.saltycrane.com/blog/2008/01/how-to-use-args-and-kwargs-in-python/
        function_to_decorate(*args, **kwargs)
    return a_wrapper_accepting_arbitrary_arguments

@a_decorator_passing_arbitrary_arguments
def function_with_no_argument():
    print "Python is cool, no argument here."

function_with_no_argument()
#outputs
#Do I have args?:
#()
#{}
#Python is cool, no argument here.

@a_decorator_passing_arbitrary_arguments
def function_with_arguments(a, b, c):
    print a, b, c

function_with_arguments(1,2,3)
#outputs
#Do I have args?:
#(1, 2, 3)
#{}
#1 2 3 

@a_decorator_passing_arbitrary_arguments
def function_with_named_arguments(a, b, c, platypus="Why not ?"):
    print "Do %s, %s and %s like platypus? %s" %\
    (a, b, c, platypus)

function_with_named_arguments("Bill", "Linus", "Steve", platypus="Indeed!")
#outputs
#Do I have args ? :
#('Bill', 'Linus', 'Steve')
#{'platypus': 'Indeed!'}
#Do Bill, Linus and Steve like platypus? Indeed!

class Mary(object):

    def __init__(self):
        self.age = 31

    @a_decorator_passing_arbitrary_arguments
    def sayYourAge(self, lie=-3): # You can now add a default value
        print "I am %s, what did you think ?" % (self.age + lie)

m = Mary()
m.sayYourAge()
#outputs
# Do I have args?:
#(<__main__.Mary object at 0xb7d303ac>,)
#{}
#I am 28, what did you think?
Passing arguments to the decorator
Great, now what would you say about passing arguments to the decorator itself? Well this is a bit twisted because a decorator must accept a function as an argument and therefore, you cannot pass the decorated function arguments directly to the decorator.

Before rushing to the solution, let's write a little reminder:

# Decorators are ORDINARY functions
def my_decorator(func):
    print "I am a ordinary function"
    def wrapper():
        print "I am function returned by the decorator"
        func()
    return wrapper

# Therefore, you can call it without any "@"

def lazy_function():
    print "zzzzzzzz"

decorated_function = my_decorator(lazy_function)
#outputs: I am a ordinary function

# It outputs "I am a ordinary function", because that's just what you do:
# calling a function. Nothing magic.

@my_decorator
def lazy_function():
    print "zzzzzzzz"

#outputs: I am a ordinary function
It's exactly the same. "my_decorator" is called. So when you @my_decorator, you are telling Python to call the function 'labeled by the variable "my_decorator"'. It's important, because the label you give can point directly to the decorator... or not! Let's start to be evil!

def decorator_maker():

    print "I make decorators! I am executed only once: "+\
          "when you make me create a decorator."

    def my_decorator(func):

        print "I am a decorator! I am executed only when you decorate a function."

        def wrapped():
            print ("I am the wrapper around the decorated function. "
                  "I am called when you call the decorated function. "
                  "As the wrapper, I return the RESULT of the decorated function.")
            return func()

        print "As the decorator, I return the wrapped function."

        return wrapped

    print "As a decorator maker, I return a decorator"
    return my_decorator

# Let's create a decorator. It's just a new function after all.
new_decorator = decorator_maker()       
#outputs:
#I make decorators! I am executed only once: when you make me create a decorator.
#As a decorator maker, I return a decorator

# Then we decorate the function

def decorated_function():
    print "I am the decorated function."

decorated_function = new_decorator(decorated_function)
#outputs:
#I am a decorator! I am executed only when you decorate a function.
#As the decorator, I return the wrapped function

# Let's call the function:
decorated_function()
#outputs:
#I am the wrapper around the decorated function. I am called when you call the decorated function.
#As the wrapper, I return the RESULT of the decorated function.
#I am the decorated function.
No surprise here. Let's do EXACTLY the same thing, but skipping intermediate variables:

def decorated_function():
    print "I am the decorated function."
decorated_function = decorator_maker()(decorated_function)
#outputs:
#I make decorators! I am executed only once: when you make me create a decorator.
#As a decorator maker, I return a decorator
#I am a decorator! I am executed only when you decorate a function.
#As the decorator, I return the wrapped function.

# Finally:
decorated_function()    
#outputs:
#I am the wrapper around the decorated function. I am called when you call the decorated function.
#As the wrapper, I return the RESULT of the decorated function.
#I am the decorated function.
Let's make it AGAIN, even shorter:

@decorator_maker()
def decorated_function():
    print "I am the decorated function."
#outputs:
#I make decorators! I am executed only once: when you make me create a decorator.
#As a decorator maker, I return a decorator
#I am a decorator! I am executed only when you decorate a function.
#As the decorator, I return the wrapped function.

#Eventually: 
decorated_function()    
#outputs:
#I am the wrapper around the decorated function. I am called when you call the decorated function.
#As the wrapper, I return the RESULT of the decorated function.
#I am the decorated function.
Hey, did you see that? We used a function call with the "@" syntax :-)

So back to decorators with arguments. If we can use functions to generate the decorator on the fly, we can pass arguments to that function, right?

def decorator_maker_with_arguments(decorator_arg1, decorator_arg2):

    print "I make decorators! And I accept arguments:", decorator_arg1, decorator_arg2

    def my_decorator(func):
        # The ability to pass arguments here is a gift from closures.
        # If you are not comfortable with closures, you can assume it's ok,
        # or read: http://stackoverflow.com/questions/13857/can-you-explain-closures-as-they-relate-to-python
        print "I am the decorator. Somehow you passed me arguments:", decorator_arg1, decorator_arg2

        # Don't confuse decorator arguments and function arguments!
        def wrapped(function_arg1, function_arg2) :
            print ("I am the wrapper around the decorated function.\n"
                  "I can access all the variables\n"
                  "\t- from the decorator: {0} {1}\n"
                  "\t- from the function call: {2} {3}\n"
                  "Then I can pass them to the decorated function"
                  .format(decorator_arg1, decorator_arg2,
                          function_arg1, function_arg2))
            return func(function_arg1, function_arg2)

        return wrapped

    return my_decorator

@decorator_maker_with_arguments("Leonard", "Sheldon")
def decorated_function_with_arguments(function_arg1, function_arg2):
    print ("I am the decorated function and only knows about my arguments: {0}"
           " {1}".format(function_arg1, function_arg2))

decorated_function_with_arguments("Rajesh", "Howard")
#outputs:
#I make decorators! And I accept arguments: Leonard Sheldon
#I am the decorator. Somehow you passed me arguments: Leonard Sheldon
#I am the wrapper around the decorated function. 
#I can access all the variables 
#   - from the decorator: Leonard Sheldon 
#   - from the function call: Rajesh Howard 
#Then I can pass them to the decorated function
#I am the decorated function and only knows about my arguments: Rajesh Howard
Here it is, a decorator with arguments. Arguments can be set as variable:

c1 = "Penny"
c2 = "Leslie"

@decorator_maker_with_arguments("Leonard", c1)
def decorated_function_with_arguments(function_arg1, function_arg2):
    print ("I am the decorated function and only knows about my arguments:"
           " {0} {1}".format(function_arg1, function_arg2))

decorated_function_with_arguments(c2, "Howard")
#outputs:
#I make decorators! And I accept arguments: Leonard Penny
#I am the decorator. Somehow you passed me arguments: Leonard Penny
#I am the wrapper around the decorated function. 
#I can access all the variables 
#   - from the decorator: Leonard Penny 
#   - from the function call: Leslie Howard 
#Then I can pass them to the decorated function
#I am the decorated function and only knows about my arguments: Leslie Howard
As you can see, you can pass arguments to the decorator like any function using this trick. You can even use *args, **kwargs if you wish. But remember decorators are called only once. Just when Python imports the script. You can't dynamically set the arguments afterwards. When you do "import x", the function is already decorated, so you can't change anything.

Let's practice: a decorator to decorate a decorator
OK, as a bonus, I'll give you a snippet to make any decorator accept generically any argument. After all, in order to accept arguments, we created our decorator using another function. We wrapped the decorator. Anything else we saw recently that wrapped function? Oh yes, decorators! Let's have some fun and write a decorator for the decorators:

def decorator_with_args(decorator_to_enhance):
    """ 
    This function is supposed to be used as a decorator.
    It must decorate an other function, that is intended to be used as a decorator.
    Take a cup of coffee.
    It will allow any decorator to accept an arbitrary number of arguments,
    saving you the headache to remember how to do that every time.
    """

    # We use the same trick we did to pass arguments
    def decorator_maker(*args, **kwargs):

        # We create on the fly a decorator that accepts only a function
        # but keeps the passed arguments from the maker.
        def decorator_wrapper(func):

            # We return the result of the original decorator, which, after all, 
            # IS JUST AN ORDINARY FUNCTION (which returns a function).
            # Only pitfall: the decorator must have this specific signature or it won't work:
            return decorator_to_enhance(func, *args, **kwargs)

        return decorator_wrapper

    return decorator_maker
It can be used as follows:

# You create the function you will use as a decorator. And stick a decorator on it :-)
# Don't forget, the signature is "decorator(func, *args, **kwargs)"
@decorator_with_args 
def decorated_decorator(func, *args, **kwargs): 
    def wrapper(function_arg1, function_arg2):
        print "Decorated with", args, kwargs
        return func(function_arg1, function_arg2)
    return wrapper

# Then you decorate the functions you wish with your brand new decorated decorator.

@decorated_decorator(42, 404, 1024)
def decorated_function(function_arg1, function_arg2):
    print "Hello", function_arg1, function_arg2

decorated_function("Universe and", "everything")
#outputs:
#Decorated with (42, 404, 1024) {}
#Hello Universe and everything

# Whoooot!
I know, the last time you had this feeling, it was after listening a guy saying: "before understanding recursion, you must first understand recursion". But now, don't you feel good about mastering this?

Best practices while using decorators
They are new as of Python 2.4, so be sure that's what your code is running on.
Decorators slow down the function call. Keep that in mind.
You can not un-decorate a function. There are hacks to create decorators that can be removed but nobody uses them. So once a function is decorated, it's done. For all the code.
Decorators wrap functions, which can make them hard to debug.
Python 2.5 solves this last issue by providing the functools module including functools.wraps that copies the name, module and docstring of any wrapped function to it's wrapper. Fun fact, functools.wraps is a decorator :-)

# For debugging, the stacktrace prints you the function __name__
def foo():
    print "foo"

print foo.__name__
#outputs: foo

# With a decorator, it gets messy    
def bar(func):
    def wrapper():
        print "bar"
        return func()
    return wrapper

@bar
def foo():
    print "foo"

print foo.__name__
#outputs: wrapper

# "functools" can help for that

import functools

def bar(func):
    # We say that "wrapper", is wrapping "func"
    # and the magic begins
    @functools.wraps(func)
    def wrapper():
        print "bar"
        return func()
    return wrapper

@bar
def foo():
    print "foo"

print foo.__name__
#outputs: foo
How can the decorators be useful?
Now the big question: what can I use decorators for? Seem cool and powerful, but a practical example would be great. Well, there are 1000 possibilities. Classic uses are extending a function behavior from an external lib (you can't modify it) or for a debug purpose (you don't want to modify it because it's temporary). You can use them to extends several functions with the same code without rewriting it every time, for DRY's sake. E.g.:

def benchmark(func):
    """
    A decorator that prints the time a function takes
    to execute.
    """
    import time
    def wrapper(*args, **kwargs):
        t = time.clock()
        res = func(*args, **kwargs)
        print func.__name__, time.clock()-t
        return res
    return wrapper


def logging(func):
    """
    A decorator that logs the activity of the script.
    (it actually just prints it, but it could be logging!)
    """
    def wrapper(*args, **kwargs):
        res = func(*args, **kwargs)
        print func.__name__, args, kwargs
        return res
    return wrapper


def counter(func):
    """
    A decorator that counts and prints the number of times a function has been executed
    """
    def wrapper(*args, **kwargs):
        wrapper.count = wrapper.count + 1
        res = func(*args, **kwargs)
        print "{0} has been used: {1}x".format(func.__name__, wrapper.count)
        return res
    wrapper.count = 0
    return wrapper

@counter
@benchmark
@logging
def reverse_string(string):
    return str(reversed(string))

print reverse_string("Able was I ere I saw Elba")
print reverse_string("A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!")

#outputs:
#reverse_string ('Able was I ere I saw Elba',) {}
#wrapper 0.0
#wrapper has been used: 1x 
#ablE was I ere I saw elbA
#reverse_string ('A man, a plan, a canoe, pasta, heros, rajahs, a coloratura, maps, snipe, percale, macaroni, a gag, a banana bag, a tan, a tag, a banana bag again (or a camel), a crepe, pins, Spam, a rut, a Rolo, cash, a jar, sore hats, a peon, a canal: Panama!',) {}
#wrapper 0.0
#wrapper has been used: 2x
#!amanaP :lanac a ,noep a ,stah eros ,raj a ,hsac ,oloR a ,tur a ,mapS ,snip ,eperc a ,)lemac a ro( niaga gab ananab a ,gat a ,nat a ,gab ananab a ,gag a ,inoracam ,elacrep ,epins ,spam ,arutaroloc a ,shajar ,soreh ,atsap ,eonac a ,nalp a ,nam A
Of course the good thing with decorators is that you can use them right away on almost anything without rewriting. DRY, I said:

@counter
@benchmark
@logging
def get_random_futurama_quote():
    import httplib
    conn = httplib.HTTPConnection("slashdot.org:80")
    conn.request("HEAD", "/index.html")
    for key, value in conn.getresponse().getheaders():
        if key.startswith("x-b") or key.startswith("x-f"):
            return value
    return "No, I'm ... doesn't!"

print get_random_futurama_quote()
print get_random_futurama_quote()

#outputs:
#get_random_futurama_quote () {}
#wrapper 0.02
#wrapper has been used: 1x
#The laws of science be a harsh mistress.
#get_random_futurama_quote () {}
#wrapper 0.01
#wrapper has been used: 2x
#Curse you, merciful Poseidon!
Python itself provides several decorators: property, staticmethod, etc. Django use decorators to manage caching and view permissions. Twisted to fake inlining asynchronous functions calls. This really is a large playground.

EDIT: given the success of this answer, and people asking me to do the same with metaclasses, I did.

[decorators](http://stackoverflow.com/questions/739654/how-can-i-make-a-chain-of-function-decorators-in-python)

Django应用部署(nginx、gunicorn、virtualenv、supervisor)
====================================================
[Django](http://djangoproject.org)在python语言中是最受欢迎的全栈式web框架，过去部署Django应用一般采用Apache+mod_wsgi，但是随着Nginx出色的性能表现，Django也有了更先进的部署方式，比较常用的一种部署方案是Nginx+Gunicorn。 接下来我会详细介绍一个完整的符合生产条件的部署过程及组件，这些组件全部属于开源实现。  
####前提条件
我假设你对Linux有基本的了解,而且拥有一台root权限的主机.我使用的服务器是Ubuntu12.04.你也可以选择其他Linux发行版(如:CentOS、Fedora)，相应的安装包管理方式分是`apt-get`和`yum`.如果你手头没有服务器,那么我推荐使用非常便宜的VPS服务器[DigitalOcean](https://www.digitalocean.com/?refcode=af4cff8f42bc)。最低$0.05/小时的费用。  
####系统更新

    $ sudo apt-get update
    $ sudo apt-get upgrade
####安装MySQL

    $ sudo apt-get install mysql-server
安装过程中会提示输入数据库密码,安装成功后创建一个MySQL新用户,并赋予权限  

    #以管理员身份登录
    mysql -uroot -p         

    #选择mysql
    use mysql               

    #创建用户名和设定密码
    create user 'test_user'@'localhost' identified by 'password' 

    #创建数据库
    create database test_db 

    #授予test_user操作test_db的所有权限
    grant all privileges on test_db.* to test_user@localhost identified by 'password'

    #使所有操作生效
    flush privileges
####安装virtualenv,为app创建一个独立的python环境
[Virtualenv](http://virtualenv.org)可以在系统中创建一个独立的python环境,多个应用彼此不受影响,这样不同的应用使用的依赖库就不会相互冲突(比如一个应用是基于Django1.5,另一个应用可以用virtualenv创建新的python环境来使用Django1.6).当然它的安装也很简单  
    
    sudo apt-get install python-virtualenv
#####为app创建并且激活一个python环境
我们把应用创建在/webapps目录下面,  

    $ cd /webapps/
    $ virtualenv hello_django

    New python executable in hello_django/bin/python
    Installing Setuptools....................................done.
    Installing Pip...........................................done.

    $ cd hello_django
    $ source bin/activate
    (hello_django) $                #注意`$`符号前的hello_django, 此时表明你已经在这个新的python执行环境中

现在python环境激活了,你就可以在这个环境中安装django等其他库  

    (hello_django) $ pip install django

    Downloading/unpacking django
      Downloading Django-1.6.1.tar.gz (6.6MB): 6.6MB downloaded
      Running setup.py egg_info for package django
        
        warning: no previously-included files matching '__pycache__' found under directory '*'
        warning: no previously-included files matching '*.py[co]' found under directory '*'
    Installing collected packages: django
      Running setup.py install for django
        changing mode of build/scripts-2.7/django-admin.py from 644 to 755
        
        warning: no previously-included files matching '__pycache__' found under directory '*'
        warning: no previously-included files matching '*.py[co]' found under directory '*'
        changing mode of /usr/local/bin/django-admin.py to 755
    Successfully installed django
    Cleaning up...
    
接下来就创建一个空的django项目  
    
    (hello_django) $ django-admin.py startproject hello

用开发模式测试一下项目是否可以正常运行

    (hello_django) $ cd hello
    (hello_django) $ python manage.py runserver localhost:80

    Validating models...
    
    0 errors found
    January 17, 2014 - 10:34:13
    Django version 1.6.1, using settings 'hello.settings'
    Starting development server at http://localhost:80/
    Quit the server with CONTROL-C.
此时你应该可以正常访问:http://localhost了.     
####配置MySQL配合Django工作

Django 使用MySQL作为后端存储需要使用`MySQL-python`数据库适配器，但是它需要依赖本地扩展库`python-dev`，`libmysqlclient-dev`，所以先安装依赖库  

    $ sudo apt-get install python-dev libmysqlclient-dev
安装 `MySQL-python`  

    (hello_django) $pip install mysql-python
在settings.py中配置数据库信息  

    DATABASES = {
        'default': {
            'ENGINE': 'django.db.backends.mysql',
            'NAME': 'test_db',
            'USER': 'test_user',
            'PASSWORD': 'password',
            'HOST': 'localhost',
            'PORT': '',                      # Set to empty string for default.
        }
    }
django初始化数据库，默认Django会创建一些数据表  
    
    (hello_dango) $ python manage.py syncdb

####为应用创建系统用户
虽然DJango有完善的安全追踪记录，但是如果应用对服务器资源的访问限制在自己的范围内，可以避免无谓的入侵危害，因此我们的web应用应该使用有限制权限的用户来运行这个web应用。  

为应用创建一个用户，名字叫做`hello`，附给系统组叫`webapps`。  

    $ sudo groupadd --system webapps
    $ sudo useradd --system --gid webapps --home /webapps/hello_django hello 
####Gunicorn
在生产环境下我们就不应该使用Django自带的单线程的开发服务器，[Gunicorn](http://gunicorn.org)就是很好的选择。  

    (hello_django) $ pip install gunicorn

    Downloading/unpacking gunicorn
      Downloading gunicorn-0.17.4.tar.gz (372Kb): 372Kb downloaded
      Running setup.py egg_info for package gunicorn
    
    Installing collected packages: gunicorn
      Running setup.py install for gunicorn
    
        Installing gunicorn_paster script to /webapps/hello_django/bin
        Installing gunicorn script to /webapps/hello_django/bin
        Installing gunicorn_django script to /webapps/hello_django/bin
    Successfully installed gunicorn
    Cleaning up...
安装成功后，现在你可以通过一下命令测试下你的django应用能否运行在gunicorn上面。  

    (hello_django) $ gunicron hello.wsgi:application --bind 0.0.0.0:8001
现在你应该可以访问Gunicron服务器从http://localhost:8001 , Gunicron安装好后，接下来再写一个bash脚本做一些配置使之用起来更方便。 文件保存为`bin/gunicorn_start.sh`

    #!/bin/bash
    NAME='hello_app'                                   #应用的名称
    DJANGODIR=/webapps/hello_django/hello              #django项目的目录
    SOCKFILE=/webapps/hello_django/run/gunicorn.sock   #使用这个sock来通信
    USER=hello                                         #运行此应用的用户
    GROUP=webapps                                      #运行此应用的组
    NUM_WORKERS=3                                      #gunicron使用的工作进程数
    DJANGO_SETTINGS_MODULE=hello.settings              #django的配置文件
    DJANGO_WSGI_MODULE=hello.wsgi                      #wsgi模块
    
    echo "starting $NAME as `whoami`"
    #激活python虚拟运行环境
    cd $DJANGODIR
    source ../bin/activate
    export  DJANGO_SETTINGS_MODULE=$DJANGO_SETTINGS_MODULE
    export PYTHONPATH=$DJANGODIR:$PYTHONPATH
    
    #如果gunicorn.sock所在目录不存在则创建
    RUNDIR=$(dirname $SOCKFILE)
    test -d $RUNDIR || mkdir -p $RUNDIR
    
    #启动Django
    
    exec ../bin/gunicorn ${DJANGO_WSGI_MODULE}:application \
        --name $NAME \
        --workers $NUM_WORKERS \
        --user=$USER --GROUP=$GROUP \
        --log-level=debug \
        --bind=unix:$SOCKFILE

用户`hello`将运新这个应用，那么要把这个应用的目录的权限交给`hello`  

    $ sudo chown -R hello:users /webapps/hello_django
    $ sudo chmod -R g+w /webapps/hello_django
    $ sudo chmod u+x bin/gunicorn_start.sh
如果你还不是组`users`的成员，使用下面命令：  

    $ sudo usermod -a -G users `whoami`

现在就可以切换到用户`hello`来执行这段脚本：  

    $sudo su - hello
    $bin/gunicorn_start.sh

    Starting hello_app as hello
    2014-01-17 15:59:25 [10724] [INFO] Starting gunicorn 18.0
    2014-01-17 15:59:25 [10724] [DEBUG] Arbiter booted
    2014-01-17 15:59:25 [10724] [INFO] Listening at: unix:/webapps/hello_django/run/gunicorn.sock (10724)
    2014-01-17 15:59:25 [10724] [INFO] Using worker: sync
    2014-01-17 15:59:25 [10735] [INFO] Booting worker with pid: 10735
    2014-01-17 15:59:25 [10736] [INFO] Booting worker with pid: 10736
    2014-01-17 15:59:25 [10737] [INFO] Booting worker with pid: 10737
    
    ^C (CONTROL-C to kill Gunicorn)
    
    2014-01-17 15:59:28 [10736] [INFO] Worker exiting (pid: 10736)
    2014-01-17 15:59:28 [10735] [INFO] Worker exiting (pid: 10735)
    2014-01-17 15:59:28 [10724] [INFO] Handling signal: int
    2014-01-17 15:59:28 [10737] [INFO] Worker exiting (pid: 10737)
    2014-01-17 15:59:28 [10724] [INFO] Shutting down: Master
    $ exit

--workers 设置的个数规则是：2*CPUs+1。因此单核CPU机器的进程数设置为3个。  
--name 默认是`gunicorn`，置顶后，可以通过`top`或`ps`查看到，唯一标识其进程。  
####s使用Supervisor启动、监控
`gunicorn_start`脚本现在准备就绪，我们需要确保系统能够自动启动或者重启，因为系统可能会由于某些原因导致异常终止，这个任务就交给supervisor，它的安装也非常简单：  

    $ sudo apt-get insatll supervisor
安装后，在`/etc/supervisor/conf.d/`目录下创建配置文件`/etc/supervisor/conf.d/hello.conf`，用来启动监视应用程序。  

    [program:hello]
    command = /webapps/hello_django/bin/gunicorn_start.sh                 ; Command to start app
    user = hello                                                          ; User to run as
    stdout_logfile = /webapps/hello_django/logs/gunicorn_supervisor.log   ; Where to write log messages
    redirect_stderr = true  

创建文件存储日子：  

    $ mkdir -p /webapps/hello/logs
    $ touch /webapps/hello_django/logs/gunicorn_supervisor.log

配置好了之后，supervisor重新加载配置文件  

    $ sudo supervisorctl reread
    hello: available
    $ sudo supervisorctl update
    hello: added process group
同时你还可以检查app的状态、启动、停止、重启  

    $ sudo aupervisorctl status hello
    hello                RUNNING
    $ sudo supervisorctl stop hello 
    hello: stopped
    $ sudo supervisorctl start hello 
    hello: started
    $sudo supervisorctl restart hello 
    hello:stoped
    hello:started
现在应用可以在系统重启或者某些原因崩溃后自动重启了。  

####Nginx
配置Nginx  

    $ sudo apt-get install nginx
    $ sudo /etc/init.d/nginx start
#####创建一个Nginx虚拟服务器服务于Django
每个Nginx虚拟服务器应该是通过一个在`/etc/nginx/sites-available`目录下的文件描述的，为了使之生效需要在`/etc/nginx/sites-enbled`做一个符号连接  
创建配置文件`/etc/nginx/sites-available/hello`，内容如下：  

    upstream hello_app_server {
      # fail_timeout=0 means we always retry an upstream even if it failed
      # to return a good HTTP response (in case the Unicorn master nukes a
      # single worker for timing out).
     
      server unix:/webapps/hello_django/run/gunicorn.sock fail_timeout=0;
    }
     
    server {
     
        listen   80;
        server_name localhost;
     
        client_max_body_size 4G;
     
        access_log /webapps/hello_django/logs/nginx-access.log;
        error_log /webapps/hello_django/logs/nginx-error.log;
     
        location /static/ {
            alias   /webapps/hello_django/static/;
        }
        
        location /media/ {
            alias   /webapps/hello_django/media/;
        }
     
        location / {
            # an HTTP header important enough to have its own Wikipedia entry:
            #   http://en.wikipedia.org/wiki/X-Forwarded-For
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
     
            # enable this if and only if you use HTTPS, this helps Rack
            # set the proper protocol for doing redirects:
            # proxy_set_header X-Forwarded-Proto https;
     
            # pass the Host: header from the client right along so redirects
            # can be set properly within the Rack application
            proxy_set_header Host $http_host;
     
            # we don't want nginx trying to do something clever with
            # redirects, we set the Host: header above already.
            proxy_redirect off;
     
            # set "proxy_buffering off" *only* for Rainbows! when doing
            # Comet/long-poll stuff.  It's also safe to set if you're
            # using only serving fast clients with Unicorn + nginx.
            # Otherwise you _want_ nginx to buffer responses to slow
            # clients, really.
            # proxy_buffering off;
     
            # Try to serve static files from nginx, no point in making an
            # *application* server like Unicorn/Rainbows! serve static files.
            if (!-f $request_filename) {
                proxy_pass http://hello_app_server;
                break;
            }
        }
     
        # Error pages
        error_page 500 502 503 504 /500.html;
        location = /500.html {
            root /webapps/hello_django/static/;
        }
    }
创建符号链接：  

    $ sudo ln -s /etc/nginx/sites-available/hello /etc/nginx/sites-enabled/hello
重启Nginx：  

    $ sudo /etc/init.d/nginx restart

所有配置基本完成了，现在你就可以看到django的欢迎界面了。  

####卸载Django应用
如果你需要卸载这个项目，那么可以按照如下步骤彻底清除  

移除虚拟服务器从Nginx的`sites-enabled`目录：  

    $ sudo rm /etc/nginx/sites-enabled/hello_django
重启Nginx：  
    
    $ sudo /etc/init.d/nginx restart
如果以后都不打算使用这个项目了，那么可以从`site-available`目录删除配置文件  
    
    $ sudo rm /etc/nginx/sites-available/hello_django

用Supervisor停掉应用：  
    
    $ sudo supervisorctl stop hello 

从supervisor的控制脚本目录中移除配置：  

    $ sudo rm /etc/supervisor/conf.d/hello.conf

最后可以把整个应用的目录删除：  
    
    $ sudo rm -r  /webapps/hello_django

####总结
如果你是一步一步根据这个教程来操作的话，那么整个目录结构应该是如下：  

    /webapps/hello_django/
    ├── bin                          <= virtualenv创建的目录
    │   ├── activate                 <= Environment activation script
    │   ├── django-admin.py
    │   ├── gunicorn
    │   ├── gunicorn_django
    │   ├── gunicorn_start.sh           <= 用Gunicorn启动应用的脚本
    │   └── python
    ├── hello                        <= 项目的根目录,把他添加到 PYTHONPATH
    │   ├── manage.py
    │   ├── project_application_1
    │   ├── project_application_2
    │   └── hello                    <= 项目的配置目录
    │       ├── __init__.py
    │       ├── settings.py          <= hello.settings - settings模块， Gunicorn需要使用
    │       ├── urls.py
    │       └── wsgi.py              <= hello.wsgi - WSGI module，Gunicorn使用
    ├── include
    │   └── python2.7 -> /usr/include/python2.7
    ├── lib
    │   └── python2.7
    ├── lib64 -> /webapps/hello_django/lib
    ├── logs                         <= 项目的日子目录
    │   ├── gunicorn_supervisor.log
    │   ├── nginx-access.log
    │   └── nginx-error.log
    ├── media                        <= 用户文件上传目录
    ├── run
    │   └── gunicorn.sock 
    └── static                       <= 项目的静态资源目录

此文参考[这里](http://michal.karzynski.pl/blog/2013/06/09/django-nginx-gunicorn-virtualenv-supervisor/)，所有步骤经过自己操作验证通过，如果你在配置过程中有任何疑问，毫不犹豫给我留言。  






####什么是描述符（descriptor）
只要是定义了`__get__()`、`__set()__`、`__delete()__`中任意一个方法的对象都叫描述符。那描述符协议是什么呢?这个协议指的就是这三个方法。  

    descr.__get__(self, obj, type=None) --> value
    
    descr.__set__(self, obj, value) --> None
    
    descr.__delete__(self, obj) --> None

那么描述符有什么牛逼的？ 通常来说Python对象的属性控制默认是这样的：从对象的字典(`__dict__`)中获取（get），设置（set）,删除（delete），比如：对于实例`a`，`a.x`的查找顺序为`a.__dict__['x']`,然后是`type(a).__dict__['x']`.如果还是没找到就往上级(父类)中查找。描述符就好比是破坏小子，他会改变这种默认的控制行为。究竟是怎么改变的呢？  

想必会你已经猜到了，如果属性`x`是一个描述符，那么访问`a.x`时不再从字典`__dict__`中读取，而是调用描述符的`__get__()`方法，对于设置和删除也是同样的原理。  

既然知道他有化腐朽为神奇的这种特点，聪明的你一定能想到的能用在什么场景下，我用邮件地址的验证这个简单的例子来演示他是如何运作的。  

    class Person(object):
        def __init__(self, email):
            self.email = email

现在如果有不安分的小子总想着搞破坏，传递一个无效的email过来，如果你不使用描述符你是没辙的，你别告诉我说你可以在init方法里面做验证嘛？老兄，python是一门动态语言，也没有像我大java一样拥有私有变量。用一个例子来粉碎你的猜想。  

    import re
    class Person(object):
        def __init__(self, email):
            m = re.match('\w+@\w+\.\w+', email)
            if not m:
                raise Exception('email not valid')
            self.email = email

上面这个初始化方法看似完美有缺，如果客户端能安分的按规则行房，错了，是行事。就不会出什么大问题。传入的无效值也能优雅的以异常的形式警告。  

    >>> p = test.Person('lzjun567@gmail.com')
    >>> p.email
    'lzjun567@gmail.com'
    >>> p2 = test.Person('dfsdfsdf')
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
      File "test.py", line 38, in __init__
        raise Exception('email not valid')
    Exception: email not valid
    >>> 

但是，捣蛋小子来了，他要这样给p对象赋值email：  
    
    >>> p.email = 'sdfsdfsdf'
    >>> p.email
    'sdfsdfsdf'
    >>> p.__dict__
    {'email': 'sdfsdfsdf'}
    >>> 

这时的`p.email`默认从`__dict__`读取值。你看给`p`传个火星来的email地址也能接受。这下只有上帝能救你于水火之中，其实上帝就是那个描述符啦。那怎么把email变成一个描述符啊?当然方式有好几种：  

#####基于类创建描述符

    import re

    class Email(object):
    
        def __init__(self):
            self._name = ''
    
        def __get__(self, obj, type=None):
            return self._name
    
        def __set__(self, obj, value):
            m = re.match('\w+@\w+\.\w+', value)
            if not m:
                raise Exception('email not valid')
            self._name = value
    
        def __delete__(self, obj):
            del self._name
        
    class Person(object):
        email = Email()

这下你给他赋值一个火星文看看:  

    >>> p = Person()
    >>> p.email = 'ではないああを行う'
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
      File "test.py", line 46, in __set__
        raise Exception('email not valid')
    Exception: email not valid
    >>> 

    >>> p.email = 'lzjun@gmail.com'
    >>> p.email
    'lzjun@gmail.com'
    
现在总算是能抵挡住大和民族的`呀咩嗲`了,再来看看`__dict__`中有哪些东西：  

    >>> Person.__dict__
    dict_proxy({'__dict__': <attribute '__dict__' of 'Person' objects>, '__module__': 'test', '__weakref__': <attribute '__weakref__' of 'Person' objects>, 'email': <test.Email object at 0x8842fcc>, '__doc__': None})
    >>> p.__dict__
    {}

嗯，纵使email赫然在列dict中，拥有了描述符后，解释器对其视而不见，转而去调用描述符中对应的方法。即使是下面的操作方式也是徒劳而已：

    >>> p.__dict__['email'] = 'xxxxxx'
    >>> p.email
    'lzjun@gmail.com'
    >>> 

#####使用property()函数创建描述符

    class Person(object):
    
        def __init__(self):
            self._email = None
    
        def get_email(self):
            return self._email
    
        def set_email(self, value):
             m = re.match('\w+@\w+\.\w+', value)
             if not m:
                 raise Exception('email not valid')
             self._email = value
    
        def del_email(self):
            del self._email
    
        email = property(get_email, set_email, del_email, 'this is email property')
            

    >>> p = Person()
    >>> p.email
    >>> p.email = 'dsfsfsd'
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
      File "test.py", line 71, in set_email
        raise Exception('email not valid')
    Exception: email not valid
    >>> p.email = 'lzjun567@gmail.com'
    >>> p.email
    'lzjun567@gmail.com'
    >>> 

property()函数返回的是一个描述符对象，它可接收四个参数：`property(fget=None, fset=None, fdel=None, doc=None)`  

* fget：属性获取方法
* fset：属性设置方法
* fdel：属性删除方法
* doc： docstring

采用property实现描述符与使用类实现描述符的作用是一样的，只是实现方式不一样。property的一种纯python的实现方式如下：  

    class Property(object):
        "Emulate PyProperty_Type() in Objects/descrobject.c"
    
        def __init__(self, fget=None, fset=None, fdel=None, doc=None):
            self.fget = fget
            self.fset = fset
            self.fdel = fdel
            if doc is None and fget is not None:
                doc = fget.__doc__
            self.__doc__ = doc
    
        def __get__(self, obj, objtype=None):
            if obj is None:
                return self
            if self.fget is None:
                raise AttributeError("unreadable attribute")
            return self.fget(obj)
    
        def __set__(self, obj, value):
            if self.fset is None:
                raise AttributeError("can't set attribute")
            self.fset(obj, value)
    
        def __delete__(self, obj):
            if self.fdel is None:
                raise AttributeError("can't delete attribute")
            self.fdel(obj)
    
        def getter(self, fget):
            return type(self)(fget, self.fset, self.fdel, self.__doc__)
    
        def setter(self, fset):
            return type(self)(self.fget, fset, self.fdel, self.__doc__)
    
        def deleter(self, fdel):
            return type(self)(self.fget, self.fset, fdel, self.__doc__)

留心的你发现property里面还有getter，setter，deleter方法，那他们是做什么用的呢？来看看第三种创建描述符的方法。  

#####使用@property装饰器

    class Person(object):
    
        def __init__(self):
            self._email = None
    
        @property
        def email(self):
            return self._email
    
        @email.setter
        def email(self, value):
             m = re.match('\w+@\w+\.\w+', value)
             if not m:
                 raise Exception('email not valid')
             self._email = value
    
        @email.deleter
        def email(self):
            del self._email
    
    >>>
    >>> Person.email
    <property object at 0x02214930>
    >>> p.email = 'lzjun'
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
      File "test.py", line 93, in email
        raise Exception('email not valid')
    Exception: email not valid
    >>> p.email = 'lzjun@gmail.com'
    >>> p.email
    'lzjun@gmail.com'
    >>>

发现没有，其实装饰器property只是property函数的一种语法糖而已，setter和deleter作用在函数上面作为装饰器使用。  

####哪些场景用到了描述符

其实python的实例方法就是一个描述符，来看下面代码块：  

    >>> class Foo(object):
    ...     def my_function(self):
    ...        pass
    ...
    >>> Foo.my_function
    <unbound method Foo.my_function>
    >>> Foo.__dict__['my_function']
    <function my_function at 0x02217830>
    >>> Foo.__dict__['my_function'].__get__(None, Foo)
    <unbound method Foo.my_function>
    >>> Foo().my_function
    <bound method Foo.my_function of <__main__.Foo object at 0x0221FFD0>>
    >>> Foo.__dict__['my_function'].__get__(Foo(), Foo)
    <bound method Foo.my_function of <__main__.Foo object at 0x02226350>>

my_function函数实现了`__get__`方法。描述符也被大量用在各种框架中，比如：django的[paginator.py](https://github.com/django/django/blob/master/django/core/paginator.py)模块，django的model其实也使用了描述符。  







python 函数默认是一个描述符.调用 my_instance.my_method会重载为Myclass.__dict__['my_method'].__get__(myinstance, MyClass).


http://docs.python.org/2/howto/descriptor.html#properties
http://stackoverflow.com/questions/17330160/python-how-does-decorator-property-work
https://pyzh.readthedocs.org/en/latest/Descriptor-HOW-TO-Guide.html
http://www.ibm.com/developerworks/cn/opensource/os-pythondescriptors/
https://blog.tonyseek.com/post/notes-about-python-descriptor/
https://speakerdeck.com/mitsuhiko/basket-of-random-python-snippets
http://docs.python.org/2/howto/descriptor.html

理解内建函数dir()与vars()
==============================
Python对象存储它的实例变量在一个字典中，该字典归这个对象所有，`vars(x)`就可以返回这个字典，它等效于`a.__dict__`。  

`dir(x)`返回的是一个


###使用Django admin模块，必须：  
1. 添加`django.contrib.admin` 到`INSTALLED_APPS`中  
2. admin依赖的app包括：`django.contrib.auth`,`django.contrib.contenttypes`,`django.contrib.messages`和`django.contrib.sessions`
3. 添加`django.contrib.messages.context_processors.messsags`到`TEMPLATE_CONTEXT_PROCESSORS`
4. 添加`django.contrib.auth.middleware.AuthenticateionMiddleware`和`django.contrib.messages.middleware.MessageMiddleware`,`到MIDDLEWARE_CLASS`

###ModelAdmin.actions

自定义action函数和普通函数没啥区别，需要是三个参数：当前的 ModelAdmin，当前的HttpRequest，用户说选中的QuerySet  

    def make_publiced(modleadmin,request,queryset):
        queryset.update(public=False)

直接调用queryset的update比逐个迭代entity更高效。默认action的下拉列表显示的名字就是函数名`make_publiced`,但是你可以起一个更优雅的名字：

    make_publiced.short_description = u"标记为公开"

最后一步就是告诉modelaction

    actions = ['make_publiced']

以上就是你需要做的全部
https://docs.djangoproject.com/en/dev/ref/contrib/admin/actions/

Django----Form的来龙去脉（-）使用篇
-------------------------------
*（注：个人学习总结，仅供参考）*  
####Form表单的功能  
1. 自动生成HTML表单元素  
2. 检查表单数据的合法性  
3. 如果验证错误，重新显示表单（数据不会重置）  
4. 数据类型转换（字符类型的数据转换成相应的Python类型）  

####Form相关的对象包括  
*Widget*：用来渲染成HTML元素的工具，如：forms.Textarea对应HTML中的`<textarea>`标签  
*Field*：Form对象中的一个字段，如：EmailField表示email字段，如果这个字段不是有效的email格式，就会产生错误。  
*Form*：一系列Field对象的集合，负责验证和显示HTML元素  
*Form Media*：用来渲染表单的CSS和JavaScript资源。  

####Form Objects
Form对象封装了一系列Field和验证规则，Form类都必须直接或间接继承自`django.forms.Form`，定义Form有两种方式:  

方法一：直接继承Form   

    from django import forms
    class ContactForm(forms.Form):
        subject = forms.CharField(max_length=100,label='主题')
        message = form.CharField(widget=forms.TextArea)
        sender = form.EmailField()
        cc_myself = forms.BooleanField(required=False)

方法二：结合Model，继承django.forms.ModelForm  

    #models.py
    class Contact(models.Model):
        title = models.CharField(max_length=30)
        content = models.CharField(max_length=20)
    
    #form.py
    class ConotactForm(ModelForm):
        class Meta:
        model = Contact
        field = ('title','content')  #只显示model中指定的字段

####在视图（view）中使用form 
在view函数中使用form的一般情景是：  

view.py:  

    form django.shortcuts import render
    form django.http import HttpResponseRedirect
    
    def contact(request):
        if request.method=="POST":
            form = ContactForm(request.POST)
            if form.is_valid():  #所有验证都通过
                #do something处理业务
                return HttpResponseRedirect('/')
        else:
            form = ContactForm()
        return render(request,'contact.html',{'form':form})

contact.html:  

    <form action='/contact/' method='POST'>
        {% for field in form %}
            <div class = 'fieldWrapper'>
                {{field.label_tag}}:{{field}}
                {{field.errors}}
            </div>
        {% endfor %}
        <div class='fieldWrapper'> <p><input type='submit' value='留言'></p></div>
    </form>

####处理表单数据  

form.is_valid()返回true后，表单数据都被存储在form.cleaned_data对象中（字典类型，意为经过清洗的数据），而且数据会被自动转换为Python对象，如：在form中定义了DateTimeField，那么该字段将被转换为datetime类型，还有诸如：IntegerField、FloatField  

    if form.is_valid():
        subject = form.cleaned_data['subject']
        message = form.cleaned_data['message']
        sender = form.cleaned_data['sender']
        cc_myself = form.cleaned_data['cc_myself']
    
        recipients = ['info@example.com']
        if cc_myself:
            recipients.append(sender)
    
        from django.core.mail import send_mail
        send_mail(subject, message, sender, recipients)
        return HttpResponseRedirect('/thanks/') # Redirect after POST

Form的简单使用方法就这些。 另：   

####在模版中显示表单的几种方式：
显示form找template中的方法多种多样，也可以自定义：  

    <form action="/contact/" method="post">{% csrf_token %}
    {{ form.as_p }}
    <input type="submit" value="Submit" />
    </form>

还可以使用form.as_table、form.as_ul，分别表示用`<p>`标签，`<table>`标签和`<ul>`表示显示表单。如果要自定义，你只要获取到每个元素的值就行：  

    <form action="/contact/" method="post">
        {{ form.non_field_errors }}
        <div class="fieldWrapper">
            {{ form.subject.errors }}
            <label for="id_subject">Email subject:</label>
            {{ form.subject }}
        </div>
        <div class="fieldWrapper">
            {{ form.message.errors }}
            <label for="id_message">Your message:</label>
            {{ form.message }}
        </div>
        <div class="fieldWrapper">
            {{ form.sender.errors }}
            <label for="id_sender">Your email address:</label>
            {{ form.sender }}
        </div>
        <div class="fieldWrapper">
            {{ form.cc_myself.errors }}
            <label for="id_cc_myself">CC yourself?</label>
            {{ form.cc_myself }}
        </div>
        <p><input type="submit" value="Send message" /></p>
    </form>
每个form字段都可以使用 {{form.name_of_field}}得到。

也可以通过迭代form，每个迭代元素对应的是form里面的field  

    <form action="/contact/" method="post">
        {% for field in form %}
            <div class="fieldWrapper">
                {{ field.errors }}
                {{ field.label_tag }}: {{ field }}
            </div>
        {% endfor %}
        <p><input type="submit" value="Send message" /></p>
    </form>
{{field}}有如下属性：  

{{field.lable}}，如：*Email address*  
{{field.label\_tag}}，如： `<label for=id_email>Email address</label>`  
{{field.value}} 如：someone.@gmail.com  
{{field.errors}}  

参考：
https://docs.djangoproject.com/en/dev/topics/forms/  
[The Forms API](https://docs.djangoproject.com/en/1.5/ref/forms/api/)
[Form field](https://docs.djangoproject.com/en/1.5/ref/forms/fields/)


filter_horizontal
raw_id_fields

网站开发阶段的静态资源文件一般都是未经过压缩合并处理的，这对于访问量巨大的网站来说不仅浪费带宽，而且也会影响网站的访问速度。django-compressor的作用就是在项目部署的时候对静态文件压缩合并成一个文件。下面先对settings配置文件的相关参数简要介绍在讨论Compressor的如何使用。如果你对setting文件非常了解不妨直接从第二部分开始。 

###第一部分：setting配置
早期的django处理静态资源要比较啰嗦，还要配置urlpatterens，不过自从django1.6开始加入了`django.contrib.staticfiles`这个内置app后，开发环境下处理静态资源就方便很多。  
1. `django.contrib.staticfiles`是django的内置(build-in)app，用于处理js，css，images等静态资源。首先确保这个app已经包含在`INSTALLED_APPS`中，django1.6默认是包含在其中的。  
2. 指定`STATIC_URL`，比如：  
    
    STATIC_URL = '/static/'
    
STATIC_URL是客户端访问静态资源的根路径，比如：模版中定义的资源路径是：  
    
    {% load staticfiles %}
    <script src="{% static "js/blog.js" %}"></script>

渲染后的效果是：    

    <script src="/static/js/blog.js"></script>

3 默认django会从app下的static子目录下查找静态文件，因此通常情况下你都是将相关静态文件独自放在各自的app/static目录下。为什么是这样的呢？django有个默认的配置项`STATICFILES_FINDERS`，他的默认值是：  

        ("django.contrib.staticfiles.finders.FileSystemFinder",
        "django.contrib.staticfiles.finders.AppDirectoriesFinder")

从上面我们看到有个叫AppDirectoriesFinder的模块，就是复杂在app/static目录下找静态文件的。至于FileSystemFinder我们稍后介绍。      
4. 像jquery，bootstrap等这样公用的资源文件都是在多个不同的app中共用的，如果是放在某个app中显得不符python哲学，因此django希望提供了公有的目录来放这些文件，需要用的一个配置参数是：`STATICFILES_DIRS`，比如：  

    STATICFILES_DIRS = (
        os.path.join(BASE_DIR, "static"),
        '/var/www/static/',
    )

也就是静态文件可以放在磁盘的任何一个位置都可以(只要有权限访问)，现在应该明白FileSystemFinder的作用了吧。就是用来查找定义在STATICFILES_DIRS中的静态文件的。  

###部署
以上是我们在开发环境下对静态资源的处理过程，那么在生产环境下是怎么处理的呢？还是这样由django自己来处理，那么累死django了，对于静态资源直接由Nginx这样的代理去处理好了。`django.contrib.staticfiles`提供非常方便的管理命令用来收集不同目录下的静态资源到一个统一的目录中去。  
1. 设置`STATIC_ROOT`，这个目录就是存放所有静态资源的地方.   

        STATIC_ROOT="/var/www/foofish.net/static/"

2 运行collectstatic管理命令  

        python manage.py collectstatic

   这个命令会拷贝所有静态资源到STATIC_ROOT目录。      
3. 配置一下nginx，让访问/static/路径的请求直接访问STATIC_ROOT就可以了。  

         location /static {
            alias /var/www/foofish.net/static/; # your Django project's static files -       amend as required
        }

**小结**  
django.contrib.staticfiles是django处理静态文件的内置app，开发阶段无需对静态资源配置繁琐的urlpatterns。STATIC_URL是客户端访问静态资源的根路径。STATICFILES_DIRS告诉django静态资源存放的位置，它由FileSystemFinder解析。STATIC_ROOT是项目部署时所有不同地方的静态资源文件汇总的地方，供nginx直接使用。python manage.py collecstatic命令是收集不同地方的资源文件到STRTIC_ROOT下去。  
###第二部分：compressor
django compressor 的安装配置非常简单，主要步骤：  

安装:  

    pip install django_compressor

配置:  

    COMPRESS_ENABLED = True

    INSTALLED_APPS = (
        # other apps
        "compressor",
    )

    STATICFILES_FINDERS = (
    'django.contrib.staticfiles.finders.AppDirectoriesFinder',
    'django.contrib.staticfiles.finders.FileSystemFinder',
    'compressor.finders.CompressorFinder',)

默认Compress开启与否取决对于DEBUG，默认是COMPRESS_ENABLED与DEBUG的值相反。因为compress的功能本身是用在生产环境下项目发布前对静态文件压缩处理的。因此想在开发阶段(DEBUG=True)的时候做测试使用，需要手动设置COMPRESS_ENABLED=True    

使用:  

    {% load compress %}
    #处理css
    {% compress css %}
    <link href="{% static "css/bootstrap.min.css" %}" rel="stylesheet">
    <link href="{% static "css/blog-home.css" %}" rel="stylesheet">
    <link href="{% static "css/github.css" %}" rel="stylesheet">
    {% endcompress %}
    
    #处理js
    {% compress js %}
    <script src="{% static "js/jquery-1.10.2.js" %}"></script>
    <script src="{% static "js/bootstrap.js" %}"></script>
    <script src="{% static "js/blog.js" %}"></script>
    {% endcompress %}

执行命令：`python manage.py compress` ,最终文件将合并成:  

    <link rel="stylesheet" href="/static/CACHE/css/f18b10165eed.css" type="text/css">
    <script type="text/javascript" src="/static/CACHE/js/9d1f64ba50fc.js"></script>
这两文件在STATIC_ROOT目录下面。  


django 模版语言
==============================
模版就是一个文本文件，可以生成HTML、XML等任何基于文本格式的文件，模版包含**变量**，变量会被值替换，**标签** 控制模版的逻辑，下面就是一个简单的模版文件  

    <h1>{{ section.title }}</h1>
    {% for story in story_list %}
    <h2>
      <a href="{{ story.get_absolute_url }}">
        {{ story.headline|upper }}
      </a>
    </h2>
    <p>{{ story.tease|truncatewords:"100" }}</p>
    {% endfor %}

####变量
- 变量的形式是：{{variable}}， 当模板引擎遇到变量的时，引擎使用变量的值代替变量。使用"**.**" 访问变量的属性，比如{{user.name}}。当模板引擎碰到"**.**"的时候，模版系统会按照如下顺序查找：  
     1. 字典查找，例如：foo['bar']
     2. 属性查找，例如：foo.bar
     3. 方法查找，例如：foo.bar()
     4. list-index查找，例如foo[bar]
 
####过滤器
- 通过过滤器可以改变变量的显示方式，过滤器的形式是：{{ variable | filter }}，管道符号'|'代表使用过滤器，例如：{{value|default:"nohting"}}表示当value的为空或者None时就会显示"nothing"。
- 过滤器能够采用链式的方式使用，例如：{{ text | lower }} 把变量text值转换为小写
- 过滤器还可以带参数，例如： {{ bio|truncatewords:30 }}
- 过滤器的参数中如果带有空格，那么需要用引号引起来，例如：{{ list | join : ", "}}
- django中30个内建的过滤器

    1. add
            使用形式为：{{ value | add: "2"}}
            意义：将value的值增加2
            例如：value的值为4，那么输出结构为6
            **注意**：add首先尝试将两个值当作整数相加，如果失败就尝试把两个值组合在一起（比如遇到字符串或者list的时候），其他失败的情况最后返回一个空字符串，例如：表达式`{{first|add:second}}`，first=[1,2,3],second=[4,5,6]，那么输出结果为[1，2，3，4，5，6]

    2. addslashes
            使用形式为：{{ value | addslashes }}
            意义：在value中的引号（单引号和双引号）前增加反斜线
            例如：{{value|addslashes}}，`value=I' using Django`，输出结果是：`I\'m using Django`.  
            
    3. capfirst
            使用形式为：{{ value | capfirst }}
            意义：value的第一个字符转化成大写形式
    4. cut
             使用形式为：{{ value | cut:arg}}
             意义：移除value中包含arg的字符串
             例如，如果value是“String with spaces” arg是" "那么输出是"Stringwithspaces"
             
    5. date
             使用形式为：：
                 (a) {{ value | date:"D d M Y" }}，例如，如果value是一个datetime对象(datetime.datetime.now())那么输出将是字符串"Wed 09 Jan 2008"
                 (b) {{ value | date }}，这种形式没有格式化字符串，这时候，格式化字符串会自动采用DATE_FORMAT所设置的形式。
             意义：将日期格式数据按照给定的格式输出
    6. default
             使用形式：{{ value | default: "nothing" }}，例如，如果value是“”，那么输出将是nothing
             意义：如果value的意义是False，那么输出使用缺省值
             
    7. default_if_none
             使用形式：{{ value | default_if_none:"nothing" }}，例如，如果value是None，那么输出将是nothing
             意义：如果value是None，那么输出将使用缺省值
             
    8. dictsort
             意义：如果value的值是一个字典，那么返回值是按照关键字排序的结果
             使用形式：{{ value | dictsort:"name"}}，例如，
             如果value是：
       [
           {'name': 'zed', 'age': 19},
           {'name': 'amy', 'age': 22},
           {'name': 'joe', 'age': 31},
       ]
       那么，输出是：
       [
           {'name': 'amy', 'age': 22},
           {'name': 'joe', 'age': 31},
           {'name': 'zed', 'age': 19},
       ]

    9. dictsortreversed
       意义：如果value的值是一个字典，那么返回值是按照关键字排序的结果的反序
       使用形式：与上述(8)完全相同。
       
    10. divisibleby
       使用形式：{{ value | divisibleby:arg}}，如果value是21，arg是3，那么输出将是True
       意义：如果value能够被arg整除，那么返回值将是True
       
    11. escape
       使用形式：{{ value | escape}}
       意义：替换value中的某些字符，以适应HTML格式，包括：
       
            < is converted to &lt;
            > is converted to &gt;
            ' (single quote) is converted to &#39;
            " (double quote) is converted to &quot;
            & is converted to &amp;
        
       escape仅仅在输出的时候才起作用，所以escape不能够用在链式过滤器的中间，
他应该总是最后一个过滤器，如果想在链式过滤器的中间使用，那么可以使用force_escape

    12. escapejs
       使用形式：{{ value | escapejs }}
       意义：替换value中的某些字符，以适应JAVASCRIPT和JSON格式。
       例如：如果value的值是： `testing\r\njavascript \'string" <b>escaping</b>`, 那么输出：`testing\\u000D\\u000Ajavascript \\u0027string\\u0022 \\u003Cb\\u003Eescaping\\u003C/b\\u003E`
       
    13. filesizeformat
       使用形式：{{ value | filesizeformat }}
       意义：格式化value，使其成为易读的文件大小，例如：13KB，4.1MB等。
       
   14. first
       使用形式：{{ value | first }}
       意义：返回列表中的第一个Item，例如，如果value是列表['a','b','c']，那么输出将是'a'。

    15. floatformat
       使用形式：{{ value | floatformat}}或者{{value|floatformat:arg}}，
                 arg可以是正数也可以是负数。没有参数的floatformat相当于floatformat:-1
       (1)如果不带arg，那么引擎会四舍五入，同时最多只保留一位小数
       
            34.23234    {{ value|floatformat }}  34.2
            34.00000	{{ value|floatformat }}	34
            34.26000	{{ value|floatformat }}	34.3
        (2)如果arg是正数，那么引擎会四舍五入，同时保留arg位的小数。

            34.23234	{{ value|floatformat:3 }}	34.232
            34.00000	{{ value|floatformat:3 }}	34.000
            34.26000	{{ value|floatformat:3 }}	34.260
        (3)如果arg是负数，那么引擎会四舍五入，如果有小数部分，那么保留arg位小数；否则，则没有任何小数部分。

            34.23234	{{ value|floatformat:"-3" }}	34.232
            34.00000	{{ value|floatformat:"-3" }}	34
            34.26000	{{ value|floatformat:"-3" }}	34.26
            
    16. get_digit
       使用形式：{{ value | get_digit:"arg"}}，例如，如果value是123456789，arg是2，那么输出是8
       意义：给定一个数字，返回，请求的数字，记住：1代表最右边的数字，如果value不是合法输入，那么会返回所有原有值。
       
    17. iriencode
       使用形式：{{value | iriencode}}
       意义：如果value中有非ASCII字符，那么将其进行转化成URL中适合的编码，如果value已经进行过URLENCODE，该操作就不会再起作用。
       
    18. join
       使用形式：{{ value | join:"arg"}}，如果value是['a','b','c']，arg是'//'那么输出是a//b//c
       意义：使用指定的字符串连接一个list，作用如同python的str.join(list)
       
    19. last
       使用形式：{{ value | last }}
       意义：返回列表中的最后一个Item
       
    20. length
       使用形式：{{ value | length }}
       意义：返回value的长度。
       
    21. length_is
       使用形式：{{ value | length_is:"arg"}}
       意义：返回True，如果value的长度等于arg的时候，例如：如果value是['a','b','c']，arg是3，那么返回True
       
    22. linebreaks
       使用形式：{{value|linebreaks}}
       意义：value中的"\n"将被<br/>替代，并且整个value使用</p>包围起来，从而适和HTML的格式
       
    23. linebreaksbr
       使用形式：{{value |linebreaksbr}}
       意义：value中的"\n"将被`<br/>`替代
       
    24. linenumbers
       使用形式：{{value | linenumbers}}
       意义：显示的文本，带有行数。
       
    25. ljust
       使用形式：{{value | ljust}}
       意义：在一个给定宽度的字段中，左对齐显示value
       
    26. center
       使用形式：{{value | center}}
       意义：在一个给定宽度的字段中，中心对齐显示value
       
    27. rjust
       使用形式：{{value | rjust}}
       意义：在一个给定宽度的字段中，右对齐显示value
       
    28. lower
       使用形式：{{value | lower}}
       意义：将一个字符串转换成小写形式
       
    29. make_list
       使用形式：{{value | make_list}}
       意义：将value转换成一个list，对于字符串，转换成字符list；对于整数，转换成整数list
       例如value是Joel，那么输出将是[u'J',u'o',u'e',u'l']；value是123，那么输出将是[1,2,3]
       
    30. pluralize
       使用形式：{{value | pluralize}}，或者{{value | pluralize:"es"}}，或者{{value | pluralize:"y,ies"}}
       意义：如果value不是1，则返回一个复数后缀，缺省的后缀是's'
    31. random
       使用形式：{{value | random}}
       意义：从给定的list中返回一个任意的Item
       
    32. removetags
       使用形式：{{value | removetags:"tag1 tag2 tag3..."}}
       意义：删除value中tag1,tag2....的标签。例如，如果value是`<b>Joel</b> <button>is</button> a <span>slug</span>`
             tags是"b span"，那么输出将是：`Joel <button>is</button> a slug`
             
    33. safe
       使用形式：{{value | safe}}
       意义：当系统设置autoescaping打开的时候，该过滤器使得输出不进行escape转换
       
    34. safeseq
       与上述safe基本相同，但有一点不同的就是：safe是针对字符串，而safeseq是针对多个字符串组成的sequence
       
    35. slice
       使用形式：{{some_list | slice:":2"}}
       意义：与python语法中的slice相同，:2表示第一的第二个元素
       
    36. slugify
        使用形式：{{value | slugify}}
        意义：将value转换成小写形式，同事删除所有分单词字符，并将空格变成横线
              例如：如果value是Joel is a slug，那么输出将是joel-is-a-slug
    37. stringformat
        这个不经常用，先不说
        简单举个例子：如果value是 10，那么输出 1.000000E+01
        
    38. striptags
        使用形式：{{value | striptags}}
        意义：删除value中的所有HTML标签
        
    39. time
        使用形式：{{value | time:"H:i"}}或者{{value | time}}
        意义：格式化时间输出，如果time后面没有格式化参数，那么输出按照TIME_FORMAT中设置的进行。
        
    40. title
        转换一个字符串成为title格式。
        如： value是 "my first post",输出： "My First Post"
        
    41. truncatewords
        使用形式：{{value | truncatewords:2}}
        意义：将value切成truncatewords指定的单词数目
        例如，如果value是Joel is a slug 那么输出将是：Joel is ...
        
    42. truncatewords_html
        使用形式同(39)
        意义：truncation点之前如果某个标签打开了，但是没有关闭，那么在truncation点会立即关闭。
              因为这个操作的效率比truncatewords低，所有只有在value是html格式时，才考虑使用。
              
    43. upper
        转换一个字符串为大写形式
        
    44. urlencode
        将一个字符串进行URLEncode
        
    45. urlize
        意义：将一个字符串中的URL转化成可点击的形式。
        使用形式：{{ value | urlize }}
        例如，如果value是Check out www.djangoproject.com，那么输出将是：
              Check out <a href="http://www.djangoproject.com">www.djangoproject.com</a>
              
    46. urlizetrunc
        使用形式：{{ value | urlizetrunc:15}}
        意义：与(43)相同，但是有一点不同就是现实的链接字符会被truncate成特定的长度，后面以...现实。
        
    47. wordcount
        返回字符串中单词的数目
        
    48. wordwrap
        使用形式：{{value | wordwrap:5}}
        意义：按照指定的长度包装字符串
        例如，如果value是Joel is a slug，那么输出将会是：
        Joel
        is a
        slug
    49. timesince
        使用形式：{{value | timesince:arg}}
        意义：返回参数arg到value的天数和小时数
        例如，如果 blog_date 是一个日期实例表示 2006-06-01 午夜， 而 comment_date 是一个日期实例表示 2006-06-01 早上8点，
              那么 {{ comment_date|timesince:blog_date }} 将返回 "8 hours".
              
    50. timeuntil
        使用形式：{{value | timeuntil}}
        意义：与(47)基本相同，一个不同点就是，返回的是value距离当前日期的天数和小时数。

###三、标签  
1. 标签的形式是：{% tag %}，标签要比变量复杂
2. 标签的作用  
      (1)在输出时创建一些文本  
      (2)通过执行循环和一些逻辑来实现控制流  
      (3)装载一些外部信息进入模板
3. 内建标签
      (1)autoescape

        使用形式：
             {% autoescape off %}
                 (内容)
             {% endautoescape %}
         意义：当某块内容不需要自动转义的时候，这样写就可以了。当然如果块内某些地方需要转义的话，调用filter也可以。
      (2)block
      
         使用形式：
             {% block %}
                 (定义块内容)
             {% endblock %}
         意义：定义一个块，该块能够被继承他的子孙模板重写
      (3)comment
      
         使用形式：
             {% comment %}
                  (内容)
             {% endcomment %}
         意义：模板系统会忽略该标签内部的所有内容。
      (4)cycle
      
         使用形式：
         例如:
             <tr class="{% cycle list%}">
              ...
             </tr>
         意义：在循环时轮流使用给定的字符串列表中的值。
         
      (5)extends
      
         使用形式：{% extends "base.html" %}或者{% extends variable %}变量可以是一个字符串，也可以是一个模板对象。
         意义：表示本模板要对指定的父模板进行扩展。
      (6)filter
      
         使用形式：
             {%filter force_escape|lower%}
                 (内容)
             {%endfilter%}
         意义：将filter 标签圈定的内容执行过滤器操作。
      (7)firstof
      
         使用形式：{%firstof var1 var2 var3%}
         意义：输出第一个值不等于False的变量
         等价于：               
         {% if var1 %}
             {{ var1 }}
         {% else %}
             {% if var2 %}
                 {{ var2 }}
             {% else %}
                 {% if var3 %}
                     {{ var3 }}
                 {% endif %}
             {% endif %}
         {% endif %}
      (8)for
      
         使用形式：
             {% for variable in list/dict %}
                   (使用variable)
             {% endfor%}
         意义：循环list中的每个值，进行相应的输出
         注意：(a)也可以反向遍历{% for variable in list/dict reversed %}
               (b)也可以{% for x, y in points %} points中的每个元素为 (x,y)
               (c)也可以{% for key,value in data.items %}   data是一个dictionary 
         for loop中定义的一些内建变量
         forloop.counter         当前的迭代器数目(从1开始)
         forloop.counter0        当前的迭代器数目(从0开始)
         forloop.revcounter      当前的反向迭代器数目(从1开始)
         forloop.revcounter0     当前的反向迭代器数目(从0开始)
         forloop.first           值为True，如果是第一次通过迭代器
         forloop.last            值为True，如果是最后一次通过迭代器
         forloop.parentloop      对于嵌套循环，这是当前循环的上一层循环
      (9)for ... empty
      
         使用形式如下：
             {% for varibale in list %}
                  (内容1)
             {% empty %}
                  (内容2)
             {% endfor %}
         意义：当list是空的时候，能够执行内容2，其形式等同于，先if判断list是否存在，然后在根据情况做什么操作。
      (10)if
      
         使用形式如下 ：
             {% if variable %}
                 (内容1)
             {% else %}
                 (内容2)
             {% endif %}
         注意：variable中可以使用and or 或者not，但是有一条必须记住，就是不允许and 和 or一起使用
       (11)ifchanged
       
          使用形式：
          (a)如果直接检测循环变量是否变化，那么使用：
              {% ifchanged %}  
                  (内容)
              {% endifchanged %}
          (b)如果检测循环变量的某个dot变量，例如循环变量是date，那么检测date.hour，那么使用：
              {% ifchanged date.hour%}  
                  (内容)
              {% endifchanged %}    
          (c)ifchanged也可以加上一个{% else %}语句
          意义：检测本次循环的值和上一次循环的值一样不一样，只能用在循环里面。 
       (12)ifequal
       
          使用形式：
              {% ifequal variable1 variable2 %}
                  ...
              {% endifequal %}
          意义：判断两个变量是否相等。
       (13)ifnotequal
       
          使用与(12)相同
       (14)include
       
          使用形式：{% include "foo/bar.html" %}或者{% include template_name %}
          意义：将另外一个模板文件中的内容添加到该文件中。注意区别extend是继承。
       (15)now
       
          使用形式：{% now "jS F Y H:i "%}，注意存在需要转义的情况例如{% now "jS o\f F" %}，因为f是格式化字符串
          
具体的格式化字符串如下所示：
a
'a.m.' or 'p.m.' (Note that this is slightly different than PHP's output, because this includes periods to match Associated Press style.)	'a.m.'  
A
'AM' or 'PM'.	'AM'

b
Month, textual, 3 letters, lowercase.	'jan'

B
Not implemented.

d
Day of the month, 2 digits with leading zeros.	'01' to '31'

D
Day of the week, textual, 3 letters.	'Fri'

f
Time, in 12-hour hours and minutes, with minutes left off if they're zero. Proprietary extension.	'1', '1:30'

F
Month, textual, long.	'January'

g
Hour, 12-hour format without leading zeros.	'1' to '12'

G
Hour, 24-hour format without leading zeros.	'0' to '23'

h
Hour, 12-hour format.	'01' to '12'

H
Hour, 24-hour format.	'00' to '23'

i
Minutes.	'00' to '59'

I
Not implemented.	 

j
Day of the month without leading zeros.	'1' to '31'

l
Day of the week, textual, long.	'Friday'

L
Boolean for whether it's a leap year.	True or False

m
Month, 2 digits with leading zeros.	'01' to '12'

M
Month, textual, 3 letters.	'Jan'

n
Month without leading zeros.	'1' to '12'

N
Month abbreviation in Associated Press style. Proprietary 
extension.	'Jan.', 'Feb.', 'March', 'May'

O
Difference to Greenwich time in hours.	'+0200'

P
Time, in 12-hour hours, minutes and 'a.m.'/'p.m.', with minutes left off if they're zero and the special-case strings 'midnight' and 'noon' if appropriate. Proprietary extension.	'1 a.m.', '1:30 p.m.', 'midnight','noon', '12:30 p.m.'

r
RFC 2822 formatted date.	'Thu, 21 Dec 2000 16:01:07+0200'

s
Seconds, 2 digits with leading zeros.	'00' to '59'

S
English ordinal suffix for day of the month, 2 characters.	'st', 'nd', 'rd' or 'th'

t
Number of days in the given month.	28 to 31

T
Time zone of this machine.	'EST', 'MDT'

U
Not implemented.	 

w
Day of the week, digits without leading zeros.	'0' (Sunday) to '6' (Saturday)

W
ISO-8601 week number of year, with weeks starting on Monday.	1, 53

y
Year, 2 digits.	'99'

Y
Year, 4 digits.	'1999'

z
Day of the year.	0 to 365

Z
Time zone offset in seconds. The offset for timezones west of UTC is always negative, and for those east of UTC is always positive.

(16)spaceless
         使用形式：{% spaceless %}
                        (内容)
                   {% endspaceless %}
         意义：删除包围内容中的所有tab或者回车字符。
         
(17)template
          使用形式：{% templatetag %}
          意义：模板系统本身没有转义的概念，因此如果要输出一个像“{%”这样的东东，就需要采用这种方式，否则就会语法错误
其参数有：

    openblock	{%
    closeblock	%}
    openvariable	{{
    closevariable	}}
    openbrace	{
    closebrace	}
    opencomment	{#
    closecomment	#}
    
(18)with

使用形式：
     {% with  "expensive var1" as var2 %}
     {% endwith %}
 意义：当一个变量的访问消耗很大的模板解析时，可以用另外一个变量替换它，这种替换只有在with内部有效。
 
(19)url
 使用形式：{% url path.to.some_view arg1,arg2 %}
 意义：给定某个module中函数的名字，给定参数，那么模板引擎给你一个URL，从而避免硬编码URL到代码中
 
 注意：前提是URLconf中存在相应的映射,如果URLconf中没有该映射，那么会抛出异常，
       这是可以选择使用
       {% url path.to.view arg1 ,arg2 as the url %}
       <a href="{{ the_url }}">Link to optional stuff</a>
       其实这相当于
       {% url path.to.view as the_url %}
       {% if the_url %}
           <a href="{{ the_url }}">Link to optional stuff</a>
       {% endif %}
             
参考：
https://docs.djangoproject.com/en/dev/ref/templates/builtins/
http://lishiguang.iteye.com/blog/1332529


####escape 
转义，遇到`<div>`等标签时，django默认就会进行转义成`$lt;div$gt;`，在页面上看到了也是`<div>`。如果对于某些`<a>`标签不想转义，有如下几种方式：  

1. 在模版中使用 **safe** 过滤器，如：{{data|safe}} 
2. 在模版中使用 **autoescape** 标签，如：{%autoescape off %} {{data}} {%endautoescape%}
3. 在view中修改设置Context的autoscape属性为False，如：context = Context({'url':url},autoescape=False)，需要注意的是它的优先级低于第二条，意味着如果在template中显示的设置了{%autoescape on %}那么在context设置为autoescape=False也不会生效  


Django url()函数详解
======================
url()函数看起来的格式象：`url(r^/account/$', views.index, name=index)`，它可以接收四个参数，分别是两个必选参数：`regex`、`view`和两个可选参数：`kwargs`、`name`，接下来详细介绍这四个参数。  
#####regex
regex代表一个正则表达式，凡是与regex匹配的URL请求都会执行到url()函数中对应的第二个参数`view`代表的视图函数中。需要注意的是：正则表达式不会匹配URL中的域名和查询参数，如：http://www.foofish.net/article/?page=3, Django只找`article/`。正则表达式在URLconf模块加载时就编译好了，所以在匹配的时候速度是很快的。  

#####view
Django匹配正则表达式成功后，就会找到相应的视图函数，Django始终用HttpRequest对象作为第一个参数传递给视图函数，此外使用regex参数中携带的参数作为可选参数传递给视图函数。如：`url(r'^(?P<article_id>\d+)/$', views.detail, name='detail')`,，括号对`(?P<article_id>\d+)`里面的参数将作为第二个参数传递给视图函数`detail(request, article_id)`，这里参数的名字必须一模一样。因为你在url函数中显示的指定了该参数的名字，当然你也可以不显示的指定，如：`url(r'^(\d+)/$', views.detail, name='detail')`，这样在视图函数里，第二个参数的名称就随便命名了。它根据位置参数的位置来匹配。  

#####name
讲name之前，先说说Django template的内建标签url，`{% url path.to.some_view%}`可以返回视图函数对应的URL（相对域名的绝对路径），比如`url(r^/account/$', views.index, name=index)`，使用`{% url view.index %}`将返回`/accout/`，这样做可以提高模版的灵活性，如果是使用硬编码的方式，模版难以维护。  

使用标签url的时候可能会遇到一个问题就是：对于：  

    urlpatterns = patterns('',
        url(r'^archive/(\d{4})/$', archive, name="full-archive"),
        url(r'^archive-summary/(\d{4})/$', archive, {'summary': True}, "arch-summary"),
    )
同一个视图函数有多个urlconf，此时模版系统想通过视图名`archive`获取URL时，就不知所措了，name参数就是用来解决此问题的。name用来唯一区一个视图对应多个urlconf的场景。通过name来反向获取URL。  
如：

    urlpatterns = patterns('',
        url(r'^archive/(\d{4})/$', archive, name="full-archive"),
        url(r'^archive-summary/(\d{4})/$', archive, {'summary': True}, "arch-summary"),
    )

在模版中可以使用：  

    {% url "arch-summary" 1945 %}
    {% url "full-archive" 2007 %}

#####kwargs
kwargs就是一个字典类型的参数，它的使用方式如：  

        url(r'^archive-summary/(\d{4})/$', archive, {'summary': True}, "arch-summary"),

这里的kwargs 就是 `{'summary': True}`  

视图函数中就是这样使用：  

    def archive(request, archive_id, summary):


注意：  

1. 如果在url.py中有`url(r'^comment/(\d{1,9})/delete/$','delete_comment'),`的配置，如果不存在`delete_comment`这样一个函数视图，如果在模版中使用了`{% url path.to.some_view %}`这个标签，那么抛出 ViewDoesNotExit错误。仔细想想很有道理，如果视图不存在，即使匹配到了URL，当访问这个URL的时候，还是会抛ViewDoesNotExit的异常，这里Django只是在加载解析URLConf的时候就做了检查。
2. 如果在根url.py文件中使用了`url(r'^people/', include('people.urls', namespace='people'))`，这里people是一个app，那么在people这个app中的url.py中`url(r'^(\d{1,9})/$','index', name='index')`必须指定了name=index才能正常使用{% url 'people:index'%}，否则：  

        NoReverseMatch at /
        Reverse for 'subjects' with arguments '()' and keyword arguments '{}' not found

当然如果你确定不是上述问题抛出的此异常，那么可以看下这两个答案：  
http://stackoverflow.com/questions/9649587/reverse-for-with-arguments-and-keyword-arguments-not-found  
http://stackoverflow.com/questions/14882491/django-release-1-5-url-requires-a-non-empty-first-argument-the-syntax-change  
本文参考  
https://docs.djangoproject.com/en/1.1/topics/http/urls/#id2  
https://docs.djangoproject.com/en/1.1/ref/templates/builtins/#std:templatetag-url

####Python 常见异常

+ NameError：访问未申明的变量  
+ ZeroDevisionError：除数为零  
+ SyntaxError：解释器语法错误，该错误不是在运行时发生的  
+ IndexError：索引超出序列范围  
+ KeyError：访问字典中不存在的Key
+ IOError：任何与IO相关的操作  
+ AttributeError：访问对象中不存在的属性
+ ValueError：任何数值操作，如int('zzz')
+ TypeError：期待的类型与实际的类型不一致时，如float(('hello',))，float只能接收字符串或者数字  

+ KeyboardInterupt，SystemExit：人为引发的错误，用户想终止程序运行  

####异常结构图：

    --BaseException
        |- KeyboarInterrupt
        |- SystemExit
        |- Exception
            |-(built-in exception)

####异常写法：

    try:
        #业务代码块
    except Exception1 [,reason]:   #异常原因是可选参数
        #异常处理代码块


    try:
        #业务代码块
    except (Exception1,Exception2) [,reason]:   #异常原因是可选参数，可以接收多个异常
        #异常处理代码块


    try:
        #业务代码块
    except Exception1 [,reason]:   #异常原因是可选参数
        #异常处理代码块
    except Exception2 [,reason]:   #异常原因是可选参数
        #异常处理代码块            #可以分别处理多个异常


    try:
        #业务代码块
    except Exception1 [,reason]:   #异常原因是可选参数
        #异常处理代码块
    else:
        #else字句，没有发生异常时，执行此处的代码
        
    try:
        #业务代码块
    except Exception1 [,reason]:   #异常原因是可选参数
        #异常处理代码块
    else:
        #else字句，没有发生异常时，执行此处的代码
    finally:
        #最终程序都会执行到这里来，无论异常发生与否


Flask之Hello world 详解
========================
以下讲解假设你对python有基本了解,熟悉wsgi,以及了解某种python web framework.  

    from flask import Flask
    app = Flask(__name__)
    
    @app.route('/')
    def hello_world():
        return "HELLO WROLD"
    
    if __name__ == '__main__':
        app.run(debug=True)

1. Flask的实例app就是我们的WSGI application.
2. 创建Flask实例需要指定一个参数,这个参数一般是application的模块名字或者是包名.Flask根据这个参数定位templates,static files等.
3. route装饰器告诉Flask什么样的请求路径对应这个函数

####Routing
route()装饰器支持变量规则,用`<variable_name>`表示.还可以制订一个转换器.例如:  

    @app.route('/user/<username>')
    def show_user_profile(username):
        # show the user profile for that user
        return 'User %s' % username
    
    @app.route('/post/<int:post_id>')
    def show_post(post_id):
        # show the post with the given id, the id is an integer
        return 'Post %d' % post_id

    @app.route('/user/<path:location>')
    def show_path(location):
        return location

有三种转换器:  

    int	    accepts integers
    float	like int but for floating point values
    path	like the default but also accepts slashes

####HTTP METHOD

    from flask import request

    @app.route('/login', methods=['GET', 'POST'])
    def login():
        if request.method == "POST":
            return 'post'
        else:
            return 'get'
    
####Static Files
在package或则module同目录下创建static目录  

    url_for('static', filename='style.css')
####rendering templates
    默认Flask配置JinJia2作为模板引擎,因为他们是一家的.Flask会在templates目录下查找模板文件,如果application是一个module,那么这个templates目录与application同级目录.如果他是一个package:  

* case 1: a module:

    /application.py
    /templates
       /hello.html
* case 2: a application
    
    /application
        /__init__.py
        /templates
            /hello.html

渲染模板使用render_template()  
    
    from flask import render_template
    @app.route('/hello/')
    @app.route('/hello/<name>')
    def hello(name=None):
        return render_template('hello.html',name=name)
JinJia2 模板的语法和Mako以及django的语法都差不多,可以稍作了解  

    <!doctype html>
    <title>Hello from Flask</title>
    {% if name %}
      <h1>Hello {{ name }}!</h1>
    {% else %}
      <h1>Hello World!</h1>
    {% endif %}

####Context locals
先跳过   

####函数式编程语言介绍

* 大部分编程语言都是面向过程了,程序就是一系列指令,这些指令告诉计算机如何操作,如:C,Pascal,shell都是过程语言.  
* 对于声明式语言, 你要编写一系列规范描述该问题如何解决.SQL就是一种声明式语言,一个SQL查询描述数据该如何获取,  
* 面向对象的编程是对对象的操作,对象有内部状态,支持方法对内部状态的修改或者查询,Smalltalk和Java就是典型的面向对象变成语言.C++和Python同样支持面向对象的编程,但是并不强制你使用面向对象的特性  
* 函数式编程分解一个问题成为一系列函数,理想情况下,函数仅仅关注输入和输出,没有任何内部状态,只有输入影响输出.Haskell就是典型的函数式编程语言.  

http://docs.python.org/2/howto/functional.html


函数式编程-----序列处理函数:map(),filter(),reduce()
----------------------------
####map(function, sequence[, ...]) → list  

创建一个新的列表,函数作用于原来列表中的每个元素  

    >>> map( int, [ "10", "12", "14", 3.1415926, 5L ] )
    [10, 12, 14, 3, 5]
这个函数等效下面这个定义:  
    
    def map(function, sequence):
        return [function(v) for v in sequence]
map函数可以接收多个序列,如果是这种情况的话,function必须接收多个参数,参数的个数必须和序列的个数保持一致.如果function=None, 那么返回的列表是有tuple构成的列表  

    >>>map(None, range(3), range(3))
    [(0, 0), (1, 1), (2, 2)]

####filter(function, sequence) → list 
返回列表对象,它的sequence元素中作用在function函数中返回True的元素,如果function是None,那么就是sequence中元素等于True的元素.它的行为定义类似于:  

    def filter( aFunction, aSequence ):
        return [ v for v in aSequence if aFunction(v) ]
例子:  

    >>> import random
    >>> rolls = list( (random.randint(1,6),random.randint(1,6)) for u in range(100) )
    >>> def hardways( pair ):
    ...     d1, d2 = pair
    ...     return d1 == d2 and d1+d2 in ( 4, 6, 8, 10 )
    >>> filter( hardways, rolls )
    [(4, 4), (5, 5), (2, 2), (5, 5), (4, 4), (5, 5), (5, 5), (3, 3), (2, 2), (2, 2), (5, 5), (4, 4)]
    >>> len(_)
    12
####reduce(function, sequence[, initial=0]) → value
function必须接收两个参数, function在内部累加sequence中的每个元素,到最后变成一个单一的value.  

    def reduce( aFunction, aSequence, init= 0 ):
        r= init
        for s in aSequence:
            r= aFunction( r, s )
        return r
例子:  

    >>> def plus( a, b ):
    ...     return a+b
    >>> reduce( plus, [1, 3, 5, 7, 9] )
    25
python的built-in函数中如:sum(),any(),all()都是类似的reduce函数.  

####zip(sequence[, sequence...]) → sequence
zip接收的参数都是序列,他把多个序列便成一个序列,新序列是tuple的集合.如果其中一个序列太长那就就会被截取.  
例子:  

    >>> zip( range(5), range(1,12,2) )
    [(0, 1), (1, 3), (2, 5), (3, 7), (4, 9)]
这个例子中,前面序列range(5)的长度是5, 后面序列的长度是6,最终长的序列会被截取掉.  当map的地一个参数function是None时,其功能与zip类似,但是map不是截取,而是对较短的序列用None填充.  

    >>> map(None, range(5), range(1,12,2))
    [(0, 1), (1, 3), (2, 5), (3, 7), (4, 9), (None, 11)]

http://www.itmaybeahack.com/book/python-2.6/html/p02/p02c10_adv_seq.html


yield：生成器
----------------
任何使用yield的函数都称之为生成器，如：  

    def count(n):
        while n > 0:
            yield n   #生成值：n
            n -= 1
另外一种说法：生成器就是一个返回迭代器的函数，与普通函数的区别是生成器包含yield语句，更简单点理解生成器就是一个迭代器。   

使用yield，可以让函数生成一个序列，该函数返回的对象类型是"generator"，通过该对象连续调用next()方法返回序列值。  

    c = count(5)
    c.next()
    >>> 5
    c.next()
    >>>4

生成器函数只有在调用next()方法的时候才开始执行函数里面的语句，比如：  

    def count(n):
        print "cunting"
        while n > 0:
            yield n   #生成值：n
            n -= 1

在调用count函数时：c=count(5)，并不会打印"counting"只有等到调用c.next()时才真正执行里面的语句。每次调用next()方法时，count函数会运行到语句` yield n`处为止，next()的返回值就是生成值`n`，再次调用next()方法时，函数继续执行yield之后的语句（熟悉Java的朋友肯定知道Thread.yield()方法，作用是暂停当前线程的运行，让其他线程执行），如：

    def count(n):
        print "cunting"
        while n > 0:
            print 'before yield'
            yield n   #生成值：n
            n -= 1
            print 'after yield'
上述代码在第一次调用next方法时，并不会打印"after yield"。如果一直调用next方法，当执行到没有可迭代的值后，程序就会报错：  
>>> Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  StopIteration

所以一般不会手动的调用next方法，而使用for循环：  

    for i in count(5):
        print i,


实例：  用yield生成器模拟Linux中命令：`tail -f | grep python` 用于查找监控日志文件中出现有python字样的行。  

    import time
    def tail(f):
        f.seek(0,2)#移动到文件EOF，参考：[seek](http://docs.python.org/2/library/stdtypes.html?highlight=file#file.seek)
        while True:
            line = f.readline()  #读取文件中新的文本行
            if not line:
                time.sleep(0.1)
                continue
            yield line
    
    def grep(lines,searchtext):
        for line in lines:
            if searchtext in line:
                yield line


调用：  

    flog = tail(open('warn.log'))
    pylines = grep(flog,'python')
    for line in pylines:
        print line,

用yield实现斐波那契数列：  

    def fibonacci():
        a=b=1
        yield a
        yield b
        while True:
            a,b = b,a+b
            yield b

调用：  

    for num in fibonacci():
        if num > 100:
            break
        print num,

yield中return的作用：  
作为生成器，因为每次迭代就会返回一个值，所以不能显示的在生成器函数中return 某个值，包括None值也不行，否则会抛出“SyntaxError”的异常，但是在函数中可以出现单独的return，表示结束该语句。  
通过固定长度的缓冲区不断读文件，防止一次性读取出现内存溢出的例子：  

    def read_file(path):
        size = 1024
        with open(path,'r') as f:
            while True:
                block = f.read(SIZE)
                if block:
                    yield block
                else:
                    return

如果是在函数中return 具体某个值，就直接抛异常了  

    >>> def test_return():
    ...      yield 4
    ...      return 0
    ...
      File "<stdin>", line 3
    SyntaxError: 'return' with argument inside generator


与yield有关的一个很重要的概念叫**协程**，下次好好研究研究。  

参考：  
http://www.cnblogs.com/huxi/archive/2011/07/14/2106863.html  
http://www.ibm.com/developerworks/cn/opensource/os-cn-python-yield/  
《Python 参考手册》  


####介绍
gevent 是一个python网络框架,对应Java的netty框架,使用greenlet提供异步API,基于libevent ,它为各种并发和网络相关的任务提供了整洁的API.   

快速基于libevent的[event loop](http://www.ruanyifeng.com/blog/2013/10/event_loop.html)  
基于greenlet的轻量级执行单元  
重用python标准api(event,queue)  
协同的socket和ssl模块  
使用标准库和第三方模块写标准阻塞socket(gevent.monkey)  
dns查询执行通过libevent-dns  
基于libevent-http的快速WSGI服务器  
####安装
>=python2.4  
greenlet  
libevent1.4.x  

    from gevent import socket
说不能导入socket,参考http://stackoverflow.com/questions/6431096/gevent-does-not-install-properly-on-ubuntu
####例子

    import gevent
    from gevent import socket
    urls = ['www.google.com','www.python.org','www.foofish.net']
    jobs = [gevent.spawn(socket.gethostbyname, url) for url in urls]
    gevent.joinall(jobs, timeout=2)
    print [job.value for job in jobs]
['74.125.128.147', '82.94.164.162', '106.186.27.60']

gevent.socket与python标准库的socket有相同的接口


http://sdiehl.github.io/gevent-tutorial/  
http://architects.dzone.com/articles/threads-versus-greenlets  
http://blog.pythonisito.com/2012/07/introduction-to-gevent.html  

###翻译
####Gevent简介
官方网站是这么介绍Gevent:  
>gevent is a coroutine-based Python networking library that uses greenlet to provide a high-level synchronous API on top of the libevent event loop.  

简单翻译过来就是：[gevent](http://www.gevent.org/)一个基于协程的Python网络库，依赖于[libevent](http://www.libevent.org/)的[event loop](http://www.ruanyifeng.com/blog/2013/10/event_loop.html)使用greenlet提供高级同步API。

这段话简单描述了gevent的架构实现和技术，不过初学者看了还是一脸茫然。我能想到的能最快让人理解的定义是:  
>gevent给了你线程,但是没有使用线程  

####为什么不使用线程
为什么不使用线程呢？线程最大的缺点对我来说就是相比较greenlets(使用在gevent中的类线程的抽象概念)来说它会占用大量资源。 例如：这个模拟helloworld webserver的小程序，下面是没有使用任何并发的代码：  
 
    import sys
    import socket
    import time
    
    def sequential(port):
        s = socket.socket()
        s.bind(('0.0.0.0', port))
        s.listen(500)
    
        while True:
            cli, addr = s.accept()
            handle_request(cli, time.sleep)
    
    def handle_request(s, sleep):
        try:
            s.recv(1024)
            sleep(0.1)
            s.send('''HTTP/1.0 200 Ok 
    
    HelloWorld''')
            s.shutdown(socket.SHUT_WR)
            print '.',
        except Exception, ex:
            print 'e', ex,
        finally:
            sys.stdout.flush()
            s.close()
    
    if __name__ == '__main__':
        sequential(int(sys.argv[1]))

这段代码使用sleep，目的是是减慢handle_request方法使它更真实。使用Apache的性能测试工具做大并发测试，然而我们得到很糟糕的结果。运行： `ab -r -n 200 -c 200 http://lcoalhost:1111/`  

结果:

    Benchmarking localhost (be patient)
    Completed 100 requests
    apr_pollset_poll: The timeout specified has expired (70007)
    Total of 196 requests Completed
到最后超时了。

也许用线程会更好，那么用threads函数替换sequential函数：

    import threading
    
    def thread(port):
        s = socket.socket()
        s.bind(('0.0.0.0', port))
        s.listen(500)
        while True:
            cli, addr = s.accept()
            t = threading.Thread(target=handle_request, args=(cli, time.sleep))
            t.daemon = True
            t.start()
结果:  

    Benchmarking localhost (be patient)
    Completed 100 requests
    Completed 200 requests
    Finished 200 requests
    
    
    Server Software:        
    Server Hostname:        localhost
    Server Port:            1115
    
    Document Path:          /
    Document Length:        10 bytes
    
    Concurrency Level:      200
    Time taken for tests:   0.229 seconds
    Complete requests:      200
    Failed requests:        0
    Write errors:           0
    Total transferred:      5600 bytes
    HTML transferred:       2000 bytes
    Requests per second:    874.02 [#/sec] (mean)
    Time per request:       228.827 [ms] (mean)
    Time per request:       1.144 [ms] (mean, across all concurrent requests)
    Transfer rate:          23.90 [Kbytes/sec] received
    
    Connection Times (ms)
                  min  mean[+/-sd] median   max
    Connect:        0    5   2.9      5      11
    Processing:   101  107   3.8    107     116
    Waiting:      101  107   3.9    106     115
    Total:        105  112   1.5    112     116
    
    Percentage of the requests served within a certain time (ms)
      50%    112
      66%    113
      75%    113
      80%    114
      90%    114
      95%    115
      98%    115
      99%    116
     100%    116 (longest request)

运行`ab -r -n 200 -c 200`，总共花时是0.229秒，现在我们用gevent做类线程的模拟操作:  

    import gevent
    def greenlet(port):
        from gevent import socket
        s = socket.socket()
        s.bind(('0.0.0.0', port))
        s.listen(500)
        while True:
            cli, addr = s.accept()
            gevent.spawn(handle_request, cli, gevent.sleep)    
结果:  

    Benchmarking localhost (be patient)
    Completed 100 requests
    Completed 200 requests
    Finished 200 requests
    
    
    Server Software:        
    Server Hostname:        localhost
    Server Port:            1115
    
    Document Path:          /
    Document Length:        0 bytes
    
    Concurrency Level:      200
    Time taken for tests:   0.012 seconds
    Complete requests:      200
    Failed requests:        597
       (Connect: 0, Receive: 398, Length: 0, Exceptions: 199)
    Write errors:           0
    Total transferred:      0 bytes
    HTML transferred:       0 bytes
    Requests per second:    16837.85 [#/sec] (mean)
    Time per request:       11.878 [ms] (mean)
    Time per request:       0.059 [ms] (mean, across all concurrent requests)
    Transfer rate:          0.00 [Kbytes/sec] received
    
    Connection Times (ms)
                  min  mean[+/-sd] median   max
    Connect:        0    0   0.0      0       0
    Processing:     0    2   2.2      4       5
    Waiting:        0    0   0.0      0       0
    Total:          0    2   2.2      4       5
    
    Percentage of the requests served within a certain time (ms)
      50%      4
      66%      4
      75%      4
      80%      4
      90%      5
      95%      5
      98%      5
      99%      5
     100%      5 (longest request)

我们看到总共花时不到0.012秒。

####为什么不要一直使用gevent/greenlets呢？
为什么不要一直在gevent中greenlet？主要Greenlets使用协助式多任务，而线程使用抢占式多任务，意味着一个greenlet永远不会停止执行来让给另外的greenlet执行，除非它使用确切的'yielding'函数(像:gevent.socket.socket.recv或gevent.sleep)，而线程完全是基于操作系统决定线程之间的切换的。   

如果你使用python一段时间了，你应该听说过关于全局解释锁(GIL)，它只允许在同一时刻单个线程执行python字节码。所以尽管在python中有线程和并发，但是线程所提供的好处不及C或者Java。  

####Gevent中还有些啥
希望在学习gevent时我能给你一些兴趣，gevent中还包括：  
* 提供monkey_patch标准库，所以你可以使用socket.socket而不需要gevent.socket  
* 用自己的handlers处理基于socket连接的server。  
* 在greenlet中更细粒度的控制spawn.  
* greenlet pools  
* greenlet-local对象  
* 两个基于greentlet的WSGI服务器  


并发编程模型主要有:  多进程,多线程,事件驱动, 协程. gevent 是基于协程的异步框架,它需要依赖于greenlet.gevent有什么样的优势? 先来通过一个简单的例子对比同步执行一个方法和使用gevent的异步方式.

普通的单线程同步执行任务

    import time

    def sync_task():
        #do something
        time.sleep(1)

    def sync_run():
        start = time.time()
        for i in range(10):
            sync_task()
        end = time.time()
    
    print("sync task executed in %f second"%(end-start))

打印结果: async task executed in 10.012671 second

如果换成多线程会是什么情况呢?  

    import threading

    def multi_thread_run():
        start = time.time()
        for i in range(10):
            t = threading.Thread(target=sync_task)
            t.start()
        end = time.time()
        print("multi thread task executed in %f second"%(end-start))

打印结果是:multi thread task executed in 0.002425 second, 呵呵,这个时间简直亮瞎了, 其实这段程序有问题,子线程还没执行完时,主线程就结束了,因此时间才那么短,其实要稍稍修改:  

    def multi_thread_run():
        start = time.time()
        threads = []
        for i in range(300):
            t = threading.Thread(target=sync_task)
            threads.append(t)
            t.start()
    
        for t in threads:
            t.join()
    
        end = time.time()
        print("multi thread task executed in %f second"%(end-start))
等所有子线程执行完之后再执行主线程,看看打印结果:  

    multi thread task executed in 1.002796 second
这是一个比较正常的结果.

换成gevent后会怎样呢?  

    import gevent
    def async_task():
        #do something
        gevent.sleep(1)
    
    def async_run():
        start = time.time()
        coroutins = []
    
        for i in range(10):
            coroutins.append(gevent.spawn(async_task))
        gevent.joinall(coroutins)
    
        end = time.time()
        print("async task executed in %f second"%(end-start))
打印输出:async task executed in 1.002012 second
gevent.spawn()方法会创建一个协程实例,gevent.joinall()是使所有的线程执行完了之后在运行主线程,这跟多线程编程是同样的概念. 发现gevent比多线程也没快多少,那gevent究竟有什么优势.现在假设把上面的10替换成1000,也就是1000线程与1000个coroutine之间的比较,会出现什么结果呢?如果是用线程的话直接报错了:`thread.error: can't start new thread`.而用协程就不会出现这种问题.  

coroutine相比thread的优势在于:  

* 创建threade的成本高,而创建coroutine的成本很低  
* thread的上下文切换成本高,而coroutin的切换速度很快  
* thread的上下文切换取决于cpu,而coroutine由自己控制  

先介绍到这里,下次接着聊  

参考[淺談coroutine與gevent](http://blog.ez2learn.com/2010/07/17/talk-about-coroutine-and-gevent/)

WSGI规范定义request/response循环,每次请求到达,调用一次应用中的callable,返回 zhuti 主体iterator.接着服务器遍历主体,分块写入socket.遍历完整个主体,就关闭客户端的连接.  这个流程是线程同步的,如果遇到等待数据(IO/socket/数据库),那么该线程就只能阻塞,而每个线程只能处理一个请求,但是服务器的线程池中的线程总数是有限的,如果请求数量一多的话,用户只能处于当代状态.性能很差劲.


而greenlet类似于传统线程,创建时只需消耗很少的资源.这样服务器可以生成无数greenlet而无需担心其资源会耗尽,为每个连接分配一个greenlet也毫无压力.让他们不阻塞当前线程,将cpu让给下一个greenlet.实际上是用基于gevent的伪线程替换了python的线程.

gevent.monkey.patch_all()的作用是将常见的阻塞如:socket, select等阻塞的地方使用协程跳转,而不是在那一直等待,

    gevent.joinall([
        gevent.spawn(task1),
        gevent.spawn(task2),
    ])


gevent.socket
gevent.sleep

迭代器(Iterator)与生成器(Generator)的区别
=========================
迭代器是一个更抽象的概念，任何对象，如果它的类有next方法（__next__ python3)和__iter__方法返回自己本身。  

每个生成器都是一个迭代器，但是反过来不行。通常生成器是通过调用一个或多个yield表达式构成的函数s生成的。同时满足迭代器的定义。  

当你需要一个类除了有生成器的特性之外还要有一些自定义的方法时，可以使用自定义的迭代器，一般来说生成器更方便，更简单。  

    def squares(start, stop):
        for i in xrange(start, stop):
            yield i*i
等同于生成器表达式：  

    （i*i for i in xrange(start, stop))
列表推倒式是：  
    
    [i*i for i in xrange(start, stop)]

如果是构建一个自定义的迭代器：  

    class Squares(object):
        def __init__(self, start, stop):
            self.start = start
            self.stop = stop
        def __iter__(self):
            return self
        def next(self):
            if self.start >= self.stop:
                raise StopIteration
            current = self.start * self.start
            self.start += 1
            return current
此时，你还可以定义自己的方法如：  

    def current(self):
        return self.start

两者的相同点：对象迭代完后就不能重写迭代了。  

Iterables, Iterators, Genrators
==============================
热身一下
--------------
如果你是来自其它语言比如c，很自然想到的方式是创建一个计数器，然后以自增的方式迭代list。  

    my_list = [17  23  47  51  101  173  999  1001]
    
    i = 0
    while i < len(my_list):
        v = my_list[i]
        print v,
        i += 1
输出：  

    17 23 47 51 101 173 999 1001

也有可能会借用range，写一个类C语言的风格的for循环：  

    for i in range(len(my_list)):
        v = my_list[i]
        print v,
输出：  

    17 23 47 51 101 173 999 1001

上面两种方法都不是Pythonic方式，取而代之的是：  

    for v in my_list:
        print v,
输出：   

    17 23 47 51 101 173 999 1001

很多类型的对象都能通过这种方式来迭代，迭代字符串会生成单个字符：  

    for v in "Hello":
        print v,
输出：  

    H e l l o
迭代字典，生成字典的key（以无序的方式）：  

    d = {
        'a': 1,
        'b': 2,
        'c': 3,
        }
    
    for v in d:
        print v,
    # 注意这里是无序的

输出：  

    a c b

迭代文件对象，产生字符串行，包括换行符：  

    f = open("suzuki.txt")
    for line in f:
        print ">", line
输出：  

    > On education
    
    > "Education has failed in a very serious way to convey the most important lesson science can teach: skepticism."
    
    > "An educational system isn't worth a great deal if it teaches young people how to make a living but doesn't teach them how to make a life."

以上可以看出列表、元祖、字符串、字典、文件都可以迭代，能被迭代的对象都称为可迭代对象（Iteratbles)，for循环不是唯一接收Iteratbles的东东，还有：  

list构造器接收任何类型的Iteratbles，可以使用list()接收字典对象返回只有key的列表：  

    list(d)
输出：  

    ['a', 'c', 'b']
还可以：  

    list("Hello")
输出：  

    ['H', 'e', 'l', 'l', 'o']

还可以用在列表推倒式中：  

    ascii = [ord(x) for x in "Hello"]
    ascii
输出：  
    
    [72, 101, 108, 108, 111]

sum()函数接收任何数字类型的可迭代对象:  

    sum(ascii)

输出：  
    
    500

str.join()方法接收任何字符类型的可迭代对象 （这里的说法不严谨，总之原则是迭代的元素必须是str类型的)：  

    "-".join(d)
输出：  

    ‘a-c-b'






 http://stackoverflow.com/questions/2776829/difference-between-python-generators-vs-iterators
http://excess.org/article/2013/02/itergen1/

Python处理JSON
==================
####概念  
**序列化（Serialization）**：将对象的状态信息转换为可以存储或可以通过网络传输的过程，传输的格式可以是JSON、XML等。反序列化就是从存储区域（JSON，XML）读取反序列化对象的状态，重新创建该对象。   

**JSON（JavaScript Object Notation）**：一种轻量级数据交换格式，相对于XML而言更简单，也易于阅读和编写，机器也方便解析和生成，Json是JavaScript中的一个子集。  

Python2.6开始加入了JSON模块，无需另外下载，Python的Json模块序列化与反序列化的过程分别是 **encoding**和 **decoding**  

**encoding**：把一个Python对象编码转换成Json字符串  
**decoding**：把Json格式字符串解码转换成Python对象  
对于简单数据类型（string、unicode、int、float、list、tuple、dict），可以直接处理。  

#####json.dumps方法对简单数据类型encoding：  

    import json
    data = [{'a':"A",'b':(2,4),'c':3.0}]  #list对象
    print "DATA:",repr(data)
    
    data_string = json.dumps(data)
    print "JSON:",data_string

输出：  

    DATA: [{'a':'A','c':3.0,'b':(2,4)}] #python的dict类型的数据是没有顺序存储的
    JSON: [{"a":"A","c":3.0,"b":[2,4]}]  

JSON的输出结果与DATA很相似，除了一些微妙的变化，如python的元组类型变成了Json的数组，Python到Json的编码转换规则是：
![python2json](../resource/image/python2json.png)

#####json.loads方法处理简单数据类型的decoding（解码）转换  

    import json
    data = [{'a':"A",'b':(2,4),'c':3.0}]  #list对象
    
    data_string = json.dumps(data)
    print "ENCODED:",data_string

    decoded = json.loads(data_string)
    print "DECODED:",decoded

    print "ORIGINAL:",type(data[0]['b'])
    print "DECODED:",type(decoded[0]['b'])

输出:  

    ENCODED: [{"a": "A", "c": 3.0, "b": [2, 4]}]
    DECODED: [{u'a': u'A', u'c': 3.0, u'b': [2, 4]}]
    ORIGINAL: <type 'tuple'>
    DECODED: <type 'list'>

解码过程中，json的数组最终转换成了python的list，而不是最初的tuple类型，Json到Python的解码规则是：
![json2python](../resource/image/json2python.png)  

####json的人文关怀  
编码后的json格式字符串紧凑的输出，而且也没有顺序，因此`dumps`方法提供了一些可选的参数，让输出的格式提高可读性，如`sort_keys`是告诉编码器按照字典排序(a到z)输出。  

    import json
    
    data = [ { 'a':'A', 'b':(2, 4), 'c':3.0 } ]
    print 'DATA:', repr(data)
    
    unsorted = json.dumps(data)
    print 'JSON:', json.dumps(data)
    print 'SORT:', json.dumps(data, sort_keys=True)

输出:  

    DATA: [{'a': 'A', 'c': 3.0, 'b': (2, 4)}]
    JSON: [{"a": "A", "c": 3.0, "b": [2, 4]}]
    SORT: [{"a": "A", "b": [2, 4], "c": 3.0}

`indent`参数根据数据格式缩进显示，读起来更加清晰: 

    import json
    
    data = [ { 'a':'A', 'b':(2, 4), 'c':3.0 } ]
    print 'DATA:', repr(data)
    
    print 'NORMAL:', json.dumps(data, sort_keys=True)
    print 'INDENT:', json.dumps(data, sort_keys=True, indent=2)

输出:  

    DATA: [{'a': 'A', 'c': 3.0, 'b': (2, 4)}]
    NORMAL: [{"a": "A", "b": [2, 4], "c": 3.0}]
    INDENT: [
      {
        "a": "A",
        "b": [
          2,
          4
        ],
        "c": 3.0
      }
    ]

`separators`参数的作用是去掉`,`,`:`后面的空格，从上面的输出结果都能看到", :"后面都有个空格，这都是为了美化输出结果的作用，但是在我们传输数据的过程中，越精简越好，冗余的东西全部去掉，因此就可以加上separators参数：  

    import json
    
    data = [ { 'a':'A', 'b':(2, 4), 'c':3.0 } ]
    print 'DATA:', repr(data)
    print 'repr(data)             :', len(repr(data))
    print 'dumps(data)            :', len(json.dumps(data))
    print 'dumps(data, indent=2)  :', len(json.dumps(data, indent=2))
    print 'dumps(data, separators):', len(json.dumps(data, separators=(',',':')))


输出：  

    DATA: [{'a': 'A', 'c': 3.0, 'b': (2, 4)}]
    repr(data)             : 35
    dumps(data)            : 35
    dumps(data, indent=2)  : 76
    dumps(data, separators): 29


`skipkeys`参数，在encoding过程中，dict对象的key只可以是string对象，如果是其他类型，那么在编码过程中就会抛出`ValueError`的异常。`skipkeys`可以跳过那些非string对象当作key的处理.

    import json
    
    data= [ { 'a':'A', 'b':(2, 4), 'c':3.0, ('d',):'D tuple' } ]
    
    try:
        print json.dumps(data)
    except (TypeError, ValueError) as err:
        print 'ERROR:', err
    print 
    print json.dumps(data, skipkeys=True)

输出:  
    
    ERROR: keys must be a string
    
    [{"a": "A", "c": 3.0, "b": [2, 4]}]



####让json支持自定义数据类型  
以上例子都是基于python的built-in类型的，对于自定义类型的数据结构，json模块默认是没法处理的，会抛出异常：`TypeError  xx is not JSON serializable`，此时你需要自定义一个转换函数:  

    import json  

    class MyObj(object):
        def __init__(self, s):
            self.s = s
        def __repr__(self):
            return '<MyObj(%s)>' % self.s

    obj = .MyObj('helloworld')
    
    try:
        print json.dumps(obj)
    except TypeError, err:
        print 'ERROR:', err
    
    #转换函数
    def convert_to_builtin_type(obj):
        print 'default(', repr(obj), ')'
        # 把MyObj对象转换成dict类型的对象
        d = { '__class__':obj.__class__.__name__, 
              '__module__':obj.__module__,
            }
        d.update(obj.__dict__)
        return d
    
    print json.dumps(obj, default=convert_to_builtin_type)

输出:  

    ERROR: <MyObj(helloworld)> is not JSON serializable
    default( <MyObj(helloworld)> )
    {"s": "hellworld", "__module__": "MyObj", "__class__": "__main__"} 
    #注意：这里的class和module根据你代码的所在文件位置不同而不同


相反，如果要把json decode 成python对象，同样也需要自定转换函数，传递给json.loads方法的`object_hook`参数：  

    #jsontest.py

    import json
    
    class MyObj(object):
    
        def __init__(self,s):
            self.s = s
    
        def __repr__(self):
    
            return "<MyObj(%s)>" % self.s
    
    def dict_to_object(d):
        if '__class__' in d:
            class_name = d.pop('__class__')
            module_name = d.pop('__module__')
            module = __import__(module_name)
    
            print "MODULE:",module
    
            class_ = getattr(module,class_name)
    
            print "CLASS",class_
    
            args = dict((key.encode('ascii'),value) for key,value in d.items())
    
            print 'INSTANCE ARGS:',args
    
            inst = class_(**args)
        else:
            inst = d
        return inst
    
    encoded_object = '[{"s":"helloworld","__module__":"jsontest","__class__":"MyObj"}]'
    
    myobj_instance = json.loads(encoded_object,object_hook=dict_to_object)
    print myobj_instance
    
输出：  

    MODULE: <module 'jsontest' from 'E:\Users\liuzhijun\workspace\python\jsontest.py'>
    CLASS <class 'jsontest.MyObj'>
    INSTANCE ARGS: {'s': u'helloworld'}
    [<MyObj(helloworld)>]
    MODULE: <module 'jsontest' from 'E:\Users\liuzhijun\workspace\python\jsontest.py'>
    CLASS <class 'jsontest.MyObj'>
    INSTANCE ARGS: {'s': u'helloworld'}
    [<MyObj(helloworld)>]


####使用Encoder与Decoder类实现json编码的转换  

**JSONEncoder**有一个迭代接口`iterencode(data)`，返回一系列编码的数据，他的好处是可以方便的把逐个数据写到文件或网络流中，而不需要一次性就把数据读入内存.  

    import json
    
    encoder = json.JSONEncoder()
    data = [ { 'a':'A', 'b':(2, 4), 'c':3.0 } ]
    
    for part in encoder.iterencode(data):
        print 'PART:', part

输出：  

    PART: [
    PART: {
    PART: "a"
    PART: :
    PART: "A"
    PART: ,
    PART: "c"
    PART: :
    PART: 3.0
    PART: ,
    PART: "b"
    PART: :
    PART: [2
    PART: , 4
    PART: ]
    PART: }
    PART: ]


`encode`方法等价于`''.join(encoder.iterencode()`，而且预先会做些错误检查（比如非字符串作为dict的key），对于自定义的对象，我们只需从些JSONEncoder的`default()`方法，其实现方式与上面提及的函数`convet_to_builtin_type()`是类似的。  


    import json
    import json_myobj

    class MyObj(object):

        def __init__(self,s):
            self.s = s

        def __repr__(self):
            return "<MyObj(%s)>" % self.s
    
    class MyEncoder(json.JSONEncoder):
        
        def default(self, obj):
            print 'default(', repr(obj), ')'
            # Convert objects to a dictionary of their representation
            d = { '__class__':obj.__class__.__name__, 
                  '__module__':obj.__module__,
                  }
            d.update(obj.__dict__)
            return d
    
    obj = json_myobj.MyObj('helloworld')
    print obj
    print MyEncoder().encode(obj)

输出：  

    <MyObj(internal data)>
    default( <MyObj(internal data)> )
    {"s": "helloworld", "__module__": "Myobj", "__class__": "MyObj"}

从json对Python对象的转换:

    class MyDecoder(json.JSONDecoder):
        
        def __init__(self):
            json.JSONDecoder.__init__(self, object_hook=self.dict_to_object)
    
        def dict_to_object(self, d):
            if '__class__' in d:
                class_name = d.pop('__class__')
                module_name = d.pop('__module__')
                module = __import__(module_name)
                print 'MODULE:', module
                class_ = getattr(module, class_name)
                print 'CLASS:', class_
                args = dict( (key.encode('ascii'), value) for key, value in d.items())
                print 'INSTANCE ARGS:', args
                inst = class_(**args)
            else:
                inst = d
            return inst
    
    encoded_object = '[{"s": "helloworld", "__module__": "jsontest", "__class__": "MyObj"}]'
    
    myobj_instance = MyDecoder().decode(encoded_object)
    print myobj_instance

输出:

    MODULE: <module 'jsontest' from 'E:\Users\liuzhijun\workspace\python\jsontest.py'>
    CLASS: <class 'jsontest.MyObj'>
    INSTANCE ARGS: {'s': u'helloworld'}
    [<MyObj(helloworld)>]


####json格式字符串写入到文件流中  
上面的例子都是在内存中操作的，如果对于大数据，把他编码到一个类文件(file-like)中更合适，`load()`和`dump()`方法就可以实现这样的功能。

    import json
    import tempfile
    
    data = [ { 'a':'A', 'b':(2, 4), 'c':3.0 } ]
    
    f = tempfile.NamedTemporaryFile(mode='w+')
    json.dump(data, f)
    f.flush()
    
    print open(f.name, 'r').read()
    

输出：

    [{"a": "A", "c": 3.0, "b": [2, 4]}]

类似的：      

    import json
    import tempfile
    
    f = tempfile.NamedTemporaryFile(mode='w+')
    f.write('[{"a": "A", "c": 3.0, "b": [2, 4]}]')
    f.flush()
    f.seek(0)
    
    print json.load(f)

输出：  

    [{u'a': u'A', u'c': 3.0, u'b': [2, 4]}]


参考：  
http://docs.python.org/2/library/json.html  
http://www.cnblogs.com/coser/archive/2011/12/14/2287739.html  
http://pymotw.com/2/json/  










Mako 模板语言
-------------------
**Mako的哲学:Python is great scripting language ,don't reinvent the wheel, your template can handle it !**, api非常简单,
####入门
Template类是创建模板和渲染模板的核心类  

    from mako.template import Template
    mytemplate = Template("hello world")
    print mytemplate.render()

Template方法的参数会编译成一个Python模块来处理.这个模块包含一个函数`render_body()`,模块的输出结果就是这个方法返回的.下面就是"hello ${name}"编译后的module.

    # -*- encoding:ascii -*-
    from mako import runtime, filters, cache
    UNDEFINED = runtime.UNDEFINED
    __M_dict_builtin = dict
    __M_locals_builtin = locals
    _magic_number = 8
    _modified_time = 1385541516.897274
    _enable_loop = True
    _template_filename = 'hello.txt'
    _template_uri = 'hello.txt'
    _source_encoding = 'ascii'
    _exports = []
    
    
    def render_body(context,**pageargs):
        __M_caller = context.caller_stack._push_frame()
        try:
            __M_locals = __M_dict_builtin(pageargs=pageargs)
            name = context.get('name', UNDEFINED)
            __M_writer = context.writer()
            # SOURCE LINE 1
            __M_writer(u'hello ')
            __M_writer(unicode(name))
            __M_writer(u'\n')
            return ''
        finally:
            context.caller_stack._pop_frame()



调用render()方法时,mako会创建一个Context对象,context对象存储了模板中的变量名.此外还存储了一个缓冲buffer,用于捕获输出结果.如果你要自定义一个Context,那么就要调用render_context()方法渲染模板.  

    from mako.template import Template
    from mako.runtime import Context
    from StringIO import StringIO
    
    mytemplate = Template("hello, ${name}")
    buf = StringIO()
    ctx = Context(buf, name='jack')
    mytemplate.render_context(ctx)
    print buf.getvalue()

Template也可以加载文件模板,使用关键字参数`filename`  

    from mako.template import Template
    mytemplate = Template(filename='/docs/mytmpel.mako')
    print mytemplate.render()

为了提高性能,你还以添加参数module_directory='/tmp/moudle',指定生成的模块持久存储在文件系统中.  

    from mako.template import Template
    
    mytemplate = Template(filename='/docs/mytmpl.txt', module_directory='/tmp/mako_modules')
    print mytemplate.render()

####语法
mako模板可以从xml,html,email等任何类型的字符流文件.模板文件可以包含mako指定的指令,如:变量,表达式,控制结构体(条件控制/循环控制),服务端注释,python代码,还有各种标签.所有这些最终都会编译成python代码,  
#####表达式替换
最简单的表达式就是变量替换,语法是`${}`  

    this is x:${x}

#####表达式转义
mako拥有内建的转义机制,有针对html,url和xml的转义还有trim函数,这些转义符号可以用`|`操作符追加在替换表达式后面  

    ${"this is some text" | u}
输出 `this+is+some+text`,`u`代表url转义,而`h`代表html转义,`x`代表xml转义,`trim`代表trim函数,用于去掉字符串两边的空格,`n`表示不对html转义    

#####控制结构
控制结构的语法都是以`%<name>`开头,以`%end<name>`结尾
**if**  

    % if x==5:
        this is some output
    % endif
**for**  

    % for a in ['one', 'two', 'three', 'four', 'five']:
        % if a[0] == 't':
        its two or three
        % elif a[0] == 'f':
        four/five
        % else:
        one
        % endif
    % endfor
在for循环中有个`loop`上下文,它提供了很多额外的信息,比如:  

    <ul>
    % for a in ("one", "two", "three"):
        <li>Item ${loop.index}: ${a}</li>
    % endfor
    </ul>
loop.index显示当前的迭代的索引位置,index的起始为0  

#####注释
单行注释: mako 以两个`#`作为注释  

    ## this is a comment.
多行注释:  

    <%doc>
        these are comments
        more comments
    </%doc>
#####换行符
mako 和python 一样一反斜缸`\\`做为换行符     

    more and more people \
    go home 
    等价于:
    more and more people go home

#####python代码块
mako中嵌入python代码块时,使用标签`<%`和`%>`  

    <% 
    ##这里就是python代码块
    x = 10000
    y = x
    %>
    
    y = ${y}
这里的python代码块是位于模板中的渲染函数中的,如果是模块级别的代码,比如,函数,那就要用下面这个:  

#####模块级别代码快
模块级代码块用`<!%`和 `%>` 就多一个感叹号   

    <%!
        import mylib
        import re
    
        def filter(text):
            return re.sub(r'^@', '', text)
    %>
这里的filter函数就是与渲染函数是平级的了.模块级代码块可以存在mako中的任何位置,可以出现任意次数,最终渲染会按照声明的顺序合并在一块.  

####标签
mako提供了很多标签,如:include, def ,page等等,她的写法是:`<%name>`开头,结尾是`/>`或者`</%name>`,比如:  

    <%include file="foo.txt"/>
    <%def name="foo" buffered="True">
        this is a def
    </%def>

标签都有属性,有些属性是必须的,同时属性还支持赋值,所以你也可以使用表达式给属性赋值. 如:  

    <%include file="/foo/bar/${myfile}.txt"/>

#####<%include>
在mako文件中可以用include标签包含另外一个文件进来,比如所有页面都应该有header.html和footer.html,就可以把这两部分提取出来.  

    <%include file="header.html"/>
    
        hello world
    
    <%include file="footer.html"/>

`include`标签还有一个`args`的参数,用来传递值给被包含的文件中去.它与标签`<%page`相对应.  

    <%include file="toolbar.html" args="current_section='members', username='ed'"/>
#####<%page>

    <%page args="x, y, z='default'"/>
    <%page cached="True" cache_type="memory"/> 
目前,在一个模板中只能存在一个page标签,其他的会被忽略.且page标签不能放在其他标签里面,如放在block标签里面的,就读不到args设定的值.  
#####<%def>
def标签定义了一个python函数,它包含一些内容,可以在其他地方调用.  

    <%def name="myfunc(x)">
        this is myfunc, x is ${x}
    </%def>
    
    ${myfunc(19)}
#####<%block>
block 可以对这块区域代码执行制定的操作,比如:  

    <%block filter="h">
        some <html> stuff.
    </%block>
对文本`some <html> stuff`执行过滤操作.,block可以没有名字, 更常用的一种方式是用在继承上,比如定义个base.html:  

    ##base.html
    <html>
        <body>
        <%block name="header">
            <h2><%block name="title"/></h2>
        </%block>
        ${self.body()}
        </body>
    </html>

然后你就可以在其它页面继承base.html,block区别可以被继承者覆盖掉 如:  

    ## index.html
    <%inherit file="base.html"/>
    
    <%block name="header">
        this is some header content
    </%block>







模块是用来组织Python代码的，包是用来组织模块的。

把其他模块中属性附加到你的模块中的操作叫做导入（import）

那些自我包含并且有组织的代码片段叫模块（module）

文件是物理层组织模块的方法，一个文件被看作是一个独立模块，一个模块也可以被看作是一个文件。模块的文件文就是模块的名字加上扩展.py。  



wsgi:web服务器和应用程序app之间统一的接口，简单来说就是规范的接收web请求（request）


python paste 是一个WSGI工具包，在wsgi的基础上包装了几层。

    def app(environ, start_response):
        start_response('200 OK', [('content-type', 'text/html')])
        return ['Hello world!']

WSGI规范的参数. app需要完成的任务是响应envrion中的请求，准备好响应头和消息体，然后交给start_response处理，并返回响应消息体。

Paste 包含一个module，用来帮助实现WSGI中间件，它包含WSGI包装器，还包括了一个简单的webserver，用来处理WSGI请求。


WSGI middleware
WSGI标准是一个接口，它允许应用使用Python代码区处理HTTP请求。


egg包是目前最流行的python应用打包部署方式

Pillow
=================
Pillow 是从PIL上面fork下来的，因为PIL自从2009年就再没有更新过了，Pillow由作者Alex Clark和其他一些contributors一起维护，算是一个更好用的PIL，它能对图片文件进行各种操作。本文不再介绍如何安装了，本博客之前曾写过一篇文章《[使用django-simple-captcha遇到的坑](http://foofish.net/index.php/%E4%BD%BF%E7%94%A8django-simple-captcha%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/)》，这篇主要介绍如何使用Pillow。  

####理解Image类
Pillow库中最重要的类就是Image类，Image类定义在pil模块下，有多种方式来创建一个Image实例，比如：通过加载图片文件生成或者通过处理其他image返回Image实例，还可以通过屏幕抓取的方式获取Image实例。  

使用open()函数从文件中加载返回一个image  

    from PIL import Image
    im = Image.open('Lenna.jpg')
    print im
    print(im.format, im.size, im.mode)

输出：  

    <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=400x400 at 0x26247B0>
    ('JPEG', (400, 400), 'RGB')
创建了Image实例后你就可以通过某些方法操作图片了，例如im.show()可以显示图片。  

####读写图片文件
读文件时，直接调用open()从磁盘中读取，你并不需要知道文件的格式，Pillow会基于文件的内容判断文件的格式，保存文件时直接调用save()方法，pillow直接根据文件名的扩展名作为文件的格式，除非你明确指定其格式。  
#####格式转换

    import os.path
    infile = "/Lenna.jpg"
    f, e = os.path.silitext(infile)
    outfile = f + ".png"
    try:
        Image.open(infile).save(outfile)
    except IOError:
        print("cannot convert"+infile)

如果你的扩展名是非标准的，那么你就需要明确指定其格式。  

#####创建缩略图

    import os.path
    infile = "/Lenna.jpg"
    outfile = os.path.splitext(infile)[0]+".thumbnail"  #这个就是一个非标准的文件格式
    size = (128,128)
    
    try:
        im = Image.open(infile)
        im.thumbnail(size)
        im.save(outfile, "JPEG")  #因为oufile不是标准的文件格式，那么这里明确指定其格式
    excep IOError:
        print("cannot create thumbnail for",infile)




Pyramid学习笔记
========================
Static Assets：
------------------------------
static assets 指那些非Python原文件，如：图片、css、js、还有目录（没有__init__.py文件的目录）以及Mako或Chamelon模板文件。  
####理解asset规范：

    render_to_response('myapp:templates/some_template.pt', {}, request)
这里的字符串`myapp:templates/some_template.pt`就是一个**asset specification**它由两部分组成：  
1. package name （myapp）
2. asset name （templates/some_template.pt），相对于package目录

这两部分用一个冒号分隔开。pyramid使用pkg_resources API 解析 package name 和 asset name成相对于操作系统上的绝对路径。比如some_template.pt最后可能是解释成/home/workspace/project/templates/some_templates.pt。这样模板引擎就能正确加载、解析、执行模板文件了。  

####Serving Static Assets：
pyramid使得存放在文件系统目录里的assets文件通过用户游览器来查看成为可能。使用pyramid.config.Configurator.add_static_view()，例如：

    # config is an instance of pyramid.config.Configurator
    config.add_static_view(name='static', path='/var/www/static')

name参数代表URL的前缀，path参数代表文件系统中的路径，当用户访问URL:`/static/foo.css`时，返回文件/var/www/static/foo.css。  

    # config is an instance of pyramid.config.Configurator
    config.add_static_view(name='static', path='some_package:a/b/c/static')
这是使用assets specification 代替前面那种绝对路径的方式作为path参数的值，  
 
    add_static_view(name, path, **kw)
添加视图用来渲染静态资源（如：图片、js、css等）。当某个静态资源的URL被访问时，pyramid会添加一个视图来渲染该资源。它的可选参数cache_max_age，用来设置静态支援的过期时间。这个方法通常与pyramid.request.Request.static_url()结合使用。  

    request.static_url('mypackage:static/foo.css') =>

                        http://example.com/static/foo.css

    request.static_path('mypackage:static/foo.css') =>

                        /static/foo.css

add_static_view的name参数也可以是一个完全限定URL（full qualified URL) 如：  

    add_static_view('http://example.com/images', 'mypackage:images/')

那么static_url和static_path返回的都是：http://example.com/imgage/foo.css



Security
--------------------------------------------
authorization:授权，权限  
authentication:认证，登录验证  
pyramid 提供了一个可选的授权认证系统,在view被调用之前,认证系统可以根据request中的证书与上下文资源一道决定是否可以被访问.它的工作流程是这样的:  

* 当用户访问应用的时候生成request对象
* 基于request,context resource 通过 resource location定位到(traversal or URL dispatch)
* view callable 通过view lookup定位到 
* authentication policy 生效,传递给request,返回一些principal identifiers.
* 如果authorization policy 激活了,view configuration 关联了view callable,t它有关联的permission,那么authorization policy 会传递给context.permission关联view,允许或拒绝
* 如果authorization policy允许访问,视图就会被调用
* 如果authorization policy拒绝访问,视图就不会被调用,取而代之代之的是forbidden view

Security在Pyramid中，不想很多系统，清晰明确的分离的authorization和authentication。authorization仅仅是一种机制，通过request中的管理证书（credential）解析成一个或多个principal。

####使authorization生效
默认情况下，pyramid的authorization policy是不生效的。所有试图可以完全在匿名用户下能访问。为了保护试图基于安全设置防止被执行，你需要使authorization policy生效。  




 

###《Python网络编程》学习笔记一
学习新知识最好的方式就是一边记笔记，一边写代码，为了更深入地了解网络编程、异步通信、事件驱动编程等领域知识，开始系统学习相关知识，主要参考书目包括《Python网络编程》、《Twisted Network Progamming Essentials》，gevent、celey、rabbitmq等官方文档。  

网络编程离不开TCP/IP，因此想写好一个网络相关的程序，那么理解TCP/IP原理是最基本的要求。你能想象如果不理解TCP/IP，能写出一个goagent出来吗？  

TCP/IP是一些协议的合集，每个TCP连接有一个IP地址和一个端口号来唯一标识。TCP是一个可靠的连接，为了实现其可靠性，每个信息包都包含一个**校验码**，它用来保证信息在传输过程中没有被更改的代码。信息包到达目的地后，接收方会对比校验码和数据，如果校验码不对，那么该包就丢弃。  

为了防止信息包的丢失，TCP要求接收方每收到一个信息包都反馈一下，如果没有提供反馈，那么就自动重新发送，直到接受者收到为止。  

为了防止信息包重复或顺序错误，TCP每传送一个信息包都会传送一个序号，接受方会检查这个序号，确保收到该信息包，并把全部信息包按顺序重新合并。如果接收方看到一个已经存在的序号，那么该信息包就会被丢弃。  

####建立socket
对于客户端程序来说，建立socket需要两个步骤，第一：建立一个socket对象，第二：把他连接到远程服务器。建立socket对象时，需要告诉系统两个事情：**通信类型和协议家族**。通信类型指明用什么协议来传输数据，协议包括IPv4(当前Internet标准）、IPv6（将来的Internet标准）等，协议家族定义了数据如何被传输。  

对于Internet通信类型基本上都是AF_INET（对应IPv4），协议家族一般是表示TCP通信的SOCK_STREAM或表示UDP通信的SOCK_DGRAM。对于TCP通信，建立socket的代码一般是：  

    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
连接socket，需要一个元组参数，包含远程主机名和端口：  

    socket.connect(('www.google.com', 80))

建立连接后，可以获取连接信息：  

    s.getsocketname()  #返回本身IP和端口号，每次运行时段口号不尽相同
    s.getpeername()    #返回远程机器的IP地址和端口号

####用socket通信
用socket接收和发送数据有两种方式，分别是socket对象和文件类对象，其中socket对象提供了send()、sendto()、recv()、recvfrom()接口，文件类对象提供了read()、write()、readline()接口。socket对象能精确控制数据的读写。而类文件对象是面向线性的对象，不适用于UDP  

    import socket, sys
    
    port = 80
    host = 'localhost'
    filename = '/subject/2412'
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.connect((host, port))

    #socket对象 
    s.sendall(filename + "/r/n")
    buf = s.recv(2048)
    while len(buf):
        sys.stdout.write(buf)
        buf = s.recv(2048)

    #类文件对象
    fd = s.makefile("rw", 0)
    fd.write(filename+"\r\n")
    for line in fd.readlines():
        sys.stdout.write(line)

####socket异常
* 与一般I/O和通信问题有关的异常是：socket.error  
        
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        except socket.error:
            pass

        try:
            port = socket.getservbyname(textport, 'tcp')
        except socket.error:
            pass

        try:
            s.sendall("GET / HTTP/1.1\r\n\r\n")
        except socket.error:
            pass

        try:
            s.recv(2048)
        except socket.error:
            pass:

* 与查询地址信息有关的异常：socket.gaierror  

        try:
            s.connect((host, port))
        except socket.gaierror:
            pass
* 与其他地址错误有关的异常：socket.herror  


新工作知识点汇总
================
**tornado**  
tornado官方站点[英文](http://www.tornadoweb.org/en/stable/)[中文](http://www.tornadoweb.cn/)  
文档[英文](http://www.tornadoweb.org/en/stable/documentation.html)[中文](http://www.tornadoweb.cn/documentation)  

**mock**  
[the mock class](http://www.voidspace.org.uk/python/mock/mock.html)  
[get start with mock](http://www.voidspace.org.uk/python/mock/getting-started.html)  
[Replacing Redis with a Python Mock](http://seeknuance.com/2012/02/18/replacing-redis-with-a-python-mock/)  

**mongodb**  
[官方站点](https://www.mongodb.org/)  
[try](http://try.mongodb.org/)  
[文档](http://docs.mongodb.org/manual/)  
[50 Tips and Tricks for MongoDB  Developers.pdf](http://ishare.iask.sina.com.cn/f/18439195.html)  
[MongoDB权威指南](http://book.douban.com/subject/6068947/)  

**Redis**   
[官方站点](http://redis.io/)  
[中文站点](http://redis.cn/)  
[Redis设计与实现](http://redisbook.readthedocs.org/en/latest/)
[springside总结的Redis](https://github.com/springside/springside4/wiki/redis)  

**视频转码**  
[ffmpeg](http://www.ckplayer.com/manual.php?id=16)  
[ffmpeg官网](http://www.ffmpeg.org/index.html)  



当某个事件发生的时候，signal(信号)允许senders(发送者)用来通知receivers(接收者)，通知receivers干嘛？你想要recivers干嘛就可以干嘛。这在多处代码对同一个事件感兴趣的时候就有用武之地了。 比如：Django提供了一个built-in signal，叫`django.core.signals.request_finished`，这个signal会在一个HTTP请求完成后发送。下面就用一个简单的实例说明：在每个请求完成后打印"request finished"    
####编写receiver
reciver是一个普通的callable对象，简单来说就是一个可被调用的函数，但是需要注意的是它需要接收一个参数`sender`和一个关键字参数`**kwargs`

    def my_callback(sender, **kwargs):
        '''
        这是个receiver函数
        你可以在这里做爱做的的事情
        '''
        print sender
        print kwargs
        print("Request finished!")

这里我们先撇开sender和kwargs后面再分析，reciver函数写好之后，就需要把`request_finished`信号连接(注册)到`my_callback`。  

    from django.core.signals import request_finished
    request_finished.connect(my_callback)

现在请求一个URL路径`/hello`，后台打印的结果：  

    [31/Mar/2014 21:52:33] "GET /hello/ HTTP/1.1" 200 263
    <class 'django.core.handlers.wsgi.WSGIHandler'>
    {'signal': <django.dispatch.dispatcher.Signal object at 0x0262E510>}
    Request finished!

以上就是一个signal的执行流程，那么django内部是怎么实现的呢？为什么调用了reciver.connect后，my_callback就能得到执行了呢？且看源代码分析：  

request_finished定义在文件django.core.signals.py里面：  

    from django.dispatch import Signal

    request_started = Signal()
    request_finished = Signal()
    got_request_exception = Signal(providing_args=["request"])

`request_finished`就是Signal的实例。GET请求完成后会执行`my_callback`方法，为什么这么神奇，我们顺着request_finished的思路来猜想，既然是请求完成了，那么此时response对象也生成了，那么神奇的事情一定是在response里面发生的。去response.py文件里面看看：django.http.response.py  

    def close(self):
        for closable in self._closable_objects:
            try:
                closable.close()
            except Exception:
                pass
        signals.request_finished.send(sender=self._handler_class)
看到在response的close方法里面有send方法，而且这个sender就是我们在前面看到的`django.core.handlers.wsgi.WSGIHandler'`，这个send方法会发送信号给所有的receivers。  

    #Signal.send方法的源代码：

    responses = []
    if not self.receivers or self.sender_receivers_cache.get(sender) is NO_RECEIVERS:
        return responses

    for receiver in self._live_receivers(sender):
        response = receiver(signal=self, sender=sender, **named)
        responses.append((receiver, response))
    return responses

注意：你可以看到在for循环里面迭代的调用的receiver方法。以上就是django内部的执行原理。思考下send方式是signal的而不是sender的呢？从面向对象的角度来说，**谁是对象的拥有者，谁就提供相应的方法**。比如汽车的drive方法肯定是由汽车提供而不是由人。


####小结
我们需要做的只是编写receiver，然后调用signal.connect方法，相当于把receiver注册到signal上去。当事件触发时，相应的signal就会通知所有注册的receivers得到调用。尼玛，这是传说中的观察者模式。  

连接receiver函数还有另外一个方法，用装饰器：  

    @receiver(request_finished):
    def my_handler(sender, **kwages):
        '''
django还提供了很多内置的signals，比如：

1. django.db.models.signals.pre_save & django.db.models.signals.post_save

    Sent before or after a model’s save() method is called.

2. django.db.models.signals.pre_delete & django.db.models.signals.post_delete

    Sent before or after a model’s delete() method or queryset’s delete() method is called.

3. django.db.models.signals.m2m_changed

    Sent when a ManyToManyField on a model is changed.

signal还可以指定具体的senders，比如pre_save这个signal是在Model对象保存在被发送，但是我希望只有某一类Model保存的时候才发送，你就可以指定：  

    @receiver(pre_save, MyModel):
    def my_handle(sender, **kwargs):
        pass
这样每次只有保存MyModel实例后才会发送，其他的XXModel就会忽略掉。  

完！


首先`django.contrib.sitemaps`添加到`INSTALLED_APPS`，sitemaps会利用模版加载器`django.template.loaders.app_directories.Loader`加载的模版。默认情况下，这个加载器已经存在django的global_settings.py文件中的。  

    TEMPLATE_LOADERS = (
        'django.template.loaders.filesystem.Loader',
        'django.template.loaders.app_directories.Loader',
        #'django.template.loaders.eggs.Loader',
    )

以前介绍过一篇[文章](http://foofish.net/blog/63/django-compressor)有个参数叫STATICFILES_FINEDERS，也有类似的两个模块是：  

    STATICFILES_FINDERS = (
        'django.contrib.staticfiles.finders.AppDirectoriesFinder',
        'django.contrib.staticfiles.finders.FileSystemFinder',
    )
接下来就是配置URL：  

    (r'^sitemap\.xml$', 'django.contrib.sitemaps.views.sitemap', {'sitemaps': sitemaps})  

####Sitemap class
一个Sitemap类代表model里面一个实体类的部分，这部分最终会出现在sitemap.xml中的。下面就是一个简单的sitemap类，他会显示满足条件is_public=True和status=p的blog。  

    #!encoding=utf-8
    
    from django.contrib.sitemaps import Sitemap 
    from apps.blog.models import Blog 
    
    class BlogSitemap(Sitemap):
        changefreq = "weekly"
        priority = 0.5
    
        def items(self):
            return Blog.objects.filter(is_public=True).filter(status='p')
    
        def lastmod(self, obj):
            return obj.update_time

因为sitemap.xml显示的都是每个blog的url，因此BlogSitemap还有一个方法叫location()，用来定义blog的url的，默认这个方法会调用blog的get_absolute_url()方法，如果你的blog类没有实现这个方法那么在访问/sitemap.xml的就会出错了。  

    AttributeError at /sitemap.xml
    'Blog' object has no attribute 'get_absolute_url'
    Request Method:	GET
    Request URL:	http://localhost:8000/sitemap.xml

因此自己来实现location方法  

    def location(self, obj):
        return  r'/blog/%d/%s' % (obj.id, obj.link)
现在访问http://localhost:8000/sitemap.xml，你就能正常查看到sitemap了。  

    <urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
    <url>
    <loc>
    http://localhost:8000/blog/1/personal-blog-based-django-and-bootstrap
    </loc>
    <lastmod>2014-03-20</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.5</priority>
    </url>
    </urlset>

 

通信类型：AF_INET   
协议家族一般是表示TCP通信的SOC_STREAM和UDP通信的SOCK_DGRAM。对于TCP通信，建立socket连接，：

        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
连接socket，
        
        s.connect((host,port))

socket通信建立连接后，利用它发送接收数据，python提供了两种方式：socket对象和文件类对象  

socket对象提供了操作系统的send()、sendto()、recv()、recvfrom()方法，文件对象提供了read()、write()、readline()方法。



###Sphinx：SQL Phrase Index  基于SQL的全文检索引擎
####主要特性：
+ 高速建立索引（10MB/sec）
+ 快速搜索（在2到4G的文本中只需0.1秒） 
+ 可扩展（可达100G文本，10亿个文档）
+ 支持分布式
+ 支持MySQL（MyIASAM和InnoDB），原生支持PostgreSQL
+ 支持词语搜索
+ 支持短语相似度排名，相关度查询
+ 支持英语和俄语分词搜索
+ 支持文档组
+ 支持任何数量的文档字段
+ 支持不同的搜索模式（继承匹配，全部匹配，词语匹配，匹配任意）

####下载安装
以下都是基于Linux Ubuntu发行版环境下的操作。  

    wget http://sphinxsearch.com/files/sphinx-2.0.7-release.tar.gz
    tar -zvxf Sphinx-2.0.7-release.tar.gz  
    cd sphinx-2.0.7-release/
    ./configure --prefix=/usr/local/sphinx --with-mysql  
    make  
    sudo make install  

--prefix=/path：该选项制定Sphinx的安装路径  
--with-mysql=/path：Sphinx会自动检测MySQL的库文件，如果没有找到，你可以制定路径  
--with-pgsql=/path：同上  
安装时出现MySQL相关错误参考：http://stackoverflow.com/questions/3095040/help-setting-up-sphinx  
如果需要支持中文检索，建议参考下面这段  
####基于Sphinx检索引擎的coorseek安装配置（适用于中文环境）

1. 下载地址：[coreseek4.1](http://www.coreseek.cn/uploads/csft/4.0/coreseek-4.1-beta.tar.gz)
2. 预安装包：

        apt-get install make gcc g++ automake libtool mysql-client libmysqlclient15-dev   libxml2-dev libexpat1-dev

3. 安装mmseg分词库

        tar -zvxf coreseek
        cd mmseg
        ./bootstrap
        ./configure --prefix=/usr/local/mmseg3
        make
        make install

4. 安装coreseek 

        cd csft
        sh buildconf.sh
        ./configure --prefix=/usr/local/coreseek  --without-unixodbc --with-mmseg --with-mmseg-includes=/usr/local/mmseg3/include/mmseg/ --with-mmseg-libs=/usr/local/mmseg3/lib/ --with-mysql
        make
        make install

####快速了解
安装完后，在安装目录（/usr/local/sphinx）用`tree`命令可以看到如下目录结构，就代表安装成功了。  

    root@60:/usr/local/sphinx# tree
    ├── bin
    │   ├── indexer
    │   ├── indextool
    │   ├── search
    │   ├── searchd
    │   └── spelldump
    ├── etc
    │   ├── example.sql
    │   ├── sphinx.conf.dist
    │   └── sphinx-min.conf.dist
    ├── share
    │   └── man
    │       └── man1
    │           ├── indexer.1
    │           ├── indextool.1
    │           ├── search.1
    │           ├── searchd.1
    │           └── spelldump.1
    └── var
        ├── data
        └── log

bin目录存放二进制执行文件  
etc目录存放配置文件  
var目录存放索引数据和搜索日志  

#####sphinx工作流概览
![dataflow](../../resource/image/dataflow.png)
由四个主要的组件构成：  
**数据源** 是真正存储数据的地方，比如MySQL  
**indexer** indexer从数据源获取数据，创建全文本索引数据。  
**searchd** searchd与客户端程序通信，使用索引快速处理查询，此外，它还能处理结果集（包括过滤、排序、分组等）  
![interaction](../../resource/image/interaction.png)

**相关度** 在搜索世界中是一个非常重要的概念。MySQL也支持全文检索，你只需要在指定的字段上添加“FULLTEXT” 索引。比如：在‘'post’表的'description'字段添加全文检索索引  

    ALTER TABLE 'posts' ADD FULLTEXT(`description`);
不过这里要注意的是只有MyISAM引擎才支持全文索引。添加索引后，就可以使用语句：  

    SELECT * FROM posts WHERE MATCH (description) AGAINST('beautiful programming');
返回结果会根据相关度排序，这比使用LIKE语句速度要快不少。

####全文检索的优点
+ 相比传统搜索更快，它的优势来自于通过单词的索引查询记录取代全表扫描  
+ 查询结果可以根据相关度排序  
+ 在上百万条数据的数据库中性能表现非常好  
+ 他能跳过一些通用的词如：an for the 等等   

####Sphinx的主要组件
**indexer**：indexer用来建立或者重新建立全文本索引，默认情况Sphinx读取/usr/local/sphinx/etc/sphinx.conf配置文件。  
**searchd**：它是用来搜索索引的进程，需要客户端访问Sphinx API。  

####Sphinx简单实战

1. 创建数据库,执行脚本  

            mysql -uroot -proot test < /usr/localsphinx/etc/example.sql
2. 创建配置文件：  

            cd /usr/local/sphinx/etc
            cp sphinx-min.conf.disk sphinx.conf
    配置文件内容：

        source src1
        {
          type         = mysql
          sql_host        = localhost
          sql_user        = test
          sql_pass        =
          sql_db          = test
          sql_port        = 3306  # optional, default is 3306
          sql_query        = \
            SELECT id, group_id, UNIX_TIMESTAMP(date_added)
              AS date_added, title, content \
            FROM documents
          sql_attr_uint      = group_id
          sql_attr_timestamp    = date_added
          sql_query_info      = SELECT * FROM documents WHERE id=$id
        }
3. 创建索引：

        /usr/local/sphinx/bin/indexer --all

    打印结果：

        using config file '/usr/local/sphinx/etc/sphinx.conf'...
        indexing index 'test1'...
        collected 4 docs, 0.0 MB
        sorted 0.0 Mhits, 100.0% done
        total 4 docs, 193 bytes
        total 0.045 sec, 4280 bytes/sec, 88.72 docs/sec
        skipping non-plain index 'testrt'...
        total 3 reads, 0.000 sec, 0.1 kb/call avg, 0.0 msec/call avg
        total 9 writes, 0.000 sec, 0.1 kb/call avg, 0.0 msec/call avg

4. 查询索引  

        /usr/local/sphinx/bin/search test
    如果报错："index 'test1':search error" ，那么指定具体的index：   

        /usr/local/sphinx/bin/search -i test1 -q  'test' 

    查询结果：  

        using config file '/usr/local/sphinx/etc/sphinx.conf'...
        index 'test1': query 'test ': returned 3 matches of 3 total in 0.000 sec
        
        displaying matches:
        1. document=1, weight=2421, group_id=1, date_added=Wed Jun  5 08:00:56 2013
        2. document=2, weight=2421, group_id=1, date_added=Wed Jun  5 08:00:56 2013
        3. document=4, weight=1442, group_id=2, date_added=Wed Jun  5 08:00:56 2013
        
        words:
        1. 'test': 3 documents, 5 hits

如果使用第三方客户端API请求，需要启动searchd进程：  

    /usr/local/sphinx/bin/searchd

####简单介绍Sphinx配置文件
配置文件分成如下几部分：  
+ **source**：创建索引时需要用到的数据源  

        source src1
        {
                type                    = mysql
        
                sql_host                = localhost
                sql_user                = root
                sql_pass                = cloud
                sql_db                  = test
                sql_port                = 3306  # optional, default is 3306
        
                sql_query_pre           = SET NAMES utf8
                sql_query               = \
                        SELECT id, group_id, UNIX_TIMESTAMP(date_added) AS date_added, title, content \
                        FROM documents
        
                sql_attr_uint           = group_id
                sql_attr_timestamp      = date_added
        
                sql_query_info          = SELECT * FROM documents WHERE id=$id
        }
sql_query：获取待索引数据查询，最多可以指定32个数据字段，这些字段都会被全文检索  
sql_query_pre： 执行sql_query前的查询，可以有多个，按照配置文件顺序执行，于查询的结果会被忽略。它一般用于设置字符集编码，标记索引的记录，更新内部计数器等。  
sql_attr：属性，属性是附加在每个文档上的额外信息，可以在搜索的时候用于过滤和排序。下面会有详细介绍属性  
sql_query_info：用来获取和显示文档信息，命令行搜索时用，而且仅用于调试目的  

####属性
搜索除了根据文档的匹配度和相关度排序外，还经常会根据其它方式对结果进行额外处理，如：用户需要对新闻检索结果依次按日期和相关度排序，或者将检索结果按月分组，Sphinx的 **属性** 就能完成上述任务。  
属性于字段不一样，它不会被全文检索，仅仅是存储在索引中。属性可以用于过滤，或者限制返回的数据，以及排序、分组。  

论坛帖子表是一个很好的例子。假设只有帖子的标题和内容这两个字段需要全文检索，但是有时检索结果需要被限制在某个特定的作者的帖子或者属于某个子论坛的帖子中（也就是说，只检索在SQL表的author_id和forum_id这两个列上有特定值的那些行），或者需要按post_date列对匹配的结果排序，或者根据post_date列对帖子按月份分组，并对每组中的帖子计数。  

为实现这些功能，可以将上述各列（除了标题和内容列）作为属性，之后即可使用API调用来设置过滤、排序和分组。以下是一个例子：  

示例： sphinx.conf 片段:  

    ...
    sql_query = SELECT id, title, content, \
    	author_id, forum_id, post_date FROM my_forum_posts
    sql_attr_uint = author_id
    sql_attr_uint = forum_id
    sql_attr_timestamp = post_date
    ...
示例： 应用程序代码 (使用 PHP):  

    // 仅搜索ID为123的作者发布的内容
    $cl->SetFilter ( "author_id", array ( 123 ) );
    
    // 仅在id为1，3，7的子论坛中搜索
    $cl->SetFilter ( "forum_id", array ( 1,3,7 ) );
    
    // 按照发布时间倒序排列获取的结果
    $cl->SetSortMode ( SPH_SORT_ATTR_DESC, "post_date" );

示例：  


    sql_query_pre = REPLACE INTO sph_tag_counter SELECT 1,MAX(id) FROM subject_tag


+ **index**：指定索引数据的方法路径以及如何存放  

        index test1
        {
                source                  = src1
                path                    = /usr/local/sphinx/var/data/test1
                docinfo                 = extern
                charset_type            = sbcs
        }

charset_type：设置文档的编码，可以为sbcs（single-byte）和UTF-8  
+ **indexer**：indexer程序相关配置  
+ **searchd**：搜索索引时 searchd程序相关配置  

        searchd
        {
                listen                  = 9312
                listen                  = 9306:mysql41
                log                     = /usr/local/sphinx/var/log/searchd.log
                query_log               = /usr/local/sphinx/var/log/query.log
                read_timeout            = 5
                max_children            = 30
                pid_file                = /usr/local/sphinx/var/log/searchd.pid
                max_matches             = 1000
                seamless_rotate         = 1
                preopen_indexes         = 1
                unlink_old              = 1
                workers                 = threads # for RT to work
                binlog_path             = /usr/local/sphinx/var/data
        }

执行indexer时错误提示：  

    FATAL: failed to lock /usr/local/sphinx/var/data/test1.spl: Resource temporarily unavailable, will not index. Try --rotate option.

如果searchd进程启动了，那么先关闭它。或者 使用在indexer后面加参数`--rotate`，但是该参数在Windows环境下(2.1.1)的版本下不起作用

####使用Sphinx全文检索的好处
+ 快速建立索引，比MySQL的全文检索快上50到100倍，比其他全文检索快4到10倍
+ 更高的检索速度
+ 相关性
+ 良好的扩展性

Sphinx的作者Andrew Aksyonoff 在5GB文本，3百50万条记录中做的性能测试结果：  

    -------------------------------------------------------
                             MySQL       Lucene      Sphinx
    -------------------------------------------------------
    Indexing time, min       1627        176         84
    Index size, MB           3011        6328        2850
    Match all, ms/q          286         30          22
    Match phrase, ms/q       3692        29          21
    Match bool top-20, ms/q  24          29          13
    -------------------------------------------------------

####Indexing
索引在Sphinx中是最重要的组件之一。  
#####什么数据库索引
在数据库中，用于提高数据库表访问速度的数据库对象，虽然索引可以提高查询速度，但是它会导致数据库系统更新数据的性能下降，因为更新数据的时候同时要更新索引。  
#####sphinx中的索引
Sphinx中的索引与数据库索引有所区别，sphinx中的索引数据是结构化 **文档** 的集合，每个文档是字段（field）的集合。一行代表一个文档，每一列代表一个字段。索引还可以包含属性（attributes）用于过滤、排序、分组，这些属性不会被全文检索，仅仅是被存储在索引中。  

举例：论坛帖子表中帖子的标题和内容这两个字段需要全文检索，但是检索结果需要限制在某个特定的作者，或者按照post_date对结果排序，实现这个功能可以将出了标题和内容的各列作为属性来做索引，之后使用API调用设置过滤、排序等操作。  
sphinx.conf片段：  

    sql_query = SELECT id, title, content, \
    	author_id, forum_id, post_date FROM my_forum_posts
    sql_attr_uint = author_id
    sql_attr_uint = forum_id
    sql_attr_timestamp = post_date

应用程序代码：

    // only search posts by author whose ID is 123
    $cl->SetFilter ( "author_id", array ( 123 ) );
    
    // only search posts in sub-forums 1, 3 and 7
    $cl->SetFilter ( "forum_id", array ( 1,3,7 ) );
    
    // sort found posts by posting date in descending order
    $cl->SetSortMode ( SPH_SORT_ATTR_DESC, "post_date" );


属性支持的数据类型包括：  

+ 无符号整数（1-32位宽）;
+ UNIX 时间戳（timestamps）;
+ 浮点值（32位，IEEE 754单精度）;
+ 字符串序列 (尤其是计算出的整数值);
+ 多值属性 MVA( multi-value attributes ) (32位无符号整型值的变长序列).

属性的作用：过滤，排序，分组  

不同的索引类型为不同的任务设计，基于磁盘的B-Tree存储结构的索引更新起来比较简单（容易向已有的索引中插入新的文档），但是搜索起来比较慢。Sphinx为了最优化建立索引和检索速度而设计，因此它更新索引时很慢的，理论上更新索引甚至比从头重建索引还要慢。不过大多数情况下可以通过建立多个索引来解决索引更新慢的问题，更多参考： ** 实时更新索引**  

实时索引采用“主索引+增量索引”（main+delta）模式来实现“近实时”的索引更新。基本思路是设置两个数据源和两个索引，对更新或根本不更新的数据建立主索引，对新增文档建立增量索引。增量索引的更新频率可以非常快，文档可以在出现几分钟内就可以被检索到。  
确定具体某一文档分属哪个索引的分类工作可以自动完成，一个可选方案是建立一个计数器，记录将文档集分成两部分和那个文档ID，每次重新构建主索引时，这个表都会被更新。 

    CREATE TABLE sph_counter
    (
        counter_id INTEGER PRIMARY KEY NOT NULL,
        max_doc_id INTEGER NOT NULL
    );
    # in sphinx.conf
    source main
    {
        # ...
        sql_query_pre = REPLACE INTO sph_counter SELECT 1, MAX(id) FROM documents
        sql_query = SELECT id, title, body FROM documents \
            WHERE id<=( SELECT max_doc_id FROM sph_counter WHERE counter_id=1 )
    }
    source delta : main
    {
        sql_query_pre =
        sql_query = SELECT id, title, body FROM documents \
            WHERE id>( SELECT max_doc_id FROM sph_counter WHERE counter_id=1 )
    }
    index main
    {
        source = main
        path = /path/to/main
        # ... all the other settings
    }
    # note how all other settings are copied from main,
    # but source and path are overridden (they MUST be)
    index delta : main
    {
        source = delta
        path = /path/to/delta
    }



一个索引的数据可以来自多个数据源，这些数据将严格按照配置文件中定义的顺序进行处理，所有从这些数据源获取到的文档将被合并，合并索引一般比重新索引快。基本语法：  

    indexer --merge des_index src_index [--rotate]
src_index将被合并到des_index中去，如果des_index已经用于searrchd提供服务，则必须加参数--rotate。
####多值属性
定义的格式如下：  
    
    sql_attr_multi = unit tag_id from query;\
                    SELECT subject_id,tag_id FROM subject_subject_tags
程序中可以这样调用：  

    int[] tags = {25770,5};
	cl.SetFilter("tag_id", tags, false);
只保留包含tag id 为 25770、5的subject
    





创建配置文件  
cd /usr/local/sphinx/etc
cp sphinx.conf.disk sphinx.conf
sudo vim sphinx.conf
修改数据源配置，执行:

    mysql -uroot -proot test < /usr/localsphinx/etc/example.sql
运行indexer 创建全文索引  
cd /usr/local/sphinx/etc
/usr/local/sphinx/bin/indexer --all

启动searchd进程  
/usr/local/sphinx/bin/searchd  

api 测试  
cd /sphinx/api
。。。。。

Sphinx 可以通过三种不同的接口于Sphinx的搜索服务（searchd）通信
1. 原生搜索API
2. 


indexer：用于创建索引  
search：一个简单的命令行测试程序，用于测试全文索引  
searchd：守护进程，web程序可以通过这个进程进行全文检索
sphinxapi：searchd的客户端API库
spelldump：命令行工具，用于提取词条
indextool：用来转储关于索引的调试信息
mmseg：用于提供中文分词和词典处理：


sphinx配置文件:  
source:指定数据源  
index：设置索引
searchd：

http://davidx.me/2010/10/31/understanding-sphinx/

找数据--> 建索引-->提供服务


####数据源
索引的数据可以来自：SQL数据库，纯文本，HTML文本等等，数据数据一个结构化的**文档**集合，一行就代表一个文档，每一列代表字段.  

####属性
属性是附加在每个文档上的额外信息，在搜索时可以用于过滤和排序，属性不会被全文索引，只是被存储在索引中，对属性检索时会报错。  

各个文档全部属性信息构成了一个集合，被称为文档信息，docinfo,他又两种存储方式  ：
1. 与全文索引数据分开存储（“外部存储，在.spa文件中存储） 
2. 在全文索引数据中，每出现一次文档Id，就出现相应的文档信息，（内联存储，在.spd文件中存储）

####MVA（多值属性）
对文章的tags，产品类型非常重要，他是文档属性的一中特例，他可以向文档附加一系列值作为属性。  他支持过滤和分组（不支持分组排序）

MVA列表项的值被限制为32位无符号整数，列表的长度不受限制，只有有足够的RAM

###索引

所有文档的ID必须是唯一的无符号非零整数，

建立索引的过程如下：
连接到数据库
执行预查询，以便完成所有必须的初始化设置，比如MySQL连接设置编码。
执行住查询 ,返回的数据将被索引。
执行后查询：清理工作
关闭数据库连接
对短语排序，索引后处理
再次链接到数据库连接
执行后索引查询，以便完成最终的清理工作
再次关闭到数据库的连接

###区段查询
从数据库中取出文档ID的最小值和最大值，将最大值和最小值定义自然数区间分成若干份，一次获取数据，建立索引。

可以使用”主索引+增量索引‘模式来实现“近实时”的索引更新  

设置两个数据源和两个索引，对很少更新或根本不更新的数据连理主索引，而对新增文档建立增量索引，



Sphinx要求每个记录（数据库中的记录）有id字段，
也就意味着配置文件sphinx.conf中source段的sql_query 的查询语句的第一个字段必须是唯一的，
无符号的正整数ID数字，。配置文件中，最多可以指定32个文本字段和任意数量的属性。
Sphinx会全文索引除ID（第一个字段）的属性之外的所有列。

Sphinx支持的属性类型： 

sql_attr_uint  和 sql_attr_bigint  32位无符号整数值和64位有符号整数值。整数和date类型可以使用  

sql_attr_float  

sql_attr_bool  类似mysql的tinyint值

sql_attr_timestamp   Unix时间戳   从1970-01-01 到2038-01-19.

sql_attr_string

索引的类型可以有：plain，默认   distributed  分布式的  rt：实时的，可以立即更新索引。ooo
preopen=1告诉searchd在加载时打开所有索引文件

配置文件的斜杠后面不能有任何空格


对于myisam的引擎，mysql也支持全文检索  alter table posts add fulltext('description')

select * from posts where match(descriptioin) against ('beautiful programming');


关于错误：  search test 出现的错误：
index 'test1':search error: .
解决的办法是：search -i test1 -q  'test'：指定具体的index


####索引合并：  

    indexer --merge DST_INDEX SRC_INDEX [--ratate]

属性


SPH_SORT_TIME_SEGMENTS 这种排序模式在windows平台好像不生效，搜出来的结果是空

[中文分词核心配置](http://www.coreseek.cn/products-install/coreseek_mmseg/)

####搜索c++,.net 等关键字时：
在index中配置

    exceptions:   /path/to/exception.txt
执行命令：

    mmseg -b /path/to/exception.txt

生成的synonyms.dat 拷贝到uni.lib所在目录

exception.txt:

    C/C++ => cdpluspluscd
    c/C++ => cdpluspluscd
    c/c++ => cdpluspluscd
    C/c++ => cdpluspluscd
    C++ => dplusplusc
    c++ => dplusplusc
    C# => csharpcs
    c# => csharpcs
    J++ =>jshhdjs
    j++ => jshhdjs
    J# => jshhhejs
    j# => jshhhejs
    .NET => dotnet
    .net => dotnet
    * => asterisk
    R&B => rhythmblues
    VB.NET => vbdontnetvb
    vB.NET => vbdotnetvb



=================================
sphinx-coreseek 优化指南
=================================
####html_strip：HTML标记清除

只保留标记之间的内容，HTML标签和HTML注释会被删除。比如:  

    <a href="http://www.google.com">google</a>
开启html_strip=1后，就只保留内容google。默认情况html_strip的值是0，表示禁用，1表示启用。如果要把标签之间的内容也删除的话，那么就要使用**html_remove_elements** 属性了。    

看下面这个例子：  
![search_html](../../resource/image/html_search0.png)
第一条记录看上去就是无相关的，点进去看了下，就是一个一个视频链接，里面有这么一段：  

    <embed src="http://player.youku.com/player.php/Type/Folder/Fid/18841125/Ob/1/sid/XNTA1MTg0NDg0/v.swf" 
    type="application/x-shockwave-flash" width="660" height="500" autostart="true" loop="true">

这个embed标签里面有一个链接包含php的字符。我们设置html_strip=1，再来看结果就只有一条记录了。  
 ![search_html1](../../resource/image/html_search1.png)

####exceptions：
在搜索c++、c#等词的时候，包含c的内容都搜索出来了，显然这不是我们想要的，exceptions的功能就是将一个或多个Token映射成一个单独的关键字，与wordforms类似，但是也有很多不同的地方。  

![exception](../../resource/image/exceptions0.png)

* exceptions 大小写敏感，wordforms大小写无关  
* exeptions 可以使用charset_table中没有的特殊符号，wordforms完全遵从charset_table。  

示例：  

    AT & T => AT&T
    AT&T => AT&T
    Standarten   Fuehrer => standartenfuhrer
    Standarten Fuhrer => standartenfuhrer
    MS Windows => ms windows
    Microsoft Windows => ms windows
    C++ => cplusplus
    c++ => cplusplus
    C plus plus => cplusplus

注意 “=》”的字符串都是单个完成的字符串，无论是"&"还是空格“ ”都是看作单个字符串的一部分。  
![exception](../../resource/image/exceptions1.png)  

你妹的，exception和wordform还相互影响   

####wordforms：词形字典

    wordforms = /usr/local/sphinx/data/wordforms.txt

用来将不同形式的词形编程单一的标准形式，如："microsoft、ms、微软"变成同一的形式microsoft。格式是：  

    ms > microsoft
    微软 > microsoft

![wordform](../../resource/image/wordform.png)  
目标词形(microsoft)只能是单个词，比如：  

     zhang san > 张三
查询chang san 的时候，只匹配张，就是说只要是含有“张”字的都匹配，无论是张三还是张四。  

####一元切分模式
有时候使用一元切分模式，反而降低的搜索的准确率。比如我在搜索”小小“时，使用一元分词后，凡是含有”小“字的内容都被搜索出来了。显然不是我们想要的。  
![yiyuan0.png](../../resource/image/yiyuan.png)  

一元分词的详细配置在http://www.coreseek.cn/products-install/ngram_len_cjk/ ，如果不想启动一元分词时，charset_type=utf-8，要改成 charset_type=zh_cn.utf-8,否则是搜出去东西来的。  



####sphnix的匹配模式
* SPH_MATCH_ALL:匹配所有查询此，这是sphinx的默认模式，比如搜索：“中国"，那么只有文档中同时出现”中国“二字时才会匹配，当然“中国”可以不出现在一块.  
* SPH_MATCH_ANY:匹配任意一个  
* SPH_MATCH_PHRASE



####数据源的一些限制条件

document 的 id 必须是唯一的无符号的非0的整数，直白点就是要大于0的整数，至于是32位还是64位的根据自己的喜好设定。我们的线上环境就有一个id为-1的数据，搜不出来，该主键是非常麻烦的，所以在新建数据的时候就要特别注意。  


####BuildExcerpts产生文本摘要和高亮

    function BuildExcerpts ( $docs, $index, $words, $opts=array() )

docs:包含文档内容的数组  
index:索引  
words:需要高亮的字符串
opts:字典类型


SQLAlchemy 学习笔记
=====================
SQLAlchemy是Python语言事实上的ORM（Object Relational Mapper）标准实现，两个主要的组件： **SQLAlchemy ORM** 和 **SQLAlchemy Core**  。  

![架构图](http://docs.sqlalchemy.org/en/rel_0_8/_images/sqla_arch_small.png)

#####安装  
    
    pip install SQLAlchemy

检查安装是否成功:  

    >>> import sqlalchemy
    >>> sqlalchemy.__version__
    0.8.0
没有报错就代表正确安装了，连接MySQL数据库(需要MySQLdb支持)：  

    from sqlalchemy import create_engine
    DB_CONNECT_STRING = 'mysql+mysqldb://root:@localhost/test2?charset=utf8'
    engine reate_engine(DB_CONNECT_STRING,echo=False)
create_engine方法返回一个Engine实例，Engine实例只有直到触发数据库事件时才真正去连接数据库，如执行：

    engine.execute("select 1").scalar()

执行上面的语句是，sqlalchemy就会从数据库连接池中获取一个连接用于执行语句。  

####声明一个映射（declare a Mapping)

`declarative_base`类维持了一个从类到表的关系，通常一个应用使用一个base实例，所有实体类都应该继承此类对象

    from sqlalchemy.ext.declarative import declarative_base
    Base = declarative_base()

现在就可以创建一个domain类  

    from sqlalchemy import Column,Integer,String

    class User(Base):
        __tablename__ = 'users'
        id = Column(Integer,primary_key=True)
        name = Column(String)
        fullname = Column(String)
        password = Column(String)   #这里的String可以指定长度，比如：String(20)

        def __init__(self,name,fullname,password):
            self.name = name
            self.fullname = fullname
            self.password = password
        
        def __repr(self):
            return "<User('%s','%s','%s')>"%(self.name,self.fullname,self.password)

    Base.metadataa.create_all(engine)  

sqlalchemy 就是把Base子类转变为数据库表，定义好User类后，会生成`Table`和`mapper()`，分别通过User.__table__  和User.__mapper__返回这两个对象，对于主键，象oracle没有自增长的主键时，要使用：  

    from sqlalchemy import Sequence
    Column(Integer,Sequence('user_idseq'),prmary_key=True)

####创建Session

Session是真正与数据库通信的handler，  

    from sqlalchemy.orm import sessionmaker
    Session = sessionmaker(bind=engine)
创建完session就可以添加数据了  

    ed_user = User('ed','Ed jone','edpasswd')
    session.add(ed_user)
    session.commit()

也可以使用session.add_all()添加多个对象 

    session.add_all([user1,user2,user3])

如果没有提交事务，如果是在add方后有查询，那么回flush一下，把数据刷一遍，add最终会把数据保存到数据库。

一样有session.rollback()

####查询
Query对象通过Session.query获取，query接收类或属性参数  

    for instance in session.query(User).order_by(User.id)
        print instance.name

    for name,fullname in session.query(User.name,User.fullname):
        print name,fullname
####常用过滤操作：  
- equals
    query.filter(User.name == 'ed')
- not equal
    query.filter(User.name !='ed')
- LIKE
    query.filter(User.name.like('%d%')
- IN:
    query.filter(User.name.in(['a','b','c'])
- NOT IN:
    query.filter(User.name.in_(['ed','x'])
- IS NULL:
    filter(User.name==None)
- IS NOT NULL:
    filter(User.name!=None)
- AND
    from sqlalchemy import and_
    filter(and_(User.name == 'ed',User.fullname=='xxx'))    
或者多次调用filter或filter_by
    filter(User.name =='ed').filter(User.fullname=='xx')
    等同于 func.add_()
- OR
- match


Django中ORM的filter方法里面只有一个等号，比如：  

    Entry.objects.all().filter(pub_date__year=2006)

all()返回列表
query = session.query(User).filter(xx)
query.all()
query.first()
query.one()有且只有一个元素时才正确返回。

####Relattionship
SQLAlchemy中的映射关系有四种,分别是**一对多**,**多对一**,**一对一**,**多对多**  
#####一对多(one to many）
一对多与多对一的区别在于其关联(relationship)的属性在多的一方还是一的一方,因为外键(ForeignKey)始终定义在多的一方.如果relationship和ForeignKey都定义在多的一方,那就是多对一,如果relationship定义在一的一方那就是一对多.  
这里的例子中,一指的是Parent,一个parent有多个child.  

    class Parent(Base):
        __tablename__ = 'parent'
        id = Column(Integer,primary_key = True)
        children = relationship("Child",backref='parent')
    
    class Child(Base):
        __tablename__ = 'child'
        id = Column(Integer,primary_key = True)
        parent_id = Column(Integer,ForeignKey('parent.id'))

#####多对一(many to one)
这个例子中many是指parent了,意思是一个child可能有多个parent(父亲和母亲),这里的外键(child_id)和relationship(child)都定义在多(parent)的一方  

    class Parent(Base):
        __tablename__ = 'parent'
        id = Column(Integer, primary_key=True)
        child_id = Column(Integer, ForeignKey('child.id'))
        child = relationship("Child", backref="parents")
    
    class Child(Base):
        __tablename__ = 'child'
        id = Column(Integer, primary_key=True)

为了建立双向关系,可以在relationship()中设置backref,Child对象就有parents属性.设置 `cascade= 'all'`，可以级联删除  

    class Parent(Base):
        __tablename__ = 'parent'
        id = Column(Integer,primary_key = True)
        children = relationship("Child",cascade='all',backref='parent')
    
    def delete_parent():
        session = Session()
        parent = session.query(Parent).get(2)
        session.delete(parent)
        session.commit()
不过不设置cascade，删除parent时，其关联的chilren不会删除，只会把chilren关联的parent.id置为空，设置cascade后就可以级联删除children  

#####一对一
一对一就是多对一和一对多的一个特例,只需在relationship加上一个参数uselist=False替换多的一端就是一对一:  
从一对多转换到一对一:  

    class Parent(Base):
        __tablename__ = 'parent'
        id = Column(Integer, primary_key=True)
        child = relationship("Child", uselist=False, backref="parent")
    
    class Child(Base):
        __tablename__ = 'child'
        id = Column(Integer, primary_key=True)
    parent_id = Column(Integer, ForeignKey('parent.id'))
从多对一转换到一对一:  

    class Parent(Base):
        __tablename__ = 'parent'
        id = Column(Integer, primary_key=True)
        child_id = Column(Integer, ForeignKey('child.id'))
        child = relationship("Child", backref=backref("parent", uselist=False))
    
    class Child(Base):
        __tablename__ = 'child'
        id = Column(Integer, primary_key=True)
#####多对多
多对多关系需要一个中间关联表,通过参数secondary来指定,  

    from sqlalchemy import Table,Text
    post_keywords = Table('post_keywords',Base.metadata,
            Column('post_id',Integer,ForeignKey('posts.id')),
            Column('keyword_id',Integer,ForeignKey('keywords.id'))
    )

    class BlogPost(Base):
        __tablename__ = 'posts'
        id = Column(Integer,primary_key=True)
        body = Column(Text)
        keywords = relationship('Keyword',secondary=post_keywords,backref='posts')
            
    class Keyword(Base):
        __tablename__ = 'keywords'
        id = Column(Integer,primary_key = True)
        keyword = Column(String(50),nullable=False,unique=True)


#####relationship()API
[relationships api](http://docs.sqlalchemy.org/en/latest/orm/relationships.html#relationships-api),参数非常多,列举一下我用到的参数:  

- backref:在一对多或多对一之间建立双向关系,比如:  

        class Parent(Base):
            __tablename__ = 'parent'
            id = Column(Integer, primary_key=True)
            children = relationship("Child", backref="parent")
        
        class Child(Base):
            __tablename__ = 'child'
            id = Column(Integer, primary_key=True)
            parent_id = Column(Integer, ForeignKey('parent.id'))
    Prarent对象获取children,parent.children,反过来Child对象可以获取parent:child.parent.
- lazy:默认值是True,说明关联对象只有到真正访问的时候才会去查询数据库,比如有parent对象,只有知道访问parent.children的时候才做关联查询.  
- remote_side:表中的外键引用的是自身时,如Node类,如果想表示多对一的关系,那么就可以使用remote_side  

        class Node(Base):
            __tablename__ = 'node'
            id = Column(Integer, primary_key=True)
            parent_id = Column(Integer, ForeignKey('node.id'))
            data = Column(String(50))
            parent = relationship("Node", remote_side=[id])
    如果是想建立一种双向的关系,那么还是结合backref:  

        class Node(Base):
        __tablename__ = 'node'
        id = Column(Integer, primary_key=True)
        parent_id = Column(Integer, ForeignKey('node.id'))
        data = Column(String(50))
        children = relationship("Node",
                    backref=backref('parent', remote_side=[id])
                )
- primaryjoin:用在一对多或者多对一的关系中,默认情况连接条件就是主键与另一端的外键,用primaryjoin参数可以用来指定连接条件 ,比如:下面user的address必须现address是一'tony'开头:  

        class User(Base):
            __tablename__ = 'user'
            id = Column(Integer, primary_key=True)
            name = Column(String)
        
            addresses = relationship("Address",
                            primaryjoin="and_(User.id==Address.user_id, "
                                "Address.email.startswith('tony'))",
                            backref="user")
        
        class Address(Base):
            __tablename__ = 'address'
            id = Column(Integer, primary_key=True)
            email = Column(String)
            user_id = Column(Integer, ForeignKey('user.id'))

- secondary:  
- order_by:  
    在一对多的关系中,如下代码:  

        class User(Base):
        # ....
        addresses = relationship("Address",
                         order_by="desc(Address.email)",
                         primaryjoin="Address.user_id==User.id")
    如果user的address要按照email排序,那么就可以在relationship中添加参数order_by.这里的参数是一字符串形式表示的,不过它等同于python表达式,其实还有另一种基于lambda的方式:  
        
        class User(Base):
        # ...
        addresses = relationship(lambda: Address,
                         order_by=lambda: desc(Address.email),
                         primaryjoin=lambda: Address.user_id==User.id)



#####association_proxy
[associationproxy](http://docs.sqlalchemy.org/en/rel_0_8/orm/extensions/associationproxy.html)是sqlalchemy扩展包里面的一个函数,是一个无关痛痒的提供便捷性的功能,在多的言语也不及官方文档的例子,还是看看文档吧.  

#####column_propety
可以用[column_property](http://docs.sqlalchemy.org/en/latest/orm/mapper_config.html#using-column-property)来实现SQL表达式作为映射类的属性(另外一种方式就是用hybrid),
 


对比Django中的ORM:  
Django 中提供了三种通用的数据库关系类型，many-to-one，many-to-many，one-to-one，  

many-to-one：  
用ForeignKey来定义多对一的关系，假设一个员工只能隶属于一个部门，但部门可以有多个员工，则可以：

    class Department(models.Model):
        ...
    
    class Employee(models.Model):
       department = models.ForeignKey(Department)
       ...

如果一个对象和自身有多对一的关系，则可以是：  

    models.ForeignKey('self'):

    class Employee(models.Model):
        manager = models.ForeignKey('self')

many-to-many：  
用ManyToManyField来定义多对多的关系，假设Blog可以有多个Tag，一个Tag也可以在多篇Blog里面，那么就可以用ManyToManyField  

    class Blog(models.Model):
        tags = ManyToManyField(Tag)
    class Tag(models.Model):
        ....

同样可以通过ManyToManyField('self')和自身建立多对多的关系.  

one-to-one:  
用OneToOneField来定义一对一的关系

相比较而言,django的orm可谓简单很多,但是性能方面未必优于sqlalchemy,不同点,sqlalchemy的model需要指定id,而django会自动帮你生成id.








####Session
Session 使用 connection发送query，把返回的result row 填充到一个object中，该对象同时还会保存在Session中，Session内部有一个叫 Identity Map的数据结构，为每一个对象维持了唯一的副本。primary key 作为 key ，value就是该object。  
session刚开始无状态，直到有query发起时。

对象的变化会被session的跟踪维持着，在数据库做下一次查询后者当前的事务已经提交了时，it fushed all pendings changes to the database.   
这就是传说中的 Unit of work 模式

例如：

    def unit_of_work():
        session = Session()
        album = session.query(Album).get(4)
        album.name = "jun"   #这里不会修改album的name属性，不会触发update语句

    def unit_of_work():
        session = Session()
        album = session.query(Album).get(4)
        album.name = "jun"   #这里修改了album的name属性，会触发一个update语句
        session.query(Artist).get(11)
        session.commit()

####构造了session，何时commit，何时close
规则：始终保持session与function和objecct分离

####transaction scope  和  session scope


#####对象的四种状态
 对象在session中可能存在的四种状态包括：  

 - **Transient** ：实例还不在session中，还没有保存到数据库中去，没有数据库身份，想刚创建出来的对象比如`User()`，仅仅只有`mapper()`与之关联  
 - **Pending** ：用add()一个transient对象后，就变成了一个pending对象，这时候仍然没有flushed到数据库中去，直到flush发生。  
 - **Persistent** ：实例出现在session中而且在数据库中也有记录了，通常是通过flush一个pending实例变成Persistent或者从数据库中querying一个已经存在的实例。
 - **Detached**：一个对象它有记录在数据库中，但是不在任何session中，


#### Hibernate中的Session
SessionFactory创建Session，SessionFactory是线程安全的，而Session是线程不安全的。Session是轻量级的，创建和删除都不需要耗太大的资源，这与JDBC的connection不一样，Connection的创建时很好资源的。  
Session对象内部有一个缓存，称之为Hibernate第一级缓存，每个session实例都有自己的缓存，存放的对象是当前工作单元中加载的对象。  
Hibernate Session 缓存三大作用：  
1. 减少数据库的访问频率，提高访问性能
2. 保证缓存的对象与数据库同步，位于缓存中的对象称为持久化对象
3. 当持久化对象存在关联时，session保证不出现对象图的死锁

####Session什么时候清理缓存
1. commit()方法调用的时候
2. 查询时会清理缓存，保证查询结果能反映对象的最新状态
3. 显示调用session的flush方法
4.  


####Querying

    q = session.query(SomeMappedClass)

session的query方法就可以创建一个查询对象，





    def add_before_query():
        session = Session()
        ed_user = User(name='zhangsan')
        session.add(ed_user)
        user = session.query(User).filter_by(name='zhangsan').first()
        print ed_user == user
这里的ed_user == user 返回True，session中会根据用主键作为key，object作为vlaue缓存在session中



    def test1():
        session = Session()
        jack = session.query(User).filter_by(name='lzjun').one()
        print jack
        print jack.addresses
默认sqlalchemy 使用的时懒加载的模式，查询user的时候，并不会查询user.addresses，只有真正使用user.addresses的时候
才会触发user.addresses的查询语句。  

    from sqlalchemy.orm import subqueryload
    def subquery_load_test():
        session = Session()
        jack = session.query(User).\
                options(subqueryload(User.addresses)).\
                filter_by(name='lzjun').one()
        print jack
使用subqueryload操作，饿汉式加载，查询user的时候，就把addresses查询出来了。  


####传统映射
用Table构建一个table metadata，然后通过映射函数mapper与User关联起来  

    from sqlalchemy import Table,Metadata
    metadata = Metadata()
    
    user = Table('user',metadata,
            Column('id',Integer,primary_key = True),
            )
    class User(object):
        def __init__(self,name):
            self.name = name
    mapper(User,user)

等价于：  

    class User(Base):
        id = Column(Integer,primary_key = True)
        name = Column(String)
        def __init__(self,name):
            self.name = name

###使用加载策略（懒加载，饿加载）
SQLAlchemy 默认使用 Lazy Loading 策略加载对象的 relationships。因此，如果你在对象 detached 之后访问对象的 relationships，会报 "DetachedInstanceError" 错误。例如：

user = session.query(User).get(id)
_session.close()
print user.comments  # this will raise DetachedInstanceError
如果你需要在对象 detach 后访问 relationships（例如需要跨进程共享对象），则应该使用 Eager Loading 策略：

session.query(User).options(joinedload('comments')).get(id)
_session.close()
print user.comments  # OK
如果需要加载所有的 relationships ，可以设置 Default Loading Strategies :

    class Parent(Base):
        __tablename__ = 'parent'
        id = Column(Integer,primary_key = True)
        children = relationship("Child",backref='parent')
    
    class Child(Base):
        __tablename__ = 'child'
        id = Column(Integer,primary_key = True)
        parent_id = Column(Integer,ForeignKey('parent.id'))

在one的那端设置了backref后，反过来就是多对一，在保存child时不需要显示的保存parent

    def save_child():
        parent = Parent()
        child1 = Child(parent = parent)
        child2 = Child(parent = parent)
        child3 = Child(parent = parent)
        session = Session()
        session.add_all([child1,child2,child3])
        session.flush()
        session.commit()

设置 `cascade= 'all'`，可以级联删除  

    class Parent(Base):
        __tablename__ = 'parent'
        id = Column(Integer,primary_key = True)
        children = relationship("Child",cascade='all',backref='parent')
    
    def delete_parent():
        session = Session()
        parent = session.query(Parent).get(2)
        session.delete(parent)
        session.commit()
不过不设置cascade，删除parent时，其关联的chilren不会删除，只会把chilren关联的parent.id置为空，设置cascade后就可以级联删除children  

####Session
Session 使用 connection发送query，把返回的result row 填充到一个object中，该对象同时还会保存在Session中，Session内部有一个叫 Identity Map的数据结构，为每一个对象维持了唯一的副本。primary key 作为 key ，value就是该object。  
session刚开始无状态，直到有query发起时。

对象的变化会被session的跟踪维持着，在数据库做下一次查询后者当前的事务已经提交了时，it fushed all pendings changes to the database.   
这就是传说中的 Unit of work 模式

例如：

    def unit_of_work():
        session = Session()
        album = session.query(Album).get(4)
        album.name = "jun"   #这里不会修改album的name属性，不会触发update语句

    def unit_of_work():
        session = Session()
        album = session.query(Album).get(4)
        album.name = "jun"   #这里修改了album的name属性，会触发一个update语句
        session.query(Artist).get(11)
        session.commit()

####构造了session，何时commit，何时close
规则：始终保持session与function和objecct分离

####transaction scope  和  session scope

#####对象的四种状态
 对象在session中可能存在的四种状态包括：  

 - **Transient** ：实例还不在session中，还没有保存到数据库中去，没有数据库身份，想刚创建出来的对象比如`User()`，仅仅只有`mapper()`与之关联  
 - **Pending** ：用add()一个transient对象后，就变成了一个pending对象，这时候仍然没有flushed到数据库中去，直到flush发生。  
 - **Persistent** ：实例出现在session中而且在数据库中也有记录了，通常是通过flush一个pending实例变成Persistent或者从数据库中querying一个已经存在的实例。
 - **Detached**：一个对象它有记录在数据库中，但是不在任何session中，


#### Hibernate中的Session
SessionFactory创建Session，SessionFactory是线程安全的，而Session是线程不安全的。Session是轻量级的，创建和删除都不需要耗太大的资源，这与JDBC的connection不一样，Connection的创建时很好资源的。  
Session对象内部有一个缓存，称之为Hibernate第一级缓存，每个session实例都有自己的缓存，存放的对象是当前工作单元中加载的对象。  
Hibernate Session 缓存三大作用：  
1. 减少数据库的访问频率，提高访问性能
2. 保证缓存的对象与数据库同步，位于缓存中的对象称为持久化对象
3. 当持久化对象存在关联时，session保证不出现对象图的死锁

####Session什么时候清理缓存
1. commit()方法调用的时候
2. 查询时会清理缓存，保证查询结果能反映对象的最新状态
3. 显示调用session的flush方法
4.  


















session.query(User).options(joinedload('*')).get(id)
_session.close()
print user.comments  # OK
print user.posts  # OK
======
####Relattionship

#####一对多  （one to many）




mapping class link to table metadata  



    print session.query(func.count(User.id)).all()
    print session.query(func.count(User.id)).first()
    print session.query(func.count(User.id)).scalar()


    all()返回的是list，[(10,)]
    first()返回的是tuple，(10,)，就是all()里面的的第0个元组
    scalar()返回的就是单一值，元组中的第0个值，而且scalar只使用于当前返回的是单个值，比如all()里面返回的10


####Classic mapping

    from sqlalchemy import Table, MetaData
    from sqlalchemy.orm import mapper
    metadata = MetaData()
    subject = Table('subject', metadata,
                Column('id', Integer, primary_key=True),
                Column('title', String(100))
            )
    class Subject(object):
        def __init__(self, name):
            self.name = name
    metadata.create_all(engine)  #生成数据库表
    mapper(Subject,subject)   #建立映射


####Hybrid Attributes  混合属性
属性在类和实例上有特殊的行为  

    from sqlalchemy import Column, Integer
    from sqlalchemy.ext.declarative import declarative_base
    from sqlalchemy.orm import Session, aliased
    from sqlalchemy.ext.hybrid import hybrid_property, hybrid_method
    
    Base = declarative_base()
    
    class Interval(Base):
        __tablename__ = 'interval'
    
        id = Column(Integer, primary_key=True)
        start = Column(Integer, nullable=False)
        end = Column(Integer, nullable=False)
    
        def __init__(self, start, end):
            self.start = start
            self.end = end
    
        @hybrid_property
        def length(self):
            print self
            return self.end - self.start
    
        @hybrid_method
        def contains(self,point):
            return (self.start <= point) & (point < self.end)
    
        @hybrid_method
        def intersects(self, other):
            return self.contains(other.start) | self.contains(other.end)

这个hybrid_property和python中的@property有什么区别呢？区别就在这个hybrid上，既然是混合的属性，也就是说，既可以作为实例属性
也可以作为类属性，

    if __name__ == '__main__':
        Base.metadata.create_all(engine)
        i = Interval(5, 10)
        print i.length
        print Interval.length


输出结果是：

    <__main__.Interval object at 0x9cfdd8c> ----
    5
    <class '__main__.Interval'> ----
    interval."end" - interval.start

而Interval.length的type是

    <class 'sqlalchemy.sql.expression.BinaryExpression'>

那它有什么用呢？  

    Session().query(Interval).filter(Interval.length > 10)

它的用法看起来跟属性start、end一样的，而你却无需在数据库中像start、end一样定义一个字段，多好。  

那@hibrid_method有什么用呢？ ,如果是判断point是不是contains，直接:  

    i.contains(7) 
就好了啊，干嘛要用@hibrid_method呢？

    Session().query(Interval).filter(Interval.contains(15))
看到了吧，和hybrid_property有相似之处


####区别于属性的表达式装饰器

    from sqlalchemy import func
    
    class Interval(object):
        # ...
    
        @hybrid_property
        def radius(self):
            return abs(self.length) / 2
    
        @radius.expression
        def radius(cls):
            return func.abs(cls.length) / 2
    

这里为什么还要用radius.expression呢，对于查询：  

    Session().query(Interval).filter(Interval.radius > 5)
直接像length一样不行吗?当然不行，不信，注释掉radius.expression试试。  

    TypeError: bad operand type for abs(): 'BinaryExpression'
其实它接收的是一个sqlahclemy里面的函数，func.abs，因为这里面使用的length也是一个hybrid的属性

    @length.setter
    def length(self, value):
        self.end = self.start + value

也支持setter

####mapping class inheritance hierarchies 


使用memecache做缓存的时候，出现了错误：读取一篇article，异常信息：  

    DetachedInstanceError: Parent instance <Article at 0xb22da4c> is not bound to a Session; lazy load operation of attribute 'user' cannot proceed

访问代码：  

     session = DBSession()
        @cache_region('long_term')
        def func_to_cache(session):
            article = session.query(Article).get(articleId)
            return article
    
        article = func_to_cache(session)

这段代码的意思相当于：  
   
    article = mc.get(key)
    if not article:
        article = session.query(Article).get(articleid)
        mc.set(key, article)

因为Article类还关联了user  

    userId = Column('user_id', IdDataType, ForeignKey(
        'user_profile.user_id'), nullable=False)
    user = relationship(UserProfile)

默认SQLAlchemy的实体是使用Lazyload模式，也就是说只有真正访问article.user的时候才会去数据库查询该用户，而这里事先把article缓存起来了，在访问article的时候延迟查询所使用的session跟原对象的关联被切断了。没法触发sql查询了。可以使用 eager loading，通过joinedload()，
http://docs.sqlalchemy.org/en/latest/orm/inheritance.html
http://docs.sqlalchemy.org/en/latest/orm/loading.html



####错误总结:  
1.用column_property()函数做为类属性的时候:  

    Article.recommendCnt = column_property(select([func.count(ArticlePGoal.id)]).where(and_( 
                    Article.id == ArticlePGoal.articleId, 
                    ArticlePGoal.artType == ArticlePGoal.ART_TYPE_RECOMMEND, 
                    Article.id == ArticlePGoal.articleId, 
                    ~Article.isDeleted)))  
抛出的异常:  

    InvalidRequestError: Select statement 'SELECT count(article_pgoal.id) AS count_1 
    FROM article_pgoal, article 
    WHERE article.id = article_pgoal.article_id AND article_pgoal.art_type = %s AND article.id = article_pgoal.article_id AND NOT article.is_deleted' returned no FROM clauses due to auto-correlation; specify correlate(<tables>) to control correlation manually.

关键看错误信息的最后一句,它告诉我们需要手动指定关联的表  

    Article.recommendCnt = column_property(select([func.count(ArticlePGoal.id)]).where(and_( 
                    Article.id == ArticlePGoal.articleId, 
                    ArticlePGoal.artType == ArticlePGoal.ART_TYPE_RECOMMEND, 
                    Article.id == ArticlePGoal.articleId, 
                    ~Article.isDeleted)).correlate(Article.__table__))

2. 使用memecache做缓存的时候,异常:  

    DetachedInstanceError: Instance <Article at 0xb3b239ec> is not bound to a Session; attribute refresh operation cannot proceed

可以设置 `session.expire_on_commit = False`

####列与数据类型
http://docs.sqlalchemy.org/en/rel_0_9/core/types.html  
**BigInteger**对应数据库中的BIGINT
**Boolean**对应BOOLEAN或SAMLLINT,Python端是True或False
**Date**对应datetime.date()对象
**DateTime**就是datetime.datetime()对象
**Float**
**Integer**
**Interval**对应datetime.timedelta(),在数据库中如果是PostgreSQL对应本地的INTERVAL类型,其它数据库用date保存.(相对于1970,1,1)
**Text**继承自String,在SQL中使用CLOB或TEXT,一般没有长度
**Time**  datetime.time()
**Unicode**继承String,有length参数
**UnicodeText**



####映射类继承层次
SQLAlchemy支持三种形式的继承,**单表继承**, 多个类对应单独的一个表,**具体表继承**:

####Querying
http://docs.sqlalchemy.org/en/rel_0_9/orm/query.html#sqlalchemy.orm.query.Query.join

StringIO---像文件一样读写字符串
===============================
有些API仅接受文件对象，但是你只有一个字符串，比如使用gzip模块压缩字符串的时候，StringIO就可以派上用场了 

    import gzip
    import StringIO

    stringio = StringIO.StringIO()
    gzip_file = gzip.GzipFile(fileobj=stringio, mode='w')
    gzip_file.write('hello world')
    gzip_file.close()

    print stringio.getvalue()  #此方法必须是在stringio.close()调用前，否则ValueError

###cStringIO：性能更高的StringIO
cStringIO是一个速度更快的StringIO，其接口与StringIO基本类似，但是有以下区别：  
1. 不能构建任何版本的子类，因为它的构造方法返回的是一个built-in类型

        #coding:utf-8
        import StringIO
        
        stringio = StringIO.StringIO(u'helloworld我是')
        print type(stringio)    #<type 'instance'>
        stringio.size = 10      #可以给实例赋任何属性
        print stringio.getvalue()
        
        import cStringIO
        cs = cStringIO.StringIO(u'helloworld')
        print type(cs) #<type 'cStringIO.StringI'>
        cs.size = 10   #此处会报错，因为cStringIO.StringI没有属性size
        print cs.getvalue()
2. cStringIO不接收中文unicode字符

        cs = cStringIO.StringIO(u'helloworldi我是')
        #异常
        Traceback (most recent call last):
          File "test.py", line 10, in <module>
            cs = cStringIO.StringIO(u'helloworldi鎴戞槸')
        UnicodeEncodeError: 'ascii' codec can't encode characters in position 11-12: ordinal not in range(128)

####python3 StringIO
python3去掉了StringIO和cStringIO模块，取而代之的是io.StringIO，要写出兼容py2和py3的代码的话，使用：

    try:
        from cStringIO import StringIO  # py2
    except ImportError:
        from io import StringIO  # py3

Python测试指南
================================
####测试的种类
#####单元测试
#####集成测试
#####系统测试

####Doctest：最简单的测试工具
1. 创建一个名为test.txt的文件
2. 插入以下文本到文件中
        
        this is a simple doctest that checks some of Python's arithmetic operations
        >>> 2+2
        4
        >>> 3*3
        10
3. 现在就可以运行doctest了，进入该文件所在目录的命令行
4. 运行：(此方法治适用于python2.6及以上版本)

        python -m doctest test.txt
5. 运行后会看到如下结果：

        **********************************************************************
        File "text.txt", line 4, in text.txt
        Failed example:
            3*3
        Expected:
            10
        Got:
            9
        **********************************************************************
        1 items had failures:
           1 of   2 in text.txt
        ***Test Failed*** 1 failures.

####Doctest的语法 
`>>>`开头的代码将会发送给python解释器，`...`作为代码下一行的追加，允许嵌套一些复杂的代码块语句到doctest中去。




####使用单元测试写基础测试

    class RomanNumeralConverter(object):
        def __init__(self, roman_numeral):
            self.roman_numeral = roman_numeral
            self.digit_map = {
                                "M":1000, 
                                "D":500,
                                "C":100,
                                "L":50,
                                "X":10,
                                "V":5,
                                "I":1
                            }
        def convert_to_decimal(self):
            val = 0
            for char in self.roman_numeral:
                val += self.digit_map[char]
            return val

    import unittest
    class RomanNumeralConverterTest(unittest.TestCase):
        def test_parsing_millenia(self):
            value = RomanNumeralConverter("M")
            self.assertEquals(1000, value.convert_to_decimal())
            
        def test_no_roman_numeral(self):
            value = RomanNumeralConverter(None)
            self.assertRaises(TypeError, value.convert_to_decimal)

        def test_empty_roman_numeral(self):
            value = RomanNumeralConverter("")
            self.assertTrue(value.convert_to_decimal() == 0)
            self.assertFalse(value.convert_to_decimal() > 0)

尽可能使用assertEquals  

    setUp(self)
    tearDown(self)

每执行一个测试用例，就会执行一遍setUp和tearDown方法  

    setUpClass/tearDownClass

unittest模块提供了TestLoader().loadTestFromTestCase，可以自动地获取所有test*方法到一个测试套件中去。这个测试套件通过unittest的TextTestRunner运行。TextTestRunner是unittest仅有的Runner。  

    if __name__ == "__main__":
        import sys
        suite = unittest.TestSuite()

单元测试是个好东西，但是如果代码中多处有数据库访问（读/写），或者代码中包含一些复杂的对象，真实环境中难以被触发的对象的时候，该如何写单元测试呢？

使用模拟对象机制测试python代码，模拟对象（mock object）可以取代真实对象的位置，用于测试一些与真实对象进行交互或依赖真实对象的功能，模拟对象的目的就是创建一个轻量级的，可控制的对象来代替测试中需要的真实对象，模拟真实对象的行为和功能，方便测试。

###Stub和Mock以及Fake的理解
> Stub:
> For replacing a method with code that returns a specified result

简单来说就是可以用stub去fake（伪造）一个方法，阻断原来方法的调用
> Mock:
> A stub with an expectations that the method gets called

简单来说mock就是stub + expectation, 说它是stub是因为它也可以像stub一样伪造方法,阻断对原来方法的调用, expectation是说它不仅伪造了这个方法,还期望你(必须)调用这个方法,如果没有被调用到,这个test就fail了

> Fake:
> objects actually have working implementations, but usually take some shortcut which makes them not suitable for production

简单来说就是一个真实对象的一个轻量级的完整实现


mock对象的使用范畴：
真实对象具有不可确定的行为，产生不可预测的结果（如：天气预报）
真实对象很难被创建
真实对象的某些行为很难被触发


###Fudge
Fudge是一个类似于Java中的JMock的纯python的mock测试模块，主要功能就是可以伪造对象，替换代码中真实的对象，来完成测试。fudge主要用来模拟那些在应用中不容易构造或者比较复杂的对象（如项目中涉及mongodb或者redis模块，使用fudge后在测试的时候可以不需要真正的redis环境就能测试代码），从而使测试顺利进行。  

####如何使用fudge

    import twitter_oauth   #pip install twitter_oauth
    
    consumer_key = '***'
    consumer_secret = '***'
    oauth_token = "***"
    oauth_token_secret = '***'
    
    
    def post_msg_to_twitter(msg):
        # create GetOauth instance
        get_oauth_obj = twitter_oauth.GetOauth(consumer_key, consumer_secret)
        # create Api instance
        api = twitter_oauth.Api(consumer_key, consumer_secret, oauth_token, oauth_token_secret)
        # post update
        api.post_update(u'Hello, Twitter:' + msg)
        print("send:%s" % msg)

因为`twitter_oauth`是独立的模块，因此只要调用了正确的方法，`post_msg_to_twitter`方法就一定能正确执行。Twitter在大陆没法直接请求访问，那怎么测试知道它没有问题呢? 使用fudge就能完成我们的任务，把twitter相关的对象伪造(fake)出来，只要我们自己的业务逻辑测试正确，那么测试就通过。    

    import fudge


    @fudge.patch('twitter_oauth.GetOauth', 'twitter_oauth.Api')
    def test_post_msg_to_twitter(msg, FakeGetOauth, FakeApi):
        FakeGetOauth.expects_call() \
            .with_args('***', '***')
    
        FakeApi.expects_call() \
            .with_args('***', '***', '***', '***') \
            .returns_fake() \
            .expects('post_update').with_args(u'Hello, Twitter:okey')
    
        post_msg_to_twitter(msg)
    
    
    if __name__ == '__main__':
        test_post_msg_to_twitter('okey')


* patch装饰器会在测试阶段根据装饰器里面的参数伪造对象，作为测试方法`test_post_to_twitter`的参数。这些伪造的对象就是stub或者mock或者是fake  
* Fudge可以根据你的需求严谨或随意的声明expectation。
    * 如果你不关心具体的参数，就可以调用`fudge.Fake.with_args()`不需要指定任何参数，如果要指定的话就必须是指定正确的参数（换句话说就是不能随意指定）
    * 如果你不关心方法调用与否，那么就可以用`fudge.Fake.provides()`代替`fudge.Fake.expects()`，这样即使代码中没有调用，测试用例也不会fail
    * 如果不关心方法的参数的具体值，那么可以用`fudge.Fake.with_arg_count()`来代替`fudge.Fake.with_args()`


###fudge模块
####fudge
* fudge.patch(*obj_paths)：测试装饰器，里面的参数都将作为fake对象将导出作为测试方法的参数使用。

        @fudge.patch('os.remove')
        def test(fake_remove):
            #do sutff
    patch方法会去调用fudge.clear\_calls()，fudge.verify()和fudge.clear\_expectations()，verify()方法才是真正验证所有方法是不是按照期待的那些调用了。
        
        def test():
            db = fudge.Fake('db').expects('connect')
            # fudge.verify()
    上面这个test函数如果没有用fudge.patch(), fudge.test() 或者 fudge.with_fakes()修饰，那么fudge就不会主动去验证方法是否得到执行，必须加上fudge.verify()方法才会触发调用。加上verify()就会提示你connect没有被调用：

        File "E:\Python27\lib\site-packages\fudge-1.0.3-py2.7.egg\fudge\__init__.py", line 453, in assert_called
            raise AssertionError("%s was not called" % (self))
        AssertionError: fake:db.connect() was not called
* fudge.test：装饰器，直接使用fake，而不是通过patch

        @fudge.test
        def test():
            db = fudge.Fake('db').expects('connect')
    不过绝大多数时候你都应该使用fudge.patch而不是fudge.test

* fudge.Fake：这个一个类，用来替换真实对象的fake对象，如上例

* fudge.calls(call)：重新定义一个call，相当于给call换一个名字

        def hello():
            print "hello there"
        
        def test_calls():
            f = fudge.Fake().provides("anthor_hello").calls(hello)
            f.anthor_hello()  #输出"hello there"

* expects(call_name)：表示期待调用call\_name方法
* expects_call()：表示该对像将得到调用
* provides(call_name)：这个方法与expects的区别是call\_name可以没有被调用

更多参考：[fudge](http://farmdev.com/projects/fudge/api/fudge.html)

####fudge.inspector
`fudge.inspector.ValueInspector`实例可以作为一种更具表现力的对象（Value inspector）传递给`fudge.Fake.with_args()`方法，为了更方便记忆ValueInspector实例简称为`arg`：  
    
    from fudge.inspector import arg
    image = fudge.Fake('image').expects('save').with_args(arg.endswith('.jpg'))
上面的测试代码就表示传递给save方法的参数必须是以`.jpg`结尾的值，否则测试没法通过

* arg.any()：表示没有任何约束
* contains(part)：必须包含指定的part参数
* has_attr(**attributes)：传递给方法的参数必须有属性在指定的attributes中
    
        class User:
            first_name="Bob"
            last_name = "James"
            job = "jazz musician"
        
        
        def test_has_attr():
            from fudge.inspector import arg
            db = fudge.Fake('db').expects("update").with_args(arg.has_attr(
                first_name="Bob",
                last_name="James"
            ))
            db.update(User())
* passes_test(test)：参数传递到test函数中必须返回True才能通过测试

        def is_valid(s):
            assert s in ['apple', 'ms', 'fb'], ('unexpected company %s' % s)
            return True
        
        def test_passes_test():
            system  = fudge.Fake('system').expects('set_company').with_args(arg.passes_test(is_valid))
            system.set_company('fb')
        
* startswith(part)：参数必须以part开头

更多参考：[fudge.inspector](http://farmdev.com/projects/fudge/api/fudge.inspector.html)

####fudge.patcher
* fudge.patcher.with\_patched\_object(obj, attr\_name, patched\_value)：装饰器，在被装饰的方法调用前给attr_name一个新的值patched\_value，方法执行完以后attr\_name再恢复成原来的值

        from fudge import with_patched_object
        
        class Session:
            state = 'clean'
            
        @with_patched_object(Session, "state", 'dirty')
        def test():
            print(Session.state)
        
        if __name__ == "__main__":
            test()
            print (Session.state)
    输出：

        dirty
        clean
    这样做的好处就是能独立于每个测试而不影响原来对象的完整性。

* fudge.pathcher.patched\_context(obj, attr\_name, patched\_value)：作用和上面的with\_patched\_object一样，只是用法上不一样而已，他的用法是：

        with patched_context(Session, 'state', 'dirty'):
            print Sessioin.state
就是[with语句](http://www.python.org/dev/peps/pep-0343/)的使用方式。

####tornado.test
由于python的单元测试模块式同步的，测试tornado中的异步代码有三种方式

1. 使用类似tornado.gen的yield生成器 tornado.testing.gen_test.

        class MyTestCase(AsyncTestCase):
        @tornado.testing.gen_test
        def test_http_fetch(self):
            client = AsyncHTTPClient(self.io_loop)
            response = yield client.fetch("http://www.tornadoweb.org")
            # Test contents of response
            self.assertIn("FriendFeed", response.body)
2. 手工方式调用self.stop，self.wait
        
        class MyTestCase2(AsyncTestCase):
            def test_http_fetch(self):
                client = AsyncHTTPClient(self.io_loop)
                client.fetch("http://www.tornadoweb.org/", self.stop)
                response = self.wait()
                # Test contents of response
                self.assertIn("FriendFeed", response.body)
3. 回调函数的方式：

        class MyTestCase3(AsyncTestCase):
            def test_http_fetch(self):
                client = AsyncHTTPClient(self.io_loop)
                client.fetch("http://www.tornadoweb.org/", self.handle_fetch)
                self.wait()
            def handle_fetch(self, response):
                #此处产生的异常会通过stack+context传播到self.wait方法中去
                self.assertIn("FriendFeed", response.body)
                self.stop()

后两者的原理是一样的，wait方法会一直运行IOLoop，直到stop方法调用或者超时（timeout默认是5's）2中的fetch的第二个参数self.stop相当于3中的self.handle_fetch，都是一个回调函数，区别就在于把sotp当成回调函数时，响应内容就会通过self.wait()函数返回，而像3中一样写一个自定义的回调函数，响应内容就会作为参数传递给该函数。可以详细查看下[tornado.testing.py](http://www.tornadoweb.org/en/stable/_modules/tornado/testing.html)这个文件中的stop和wait方法。

默认情况下，每个单元会构造一个新的IOLoop实例，这个IOLoop是在构造HTTP clients/servers的时候使用。如果测试需要一个全局的IOLoop，那么就需要重写get_new_ioloop方法。 源码：

    def setUp(self):
        super(AsyncTestCase, self).setUp()
        self.io_loop = self.get_new_ioloop()
        self.io_loop.make_current()

    def get_new_ioloop(self):
            """Creates a new `.IOLoop` for this test.  May be overridden in
            subclasses for tests that require a specific `.IOLoop` (usually
            the singleton `.IOLoop.instance()`).
            获取全局IOLoop时，调用IOLoop.instance()这个单例方法即可
            """
            return IOLoop()

* tornado.testing.AsyncHTTPTestCase  
这个类是AsyncTestCase的子类，一个测试用例会启动一个HTTP server，AsyncHTTPTestCase的子类必须重写`get_app()`方法，这个方法返回`tornado.web.Application`实例。application实例就是实际代码的application。  

        app = tornado.web.Application(handlers=[
               (r'/sleep', SleepHandler),
               (r'/now', JustNowHandler)
           ])
    返回这个app就好了。测试用例通常使用`self.http_client`来请求（fetch）这个server上的url。

        class MyHTTPTest(AsyncHTTPTestCase):
            def get_app(self):
                app = tornado.web.Application(handlers=[
                       (r'/sleep', SleepHandler),
                       (r'/now', JustNowHandler)
                ])
                return app
            def test_now(self):
                self.http_client.fetch(self.get_url('/'), self.stop)
                response = self.wait()
                self.assertIn('xx', response.body)  #判断返回的请求体中是否有字符串`xx`

    其实self.http_client就是一个AsyncHTTPClient实例，从源码中查看到：  

        def get_http_client(self):
            return AsyncHTTPClient(io_loop=self.io_loop)

####fakeredis
[fakeredis](https://github.com/jamesls/fakeredis)是[redis-py](https://github.com/andymccurdy/redis-py)的实现，模拟redis服务器通信的模块。应用场景只有一个：写单元测试。

Python 实用技巧
-----------------
本文整理自SO上的热门问答[hidden features of python](http://stackoverflow.com/questions/101268/hidden-features-of-python?rq=1)，早期有人做过类似的整理，但是内容比较旧而且比较粗糙，因此笔者在原文基础上加入自己的一些理解，另外那些高质量的评论也引入进来了。总之，这是一篇用心之作，希望你可以喜欢。
####链式比较操作

    >>> x = 5
    >>> 1 < x < 10
    True
    >>> 10 < x < 20 
    False
    >>> x < 10 < x*10 < 100
    True
    >>> 10 > x <= 9
    True
    >>> 5 == x > 4
    True

你可能认为它执行的过程先是：`1 < x`，返回`True`，然后再比较`True < 10`,当然这么做也是返回`True`,比较表达式`True < 10`,因为解释器会把`True`转换成`1`，`False`转换成`0`。但这里的链式比较解释器在内部并不是这样干的，它会把这种链式的比较操作转换成：`1 < x and x < 10`，不信你可以看看最后一个例子。这样的链式操作本可以值得所有编程语言拥有，但是很遗憾  

####枚举

    >>> a = ['a', 'b', 'c', 'd', 'e']
    >>> for index, item in enumerate(a): print index, item
    ...
    0 a
    1 b
    2 c
    3 d
    4 e
    >>>
用enumerate包装一个可迭代对象,可以同时使用迭代项和索引，如果你不这么干的话，下面有一种比较麻烦的方法：  

    for i in range(len(a)):
        print i, a[i]

enumerate 还可以接收一个可选参数start，默认start等于0。`enumerate(list, start=1)`，这样index的起始值就是1  

####生成器对象

    x=(n for n in foo if bar(n))  #foo是可迭代对象
    >>> type(x)
    <type 'generator'>
你可以把生成器对象赋值给x，意味着可以对x进行迭代操作：  

    for n in x:
        pass
它的好处就是不需要存储中间结果，也许你会使用（列表推倒式）：  

    x = [n for n in foo if bar(n)]
    >>> type(x)
    <type 'list'>
它比生成器对象能带来更快的速度。相对地，生成器更能节省内存开销，它的值是按需生成，不需要像列表推倒式一样把整个结果保存在内存中，同时它不能重新迭代，列表推倒式则不然。  

####iter()可接收callable参数
iter()内建函数接收的参数分为两种，第一种是：  
    
    iter(collection)---> iterator
参数collection必须是可迭代对象或者是序列 ，第二种是：  

    iter（callable， sentinel) --> iterator
callable函数会一直被调用，直到它的返回结果等于sentinel，例如：  

    def seek_next_line(f):
        #每次读一个字符，直到出现换行符就返回
        for c in iter(lambda: f.read(1),'\n'):  
            pass

####小心可变的默认参数

    >>> def foo(x=[]):
    ...     x.append(1)
    ...     print x
    ... 
    >>> foo()
    [1]
    >>> foo()
    [1, 1]
    >>> foo()
    [1, 1, 1]

取而代之的是你应该使用一个标记值表示“没有指定”来替换可变值,如：  

    >>> def foo(x=None):
    ...     if x is None:
    ...         x = []
    ...     x.append(1)
    ...     print x
    >>> foo()
    [1]
    >>> foo()
    [1]

####发送值到生成器函数在中

    def mygen():
        """Yield 5 until something else is passed back via send()"""
        a = 5
        while True:
            f = (yield a) #yield a and possibly get f in return
            if f is not None: 
                a = f  #store the new value
你可以：  

    >>> g = mygen()
    >>> g.next()
    5
    >>> g.next()
    5
    >>> g.send(7)  #we send this back to the generator
    7
    >>> g.next() #now it will yield 7 until we send something else
    7

####如果你不喜欢使用空格缩进，那么可以使用C语言花括号{}定义函数：  

    >>> from __future__ import braces   #这里的braces 指的是：curly braces（花括号）
      File "<stdin>", line 1
    SyntaxError: not a chance

当然这仅仅是一个玩笑，想用花括号定义函数？没门。感兴趣的还可以了解下：  

    from __future__ import barry_as_FLUFL

不过这是python3里面的特性，http://www.python.org/dev/peps/pep-0401/  

####切片操作中的步长参数

    a = [1,2,3,4,5]
    >>> a[::2]  # iterate over the whole list in 2-increments
    [1,3,5]
还有一个特例：`x[::-1]`，反转列表：  

    >>> a[::-1]
    [5,4,3,2,1]
有关反转，还有两个函数reverse、reversed，reverse是list对象的方法，没有返回值，而reversed是内建方法，可接收的参数包括tuple、string、list、unicode，以及用户自定义的类型，返回一个迭代器。  

    >>> l = range(5)
    >>> l
    [0, 1, 2, 3, 4]
    >>> l.reverse()
    >>> l
    [4, 3, 2, 1, 0]
    >>> l2 = reversed(l)
    >>> l2
    <listreverseiterator object at 0x99faeec>
####装饰器
装饰器使一个函数或方法包装在另一个函数里头，可以在被包装的函数添加一些额外的功能，比如日志，还可以对参数、返回结果进行修改。装饰器有点类似Java中的AOP。下面这个例子是打印被装饰的函数里面的参数的装饰器，  

    >>> def print_args(function):
    >>>     def wrapper(*args, **kwargs):
    >>>         print 'Arguments:', args, kwargs
    >>>         return function(*args, **kwargs)
    >>>     return wrapper
    
    >>> @print_args
    >>> def write(text):
    >>>     print text
    
    >>> write('foo')
    Arguments: ('foo',) {}
    foo

@是语法糖，它等价于：  

    >>> write = print_args(write)
    >>> write('foo')
    arguments: ('foo',) {}
    foo

####for ... else语法

    for i in foo:
        if i == 0:
            break
    else:
        print("i was never 0")
else代码块只有在for循环正常结束后执行如果遇到break语句那么不会执行else语句块，等价于下面：  

    found = False
    for i in foo:
        if i == 0:
            found = True
            break
    if not found: 
        print("i was never 0")
不过这种语法看起来怪怪地，让人感觉是else块是在for语句块没有执行的时候执行的，很容易让人去类比 if else 的语法，如果是把else换成finally或许更容易理解    

####python2.5有个`__missing__`方法
dict的子类如果定义了方法`__missing__(self, key)`，如果key不再dict中，那么d[key]就会调用`__missing__`方法，而且d[key]的返回值就是`__missing__`的返回值。  

    >>> class MyDict(dict):
    ...  def __missing__(self, key):
    ...   self[key] = rv = []
    ...   return rv
    ... 
    >>> m = MyDict()
    >>> m["foo"].append(1)
    >>> m["foo"].append(2)
    >>> dict(m)
    {'foo': [1, 2]}

在collections模块下有一个叫defaultdict的dict子类，它与missing非常类似，但是对于不存在的项不需要传递参数。  

    >>> from collections import defaultdict
    >>> m = defaultdict(list)
    >>> m["foo"].append(1)
    >>> m["foo"].append(2)
    >>> dict(m)
    {'foo': [1, 2]}

####变量值交换

    >>> a = 10
    >>> b = 5
    >>> a, b
    (10, 5)
    
    >>> a, b = b, a
    >>> a, b
    (5, 10)

等号右边是一个创建元组的表达式，等号左边解压（没有引用的）元组分别赋给名称（变量）a和b。赋完值后因为没有被其他名字引用，因此被标记之后被垃圾收集器回收，而绑定到a和b的值已经被交换了。  
注意：多值赋值其实仅仅就是元组打包和序列解包的组合的过程  

####可读的正则表达式
在Python中你可以把正则表达式分割成多行写，还可以写注释  

    >>> pattern = """
    ... ^                   # beginning of string
    ... M{0,4}              # thousands - 0 to 4 M's
    ... (CM|CD|D?C{0,3})    # hundreds - 900 (CM), 400 (CD), 0-300 (0 to 3 C's),
    ...                     #            or 500-800 (D, followed by 0 to 3 C's)
    ... (XC|XL|L?X{0,3})    # tens - 90 (XC), 40 (XL), 0-30 (0 to 3 X's),
    ...                     #        or 50-80 (L, followed by 0 to 3 X's)
    ... (IX|IV|V?I{0,3})    # ones - 9 (IX), 4 (IV), 0-3 (0 to 3 I's),
    ...                     #        or 5-8 (V, followed by 0 to 3 I's)
    ... $                   # end of string
    ... """
    >>> re.search(pattern, 'M', re.VERBOSE)




####函数参数解包(unpacking)
分别使用`*`和`**`解包列表和字典,这是一种非常实用的快捷方式,因为list,tuple,dict作为容器被广泛使用    

    def draw_point(x, y):
        # do some magic
    
    point_foo = (3, 4)
    point_bar = {'y': 3, 'x': 2}
    
    draw_point(*point_foo)
    draw_point(**point_bar)

####动态地创建新类型
动态创建新类型虽不是实用功能,但了解一下也是有好处的  

    >>> NewType = type("NewType", (object,), {"x": "hello"})
    >>> n = NewType()
    >>> n.x
    "hello"
type的第一个参数就是类名,第二个参数是继承的父类,第三个参数是类的属性.它完全等同于:  

    >>> class NewType(object):
    >>>     x = "hello"
    >>> n = NewType()
    >>> n.x
    "hello"

####上下文管理器与with语句
上下文管理器(context manager)用于规定某个对象的使用范围,进入或退出该范围时,特殊的操作会被执行(比如关闭连接,释放内存等等),语法是:`with... as ...`,该特性在python2.5引入的.
上下文管理器协议有两个方法组成`contextmanager.__enter__()`和`contextmanager.__exit__()`,任何实现了这两个方法的对象都称之为上下文管理器对象,比如文件对象就默认实现了该协议.

    with open('foo.txt', 'w') as f:
        f.write('hello!')
####字典的get()方法
字典的get()方法用来替换d['key'],后者如果是遇到key不存在会有异常,如果使用的d.get('key'),key不存在时它返回的是None,你可以指定两个参数如:d.get('key',0)来用0取代返回的None  

    sum[value] = sum.get(value, 0) + 1
还有一个类似的方法`setdefault(key, value)`,如果字典中存在key,那么就直接返回d[key],否则设置d[key]=value,并返回该值.  

    >>> d = {'key':123}
    >>> d.setdefault('key',456)
    123
    >>> d['key']
    123
    >>> d.setdefault('key2',456)
    456
    >>> d['key2']
    456

collections.Counter是dict的子类,用来统计可哈稀对象,

    >>> cnt = Counter('helloworld')
    >>> cnt
    Counter({'l': 3, 'o': 2, 'e': 1, 'd': 1, 'h': 1, 'r': 1, 'w': 1})
    >>> cnt['l']
    3
    >>> cnt['x'] = 10
    >>> cnt.get('y')

####描述符(Descriptors)
描述符是python的核心特新之一,当你使用`.`访问成员时,(如:x.y),python首先在实例字典中查找该成员,如果没有发现再从类字典中查找,如果这个对象实现了描述符(实现了`__get__,__set__,__delete__`),那么优先返回`__get__`方法的返回值.  

####条件赋值
为什么python中没有类c语言的三目运算符,Guido van Rossum说过了,条件赋值更容易理解  

    x = 3 if (y == 1) else 2
这个表达式的意思就是:如果y等于那么就把3赋值给x,否则把2赋值给x, 条件中的括号是可选的,为了可读性可以考虑加上去.if else中的表达式可以是任何类型的,既可以函数,还可以类  

    (func1 if y == 1 else func2)(arg1, arg2) 
如果y等于1,那么调用func1(arg1,arg2)否则调用func2(arg1,arg2)  

    x = (class1 if y == 1 else class2)(arg1, arg2)
class1,class2是两个类  

####异常else语句块

    try:
       try_this(whatever)
    except SomeException, exception:
       #Handle exception
    else:
        # do something
    finally:
        #do something
else语句块会在没有异常的情况下执行,先于finally,它的好处就是你可以明确知道它会在没有异常的情况下执行,如果是把else语句块放在try语句块里面就达不到这种效果.  



virtualenv
--------------
virtualenv用于创建独立的Python环境，多个Python相互独立，互不影响，它能够：  
1. 在没有权限的情况下安装新套件  
2. 不同应用可以使用不同的套件版本  
3. 套件升级不影响其他应用  

####安装 

    sudo apt-get install python-virtualenv
####使用方法

    virtualenv [虚拟环境名称] 
如，创建**ENV**的虚拟环境  

    virtualenv ENV
默认情况下，虚拟环境会依赖系统环境中的site packages，就是说系统中已经安装好的第三方package也会安装在虚拟环境中，如果不想依赖这些package，那么可以加上参数 `--no-site-packages`建立虚拟环境  

    virtualenv --no-site-packages [虚拟环境名称]

####启动虚拟环境

    cd ENV
    source ./bin/activate

注意此时命令行会多一个`(ENV)`，ENV为虚拟环境名称，接下来所有模块都只会安装到该目录中去。

####退出虚拟环境  
    
    deactivate

####在虚拟环境安装Python套件  

Virtualenv 附带有pip安装工具，因此需要安装的套件可以直接运行：  
    
    pip install [套件名称]
如果没有启动虚拟环境，系统也安装了pip工具，那么套件将被安装在系统环境中，为了避免发生此事，可以在`~/.bashrc`文件中加上：  
    
    export PIP_REQUIRE_VIRTUALENV=true
或者让在执行pip的时候让系统自动开启虚拟环境：  

    export PIP_RESPECT_VIRTUALENV=true

####Virtualenvwrapper
Virtaulenvwrapper是virtualenv的扩展包，用于更方便管理虚拟环境，它可以做：  
1. 将所有虚拟环境整合在一个目录下  
2. 管理（新增，删除，复制）虚拟环境  
3. 切换虚拟环境  
4. ...  
#####安装

    sudo easy_install virtualenvwrapper  
此时还不能使用virtualenvwrapper，默认virtualenvwrapper安装在/usr/local/bin下面，实际上你需要运行virtualenvwrapper.sh文件才行，先别急，打开这个文件看看,里面有安装步骤，我们照着操作把环境设置好。  

1. 创建目录用来存放虚拟环境

        mkdir $HOME/.virtualenvs
2. 在~/.bashrc中添加行： *export WORKON_HOME=$HOME/.virtualenvs*
3. 在~/.bashrc中添加行：*source /usr/local/bin/virtualenvwrapper.sh*
4. 运行： `source    ~/.bashrc`

此时virtualenvwrapper就可以使用了。 

列出虚拟环境列表  
    
    workon
也可以使用  

    lsvirtualenv
新建虚拟环境  
    
    mkvirtualenv [虚拟环境名称]

启动/切换虚拟环境  
    
    workon [虚拟环境名称]

删除虚拟环境  

    rmvirtualenv [虚拟环境名称]

离开虚拟环境  
    
    deactivate


参考：  
http://www.virtualenv.org/en/latest/  
http://stackoverflow.com/questions/11372221/virtualenvwrapper-not-found  
http://www.openfoundry.org/tw/tech-column/8516-pythons-virtual-environment-and-multi-version-programming-tools-virtualenv-and-pythonbrew  
http://virtualenvwrapper.readthedocs.org/en/latest/index.html  



深入理解WSGI
===================
WSGI是什么?是一种规范,用来规范Python web应用与服务器之间通信的标准.好比你和老外说话也需要建立一种事先制定的语言来沟通一样.如果今天你碰一德国人,然后你就去学德语,如果碰到日本人,然后去学日语,这样累死了,干脆定一种标准,大家都说英语好了.全世界通用.同样的道理,在python语言中,web框架多如牛毛,这么多框架如果大家都不遵守规则,然后写服务器也没啥规范,这个世界就乱套了.因此python2.5就提出了WSGI, [PEP3333](http://www.python.org/dev/peps/pep-3333/).

####python web 框架有哪些?

1. Django
2. Pyramid
3. Tornado
4. Flask
5. web.py
.....
####python wsgi server有那些?

1. CherryPy WSGI Server  

    cherrypy除了作为web server外,其实他还是一个web framework ,其宣称是"A high-speed, production ready, thread-pooled,generic HTTP server". 
2. Gunicorn  

    gunicorn就是一个纯粹的web server.他使用的pre-fork模型,使用一个central master 进程,用来管理多个worker processes.,这些worker processes 直接处理请求.  

3. Tornado  
    
    Tornado同时是web应用开发框架和网络库,用来处理异步操作.同时有自己的WSGI server.

4. Twisted Web

    Twisted Web 来自于 Twisted 网络库

5. uWSGI

    uWSGI是一个很全面的项目,目标是提供全栈式服务,uWSGI server 就是其中的一个组建.

6. mod_wsgi
    
    mod_wsgi是一个WSGI兼容的模块,能够在Apache HTTP Server 上运行 WSGI应用.

####wsgi对web框架/应用的规范是怎样的?
WSGI应用接口由一个callable对象实现,这个callable对象可以是function,method,class,或者是显现的__call__的实例方法.这个callable只要满足以下两个条件:  
* 必须接收两个位置参数
    * 字典对象
    * 一个回调函数,用于发送HTTP 状态码/消息和HTTP头给server.
* 必须返回响应体给 server,返回对象作为字符串包装在迭代器里面.

####application/framework
application的骨架代码:   

    #这个就是我们的application 对象, 名字随便取,但是如果你用mod_wsgi的话,就必须叫"application"
    def application(#接收两个参数
            #字典对象,包含类似CGI的环境参数,从客户端接收过来的请求有server填充
            environ,
            #start_response是一个回调函数,由server提供.用来发送HTTP status和header给server
            start_response):
    
        #响应体
        response_body = "The request method was %s" % environ['REQUEST_METHOD']
        #状态码
        status = "200 OK"
        
        #响应头
        response_headers = [('Content-Type':'text/plain'),
                            ('Content-Length':str(len(response_body)))]
        #发送给server
        start_response(status, response_headers)
    
        #把响应体返回给server
        #注意:尽管response_body是一个iterable,但是要包装成list,否则server会单个字节的发送给client.
        return [response_body]

####web server size
python标准库中提供了wsgiref模块提供了一个参考实现.
    
    from wsgiref import make_server
    
    httpd = make_server(
        'localhost',
        8000,
        application
        )
    httpd.handle_request()
    
####middleware 
middleware要尽可能透明  

单元测试是个好东西，但是如果代码中多处有数据库访问（读/写），或者代码中包含一些复杂的对象，真实环境中难以被触发的对象的时候，该如何写单元测试呢？

使用模拟对象机制测试python代码，模拟对象（mock object）可以取代真实对象的位置，用于测试一些与真实对象进行交互或依赖真实对象的功能，模拟对象的目的就是创建一个轻量级的，可控制的对象来代替测试中需要的真实对象，模拟真实对象的行为和功能，方便测试。

###Stub和Mock以及Fake的理解
> Stub:
> For replacing a method with code that returns a specified result

简单来说就是可以用stub去fake（伪造）一个方法，阻断原来方法的调用
> Mock:
> A stub with an expectations that the method gets called

简单来说mock就是stub + expectation, 说它是stub是因为它也可以像stub一样伪造方法,阻断对原来方法的调用, expectation是说它不仅伪造了这个方法,还期望你(必须)调用这个方法,如果没有被调用到,这个test就fail了

> Fake:
> objects actually have working implementations, but usually take some shortcut which makes them not suitable for production
简单来说就是一个真实对象的一个轻量级的完整实现


mock对象的使用范畴：
真实对象具有不可确定的行为，产生不可预测的结果（如：天气预报）
真实对象很难被创建
真实对象的某些行为很难被触发


###Fudge
Fudge是一个类似于Java中的JMock的纯python的mock测试模块，主要功能就是可以伪造对象，替换代码中真实的对象，来完成测试。fudge主要用来模拟那些在应用中不容易构造或者比较复杂的对象（如项目中涉及mongodb或者redis模块，使用fudge后在测试的时候可以不需要真正的redis环境就能测试代码），从而使测试顺利进行。  

####如何使用fudge

    import twitter_oauth   #pip install twitter_oauth
    
    consumer_key = '***'
    consumer_secret = '***'
    oauth_token = "***"
    oauth_token_secret = '***'
    
    
    def post_msg_to_twitter(msg):
        # create GetOauth instance
        get_oauth_obj = twitter_oauth.GetOauth(consumer_key, consumer_secret)
        # create Api instance
        api = twitter_oauth.Api(consumer_key, consumer_secret, oauth_token, oauth_token_secret)
        # post update
        api.post_update(u'Hello, Twitter:' + msg)
        print("send:%s" % msg)

因为`twitter_oauth`是独立的模块，因此只要调用了正确的方法，`post_msg_to_twitter`方法就一定能正确执行。Twitter在大陆没法直接请求访问，那怎么测试知道它没有问题呢? 使用fudge就能完成我们的任务，把twitter相关的对象伪造(fake)出来，只要我们自己的业务逻辑测试正确，那么测试就通过。    

    import fudge


    @fudge.patch('twitter_oauth.GetOauth', 'twitter_oauth.Api')
    def test_post_msg_to_twitter(msg, FakeGetOauth, FakeApi):
        FakeGetOauth.expects_call() \
            .with_args('***', '***')
    
        FakeApi.expects_call() \
            .with_args('***', '***', '***', '***') \
            .returns_fake() \
            .expects('post_update').with_args(u'Hello, Twitter:okey')
    
        post_msg_to_twitter(msg)
    
    
    if __name__ == '__main__':
        test_post_msg_to_twitter('okey')


* patch装饰器会在测试阶段根据装饰器里面的参数伪造对象，作为测试方法`test_post_to_twitter`的参数。这些伪造的对象就是stub或者mock或者是fake  
* Fudge可以根据你的需求严谨或随意的声明expectation。
    * 如果你不关心具体的参数，就可以调用`fudge.Fake.with_args()`不需要指定任何参数，如果要指定的话就必须是指定正确的参数（换句话说就是不能随意指定）
    * 如果你不关心方法调用与否，那么就可以用`fudge.Fake.provides()`代替`fudge.Fake.expects()`，这样即使代码中没有调用，测试用例也不会fail
    * 如果不关心方法的参数的具体值，那么可以用`fudge.Fake.with_arg_count()`来代替`fudge.Fake.with_args()`


###fudge模块
####fudge
* fudge.patch(*obj_paths)：测试装饰器，里面的参数都将作为fake对象将导出作为测试方法的参数使用。

        @fudge.patch('os.remove')
        def test(fake_remove):
            #do sutff
    patch方法会去调用fudge.clear\_calls()，fudge.verify()和fudge.clear\_expectations()，verify()方法才是真正验证所有方法是不是按照期待的那些调用了。
        
        def test():
            db = fudge.Fake('db').expects('connect')
            # fudge.verify()
    上面这个test函数如果没有用fudge.patch(), fudge.test() 或者 fudge.with_fakes()修饰，那么fudge就不会主动去验证方法是否得到执行，必须加上fudge.verify()方法才会触发调用。加上verify()就会提示你connect没有被调用：

        File "E:\Python27\lib\site-packages\fudge-1.0.3-py2.7.egg\fudge\__init__.py", line 453, in assert_called
            raise AssertionError("%s was not called" % (self))
        AssertionError: fake:db.connect() was not called
* fudge.test：装饰器，直接使用fake，而不是通过patch

        @fudge.test
        def test():
            db = fudge.Fake('db').expects('connect')
    不过绝大多数时候你都应该使用fudge.patch而不是fudge.test

* fudge.Fake：这个一个类，用来替换真实对象的fake对象，如上例

* fudge.calls(call)：重新定义一个call，相当于给call换一个名字

        def hello():
            print "hello there"
        
        def test_calls():
            f = fudge.Fake().provides("anthor_hello").calls(hello)
            f.anthor_hello()  #输出"hello there"

* expects(call_name)：表示期待调用call_name方法
* expects_call()：表示该对应将得到调用
* provides(call_name)：这个方法与expects的区别是call_name可以没有被调用

更多参考：[fudge](http://farmdev.com/projects/fudge/api/fudge.html)

####fudge.inspector
`fudge.inspector.ValueInspector`实例可以作为一种更具表现力的对象（Value inspector）传递给`fudge.Fake.with_args()`方法，为了更方便记忆ValueInspector实例简称为`arg`：  
    
    from fudge.inspector import arg
    image = fudge.Fake('image').expects('save').with_args(arg.endswith('.jpg'))
上面的测试代码就表示传递给save方法的参数必须是以`.jpg`结尾的值，否则测试没法通过

* arg.any()：表示没有任何约束
* contains(part)：必须包含指定的part参数
* has_attr(**attributes)：传递给方法的参数必须有属性在指定的attributes中
    
        class User:
            first_name="Bob"
            last_name = "James"
            job = "jazz musician"
        
        
        def test_has_attr():
            from fudge.inspector import arg
            db = fudge.Fake('db').expects("update").with_args(arg.has_attr(
                first_name="Bob",
                last_name="James"
            ))
            db.update(User())
* passes_test(test)：参数传递到test函数中必须返回True才能通过测试

        def is_valid(s):
            assert s in ['apple', 'ms', 'fb'], ('unexpected company %s' % s)
            return True
        
        def test_passes_test():
            system  = fudge.Fake('system').expects('set_company').with_args(arg.passes_test(is_valid))
            system.set_company('fb')
        
* startswith(part)：参数必须以part开头

更多参考：[fudge.inspector](http://farmdev.com/projects/fudge/api/fudge.inspector.html)

####fudge.patcher
* fudge.patcher.with_patched_object(obj, attr_name, patched_value)：装饰器，在被装饰的方法调用前给attr_name一个新的值patched_value，方法执行完以后attr_name再恢复成原来的值
        from fudge import with_patched_object
        
        class Session:
            state = 'clean'
            
        @with_patched_object(Session, "state", 'dirty')
        def test():
            print(Session.state)
        
        if __name__ == "__main__":
            test()
            print (Session.state)
    输出：

        dirty
        clean
    这样做的好处就是能独立于每个测试而不影响原来对象的完整性。

* fudge.pathcher.patched_context(obj, attr_name, patched_value)：作用和上面的with_patched_object一样，只是用法上不一样而已，他的用法是：

        with patched_context(Session, 'state', 'dirty'):
            print Sessioin.state
就是[with语句](http://www.python.org/dev/peps/pep-0343/)的使用方式。

####tornado.test
由于python的单元测试模块式同步的，测试tornado中的异步代码有三种方式

1. 使用类似tornado.gen的yield生成器 tornado.testing.gen_test.

        class MyTestCase(AsyncTestCase):
        @tornado.testing.gen_test
        def test_http_fetch(self):
            client = AsyncHTTPClient(self.io_loop)
            response = yield client.fetch("http://www.tornadoweb.org")
            # Test contents of response
            self.assertIn("FriendFeed", response.body)
2. 手工方式调用self.stop，self.wait
        
        class MyTestCase2(AsyncTestCase):
            def test_http_fetch(self):
                client = AsyncHTTPClient(self.io_loop)
                client.fetch("http://www.tornadoweb.org/", self.stop)
                response = self.wait()
                # Test contents of response
                self.assertIn("FriendFeed", response.body)
3. 回调函数的方式：

        class MyTestCase3(AsyncTestCase):
            def test_http_fetch(self):
                client = AsyncHTTPClient(self.io_loop)
                client.fetch("http://www.tornadoweb.org/", self.handle_fetch)
                self.wait()
            def handle_fetch(self, response):
                #此处产生的异常会通过stack+context传播到self.wait方法中去
                self.assertIn("FriendFeed", response.body)
                self.stop()

后两者的原理是一样的，wait方法会一直运行IOLoop，直到stop方法调用或者超时（timeout默认是5's）2中的fetch的第二个参数self.stop相当于3中的self.handle_fetch，都是一个回调函数，区别就在于把sotp当成回调函数时，响应内容就会通过self.wait()函数返回，而像3中一样写一个自定义的回调函数，响应内容就会作为参数传递给该函数。可以详细查看下[tornado.testing.py](http://www.tornadoweb.org/en/stable/_modules/tornado/testing.html)这个文件中的stop和wait方法。

默认情况下，每个单元会构造一个新的IOLoop实例，这个IOLoop是在构造HTTP clients/servers的时候使用。如果测试需要一个全局的IOLoop，那么就需要重写get_new_ioloop方法。 源码：

    def setUp(self):
        super(AsyncTestCase, self).setUp()
        self.io_loop = self.get_new_ioloop()
        self.io_loop.make_current()

    def get_new_ioloop(self):
            """Creates a new `.IOLoop` for this test.  May be overridden in
            subclasses for tests that require a specific `.IOLoop` (usually
            the singleton `.IOLoop.instance()`).
            获取全局IOLoop时，调用IOLoop.instance()这个单例方法即可
            """
            return IOLoop()

* tornado.testing.AsyncHTTPTestCase  
这个类是AsyncTestCase的子类，一个测试用例会启动一个HTTP server，AsyncHTTPTestCase的子类必须重写`get_app()`方法，这个方法返回`tornado.web.Application`实例。application实例就是实际代码的application。  

        app = tornado.web.Application(handlers=[
               (r'/sleep', SleepHandler),
               (r'/now', JustNowHandler)
           ])
    返回这个app就好了。测试用例通常使用`self.http_client`来请求（fetch）这个server上的url。

        class MyHTTPTest(AsyncHTTPTestCase):
            def get_app(self):
                app = tornado.web.Application(handlers=[
                       (r'/sleep', SleepHandler),
                       (r'/now', JustNowHandler)
                ])
                return app
            def test_now(self):
                self.http_client.fetch(self.get_url('/'), self.stop)
                response = self.wait()
                self.assertIn('xx', response.body)  #判断返回的请求体中是否有字符串`xx`

    其实self.http_client就是一个AsyncHTTPClient实例，从源码中查看到：  

        def get_http_client(self):
            return AsyncHTTPClient(io_loop=self.io_loop)

####fakeredis
[fakeredis](https://github.com/jamesls/fakeredis)是[redis-py](https://github.com/andymccurdy/redis-py)的实现，模拟redis服务器通信的模块。应用场景只有一个：写单元测试。

﻿###学习笔记
在这里记录自己的学习笔记，有些文章是半成品，部分完整文章有可能会发布在自己的[博客](http://foofish.net)里面。用GitHub记录的一个好处是版本控制，当然有时候我也用Evernote来记录。  

####Python
5. [collections学习笔记](./note/python/collections.md)
5. [函数式编程------序列处理函数](./note/python/function_programming_of_function_processing_functions.md)
6. [协程](./note/python/coroutine.md)
7. [装饰器](./note/python/decorators.md)
10. [异常](./note/python/exception.md)
11. [yield 生成器](./note/python/generator.md)
12. [迭代器与生成器的区别](./note/python/iterator_generator.md)
13. [python json](./note/python/json.md)
15. [Python虚拟环境：virtualenv](./note/python/virtualenv.md)
16. [Python实用技巧](./note/python/useful_features.md)
17. [python测试](./note/python/testing.md)
18. [gevent简介](./note/python/gevent.md)
19. [Django应用部署(nginx、gunicorn、virtualenv、supervisor)](.\note\python\deploy_django_with_nginx.md)
20. [理解WSGI](./note/python/wsgi.md)
21. [Flask之Hello world详解](./note/python/flask.md)

#####Django
1. [Django测试指南](./note/python/a_guide_to_testing_in_django.md)
2. [Django模版语言](./note/python/django_template.md)
3. [使用django-simple-captcha遇到的坑](./note/python/captcha.md)
3. [Python/Django编程实践指南](./note/python/code_style.md)
8. [Django Form](./note/python/django_form.md)
9. [Django url()函数详解](./note/python/django_url.md)
10. [Django signal](./note/python/signals.md)


#####Mako模板

5. [mako简介](./note/python/mako.md)

#####SQLAlchemy
14. [SQLAlchemy学习笔记](./note/python/sqlalchemy.md)

####Java
此系列文章绝大部分发布在[importnew.com](http://www.importnew.com)网站上  

1. [JDBC批处理Select语句](./note/java/JDBC Performance Tips.md)
2. [JDBC为什么要使用PreparedStatement而不是Statement](./note/java/Why use PreparedStatement in Java JDBC .md)
3. [Java为什么需要Lambda表达式（-）](./note/java/Why W Need Lambda Expressions in Java Part2.md)
4. [深入单例模式](./note/java/singleton.md)
5. [范行实践](./note/java/Generic.md)
6. [类加载与初始化](./note/java/classloading and initialization.md)

####Vim
[Vim相关文章](./note/vim/目录.md)，早期写的一些文章可以在我的旧博客：[liuzhijun.iteye.com](http://liuzhijun.iteye.com/category/270228)查看到  

10. [正则表达式](./note/vim/10.md) 
11. [Vim11](./note/vim/11.md)
12. [Vim12---ab与map](./note/vim/12.md)
13. [Vim13  多窗口](./note/vim/13.md)
14. [Vim14  标签页](./note/vim/14.md)
15. [Vim15 折叠](./note/vim/15折叠.md)
16. [Vim16 Visual 模式（0）](./note/vim/16.md)
17. [Vim17 Visual 模式（1）](./note/vim/17.md)
18. [Vim18 Text-Objects](./note/vim/18.md)
19. [Vim19 Visaul 模式（2）](./note/vim/19.md)
20. [Vim20 Taglist初体验](./note/vim/20.md)
21. [Vim21 又谈abbreviation](./note/vim/21.md)
22. [Vim22 编码设置](./note/vim/22.md)
23. [Vim23 filetype](./note/vim/23.md)
24. [Vim24 record、play](./note/vim/24.md)
25. [Vim25 行复制与移动](./note/vim/25.md)
26. [Vim26 跨行执行〈Normal模式下的〉命令](./note/vim/26.md)
27. [Vim27 高亮所有搜索模式匹配](./note/vim/27.md)
28. [Vim28 全局命令](./note/vim/28.md)
[我的vim配置](./note/vim/vimrc.md)  

####memcached
1. [入门安装篇](./note/memcached/introduce_install.md)  
2. [命令介绍篇](./note/memcached/telnet_command.md)
3. 
4. 

####redis
1. [入门篇](./note/redis/introduce.md)


####sphinx/coreseek
1. [sphinx笔记](./note/python/sphinx/introduce.md)  
不定时更新 


很喜欢redis作者[antirez](http://antirez.com/latest/0)里面的几句话, **代码就像一首诗**, **设计就是与复杂性做斗争**, **coding是一件很辛苦的事, 唯一的办法是享受它, 如果它不能带来快乐就停止它**.  

####下载安装
[redis官方站点](http://redis.io/download)下载:  

    $ wget http://download.redis.io/releases/redis-2.8.7.tar.gz
    $ tar xzf redis-2.8.7.tar.gz
    $ cd redis-2.8.7
    $ make

####运行连接

    $ src/redis-server
顺利的话, redis会正常启动, 启动信息  
redis 2.8.7 (00000000/0) 32 bit  
Running in stand alone mode  
Port: 6379  
PID: 11156  

使用内建的客户端连接:  

    $ src/redis-cli 
    127.0.0.1:6379> set foo bar
    OK
    127.0.0.1:6379> get foo
    "bar"
    127.0.0.1:6379> 




:

每日一Vim（10）-----正则表达式
==========
首先鄙视一下自己，写了这么期Vim竟然没一篇是用Vim写出来的，因为需要同步,所以主要用的Evernote，但是Eevernote有缺陷啊，不支持markdown语法，于是今天痛改前嫌，决定用github来托管。在网上找了两个资源，一个是[markdown-preview](https://github.com/volca/markdown-preview)---这是一个预览markdown语法生成文件的chrome插件，第二个是[vim-markdown](https://github.com/plasticboy/vim-markdown)-----这是个vim的markdown插件，它可以按照markdown的语法高亮。具体怎么安装？这两个插件的README文件说的再清楚不过了，如果您遇到什么问题，欢迎留言给我！最后再吐槽一句：第一次用vim写大篇的中文还真不习惯呢,现在开始进入我们的主题：  
###正则表达式


<table border="1" cellspacing="0" cellpadding="0" >
         <colgroup>
            <col width="123"/>
            <col width="211"/>
            <col width="402"/>
         </colgroup>
         <tr >
            <td colspan="3" >
               <p>匹配单个字符的元字符</p>
            </td>
         </tr>
         <tr >
            <td >
            <td >
               <p>元字符</p>
            </td>
            <td >
               <p>匹配对象</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>.</p>
            </td>
            <td >
               <p>点号</p>
            </td>
            <td >
               <p>匹配单个任意字符</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>[abc]</p>
            </td>
            <td >
               <p>字符组</p>
            </td>
            <td >
               <p>匹配abc中的任意单个字符，写正则表达式的时候"["和"]"需要用"\"转义</p> </td> </tr> <tr >
            <td >
               <p>[^abc]</p>
            </td>
            <td >
               <p>排除型字符组</p>
            </td>
            <td >
               <p>匹配abc之外的任意单个字符，"["同样需要转义</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>\char</p>
            </td>
            <td >
               <p>转义字符</p>
            </td>
            <td >
               <p>匹配char对应的普通字符，例如char是*，那么\*就匹配*</p>
            </td>
         </tr>
         <tr >
            <td colspan="3" >
               <p>提供计算功能的元字符</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>？</p>
            </td>
            <td >
               <p>问号</p>
            </td>
            <td >
               <p>匹配一次或0次</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>*</p>
            </td>
            <td >
               <p>星号</p>
            </td>
            <td >
               <p>匹配任意次或0此</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>+</p>
            </td>
            <td >
               <p>加号</p>
            </td>
            <td >
               <p>至少匹配一次</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>{min,max}</p>
            </td>
            <td >
               <p>区间量词</p>
            </td>
            <td >
               <p>至少匹配min次，至多匹配max次</p>
            </td>
         </tr>
         <tr >
            <td colspan="3" >
               <p>匹配位置的元字符</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>^</p>
            </td>
            <td >
               <p>脱字符</p>
            </td>
            <td >
               <p>匹配一行的开头处</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>$</p>
            </td>
            <td >
               <p>美元符</p>
            </td>
            <td >
               <p>匹配一行的结尾处</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>\&lt;</p>
            </td>
            <td >
               <p>单词分界符</p>
            </td>
            <td >
               <p>匹配单词的开始位置</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>\&gt;</p>
            </td>
            <td >
               <p>单词分界符</p>
            </td>
            <td >
               <p>匹配单词的结束位置</p>
            </td>
         </tr>
         <tr >
            <td colspan="3" >
               <p>其他元字符</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>|</p>
            </td>
            <td >
               <p>多选（alternation）</p>
            </td>
            <td >
               <p>匹配任意分隔的表达式，写正则时需要写成"\|"</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>(…)</p>
            </td>
            <td >
               <p>括号</p>
            </td>
            <td >
               <p>限定多选结构的范围，同样"("和")"需要转义</p>
            </td>
         </tr>
         <tr >
            <td >
               <p>\1  \2 …</p>
            </td>
            <td >
               <p>反向引用</p>
            </td>
            <td >
               <p>匹配之前第一组括号，第二组括号...中匹配的文本</p>
            </td>
         </tr>
      </table>

好了，这篇文章就是采用vim+github+markdown来完成的，不信):？看看[这里](https://github.com/lzjun567/one_day_one_vim/blob/master/resource/10.md)  
*转载请注明出处，谢谢合作。作者---[zhijun](http://weibo.com/527355345)*

每日一Vim（11）
============
###文件保存高级篇  

以下部分命令在之前的篇幅中有涉及过，有句话说的好：*vim对新手最痛苦的是选择太多，不知所措，对老手来说最让人快乐的是一个问题总有不同的解决方法，而对寻找最优方法乐此不疲*，细心的读者相信您都能从中总结出自己的规律以及经验来。  

    :w new_file：将缓冲区内容保存为new_file文件，原文件内容不更改。
    :20,$w new_file：将文件20行处到结尾保存为new_file文件
    :.,20w new_file ：将光标所在行到第20行保存为new_file 文件
    :20,30w >> new_file：追加20至30行内容到new_file文件中
###一个文件copy到另一文件

    :r filename：把filename中的内容插入到光标所在行的下一行
    :100r filename :把filename中的内容插入到100行的后面
    :$r filename：插入行尾
    :0r filename :插入行首
    :/parttern/r filename ：还可以使用正则表达式，插入到匹配出的后面一行，需要注意的是如果有多处匹配，它只插入到首个匹配的地方。
###标记
标记又称为书签，在某个位置打上标记后，在别处编辑完，通过命令可以回到标记处（以下命令模式中执行）

    mx  将当前位置标记诚x（此处的x可以是热任意字母）
    'x  （单引号）光标移到标记x处的行首
    `x   (反引号）光标移到标记x处
    ``  （双反引号）当前光标处于标记处来回切换
    ''  （双引号） 当前光标所在行处与标记处来回切换，光标定位在行首
 

*转载请注明出处，谢谢合作。作者---[zhijun](http://weibo.com/527355345)*

每日一Vim（12）ab与map命令
=============
###ab命令：  

`ab`命令可以将一长串字符用缩写来定义，这有点象Linux中的alias，比如Linux中的`ll`命令就是`ls -l`的别名，`ab`的语法为： 

    :ab abbr phrase

abbr就是对phrase的简写，在insert 模式中，输入abbr，再按非字母字符（比如空格，点号等）Vim就自动把phrase插入到光标处位置。此情景一般用在频繁输入的字符中，通常建议abbr选择使用频率很低的字符，比如Eclipse常用的一个快捷键syso，你可以定义成如下：  

    :ab syso  public static void main(String[] args) 

这样一来，每次输入syso的时候，整个main方法就自动插入到文本行了。如果你就是想输入'syso'这个原生字符串，那么您可以用下面这个命令取消：  

    :unab syso

列出当前定义的缩写有哪些可以用命令：  

    :ab
****
###map命令  

![图](https://github.com/lzjun567/note/blob/master/resource/image/map.png?raw=true)

上图是执行`:map`命令显示的内容，我们暂且先不对图做说明，稍后再分析，map的功能比ab更强大，它不仅可以在insert 模式下定义宏（快捷键）而且可以normal，visual等模式下定义。其语法举例说明：（目标：在normal下用`lv`选中光标所在行）  

    :map lv 0v$ 

解析：0代表光标移至行首，v就是visual模式（该模式下可以通过hjkl来选中文本），$代表行尾，这样一来，在normal模式输入`lv`就能选中光标所在行了。  

    :map 列出所有已定义的映射命令
    :unmap lv 取消lv映射的命令
    :mapclear  清空所有映射

需要注意的是：  

1. 默认情况下，map命令是作用在normal模式下的
2. 如果是想在virsual模式下新建某个命令的宏，可以使用:vmap，举例：:vmap d \<esc>dd就可以在virsual模式下把光标所在行删除。`<esc>`是纯粹的5个原始字符，意思是回到normal模式。
3. 默认情况下，map是采用递归映射的，比如a映射成b，`:map a b`，然后c 又映射成了a，`:map c a` ，那么最终c也会自动映射成b，等同于`:map c b`，您现在可以试一试a,b,c的效果都是光标向前移动一个单词的长度。如果要不想使用递归，那么就要用`:noremap`
4. 现在你应该能看明白上图的内容了吧，第一列就是宏会在哪中模式下生效，第二列代表快捷键了，第三列就是真正的命令序列集合了。您可以注意一下最后一个命令：<S-Insert>（Shift+Insert）就是前些天分享过的，代表在normal模式下粘贴系统剪切板中的内容。

###实用例子：

    :map <C-a> <Esc>ggVG   实现类似于Widnows下的Ctrl+a全选 
    :inoremap ( ()<esc>i   插入模式下输入'('后自动补全')'，同理还可以实现'['，'{'
更多的例子就要靠您的创造力和想象力的，如果您能把基本的命令学好了，这些命令组合在一起使用的话，威力无比。  
ps：`"+y`可以把光标所在行或选选中的字符copy到系统剪切板中。  

*转载请注明出处，谢谢合作。作者---[zhijun](http://weibo.com/527355345)*

每日一Vim(13) 多窗口
==========
*题外话之Vim的简史：Vim是vi演化过来的，其全名叫vi Improved.最初是由一个叫做Bram的大神在vi的基础上开发出来的。她的设计目标是成为一个可靠而且可以为专业程序员所依赖的编辑器。*

在[每日一Vim（4）](http://liuzhijun.iteye.com/blog/1828467)谈过一点点多文件编辑的内容，今天稍微详细的讲解多窗口的编辑。  

默认情况下，Vim只为一个session打开一个窗口，可以用参数**-o**来打开多个窗口，如:`vim -o file1 fiel2`，默认这个session会水平分割两个窗口显示，另外参数o后面还可以跟数字:`vim -o3 file1 file2` 这样Vim会打开三个窗口，最后一个窗口会留空白.

###打开窗口
如果vim已开启，那么在normal模式如下命令使用：
####水平分割窗口
    :split             当前窗口一分为二，两个窗口显示相同内容。  
    :10split           新窗口的高度10行
    :split otherfile   新窗口中打开otherfile   
    :new               功能和split一样  
    :sp                split的缩写形式  
    ctrl+w+s           分割窗口的快捷方式
    :q                 关闭当前窗口

####垂直分割窗口
`:vsplit`   以上所有命令都适用于打开垂直分割窗口，只要在前面加v(vetical)

###窗口光标移动：
####鼠标操作
gvim默认支持鼠标移动光标操作。  
vim可以设置  `:set mouse=a`,我猜a就是available的意思。  
####键盘操作
    ctrl+w+k  使用ctrl+w（window)结合hjkl来移动。先按住CTRL+w，在按k，光标就移到上面窗口。hjkl前面可加数字，移动多个窗口
    ctrl+w+T  大写T）移动当前窗口至新的标签页（tab，下节专业讲讲标签页）
    ctrl+w+K  （大写K）HJKL四个组合命令（移动并回流窗口命令，窗口和光标一起移动）

###调整窗口尺寸
gvim鼠标支持拖拉动作来改变窗口大小。我想你不会这么做，命令行才是高效率工作。   
ctrl+w结合`+-=`  当然`+-=`前面可以接数字，分表代表增大、减小、均分窗口。  
resize -4    明确指定窗口减少多少  
ctrl+w结合`< >` 增加窗口宽度  
*转载请注明出处，谢谢合作。作者---[zhijun](http://weibo.com/527355345)*

每日一Vim（14）标签页（tab）
-----------------------
上期讲了多窗口的一些操作，其中有提到把一个窗口移动标签页的技巧，命令：`ctrl+w+T`，今天就来简单聊聊标签页的操作。

####新建标签页

    :tabe        新建未命名的标签页
    :tabe file   在新标签页中打开或新建文件file 
    :tabnew      和tabe命令功能一样
    :tab split   在新标签页中打开当前窗口（缓冲区）的文件
    :tabf *.txt  当前目录搜索匹配*.txt的文件，在新标签页打开。
                 该命令只能打开一个文件，如果该正则表达式匹配了多个文件，则提示“文件名过多”而无法打开。
####列出标签页

    :tabs   列出已打开的标签列表，">"表示当前标签页 
####切换标签页

    :tabn    移动到一个标签页（next）
    :tabp    移动到上一个标签页（previous）
    gt       等效于:tabn
    gT       等效于:tabp
    :tabfirst  移到第一个标签页
    :tabr      等效于tabfirst
    :tablast   移到最后一个标签页
    :tabm 0      移到第一个标签页
    :tabm       当前标签移到最后
    标签移到两端时会循环移动
####关闭标签页
    
    :tabc    关闭当前标签页
    :tabo    关闭当前标签以外的标签页 
    :set showtabline=0   关闭标签页菜单
    :set showtabline=1   显示标签页菜单
**************************************
**:tabdo** 多标签页命令，可以在多个标签页中执行命令，比如替换多个标签中的内容
`:tabdo %s/foo/bar/g`

更多细节：`:help tab-page-intro`

*转载请注明出处，谢谢合作。作者---[zhijun](http://weibo.com/527355345)*


每日一Vim（15）折叠(fold)
--------------------
抱歉，今天的文章可能写的很难懂，还请大家多多包涵。  
写程序遇到大段的代码时，如果想像Eclipse一样把函数都折叠起来，只显示函数的签名，或者折叠一个函数中小段代码，这样一来，整个文件的代码结构一览无余，非常清晰，如果要查看函数里面的具体内容就打开，对程序员来说这是很实用的技巧。  

Vim用命令foldmethod实现折叠功能，一共有六种折叠方式，可以用`:set foldmethod`查看当前session用的是哪种折叠，默认vim使用manual（手动）方式。

####manual
手工折叠是最基本的折叠方式，在处理小块文件的时候简单实用。
    
    zf   创建折叠（fold creation）
    zo   打开折叠(open)
    zc   再次折叠起来(close)
------------------------
举例说明：

    v{motion}zf  折叠V模式下选中的文本。（这里的v{motion}指的是Shift+v）。
    zf\`a    折叠当前光标处到标记a处的文本 （`ma`就表示在当前光标出做a标记）      
    zf3j     折叠当前光标出下3行
    zf10G    从当前行折叠至第20行
    zfgg     折叠至行首
    zf%      光标移至'{'时，vim会去匹配'}'，这样'{}'之间的内容就可以折叠起来


####indent
vim自动根据缩进折叠，缩进量与折叠行的嵌套深度关系有`shiftwidth`控制，通过设置`:set foldlevel=num`，num代表数字。foldlevel=0时关闭所有折叠，等价于`zM`，`zR`设置折行为最大值


每日一Vim（16）Visual 模式（0）
----------------------

前两天没更新，这里要对不起 _isensen_ 等童鞋了:-)，这两天写代码比较多，就落下来没写了，当然这其实是借口，昨天确实堕落了一天。**有错就改**，以后尽可能保证每周有五篇简短的文章_say less,do more_，谢谢isensen等童鞋每天光顾这里，你们的建议是我前进的动力。

Vim的Visual模式（中文称之为可视化模式）可以对所选择的文本进行各种操作，Virsual模式可以分为三种，分别是**字符（Characters）、行（line）、矩形块（rectangular block）**，既然是Visual模式，肯定是和字母v相关的操作，前面的一些篇章也用到过v模式（说到V，让我想起一篇文章《中国黑客传说：游走在黑暗中的精灵》，看完我这篇短文后不妨去看看那篇文章，挺有意思的，链接在文章最后）。  

####viwc
今天呢，就只讲一点点有关V模式的用途吧，在windows中替换一个单词惯用的手段就是先找到这个单词，鼠标双击该单词，选中之后直接输入新的单词就Ok了，但是使用Vim，你就应该摒弃鼠标，甚至四个方向键也不要去碰。那么在Vim中，概括起来就是四个字&lt;E>f{char}viwc（请看小标题，这里貌似有十多个字儿，且慢，一个个解析下：&lt;E>：Esc，进入normal模式，f：查找字符串，当然还可以用“;”或者“，”继续往后或往前找，v：visual模式，iw：选中整个单词，c：删除单词，进入插入模式），这样整个单词就会删除，接着就可以插入你想替换的单词了。其次，在Visual模式下，hjkl光标移动的键同样是可用的。对了，在normal模式下“.”可以重复执行上一次操作，有点象Python中的下划线“_”表示最后一个表达式的值一样。例如你最后执行的命令dd，那么按“.”就会继续删除当前行。（以后如果突然想起一个实用的东东，如果前面没介绍过的，我就顺便查到文章里头了）。

另附：为了彻底甩掉对四个箭头移动光标的依赖，在.vimc文件中可配置:  

    nnoremap <up> <nop>
    nnoremap <left> <nop>
    nnoremap <right> <nop>
    nnoremap <down> <nop>
[中国黑客传说：游走在黑暗中的精灵](http://taosay.net/?p=189)。

转载请注明出处，谢谢合作，周末愉快！作者---[zhijun](http://weibo.com/527355345)

周末没事的时候可以看看这张图：大图在这里：http://www.viemu.com/vi-vim-cheat-sheet.gif ![vim cheat-sheet](../resource/image/vi-vim-cheat-sheet.png)




每日一Vim（17）Visual 模式（1）
--------------------------
Visual 模式的三种子模式(基于字符，行，块）可以对不同文本域进行处理，这一小节看看如何使用这三种模式以及他们之间如何切换。  

_字符可视化模式_可以对任何单个字符或字符串甚至是多行进行处理，通常适用于处理单词或者词组，如果是想处理整行，那么就可以使用 _（line）行可视化模式_，*块可视化* 则可以对文档区域操作，支持列操作。normal 模式下，命令对应的Visual表如下：

    v         基于字符的Visual模式
    V         基于行的Visual模式
    Ctrl+v    基于块的Visual 模式
    gv        重新选取最后一次使用Visual模式选中的文本


####Visual模式之间的切换

如果当前是在字符Visual模式下，V就能切换到基于行的Visual模式，Ctrl+v就是切换到基于块的Visual模式下，来回的按v能在normal模式和字符Visual模式下切换。此规则同样适用与另外两种Vrsual模式。

####光标在选择区域首尾切换

首先我们在看这么一个图：  
![vim17_1](../resource/image/vim17_1.png)  
当前光标在第一行的h位置，我想实现的效果是通过光标在选择区域两端切换的方式把_here to here_ 都选中，那么命令o就能用来区域首尾切换的。其对应的命令如下图所以：  
![vim17_2](../resource/image/vim17_2.png)

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345)




每日一Vim（18）Text-Object
-----------------------
前两节讲了Visual mode相关内容，这里提一个小问题，“如何选择一个单词？”3秒后...，你可能会使用命令`vw`，很不幸的是它会把下一个单词的首字母也选中。如果你足够细心的话，你会发现答案在之前的章节中讲过，命令是：`viw`。它的作用是选取一个单词（word），无论光标在这个单词的哪个位置都能选中整个单词，那么`i`到底有什么作用呢？这就是今天要讲解的内容。  


Text-Object：可以指一个单词，一整句文本，抑或一对括号内的文本，甚至是html或xml标签内的文本，都可以抽象成Text-Object。与Text-Object紧密相关的两个命令就是`a`和`i`，啊？这两个命令不是append和insert吗？其实，a和i操作在Visual mode或者某些操作（比如：`d`,`y`等）后面就是另外一种效果了。例如，删除一个单词可以用`daw`或者`diw`。那么`a`与`i`又有什么区别呢？

**  `a`会选择一个对象（an object）包括空格在内，而`i`只会选择一个对象的内部（an inner object）不包含空格。**

下面就是一些命令含义：  

    aw   a word
    iw   inner word
    aW   a WORD   
    iW   inner WORD
    as   a sentence
    is   inner sentence
    ap   a paragraph
    ip   inner paragraph
    a[|]   a[] block （这里的'|'是或的意思，也就是说'a['和'a]'都表示一个[]块）
    '{} &al;>()与[]作用类似
    at   a  tag （这里的tag可以是html或xml中任何标签对）
    it   inner tag

比如在一个html文件中，当前光标在某个标签对的内容里头的时候，命令`dat`会把整个标签对包括内容都会删除，而`dit`只会删除标签对之间的内容，保留标签对。详细说明可以`:help text-objecgts`


转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345)

每日一Vim（19）Visual-Block 模式
-------------------------
从这节开始做点小小变化，增加一些例子的成分，这些例子一般来自于实际编程情景中，算是理论与实践相结合。  

Visual-Block模式一个非常强大的功能就是它支持列操作，比如在某个代码块每行的行首插入注释符号。举例说明：假如有如下Python代码，我想把它全部注释  

    for e in exclude:
    if e.endswith(".py"):
            try:
            os.remove("%sc" % e)
            except:
                    pass
                    try:
                    with open(e, "r") as f:
            exclude[e] = (f.read(), os.stat(e))
            os.remove(e)
            except:
                    pass

1. 光标定位到代码块的行首，`Ctrl+v`进入Visual-block模式
2. 光标向下移动，直到选择所有代码行的第0列
3. 输入`I`（光标前插入字符），此时你会发现光标跳到了代码块的开头处，此时已经是insert 模式了，现在就插入python的注释字符'#'
4. 按`Esc`键，此时你会发现代码块所选区域都打上了注释符号，如下所示：  

        #for e in exclude:
        #if e.endswith(".py"):
        #   try:
        #       os.remove("%sc" % e)
        #   except:
        #      pass
        #      try:
        #      with open(e, "r") as f:
        #   exclude[e] = (f.read(), os.stat(e))
        #   os.remove(e)
        #   except:
        #        pass


第二个例子：下面是一段JavaScript片断：

    var foo = "a"
    var bar = "bcd"
    var fb = foo+bar

我们知道js中大部分浏览器都能忍受后面没有分号结尾的语句，但是并不推荐这样做，因为我们有必要给他们在行末都加上分号，我们知道vim吸引人的地方之一就是一个问题往往有不同的解决方案，这里我们至少有两种方法，1.替换法：`:1,3s/$/;/g`（这里的1，3是第一到第三行）2.在Visual block模式下append（追加）。  

我们观察上段代码发现每行的语句的长短不一，那有如何批量的加上";"呢，这里关键的一个命令是`$`，美元符号定位了行未。操作步骤基本还是和第一个例子差不多。只需在选中代码块的时候要注意是：`Ctrl+v jj$`，这样就能选中到每一行的行末。接着输入`A`命令表示在行末追加字符，输入“;”再按`Esc`大功告成了。最终的效果：  

    var foo = "a";
    var bar = "bcd";
    var fb = foo+bar;

今天推荐一个vim的游戏给大家，[vim-advanture](http://vim-adventures.com/)，这是一个迷宫游戏，前三关可以免费玩，之后就要$9.9才能继续玩了，如果没弄懂怎么玩，可以看下这里的[攻略](http://coolshell.cn/articles/7166.html)，祝玩得开心。

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345)

每日一Vim（20）Tagelist初体验
---------------------------

Taglist 插件一个源代码浏览器，这个插件在今年发布了4.6的版本，4.5还要追溯到2007年Taglist需要结合ctag才能使用，否则会出现: *Exuberant ctags (http://ctags.sf.net) not found in PATH.Plugin is not loaded*这样的错误。

####下载安装：
[ctag](http://sourceforge.net/projects/ctags/?source=dlp)  
[taglist](http://sourceforge.net/projects/vim-taglist/?source=dlp)  
上面两个链接有可能需要fan墙，找到对应平台的压缩包后，解压。windows平台下的**ctags**直接把ctags.exe放到Vim的安装目录即可，对于Linux，需要编译安装:  

    $tar -zvxf ctags-5.8.tar.gz
    $cd ctags-5.8
    $./configure
    $make
    $sudo make install

对于taglist，解压后有对应如下的文件目录：  
    
    ├── doc
    │   └── taglist.txt
    └── plugin
        └── taglist.vim

Windows：把taglist.txt和taglist.vim分别放到Vim安装目录对应的doc和plugin目录下。
Linux：把taglist.txt和taglist.vim分别放到`~/.vim`目录下的doc和plugin目录下。如果没有.vim没有，就先创建。总之，不管什么平台，原理是一样的。

正确安装完成后，我们就可以拿它来一展身手了。首先我们看看下面这个效果图：
![tlit](../resource/image/tlist.png)  

这看起来就有点Eclipse的味道了，左侧是类，方法，等成员的缩略图(taglist窗口），右侧是代码区窗口。当打开一个文件时（c或者python等编程语言的文本）,命令模式下输入：`TlistToggle`就可以出现上面的效果图，再次输入`TlistToggle`时该窗口又会关闭。

最后推荐一个视频给大家：[周鸿祎谈颠覆式创新](http://www.wpcourse.com/innovation-of-zhou.html)，看前半部分内容就可以了。

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 

每日一Vim（22）又谈abbreviation
------------------------
Vim有一句哲学是这样说的：“if you write a thing once,it it okay,However,if you're writing it twice or more times,then you should find a better way to do it"。这句话估计也是引用软件开发里面的DRP（Don't Repeat Yourself）原则。如果你老是需要重复的写一些相同的东西，此时你就应该使用**abbreviation（缩写）**.

     :abbreviate 作用于所有模式   （ab） 
     :iabbrev    仅作用于插入模式 （iab）
     :cabbrev    仅作用于命令行模式（cab）

abbreviation可以用在很多有意思的地方，比如：  

1. 纠正错误的拼写:`:iabbr teh the`
2. 程序中你能想到的模版语句：`:iabbr forx for(x=0;x<100;x++){<cr><cr>}`
3. 简化命令的输入：`cabbr cse colorscheme evening` 
4. 如果你是Java程序员，如下命令毫不逊色于Eclipse  

         abbr psvm public static void main(String[] args){<CR>}<esc>O
         abbr sysout System.out.println("");<esc>2hi
         abbr sop System.out.println("");<esc>2hi
         abbr syserr System.err.println("");<esc>2hi
         abbr sep System.err.println("");<esc>2hi
         
         abbr forl for (int i = 0; i < ; i++) {<esc>7hi
         abbr tryb try {<CR>} catch (Exception ex) {<CR> ex.printStackTrace();<CR>}<esc>hx3ko
         abbr const public static final int
         
         abbr ctm System.currentTimeMillis()
         abbr slept try {<CR> Thread.sleep();<CR>}<esc>hxA catch(Exception ex) {<CR> ex.printStackTrace();<CR>}<esc>hx3k$hi

可以说只有你想不到了，没有做不到的。

写程序追求的高内聚，低耦合，同样，毫无疑问，Vim也遵循同样的原则，如果我们有上十条百条这样的缩写命令，如果都挤在vimrc配置文件中，这样过显得很难管理，因此我们可以把专门用于缩写的命令放置在单独的文件中，然后在vimrc文件中引用就ok，`:source $VIM/abbreviation.vim`

你有没有想过一个问题，如果把`forx`设置成了缩写格式，那么有时候我本意是输入'forx'呢？

* 方法一：就是把它的映射取消掉`una forx`，这样有个缺点是下次我又需要这个缩写了，这时又不得不重新捡回来。
* 方法二：写一个函数，在每次输入'forx'的时候询问是作为普通字符串还是作为缩写呢？函数如下：

        function! s:forxAsk(abbr,expansion)
          let answer = confirm("使用缩写'" . a:abbr ."'?",
                                 "&Yes\n&No",1)
          return answer ==1 ? a:expansion : a:abbr
        endfunction

        iabbrev <expr> forx <SID>forxAsk('forx','for(x=0;x<100;x++)')
函数中`abbr`是缩写，`expansion`就是全写，这样一来，每次输入`forx`时，就会弹出一对话框询问你是使用缩写还写不使用。当然这种方式显得比较笨拙，另外一个目的也是告诉大家如果写函数。
* 方法三：使出杀手锏，输入`forx`完成后，按`Ctrl-v`（windows系统按`Ctrl-q`）就能避免尴尬了。

更多参考：

* `:help abbr`
*  [wikia](http://vim.wikia.com/wiki/Using_abbreviations)

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 


每日一Vim（22）Vim 编码设置
------------
####Vim的编码选项
vim编码涉及四个概念，分别是`enc,fenc,fencs,tenc`,一般乱码多是因这些参数设置不正确引起的，要想彻底摆脱vim的乱码问题，还是把这四个概念理清楚了，下面详细介绍之。
#####enc(encoding)
`enc`的全称为`encoding`，这是Vim内部使用的编码，如buffer，寄存器中的字符串。在Vim打开文本后，如果它的编码方式与它的内部编码不一致，Vim会先把编码转换成内部编码，如果它用的编码中含有没法转换为内部编码的字符，那么这些字符就会丢失掉。默认值是系统的locale来决定的，比如在windows下一般就是gbk或gb2312的，而在linux下就是utf-8。可以用命令`:set enc`查看当前vim的enc是什么值，笔者的windows显示的是`cp936`这里的cp936其实相当于gb2312，指系统的第936号编码格式。  

#####fenc(fileencoding)
fenc为当前缓冲区（当前Vim打开这个文件）文件自身的编码，从磁盘读文件时，Vim会对文件编码检查，如果文件的编码与Vim内部编码（enc）不同，Vim就会对文本做编码转换，将fenc设置为文件的编码。Vim写文件到磁盘时，如果enc与fenc不一样，Vim就做编码转换，转换成编码fenc保存文件。在windows下你可以借由notepad++等编辑器检查文件是什么编码的。由于fenc是在打开文件时由Vim自动检测的，所以如果文章中有乱码也没法通过重新设置fenc来纠正，设置fenc只能改变文本的编码格式。

#####fencs(fileencodings)
这是一个字符编码的列表，编码的自动识别就是通过设置fencs实现的。当打开一个文件时，Vim会按照fencs中编码的顺序进行解码操作，如果匹配成功就用该编码来进行解码，并把这种编码设为fenc的值。这里的匹配成功指的是Vim能正确解码，不会出错，但是不保证没有乱码，所以fencs编码列表的顺序设置很关键，由于lanin1是iso8859-1，属于国际化的标准编码，他能表示任何字符，也就用于也不会出错，但是我们看到的可以是“乱码”。
所以一般fencs设置的顺序是这样子的：lan1放到最后面  
     
     set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1


#####tenc(termencoding)
终端使用文本编码，或者说是Vim用于屏幕显示时的编码，显示的时候Vim会把内部编码转换为屏幕编码再输出，也就是说我们从屏幕上看到的字符都是tenc编码的字符，如果为空，默认就是enc。windows平台Gvim会忽略掉tenc。一般就是从一个终端远程登陆到linux系统时候tenc会起作用。

####乱码问题
如果碰到了乱码问题，只要你把enc，fenc统一设成utf-8问题都会解决了。下面这段配置就是我的Vimrc文件的关于解决乱码配置的代码段：  

    " 设置vim内部编码格式
    set encoding=utf-8
    
    " 解决windows下如果encoding设置utf-8，菜单会乱码问题
    set langmenu=zh_CN.UTF-8
    language message zh_CN.UTF-8
    source $VIMRUNTIME/delmenu.vim
    source $VIMRUNTIME/menu.vim
    
    "默认文件编码
    set fileencoding=utf-8 
    set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1

参考：http://edyfox.codecarver.org/html/vim_fileencodings_detection.html  

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 

 每日一Vim（23）filetype---- 文件类型检测
 ----------------------
 当你用Vim打开某种编程语言的文件时，你会看到关键字，函数名等等都会高亮，下图是两个内容一样，名称不一样的文件，一个是txt，一个是py，明显能看出txt文件显示并不是那么友好。这就和`filetype`有关系啦。  
![filetype](../resource/image/filetype.png)

执行`:filetype`可以查看Vim的文件类型检测功能是否已打开，默认你会看到：`detection:ON plugin:OFF indent:OFF`。下面详细介绍这三个参数的具体含义。

detection：默认情况vim会对文件自动检测文件类型，也就是你看到的'detection:ON'，同样你可以手动关闭`:filetype off`。 因此我们看到dection 也是ON，所以Vim会很友好的显示文本， 可以用`:set filetype`查看当前文件是什么类型了。 类似的如果如上图中file.txt文件的filetype设置为python那么就和普通的python文件一样的显示效果了：`set filetype=python`。  

另一种方式就是在文件内容中指定，Vim会从文件的头几行自动扫描文件是否有声明文件的类型的代码，如在文件的行首加入`# vim: filetype=python`，Java文件变通的做法`/* vim: filetype=java */`，总之就是把这行当作注释，以致于不影响文件的编译，这样Vim不通过文件名也能检测出文件是什么类型了。

plugin：如果plugin状态时ON，那么就会在Vim的运行时环境目录下加载该类型相关的插件。比如为了让Vim更好的支持Python编程，你就需要下载一些Python相关的插件，此时就必须设置plugin为ON插件才会生效，具体设置方法就是`:filetype plugin on`

indent：不同类型文件有不同的方式，比如Python就要求使用4个空格作为缩进，而c使用两个tab作为缩进，那么indent就可以为不同文件类型选择合适的缩进方式了。你可以在Vim的安装目录的indent目录下看到定义了很多缩进相关的脚本。具体设置方法：`filetype plugin on`。

以上三个参数，可以写成一行`filetype plugin indent on`设置在_vimrc文件中。

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 

每日一Vim（24）宏---Record、Play
----------------------
写这篇文章的时候想到了读高中那会儿买的第一个电子产品，某某高复读机，话说是为了学英语，呵呵，你懂的，其实是为了好玩。当时差不多花了300担，父母在子女的教育方面可是毫不手软，想想如果那时开始接触计算机互联网相关的东西了，买的就是一台电脑，我离那“一万小时定律”就要早几年完成了...言归正传。  
![tu](../resource/image/recode.jpg)

今天要说的其实就和这个复读机相关，复读机在按下复读的按钮后，就开机录制需要复读的内容，再按一下录制完成，接下来就可以播放了。Vim中也有与之惊人相似的操作，如果想重复某个操作，就可以用**宏**来完成，还记得以前讲过的一个命令吗：`.`就是这个**点**可以重复执行最后一次操作，但是这个`.`的功能比较弱，没法组合使用，如下代码，想在每行末加上分号";"：  

    int a = 1
    int b = 2
    int c = a+b
    print a
    print b
    print c

如果是用`.`来实现的话，首先在第一行执行`$a;`，然后重复5次执行`j$.`，这样算下来你要敲击的键总数在15次之多，但是我们用Record/Play的话，即使是100行代码，按键也不会超过10次。命令闪亮登场：`q`，就是这个q，它的威力很猛。接下来就详细介绍如何操作`q`来实现上述需求。  

1. normal 模式下输入`q`启动recoding，q后面跟任意a-z的小写字母比如`m`，这个字母就是宏的名字，接下来你要执行的操作就会记录在这个宏中。
2. 执行我们的任务：“行末加分号”，命令是：`$a;<Esc>j$`，这条命令意思就是：移动行尾插入分号，退到normal模式，光标移动到下一行的末尾。
3. 再次输入`q`，表示录制结束
4. 录制结束后我们就可以play了，输入`@m`就会执行宏中的操作，`m`是第一步中使用的宏的名称，`5@m`表示重复执行5次。这样，所有行都给加上分号了，真是好使。

再举一例：实现如下效果：从1到100，每行+1。  

    1
    2
    3
    ...
    100

命令：首先在第一行插入1，然后光标定位了“1”处，进入normal模式，开始录制：`qmyyp<Ctrl>aq`，（解释：`yyp`：拷贝一行再粘贴在新的一行，`<Ctrl>a`：数字+1）后然执行`98@m`，收工。

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 

答应推荐一个微信号的：`Mac技巧`，主人是70后程序员，主要讲人文科技+mac技巧相关内容。

每日一Vim（25）行复制与移动
------------------------
很开心看到 @kidneyball童鞋一口气在上一篇文章中提了三个建议，而且都很有建设性，当然还要谢谢@isensen等童鞋，又在催我了。这下动力又有了，今天继续写，不过我的写的时候呢，没有太多的章法，想到哪里就写哪里，学Vim是个技巧活，需要不断实践，练得好就有如身披一把AK47。  

今天要讲的是整行移动和拷贝，涉及的命令是：`:m`和`t`。这两个命令其实是`move`和`copy`的简写形式。 其实整行的拷贝相信你能用yank解决，但是它有一个缺点就是必须把光标移到要拷贝的行才能执行该操作，然而`:copy`和`:move`命令可以在任何地方拷贝或者移动任意一行或者多行。  

**copy**命令格式：`:[range]copy{address}`，range表示拷贝范围，address表示目标地址。举例来说：把下面三行if语句块拷贝到main代码段中去，不管此时你的光标在何处，现在假设光标在main那行： 
		
    if choise=='n':newuser()
    if choise=='e':olduser()
	if choise=='q':done=True

    if __name__=='__main__':

我们可以用`:1copy.`把第一行拷贝到光标的下一行（`.`代表当前行），如果三行全拷贝：`:1,3copy.`，copy的另外两个写法`:co`或者`:t`。
常用命令：  
`:3t.`    拷贝第三行到当前光标的下一行  
`:t3`      拷贝当前行到第三行的下一行  
`:t.`      拷贝当前行到光标的一下行，相当于`Yp`和`yyp`  
`:t$`      拷贝当前行到最后一行  
`:'<,'>t0` 拷贝所选区域到文本的开头处，这里的操作步骤是：现在visual 模式下选中文本，然后输入`:`，接着`t0`。

**move**：move的操作完全和copy是一样的，它的简写格式有`mo`和`m`。可以对照上面的例子重复操作一遍。更多帮助可以查看`:h :move`和`:h copy`。

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 


每日一Vim（26）---跨行执行〈Normal模式下的〉命令
-----------------------------------
以往，要想在多行执行normal 模式下命令可以通过定义宏来重复操作，今天讲个新鲜的。`:normal`命令。之前讲过一个列子，实现注释多行代码这样一个需求，可选的方法如下三种方式：（当然你还可以相出更多的办法来）  

    import urllib2
    def html():
        f = urllib2.urlopen("http://www.douban.com")
        print f.read()

1. 替换：`:%s/^/#/g`
2. visual block：`gg<Ctrl-v>I#<Esc>`
3.  注释第一行后用`.`重复执行每一行  

我们可以在第三种方法之上用`normal`命令实现上述需求，步骤：  

1. 光标定位到首行，执行：`I#<Esc>`  
2. `jVG`选中之后的所有行
3. `:'<,'>normal .`这样刚刚选中的行都将执行`.`代表的最后一次操作。注：只要输入`:`就能实现`:'<,'>`，你可以注意VIm的左下角的提示。

第四种方法：`:%normal I#`，%代表这个文件，当然你可以选择具体的范围，如：`:1,4normal I#`

总结：`:normal`命令可以执行任何normal 模式下的命令，更多帮助：`:help normal`。对了，上面这个例子你还可以用“宏，record”来达到要求，如果没有想起来，翻开[Recode/Play](http://liuzhijun.iteye.com/blog/1844845)试试吧。

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 

每日一Vim（27）高亮所有搜索模式匹配
-------------------------

`*`  向后搜索光标所在位置的单词  
`#`  向前搜索光标所在位置的单词  
`n`和`N`可以继续向后或向前搜索匹配的字符串  

`:set hlsearch`   高亮所有匹配字符串  
`:nohlsearch`     临时关闭，他的缩写形式是：`:noh`  
`:set nohlsearch` 彻底关闭，只有重新`:set hlsearch`才可以高亮搜索  

`:nnormap <silent> <Space> :nohlsearch<Bar>:echo<CR>`按空格关闭高亮，清空所有已经显示的  
如果你想在高亮与不高亮之间快速切换，可以做一个映射  ：
`:noremap <F4> :set hlsearch! hlsearch?<CR>`  
按回车，临时返回高亮搜索  
`:nnoremap <CR> :nohlsearch<CR><CR>`  

每日一Vim（28）全局命令
----------------
全局命令在Vim中有这举足轻重的作用，特别对于那些重复性的工作尤为有效，它能对匹配的所有行执行某个命令，先来看看它的语法：  

`:[range]global[!]/{pattern}/{command}`  

`[range]`指定作用范围，默认global命令作用于整个文件，不像`:normal`等命令，normal默认是作用于当前行。  

`{pattern}`：对于range范围内的文本，如果匹配pattern，就会执行command，`[!]`：相当于取反（也可以用`vglobal`），也就是不匹配patten的行。  

`command`默认是`print`，打印文本行。  

####举例：
1. 实现Linux命令`tac`的功能（与cat对应的一个命令，反向输入文本行）  
`:g/^/m 0`   这里的`^`表示所有行（包括空行），`.`表示非空行，`m 0`表示将当前行移至第0行。这样就实现了tac的功能。  

2. `grep`：使用Linux的朋友对grep再熟悉不过了，它其实就是`:g/re/p`的缩写，re表示regular express，p表示print
3. `vred`：删除不匹配re的行，v就是vglobal的缩写，比如删除所有不包含`href`的行：`:v/href/d` 
4. 排序：对于下面的css片段:

        div{
            border:0;
            margin:0;
            padding:0;
            font-size:12px;
            font:inherit;
            vertical-align:baseline;
        }
我们想把{}中的样式按照字母的顺序排列成如下:  

        div{
            border:0;
            font-size:12px;
            font:inherit;
            margin:0;
            padding:0;
            vertical-align:baseline;
        }

我们可以使用命令：`:g/{/ .+1,/}/-1 sort`，这个命令看起来很复杂，好像也不符合global的语法。其实对于global语法，可以扩展成：`:g/{pattern}/[range][cmd]`，就是说cmd前面还可以指定range.因此我们可以把上面的命令来做一次剖析： 
 
`.+1,/}/-1 sort` 这个命令就相当于`[range][cmd]`，这里的range范围为：当前行（`.`）的下一行（`+1`）直到（`,`）匹配（`}`）的前一行（`-1`）。如此一来这条完整的命令就好解释了，表示`{`的下一行一直到`}`的上一行执行sort命令。  

费了这么大心思就为了这么一小块代码排个序，看似有点不值，完全可以把大括号里面的内容选中后执行sort就得了嘛，干嘛这么费劲啊，你可别忘了，global的厉害，它可以作用于这个文件，如果css文件有上百行，甚至千行，如果使用V模式执行sort麻烦可大了。  

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 

每日一Vim（29）ctags
--------------------
每日一Vim系列文章到目前刚好30篇，内容差不多可以应付日常工作的百分之七八十，当然还有很多细节包括插件，以及如何编写自己的插件等等。从这篇文章开始，我会把脚步稍微放慢点，进一步放低更新频率，有句话叫*easy come ,easy go*，学的快，忘得也快，还是要经常温故。好了，上次有篇文章讲了ctags、taglist等插件的安装，今天讲讲怎么使用ctags吧。  

简单来说，Ctags的作用就是在一个包含有源代码文件的目录下生成一个tag文件（可以理解为索引文件），以便vim编辑器能快速定位到文件某个位置的工具。那到底怎么使用它呢？  

如果你正确安装了ctags的话（参考：http://liuzhijun.iteye.com/blog/1843522 ），直接在命令行就可以直接运行ctags命令。

`ctags -R *`：  
  直接在命令行运行上面这条命令，意思是：为当前目录以及子目录的所有文件创建一个tags文件，vim启动时就会自动载入该文件，tags文件中包含什么内容呢？你可以试着打开看看。一般包含的对象包括：
>类（class）、接口（interface）、枚举
变量
成员变量，方法

`gvim -t $tag`：打开定义有$tag的文件，比如 `gvim -t Person`就会打开包含有Person变量或类型等关键字的文件。  
`ts`：列出哪些地方出现有$tag关键字  
`tn`：如果打开有tag出现在多处地方，就可以用tp切换，移动到下一处  
`tp`：与上面的命令作用是一样的，移动方向相反  
`Ctrl+]`：这个命令可以让光标直接定位到$tag的定义的地方  
`Ctrl+T`：回到最初打开文件的位置  

当然，想充分利用好tags还得和taglist等插件结合起来用，下次再介绍吧！  

转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345) 

每日一Vim（30）合二为一
-----------------------
有句英语叫做：*two for the price of one* ,它的意思是买一送一，Vim中有很多的买一送一的命令，也叫做合二为一的命令，今天摘出一些常见的买一送一的命令吧。  

C == c$  删除光标出字符后直到行末，然后插入模式  
s == cl  删除当前字符然后进入插入模式  
S == ^C  删除整行，然后进入插入模式  
I == ^i  在行首插入  
A == $a  在行末追加
o == A<Enter>  在下一行插入  
O = ko   在上一行插入  

`;`的作用，举例：  

var foo = "method("+arg1+","+arg2+")"  
想让他变美观点，可以这样:  
var foo = "method(" + arg1 + "," + arg2 + ")"  
命令：`f+`，‘`s`,` + <Esc>`，然后重复执行：`;.`，分号可以让你查找下一个f命令搜索的关键字.




    "注：双引号表示注释
    "这个我的vim的配置，我主要用来做Python开发
    
    "默认文件编码
    set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1
    set fileencoding=utf-8
    set encoding=utf-8   "设置vim内部编码格式
    
    colorscheme desert   "编辑器背景颜色
    
    syntax on   "语法
    
    " 解决windows下如果encoding设置utf-8，菜单会乱码问题
     set langmenu=zh_CN.UTF-8
     language message zh_CN.UTF-8
     source $VIMRUNTIME/delmenu.vim
     source $VIMRUNTIME/menu.vim
    
    
    "  以下命令代码缩进相关
    "set autoindent  "继承前一行的缩进
    set smartindent
    set smarttab
    set expandtab   "tab都用空格代替
    set softtabstop=4  "tab=四个空格
    set tabstop=4
    set shiftwidth=4
    "set textwidth=79
    
    set nocompatible "不兼容vi的键盘模式
    set ruler  "在状态行显示光标所在位置的行号和列号
    set nu
    set mouse=a
    
    "不生成临时文件
    set noswapfile
    set nobackup
    set backspace=2  "允许退格键删除字符
    set ignorecase  "搜索忽略大小写
    
    "禁掉箭头移动功能
    nnoremap <up> <nop>
    nnoremap <down> <nop>
    nnoremap <left> <nop>
    nnoremap <right> <nop>
    
    "markdown 语法，在浏览器查看效果，自动刷新
    function! ViewAtChrome(name)
        let file = expand("%:p")
        exec ":update " . file
        let l:browser = {
            "cr":"C:/Program Files (x86)/Google/Chrome/Application/chrome.exe"   
            }
        exec ":silent !start".l:browsers[a:name]."file://".file
    endfunction 
    
    "快捷键  调出浏览器
    nmap <f4>cr :call ViewAtChrome("cr")<cr>
    
    "快捷键
    ab reprint 转载请注明出处，谢谢合作！作者---[zhijun](http://weibo.com/527355345)
    
    "缩写时提示
    function! s:forxAsk(forx,expansion)
        let answer = confirm("使用缩写'" . a:forx ."'?","&Yes\n&No",1)
        return answer == 1 ? a:expansion :a:forx
    endfunction
    :iabbrev <expr> forx <SID>forxAsk('forx','for(x=0;x<100;x++){<CR><CR>}<Esc>gi<Tab>')
    
    
    "自动补全
    filetype plugin indent on
    set completeopt=longest,menu
    "自动补全命令时使用菜单式匹配列表
    set wildmenu
    " 在windows下Vim7的omni-completion功能不支持64位的python，所以按Ctrl-x
    " Ctrl-O无效，必须换成32位的
    autocmd FileType python set omnifunc=pythoncomplete#Complete
    autocmd FileType html set omnifunc=htmlcomplete#COmpleteTags
    "Pydiction
    let g:pydiction_location='E:\Vim\vim73\complete-dict'
    
    "TagList
    let Tlist_Show_One_File=1
    let Tlist_Exit_OnlyWindow=1
    
    "===========  F5 run python ====================
    autocmd BufRead *.py set makeprg=python\ -c\ \"import\ py_compile,sys;\ sys.stderr=sys.stdout;\ py_compile.compile(r'%')\"
    autocmd BufRead *.py set efm=%C\ %.%#,%A\ \ File\ \"%f\"\\,\ line\ %l%.%#,%Z%[%^\ ]%\\@=%m
    autocmd BufRead *.py nmap <F5> :!python %<CR>
    
    autocmd BufRead *.py set tabstop=4
    autocmd BufRead *.py set nowrap
    autocmd BufRead *.py set go+=b
    
    "F8切换到taglist窗口
    nnoremap <silent><F8> :TlistToggle<CR>
    
    ""http://www.cnblogs.com/renrenqq/archive/2010/09/09/1813669.html
    ""https://github.com/rkulla/pydiction
    
    "常用的折叠方式就两种，indent和marker
    "indent方式会利用缩进自动进行折叠
    set foldmethod=indent

" 无论是normal模式还是插入模式还是visual模式，按crtl+s 保存文件
nmap <c-s> :w<CR>
vmap <c-s> <Esc><c-s>gv
imap <c-s> <Esc><c-s>

10. [正则表达式](./10.md) 
11. [每日一Vim11](./11.md)
12. [每日一Vim12---ab与map](./12.md)
13. [每日一Vim13  多窗口](./13.md)
14. [每日一Vim14  标签页](./14.md)
15. [每日一Vim15 折叠](./15折叠.md)
16. [每日一Vim16 Visual 模式（0）](./16.md)
17. [每日一Vim17 Visual 模式（1）](./17.md)
18. [每日一Vim18 Text-Objects](./18.md)
19. [每日一Vim19 Visaul 模式（2）](./19.md)
20. [每日一Vim20 Taglist初体验](./20.md)
21. [每日一Vim21 又谈abbreviation](./21.md)
22. [每日一Vim22 编码设置](./22.md)
23. [每日一Vim23 filetype](./23.md)
24. [每日一Vim24 record、play](./24.md)
25. [每日一Vim25 行复制与移动](./25.md)
26. [每日一Vim26 跨行执行〈Normal模式下的〉命令](./26.md)
27. [每日一Vim27 高亮所有搜索模式匹配](./27.md)
28. [每日一Vim28 全局命令](./28.md)
[我的vim配置](./one_day_one_vim/vimrc.md)  

﻿###学习笔记
在这里记录自己的学习笔记，有些文章是半成品，部分完整文章有可能会发布在自己的[博客](http://foofish.net)里面。用GitHub记录的一个好处是版本控制，当然有时候我也用Evernote来记录。  

####Python
5. [collections学习笔记](./note/python/collections.md)
5. [函数式编程------序列处理函数](./note/python/function_programming_of_function_processing_functions.md)
6. [协程](./note/python/coroutine.md)
7. [装饰器](./note/python/decorators.md)
10. [异常](./note/python/exception.md)
11. [yield 生成器](./note/python/generator.md)
12. [迭代器与生成器的区别](./note/python/iterator_generator.md)
13. [python json](./note/python/json.md)
15. [Python虚拟环境：virtualenv](./note/python/virtualenv.md)
16. [Python实用技巧](./note/python/useful_features.md)
17. [python测试](./note/python/testing.md)
18. [gevent简介](./note/python/gevent.md)
19. [Django应用部署(nginx、gunicorn、virtualenv、supervisor)](.\note\python\deploy_django_with_nginx.md)
20. [理解WSGI](./note/python/wsgi.md)
21. [Flask之Hello world详解](./note/python/flask.md)

#####Django
1. [Django测试指南](./note/python/a_guide_to_testing_in_django.md)
2. [Django模版语言](./note/python/django_template.md)
3. [使用django-simple-captcha遇到的坑](./note/python/captcha.md)
3. [Python/Django编程实践指南](./note/python/code_style.md)
8. [Django Form](./note/python/django_form.md)
9. [Django url()函数详解](./note/python/django_url.md)
10. [Django signal](./note/python/signals.md)


#####Mako模板

5. [mako简介](./note/python/mako.md)

#####SQLAlchemy
14. [SQLAlchemy学习笔记](./note/python/sqlalchemy.md)

####Java
此系列文章绝大部分发布在[importnew.com](http://www.importnew.com)网站上  

1. [JDBC批处理Select语句](./note/java/JDBC Performance Tips.md)
2. [JDBC为什么要使用PreparedStatement而不是Statement](./note/java/Why use PreparedStatement in Java JDBC .md)
3. [Java为什么需要Lambda表达式（-）](./note/java/Why W Need Lambda Expressions in Java Part2.md)
4. [深入单例模式](./note/java/singleton.md)
5. [范行实践](./note/java/Generic.md)
6. [类加载与初始化](./note/java/classloading and initialization.md)

####Vim
[Vim相关文章](./note/vim/目录.md)，早期写的一些文章可以在我的旧博客：[liuzhijun.iteye.com](http://liuzhijun.iteye.com/category/270228)查看到  

10. [正则表达式](./note/vim/10.md) 
11. [Vim11](./note/vim/11.md)
12. [Vim12---ab与map](./note/vim/12.md)
13. [Vim13  多窗口](./note/vim/13.md)
14. [Vim14  标签页](./note/vim/14.md)
15. [Vim15 折叠](./note/vim/15折叠.md)
16. [Vim16 Visual 模式（0）](./note/vim/16.md)
17. [Vim17 Visual 模式（1）](./note/vim/17.md)
18. [Vim18 Text-Objects](./note/vim/18.md)
19. [Vim19 Visaul 模式（2）](./note/vim/19.md)
20. [Vim20 Taglist初体验](./note/vim/20.md)
21. [Vim21 又谈abbreviation](./note/vim/21.md)
22. [Vim22 编码设置](./note/vim/22.md)
23. [Vim23 filetype](./note/vim/23.md)
24. [Vim24 record、play](./note/vim/24.md)
25. [Vim25 行复制与移动](./note/vim/25.md)
26. [Vim26 跨行执行〈Normal模式下的〉命令](./note/vim/26.md)
27. [Vim27 高亮所有搜索模式匹配](./note/vim/27.md)
28. [Vim28 全局命令](./note/vim/28.md)
[我的vim配置](./note/vim/vimrc.md)  

####memcached
1. [入门安装篇](./note/memcached/introduce_install.md)  
2. [命令介绍篇](./note/memcached/telnet_command.md)
3. 
4. 

####redis
1. [入门篇](./note/redis/introduce.md)


####sphinx/coreseek
1. [sphinx笔记](./note/python/sphinx/introduce.md)  
不定时更新 


