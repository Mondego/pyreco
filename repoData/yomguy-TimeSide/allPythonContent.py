__FILENAME__ = conf
# -*- coding: utf-8 -*-
#
# TimeSide documentation build configuration file, created by
# sphinx-quickstart on Thu Aug 22 10:49:09 2013.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os


# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
sys.path.insert(0, os.path.abspath('../../'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinx.ext.coverage', 'sphinx.ext.viewcode', 'sphinx.ext.autosummary', 'sphinx.ext.doctest', 'numpydoc']

doctest_path = os.path.abspath('../../')
doctest_global_setup = '''
import os
# os.getcwd() -> /doc
wav_file = os.path.join(os.getcwd(),'../tests/samples/sweep.mp3')
'''

autodoc_default_flags = 'show-inheritance'
autoclass_content = 'both'

#autosummary_generate = True
numpydoc_show_class_members = False

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = u'TimeSide'
copyright = u'2014, Guillaume Pellerin, Paul Brossier, Thomas Fillon'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
from timeside import __version__ as TimeSideVersion
# The short X.Y version.
version = '.'.join(TimeSideVersion.split('.')[0:2])
# The full version, including alpha/beta/rc tags.
release = TimeSideVersion

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
modindex_common_prefix = ['timeside.']


# -- Options for HTML output ---------------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
# html_theme = 'default'
import sphinx_rtd_theme
html_theme = 'sphinx_rtd_theme'
html_theme_path = [sphinx_rtd_theme.get_html_theme_path()]

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True
# This is required to remove the superfluous np module index added by numpydoc
html_domain_indices = ['py-modindex']

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'TimeSidedoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'TimeSide.tex', u'TimeSide Documentation',
   u'Guillaume Pellerin, Paul Brossier, Thomas Fillon', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'timeside', u'TimeSide Documentation',
     [u'Guillaume Pellerin, Paul Brossier, Thomas Fillon'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'TimeSide', u'TimeSide Documentation',
   u'Guillaume Pellerin, Paul Brossier, Thomas Fillon', 'TimeSide', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'


# -- Options for Epub output ---------------------------------------------------

# Bibliographic Dublin Core info.
epub_title = u'TimeSide'
epub_author = u'Guillaume Pellerin, Paul Brossier, Thomas Fillon'
epub_publisher = u'Guillaume Pellerin, Paul Brossier, Thomas Fillon'
epub_copyright = u'2014, Guillaume Pellerin, Paul Brossier, Thomas Fillon'

# The language of the text. It defaults to the language option
# or en if the language is not set.
#epub_language = ''

# The scheme of the identifier. Typical schemes are ISBN or URL.
#epub_scheme = ''

# The unique identifier of the text. This can be a ISBN number
# or the project homepage.
#epub_identifier = ''

# A unique identification for the text.
#epub_uid = ''

# A tuple containing the cover image and cover page html template filenames.
#epub_cover = ()

# HTML files that should be inserted before the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_pre_files = []

# HTML files shat should be inserted after the pages created by sphinx.
# The format is a list of tuples containing the path and title.
#epub_post_files = []

# A list of files that should not be packed into the epub file.
#epub_exclude_files = []

# The depth of the table of contents in toc.ncx.
#epub_tocdepth = 3

# Allow duplicate toc entries.
#epub_tocdup = True

########NEW FILE########
__FILENAME__ = get_samples
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from tools import check_samples

check_samples()

########NEW FILE########
__FILENAME__ = examples
# -*- coding: utf-8 -*-

from timeside.core import Processor, implements, interfacedoc, FixedSizeInputAdapter
from timeside.api import *
import numpy


class Gain(Processor):
    implements(IEffect)

    @interfacedoc
    def __init__(self, gain=1.0):
        self.gain = gain

    @staticmethod
    @interfacedoc
    def id():
        return "test_gain"

    @staticmethod
    @interfacedoc
    def name():
        return "Gain test effect"

    def process(self, frames, eod=False):
        return numpy.multiply(frames, self.gain), eod

########NEW FILE########
__FILENAME__ = example_CMMR
# -*- coding: utf-8 -*-
"""
Created on Tue Jul 16 13:04:49 2013

@author: thomas
"""
from __future__ import division
import timeside
import matplotlib.pyplot as plt
import numpy as np
import sys

if not sys.argv[-1]:
    wav_file = 'toto.wav'
else:
    wav_file = sys.argv[-1]

# normal
decoder = timeside.decoder.FileDecoder(wav_file, start=10, duration=15)
#e = timeside.encoder.VorbisEncoder('output.ogg', overwrite = True)
aubio_pitch = timeside.analyzer.AubioPitch()
aubio_temporal = timeside.analyzer.AubioTemporal()
specgram = timeside.analyzer.Spectrogram()
waveform = timeside.analyzer.Waveform()
#g  =  timeside.grapher.Spectrogram()

pipe = (decoder | aubio_pitch | aubio_temporal | specgram | waveform)
print pipe
pipe.run()

print pipe.results.keys()

# Display Spectrogram + Aubio Pitch + Aubio Beat
plt.figure(1)

spec_res = specgram.results['spectrogram_analyzer']
N = spec_res.parameters['FFT_SIZE']
plt.imshow(20 * np.log10(spec_res.data.T),
           origin='lower',
           extent=[spec_res.time[0], spec_res.time[-1], 0,
                   (N // 2 + 1) / N * spec_res.frame_metadata.samplerate],
           aspect='auto')

res_pitch = aubio_pitch.results['aubio_pitch.pitch']
plt.plot(res_pitch.time, res_pitch.data)


res_beats = aubio_temporal.results['aubio_temporal.beat']

for time in res_beats.time:
    plt.axvline(time, color='r')

plt.title('Spectrogram + Aubio pitch + Aubio beat')
plt.grid()

# Display waveform + Onsets
plt.figure(2)
res_wave = waveform.results['waveform_analyzer']
plt.plot(res_wave.time, res_wave.data)
res_onsets = aubio_temporal.results['aubio_temporal.onset']
for time in res_onsets.time:
    plt.axvline(time, color='g')
plt.grid()
plt.title('Waveform + Aubio onset')
plt.show()

########NEW FILE########
__FILENAME__ = exempleCMMR_vamp
# -*- coding: utf-8 -*-
"""
Created on Fri Oct 11 13:22:37 2013

@author: thomas
"""

from __future__ import division
import timeside
import matplotlib.pyplot as plt
import numpy as np
import sys

#wav_file = sys.argv[-1]
wav_file =  '/home/thomas/code/timeside/TimeSide/tests/samples/sweep.wav'

# normal
d = timeside.decoder.FileDecoder(wav_file)

specgram = timeside.analyzer.Spectrogram()
waveform = timeside.analyzer.Waveform()

# Get available Vamp plugins list
from timeside.analyzer.vamp_plugin import VampSimpleHost
plugins_list = VampSimpleHost.get_plugins_list()

# Display avalaible plugins
print 'index \t soname \t \t identifier \t output '
print '------ \t \t ---------- \t ------ '
for index, line in zip(xrange(len(plugins_list)),plugins_list):
    print '%d : %s \t %s \t %s' % (index,line[0],line[1],line[2])

# Let's choose #7
my_plugin = plugins_list[7]
print my_plugin

#
# Vamp plugin Analyzer
vamp = timeside.analyzer.VampSimpleHost([my_plugin])
#vamp = timeside.analyzer.VampSimpleHost()

#
myPipe = (d | vamp | specgram | waveform).run()

# Get spectrogram result and plot the spectrogram
spec_res = specgram.results['spectrogram_analyzer']
N = spec_res.parameters['FFT_SIZE']
max_freq = (N // 2 + 1) / N * spec_res.frame_metadata.samplerate



# Get the vamp plugin result and plot it
for key in vamp.results.keys():
    print vamp.results[key].data

res_vamp = vamp.results['vamp_simple_host.percussiononsets.detectionfunction']

plt.figure(1)

plt.subplot(2,1,1)
plt.plot(res_vamp.time, res_vamp.data)
plt.xlabel('time in s')
plt.grid
plt.title(res_vamp.name)

plt.subplot(2,1,2)
plt.imshow(20 * np.log10(spec_res.data.T + 1e-6),
           origin='lower',
           extent=[spec_res.time[0], spec_res.time[-1], 0,
                   max_freq],
           aspect='auto')

data = (res_vamp.data - res_vamp.data.mean()).clip(0)
plt.plot(res_vamp.time, abs(data / data.max() * max_freq))


plt.xlabel('time in s')
plt.show()
########NEW FILE########
__FILENAME__ = test_all
# -*- coding: utf-8 -*-

import os, sys
import timeside

path = sys.argv[-1]
filename = path.split(os.sep)[-1]
result_dir = '../results/'

if not os.path.exists(result_dir):
    os.makedirs(result_dir)

decoder  = timeside.decoder.FileDecoder(path)
graphers = timeside.core.processors(timeside.api.IGrapher)
encoders = timeside.core.processors(timeside.api.IEncoder)
analyzers = timeside.core.processors(timeside.api.IAnalyzer)

grapher_list = []
analyzer_list = []
encoder_list = []

pipe = decoder

for grapher in graphers:
    proc = grapher()
    grapher_list.append(proc)
    pipe = pipe | proc

for analyzer in analyzers:
    proc = analyzer()
    analyzer_list.append(proc)
    pipe = pipe | proc

for encoder in encoders:
    path = result_dir + os.sep + filename + '.' + encoder.file_extension()
    proc = encoder(path, overwrite=True)
    encoder_list.append(proc)
    pipe = pipe | proc

print pipe
pipe.run()

for grapher in grapher_list:
    image = result_dir + os.sep + filename + '-' + grapher.id() + '.png'
    grapher.render(image)


########NEW FILE########
__FILENAME__ = test_all_graphers
# -*- coding: utf-8 -*-

import os, sys
import timeside

audio_file = sys.argv[-1]
audio_filename = audio_file.split(os.sep)[-1]
img_dir = '../results/img'

if not os.path.exists(img_dir):
    os.makedirs(img_dir)

decoder  = timeside.decoder.FileDecoder(audio_file)
graphers = timeside.core.processors(timeside.api.IGrapher)
pipe = decoder
proc_list = []

for grapher in graphers:
    proc = grapher()
    proc_list.append(proc)
    print proc.id()
    pipe = pipe | proc

pipe.run()

for grapher in proc_list:
    image = img_dir + os.sep + audio_filename + '-' + grapher.id() + '.png'
    grapher.render(image)

########NEW FILE########
__FILENAME__ = test_analyzer
# -*- coding: utf-8 -*-

import timeside
from sys import stdout
import os.path
import numpy

class TestAnalyzer:

    graphers = timeside.get_processors(timeside.api.IGrapher)
    decoders = timeside.get_processors(timeside.api.IDecoder)
    encoders= timeside.get_processors(timeside.api.IEncoder)
    analyzers = timeside.get_processors(timeside.api.IAnalyzer)

    def __init__(self, path):
        self.source = os.path.join(os.path.dirname(__file__), path)
        print "Processing %s" % self.source
        self.decoder  = timeside.decoder.FileDecoder(self.source)
        print 'format: ', self.decoder.format()
        self.pipe = self.decoder
        self.analyzers_sub_pipe = []

    def process(self):
        for analyzer in self.analyzers:
            sub_pipe = analyzer()
            self.analyzers_sub_pipe.append(sub_pipe)
            self.pipe = self.pipe | sub_pipe
        self.pipe.run()

    def results(self):
        results = []
        for analyzer in self.analyzers_sub_pipe:
            if hasattr(analyzer, 'results'):
                results.append(analyzer.results())
            else:
                value = analyzer.result()
                results.append([{'name':analyzer.name(),
                                'id':analyzer.id(),
                                'unit':analyzer.unit(),
                                'value':str(value)}])
        print results


test = TestAnalyzer('../samples/guitar.wav')
#test = TestAnalyzer('/home/momo/music/wav/Cellar/Cellar-FinallyMix_01.wav')
test.process()
test.results()


########NEW FILE########
__FILENAME__ = test_analyzer3
# -*- coding: utf-8 -*-

import timeside
import sys
import os.path
import numpy
import time


class TestAnalyzer:

    analyzer = timeside.analyzer.Level()

    def __init__(self, path):
        self.source = path
        print "Processing %s" % self.source
        self.decoder  = timeside.decoder.FileDecoder(self.source)
        print 'format: ', self.decoder.format()
        self.pipe = self.decoder
        self.sub_pipe = self.analyzer

    def process(self):
        self.pipe = self.pipe | self.sub_pipe
        self.pipe.run()

    def results(self):
        print {'name':self.analyzer.name(),
                            'id':self.analyzer.id(),
                            'unit':self.analyzer.unit(),
                            'value':str(self.analyzer.value)}

test = TestAnalyzer(sys.argv[-1])
test.process()
test.results()

########NEW FILE########
__FILENAME__ = test_analyzer4
# -*- coding: utf-8 -*-

import timeside
import sys
import os.path
import numpy
import time


class TestAnalyzer:

    analyzer = timeside.analyzer.Level()

    def __init__(self, path):
        self.source = path
        print "Processing %s" % self.source
        self.decoder  = timeside.decoder.FileDecoder(self.source)
        print 'format: ', self.decoder.format()
        self.pipe = self.decoder
        self.sub_pipe = self.analyzer

    def process(self):
        self.pipe = self.pipe | self.sub_pipe
        self.pipe.run()

    def results(self):
        print self.sub_pipe.results()

test = TestAnalyzer(sys.argv[-1])
test.process()
test.results()

########NEW FILE########
__FILENAME__ = test_analyzer_stack
# -*- coding: utf-8 -*-

import timeside
import sys

analyzers = [timeside.analyzer.Level(),
                 timeside.analyzer.AubioTemporal(),]

source = sys.argv[-1]
print "Processing %s" % source
pipe  = timeside.decoder.FileDecoder(source, stack=True)
print 'format: ', pipe.format()
for analyzer in analyzers:
    pipe |= analyzer

pipe.run()
print pipe.results


########NEW FILE########
__FILENAME__ = test_aubio_bpm
# -*- coding: utf-8 -*-

import sys
sys.path.append('/home/momo/dev/aubio/interfaces/python/build/lib.linux-x86_64-2.6/')

import timeside

decoder  =  timeside.decoder.FileDecoder('/home/momo/music_local/Kavinsky - Nightcall EP/01 Nightcall (Feat. Lovefoxxx).mp3')
analyzer = timeside.analyzer.AubioBPM()
(decoder | analyzer).run()
print analyzer.result()



########NEW FILE########
__FILENAME__ = test_aubio_onsetrate
# -*- coding: utf-8 -*-

import timeside

decoder  =  timeside.decoder.FileDecoder('/home/momo/music_local/Kavinsky - Nightcall EP/01 Nightcall (Feat. Lovefoxxx).mp3')
analyzer = timeside.analyzer.AubioOnsetRate()
(decoder | analyzer).run()
print analyzer.result()



########NEW FILE########
__FILENAME__ = test_enc_flac
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.encoder import *
import os.path
import sys

source = sys.argv[-1]
dest = source+'.flac'

decoder  = FileDecoder(source)
encoder  = FlacEncoder(dest, overwrite=True)

(decoder | encoder).run()

########NEW FILE########
__FILENAME__ = test_enc_mp3
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.encoder import *
import os.path
import sys

if len(sys.argv) < 2:
    print 'usage:', sys.argv[0], '<inputfile>'
    sys.exit(1)

source = sys.argv[-1]
dest = source+'.mp3'

print 'converting', source, 'to', dest

decoder  = FileDecoder(source)
encoder  = Mp3Encoder(dest, overwrite=True)

(decoder | encoder).run()

metadata = {'TIT2': 'title',  #title2
             'TCOM': 'composer',  #composer
             'TPE1': 'lead creator', #lead
             'UFID': 'identifier',  #Unique ID...
             'TALB': 'album',  #album
             'TCON': 'genre',  #genre
             'TDRC': '2011', #year
#             'COMM': 'blabla',  #comment
             }

encoder.set_metadata(metadata)
encoder.write_metadata()

########NEW FILE########
__FILENAME__ = test_enc_mp3_by_block
from numpy import vstack, zeros

from timeside.decoder import *
from timeside.encoder import *

import sys, os.path

def transcode(source, target):
    decoder = FileDecoder(source)
    decoder.setup()

    channels  = decoder.channels()
    samplerate = decoder.samplerate()

    print channels, samplerate

    encoder = Mp3Encoder(target)
    encoder.setup(channels = channels, samplerate = samplerate)

    totalframes = 0
    while True:
        frames, eod = decoder.process()
        encoder.process(frames, eod)
        totalframes += frames.shape[0]
        if eod or encoder.eod:
            break

if __name__ == '__main__':

    if len(sys.argv) < 3:
        print 'needs 2 args'
        sys.exit(1)
    transcode(sys.argv[1], sys.argv[2])

########NEW FILE########
__FILENAME__ = test_enc_ogg
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.encoder import *
import os.path
import sys

if len(sys.argv) < 2:
    print 'usage:', sys.argv[0], '<inputfile>'
    sys.exit(1)

source = sys.argv[-1]
dest = source+'.ogg'

print 'converting', source, 'to', dest

decoder  = FileDecoder(source)
encoder  = VorbisEncoder(dest, overwrite=True)

(decoder | encoder).run()

########NEW FILE########
__FILENAME__ = test_enc_webm
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.encoder import *
import os.path
import sys

source = sys.argv[-1]
dest = source+'.webm'

decoder  = FileDecoder(source)
encoder  = WebMEncoder(dest)

(decoder | encoder).run()

########NEW FILE########
__FILENAME__ = test_flac
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.encoder import *
import os.path

source = os.path.join(os.path.dirname(__file__), "../samples/sweep.wav")
dest = os.path.join(os.path.dirname(__file__), "../results/sweep_wav.flac")

decoder  = FileDecoder(source)
encoder  = FlacEncoder(dest)

(decoder | encoder).run()

########NEW FILE########
__FILENAME__ = test_limsi_sad
# -*- coding: utf-8 -*-

import timeside

decoder  =  timeside.decoder.FileDecoder('/home/momo/music_local/test/sweep.wav')
analyzer = timeside.analyzer.LimsiSad('etape')
(decoder | analyzer).run()
print analyzer.results()

########NEW FILE########
__FILENAME__ = test_live
# -*- coding: utf-8 -*-

import timeside
import matplotlib.pyplot as plt
import numpy as np


d = timeside.decoder.LiveDecoder(num_buffers=256)
w = timeside.analyzer.Waveform()
s = timeside.analyzer.Spectrogram()
m = timeside.encoder.Mp3Encoder('/tmp/test_live.mp3', overwrite=True)
v = timeside.encoder.VorbisEncoder('/tmp/test_live.ogg', overwrite=True)

(d | w | s | m | v).run()

plt.figure(1)
plt.plot(w.results['waveform_analyzer'].time, w.results['waveform_analyzer'].data)

plt.figure(2)
sr = s.results['spectrogram_analyzer']
N = sr.parameters['FFT_SIZE']
plt.imshow(20 * np.log10(sr.data.T),
           origin='lower',
           extent=[sr.time[0], sr.time[-1], 0,
                   (N // 2 + 1) / N * sr.frame_metadata.samplerate],
           aspect='auto')

plt.show()

########NEW FILE########
__FILENAME__ = test_lolevel
# -*- coding: utf-8 -*-

from timeside.tests.api.examples import Gain
from timeside.core import *
from timeside.decoder import *
from timeside.analyzer import *
from timeside.encoder import *
from timeside.api import *

import sys
if len(sys.argv) > 1:
    source = sys.argv[1]
else:
    import os.path
    source= os.path.join (os.path.dirname(__file__),  "../samples/guitar.wav")

Decoder = FileDecoder
print "Creating decoder with id=%s for: %s" % (Decoder.id(), source)
decoder = Decoder(source)
analyzer = MaxLevel()
decoder.setup()
nchannels  = decoder.channels()
samplerate = decoder.samplerate()
nframes = decoder.nframes()
analyzer.setup(nchannels, samplerate)

print "Stats: duration=%f, nframes=%d, nchannels=%d, samplerate=%d, resolution=%d" % (
        nframes / float(samplerate), nframes, nchannels, samplerate, decoder.resolution())

while True:
    frames, eod = decoder.process()
    analyzer.process(frames, eod)
    if eod:
        break

max_level = analyzer.result()
print "Max level: %f" % max_level

destination = "../results/guitar_normalized.wav"
Encoder = WavEncoder
print "Creating encoder with id=%s for: %s" % (Encoder.id(), destination)
encoder = Encoder(destination)

gain = 1
if max_level > 0:
    gain = 0.9 / max_level

effect = Gain(gain)

decoder.setup()
effect.setup(decoder.channels(), decoder.samplerate())
encoder.setup(effect.channels(), effect.samplerate())

print "Applying effect id=%s with gain=%f" % (effect.id(), gain)

while True:
    frames, eod = decoder.process()
    encoder.process(*effect.process(frames, eod))
    if eod:
        break


########NEW FILE########
__FILENAME__ = test_lolevel_streaming
# -*- coding: utf-8 -*-

from timeside.core import *
from timeside.decoder.file import FileDecoder
from timeside.encoder import Mp3Encoder

import sys
if len(sys.argv) > 1:
    source = sys.argv[1]
else:
    import os.path
    source= os.path.join (os.path.dirname(__file__),  "../samples/sweep.flac")

decoder = FileDecoder(source)

print "Creating decoder with id=%s for: %s" % (decoder.id(), source)
decoder.setup()

channels  = decoder.channels()
print 'channels :', channels
samplerate = decoder.samplerate()
#nframes = decoder.nframes()

dest1 = "/tmp/test_filesink.mp3"
dest2 = "/tmp/test_appsink.mp3"
f = open(dest2,'w')

streaming=True
encoder = Mp3Encoder(dest1, streaming=True, overwrite=True)
encoder.setup(channels=channels, samplerate=samplerate,
              blocksize=decoder.blocksize(), totalframes=decoder.totalframes())
while True:
    encoder.process(*decoder.process())
    if streaming:
        f.write(encoder.chunk)
    if encoder.eod:
        break

f.close()
print encoder.pipe

import os
dest1_size = os.path.getsize(dest1)
dest2_size = os.path.getsize(dest2)

print "sizes : %d , %d" % (dest1_size, dest2_size)

assert os.path.getsize(dest1)==os.path.getsize(dest2)

########NEW FILE########
__FILENAME__ = test_lolevel_streaming_mp3
# -*- coding: utf-8 -*-

import os, sys, time

from timeside.core import *
from timeside.decoder import *
from timeside.analyzer import *
from timeside.encoder import *
from timeside.api import *


if len(sys.argv) > 1:
    source = sys.argv[1]
else:
    import os.path
    source= os.path.join(os.path.dirname(__file__),  "../samples/sweep.wav")

streaming = True

dest1 = "/tmp/test_filesink.mp3"
dest2 = "/tmp/test_appsink.mp3"
f = open(dest2,'w')

decoder = FileDecoder(source)
decoder.setup()

encoder = Mp3Encoder(dest1, streaming=streaming, overwrite=True)
encoder.setup(channels=decoder.channels(), samplerate=decoder.samplerate(),
              blocksize=decoder.blocksize(), totalframes=decoder.totalframes())

print encoder.pipe

while True:
    encoder.process(*decoder.process())
    # time.sleep(0.1)
    if streaming:
    	f.write(encoder.chunk)
    if encoder.eod:
        break

decoder.release()
encoder.release()
f.close()

os.system('ls -tl /tmp/test*')
########NEW FILE########
__FILENAME__ = test_lolevel_streaming_threaded
# -*- coding: utf-8 -*-

from timeside.core import *
from timeside.decoder.file import FileDecoder
from timeside.encoder import Mp3Encoder

import sys
if len(sys.argv) > 1:
    source = sys.argv[1]
else:
    import os.path
    audio_file = '../samples/sweep.flac'
    source = os.path.join(os.path.dirname(__file__), audio_file)

#source = '/home/thomas/data/CNRSMH_E_1985_001_001_001_04.wav'
decoder = FileDecoder(source)

print "Creating decoder with id=%s for: %s" % (decoder.id(), source)

dest1 = "/tmp/test_filesink.mp3"
dest2 = "/tmp/test_appsink.mp3"
f = open(dest2, 'w')


streaming = True
encoder = Mp3Encoder(dest1, streaming=streaming, overwrite=True)

pipe = (decoder | encoder)
print pipe
#pipe.run()

for chunk in pipe.stream():
    f.write(chunk)
#while True:
#    encoder.process(*decoder.process())
#    if streaming:
#        f.write(encoder.chunk)
#    if encoder.eod:
#        break

f.close()
#print encoder.pipe

import os
dest1_size = os.path.getsize(dest1)
dest2_size = os.path.getsize(dest2)

print "Filesink filesize: %d" % dest1_size
print "Appsink filesize: %d" % dest2_size
#assert os.path.getsize(dest1) == os.path.getsize(dest2)

########NEW FILE########
__FILENAME__ = test_lolevel_streaming_threaded_ogg
# -*- coding: utf-8 -*-

from timeside.core import *
from timeside.decoder.file import FileDecoder
from timeside.encoder import Mp3Encoder, VorbisEncoder

import sys
if len(sys.argv) > 1:
    source = sys.argv[1]
else:
    import os.path
    audio_file = '../samples/sweep.flac'
    source = os.path.join(os.path.dirname(__file__), audio_file)

decoder = FileDecoder(audio_file)

print "Creating decoder with id=%s for: %s" % (decoder.id(), audio_file)

dest1 = "/tmp/test_filesink.ogg"
dest2 = "/tmp/test_appsink.ogg"
f = open(dest2, 'w')


streaming = True
encoder = VorbisEncoder(dest1, streaming=streaming, overwrite=True)

pipe = (decoder | encoder)
print pipe
#pipe.run()

for chunk in pipe.stream():
    f.write(chunk)
#while True:
#    encoder.process(*decoder.process())
#    if streaming:
#        f.write(encoder.chunk)
#    if encoder.eod:
#        break

f.close()
#print encoder.pipe

import os
dest1_size = os.path.getsize(dest1)
dest2_size = os.path.getsize(dest2)

print "sizes : %d , %d" % (dest1_size, dest2_size)

assert os.path.getsize(dest1) == os.path.getsize(dest2)

# Sometime randomly freeze
# Appsink file is always 1 buffer longer than filesink
# TODO : Try to transcode with a pure gstreamer pipe to see the file length
# maybe appsink is fine but filesink not ? just to be checked

########NEW FILE########
__FILENAME__ = test_lolevel_streaming_vorbis
# -*- coding: utf-8 -*-

from timeside.core import *
from timeside.decoder import *
from timeside.analyzer import *
from timeside.encoder import *
from timeside.api import *

import sys
if len(sys.argv) > 1:
    source = sys.argv[1]
else:
    import os.path
    source= os.path.join (os.path.dirname(__file__),  "../samples/sweep.flac")

decoder = FileDecoder(source)
print "Creating decoder with id=%s for: %s" % (decoder.id(), source)
decoder.setup()
channels  = decoder.channels()
print 'channels :', channels
samplerate = decoder.samplerate()
nframes = decoder.nframes()

dest1 = "/tmp/test_filesink.ogg"
dest2 = "/tmp/test_appsink.ogg"
f = open(dest2,'w')

streaming=True
encoder = VorbisEncoder(dest1, streaming=True)
encoder.setup(channels=channels, samplerate=samplerate)

print encoder.pipe

while True:
    encoder.process(*decoder.process())
    if streaming:
        f.write(encoder.chunk)
    if encoder.eod :
        break

f.close()
print encoder.pipe

########NEW FILE########
__FILENAME__ = test_mp3
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.encoder import *
import os.path

source = os.path.join(os.path.dirname(__file__), "../samples/sweep.wav")
dest = os.path.join(os.path.dirname(__file__), "/tmp/sweep_wav.mp3")

decoder  = FileDecoder(source)
encoder  = Mp3Encoder(dest)

(decoder | encoder).run()

metadata = {'TIT2': 'title',  #title2
             'TCOM': 'composer',  #composer
             'TPE1': 'lead creator', #lead
             'UFID': 'identifier',  #Unique ID...
             'TALB': 'album',  #album
             'TCON': 'genre',  #genre
             'TDRC': '2011', #year
#             'COMM': 'blabla',  #comment
             }

encoder.set_metadata(metadata)
encoder.write_metadata()


########NEW FILE########
__FILENAME__ = test_mp3_2
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.encoder import *
import os.path

source = os.path.join(os.path.dirname(__file__), "../samples/sweep.wav")
dest = os.path.join(os.path.dirname(__file__), "/tmp/sweep_wav.mp3")

decoder  = FileDecoder(source)
encoder  = Mp3Encoder(dest)

(decoder | encoder).run()

metadata = {'TIT2': 'title',  #title2
             'TCOM': 'composer',  #composer
             'TPE1': 'lead creator', #lead
             'UFID': 'identifier',  #Unique ID...
             'TALB': 'album',  #album
             'TCON': 'genre',  #genre
             'TDRC': '2011', #year
#             'COMM': 'blabla',  #comment
             }

encoder.set_metadata(metadata)
encoder.write_metadata()


########NEW FILE########
__FILENAME__ = test_mp3_3
# -*- coding: utf-8 -*-

import sys
import time
import timeside

metadata = {'TIT2': 'title',  #title2
             'TCOM': 'composer',  #composer
             'TPE1': 'lead creator', #lead
             'UFID': 'identifier',  #Unique ID...
             'TALB': 'album',  #album
             'TCON': 'genre',  #genre
             'TDRC': '2011', #year
#             'COMM': 'blabla',  #comment
             }

decoder  =  timeside.decoder.FileDecoder(sys.argv[-1])

encoder  =  timeside.encoder.Mp3Encoder('/tmp/output.mp3', overwrite=True)
encoder.set_metadata(metadata)

(decoder | encoder).run()

########NEW FILE########
__FILENAME__ = test_parent
# -*- coding: utf-8 -*-

import timeside
import os.path

source = os.path.join(os.path.dirname(__file__), "../samples/sweep.wav")

d = timeside.decoder.FileDecoder(source)
a  = timeside.analyzer.OnsetDetectionFunction()

pipe = d | a
pipe.run()

print pipe.results

a.results.to_hdf5('../results/sweep_odf.hdf5')

########NEW FILE########
__FILENAME__ = test_pipe
# -*- coding: utf-8 -*-

from timeside.tests.api.examples import Gain
from timeside.core import *
from timeside.decoder import *
from timeside.analyzer import *
from timeside.encoder import *
from timeside.api import *
from sys import stdout
import os.path
import numpy

source = os.path.join(os.path.dirname(__file__),  "../samples/guitar.wav")

print "Normalizing %s" % source
decoder  = FileDecoder(source)
maxlevel = MaxLevel()
duration = Duration()

(decoder | maxlevel | duration).run()

gain = 1
if maxlevel.result() < 0:
    gain = 0.9 / numpy.exp(maxlevel.result()/20)

print "input maxlevel: %f" % maxlevel.result()
print "gain: %f" % gain
print "duration: %f %s" % (duration.result(), duration.unit())

gain     = Gain(gain)
encoder  = WavEncoder("../results/guitar_normalized.wav")

subpipe  = gain | maxlevel

(decoder | subpipe | encoder).run()

print "output maxlevel: %f" % maxlevel.result()



########NEW FILE########
__FILENAME__ = test_results
# -*- coding: utf-8 -*-

import timeside.decoder
import timeside.analyzer


decoder  =  timeside.decoder.FileDecoder('/home/momo/dev/timeside/timeside/tests/samples/sweep.wav')
analyzer = timeside.analyzer.AubioMelEnergy()
(decoder | analyzer).run()

print len(analyzer.results())
print len(analyzer.results())
print len(analyzer.results())




########NEW FILE########
__FILENAME__ = test_spectrogram
# -*- coding: utf-8 -*-

import os
from timeside.core import *
from timeside.api import *
from timeside.decoder import *
from timeside.grapher import *

sample_dir = '../samples'
img_dir = '../results/img'
if not os.path.exists(img_dir):
    os.mkdir(img_dir)

test_dict = {'sweep.wav': 'spec_wav.png',
            'sweep.flac': 'spec_flac.png',
            'sweep.ogg': 'spec_ogg.png',
            'sweep.mp3': 'spec_mp3.png',
            }

for source, image in test_dict.iteritems():
    audio = os.path.join(os.path.dirname(__file__), sample_dir + os.sep + source)
    image = img_dir + os.sep + image
    print 'Test : decoder(%s) | waveform (%s)' % (source, image)
    decoder  = FileDecoder(audio)
    spectrogram = Spectrogram()
    (decoder | spectrogram).run()
    print 'frames per pixel = ', spectrogram.samples_per_pixel
    print "render spectrogram to: %s" %  image
    spectrogram.render(image)




########NEW FILE########
__FILENAME__ = test_spectrogram2
# -*- coding: utf-8 -*-

import os
from timeside.decoder import *
from timeside.grapher import *

sample_dir = '../samples'
img_dir = '../results/img'
if not os.path.exists(img_dir):
    os.mkdir(img_dir)

test_dict = {'sweep.wav': 'spec_wav.png',}

for source, image in test_dict.iteritems():
    audio = os.path.join(os.path.dirname(__file__), sample_dir + os.sep + source)
    image = img_dir + os.sep + image
    print 'Test : decoder(%s) | waveform (%s)' % (source, image)
    decoder  = FileDecoder(audio)
    spectrogram = SpectrogramLinear()
    (decoder | spectrogram).run()
    print 'frames per pixel = ', spectrogram.samples_per_pixel
    print "render spectrogram to: %s" %  image
    spectrogram.render(image)




########NEW FILE########
__FILENAME__ = test_spectrogram3
# -*- coding: utf-8 -*-

import os
import timeside

audio_dir = '/home/momo/music_local/test/aboul/wav/'
audio_file = 'aboul.wav'
audio_path = audio_dir + audio_file
img_dir = '../results/img'

if not os.path.exists(img_dir):
    os.makedirs(img_dir)

decoder  = timeside.decoder.FileDecoder(audio_path)
analyzers = timeside.core.processors(timeside.api.IAnalyzer)
pipe = decoder

for analyzer in analyzers:
    subpipe = analyzer()
    analyzers_sub.append(subpipe)
    pipe = pipe | subpipe

image = img_dir + os.sep + source + '.png'
print 'Test : decoder(%s) | waveform (%s)' % (source, image)

spectrogram = SpectrogramLinear(width=10240, height=512, bg_color=(0,0,0), color_scheme='default')
(decoder | spectrogram).run()
print 'frames per pixel = ', spectrogram.samples_per_pixel
print "render spectrogram to: %s" %  image
spectrogram.render(image)


########NEW FILE########
__FILENAME__ = test_vorbis
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.encoder import *
import os.path

source = os.path.join(os.path.dirname(__file__), "../samples/sweep.wav")
dest = os.path.join(os.path.dirname(__file__), "../results/sweep_wav.ogg")

decoder  = FileDecoder(source)
encoder  = VorbisEncoder(dest)

(decoder | encoder).run()

########NEW FILE########
__FILENAME__ = test_wav
# -*- coding: utf-8 -*-

from timeside.decoder import *
from timeside.analyzer import *
from timeside.encoder import *

import os.path
source = os.path.join(os.path.dirname(__file__),  "../samples/sweep.wav")
dest = os.path.join(os.path.dirname(__file__), "../results/sweep_wav.wav")

decoder  = FileDecoder(source)
encoder  = WavEncoder(dest)

(decoder | encoder).run()


########NEW FILE########
__FILENAME__ = test_waveform
# -*- coding: utf-8 -*-

import os
from timeside.core import *
from timeside.api import *
from timeside.decoder import *
from timeside.grapher import *

sample_dir = '../samples'
img_dir = '../results/img'
if not os.path.exists(img_dir):
    os.makedirs(img_dir)

test_dict = {'sweep.wav': 'waveform_wav.png',
            'sweep.flac': 'waveform_flac.png',
            'sweep.ogg': 'waveform_ogg.png',
            'sweep.mp3': 'waveform_mp3.png',
            }

for source, image in test_dict.iteritems():
    audio = os.path.join(os.path.dirname(__file__), sample_dir + os.sep + source)
    image = img_dir + os.sep + image
    print 'Test : decoder(%s) | waveform (%s)' % (source, image)
    decoder  = FileDecoder(audio)
    waveform = Waveform(width=1024, height=256, bg_color=(255,255,255), color_scheme='default')
    (decoder | waveform).run()
    print 'frames per pixel = ', waveform.samples_per_pixel
    print "render waveform to: %s" %  image
    waveform.render(image)

########NEW FILE########
__FILENAME__ = test_waveform3
# -*- coding: utf-8 -*-

import os
from timeside.core import *
from timeside.api import *
from timeside.decoder import *
from timeside.grapher import *

sample_dir = '/home/momo/music_local/Isabelle Aboulker/Mon imagier des instruments/wav/'
img_dir = '../results/img'
if not os.path.exists(img_dir):
    os.mkdir(img_dir)

for source in os.listdir(sample_dir):
    audio = sample_dir + os.sep + source
    image = img_dir + os.sep + source + '.png'
    print 'Test : decoder(%s) | waveform (%s)' % (source, image)
    decoder  = FileDecoder(audio)
    waveform = Waveform(width=1024, height=256, bg_color=(0,0,0), color_scheme='default')
    (decoder | waveform).run()
    print 'frames per pixel = ', waveform.graph.samples_per_pixel
    print "render waveform to: %s" %  image
    waveform.render(image)




########NEW FILE########
__FILENAME__ = test_waveform4
# -*- coding: utf-8 -*-

import os
from timeside.core import *
from timeside.api import *
from timeside.decoder import *
from timeside.grapher import *

sample = '/home/momo/music_local/Isabelle Aboulker/Mon imagier des instruments/16 - Isabelle Aboulker - 16 instru.flac'
img_dir = '../results/img'
if not os.path.exists(img_dir):
    os.mkdir(img_dir)

audio = sample
image = img_dir + os.sep + 'toto.png'
decoder  = FileDecoder(audio)
waveform = Waveform(width=1211, height=170, bg_color=(0,0,0), color_scheme='default')
(decoder | waveform).run()
print 'frames per pixel = ', waveform.graph.samples_per_pixel
print "render waveform to: %s" %  image
waveform.render(image)




########NEW FILE########
__FILENAME__ = test_waveform_centroid
# -*- coding: utf-8 -*-

import os
from timeside.core import *
from timeside.api import *
from timeside.decoder import *
from timeside.grapher import *

sample_dir = '../samples'
img_dir = '../results/img'
if not os.path.exists(img_dir):
    os.makedirs(img_dir)

test_dict = {'sweep.wav': 'waveform_wav.png',
            'sweep.flac': 'waveform_flac.png',
            'sweep.ogg': 'waveform_ogg.png',
            'sweep.mp3': 'waveform_mp3.png',
            }

for source, image in test_dict.iteritems():
    audio = os.path.join(os.path.dirname(__file__), sample_dir + os.sep + source)
    image = img_dir + os.sep + image
    print 'Test : decoder(%s) | waveform (%s)' % (source, image)
    decoder  = FileDecoder(audio)
    waveform = WaveformCentroid(width=1024, height=256, bg_color=(0,0,0), color_scheme='default')
    (decoder | waveform).run()
    print 'frames per pixel = ', waveform.samples_per_pixel
    print "render waveform to: %s" %  image
    waveform.render(image)

########NEW FILE########
__FILENAME__ = test_waveform_contour
# -*- coding: utf-8 -*-

import os
from timeside.core import *
from timeside.api import *
from timeside.decoder import *
from timeside.grapher import *

sample_dir = '../samples'
img_dir = '../results/img'
if not os.path.exists(img_dir):
    os.makedirs(img_dir)

test_dict = {'sweep.wav': 'waveform_wav.png',
            'sweep.flac': 'waveform_flac.png',
            'sweep.ogg': 'waveform_ogg.png',
            'sweep.mp3': 'waveform_mp3.png',
            }

for source, image in test_dict.iteritems():
    audio = os.path.join(os.path.dirname(__file__), sample_dir + os.sep + source)
    image = img_dir + os.sep + image
    print 'Test : decoder(%s) | waveform (%s)' % (source, image)
    decoder  = FileDecoder(audio)
    waveform = WaveformContourBlack()
    (decoder | waveform).run()
    print 'frames per pixel = ', waveform.samples_per_pixel
    print "render waveform to: %s" %  image
    waveform.render(image)

########NEW FILE########
__FILENAME__ = test_waveform_simple
# -*- coding: utf-8 -*-

import os
from timeside.core import *
from timeside.api import *
from timeside.decoder import *
from timeside.grapher import *

sample_dir = '../samples'
img_dir = '../results/img'
if not os.path.exists(img_dir):
    os.makedirs(img_dir)

test_dict = {'sweep.wav': 'waveform_wav.png',
            'sweep.flac': 'waveform_flac.png',
            'sweep.ogg': 'waveform_ogg.png',
            'sweep.mp3': 'waveform_mp3.png',
            }

for source, image in test_dict.iteritems():
    audio = os.path.join(os.path.dirname(__file__), sample_dir + os.sep + source)
    image = img_dir + os.sep + image
    print 'Test : decoder(%s) | waveform (%s)' % (source, image)
    decoder  = FileDecoder(audio)
    waveform = Waveform()
    (decoder | waveform).run()
    print 'frames per pixel = ', waveform.samples_per_pixel
    print "render waveform to: %s" %  image
    waveform.render(image)

########NEW FILE########
__FILENAME__ = test_wav_resample
# -*- coding: utf-8 -*-

import timeside
import os.path

source = os.path.join(os.path.dirname(__file__),  "../samples/sweep.wav")
dest = os.path.join(os.path.dirname(__file__), "../results/sweep_wav_48000.wav")

decoder  = timeside.decoder.FileDecoder(source)
decoder.output_samplerate = 48000
encoder  = timeside.encoder.WavEncoder(dest)
(decoder | encoder).run()

########NEW FILE########
__FILENAME__ = test_AnalyzerResult
#! /usr/bin/env python

from unit_timeside import unittest, TestRunner
from timeside.analyzer.core import AnalyzerResult, AnalyzerResultContainer
from timeside import __version__
import numpy as np
from math import pi


verbose = 0


class TestAnalyzerResult(unittest.TestCase):
    """ test AnalyzerResult """

    def setUp(self):
        self.result = AnalyzerResult.factory(data_mode='value',
                                             time_mode='framewise')

        from datetime import datetime
        res_date = datetime.now().replace(microsecond=0).isoformat(' ')
        self.result.id_metadata = dict(date=res_date,
                                       version=__version__,
                                       author='TimeSide',
                                       id="foo_bar",
                                       name="Foo bar",
                                       unit="foo")
        self.result.audio_metadata = dict(uri='Foo.wav',
                                          start=0, duration=20,
                                          channels=2)

    def tearDown(self):
        pass

# Get good and bad types for AnalyzerResult.data_object.data.value
from timeside.analyzer.core import numpy_data_types as good_dtypes
good_numpy_data_types = [str(dtype)[13:-2] for dtype in good_dtypes]
bad_numpy_data_types = [
    # not understood by json or yaml
    'float128',
    # Not supported by h5py for version < 2.2
    'float16',
    # complex can not be serialized in json
    'complex256',
    'complex128',
    'complex64',
    # ?
    'datetime64',
    'timedelta64',
    'unicode_',
    'string_'
    ]


class TestAnalyzerResultBadType(TestAnalyzerResult):
    """ test AnalyzerResult on bad numpy data type"""

    def method(self, numpy_data_type):
        try:
            data = getattr(np, numpy_data_type)(pi)
        except ValueError:
            data = getattr(np, numpy_data_type)()

        self.assertRaises(TypeError,
                          self.result.data_object.__setattr__,
                          'value', data)

    @classmethod
    def add_method(cls, numpy_data_type):
        test_method = lambda self: self.method(numpy_data_type)
        test_method.__name__ = 'testOnNumpy_%s' % numpy_data_type
        test_method.__doc__ = 'TypeError on numpy %s' % numpy_data_type
        setattr(cls, test_method.__name__, test_method)

# Add tests for each type in bad_numpy_data_types
for numpy_data_type in bad_numpy_data_types:
    TestAnalyzerResultBadType.add_method(numpy_data_type)


class TestAnalyzerResultGoodType(TestAnalyzerResult):
    """ test AnalyzerResult on good numpy data type"""
    def testOnFloat(self):
        "float result"
        self.result.data_object.value = 1.2

    def testOnInt(self):
        "integer result"
        self.result.data_object.value = 1

    def testOnList(self):
        "list result"
        self.result.data_object.value = [1., 2.]

    @unittest.skip("String have to be handled through label metadata")
    def testOnString(self):
        "string result"
        self.result.data_object.value = "hello"

    @unittest.skip("String have to be handled through label metadata")
    def testOnListOfString(self):
        "list of strings result"
        self.result.data_object.value = ["hello", "hola"]

    def testOnListOfList(self):
        "list of lists result"
        self.result.data_object.value = [[0, 1], [0, 1, 2]]

    def testOnNumpyVectorOfFloat(self):
        "numpy vector of float"
        self.result.data_object.value = np.ones(2, dtype='float') * pi

    def testOnNumpy2DArrayOfFloat64(self):
        "numpy 2d array of float64"
        self.result.data_object.value = np.ones([2, 3], dtype='float64') * pi

    def testOnNumpy3DArrayOfInt32(self):
        "numpy 3d array of int32"
        self.result.data_object.value = np.ones([2, 3, 2], dtype='int32')

    @unittest.skip("String have to be handled through label metadata")
    def testOnNumpyArrayOfStrings(self):
        "numpy array of strings"
        self.result.data_object.value = np.array(['hello', 'hola'])

    def testOnEmptyList(self):
        "empty list"
        self.result.data_object.value = []

    def testOnNone(self):
        "None"
        self.result.data_object.value = None

    @unittest.skip("String have to be handled through label metadata")
    def testOnUnicode(self):
        "Unicode"
        self.result.data_object.value = u'\u0107'

    def method(self, numpy_data_type):
        """Good numpy data type"""
        self.result.data_object.value = getattr(np, numpy_data_type)(pi)

    @classmethod
    def add_method(cls, numpy_data_type):
        test_method = lambda self: self.method(numpy_data_type)
        test_method.__name__ = 'testOnNumpy_%s' % numpy_data_type
        test_method.__doc__ = 'Support numpy %s' % numpy_data_type
        setattr(cls, test_method.__name__, test_method)

# Add tests for each type in good_numpy_data_types
for numpy_data_type in good_numpy_data_types:
    TestAnalyzerResultGoodType.add_method(numpy_data_type)


class TestAnalyzerResultNumpy(TestAnalyzerResultGoodType):
    """ test AnalyzerResult numpy serialize """

    def tearDown(self):
        results = AnalyzerResultContainer([self.result])
        results.to_numpy('/tmp/t.npy')
        d_numpy = results.from_numpy('/tmp/t.npy')
        if verbose:
            print '%15s' % 'from numpy:',
            print d_numpy
        self.assertEqual(d_numpy, results)


class TestAnalyzerResultHdf5(TestAnalyzerResultGoodType):
    """ test AnalyzerResult hdf5 serialize """

    def tearDown(self):
        results = AnalyzerResultContainer([self.result])
        results.to_hdf5('/tmp/t.h5')
        res_hdf5 = results.from_hdf5('/tmp/t.h5')
        if verbose:
            print '%15s' % 'from hdf5:',
            print res_hdf5
        self.assertEqual(results, res_hdf5)


class TestAnalyzerResultYaml(TestAnalyzerResultGoodType):
    """ test AnalyzerResult yaml serialize """
    def tearDown(self):
        results = AnalyzerResultContainer(self.result)
        r_yaml = results.to_yaml()
        if verbose:
            print 'to yaml:'
            print r_yaml
        d_yaml = results.from_yaml(r_yaml)
        if verbose:
            print '%15s' % 'from yaml:',
            print d_yaml
        #for i in range(len(d_yaml)):
        self.assertEqual(results, d_yaml)


class TestAnalyzerResultXml(TestAnalyzerResultGoodType):
    """ test AnalyzerResult xml serialize """
    def tearDown(self):
        results = AnalyzerResultContainer([self.result])
        r_xml = results.to_xml()
        if verbose:
            print 'to xml:'
            print r_xml

        d_xml = results.from_xml(r_xml)
        if verbose:
            print '%15s' % 'from xml:',
            print d_xml

        #for i in range(len(d_xml)):
        self.assertEqual(d_xml, results)


class TestAnalyzerResultJson(TestAnalyzerResultGoodType):
    """ test AnalyzerResult """
    def tearDown(self):
        results = AnalyzerResultContainer([self.result])
        try:
            r_json = results.to_json()
        except TypeError:
            print('TYPE ERROR IN JSON')
        if verbose:
            print 'to json:'
            print r_json

        d_json = results.from_json(r_json)
        if verbose:
            print d_json
            print '%15s' % 'from json:',

        #for i in range(len(d_json)):
        self.assertEqual(d_json, results)


class TestAnalyzerResultAsDict(TestAnalyzerResultGoodType):
    """ test AnalyzerResult as Dictionnary"""

    def tearDown(self):

        self.assertIsInstance(self.result.as_dict(), dict)
        self.assertItemsEqual(self.result.keys() + ['data_mode', 'time_mode'],
                              self.result.as_dict().keys())

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_analyzers_stress
#! /usr/bin/env python

# Author : Thomas Fillon <thomas@parisson.com>


from unit_timeside import unittest, TestRunner
import timeside
import numpy as np


class TestAnalyzers_with_zeros(unittest.TestCase):
    """Stress test for analyzer with null input"""

    def setUp(self):
        import timeside.analyzer
        samplerate = 16000  # LimsiSad require Fs = 16000 Hz
        duration = 10
        samples = np.zeros((duration * samplerate, 1))
        decoder_cls = timeside.core.get_processor('array_dec')
        self.decoder = decoder_cls(samples, samplerate=samplerate)

    def _perform_test(self, analyzer_cls):
        """Internal function that test if there is NaN in the results
        of a given analyzer"""

        pipe = (self.decoder | analyzer_cls())
        pipe.run()
        for key, result in pipe.results.items():
            if 'value' in result.data_object.keys():
                # Test for NaN
                self.assertFalse(np.any(np.isnan(result.data)),
                                 'NaN in %s data value' % result.name)
                # Test for Inf
                self.assertFalse(np.any(np.isinf(result.data)),
                                 'Inf in %s data value' % result.name)


class TestAnalyzers_withDC(TestAnalyzers_with_zeros):
    """Stress test for analyzer with constant input"""

    def setUp(self):
        import timeside.analyzer
        samplerate = 16000  # LimsiSad require Fs = 16000 Hz
        duration = 10
        samples = -1000*np.ones((duration * samplerate, 1))
        decoder_cls = timeside.core.get_processor('array_dec')
        self.decoder = decoder_cls(samples, samplerate=samplerate)


def _tests_factory(test_class, test_doc, list_analyzers, skip_reasons={}):
    """Define a test for each analyzer provided in the list"""
    for analyzer in list_analyzers:

        def test_func_factory(analyzer):
            test_func = lambda self: self._perform_test(analyzer)
            test_func.__doc__ = test_doc % analyzer.__name__
            return test_func

        test_func_name = "test_%s" % analyzer.__name__
        test_func = test_func_factory(analyzer)

        if analyzer.__name__ not in skip_reasons:
            setattr(test_class, test_func_name,
                    test_func_factory(analyzer))
        else:  # Decorate with unittest.skip to skip test
            setattr(test_class, test_func_name,
                    unittest.skip(skip_reasons[analyzer.__name__])(test_func))


# Define test to skip and corresponding reasons
skip_reasons = {'VampSimpleHost': ('VampSimpleHost bypasses the decoder '
                                   'and requires a file input')}

# For each analyzer in TimeSide, test with constant input
_tests_factory(test_class=TestAnalyzers_withDC,
               test_doc="Stress test for %s",
               list_analyzers=timeside.core.processors(timeside.api.IAnalyzer),
               skip_reasons=skip_reasons)

# For each analyzer in TimeSide, test with null input
_tests_factory(test_class=TestAnalyzers_with_zeros,
               test_doc="Stress test for %s",
               list_analyzers=timeside.core.processors(timeside.api.IAnalyzer),
               skip_reasons=skip_reasons)


if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_analyzer_dc
#! /usr/bin/env python

from unit_timeside import *
from timeside.decoder.file import FileDecoder
from timeside.analyzer.dc import MeanDCShift
import os

class TestAnalyzerDC(unittest.TestCase):

    def setUp(self):
        self.analyzer = MeanDCShift()

    def testOnSweep(self):
        "runs on sweep"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "sweep.wav")

        self.expected = {'mean_dc_shift': -0.000}

    def testOnGuitar(self):
        "runs on guitar"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "guitar.wav")
        self.expected = {'mean_dc_shift': 0.054}

    def tearDown(self):
        decoder = FileDecoder(self.source)
        (decoder | self.analyzer).run()
        results = self.analyzer.results
        for key in self.expected.keys():
            self.assertEquals(results[key].data_object.value, self.expected[key])

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_analyzer_level
#! /usr/bin/env python

from unit_timeside import *
from timeside.decoder.file import FileDecoder
from timeside.analyzer.level import Level
import os

class TestAnalyzerLevel(unittest.TestCase):

    def setUp(self):
        self.analyzer = Level()

    def testOnSweep(self):
        "runs on sweep"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "sweep.wav")

        max_level_value = -6.021
        rms_level_value = -9.856

        self.expected = {'level.max':max_level_value , 'level.rms':rms_level_value }

    def testOnGuitar(self):
        "runs on guitar"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "guitar.wav")

        max_level_value = -4.054
        rms_level_value = -21.945

        self.expected = {'level.max':max_level_value , 'level.rms':rms_level_value }


    def tearDown(self):
        decoder = FileDecoder(self.source)
        (decoder | self.analyzer).run()
        results = self.analyzer.results
        for key in self.expected.keys():
            self.assertEquals(results[key].data_object.value, self.expected[key])
        #print results
        #print results.to_yaml()
        #print results.to_json()
        #print results.to_xml()

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_analyzer_preprocessors
#! /usr/bin/env python
# -*- coding: utf-8 -*-
# Author : Thomas fillon <thomas@parisson.com>

from unit_timeside import *
from timeside.decoder import *
from timeside.analyzer.preprocessors import downmix_to_mono, frames_adapter
import numpy as np

BLOCKSIZE = 1024
STEPSIZE = 256

class FakeAnalyzer(object):
    def __init__(self, blocksize=BLOCKSIZE, stepsize=STEPSIZE):
        self.frames = []  # Container for the frame as viewed by process
        self.input_blocksize = blocksize
        self.input_stepsize= stepsize

    def process(self, frames, eod):
        self.frames.append(frames)
        return frames, eod


class TestAnalyzerPreProcessors(unittest.TestCase):

    def tearDown(self):

        analyzer = FakeAnalyzer()

        process_output = []
        for frames, eod in zip(self.input_frames, self.input_eod):
            process_output.append(analyzer.decorated_process(frames, eod))

        output_frames = np.asarray([frames for frames, _ in process_output])
        output_eod = [eod for _, eod in process_output]

        self.assertEqual(self.input_frames.tolist(), output_frames.tolist())
        self.assertEqual(self.input_eod, output_eod)
        self.assertEqual(self.process_frames.tolist(),
                         np.asarray(analyzer.frames).tolist())


class TestDownmixToMono(TestAnalyzerPreProcessors):

    def setUp(self):
        self.decorator = downmix_to_mono
        # Decorate the process
        FakeAnalyzer.decorated_process = self.decorator(FakeAnalyzer.process)

    def test_on_mono(self):
        "Run on stereo, eod = False"
        self.input_frames = np.random.randn(30, 4096)
        self.input_eod = np.repeat(False, 30).tolist()
        self.process_frames = self.input_frames

    def test_on_stereo(self):
        "Run on stereo, eod = False"
        self.input_frames = np.random.randn(30, 4096, 2)
        self.input_eod = np.repeat(False, 30).tolist()
        self.process_frames = self.input_frames.mean(axis=-1)

    def test_on_multichannel(self):
        "Run on multi-channel, eod = False"
        self.input_frames = np.random.randn(30, 4096, 6)
        self.input_eod = np.repeat(False, 30).tolist()
        self.process_frames = self.input_frames.mean(axis=-1)

    def test_on_mono_eod_true(self):
        "Run on mono, last eod = True"
        self.input_frames = np.random.randn(30, 4096)
        self.input_eod = np.repeat(False, 30).tolist()
        self.input_eod[-1] = True
        self.process_frames = self.input_frames

    def test_on_stereo_eod_true(self):
        "Run on stereo, last eod = True"
        self.input_frames = np.random.randn(30, 4096, 2)
        self.input_eod = np.repeat(False, 30).tolist()
        self.input_eod[-1] = True
        self.process_frames = self.input_frames.mean(axis=-1)

    def test_on_multichannel_eod_true(self):
        "Run on multi-channel, last eod = True"
        self.input_frames = np.random.randn(30, 4096, 6)
        self.input_eod = np.repeat(False, 30).tolist()
        self.input_eod[-1] = True
        self.process_frames = self.input_frames.mean(axis=-1)

class TestFramesAdapter(TestAnalyzerPreProcessors, unittest.TestCase):

    def setUp(self):
        self.decorator = frames_adapter
        # Decorate the process
        FakeAnalyzer.decorated_process = self.decorator(FakeAnalyzer.process)

    def test_on_mono(self):
        "Run on mono"
        self.input_frames = np.arange(0, 2500).reshape(5, -1)
        self.input_eod = [False, False, False, False, False]

        self.process_frames = np.asarray([range(0, 1024),
                                          range(256, 1280),
                                          range(512, 1536),
                                          range(768, 1792),
                                          range(1024, 2048),
                                          range(1280, 2304)])

    def test_on_stereo(self):
        "Run on stereo"
        self.input_frames = np.arange(0, 5000).reshape(5, -1, 2)
        self.input_eod = [False, False, False, False, False]

        self.process_frames = np.asarray([np.arange(0, 2048).reshape(-1, 2),
                                          np.arange(512, 2560).reshape(-1, 2),
                                          np.arange(1024, 3072).reshape(-1, 2),
                                          np.arange(1536, 3584).reshape(-1, 2),
                                          np.arange(2048, 4096).reshape(-1, 2),
                                          np.arange(2560, 4608).reshape(-1, 2)])
    def test_on_mono_eod_true(self):
        "Run on mono, last eod = True"
        self.input_frames = np.arange(0, 2500).reshape(5, -1)
        self.input_eod = [False, False, False, False, True]
        last_frames = range(1536, 2500)
        last_frames.extend([0]*60)
        self.process_frames = np.asarray([range(0, 1024),
                                          range(256, 1280),
                                          range(512, 1536),
                                          range(768, 1792),
                                          range(1024, 2048),
                                          range(1280, 2304),
                                          last_frames])

    def test_on_stereo_eod_true(self):
        "Run on stereo, last eod = True"
        self.input_frames = np.arange(0, 5000).reshape(5, -1, 2)
        self.input_eod = [False, False, False, False, True]
        last_frames = np.hstack([np.arange(3072, 5000),
                                 np.zeros((120,))]).reshape(-1, 2)
        self.process_frames = np.asarray([np.arange(0, 2048).reshape(-1, 2),
                                          np.arange(512, 2560).reshape(-1, 2),
                                          np.arange(1024, 3072).reshape(-1, 2),
                                          np.arange(1536, 3584).reshape(-1, 2),
                                          np.arange(2048, 4096).reshape(-1, 2),
                                          np.arange(2560, 4608).reshape(-1, 2),
                                          last_frames])

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_array_decoding
#! /usr/bin/env python
from __future__ import division

from timeside.decoder.array import ArrayDecoder
from unit_timeside import *

import numpy as np


class TestDecoding(unittest.TestCase):

    "Test decoding for ArrayDecoder"

    def setUp(self):
        self.samplerate, self.channels, self.blocksize = None, None, None
        self.start = 0
        self.duration = None
        self.array_duration = 8
        self.expected_duration = self.array_duration
        self.expected_is_segment = False

    def test1DArray(self):
        "Test 1D Array decoding"
        self.source_samplerate = 44100
        self.source = np.random.randn(
            self.array_duration * self.source_samplerate,)
        self.source_channels = 1

    def test2DArrayMono(self):
        "Test 2D Array mono decoding"
        self.source_samplerate = 32000
        self.source = np.random.randn(
            self.array_duration * self.source_samplerate, 1)
        self.source_channels = 1

    def test2DArrayStereo(self):
        "Test 2D Array stereo decoding"
        self.source_samplerate = 22050
        self.source = np.random.randn(
            self.array_duration * self.source_samplerate, 2)
        self.source_channels = 2

    def test2DArrayMultiChannel(self):
        "Test 2D Array multi-channel decoding"
        self.source_samplerate = 16000
        self.source = np.random.randn(
            self.array_duration * self.source_samplerate, 5)
        self.source_channels = 5

    def tearDown(self):
        decoder = ArrayDecoder(samples=self.source,
                               samplerate=self.source_samplerate,
                               start=self.start,
                               duration=self.duration)

        decoder.setup(samplerate=self.samplerate, channels=self.channels,
                      blocksize=self.blocksize)

        # Check input
        self.assertEqual(self.source_samplerate, decoder.input_samplerate)
        self.assertEqual(self.expected_is_segment, decoder.is_segment)
        self.assertEqual(self.expected_duration, decoder.input_duration)
        self.assertEqual(self.source_channels, decoder.input_channels)
        # Check output
        self.assertEqual(self.source_samplerate, decoder.samplerate())
        self.assertEqual(self.source_channels, decoder.channels())

        # Check Idecoder interface
        self.assertIsInstance(decoder.mediainfo(), dict)
        self.assertIsInstance(decoder.format(), str)
        self.assertIsInstance(decoder.encoding(), str)
        self.assertIsInstance(decoder.resolution(), int)
        self.assertIsNone(decoder.metadata())

        totalframes = 0

        while True:
            frames, eod = decoder.process()
            totalframes += frames.shape[0]
            if eod:
                break
            self.assertEqual(frames.shape[0], decoder.blocksize())
            self.assertEqual(frames.shape[1], decoder.channels())

        if self.channels:
            # when specified, check that the channels are the ones requested
            self.assertEqual(self.channels, decoder.output_channels)
        else:
            # otherwise check that the channels are preserved, if not specified
            self.assertEqual(decoder.input_channels, decoder.output_channels)
            # and if we know the expected channels, check the output match
            if self.source_channels:
                self.assertEqual(
                    self.source_channels, decoder.output_channels)
        # do the same with the sampling rate
        if self.samplerate:
            self.assertEqual(self.samplerate, decoder.output_samplerate)
        else:
            self.assertEqual(
                decoder.input_samplerate, decoder.output_samplerate)

        self.assertEqual(totalframes,
                         self.expected_duration * decoder.output_samplerate)
        self.assertEquals(totalframes, decoder.totalframes())


class TestDecodingSegment(TestDecoding):

    def setUp(self):
        super(TestDecodingSegment, self).setUp()
        self.start = 1
        self.duration = 3
        self.expected_is_segment = True
        self.expected_duration = self.duration


class TestDecodingSegmentDefaultStart(TestDecodingSegment):

    def setUp(self):
        super(TestDecodingSegmentDefaultStart, self).setUp()
        self.start = 0
        self.duration = 1
        self.expected_duration = self.duration


class TestDecodingSegmentDefaultDuration(TestDecodingSegment):

    def setUp(self):
        super(TestDecodingSegmentDefaultDuration, self).setUp()
        self.start = 1
        self.duration = None
        self.expected_duration = self.array_duration - self.start


class TestDecodingShortBlock(TestDecoding):

    def setUp(self):
        super(TestDecodingShortBlock, self).setUp()
        self.blocksize = 256


class TestDecodingLongBlock(TestDecoding):

    def setUp(self):
        super(TestDecodingLongBlock, self).setUp()
        self.blocksize = 1024 * 8 * 2


if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_aubio_melenergy
#! /usr/bin/env python

from unit_timeside import unittest, TestRunner
import os
from timeside.decoder.file import FileDecoder
from timeside.core import get_processor
from timeside import _WITH_AUBIO


@unittest.skipIf(not _WITH_AUBIO, 'Aubio library is not available')
class TestAubioMelEnergy(unittest.TestCase):

    def setUp(self):
        self.analyzer = get_processor('aubio_melenergy')()

    def testOnSweep(self):
        "runs on sweep"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples", "sweep.wav")

    def testOnGuitar(self):
        "runs on guitar"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples", "guitar.wav")

    def tearDown(self):
        decoder = FileDecoder(self.source)
        (decoder | self.analyzer).run()
        results = self.analyzer.results
        #print results
        #print results.to_yaml()
        #print results.to_json()
        #print results.to_xml()

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_aubio_mfcc
#! /usr/bin/env python

from unit_timeside import unittest, TestRunner
import os
from timeside.decoder.file import FileDecoder
from timeside.core import get_processor
from timeside import _WITH_AUBIO


@unittest.skipIf(not _WITH_AUBIO, 'Aubio library is not available')
class TestAubioMfcc(unittest.TestCase):

    def setUp(self):
        self.analyzer = get_processor('aubio_mfcc')()

    def testOnSweep(self):
        "runs on sweep"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "sweep.wav")

    def testOnGuitar(self):
        "runs on guitar"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "guitar.wav")

    def tearDown(self):
        decoder = FileDecoder(self.source)
        (decoder | self.analyzer).run()
        results = self.analyzer.results
        #print results
        #print results.to_yaml()
        #print results.to_json()
        #print results.to_xml()

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_aubio_pitch
#! /usr/bin/env python

from unit_timeside import unittest, TestRunner
import os
from timeside.decoder.file import FileDecoder
from timeside.core import get_processor
from timeside import _WITH_AUBIO


@unittest.skipIf(not _WITH_AUBIO, 'Aubio library is not available')
class TestAubioPitch(unittest.TestCase):

    def setUp(self):
        self.analyzer = get_processor('aubio_pitch')()

    def testOnSweep(self):
        "runs on sweep"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples", "sweep.wav")

    def testOnGuitar(self):
        "runs on guitar"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples", "guitar.wav")

    def tearDown(self):
        decoder = FileDecoder(self.source)
        (decoder | self.analyzer).run()
        results = self.analyzer.results
        #print "result:", self.analyzer.result()

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_aubio_specdesc
#! /usr/bin/env python

from unit_timeside import unittest, TestRunner
import os
from timeside.decoder.file import FileDecoder
from timeside.core import get_processor
from timeside import _WITH_AUBIO


@unittest.skipIf(not _WITH_AUBIO, 'Aubio library is not available')
class TestAubioSpecdesc(unittest.TestCase):

    def setUp(self):
        self.analyzer = get_processor('aubio_specdesc')()

    def testOnSweep(self):
        "runs on sweep"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples", "sweep.wav")

    def testOnGuitar(self):
        "runs on guitar"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples", "guitar.wav")

    def tearDown(self):
        decoder = FileDecoder(self.source)
        (decoder | self.analyzer).run()
        results = self.analyzer.results
        #results.to_yaml()
        #results.to_json()
        #results.to_xml()

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_aubio_temporal
#! /usr/bin/env python

from unit_timeside import unittest, TestRunner
import os
from timeside.decoder.file import FileDecoder
from timeside.core import get_processor
from timeside import _WITH_AUBIO


@unittest.skipIf(not _WITH_AUBIO, 'Aubio library is not available')
class TestAubioTemporal(unittest.TestCase):

    def setUp(self):
        self.analyzer = get_processor('aubio_temporal')()

    def testOnSweep(self):
        "runs on sweep"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples", "sweep.wav")

    def testOnGuitar(self):
        "runs on guitar"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples", "guitar.wav")

    def tearDown(self):
        decoder = FileDecoder(self.source)
        (decoder | self.analyzer).run()
        results = self.analyzer.results
        #print results
        results.to_yaml()
        results.to_json()
        results.to_xml()

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_component
#! /usr/bin/env python

from timeside.component import *
from unit_timeside import *

__all__ = ['TestComponentArchitecture']


class TestComponentArchitecture(unittest.TestCase):

    "Test the component and interface system"

    def testOneInterface(self):
        "Test a component implementing one interface"
        self.assertItemsEqual(implementations(I1), [C1])

    def testTwoInterfaces(self):
        "Test a component implementing two interfaces"
        self.assertItemsEqual(implementations(I2), [C2])
        self.assertItemsEqual(implementations(I3), [C2])

    def testTwoImplementations(self):
        "Test an interface implemented by two components"
        self.assertItemsEqual(implementations(I4), [C3, C4])

    def testInterfaceInheritance(self):
        "Test whether a component implements an interface's parent"
        self.assertItemsEqual(implementations(I5), [C5])

    def testImplementationInheritance(self):
        "Test that a component doesn't implement the interface implemented by its parent"
        self.assertItemsEqual(implementations(I7), [C6])

    def testImplementationRedundancy(self):
        "Test implementation redundancy across inheritance"
        self.assertItemsEqual(implementations(I8), [C8, C9])

    def testAbstractImplementation(self):
        "Test abstract implementation"
        self.assertItemsEqual(implementations(I11), [])
        self.assertItemsEqual(implementations(I11, abstract=True), [C11])

    def testInterfaceDoc(self):
        "Test @interfacedoc decorator"
        self.assertEquals(C10.test.__doc__, "testdoc")

    def testInterfaceDocStatic(self):
        "Test @interfacedoc decorator on static method"
        self.assertEquals(C10.teststatic.__doc__, "teststaticdoc")

    def testIntefaceDocReversed(self):
        "Test @interfacedoc on static method (decorators reversed)"

        try:

            class BogusDoc1(Component):
                implements(I10)

                @interfacedoc
                @staticmethod
                def teststatic(self):
                    pass

            self.fail("No error raised with reversed decorators")

        except ComponentError:
            pass

    def testInterfaceDocBadMethod(self):
        "Test @interfacedoc with unexistant method in interface"

        try:
            class BogusDoc2(Component):
                implements(I10)

                @interfacedoc
                def nosuchmethod(self):
                    pass

            self.fail("No error raised when decorating an unexistant method")

        except ComponentError:
            pass


class I1(Interface):
    pass


class I2(Interface):
    pass


class I3(Interface):
    pass


class I4(Interface):
    pass


class I5(Interface):
    pass


class I6(I5):
    pass


class I7(Interface):
    pass


class I8(Interface):
    pass


class I9(I8):
    pass


class I10(Interface):

    def test(self):
        """testdoc"""

    @staticmethod
    def teststatic(self):
        """teststaticdoc"""


class I11(Interface):
    pass


class C1(Component):
    implements(I1)


class C2(Component):
    implements(I2, I3)


class C3(Component):
    implements(I4)


class C4(Component):
    implements(I4)


class C5(Component):
    implements(I6)


class C6(Component):
    implements(I7)


class C7(C6):
    pass


class C8(Component):
    implements(I8)


class C9(Component):
    implements(I8, I9)


class C10(Component):
    implements(I10)

    @interfacedoc
    def test(self):
        pass

    @staticmethod
    @interfacedoc
    def teststatic(self):
        pass


class C11(Component):
    abstract()
    implements(I11)

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_decoder_utils
#! /usr/bin/env python

# author: Thomas Fillon <thomas@parisson.com>

from __future__ import division

from numpy import arange, sin
from unit_timeside import *
from timeside.decoder.utils import get_uri, get_media_uri_info, path2uri
import os.path


class TestGetUri(unittest.TestCase):
    "Test get_uri function"
    def testFileName(self):
        "Retrieve the uri from a filename"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.wav")

        self.uri = path2uri(os.path.abspath(self.source))

    def testUri(self):
        "Retrieve the uri from an uri"
        self.uri = 'file://already/an/uri/file.wav'
        self.source = self.uri

    def tearDown(self):
        self.assertEqual(self.uri, get_uri(self.source))


class TestGetUriWrongUri(unittest.TestCase):
    def testMissingFile(self):
        "Missing file raise IOerror"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "a_missing_file_blahblah.wav")
    def testNotValidUri(self):
        "Not valid uri raise IOerror"
        self.source = os.path.join("://not/a/valid/uri/parisson.com")

    def testNotSupportedUriProtocol(self):
        "Not supported uri protocol raise IOerror"
        self.source = os.path.join("mailto://john.doe@parisson.com")

    def tearDown(self):
        self.assertRaises(IOError, get_uri, self.source)


class TestGetMediaInfo(unittest.TestCase):
    "Test get_media_uri_info function on an uri"

    def setUp(self):
        self.test_exact_duration = True
        self.source_duration = 8
        self.test_exact_duration = True
        self.expected_channels = 2
        self.expected_samplerate = 44100
        self.expected_depth = 16

    def testWav(self):
        "Test wav decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.wav")


    def testWavMono(self):
        "Test mono wav decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep_mono.wav")

        self.expected_channels = 1

    def testWav32k(self):
        "Test 32kHz wav decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep_32000.wav")
        self.expected_samplerate = 32000

    def testFlac(self):
        "Test flac decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.flac")

    def testOgg(self):
        "Test ogg decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.ogg")
        self.expected_depth = 0  # ?

    def testMp3(self):
        "Test mp3 decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.mp3")
        self.expected_depth = 32
        self.test_exact_duration = False


    def tearDown(self):
        uri = get_uri(self.source)
        uri_info = get_media_uri_info(uri)
        if self.test_exact_duration:
            self.assertEqual(self.source_duration, uri_info['duration'])
        else:
            self.assertAlmostEqual(self.source_duration,
                                   uri_info['duration'],
                                   places=1)
        self.assertEqual(self.expected_channels, uri_info['streams'][0]['channels'])
        self.assertEqual(self.expected_samplerate, uri_info['streams'][0]['samplerate'])
        self.assertEqual(self.expected_depth, uri_info['streams'][0]['depth'])

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_decoding
#! /usr/bin/env python

from __future__ import division

from timeside.decoder.file import FileDecoder
from timeside.core import ProcessPipe

from unit_timeside import *

import os.path

#from glib import GError as GST_IOError
# HINT : to use later with Gnonlin only


class TestDecoding(unittest.TestCase):

    "Test decoding features"

    def setUp(self):
        self.samplerate, self.channels, self.blocksize = None, None, None
        self.start = 0
        self.duration = None

        self.expected_samplerate = 44100
        self.expected_channels = 2
        self.expected_totalframes = 352800
        self.test_exact_duration = True
        self.source_duration = 8
        self.expected_mime_type = 'audio/x-wav'

    def testWav(self):
        "Test wav decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.wav")

    def testWavMono(self):
        "Test mono wav decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep_mono.wav")

        self.expected_channels = 1

    def testWav32k(self):
        "Test 32kHz wav decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep_32000.wav")

        expected_samplerate = 32000
        ratio = expected_samplerate / self.expected_samplerate

        self.expected_totalframes = int(self.expected_totalframes * ratio)
        self.expected_samplerate = expected_samplerate

    def testFlac(self):
        "Test flac decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.flac")
        self.expected_mime_type = 'audio/x-flac'

    def testOgg(self):
        "Test ogg decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.ogg")

        self.expected_totalframes = 352832
        self.expected_mime_type = 'application/ogg'
        self.test_exact_duration = False

    def testMp3(self):
        "Test mp3 decoding"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.mp3")

        self.expected_totalframes = 353664
        self.expected_mime_type = 'audio/mpeg'
        self.test_exact_duration = False

    def tearDown(self):
        decoder = FileDecoder(uri=self.source,
                              start=self.start,
                              duration=self.duration)

        decoder.setup(samplerate=self.samplerate, channels=self.channels,
                      blocksize=self.blocksize)

        totalframes = 0

        while True:
            frames, eod = decoder.process()
            totalframes += frames.shape[0]
            if eod or decoder.eod:
                break
            self.assertEqual(frames.shape[0], decoder.blocksize())
            self.assertEqual(frames.shape[1], decoder.channels())

        ratio = decoder.output_samplerate / decoder.input_samplerate
        if 0:
            print "input / output_samplerate:", decoder.input_samplerate, '/', decoder.output_samplerate,
            print "ratio:", ratio
            print "input / output_channels:", decoder.input_channels, decoder.output_channels
            print "input_duration:", decoder.input_duration
            print "input_totalframes:", decoder.input_totalframes
            print "mime_type", decoder.mime_type()

        if self.channels:
            # when specified, check that the channels are the ones requested
            self.assertEqual(self.channels, decoder.output_channels)
        else:
            # otherwise check that the channels are preserved, if not specified
            self.assertEqual(decoder.input_channels, decoder.output_channels)
            # and if we know the expected channels, check the output match
            if self.expected_channels:
                self.assertEqual(
                    self.expected_channels, decoder.output_channels)
        # do the same with the sampling rate
        if self.samplerate:
            self.assertEqual(self.samplerate, decoder.output_samplerate)
        else:
            self.assertEqual(
                decoder.input_samplerate, decoder.output_samplerate)
            if self.expected_samplerate:
                self.assertEqual(
                    self.expected_samplerate, decoder.output_samplerate)

        self.assertEqual(decoder.mime_type(), self.expected_mime_type)

        expected_totalframes = [self.expected_totalframes, self.expected_totalframes +32]  # +32 to handle some issue with ogg
        self.assertIn(totalframes, expected_totalframes)

        input_duration = decoder.input_totalframes / decoder.input_samplerate
        output_duration = decoder.totalframes() / decoder.output_samplerate
        if self.test_exact_duration:
            self.assertEqual(input_duration, output_duration)
            self.assertEqual(input_duration,
                             decoder.uri_duration)
            self.assertEqual(self.source_duration,
                             decoder.uri_duration)
        else:
            self.assertAlmostEqual(input_duration, output_duration,
                                   places=1)
            self.assertAlmostEqual(input_duration,
                                   decoder.uri_duration,
                                   places=1)
            self.assertAlmostEqual(self.source_duration,
                                   decoder.uri_duration,
                                   places=1)


class TestDecodingSegment(TestDecoding):

    def setUp(self):
        super(TestDecodingSegment, self).setUp()
        self.start = 1
        self.duration = 3
        self.source_duration = self.duration

        self.expected_totalframes = self.duration * self.expected_samplerate

    def testMp3(self):
        "Test mp3 decoding"
        super(TestDecodingSegment, self).testMp3()
        self.expected_totalframes = self.duration * \
            self.expected_samplerate + 1

    def testWav(self):
        "Test wav decoding"
        super(TestDecodingSegment, self).testWav()

    def testWavMono(self):
        "Test mono wav decoding"
        super(TestDecodingSegment, self).testWavMono()

    def testWav32k(self):
        "Test 32kHz wav decoding"
        super(TestDecodingSegment, self).testWav32k()

    @unittest.skip("Flac not supported until bug fix is GST Gnonlin")
    def testFlac(self):
        "Test flac decoding"

    @unittest.skip("Ogg not supported until bug fix is GST Gnonlin")
    def testOgg(self):
        "Test ogg decoding"


class TestDecodingSegmentDefaultStart(TestDecodingSegment):

    def setUp(self):
        super(TestDecodingSegmentDefaultStart, self).setUp()
        self.duration = 1
        self.source_duration = self.duration
        self.expected_totalframes = self.duration * self.expected_samplerate

    def testMp3(self):
        "Test mp3 decoding"
        super(TestDecodingSegmentDefaultStart, self).testMp3()
        self.expected_totalframes = self.duration * \
            self.expected_samplerate + 1


class TestDecodingSegmentDefaultDuration(TestDecodingSegment):

    def setUp(self):
        super(TestDecodingSegment, self).setUp()
        self.start = 1
        self.source_duration -= self.start

        self.expected_totalframes = (self.expected_totalframes
                                     - self.start * self.expected_samplerate)

    def testWav(self):
        "Test wav decoding"
        super(TestDecodingSegment, self).testWav()

    def testWavMono(self):
        "Test mono wav decoding"
        super(TestDecodingSegment, self).testWavMono()

    def testWav32k(self):
        "Test 32kHz wav decoding"
        super(TestDecodingSegment, self).testWav32k()

    def testMp3(self):
        "Test mp3 decoding"
        super(TestDecodingSegment, self).testMp3()
        self.expected_totalframes = 310715  # was  308701 ?


class TestDecodingSegmentBadParameters(unittest.TestCase):

    def setUp(self):
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.wav")

    def test_bad_start_value(self):
        "Test decoding segment with start value exceeding the media duration"
        decoder = FileDecoder(self.source, start=10)
        pipe = ProcessPipe(decoder)
        self.assertRaises(ValueError, pipe.run)

    def test_bad_duration_value(self):
        "Test decoding segment with a too large duration value argument"
        decoder = FileDecoder(self.source, duration=10)
        pipe = ProcessPipe(decoder)
        self.assertRaises(ValueError, pipe.run)


class TestDecodingStereo(TestDecoding):

    def setUp(self):
        super(TestDecodingStereo, self).setUp()
        self.samplerate, self.channels, self.blocksize = None, 2, None


class TestDecodingMonoUpsampling(TestDecoding):

    def setUp(self):
        super(TestDecodingMonoUpsampling, self).setUp()
        self.samplerate, self.channels, self.blocksize = 48000, None, None
        self.expected_totalframes = 384000

    def testMp3(self):
        "Test mp3 decoding"
        super(TestDecodingMonoUpsampling, self).testMp3()
        self.expected_totalframes = 384941

    def testWav(self):
        "Test wav decoding"
        super(TestDecodingMonoUpsampling, self).testWav()

    def testWavMono(self):
        "Test mono wav decoding"
        super(TestDecodingMonoUpsampling, self).testWavMono()

    def testWav32k(self):
        "Test 32kHz wav decoding"
        super(TestDecodingMonoUpsampling, self).testWav32k()
        self.expected_totalframes = 384000

    def testFlac(self):
        "Test flac decoding"
        super(TestDecodingMonoUpsampling, self).testFlac()

    def testOgg(self):
        "Test ogg decoding"
        super(TestDecodingMonoUpsampling, self).testOgg()
        self.expected_totalframes = 384000


class TestDecodingMonoDownsampling(TestDecoding):

    def setUp(self):
        super(TestDecodingMonoDownsampling, self).setUp()
        self.samplerate, self.channels, self.blocksize = 16000, None, None

        self.expected_totalframes = 128000

    def testWav32k(self):
        "Test 32kHz wav decoding"
        super(TestDecodingMonoDownsampling, self).testWav32k()
        self.expected_totalframes = 128000

    def testOgg(self):
        "Test ogg decoding"
        super(TestDecodingMonoDownsampling, self).testOgg()
        self.expected_totalframes = 127980

    def testMp3(self):
        "Test mp3 decoding"
        super(TestDecodingMonoDownsampling, self).testMp3()
        self.expected_totalframes = 128314


class TestDecodingStereoDownsampling(TestDecoding):

    def setUp(self):
        super(TestDecodingStereoDownsampling, self).setUp()
        self.samplerate, self.channels, self.blocksize = 32000, 2, None

        self.expected_totalframes = 256000

    def testWav32k(self):
        "Test 32kHz wav decoding"
        super(TestDecodingStereoDownsampling, self).testWav32k()
        self.expected_totalframes = 256000

    def testOgg(self):
        "Test ogg decoding"
        super(TestDecodingStereoDownsampling, self).testOgg()
        self.expected_totalframes = 255992

    def testMp3(self):
        "Test mp3 decoding"
        super(TestDecodingStereoDownsampling, self).testMp3()
        self.expected_totalframes = 256627


class TestDecodingStereoUpsampling(TestDecoding):

    def setUp(self):
        super(TestDecodingStereoUpsampling, self).setUp()
        self.samplerate, self.channels, self.blocksize = 96000, 2, None

        self.expected_totalframes = 768000

    def testWav32k(self):
        "Test 32kHz wav decoding"
        super(TestDecodingStereoUpsampling, self).testWav32k()
        self.expected_totalframes = 768000

    def testOgg(self):
        "Test ogg decoding"
        super(TestDecodingStereoUpsampling, self).testOgg()
        self.expected_totalframes = 768000

    def testMp3(self):
        "Test mp3 decoding"
        super(TestDecodingStereoUpsampling, self).testMp3()
        self.expected_totalframes = 769881


class TestDecodingShortBlock(TestDecoding):

    def setUp(self):
        super(TestDecodingShortBlock, self).setUp()
        self.samplerate, self.channels, self.blocksize = None, None, 256


class TestDecodingLongBlock(TestDecoding):

    def setUp(self):
        super(TestDecodingLongBlock, self).setUp()
        self.samplerate, self.channels, self.blocksize = None, None, 1024 * \
            8 * 2


class TestDecodingWrongFiles(unittest.TestCase):

    "Test decoding features"

    def testMissingFile(self):
        "Test decoding missing file"
        self.source = os.path.join(os.path.dirname(__file__),
                                   "a_missing_file_blahblah.wav")
        self.assertRaises(IOError, FileDecoder, self.source)

    def testDevNull(self):
        "Test decoding dev null"
        self.source = "/dev/null"
        with self.assertRaises(IOError):
            FileDecoder(self.source)

    def testNoAudioStream(self):
        "Test decoding file withouth audio stream"
        self.source = __file__
        with self.assertRaises(IOError):
            FileDecoder(self.source)

    def testEmptyFile(self):
        "Test decoding empty file"
        import tempfile
        self.tmpfile = tempfile.NamedTemporaryFile(delete=True)
        self.source = self.tmpfile.name
        with self.assertRaises(IOError):
            FileDecoder(self.source)

        self.tmpfile.close()

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_decoding_stack
#! /usr/bin/env python

from __future__ import division

from timeside.decoder.file import FileDecoder
from timeside.analyzer.level import Level
from timeside.core import ProcessPipe
from unit_timeside import *

import os.path

#from glib import GError as GST_IOError
# HINT : to use later with Gnonlin only


class TestDecodingFromStack(unittest.TestCase):
    "Test decoder stack"

    def setUp(self):
        self.samplerate, self.channels, self.blocksize = None, None, None
        self.start = 0
        self.duration = None

        self.expected_samplerate = 44100
        self.expected_channels = 2
        self.expected_totalframes = 352800
        self.test_exact_duration = True
        self.source_duration = 8
        self.expected_mime_type = 'audio/x-wav'
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.wav")

    def testProcess(self):
        "Test decoder stack: test process"
        decoder = FileDecoder(uri=self.source,
                              start=self.start,
                              duration=self.duration,
                              stack=True)
        self.assertTrue(decoder.stack)
        self.assertFalse(decoder.from_stack)

        pipe = ProcessPipe(decoder)

        pipe.run()

        self.assertFalse(decoder.stack)
        self.assertTrue(decoder.from_stack)

        self.assertEqual(len(pipe.frames_stack), 44)

        pipe.run()

    def testResults(self):
        "Test decoder stack: test frames content"

        decoder = FileDecoder(uri=self.source,
                              start=self.start,
                              duration=self.duration,
                              stack=True)
        level_on_file = Level()
        pipe = (decoder | level_on_file)

        pipe.run()

        self.assertIsInstance(pipe.frames_stack, list)

        results_on_file = pipe.results['level.rms'].data.copy()

        # If the pipe is used for a second run, the processed frames stored
        # in the stack are passed to the other processors
        # without decoding the audio source again.
        #Let's define a second analyzer equivalent to the previous one:

        level_on_stack = Level()
        pipe |= level_on_stack
        pipe.run()

        # to assert that the frames passed to the two analyzers are the same,
        # we check that the results of these analyzers are equivalent:
        results_on_stack = pipe.results['level.rms'].data

        self.assertEqual(results_on_stack,
                         results_on_file)


if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_encoding
#! /usr/bin/env python

from __future__ import division

from math import pi
import numpy as np
from unit_timeside import *
from timeside.decoder.utils import get_uri, get_media_uri_info
from timeside.decoder.array import ArrayDecoder
import os
from tools import tmp_file_sink


class TestEncoding(unittest.TestCase):
    "Test encoding features"

    def generate_source(self):
        self.expected_total_frames = self.source_duration * self.samplerate

        f0 = 440.
        f = f0 * np.logspace(0, 4/12*(self.channels-1), self.channels, base=2)
        omega = 2. * pi * f / self.samplerate
        samples = np.empty((self.expected_total_frames, self.channels))
        for n in xrange(self.channels):
            samples[:, n] = .75 * np.sin(omega[n] *
                                         np.arange(self.expected_total_frames))
        return samples

    def setUp(self):
        self.samplerate, self.channels, self.blocksize = 44100, 1, 1024
        self.overwrite = False
        self.encode_to_file = True
        self.test_duration = True
        self.test_channels = True

        # Source
        self.source_duration = 10.

    def testWav(self):
        "Test wav encoding"
        from timeside.encoder.wav import WavEncoder
        self.encoder_function = WavEncoder
        self.delta = 0

    def testVorbis(self):
        "Test vorbis encoding"
        from timeside.encoder.ogg import VorbisEncoder
        self.encoder_function = VorbisEncoder
        self.delta = 0.3

    def testMp3(self):
        "Test mp3 encoding"
        from timeside.encoder.mp3 import Mp3Encoder
        self.encoder_function = Mp3Encoder
        self.delta = 0.2

    def testAac(self):
        "Test aac encoding"
        from timeside.encoder.m4a import AacEncoder
        self.encoder_function = AacEncoder
        self.test_channels = False
        self.delta = 0.3

    def testFlac(self):
        "Test flac encoding"
        from timeside.encoder.flac import FlacEncoder
        self.encoder_function = FlacEncoder
        self.delta = 0

    def testWebM(self):
        "Test webm encoding, audio only"
        from timeside.encoder.webm import WebMEncoder
        self.encoder_function = WebMEncoder
        self.test_duration = False  # webmmux encoder with streamable=true
                                    # does not return a valid duration

    def testWebMVideo(self):
        "Test webm encoding, video"
        from timeside.encoder.webm import WebMEncoder
        self.encoder_function = WebMEncoder
        self.test_duration = False  # webmmux encoder with streamable=true
                                    # does not return a valid duration
        if not hasattr(self, 'sink'):
            file_extension = '.' + self.encoder_function.file_extension()
            self.sink = tmp_file_sink(prefix=self.__class__.__name__,
                                      suffix=file_extension)
            self.encoder = self.encoder_function(self.sink,
                                                 overwrite=self.overwrite,
                                                 video=True)

    def testOpus(self):
        "Test opus encoding"
        from timeside.encoder.opus import OpusEncoder
        self.encoder_function = OpusEncoder
        self.delta = 0.1
        self.samplerate = 48000  # 44100 is not supported by opusenc

    def tearDown(self):

        # Source through ArrayDecoder

        decoder = ArrayDecoder(self.generate_source(),
                               samplerate=self.samplerate)
        # Encoder
        if not hasattr(self, 'sink'):
            file_extension = '.' + self.encoder_function.file_extension()
            self.sink = tmp_file_sink(prefix=self.__class__.__name__,
                                      suffix=file_extension)

        if not hasattr(self, 'encoder'):
            self.encoder = self.encoder_function(self.sink,
                                                 overwrite=self.overwrite)

        # Run Pipe
        (decoder | self.encoder).run()

        if self.encode_to_file:
            media_info = get_media_uri_info(get_uri(self.sink))
            media_duration = media_info['duration']
            media_channels = media_info['streams'][0]['channels']
            media_samplerate = media_info['streams'][0]['samplerate']

            os.unlink(self.sink)

            if self.test_duration:
                self.assertAlmostEqual(self.source_duration,
                                       media_duration,
                                       delta=self.delta)
            if self.test_channels:
                self.assertEqual(self.channels, media_channels)
            else:
                self.assertEqual(2, media_channels)   # voaacenc bug ?
            self.assertEqual(media_samplerate, self.samplerate)

        if 0:
            import commands
            print commands.getoutput('sndfile-info ' + self.sink)

        self.assertEqual(self.expected_total_frames, self.encoder.num_samples)
        self.assertEqual(self.channels, self.encoder.channels())
        self.assertEqual(self.samplerate, self.encoder.samplerate())
        self.assertEqual(self.source_duration,
                         self.encoder.num_samples/self.encoder.samplerate())


class TestEncodingLongBlock(TestEncoding):
    "Test encoding features with longer blocksize"

    def setUp(self):
        super(TestEncodingLongBlock, self).setUp()
        self.blocksize *= 8


class TestEncodingShortBlock(TestEncoding):
    "Test encoding features with short blocksize"

    def setUp(self):
        super(TestEncodingShortBlock, self).setUp()
        self.blocksize = 64


class TestEncodingLowSamplerate(TestEncoding):
    "Test encoding features with low samplerate"

    def setUp(self):
        super(TestEncodingLowSamplerate, self).setUp()
        self.samplerate = 8000


class TestEncodingHighSamplerate(TestEncoding):
    "Test encoding features with high samplerate"

    def setUp(self):
        super(TestEncodingHighSamplerate, self).setUp()
        self.samplerate = 48000


# class TestEncodingTooManyChannels(TestEncoding):
#     "Test encoding features with high samplerate"

#     def setUp(self):
#         super(TestEncodingTooManyChannels, self).setUp()
#         self.samplerate = 192000 * 2
#         self.channels = 128

#     def tearDown(self):
#         self.encoder.setup(channels = self.channels,
#                            samplerate = self.samplerate)
#         self.assertRaises(IOError, self.encoder.release)
#         unlink(self.sink)


class TestEncodingStereo(TestEncoding):
    "Test encoding features with stereo"

    def setUp(self):
        super(TestEncodingStereo, self).setUp()
        self.channels = 2


class TestEncodingToDevNull(TestEncoding):
    "Test encoding features with /dev/null"

    def setUp(self):
        super(TestEncodingToDevNull, self).setUp()
        self.sink = '/dev/null'
        self.encode_to_file = False


class TestEncodingToDirectory(TestEncoding):
    "Test encoding features to a directory"

    def setUp(self):
        self.samplerate, self.channels, self.blocksize = 44100, 1, 1024
        import tempfile
        self.sink = tempfile.mkdtemp()
        self.overwrite = False

    def tearDown(self):
        from os import rmdir
        self.assertRaises(IOError, self.encoder_function, self.sink)
        rmdir(self.sink)


class TestEncodingOverwriteFails(unittest.TestCase):
    "Test encoding features"

    def setUp(self):
        self.samplerate, self.channels, self.blocksize = 44100, 1, 1024
        self.overwrite = False

    def tearDown(self):
        self.assertRaises(IOError, self.encoder_function, self.sink)


class TestEncodingOverwriteForced(unittest.TestCase):
    "Test encoding features"

    def setUp(self):
        self.samplerate, self.channels, self.blocksize = 44100, 1, 1024
        import tempfile
        self.tmpfile = tempfile.NamedTemporaryFile(delete=True)
        self.sink = self.tmpfile.name
        self.overwrite = True

    def tearDown(self):
        super(TestEncodingOverwriteForced, self).tearDown()


if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_graphing
#! /usr/bin/env python

from timeside.decoder.file import FileDecoder
from unit_timeside import *

import os.path

__all__ = ['TestGraphing']


class TestGraphing(unittest.TestCase):
    "Test all graphers with WAV input media format"

    def setUp(self):
        pass

    # WAVEFORMS
    def testWav2Waveform(self):
        "Test WAV to Waveform"
        from timeside.grapher.waveform_simple import Waveform
        self.source = os.path.join (os.path.dirname(__file__),  "samples/sweep.wav")
        self.image = "/tmp/test_waveform_sweep_wav.png"
        self.grapher = Waveform(width=1024, height=256, bg_color=(255,255,255), color_scheme='default')

    # WAVEFORM CENTROID
    def testWav2WaveformCentroid(self):
        "Test WAV to WaveformCentroid"
        from timeside.grapher.waveform_centroid import WaveformCentroid
        self.source = os.path.join (os.path.dirname(__file__),  "samples/sweep.wav")
        self.image = "/tmp/test_waveform_centroid_sweep_wav.png"
        self.grapher = WaveformCentroid(width=1024, height=256, bg_color=(0,0,0), color_scheme='default')

    # WAVEFORMS TRANSPARENT
    def testWav2WaveformTransparent(self):
        "Test WAV to WaveformTransparent"
        from timeside.grapher.waveform_transparent import WaveformTransparent
        self.source = os.path.join (os.path.dirname(__file__),  "samples/sweep.wav")
        self.image = "/tmp/test_waveform_transparent_sweep_wav.png"
        self.grapher = WaveformTransparent(width=1024, height=256, bg_color=None, color_scheme='default')

    # WAVEFORMS CONTOUR BLACK
    def testWav2WaveformContourBlack(self):
        "Test WAV to WaveformContourBlack"
        from timeside.grapher.waveform_contour import WaveformContourBlack
        self.source = os.path.join (os.path.dirname(__file__),  "samples/sweep.wav")
        self.image = "/tmp/test_waveform_contour_bk_sweep_wav.png"
        self.grapher = WaveformContourBlack(width=1024, height=256, bg_color=(0,0,0), color_scheme='default')

    # WAVEFORMS CONTOUR WHITE
    def testWav2WaveformContourWhite(self):
        "Test WAV to WaveformContourWhite"
        from timeside.grapher.waveform_contour import WaveformContourWhite
        self.source = os.path.join (os.path.dirname(__file__),  "samples/sweep.wav")
        self.image = "/tmp/test_waveform_contour_wh_sweep_wav.png"
        self.grapher = WaveformContourWhite(width=1024, height=256, bg_color=(255,255,255), color_scheme='default')

    # LOG SPECTROGRAMS
    def testWav2Spectrogram(self):
        "Test WAV to Spectrogram"
        from timeside.grapher.spectrogram_log import SpectrogramLog
        self.source = os.path.join (os.path.dirname(__file__),  "samples/sweep.wav")
        self.image = "/tmp/test_spectrogram_log_sweep_wav.png"
        self.grapher = SpectrogramLog(width=1024, height=256, bg_color=(0,0,0), color_scheme='default')

    # LIN SPECTROGRAMS
    def testWav2Spectrogram(self):
        "Test WAV to SpectrogramLinear"
        from timeside.grapher.spectrogram_lin import SpectrogramLinear
        self.source = os.path.join (os.path.dirname(__file__),  "samples/sweep.wav")
        self.image = "/tmp/test_spectrogram_lin_sweep_wav.png"
        self.grapher = SpectrogramLinear(width=1024, height=256, bg_color=(0,0,0), color_scheme='default')

    def tearDown(self):
        decoder = FileDecoder(self.source)
        (decoder | self.grapher).run()
        self.grapher.render(self.image)

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())


########NEW FILE########
__FILENAME__ = test_inputadapter
#! /usr/bin/env python

from timeside.core import FixedSizeInputAdapter
from unit_timeside import *
import numpy

class TestFixedSizeInputAdapter(unittest.TestCase):
    "Test the fixed-sized input adapter"

    def assertIOEquals(self, adapter, input, input_eod, output, output_eod=None):
        output = output[:]
        output.reverse()
        _eod = None
        for buffer, _eod in adapter.process(input, input_eod):
            a = output.pop()
            if not numpy.array_equiv(buffer, a):
                self.fail("\n-- Actual --\n%s\n -- Expected -- \n%s\n" % (str(buffer), str(a)))

        if _eod != output_eod:
            self.fail("eod do not match: %s != %s", (str(_eod), str(output_eod)))

        if output:
            self.fail("trailing expected data: %s" % output)

    def setUp(self):
        self.data = numpy.arange(44).reshape(2,22).transpose()

    def testTwoChannels(self):
        "Test simple stream with two channels"
        adapter = FixedSizeInputAdapter(4, 2)

        self.assertEquals(len(self.data), adapter.blocksize(len(self.data)))

        self.assertIOEquals(adapter, self.data[0:1], False, [])
        self.assertIOEquals(adapter, self.data[1:5], False, [self.data[0:4]], False)
        self.assertIOEquals(adapter, self.data[5:12], False, [self.data[4:8], self.data[8:12]], False)
        self.assertIOEquals(adapter, self.data[12:13], False, [])
        self.assertIOEquals(adapter, self.data[13:14], False, [])
        self.assertIOEquals(adapter, self.data[14:18], False, [self.data[12:16]], False)
        self.assertIOEquals(adapter, self.data[18:20], False, [self.data[16:20]], False)
        self.assertIOEquals(adapter, self.data[20:21], False, [])
        self.assertIOEquals(adapter, self.data[21:22], True, [self.data[20:22]], True)

    def testPadding(self):
        "Test automatic padding support"
        adapter = FixedSizeInputAdapter(4, 2, pad=True)

        self.assertEquals(len(self.data) + 2, adapter.blocksize(len(self.data)))

        self.assertIOEquals(adapter, self.data[0:21], False,
            [self.data[0:4], self.data[4:8], self.data[8:12], self.data[12:16], self.data[16:20]],
            False)

        self.assertIOEquals(adapter, self.data[21:22], True, [[
            [20, 42],
            [21, 43],
            [0, 0],
            [0, 0]
        ]], True)

    def testSizeMultiple(self):
        "Test a stream which contain a multiple number of buffers"
        adapter = FixedSizeInputAdapter(4, 2)

        self.assertIOEquals(adapter, self.data[0:20], True,
            [self.data[0:4], self.data[4:8], self.data[8:12], self.data[12:16], self.data[16:20]],
            True)


if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())


########NEW FILE########
__FILENAME__ = test_list_processors
#! /usr/bin/env python

from unit_timeside import *
import timeside
verbose = 0

class TestListCoreProcessors(unittest.TestCase):
    """ test get list of processors """

    def testHasSomeDecoders(self):
        "has some decoders"
        import timeside.decoder
        procs = timeside.core.processors(timeside.api.IDecoder)
        self.assertNotEquals(len(procs), 0)

    def testHasSomeEncoders(self):
        "has some encoders"
        import timeside.encoder
        procs = timeside.core.processors(timeside.api.IEncoder)
        self.assertNotEquals(len(procs), 0)

    def testHasSomeAnalyzers(self):
        "has some analyzers"
        import timeside.analyzer
        procs = timeside.core.processors(timeside.api.IAnalyzer)
        self.assertNotEquals(len(procs), 0)

    def testHasSomeGraphers(self):
        "has some graphers"
        import timeside.grapher
        procs = timeside.core.processors(timeside.api.IGrapher)
        self.assertNotEquals(len(procs), 0)


if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_run_all_doctests
#! /usr/bin/env python
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2013 Parisson SARL

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors:
#   Thomas Fillon <thomas  at parisson.com>
import unittest
from unit_timeside import TestRunner
import doctest
import timeside
from timeside.tools.package import discover_modules


def load_tests(loader, tests, ignore):

    finder = doctest.DocTestFinder(exclude_empty=False)

    # Create tests for doctest in timeside modules and sub-modules
    modules_list = discover_modules(timeside.__name__)

    for module in modules_list:
        _tmp = __import__(module, fromlist=['DOCTEST_ALIAS'])
        try:
            DOCTEST_ALIAS = _tmp.DOCTEST_ALIAS
        except AttributeError:
            DOCTEST_ALIAS = {}

        tests.addTests(doctest.DocTestSuite(module, extraglobs=DOCTEST_ALIAS,
                                            test_finder=finder))

    return tests


if __name__ == '__main__':
    import os
     # Do not run doctest for environment without a display (e.g. server)
    if 'DISPLAY' in os.environ:
        unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_transcoding
#! /usr/bin/env python

from __future__ import division

from timeside.core import get_processor, ProcessPipe
from timeside.decoder.file import FileDecoder
from timeside.component import *

from unit_timeside import *
from tools import tmp_file_sink
import os.path


class TestTranscodingFromWav(unittest.TestCase):
    "Test transcoding from wav"

    def setUp(self):
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.wav")
        self.test_duration = True
        self.test_channels = True

    def testWav(self):
        "Test conversion to wav"
        self.encoder_id = 'gst_wav_enc'

    def testMp3(self):
        "Test conversion to mp3"
        self.encoder_id = 'gst_mp3_enc'

    def testOgg(self):
        "Test conversion to ogg"
        self.encoder_id = 'gst_vorbis_enc'

    def testWebM(self):
        "Test conversion to webm"
        self.encoder_id = 'gst_webm_enc'
        self.test_duration = False  # webmmux encoder with streamable=true
                                    # does not return a valid duration

    def testM4a(self):
        "Test conversion to m4a"
        self.encoder_id = 'gst_aac_enc'

    def tearDown(self):
        decoder = FileDecoder(self.source)

        encoder_cls = get_processor(self.encoder_id)

        file_extension = '.' + encoder_cls.file_extension()

        self.target = tmp_file_sink(prefix=self.__class__.__name__,
                                  suffix=file_extension)
        encoder = encoder_cls(self.target)
        (decoder | encoder).run()

        decoder_encoded = FileDecoder(self.target)

        pipe = ProcessPipe(decoder_encoded)
        pipe.run()

        import os
        os.unlink(self.target)

        #print decoder.channels(), decoder.samplerate(), written_frames
        #print media_channels

        if self.test_channels:
            self.assertEqual(decoder.channels(), decoder_encoded.channels())
        else:
            self.assertEqual(2, decoder_encoded.channels())  # voaacenc bug ?

        self.assertEqual(decoder.samplerate(),
                         decoder_encoded.samplerate())

        if self.test_duration:
            self.assertAlmostEqual(decoder.input_duration,
                                   decoder_encoded.input_duration,
                                   delta=0.2)

class TestTranscodingFromMonoWav(TestTranscodingFromWav):
    "Test transcoding from a mono wav"

    def setUp(self):
        super(TestTranscodingFromMonoWav, self).setUp()
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep_mono.wav")

    def testM4a(self):
        "Test conversion to m4a"
        super(TestTranscodingFromMonoWav, self).testM4a()
        self.test_channels = False  # voaacenc bug ? : always encode stereo


class TestTranscodingFromAnotherWav(TestTranscodingFromMonoWav):
    "Test transcoding from another wav"

    def setUp(self):
        super(TestTranscodingFromAnotherWav, self).setUp()
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/guitar.wav")  # Mono


class TestTranscodingFromMp3(TestTranscodingFromWav):
    "Test transcoding from mp3"

    def setUp(self):
        super(TestTranscodingFromMp3, self).setUp()
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.mp3")


class TestTranscodingFromFlac(TestTranscodingFromWav):
    "Test transcoding from flac"

    def setUp(self):
        super(TestTranscodingFromFlac, self).setUp()
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.flac")


class TestTranscodingFromOgg(TestTranscodingFromWav):
    "Test transcoding from ogg"

    def setUp(self):
        super(TestTranscodingFromOgg, self).setUp()
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.ogg")





class TestTranscodingFrom32kHzWav(TestTranscodingFromWav):
    "Test transcoding from a 32kHz wav"

    def setUp(self):
        super(TestTranscodingFrom32kHzWav, self).setUp()
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep_32000.wav")


class TestTranscodingFromMissingFile(TestTranscodingFromWav):
    "Test transcoding from a missing file"

    def setUp(self):
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/unexisting.wav")

    def tearDown(self):
        decoder = FileDecoder
        self.assertRaises(IOError, decoder, self.source)

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_transcoding_streaming
#! /usr/bin/env python

from __future__ import division

from timeside.core import get_processor, ProcessPipe
from timeside.decoder.file import FileDecoder
#from timeside.analyzer import *
#from timeside.encoder import *
#from timeside.component import *

from unit_timeside import *
from tools import tmp_file_sink
import os.path


class TestTranscodingStreaming(unittest.TestCase):
    "Test transcoding and streaming"

    def setUp(self):
        self.source = os.path.join(os.path.dirname(__file__),
                                   "samples/sweep.wav")
        self.test_duration = True
        self.test_channels = True
        self.filesize_delta = None
        self.expected_sample_rate = None

    def testMp3(self):
        "Test conversion to mp3"
        self.encoder_id = 'gst_mp3_enc'
        self.filesize_delta = 156

    def testOgg(self):
        "Test conversion to ogg"
        self.encoder_id = 'gst_vorbis_enc'

    def testOpus(self):
        "Test conversion to opus"
        self.encoder_id = 'gst_opus_enc'
        self.expected_sample_rate = 48000

    def testWebM(self):
        "Test conversion to webm"
        self.encoder_id = 'gst_webm_enc'
        self.test_duration = False  # webmmux encoder with streamable=true
                                    # does not return a valid duration

    def tearDown(self):
        decoder = FileDecoder(self.source)
        encoder_cls = get_processor(self.encoder_id)

        file_extension = '.' + encoder_cls.file_extension()

        self.target_filesink = tmp_file_sink(prefix=self.__class__.__name__,
                                             suffix=file_extension)

        self.target_appsink = tmp_file_sink(prefix=self.__class__.__name__,
                                            suffix=file_extension)

        encoder = encoder_cls(self.target_filesink, streaming=True)
        pipe = (decoder | encoder)

        with open(self.target_appsink, 'w') as f:
            for chunk in pipe.stream():
                f.write(chunk)

        decoder_encoded = FileDecoder(self.target_filesink)

        pipe2 = ProcessPipe(decoder_encoded)
        pipe2.run()

        import os
        filesink_size = os.path.getsize(self.target_filesink)
        appsink_size = os.path.getsize(self.target_appsink)

        os.unlink(self.target_filesink)
        os.unlink(self.target_appsink)
        #print decoder.channels(), decoder.samplerate(), written_frames
        #print media_channels

        if self.test_channels:
            self.assertEqual(decoder.channels(), decoder_encoded.channels())
        else:
            self.assertEqual(2, decoder_encoded.channels())  # voaacenc bug ?

        if not self.expected_sample_rate:
            self.expected_sample_rate = decoder.samplerate()
        self.assertEqual(self.expected_sample_rate,
                         decoder_encoded.samplerate())

        if self.test_duration:
            self.assertAlmostEqual(decoder.input_duration,
                                   decoder_encoded.input_duration,
                                   delta=0.2)
        self.assertAlmostEqual(filesink_size, appsink_size,
                               delta=self.filesize_delta)

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = test_yaafe
#! /usr/bin/env python

from unit_timeside import *
from timeside.decoder.file import FileDecoder
from timeside import _WITH_YAAFE
if _WITH_YAAFE:
    from timeside.analyzer.yaafe import Yaafe
    from yaafelib import DataFlow, FeaturePlan
import os


@unittest.skipIf(not _WITH_YAAFE, 'Yaafe library is not available')
class TestYaafe(unittest.TestCase):

    def setUp(self):
        self.sample_rate = 16000

    def testOnSweepWithFeaturePlan(self):
        "runs on sweep and define feature plan manually"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "sweep.wav")

        # Setup Yaafe Analyzer
        # Define Yaafe Feature Plan
        fp = FeaturePlan(sample_rate=self.sample_rate)
        # add feature definitions manually
        fp.addFeature('mfcc: MFCC blockSize=512 stepSize=256')
        fp.addFeature('mfcc_d1: MFCC blockSize=512 stepSize=256 > Derivate DOrder=1')
        fp.addFeature('mfcc_d2: MFCC blockSize=512 stepSize=256 > Derivate DOrder=2')

        # Setup a new Yaafe TimeSide analyzer
        # from FeaturePlan
        self.analyzer = Yaafe(fp)

        # Expected Results
        self.result_length = 3

    def testOnGuitarWithFeaturePlanFromFile(self):
        "runs on guitar and load Yaafe feature plan from file"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "guitar.wav")
        # Setup Yaafe Analyzer
        # Load Yaafe Feature Plan
        fp = FeaturePlan(sample_rate=self.sample_rate)
        fp_file = os.path.join (os.path.dirname(__file__),  "yaafe_config", "yaafeFeaturePlan")

        fp.loadFeaturePlan(fp_file)
        # Setup a new Yaafe TimeSide analyzer
        # from FeaturePlan
        self.analyzer = Yaafe(fp)

        # Expected Results
        self.result_length = 3

    def testOnGuitarWithDataFlow(self):
        "runs on guitar and load Yaafe dataflow from file"
        self.source = os.path.join (os.path.dirname(__file__),  "samples", "guitar.wav")
        # Setup Yaafe Analyzer
        # Load DataFlow from file
        df = DataFlow()
        df_file = os.path.join (os.path.dirname(__file__),  "yaafe_config", "yaafeDataFlow")
        df.load(df_file)

        # Setup a new Yaafe TimeSide analyzer
        # from DataFlow
        self.analyzer = Yaafe(df)

        # Expected Results
        self.result_length = 5

    def tearDown(self):
        decoder = FileDecoder(self.source)
        decoder.output_samplerate = self.sample_rate
        (decoder | self.analyzer).run()
        results = self.analyzer.results
        self.assertEquals(self.result_length, len(results))
        #print results
        #print results.to_yaml()
        #print results.to_json()
        #print results.to_xml()

if __name__ == '__main__':
    unittest.main(testRunner=TestRunner())

########NEW FILE########
__FILENAME__ = tools
import os
import urllib


def check_samples():
    url = 'http://github.com/yomguy/timeside-samples/raw/master/samples/'
    samples = ['guitar.wav', 'sweep.wav', 'sweep_mono.wav', 'sweep_32000.wav', 'sweep.flac', 'sweep.ogg', 'sweep.mp3', 'sweep_source.wav']
    path = os.path.normpath(os.path.dirname(__file__))
    dir = path + os.sep + 'samples'

    if not os.path.exists(dir):
        os.makedirs(dir)

    for sample in samples:
        path = dir + os.sep + sample
        if not os.path.exists(path):
            print 'downloading: ' + sample
            f = open(path, 'w')
            u = urllib.urlopen(url+sample)
            f.write(u.read())
            f.close()


def tmp_file_sink(prefix=None, suffix = None):
    import tempfile
    tmpfile = tempfile.NamedTemporaryFile(delete=True,
                                          prefix=prefix,
                                          suffix=suffix)
    tmpfile.close()
    return tmpfile.name
########NEW FILE########
__FILENAME__ = unit_timeside
# -*- coding: utf-8 -*-

import unittest
import doctest
import sys
import time
from tools import check_samples

check_samples()


class _TextTestResult(unittest.TestResult):
    """A test result class that can print formatted text results to a stream.

    Used by TextTestRunner.
    """
    separator1 = '=' * 70
    separator2 = '-' * 70

    def __init__(self, stream, descriptions, verbosity):
        unittest.TestResult.__init__(self)
        self.stream = stream
        self.showAll = verbosity > 1
        self.dots = verbosity == 1
        self.descriptions = descriptions
        self.currentTestCase = None

    def getDescription(self, test):
        if self.descriptions:
            return test.shortDescription() or str(test)
        else:
            return str(test)

    def startTest(self, test):
        unittest.TestResult.startTest(self, test)
        if self.showAll:
            if self.currentTestCase != test.__class__:
                self.currentTestCase = test.__class__
                self.stream.writeln()
                self.stream.writeln("[%s]" % self.currentTestCase.__name__)
            self.stream.write("  " + self.getDescription(test))
            self.stream.write(" ... ")

    def addSuccess(self, test):
        unittest.TestResult.addSuccess(self, test)
        if self.showAll:
            self.stream.writeln("ok")
        elif self.dots:
            self.stream.write('.')

    def addError(self, test, err):
        unittest.TestResult.addError(self, test, err)
        if self.showAll:
            self.stream.writeln("ERROR")
        elif self.dots:
            self.stream.write('E')

    def addFailure(self, test, err):
        unittest.TestResult.addFailure(self, test, err)
        if self.showAll:
            self.stream.writeln("FAIL")
        elif self.dots:
            self.stream.write('F')

    def addSkip(self, test, reason):
        unittest.TestResult.addSkip(self, test, reason)
        if self.showAll:
            self.stream.writeln("SKIP : " + reason)
        elif self.dots:
            self.stream.write('S')

    def printErrors(self):
        if self.dots or self.showAll:
            self.stream.writeln()
        self.printErrorList('ERROR', self.errors)
        self.printErrorList('FAIL', self.failures)

    def printErrorList(self, flavour, errors):
        for test, err in errors:
            self.stream.writeln(self.separator1)
            self.stream.writeln("%s: [%s] --> %s "
                                % (flavour,
                                   test.__class__.__name__,
                                   self.getDescription(test)))
            self.stream.writeln(self.separator2)
            self.stream.writeln("%s" % err)


class _WritelnDecorator:
    """Used to decorate file-like objects with a handy 'writeln' method"""
    def __init__(self, stream):
        self.stream = stream

    def __getattr__(self, attr):
        return getattr(self.stream, attr)

    def writeln(self, arg=None):
        if arg:
            self.write(arg)
        self.write('\n')  # text-mode streams translate to \r\n if needed


class TestRunner:
    """A test runner class that displays results in textual form.

    It prints out the names of tests as they are run, errors as they
    occur, and a summary of the results at the end of the test run.
    """

    def __init__(self, stream=sys.stderr, descriptions=1, verbosity=2):
        self.stream = _WritelnDecorator(stream)
        self.descriptions = descriptions
        self.verbosity = verbosity
        check_samples()

    def _makeResult(self):
        return _TextTestResult(self.stream, self.descriptions, self.verbosity)

    def run(self, test):
        "Run the given test case or test suite."
        result = self._makeResult()
        startTime = time.time()
        test(result)
        stopTime = time.time()
        timeTaken = stopTime - startTime
        result.printErrors()
        self.stream.writeln(result.separator2)
        run = result.testsRun
        self.stream.writeln("Ran %d test%s in %.3fs" %
                            (run, run != 1 and "s" or "", timeTaken))
        self.stream.writeln()
        if not result.wasSuccessful():
            self.stream.write("FAILED (")
            failed, errored = map(len, (result.failures, result.errors))
            if failed:
                self.stream.write("failures=%d" % failed)
            if errored:
                if failed:
                    self.stream.write(", ")
                self.stream.write("errors=%d" % errored)
            self.stream.writeln(")")
        else:
            self.stream.writeln("OK")
        return result


def run_test_module(test_modules_list=None, test_prefix=None):
    suite = unittest.TestSuite()
    finder = doctest.DocTestFinder(exclude_empty=False)  # finder for doctest
    if test_prefix:
        unittest.TestLoader.testMethodPrefix = test_prefix
    if not test_modules_list:
        test_modules_list = []
    elif not isinstance(test_modules_list, list):
        test_modules_list = [test_modules_list]
    test_modules_list.append('__main__')
    for test in test_modules_list:
        # Doctest
        suite.addTest(doctest.DocTestSuite(test, test_finder=finder))
        # unittest
        suite.addTest(unittest.loader.TestLoader().loadTestsFromModule(test))
    TestRunner().run(suite)

########NEW FILE########
__FILENAME__ = aubio_melenergy
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>
from __future__ import absolute_import

from ...core import implements, interfacedoc
from ..core import Analyzer
from ...api import IAnalyzer
from ..preprocessors import downmix_to_mono, frames_adapter

from aubio import filterbank, pvoc


class AubioMelEnergy(Analyzer):

    """Aubio Mel Energy analyzer"""
    implements(IAnalyzer)

    def __init__(self):
        super(AubioMelEnergy, self).__init__()
        self.input_blocksize = 1024
        self.input_stepsize = self.input_blocksize / 4

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(AubioMelEnergy, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.n_filters = 40
        self.n_coeffs = 13
        self.pvoc = pvoc(self.input_blocksize, self.input_stepsize)
        self.melenergy = filterbank(self.n_filters, self.input_blocksize)
        self.melenergy.set_mel_coeffs_slaney(samplerate)
        self.block_read = 0
        self.melenergy_results = []

    @staticmethod
    @interfacedoc
    def id():
        return "aubio_melenergy"

    @staticmethod
    @interfacedoc
    def name():
        return "Mel Energy (aubio)"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    @downmix_to_mono
    @frames_adapter
    def process(self, frames, eod=False):

        fftgrain = self.pvoc(frames)
        self.melenergy_results.append(self.melenergy(fftgrain))
        self.block_read += 1
        return frames, eod

    def post_process(self):
        melenergy = self.new_result(data_mode='value', time_mode='framewise')
        melenergy.parameters = dict(n_filters=self.n_filters,
                                    n_coeffs=self.n_coeffs)
        melenergy.data_object.value = self.melenergy_results
        self.process_pipe.results.add(melenergy)

########NEW FILE########
__FILENAME__ = aubio_mfcc
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>
from __future__ import absolute_import

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer
from timeside.analyzer.preprocessors import downmix_to_mono, frames_adapter

import numpy
from aubio import mfcc, pvoc


class AubioMfcc(Analyzer):

    """Aubio MFCC analyzer"""
    implements(IAnalyzer)

    def __init__(self):
        super(AubioMfcc, self).__init__()
        self.input_blocksize = 1024
        self.input_stepsize = self.input_blocksize / 4

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(AubioMfcc, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.n_filters = 40
        self.n_coeffs = 13
        self.pvoc = pvoc(self.input_blocksize, self.input_stepsize)
        self.mfcc = mfcc(self.input_blocksize,
                         self.n_filters,
                         self.n_coeffs,
                         samplerate)
        self.block_read = 0
        self.mfcc_results = numpy.zeros([self.n_coeffs, ])

    @staticmethod
    @interfacedoc
    def id():
        return "aubio_mfcc"

    @staticmethod
    @interfacedoc
    def name():
        return "MFCC (aubio)"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    @downmix_to_mono
    @frames_adapter
    def process(self, frames, eod=False):
        fftgrain = self.pvoc(frames)
        coeffs = self.mfcc(fftgrain)
        self.mfcc_results = numpy.vstack((self.mfcc_results, coeffs))
        self.block_read += 1
        return frames, eod

    def post_process(self):
        mfcc = self.new_result(data_mode='value', time_mode='framewise')
        mfcc.parameters = dict(n_filters=self.n_filters,
                               n_coeffs=self.n_coeffs)
        mfcc.data_object.value = self.mfcc_results
        self.process_pipe.results.add(mfcc)

########NEW FILE########
__FILENAME__ = aubio_pitch
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>
from __future__ import absolute_import

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer
from timeside.analyzer.preprocessors import downmix_to_mono, frames_adapter
from aubio import pitch
import numpy as np


class AubioPitch(Analyzer):

    """Aubio Pitch estimation analyzer"""
    implements(IAnalyzer)  # TODO check if needed with inheritance

    def __init__(self):
        super(AubioPitch, self).__init__()
        self.input_blocksize = 2048
        self.input_stepsize = self.input_blocksize / 2

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(AubioPitch, self).setup(channels,
                                      samplerate,
                                      blocksize,
                                      totalframes)
        self.aubio_pitch = pitch(
            "default", self.input_blocksize, self.input_stepsize,
            samplerate)
        self.aubio_pitch.set_unit("freq")
        self.block_read = 0
        self.pitches = []
        self.pitch_confidences = []

    @staticmethod
    @interfacedoc
    def id():
        return "aubio_pitch"

    @staticmethod
    @interfacedoc
    def name():
        return "f0 (aubio)"

    @staticmethod
    @interfacedoc
    def unit():
        return "Hz"

    def __str__(self):
        return "pitch values"

    @downmix_to_mono
    @frames_adapter
    def process(self, frames, eod=False):
        #time = self.block_read * self.input_stepsize * 1. / self.samplerate()
        self.pitches += [self.aubio_pitch(frames)[0]]
        self.pitch_confidences += [
            np.nan_to_num(self.aubio_pitch.get_confidence())]
        self.block_read += 1
        return frames, eod

    def post_process(self):
        pitch = self.new_result(data_mode='value', time_mode='framewise')

        # parameters : None # TODO check with Piem "default" and "freq" in
        # setup

        pitch.id_metadata.id += '.' + "pitch"
        pitch.id_metadata.name += ' ' + "pitch"
        pitch.id_metadata.unit = "Hz"
        pitch.data_object.value = self.pitches
        self.process_pipe.results.add(pitch)

        pitch_confidence = self.new_result(
            data_mode='value', time_mode='framewise')
        pitch_confidence.id_metadata.id += '.' + "pitch_confidence"
        pitch_confidence.id_metadata.name += ' ' + "pitch confidence"
        pitch_confidence.id_metadata.unit = None
        pitch_confidence.data_object.value = self.pitch_confidences
        self.process_pipe.results.add(pitch_confidence)

########NEW FILE########
__FILENAME__ = aubio_specdesc
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>
from __future__ import absolute_import

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer
from timeside.analyzer.preprocessors import downmix_to_mono, frames_adapter

from aubio import specdesc, pvoc


class AubioSpecdesc(Analyzer):

    """Aubio Spectral Descriptors collection analyzer"""
    implements(IAnalyzer)

    def __init__(self):
        super(AubioSpecdesc, self).__init__()
        self.input_blocksize = 1024
        self.input_stepsize = self.input_blocksize / 4

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(
            AubioSpecdesc,
            self).setup(
            channels,
            samplerate,
            blocksize,
            totalframes)
        self.block_read = 0
        self.pvoc = pvoc(self.input_blocksize, self.input_stepsize)
        self.methods = [
            'default', 'energy', 'hfc', 'complex', 'phase', 'specdiff', 'kl',
            'mkl', 'specflux', 'centroid', 'slope', 'rolloff', 'spread', 'skewness',
            'kurtosis', 'decrease']
        self.specdesc = {}
        self.specdesc_results = {}
        for method in self.methods:
            self.specdesc[method] = specdesc(method, self.input_blocksize)
            self.specdesc_results[method] = []

    @staticmethod
    @interfacedoc
    def id():
        return "aubio_specdesc"

    @staticmethod
    @interfacedoc
    def name():
        return "Spectral Descriptor (aubio)"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    @downmix_to_mono
    @frames_adapter
    def process(self, frames, eod=False):
        fftgrain = self.pvoc(frames)
        for method in self.methods:
            self.specdesc_results[method] += [
                self.specdesc[method](fftgrain)[0]]
        return frames, eod

    def post_process(self):

        # For each method store results in container
        for method in self.methods:
            res_specdesc = self.new_result(data_mode='value',
                                           time_mode='framewise')
            # Set metadata
            res_specdesc.id_metadata.id += '.' + method
            res_specdesc.id_metadata.name = ' ' + method
            res_specdesc.data_object.value = self.specdesc_results[method]

            self.process_pipe.results.add(res_specdesc)

########NEW FILE########
__FILENAME__ = aubio_temporal
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>
from __future__ import absolute_import

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer
from timeside.analyzer.preprocessors import downmix_to_mono, frames_adapter
from aubio import onset, tempo

import numpy


class AubioTemporal(Analyzer):

    """Aubio Temporal analyzer"""
    implements(IAnalyzer)

    def __init__(self):
        super(AubioTemporal, self).__init__()
        self.input_blocksize = 1024
        self.input_stepsize = 256

    @interfacedoc
    def setup(self,
              channels=None,
              samplerate=None,
              blocksize=None,
              totalframes=None):
        super(AubioTemporal, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.o = onset(
            "default", self.input_blocksize, self.input_stepsize, samplerate)
        self.t = tempo(
            "default", self.input_blocksize, self.input_stepsize, samplerate)
        self.block_read = 0
        self.onsets = []
        self.beats = []
        self.beat_confidences = []

    @staticmethod
    @interfacedoc
    def id():
        return "aubio_temporal"

    @staticmethod
    @interfacedoc
    def name():
        return "onsets (aubio)"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    def __str__(self):
        return "%s %s" % (str(self.value), self.unit())

    @downmix_to_mono
    @frames_adapter
    def process(self, frames, eod=False):
        if self.o(frames):
            self.onsets += [self.o.get_last_s()]
        if self.t(frames):
            self.beats += [self.t.get_last_s()]
            self.beat_confidences += [self.t.get_confidence()]
        self.block_read += 1
        return frames, eod

    def post_process(self):

        #---------------------------------
        #  Onsets: Event (time, "Onset")
        #---------------------------------
        onsets = self.new_result(data_mode='label', time_mode='event')
        onsets.id_metadata.id += '.' + 'onset'
        onsets.id_metadata.name += ' ' + 'Onset'
        onsets.id_metadata.unit = 's'
        onsets.data_object.time = self.onsets
        onsets.data_object.label = numpy.ones(len(self.onsets))
        onsets.label_metadata.label = {1: 'Onset'}

        self.process_pipe.results.add(onsets)

        #---------------------------------
        #  Onset Rate: Segment (time, duration, value)
        #---------------------------------
        onsetrate = self.new_result(data_mode='value', time_mode='segment')
        onsetrate.id_metadata.id += '.' + "onset_rate"
        onsetrate.id_metadata.name = " " + "Onset Rate"
        onsetrate.id_metadata.unit = "bpm"
        if len(self.onsets) > 1:
            periods = numpy.diff(self.onsets)
            periods = numpy.append(periods, periods[-1])
            onsetrate.data_object.time = self.onsets
            onsetrate.data_object.duration = periods
            onsetrate.data_object.value = 60. / periods
        else:
            onsetrate.data_object.value = []
            onsetrate.data_object.time = []

        self.process_pipe.results.add(onsetrate)

        #---------------------------------
        #  Beats: Event (time, "Beat")
        #---------------------------------
        beats = self.new_result(data_mode='label', time_mode='event')
        beats.id_metadata.id += '.' + "beat"
        beats.id_metadata.name += " " + "Beats"
        beats.id_metadata.unit = "s"
        beats.data_object.time = self.beats
        beats.data_object.label = numpy.ones(len(self.beats))
        beats.label_metadata.label = {1: 'Beat'}

        self.process_pipe.results.add(beats)

        #---------------------------------
        #  Beat confidences: Event (time, value)
        #---------------------------------
        beat_confidences = self.new_result(
            data_mode='value', time_mode='event')
        beat_confidences.id_metadata.id += '.' + "beat_confidence"
        beat_confidences.id_metadata.name += " " + "Beat confidences"
        beat_confidences.id_metadata.unit = None
        beat_confidences.data_object.time = self.beats
        beat_confidences.data_object.value = self.beat_confidences

        self.process_pipe.results.add(beat_confidences)

        #---------------------------------
        #  BPM: Segment (time, duration, value)
        #---------------------------------
        bpm = self.new_result(data_mode='value', time_mode='segment')
        bpm.id_metadata.id += '.' + "bpm"
        bpm.id_metadata.name += ' ' + "bpm"
        bpm.id_metadata.unit = "bpm"
        if len(self.beats) > 1:
            periods = numpy.diff(self.beats)
            periods = numpy.append(periods, periods[-1])
            bpm.data_object.time = self.beats
            bpm.data_object.duration = periods
            bpm.data_object.value = 60. / periods
        else:
            bpm.data_object.value = []

        self.process_pipe.results.add(bpm)

########NEW FILE########
__FILENAME__ = core
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2013 Parisson SARL

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors:
#   Guillaume Pellerin <yomguy at parisson.com>
#   Paul Brossier <piem@piem.org>
#   Thomas Fillon <thomas  at parisson.com>

from __future__ import division

from timeside.core import Processor
import timeside  # import __version__
import numpy
from collections import OrderedDict
import h5py
import h5tools

import os

if 'DISPLAY' not in os.environ:
    import matplotlib
    matplotlib.use('Agg')

import matplotlib.pyplot as plt
from matplotlib.figure import Figure
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas

numpy_data_types = [
    #'float128',
    'float64',
    'float32',
    #'float16', Not supported by h5py for version < 2.2
    'int64',
    'int16',
    'int32',
    'int8',
    'uint64',
    'uint32',
    'uint16',
    'uint8',
    #'unicode_', Strings should be handled through label_metadata
    #'string_',
    'object_',
    'longlong',
    #'timedelta64',
    #'datetime64',
    #'complex128',
    #'complex64',
]
numpy_data_types = map(lambda x: getattr(numpy, x), numpy_data_types)
#numpy_data_types += [numpy.ndarray]


class MetadataObject(object):

    """
    Object that contains a metadata structure
    stucture inspired by [1]
    [1] : http://www.saltycrane.com/blog/2012/08/python-data-object-motivated-desire-mutable-namedtuple-default-values/

    Metadata
    ----------


    Methods
    -------
    as_dict()
        Return a dictionnary representation of the MetadataObject
    """

    # Define default values as an OrderDict
    # in order to keep the order of the keys for display
    _default_value = OrderedDict()

    def __init__(self, **kwargs):
        '''
        Construct an Metadata object
        Abstract Class _default_value must be specified by

        Metadata()

        Parameters
        ----------

        Returns
        -------
        Metadata
        '''
        # Set Default values
        for key, value in self._default_value.items():
            setattr(self, key, value)

        # Set metadata passed in as arguments
        # for k, v in zip(self._default_value.keys(), args):
        #    setattr(self, k, v)
        #    print 'args'
        for key, value in kwargs.items():
            setattr(self, key, value)

    def __setattr__(self, name, value):
        if name not in self._default_value.keys():
            raise AttributeError("%s is not a valid attribute in %s" %
                                 (name, self.__class__.__name__))
        super(MetadataObject, self).__setattr__(name, value)

    def __delattr__(self, name):
        if name in self._default_value.keys():
            new_default_value = self._default_value.copy()
            del new_default_value[name]
            super(MetadataObject, self).__setattr__('_default_value',
                                                    new_default_value)
            super(MetadataObject, self).__delattr__(name)

    def as_dict(self):
        return dict((att, getattr(self, att))
                    for att in self.keys())

    def keys(self):
        return [attr for attr in self._default_value.keys()]

    def values(self):
        return [self[attr] for attr in self.keys()]

    def items(self):
        return [(attr, self[attr]) for attr in self.keys()]

    def __getitem__(self, key, default=None):
        try:
            return getattr(self, key)
        except AttributeError:
            return default

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def __repr__(self):
        return '{}({})'.format(
            self.__class__.__name__,
            ', '.join('{}={}'.format(
                att, repr(getattr(self, att)))
                for att in self.keys()))

    def __str__(self):
        return self.as_dict().__str__()

    def __eq__(self, other):
        return (isinstance(other, self.__class__)
                and all([self[key] == other[key] for key in self.keys()]))

    def __ne__(self, other):
        return not(isinstance(other, self.__class__)
                   or self.as_dict() != other.as_dict())

    def to_xml(self):
        import xml.etree.ElementTree as ET
        root = ET.Element('Metadata')

        for key in self.keys():
            child = ET.SubElement(root, key)
            child.text = repr(getattr(self, key))

        return ET.tostring(root, encoding="utf-8", method="xml")

    def from_xml(self, xml_string):
        import xml.etree.ElementTree as ET
        import ast
        root = ET.fromstring(xml_string)
        for child in root:
            key = child.tag
            if child.text:
                self[key] = ast.literal_eval(child.text)

    def to_hdf5(self, h5group):
        h5tools.dict_to_hdf5(self, h5group)

    def from_hdf5(self, h5group):
        h5tools.dict_from_hdf5(self, h5group)


class IdMetadata(MetadataObject):

    '''
    Metadata object to handle Audio related Metadata

        Attributes
        ----------
        id : str
        name : str
        unit : str
        description : str
        date : str
            date and time in ISO  8601 format YYYY-MM-DDTHH:MM:SS
        version : str
        author : str
        uuid : str
    '''
    # TODO :
    # - (long) description -->  mettre dans l'API Processor

    # Define default values
    _default_value = OrderedDict([('id', None),
                                  ('name', None),
                                  ('unit', None),
                                  ('description', None),
                                  ('date', None),
                                  ('version', None),
                                  ('author', None),
                                  ('uuid', None)])

    def __setattr__(self, name, value):
        if value is None:
            value = ''

        super(IdMetadata, self).__setattr__(name, value)


class AudioMetadata(MetadataObject):

    '''
    Metadata object to handle Identification Metadata

        Attributes
        ----------
        uri : str
        start : float
            Start time of the segment in seconds
        duration : float
            Duration of the segment in seconds
        is_segment : boolean
            Is the media a segment of an audio source
        sha1 : str
            Sha1 hexadecimal digest of the audio source
        channels : int
            Number of channels
        channelsManagement : str
            A string that indicates how the channels are manage
            Examples :
                channelsManagement = '(L+R)/2'
                channelsManagement = 'R' keep only right channel
                channelsManagement = 'L' keep only left channel
                channelsManagement = 'stereo' keep both stereo channels
    '''

    # Define default values
    _default_value = OrderedDict([('uri', ''),
                                  ('start', 0),
                                  ('duration', None),
                                  ('is_segment', None),
                                  ('sha1', ''),
                                  ('channels', None),
                                  ('channelsManagement', '')])


class LabelMetadata(MetadataObject):

    '''
    Metadata object to handle Label Metadata

        Attributes
        ----------
        label : dict
            A dictionnary that contains :
                - label id has keys and
                - label names has values

        description : dict
            A dictionnary that contains :
                - label id has keys and
                - label descriptions has values

        label_type : str
            = 'mono' or 'multi'
            'mono' or 'multi' enable to specify the label mode :
            - 'mono'  : mono-label (only 1 label at a time)
            - 'multi' : multi-label (several labels can be observe
                        at the same time)


    '''

    # Define default values
    _default_value = OrderedDict([('label', {}),
                                  ('description', {}),
                                  ('label_type', 'mono')])

    def to_hdf5(self, h5group):
        """
        Save a dictionnary-like object inside a h5 file group
        """
        # Write attributes
        name = 'label_type'
        if self.__getattribute__(name) is not None:
            h5group.attrs[name] = self.__getattribute__(name)

        for name in ['label', 'description']:
            subgroup = h5group.create_group(name)
            h5tools.dict_to_hdf5(self.__getattribute__(name), subgroup)


class FrameMetadata(MetadataObject):

    '''
    Metadata object to handle Frame related Metadata

        Attributes
        ----------
        samplerate : int (or float?)
        blocksize : int
        stepsize : int
    '''
    # TODO : check is samplerate can support float

    # Define default values
    _default_value = OrderedDict([('samplerate', None),
                                  ('blocksize', None),
                                  ('stepsize', None)])


class DataObject(MetadataObject):

    '''
    Metadata object to handle data related Metadata

        Attributes
        ----------
        value : numpy array
        label : numpy array of int
        time : numpy array of float
        duration : numpy array of float

    '''

    # Define default values
    _default_value = OrderedDict([('value', None),
                                  ('label', None),
                                  ('time', None),
                                  ('duration', None)])

    def __setattr__(self, name, value):
        if value is None:
            value = []

        # Set Data with the proper type
        if name == 'value':
            value = numpy.asarray(value)
            if value.dtype.type not in numpy_data_types:
                raise TypeError(
                    'Result Data can not accept type %s for %s' %
                    (value.dtype.type, name))
            if value.shape == ():
                value.resize((1,))

        elif name == 'label':
            try:
                value = numpy.asarray(value, dtype='int')
            except ValueError:
                raise TypeError(
                    'Result Data can not accept type %s for %s' %
                    (value.dtype.type, name))

        elif name in ['time', 'duration']:
            try:
                value = numpy.asfarray(value)
            except ValueError:
                raise TypeError(
                    'Result Data can not accept type %s for %s' %
                    (value.dtype.type, name))
        elif name == 'dataType':
            return

        super(DataObject, self).__setattr__(name, value)

    def __eq__(self, other):
        try:
            return (isinstance(other, self.__class__) and
                    all([numpy.array_equal(self[key], other[key])
                         for key in self.keys()]))
        except AttributeError:
            return (isinstance(other, self.__class__) and
                    all([bool(numpy.logical_and.reduce((self[key] == other[key]).ravel()))
                         for key in self.keys()]))

    def __ne__(self, other):
        return not(isinstance(other, self.__class__) or
                   any([numpy.array_equal(self[key], other[key])
                        for key in self.keys()]))

    def to_xml(self):
        import xml.etree.ElementTree as ET
        root = ET.Element('Metadata')

        for key in self.keys():
            child = ET.SubElement(root, key)
            value = getattr(self, key)
            if value not in [None, []]:
                child.text = repr(value.tolist())
                child.set('dtype', value.dtype.__str__())

        return ET.tostring(root, encoding="utf-8", method="xml")

    def from_xml(self, xml_string):
        import xml.etree.ElementTree as ET
        import ast
        root = ET.fromstring(xml_string)
        for child in root:
            key = child.tag
            if child.text:
                self[key] = numpy.asarray(ast.literal_eval(child.text),
                                          dtype=child.get('dtype'))

    def to_hdf5(self, h5group):
        # Write Datasets
        for key in self.keys():
            if self.__getattribute__(key) is None:
                continue
            if self.__getattribute__(key).dtype == 'object':
                # Handle numpy type = object as vlen string
                h5group.create_dataset(key,
                                       data=self.__getattribute__(
                                           key).tolist().__repr__(),
                                       dtype=h5py.special_dtype(vlen=str))
            else:
                if numpy.prod(self.__getattribute__(key).shape):
                    maxshape = None
                else:
                    maxshape = (None,)
                h5group.create_dataset(
                    key, data=self.__getattribute__(key), maxshape=maxshape)

    def from_hdf5(self, h5group):
        for key, dataset in h5group.items():
            # Load value from the hdf5 dataset and store in data
            # FIXME : the following conditional statement is to prevent
            # reading an empty dataset.
            # see : https://github.com/h5py/h5py/issues/281
            # It should be fixed by the next h5py version
            if dataset.shape != (0,):
                if h5py.check_dtype(vlen=dataset.dtype):
                    # to deal with VLEN data used for list of
                    # list
                    self.__setattr__(key, eval(dataset[...].tolist()))
                else:
                    self.__setattr__(key, dataset[...])
            else:
                self.__setattr__(key, [])


class AnalyzerParameters(dict):

    def as_dict(self):
        return self

    def to_xml(self):
        import xml.etree.ElementTree as ET
        root = ET.Element('Metadata')

        for key, value in self.items():
            child = ET.SubElement(root, key)
            child.text = repr(self.get(key))

        return ET.tostring(root, encoding="utf-8", method="xml")

    def from_xml(self, xml_string):
        import xml.etree.ElementTree as ET
        import ast
        root = ET.fromstring(xml_string)
        for child in root.iter():
            if child.text:
                self.set(child.tag, ast.literal_eval(child.text))

    def to_hdf5(self, subgroup):
        h5tools.dict_to_hdf5(self, subgroup)

    def from_hdf5(self, h5group):
        h5tools.dict_from_hdf5(self, h5group)


class AnalyzerResult(MetadataObject):

    """
    Object that contains the metadata and parameters of an analyzer process

    Parameters
    ----------
    data_mode : str
        data_mode describes the type of data :
            - 'value' for values
            - 'label' for label data see LabelMetadata
    time_mode : str
        time_mode describes the correspondance between data values and time
            - 'framewise'
            - 'global'
            - 'segment'
            - 'event'

    Returns
    -------
    A new MetadataObject with the following attributes :
        - data_object : :class:`DataObject`
        - id_metadata : :class:`IdMetadata`
        - audio_metadata : :class:`AudioMetadata`
        - frame_metadata : :class:`FrameMetadata`
        - label_metadata : :class:`LabelMetadata`
        - parameters : :class:`AnalyzerParameters` Object

    """

    # Define default values
    _default_value = OrderedDict([('id_metadata', None),
                                  ('data_object', None),
                                  ('audio_metadata', None),
                                  ('frame_metadata', None),
                                  ('label_metadata', None),
                                  ('parameters', None)
                                  ])

    def __init__(self, data_mode=None, time_mode=None):
        super(AnalyzerResult, self).__init__()

        self.id_metadata = IdMetadata()
        self.data_object = DataObject()
        self.audio_metadata = AudioMetadata()
        self.frame_metadata = FrameMetadata()
        self.label_metadata = LabelMetadata()
        self.parameters = AnalyzerParameters()

    @staticmethod
    def factory(data_mode='value', time_mode='framewise'):
        """
        Factory function for Analyzer result
        """
        for result_cls in AnalyzerResult.__subclasses__():
            if (hasattr(result_cls, '_time_mode') and
                hasattr(result_cls, '_data_mode') and
                (result_cls._data_mode, result_cls._time_mode) == (data_mode,
                                                                   time_mode)):
                return result_cls()
        print data_mode, time_mode
        raise ValueError('Wrong arguments')

    def __setattr__(self, name, value):
        if name in ['_data_mode', '_time_mode']:
            super(MetadataObject, self).__setattr__(name, value)
            return

        elif name in self.keys():
            if isinstance(value, dict) and value:
                for (sub_name, sub_value) in value.items():
                    self[name][sub_name] = sub_value
                return

        super(AnalyzerResult, self).__setattr__(name, value)

    def __len__(self):
        if self.data_mode == 'value':
            return len(self.data_object.value)
        else:
            return len(self.data_object.label)

    def as_dict(self):
        return dict([(key, self[key].as_dict())
                    for key in self.keys() if hasattr(self[key], 'as_dict')] +
                    [('data_mode', self.data_mode), ('time_mode', self.time_mode)])
                    # TODO : check if it can be simplified now

    def to_xml(self):
        import xml.etree.ElementTree as ET
        root = ET.Element('result')
        root.metadata = {'name': self.id_metadata.name,
                         'id': self.id_metadata.id}

        for name in ['data_mode', 'time_mode']:
            child = ET.SubElement(root, name)
            child.text = str(self.__getattribute__(name))
            child.tag = name
            root.append(child)

        for key in self.keys():
            child = ET.fromstring(self[key].to_xml())
            child.tag = key
            root.append(child)

        return ET.tostring(root, encoding="utf-8", method="xml")

    @staticmethod
    def from_xml(xml_string):
        import xml.etree.ElementTree as ET
        root = ET.fromstring(xml_string)

        data_mode_child = root.find('data_mode')
        time_mode_child = root.find('time_mode')
        result = AnalyzerResult.factory(data_mode=data_mode_child.text,
                                        time_mode=time_mode_child.text)
        for child in root:
            key = child.tag
            if key not in ['data_mode', 'time_mode']:
                child_string = ET.tostring(child)
                result[key].from_xml(child_string)

        return result

    def to_hdf5(self, h5_file):
        # Save results in HDF5 Dataset
        group = h5_file.create_group(self.id_metadata.id)
        group.attrs['data_mode'] = self.__getattribute__('data_mode')
        group.attrs['time_mode'] = self.__getattribute__('time_mode')
        for key in self.keys():
            if key in ['data_mode', 'time_mode']:
                continue
            subgroup = group.create_group(key)
            self.__getattribute__(key).to_hdf5(subgroup)

    @staticmethod
    def from_hdf5(h5group):
        # Read Sub-Group
        result = AnalyzerResult.factory(data_mode=h5group.attrs['data_mode'],
                                        time_mode=h5group.attrs['time_mode'])
        for subgroup_name, h5subgroup in h5group.items():
            result[subgroup_name].from_hdf5(h5subgroup)
        return result

    def _render_plot(self, ax):
        return NotImplemented

    def render(self):
        '''Render a matplotlib figure from the analyzer result

           Return the figure, use fig.show() to display if neeeded
        '''
        # TODO : this may crash if the data array is too large
        # possible workaround downsampled the data
        #  and plot center, min, max values
        # see http://stackoverflow.com/a/8881973

        fig, ax = plt.subplots()
        self._render_plot(ax)
        return fig

    def _render_PIL(self, size=(1024, 256), dpi=80):
        from ..grapher.core import Image
        image_width, image_height = size

        xSize = image_width / dpi
        ySize = image_height / dpi

        fig = Figure(figsize=(xSize, ySize), dpi=dpi)

        ax = fig.add_axes([0, 0, 1, 1], frame_on=False)

        self._render_plot(ax)

        ax.autoscale(axis='x', tight=True)

        # Export to PIL image
        from StringIO import StringIO
        imgdata = StringIO()
        canvas = FigureCanvas(fig)
        canvas.print_png(imgdata, dpi=dpi)
        imgdata.seek(0)  # rewind the data

        return Image.open(imgdata)

    @property
    def data_mode(self):
        return self._data_mode

    @property
    def time_mode(self):
        return self._time_mode

    @property
    def data(self):
        raise NotImplementedError

    @property
    def time(self):
        raise NotImplementedError

    @property
    def duration(self):
        raise NotImplementedError

    @property
    def id(self):
        return self.id_metadata.id

    @property
    def name(self):
        return self.id_metadata.name

    @property
    def unit(self):
        return self.id_metadata.unit


class ValueObject(object):
    _data_mode = 'value'

    def __init__(self):
        super(ValueObject, self).__init__()
        del self.data_object.label
        del self.label_metadata

    @property
    def data(self):
        return self.data_object.value

    @property
    def properties(self):
        return dict(mean=numpy.mean(self.data, axis=0),
                    std=numpy.std(self.data, axis=0, ddof=1),
                    median=numpy.median(self.data, axis=0),
                    max=numpy.max(self.data, axis=0),
                    min=numpy.min(self.data, axis=0),
                    shape=self.data.shape,
                    )


class LabelObject(object):
    _data_mode = 'label'

    def __init__(self):
        super(LabelObject, self).__init__()
        del self.data_object.value

    @property
    def data(self):
        return self.data_object.label


class GlobalObject(object):
    _time_mode = 'global'

    def __init__(self):
        super(GlobalObject, self).__init__()
        del self.frame_metadata
        del self.data_object.time
        del self.data_object.duration

    @property
    def time(self):
        return self.audio_metadata.start

    @property
    def duration(self):
        return self.audio_metadata.duration


class FramewiseObject(object):
    _time_mode = 'framewise'

    def __init__(self):
        super(FramewiseObject, self).__init__()
        del self.data_object.time
        del self.data_object.duration

    @property
    def time(self):
        return (self.audio_metadata.start +
                self.frame_metadata.stepsize /
                self.frame_metadata.samplerate *
                numpy.arange(0, len(self)))

    @property
    def duration(self):
        return (self.frame_metadata.blocksize / self.frame_metadata.samplerate
                * numpy.ones(len(self)))


class EventObject(object):
    _time_mode = 'event'

    def __init__(self):
        super(EventObject, self).__init__()
        del self.frame_metadata
        del self.data_object.duration

    @property
    def time(self):
        return self.audio_metadata.start + self.data_object.time

    @property
    def duration(self):
        return numpy.zeros(len(self))

    def _render_plot(self, ax):
        ax.stem(self.time, self.data)


class SegmentObject(EventObject):
    _time_mode = 'segment'

    def __init__(self):
        super(EventObject, self).__init__()
        del self.frame_metadata

    @property
    def duration(self):
        return self.data_object.duration


class GlobalValueResult(ValueObject, GlobalObject, AnalyzerResult):
    pass


class GlobalLabelResult(LabelObject, GlobalObject, AnalyzerResult):
    pass


class FrameValueResult(ValueObject, FramewiseObject, AnalyzerResult):

    def _render_plot(self, ax):
        ax.plot(self.time, self.data)


class FrameLabelResult(LabelObject, FramewiseObject, AnalyzerResult):

    def _render_plot(self, ax):
        pass


class EventValueResult(ValueObject, EventObject, AnalyzerResult):
    pass


class EventLabelResult(LabelObject, EventObject, AnalyzerResult):
    pass


class SegmentValueResult(ValueObject, SegmentObject, AnalyzerResult):

    def _render_plot(self, ax):
        for time, value in (self.time, self.data):
            ax.axvline(time, ymin=0, ymax=value, color='r')
            # TODO : check value shape !!!


class SegmentLabelResult(LabelObject, SegmentObject, AnalyzerResult):

    def _render_plot(self, ax):
        import itertools
        colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])
        ax_color = {}
        for key in self.label_metadata.label.keys():
            ax_color[key] = colors.next()
        for time, duration, label in zip(self.time, self.duration, self.data):
            ax.axvspan(time, time + duration, color=ax_color[label], alpha=0.3)


class AnalyzerResultContainer(dict):

    '''
    >>> import timeside
    >>> from timeside.analyzer.core import Analyzer
    >>> wav_file = 'tests/samples/sweep.mp3' # doctest: +SKIP
    >>> d = timeside.decoder.file.FileDecoder(wav_file)

    >>> a = Analyzer()
    >>> (d|a).run()
    >>> a.new_result() #doctest: +ELLIPSIS
    FrameValueResult(id_metadata=IdMetadata(id='analyzer', name='Generic analyzer', unit='', description='', date='...', version='...', author='TimeSide', uuid='...'), data_object=DataObject(value=array([], dtype=float64)), audio_metadata=AudioMetadata(uri='...', start=0.0, duration=8.0..., is_segment=False, sha1='...', channels=2, channelsManagement=''), frame_metadata=FrameMetadata(samplerate=44100, blocksize=8192, stepsize=8192), parameters={})
    >>> resContainer = timeside.analyzer.core.AnalyzerResultContainer()
    '''

    def __init__(self, analyzer_results=None):
        super(AnalyzerResultContainer, self).__init__()
        if analyzer_results is not None:
            self.add(analyzer_results)

    def add(self, analyzer_result):
        if isinstance(analyzer_result, list):
            for res in analyzer_result:
                self.add(res)
            return
        # Check result
        if not isinstance(analyzer_result, AnalyzerResult):
            raise TypeError('only AnalyzerResult can be added')

        self.__setitem__(analyzer_result.id_metadata.id,
                         analyzer_result)
        #self.results += [analyzer_result]

    def to_xml(self, output_file=None):

        import xml.etree.ElementTree as ET
        # TODO : cf. telemeta util
        root = ET.Element('timeside')

        for result in self.values():
            if result is not None:
                root.append(ET.fromstring(result.to_xml()))

        xml_str = ET.tostring(root, encoding="utf-8", method="xml")
        if output_file:
            open(output_file, 'w').write(xml_str)
        else:
            return xml_str

    @staticmethod
    def from_xml(xml_string):
        import xml.etree.ElementTree as ET

        results = AnalyzerResultContainer()
        # TODO : from file
        #tree = ET.parse(xml_file)
        #root = tree.getroot()
        root = ET.fromstring(xml_string)
        for child in root.iter('result'):
            results.add(AnalyzerResult.from_xml(ET.tostring(child)))

        return results

    def to_json(self, output_file=None):
        #if data_list == None: data_list = self.results
        import simplejson as json

        # Define Specialize JSON encoder for numpy array
        def NumpyArrayEncoder(obj):
            if isinstance(obj, numpy.ndarray):
                return {'numpyArray': obj.tolist(),
                        'dtype': obj.dtype.__str__()}
            elif isinstance(obj, numpy.generic):
                return numpy.asscalar(obj)
            else:
                print type(obj)
                raise TypeError(repr(obj) + " is not JSON serializable")

        json_str = json.dumps([res.as_dict() for res in self.values()],
                              default=NumpyArrayEncoder)
        if output_file:
            open(output_file, 'w').write(json_str)
        else:
            return json_str

    @staticmethod
    def from_json(json_str):
        import simplejson as json

        # Define Specialize JSON decoder for numpy array
        def NumpyArrayDecoder(obj):
            if isinstance(obj, dict) and 'numpyArray' in obj:
                numpy_obj = numpy.asarray(obj['numpyArray'],
                                          dtype=obj['dtype'])
                return numpy_obj
            else:
                return obj

        results_json = json.loads(json_str, object_hook=NumpyArrayDecoder)
        results = AnalyzerResultContainer()
        for res_json in results_json:

            res = AnalyzerResult.factory(data_mode=res_json['data_mode'],
                                         time_mode=res_json['time_mode'])
            for key in res_json.keys():
                if key not in ['data_mode', 'time_mode']:
                    res[key] = res_json[key]

            results.add(res)
        return results

    def to_yaml(self, output_file=None):
        #if data_list == None: data_list = self.results
        import yaml

        # Define Specialize Yaml encoder for numpy array
        def numpyArray_representer(dumper, obj):
            return dumper.represent_mapping(u'!numpyArray',
                                            {'dtype': obj.dtype.__str__(),
                                             'array': obj.tolist()})

        yaml.add_representer(numpy.ndarray, numpyArray_representer)

        yaml_str = yaml.dump([res.as_dict() for res in self.values()])
        if output_file:
            open(output_file, 'w').write(yaml_str)
        else:
            return yaml_str

    @staticmethod
    def from_yaml(yaml_str):
        import yaml

        # Define Specialize Yaml encoder for numpy array
        def numpyArray_constructor(loader, node):
            mapping = loader.construct_mapping(node, deep=True)
            return numpy.asarray(mapping['array'], dtype=mapping['dtype'])

        yaml.add_constructor(u'!numpyArray', numpyArray_constructor)

        results_yaml = yaml.load(yaml_str)
        results = AnalyzerResultContainer()
        for res_yaml in results_yaml:
            res = AnalyzerResult.factory(data_mode=res_yaml['data_mode'],
                                         time_mode=res_yaml['time_mode'])
            for key in res_yaml.keys():
                if key not in ['data_mode', 'time_mode']:
                    res[key] = res_yaml[key]
            results.add(res)
        return results

    def to_numpy(self, output_file=None):
        if output_file:
            numpy.save(output_file, self)
        else:
            return self

    @staticmethod
    def from_numpy(input_file):
        return numpy.load(input_file)

    def to_hdf5(self, output_file):
        # Open HDF5 file and save dataset (overwrite any existing file)
        with h5py.File(output_file, 'w') as h5_file:
            for res in self.values():
                res.to_hdf5(h5_file)

    @staticmethod
    def from_hdf5(input_file):
        import h5py
        # TODO : enable import for yaafe hdf5 format

        # Open HDF5 file for reading and get results
        h5_file = h5py.File(input_file, 'r')
        results = AnalyzerResultContainer()
        try:
            for group in h5_file.values():
                result = AnalyzerResult.from_hdf5(group)
                results.add(result)
        except TypeError:
            print('TypeError for HDF5 serialization')
        finally:
            h5_file.close()  # Close the HDF5 file

        return results


class Analyzer(Processor):

    '''
    Generic class for the analyzers
    '''

    type = 'analyzer'

    def __init__(self):
        super(Analyzer, self).__init__()

    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(Analyzer, self).setup(channels, samplerate,
                                    blocksize, totalframes)

        # Set default values for result_* attributes
        # may be overwritten by the analyzer
        self.result_channels = self.input_channels
        self.result_samplerate = self.input_samplerate
        self.result_blocksize = self.input_blocksize
        self.result_stepsize = self.input_stepsize

    @property
    def results(self):
        return AnalyzerResultContainer(
            [self.process_pipe.results[key] for key in self.process_pipe.results.keys()
             if key.split('.')[0] == self.id()])

    @staticmethod
    def id():
        return "analyzer"

    @staticmethod
    def name():
        return "Generic analyzer"

    @staticmethod
    def unit():
        return ""

    def new_result(self, data_mode='value', time_mode='framewise'):
        '''
        Create a new result

        Attributes
        ----------
        data_object : MetadataObject
        id_metadata : MetadataObject
        audio_metadata : MetadataObject
        frame_metadata : MetadataObject
        label_metadata : MetadataObject
        parameters : dict

        '''

        from datetime import datetime

        result = AnalyzerResult.factory(data_mode=data_mode,
                                        time_mode=time_mode)

        # Automatically write known metadata
        result.id_metadata.date = datetime.now().replace(
            microsecond=0).isoformat(' ')
        result.id_metadata.version = timeside.__version__
        result.id_metadata.author = 'TimeSide'
        result.id_metadata.id = self.id()
        result.id_metadata.name = self.name()
        result.id_metadata.unit = self.unit()
        result.id_metadata.uuid = self.uuid()

        result.audio_metadata.uri = self.mediainfo()['uri']
        result.audio_metadata.sha1 = self.mediainfo()['sha1']
        result.audio_metadata.start = self.mediainfo()['start']
        result.audio_metadata.duration = self.mediainfo()['duration']
        result.audio_metadata.is_segment = self.mediainfo()['is_segment']
        result.audio_metadata.channels = self.channels()

        if time_mode == 'framewise':
            result.frame_metadata.samplerate = self.result_samplerate
            result.frame_metadata.blocksize = self.result_blocksize
            result.frame_metadata.stepsize = self.result_stepsize

        return result

DOCTEST_ALIAS = {'wav_file':
                 'https://github.com/yomguy/timeside-samples/raw/master/samples/sweep.mp3'}


if __name__ == "__main__":
    import doctest
    doctest.testmod(extraglobs=DOCTEST_ALIAS)

########NEW FILE########
__FILENAME__ = dc
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2009 Guillaume Pellerin <yomguy@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Guillaume Pellerin <yomguy@parisson.com>

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IValueAnalyzer
import numpy


class MeanDCShift(Analyzer):

    """Mean DC shift analyzer"""
    implements(IValueAnalyzer)

    @interfacedoc
    def setup(self, channels=None,
              samplerate=None,
              blocksize=None,
              totalframes=None):
        super(MeanDCShift, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.values = numpy.array([0])

    @staticmethod
    @interfacedoc
    def id():
        return "mean_dc_shift"

    @staticmethod
    @interfacedoc
    def name():
        return "Mean DC shift"

    @staticmethod
    @interfacedoc
    def unit():
        return "%"

    def process(self, frames, eod=False):
        if frames.size:
            self.values = numpy.append(self.values, numpy.mean(frames))
        return frames, eod

    def post_process(self):
        dc_result = self.new_result(data_mode='value', time_mode='global')
        dc_result.data_object.value = numpy.round(
            numpy.mean(100 * self.values), 3)
        self.process_pipe.results.add(dc_result)

########NEW FILE########
__FILENAME__ = h5tools
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2013 Parisson SARL

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author:
#   Thomas Fillon <thomas  at parisson.com>


def dict_to_hdf5(dict_like, h5group):
    """
    Save a dictionnary-like object inside a h5 file group
    """
    # Write attributes
    attrs = dict_like.keys()
    for name in attrs:
        if dict_like[name] is not None:
            h5group.attrs[str(name)] = dict_like[name]


def dict_from_hdf5(dict_like, h5group):
    """
    Load a dictionnary-like object from a h5 file group
    """
    # Read attributes
    for name, value in h5group.attrs.items():
        dict_like[name] = value

########NEW FILE########
__FILENAME__ = irit_speech_4hz
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Maxime Le Coz <lecoz@irit.fr>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Maxime Le Coz <lecoz@irit.fr>

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.analyzer.utils import melFilterBank, computeModulation
from timeside.analyzer.utils import segmentFromValues
from timeside.api import IAnalyzer
from numpy import array, hamming, dot, mean, float
from numpy.fft import rfft
from scipy.signal import firwin, lfilter


class IRITSpeech4Hz(Analyzer):

    '''Speech Segmentor based on the 4Hz energy modulation analysis.

    Properties:
        - energy4hz 		(list) 		: List of the 4Hz energy by frame for the modulation computation
        - threshold 		(float) 	: Threshold for the classification Speech/NonSpeech
        - frequency_center	(float)		: Center of the frequency range where the energy is extracted
        - frequency_width	(float)		: Width of the frequency range where the energy is extracted
        - orderFilter		(int)		: Order of the pass-band filter extracting the frequency range
        - normalizeEnergy	(boolean)	: Whether the energy must be normalized or not
        - nFFT 				(int)		: Number of points for the FFT. Better if 512 <= nFFT <= 2048
        - nbFilters			(int)		: Length of the Mel Filter bank
        - melFilter		(numpy array)	: Mel Filter bank
        - modulLen			(float)		: Length (in second) of the modulation computation window
    '''

    implements(IAnalyzer)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(IRITSpeech4Hz, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.energy4hz = []
        # Classification
        self.threshold = 2.0

        # Pass-band Filter
        self.frequency_center = 4.0
        self.frequency_width = 0.5
        self.orderFilter = 100

        self.normalizeEnergy = True
        self.nFFT = 2048
        self.nbFilters = 30
        self.modulLen = 2.0
        self.melFilter = melFilterBank(self.nbFilters, self.nFFT, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "irit_speech_4hz"

    @staticmethod
    @interfacedoc
    def name():
        return "IRIT Speech 4Hz Modulation"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    def __str__(self):
        return "Speech confidences indexes"

    def process(self, frames, eod=False):
        '''

        '''

        frames = frames.T[0]
        # windowing of the frame (could be a changeable property)
        w = frames * hamming(len(frames))

        # Mel scale spectrum extraction
        f = abs(rfft(w, n=2 * self.nFFT)[0:self.nFFT])
        e = dot(f ** 2, self.melFilter)

        self.energy4hz.append(e)

        return frames, eod

    def post_process(self):
        '''

        '''
        # Creation of the pass-band filter
        Wo = self.frequency_center / self.samplerate()
        Wn = [Wo - (self.frequency_width / 2) / self.samplerate(),
              Wo + (self.frequency_width / 2) / self.samplerate()]
        num = firwin(self.orderFilter, Wn, pass_zero=False)

        # Energy on the frequency range
        self.energy4hz = array(self.energy4hz)
        energy = lfilter(num, 1, self.energy4hz.T, 0)
        energy = sum(energy)

        # Normalization
        if self.normalizeEnergy and energy.any():
            energy = energy / mean(energy)

        # Energy Modulation
        frameLenModulation = int(
            self.modulLen * self.samplerate() / self.blocksize())
        modEnergyValue = computeModulation(energy, frameLenModulation, True)

        # Confidence Index
        conf = array(modEnergyValue - self.threshold) / self.threshold
        conf[conf > 1] = 1

        modEnergy = self.new_result(data_mode='value', time_mode='framewise')
        modEnergy.id_metadata.id += '.' + 'energy_confidence'
        modEnergy.id_metadata.name += ' ' + 'Energy Confidence'

        modEnergy.data_object.value = conf

        self.process_pipe.results.add(modEnergy)

        # Segment
        convert = {False: 0, True: 1}
        label = {0: 'nonSpeech', 1: 'Speech'}

        segList = segmentFromValues(modEnergyValue > self.threshold)
        # Hint : Median filtering could imrove smoothness of the result
        # from scipy.signal import medfilt
        # segList = segmentFromValues(medfilt(modEnergyValue > self.threshold, 31))

        segs = self.new_result(data_mode='label', time_mode='segment')
        segs.id_metadata.id += '.' + 'segments'
        segs.id_metadata.name += ' ' + 'Segments'

        segs.label_metadata.label = label

        segs.data_object.label = [convert[s[2]] for s in segList]
        segs.data_object.time = [(float(s[0]) * self.blocksize() /
                                 self.samplerate())
                                 for s in segList]
        segs.data_object.duration = [(float(s[1] - s[0] + 1) * self.blocksize() /
                                     self.samplerate())
                                     for s in segList]

        self.process_pipe.results.add(segs)

        return

########NEW FILE########
__FILENAME__ = irit_speech_entropy
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Maxime Le Coz <lecoz@irit.fr>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Maxime Le Coz <lecoz@irit.fr>

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.analyzer.utils import entropy, computeModulation
from timeside.analyzer.utils import segmentFromValues
from timeside.api import IAnalyzer
from numpy import array
from scipy.ndimage.morphology import binary_opening


class IRITSpeechEntropy(Analyzer):

    """Speech Segmentor based on Entropy analysis."""

    implements(IAnalyzer)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(IRITSpeechEntropy, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.entropyValue = []
        self.threshold = 0.4
        self.smoothLen = 5
        self.modulLen = 2

    @staticmethod
    @interfacedoc
    def id():
        return "irit_speech_entropy"

    @staticmethod
    @interfacedoc
    def name():
        return "IRIT Speech entropy"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    def __str__(self):
        return "Speech confidences indexes"

    def process(self, frames, eod=False):
        self.entropyValue.append(entropy(frames))
        return frames, eod

    def post_process(self):

        entropyValue = array(self.entropyValue)
        w = self.modulLen * self.samplerate() / self.blocksize()
        modulentropy = computeModulation(entropyValue, w, False)
        confEntropy = array(modulentropy - self.threshold) / self.threshold
        confEntropy[confEntropy > 1] = 1

        conf = self.new_result(data_mode='value', time_mode='framewise')

        conf.id_metadata.id += '.' + 'confidence'
        conf.id_metadata.name += ' ' + 'Confidence'

        conf.data_object.value = confEntropy
        self.process_pipe.results.add(conf)

        # Binary Entropy
        binaryEntropy = modulentropy > self.threshold
        binaryEntropy = binary_opening(
            binaryEntropy, [1] * (self.smoothLen * 2))

        convert = {False: 0, True: 1}
        label = {0: 'NonSpeech', 1: 'Speech'}
        segList = segmentFromValues(binaryEntropy)

        segs = self.new_result(data_mode='label', time_mode='segment')
        segs.id_metadata.id += '.' + 'segments'
        segs.id_metadata.name += ' ' + 'Segments'

        segs.label_metadata.label = label

        segs.data_object.label = [convert[s[2]] for s in segList]
        segs.data_object.time = [(float(s[0]) * self.blocksize() /
                                 self.samplerate())
                                 for s in segList]
        segs.data_object.duration = [(float(s[1] - s[0] + 1) * self.blocksize() /
                                     self.samplerate())
                                     for s in segList]

        self.process_pipe.results.add(segs)

        return

########NEW FILE########
__FILENAME__ = level
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2009 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2009 Olivier Guilyardi <olivier@samalyse.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Guillaume Pellerin <yomguy@parisson.com>

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IValueAnalyzer
import numpy as np
from timeside.analyzer.utils import MACHINE_EPSILON


class Level(Analyzer):

    """RMS level analyzer"""
    implements(IValueAnalyzer)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(Level, self).setup(channels, samplerate, blocksize, totalframes)
        # max_level
        self.max_value = 0
        # rms_level
        self.mean_values = np.array([])

    @staticmethod
    @interfacedoc
    def id():
        return "level"

    @staticmethod
    @interfacedoc
    def name():
        return "Level"

    @staticmethod
    @interfacedoc
    def unit():
        return "dBFS"

    def process(self, frames, eod=False):
        if frames.size:
            # max_level
            max_value = np.abs(frames).max()
            if max_value > self.max_value:
                self.max_value = max_value
            # rms_level
            self.mean_values = np.append(self.mean_values,
                                         np.mean(np.square(frames)))
        return frames, eod

    def post_process(self):
        # Max level
        max_level = self.new_result(data_mode='value', time_mode='global')

        max_level.id_metadata.id += '.' + "max"
        max_level.id_metadata.name += ' ' + "Max"

        if self.max_value == 0:  # Prevent np.log10(0) = Inf
            self.max_value = MACHINE_EPSILON

        max_level.data_object.value = np.round(
            20 * np.log10(self.max_value), 3)
        self.process_pipe.results.add(max_level)

        # RMS level
        rms_level = self.new_result(data_mode='value', time_mode='global')
        rms_level.id_metadata.id += '.' + "rms"
        rms_level.id_metadata.name += ' ' + "RMS"

        rms_val = np.sqrt(np.mean(self.mean_values))

        if rms_val == 0:
            rms_val = MACHINE_EPSILON

        rms_level.data_object.value = np.round(20 * np.log10(rms_val), 3)
        self.process_pipe.results.add(rms_level)

########NEW FILE########
__FILENAME__ = limsi_sad
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 David Doukhan <doukhan@limsi.fr>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: David Doukhan <doukhan@limsi.fr>

from timeside.core import implements, interfacedoc, get_processor
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer
import timeside

import yaafelib
import numpy as np
import pickle
import os.path


class GMM:

    def __init__(self, weights, means, vars):
        self.weights = weights
        self.means = means
        self.vars = vars

    def llh(self, x):
        n_samples, n_dim = x.shape
        llh = -0.5 * (n_dim * np.log(2 * np.pi) + np.sum(np.log(self.vars), 1)
                      + np.sum((self.means ** 2) / self.vars, 1)
                      - 2 * np.dot(x, (self.means / self.vars).T)
                      + np.dot(x ** 2, (1.0 / self.vars).T))
        + np.log(self.weights)
        m = np.amax(llh, 1)
        dif = llh - np.atleast_2d(m).T
        return m + np.log(np.sum(np.exp(dif), 1))


class LimsiSad(Analyzer):

    """
    Limsi Speech Activity Detection Systems
    LimsiSad performs frame level speech activity detection based on GMM models
    For each frame, it computes the log likelihood difference between a speech model and a non speech model.
    The highest is the estimate, the largest is the probability that the frame corresponds to speech.
    The initialization of the analyzer requires to chose a model between 'etape' and 'maya'
    'etape' models were trained on data distributed in the framework of the ETAPE campaign (http://www.afcp-parole.org/etape.html)
    'maya' models were obtained on data collected by EREA  Centre Enseignement et Recherche en Ethnologie Amerindienne
    """
    implements(IAnalyzer)

    def __init__(self, sad_model='etape'):
        """
        Parameters:
        ----------
        sad_model : string bellowing to 'etape' 'maya'
        alllows the selection of a SAD model:
        'etape' is more suited to radionews material
        'maya' is more suited to speech obtained in noisy environments
        """
        super(LimsiSad, self).__init__()

        # feature extraction defition
        spec = yaafelib.FeaturePlan(sample_rate=16000)
        spec.addFeature(
            'mfcc: MFCC CepsIgnoreFirstCoeff=0 blockSize=1024 stepSize=256')
        spec.addFeature(
            'mfccd1: MFCC CepsIgnoreFirstCoeff=0 blockSize=1024 stepSize=256 > Derivate DOrder=1')
        spec.addFeature(
            'mfccd2: MFCC CepsIgnoreFirstCoeff=0 blockSize=1024 stepSize=256 > Derivate DOrder=2')
        spec.addFeature('zcr: ZCR blockSize=1024 stepSize=256')
        parent_analyzer = get_processor('yaafe')(spec)
        self.parents.append(parent_analyzer)

        # informative parameters
        # these are not really taken into account by the system
        # these are bypassed by yaafe feature plan
        self.input_blocksize = 1024
        self.input_stepsize = 256

        # load gmm model
        if sad_model not in ['etape', 'maya']:
            raise ValueError(
                "argument sad_model %s not supported. Supported values are 'etape' or 'maya'" % sad_model)
        picfname = os.path.join(
            timeside.__path__[0], 'analyzer', 'trained_models', 'limsi_sad_%s.pkl' % sad_model)
        self.gmms = pickle.load(open(picfname, 'rb'))

    @staticmethod
    @interfacedoc
    def id():
        return "limsi_sad"

    @staticmethod
    @interfacedoc
    def name():
        return "Limsi speech activity detection system"

    @staticmethod
    @interfacedoc
    def unit():
        # return the unit of the data dB, St, ...
        return "Log Probability difference"

    def process(self, frames, eod=False):
        if self.input_samplerate != 16000:
            raise Exception(
                '%s requires 16000 input sample rate: %d provided' %
                (self.__class__.__name__, self.input_samplerate))
        return frames, eod

    def post_process(self):
        mfcc = self.process_pipe.results['yaafe.mfcc']['data_object']['value']
        mfccd1 = self.process_pipe.results[
            'yaafe.mfccd1']['data_object']['value']
        mfccd2 = self.process_pipe.results[
            'yaafe.mfccd2']['data_object']['value']
        zcr = self.process_pipe.results['yaafe.zcr']['data_object']['value']

        features = np.concatenate((mfcc, mfccd1, mfccd2, zcr), axis=1)

        res = 0.5 + 0.5 * \
            (self.gmms[0].llh(features) - self.gmms[1].llh(features))

        sad_result = self.new_result(data_mode='value', time_mode='framewise')
        sad_result.id_metadata.id += '.' + 'sad_lhh_diff'
        sad_result.id_metadata.name += ' ' + \
            'Speech Activity Detection Log Likelihood Difference'
        sad_result.data_object.value = res
        self.process_pipe.results.add(sad_result)

########NEW FILE########
__FILENAME__ = odf
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Thomas Fillon <thomas@parisson.com>

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from .spectrogram import Spectrogram
from timeside.api import IAnalyzer
import numpy as np
from numpy import pi as Pi
from scipy import signal


class OnsetDetectionFunction(Analyzer):

    """Onset Detection Function analyzer"""
    implements(IAnalyzer)

    def __init__(self, blocksize=1024, stepsize=None):
        super(OnsetDetectionFunction, self).__init__()

        self.input_blocksize = blocksize
        if stepsize:
            self.input_stepsize = stepsize
        else:
            self.input_stepsize = blocksize / 2

        self.parents.append(Spectrogram(blocksize=self.input_blocksize,
                            stepsize=self.input_stepsize))

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(OnsetDetectionFunction, self).setup(channels, samplerate,
                                                  blocksize, totalframes)

    @staticmethod
    @interfacedoc
    def id():
        return "odf"

    @staticmethod
    @interfacedoc
    def name():
        return "Onset Detection Function"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    def process(self, frames, eod=False):
        return frames, eod

    def post_process(self):

        #spectrogram = self.parents()[0]['spectrogram_analyzer'].data
        spectrogram = self.process_pipe.results['spectrogram_analyzer'].data
        #spectrogram = self.pipe._results[self.parents()[0].id]

        # Low-pass filtering of the spectrogram amplitude along the time axis
        S = signal.lfilter(signal.hann(15)[8:], 1, abs(spectrogram), axis=0)

        # Clip small value to a minimal threshold
        np.maximum(S, 1e-9, out=S)

        S = np.log10(S)

#        plt.figure()
#        plt.imshow(S,origin='lower', aspect='auto', interpolation='nearest')
#        plt.show()

        # S[S<1e-3]=0
        np.maximum(S, 1e-3, out=S)

        # Differentiator filter
        df_filter = signal.fir_filter_design.remez(31, [0, 0.5], [Pi],
                                                   type='differentiator')

        S_diff = signal.lfilter(df_filter, 1, S, axis=0)
        S_diff[S_diff < 1e-10] = 0

        # Summation along the frequency axis
        odf_diff = S_diff.sum(axis=1)
        odf_median = np.median(odf_diff)
        if odf_median:
            odf_diff = odf_diff / odf_median  # Normalize

        odf = self.new_result(data_mode='value', time_mode='framewise')
        #odf.parameters = {'FFT_SIZE': self.FFT_SIZE}
        odf.data_object.value = odf_diff
        self.process_pipe.results.add(odf)

########NEW FILE########
__FILENAME__ = preprocessors
# -*- coding: utf-8 -*-
#
# Copyright (c) 2009-2013 Parisson SARL
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.
#
# Author : Thomas fillon <thomas@parisson.com>
'''
    Collections of preprocessors to use as decorators for the analyzers process

    Preprocessors process the (frame, eod) arguments in order to handle various
    preprocessing such as :
        - Downmixing to mono
        - Adapt the frames to match the input_blocksize and input_stepsize
            of the analyzer
'''


def downmix_to_mono(process_func):
    '''
    Pre-processing decorator that downmixes frames from multi-channel to mono

    Downmix is achieved by averaging all channels

    >>> from timeside.analyzer.preprocessors import downmix_to_mono
    >>> @downmix_to_mono
    ... def process(analyzer,frames,eod):
    ...     print 'Frames, eod inside process :'
    ...     print frames, eod
    ...     return frames, eod
    ...
    >>> import numpy as np
    >>> frames = np.asarray([[1,2],[3,4],[5,6],[7,8],[9,10]])
    >>> eod = False
    >>> frames_, eod_ = process(object(),frames,eod)
    Frames, eod inside process :
    [ 1.5  3.5  5.5  7.5  9.5] False

    Outside Process frames and eod are preserved :

    >>> frames_
    array([[ 1,  2],
           [ 3,  4],
           [ 5,  6],
           [ 7,  8],
           [ 9, 10]])
    >>> eod_
    False
    '''

    import functools

    @functools.wraps(process_func)
    def wrapper(analyzer, frames, eod):
        # Pre-processing
        if frames.ndim > 1:
            downmix_frames = frames.mean(axis=-1)
        else:
            downmix_frames = frames
        # Processing
        process_func(analyzer, downmix_frames, eod)

        return frames, eod
    return wrapper


def frames_adapter(process_func):
    '''
    Pre-processing decorator that adapt frames to match input_blocksize and
    input_stepsize of the decorated analyzer

    >>> from timeside.analyzer.preprocessors import frames_adapter
    >>> @frames_adapter
    ... def process(analyzer,frames,eod):
    ...     analyzer.frames.append(frames)
    ...     return frames, eod
    ...
    >>> class Fake_Analyzer(object):
    ...     def __init__(self):
    ...         self.input_blocksize = 4
    ...         self.input_stepsize = 3
    ...         self.frames = [] # Container for the frame as viewed by process
    >>> import numpy as np
    >>> analyzer = Fake_Analyzer()
    >>> frames = np.asarray(range(0,12))
    >>> eod = False
    >>> frames_, eod_ = process(analyzer,frames,eod)

    Inside the process the frames have been adapted to match input_blocksize
    and input_stepsize

    >>> analyzer.frames
    [array([0, 1, 2, 3]), array([3, 4, 5, 6]), array([6, 7, 8, 9])]

    Outside the process, the original frames and eod are preserved:

    >>> frames_
    array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
    >>> eod_
    False

    Releasing the process with eod=True will zeropad the last frame if necessary

    >>> frames = np.asarray(range(12,14))
    >>> eod = True
    >>> frames_, eod_ = process(analyzer,frames,eod)
    >>> analyzer.frames
    [array([0, 1, 2, 3]), array([3, 4, 5, 6]), array([6, 7, 8, 9]), array([ 9, 10, 11, 12]), array([12, 13,  0,  0])]
    '''

    import functools
    import numpy as np

    class framesBuffer(object):

        def __init__(self, blocksize, stepsize):
            self.blocksize = blocksize
            self.stepsize = stepsize
            self.buffer = None

        def frames(self, frames, eod):
            if self.buffer is not None:
                stack = np.concatenate([self.buffer, frames])
            else:
                stack = frames.copy()

            stack_length = len(stack)

            nb_frames = (
                stack_length - self.blocksize + self.stepsize) // self.stepsize
            nb_frames = max(nb_frames, 0)
            frames_length = nb_frames * self.stepsize + \
                self.blocksize - self.stepsize
            last_block_size = stack_length - frames_length

            if eod:
                # Final zeropadding
                pad_shape = tuple(
                    self.blocksize - last_block_size if i == 0 else x
                    for i, x in enumerate(frames.shape))
                stack = np.concatenate([stack, np.zeros(pad_shape,
                                                        dtype=frames.dtype)])
                nb_frames += 1

            self.buffer = stack[nb_frames * self.stepsize:]

            eod_list = np.repeat(False, nb_frames)
            if eod and len(eod_list):
                eod_list[-1] = eod

            for index, eod in zip(xrange(0, nb_frames * self.stepsize, self.stepsize), eod_list):
                yield (stack[index:index + self.blocksize], eod)

    @functools.wraps(process_func)
    def wrapper(analyzer, frames, eod):
        # Pre-processing
        if not hasattr(analyzer, 'frames_buffer'):
            analyzer.frames_buffer = framesBuffer(analyzer.input_blocksize,
                                                  analyzer.input_stepsize)

        # Processing
        for adapted_frames, adapted_eod in analyzer.frames_buffer.frames(frames, eod):
            process_func(analyzer, adapted_frames, adapted_eod)

        return frames, eod
    return wrapper


if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = spectrogram
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer
from timeside.analyzer.preprocessors import downmix_to_mono, frames_adapter
import numpy as np


class Spectrogram(Analyzer):

    """Spectrogram analyzer"""
    implements(IAnalyzer)

    def __init__(self, blocksize=2048, stepsize=None, fft_size=None):
        super(Spectrogram, self).__init__()

        self.input_blocksize = blocksize
        if stepsize:
            self.input_stepsize = stepsize
        else:
            self.input_stepsize = blocksize / 2

        if not fft_size:
            self.FFT_SIZE = blocksize
        else:
            self.FFT_SIZE = fft_size

        self.values = []

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(Spectrogram, self).setup(channels, samplerate,
                                       blocksize, totalframes)

    @staticmethod
    @interfacedoc
    def id():
        return "spectrogram_analyzer"

    @staticmethod
    @interfacedoc
    def name():
        return "Spectrogram Analyzer"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    @downmix_to_mono
    @frames_adapter
    def process(self, frames, eod=False):
            self.values.append(np.abs(np.fft.rfft(frames, self.FFT_SIZE)))
            return frames, eod

    def post_process(self):
        spectrogram = self.new_result(data_mode='value', time_mode='framewise')
        spectrogram.parameters = {'FFT_SIZE': self.FFT_SIZE}
        spectrogram.data_object.value = self.values
        self.process_pipe.results.add(spectrogram)

########NEW FILE########
__FILENAME__ = utils
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>

import numpy as np

MACHINE_EPSILON = np.finfo(np.float32).eps


def downsample_blocking(frames, hop_s, dtype='float32'):
    # downmixing to one channel
    if len(frames.shape) != 1:
        downsampled = frames.sum(axis=-1) / frames.shape[-1]
    else:
        downsampled = frames
    # zero padding to have a multiple of hop_s
    if downsampled.shape[0] % hop_s != 0:
        pad_length = hop_s + \
            downsampled.shape[0] / hop_s * hop_s - downsampled.shape[0]
        downsampled = np.hstack(
            [downsampled, np.zeros(pad_length, dtype=dtype)])
    # blocking
    return downsampled.reshape(downsampled.shape[0] / hop_s, hop_s)


def computeModulation(serie, wLen, withLog=True):
        '''
        Compute the modulation of a parameter centered.
        Extremums are set to zero.

        Args :
            - serie       : list or numpy array containing the serie.
            - wLen        : Length of the analyzis window in samples.
            - withLog     : Whether compute the var() or log(var()) .

        Returns :
            - modul       : Modulation of the serie.

        '''
        sLen = len(serie)
        modul = np.zeros((sLen,))
        w = int(wLen / 2)

        for i in range(w, sLen - w):

            d = serie[i - w:i + w]
            if withLog:
                if not (d > 0).all():
                    d[d <= 0] = MACHINE_EPSILON  # prevent log(0)=inf
                d = np.log(d)

            modul[i] = np.var(d)

        modul[:w] = modul[w]
        modul[-w:] = modul[-w - 1]

        return modul


def segmentFromValues(values, offset=0):
    '''

    '''

    seg = [offset, -1, values[0]]
    segList = []
    for i, v in enumerate(values):

        if not (v == seg[2]):
            seg[1] = i + offset - 1
            segList.append(tuple(seg))
            seg = [i + offset, -1, v]

    seg[1] = i + offset
    segList.append(tuple(seg))

    return segList


# Attention
# ---------
#
# Double emploi avec le calcul mfcc d'aubio. Voir pour la fusion...
#                         Maxime

def melFilterBank(nbFilters, fftLen, sr):
    '''
    Grenerate a Mel Filter-Bank

    Args :
        - nbFilters  : Number of filters.
        - fftLen     : Length of the frequency range.
        - sr         : Sampling rate of the signal to filter.
    Returns :
        - filterbank : fftLen x nbFilters matrix containing one filter by column.
                        The filter bank can be applied by matrix multiplication
                        (Use numpy *dot* function).
    '''

    fh = float(sr) / 2.0
    mh = 2595 * np.log10(1 + fh / 700)

    step = mh / nbFilters

    mcenter = np.arange(step, mh, step)

    fcenter = 700 * (10 ** (mcenter / 2595) - 1)

    filterbank = np.zeros((fftLen, nbFilters))

    for i, _ in enumerate(fcenter):

        if i == 0:
            fmin = 0.0
        else:
            fmin = fcenter[i - 1]

        if i == len(fcenter) - 1:
            fmax = fh
        else:
            fmax = fcenter[i + 1]

        imin = np.ceil(fmin / fh * fftLen)
        imax = np.ceil(fmax / fh * fftLen)

        filterbank[imin:imax, i] = triangle(imax - imin)

    return filterbank


def triangle(length):
    '''
    Generate a triangle filter.

    Args :
         - length  : length of the filter.
    returns :
        - triangle : triangle filter.

    '''
    triangle = np.zeros((1, length))[0]
    climax = np.ceil(length / 2)

    triangle[0:climax] = np.linspace(0, 1, climax)
    triangle[climax:length] = np.linspace(1, 0, length - climax)
    return triangle


def entropy(serie, nbins=10, base=np.exp(1), approach='unbiased'):
        '''
        Compute entropy of a serie using the histogram method.

        Args :
            - serie     : Serie on witch compute the entropy
            - nbins     : Number of bins of the histogram
            - base      : Base used for normalisation
            - approach  : String in the following set : {unbiased,mmse}
                          for un-biasing value.

        Returns :
            - estimate  : Entropy value
            - nbias     : N-bias of the estimate
            - sigma     : Estimated standard error

        Raises :
            A warning in case of unknown 'approach' value.
            No un-biasing is then performed

        '''

        estimate = 0
        sigma = 0
        bins, edges = np.histogram(serie, nbins)
        ncell = len(bins)
        norm = (np.max(edges) - np.min(edges)) / len(bins)

        for b in bins:
            if b == 0:
                logf = 0
            else:
                logf = np.log(b)
            estimate = estimate - b * logf
            sigma = sigma + b * logf ** 2

        count = np.sum(bins)
        estimate = estimate / count
        sigma = np.sqrt((sigma / count - estimate ** 2) / float(count - 1))
        estimate = estimate + np.log(count) + np.log(norm)
        nbias = -(ncell - 1) / (2 * count)

        if approach == 'unbiased':
            estimate = estimate - nbias
            nbias = 0

        elif approach == 'mmse':
            estimate = estimate - nbias
            nbias = 0
            lambda_value = estimate ^ 2 / (estimate ^ 2 + sigma ^ 2)
            nbias = (1 - lambda_value) * estimate
            estimate = lambda_value * estimate
            sigma = lambda_value * sigma
        else:
            return 0

        estimate = estimate / np.log(base)
        nbias = nbias / np.log(base)
        sigma = sigma / np.log(base)
        return estimate

########NEW FILE########
__FILENAME__ = vamp_plugin
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer

import subprocess
import numpy as np


def simple_host_process(argslist):
    """Call vamp-simple-host"""

    vamp_host = 'vamp-simple-host'
    command = [vamp_host]
    command.extend(argslist)
    # try ?
    stdout = subprocess.check_output(
        command, stderr=subprocess.STDOUT).splitlines()

    return stdout


# Raise an exception if Vamp Host is missing
from ..exceptions import VampImportError
try:
    simple_host_process(['-v'])
    WITH_VAMP = True
except OSError:
    WITH_VAMP = False
    raise VampImportError


class VampSimpleHost(Analyzer):

    """Vamp plugins library interface analyzer"""

    implements(IAnalyzer)

    def __init__(self, plugin_list=None):
        super(VampSimpleHost, self).__init__()
        if plugin_list is None:
            plugin_list = self.get_plugins_list()
            #plugin_list = [['vamp-example-plugins', 'percussiononsets', 'detectionfunction']]

        self.plugin_list = plugin_list

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(VampSimpleHost, self).setup(
            channels, samplerate, blocksize, totalframes)

    @staticmethod
    @interfacedoc
    def id():
        return "vamp_simple_host"

    @staticmethod
    @interfacedoc
    def name():
        return "Vamp Plugins host"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

    def process(self, frames, eod=False):
        pass
        return frames, eod

    def post_process(self):
        #plugin = 'vamp-example-plugins:amplitudefollower:amplitude'

        wavfile = self.mediainfo()['uri'].split('file://')[-1]

        for plugin_line in self.plugin_list:

            plugin = ':'.join(plugin_line)
            (time, duration, value) = self.vamp_plugin(plugin, wavfile)
            if value is None:
                return

            if duration is not None:
                plugin_res = self.new_result(
                    data_mode='value', time_mode='segment')
                plugin_res.data_object.duration = duration
            else:
                plugin_res = self.new_result(
                    data_mode='value', time_mode='event')

            plugin_res.data_object.time = time
            plugin_res.data_object.value = value

# Fix strat, duration issues if audio is a segment
#            if self.mediainfo()['is_segment']:
#                start_index = np.floor(self.mediainfo()['start'] *
#                                       self.result_samplerate /
#                                       self.result_stepsize)
#
#                stop_index = np.ceil((self.mediainfo()['start'] +
#                                      self.mediainfo()['duration']) *
#                                     self.result_samplerate /
#                                     self.result_stepsize)
#
#                fixed_start = (start_index * self.result_stepsize /
#                               self.result_samplerate)
#                fixed_duration = ((stop_index - start_index) * self.result_stepsize /
#                                  self.result_samplerate)
#
#                plugin_res.audio_metadata.start = fixed_start
#                plugin_res.audio_metadata.duration = fixed_duration
#
#                value = value[start_index:stop_index + 1]
            plugin_res.id_metadata.id += '.' + '.'.join(plugin_line[1:])
            plugin_res.id_metadata.name += ' ' + \
                ' '.join(plugin_line[1:])

            self.process_pipe.results.add(plugin_res)

    @staticmethod
    def vamp_plugin(plugin, wavfile):

        args = [plugin, wavfile]

        stdout = simple_host_process(args)  # run vamp-simple-host

        stderr = stdout[0:8]  # stderr containing file and process information
        res = stdout[8:]  # stdout containg the feature data

        if len(res) == 0:
            return ([], [], [])

        # Parse stderr to get blocksize and stepsize
        blocksize_info = stderr[4]

        import re
        # Match agianst pattern 'Using block size = %d, step size = %d'
        m = re.match(
            'Using block size = (\d+), step size = (\d+)', blocksize_info)

        blocksize = int(m.groups()[0])
        stepsize = int(m.groups()[1])
        # Get the results

        value = np.asfarray([line.split(': ')[1].split(' ')
                            for line in res if (len(line.split(': ')) > 1)])
        time = np.asfarray([r.split(':')[0].split(',')[0] for r in res])

        time_len = len(res[0].split(':')[0].split(','))
        if time_len == 1:
            # event
            duration = None
        elif time_len == 2:
            # segment
            duration = np.asfarray(
                [r.split(':')[0].split(',')[1] for r in res])

        return (time, duration, value)

    @staticmethod
    def get_plugins_list():
        arg = ['--list-outputs']
        stdout = simple_host_process(arg)

        return [line.split(':')[1:] for line in stdout]

########NEW FILE########
__FILENAME__ = waveform
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Paul Brossier <piem@piem.org>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer
import numpy as np


class Waveform(Analyzer):

    """Waveform analyzer"""
    implements(IAnalyzer)  # TODO check if needed with inheritance

    def __init__(self):
        super(Waveform, self).__init__()
#        self.input_blocksize = 2048
#        self.input_stepsize = self.input_blocksize / 2

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(Waveform, self).setup(channels, samplerate,
                                    blocksize, totalframes)
        self.values = []
        self.result_blocksize = 1
        self.result_stepsize = 1

    @staticmethod
    @interfacedoc
    def id():
        return "waveform_analyzer"

    @staticmethod
    @interfacedoc
    def name():
        return "Waveform Analyzer"

    @staticmethod
    @interfacedoc
    def unit():
        return ""

#    @downmix_to_mono
#    @frames_adapter
    def process(self, frames, eod=False):
        self.values.append(frames)
        return frames, eod

    def post_process(self):
        waveform = self.new_result(data_mode='value', time_mode='framewise')
        waveform.data_object.value = np.vstack(self.values)
        self.process_pipe.results.add(waveform)

########NEW FILE########
__FILENAME__ = yaafe
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013 Thomas Fillon <thomas@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author : Thomas Fillon <thomas@parisson.com>
"""
Module Yaafe Analyzer
"""

from timeside.core import implements, interfacedoc
from timeside.analyzer.core import Analyzer
from timeside.api import IAnalyzer

import yaafelib
import numpy
from timeside.analyzer.preprocessors import downmix_to_mono


class Yaafe(Analyzer):
    """Yaafe feature extraction library interface analyzer"""
    implements(IAnalyzer)

    def __init__(self, yaafeSpecification=None):
        super(Yaafe, self).__init__()

        # Check arguments
        if yaafeSpecification is None:
            yaafeSpecification = yaafelib.FeaturePlan(sample_rate=32000)
            # add feature definitions manually
            yaafeSpecification.addFeature(
                'mfcc: MFCC blockSize=512 stepSize=256')

        if isinstance(yaafeSpecification, yaafelib.DataFlow):
            self.dataFlow = yaafeSpecification
        elif isinstance(yaafeSpecification, yaafelib.FeaturePlan):
            self.featurePlan = yaafeSpecification
            self.dataFlow = self.featurePlan.getDataFlow()
        else:
            raise TypeError("'%s' Type must be either '%s' or '%s'" %
                            (str(yaafeSpecification),
                             str(yaafelib.DataFlow),
                             str(yaafelib.FeaturePlan)))
        self.yaafe_engine = None

    @interfacedoc
    def setup(self, channels=None, samplerate=None,
              blocksize=None, totalframes=None):
        super(Yaafe, self).setup(channels, samplerate, blocksize, totalframes)
        # Configure a YAAFE engine
        self.yaafe_engine = yaafelib.Engine()
        self.yaafe_engine.load(self.dataFlow)
        self.yaafe_engine.reset()
        self.input_samplerate = samplerate
        self.input_blocksize = blocksize

    @staticmethod
    @interfacedoc
    def id():
        return "yaafe"

    @staticmethod
    @interfacedoc
    def name():
        return "Yaafe Descriptor"

    @staticmethod
    @interfacedoc
    def unit():
        return ''

    @downmix_to_mono
    def process(self, frames, eod=False):
        # do process things...
        # Convert to float64and reshape
        # for compatibility with Yaafe engine
        yaafe_frames = frames.astype(numpy.float64).reshape(1, -1)

        # write audio array on 'audio' input
        self.yaafe_engine.writeInput('audio', yaafe_frames)
        # process available data
        self.yaafe_engine.process()
        if eod:
            # flush yaafe engine to process remaining data
            self.yaafe_engine.flush()

        return frames, eod

    def post_process(self):
        # Get feature extraction results from yaafe
        featNames = self.yaafe_engine.getOutputs().keys()
        if len(featNames) == 0:
            raise KeyError('Yaafe engine did not return any feature')
        for featName in featNames:

            result = self.new_result(data_mode='value', time_mode='framewise')
            result.id_metadata.id += '.' + featName
            result.id_metadata.name += ' ' + featName
            # Read Yaafe Results
            result.data_object.value = self.yaafe_engine.readOutput(featName)

            yaafe_metadata = self.yaafe_engine.getOutputs()[featName]
            result.frame_metadata.blocksize = yaafe_metadata['frameLength']
            result.frame_metadata.stepsize = yaafe_metadata['sampleStep']
            result.frame_metadata.samplerate = yaafe_metadata['sampleRate']

            # Store results in Container
            if len(result.data_object.value):
                self.process_pipe.results.add(result)

########NEW FILE########
__FILENAME__ = api
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2013 Parisson SARL
# Copyright (c) 2007 Olivier Guilyardi <olivier@samalyse.com>
# Copyright (c) 2007-2009 Guillaume Pellerin <pellerin@parisson.com>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.
from __future__ import absolute_import


from .component import Interface


class IProcessor(Interface):

    """Common processor interface"""

    @staticmethod
    def id():
        """Short alphanumeric, lower-case string which uniquely identify this
        processor, suitable for use as an HTTP/GET argument value, in filenames,
        etc..."""

        # implementation: only letters and digits are allowed. An exception will
        # be raised by MetaProcessor if the id is malformed or not unique amongst
        # registered processors.

    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        """Allocate internal resources and reset state, so that this processor is
        ready for a new run.

        The channels, samplerate and/or blocksize and/or totalframes arguments
        may be required by processors which accept input. An error will occur if any of
        these arguments is passed to an output-only processor such as a decoder.
        """

        # implementations should always call the parent method

    def channels(self):
        """Number of channels in the data returned by process(). May be different from
        the number of channels passed to setup()"""

    def samplerate(self):
        """Samplerate of the data returned by process(). May be different from
        the samplerate passed to setup()"""

    def blocksize():
        """The total number of frames that this processor can output for each step
        in the pipeline, or None if the number is unknown."""

    def totalframes():
        """The total number of frames that this processor will output, or None if
        the number is unknown."""

    def process(self, frames=None, eod=False):
        """Process input frames and return a (output_frames, eod) tuple.
        Both input and output frames are 2D numpy arrays, where columns are
        channels, and containing an undetermined number of frames.  eod=True
        means that the end-of-data has been reached.

        Output-only processors (such as decoders) will raise an exception if the
        frames argument is not None. All processors (even encoders) return data,
        even if that means returning the input unchanged.

        Warning: it is required to call setup() before this method."""

    def post_process(self):
        '''
        Post-Process data after processign the input frames with process()

        Processors such as analyzers will produce Results during the Post-Process
        '''

    def release(self):
        """Release resources owned by this processor. The processor cannot
        be used anymore after calling this method."""

        # implementations should always call the parent method

    def mediainfo(self):
        """
        Information about the media object
        uri
        start
        duration
        """

    @staticmethod
    def uuid():
        """Return the UUID of the processor"""


class IEncoder(IProcessor):

    """Encoder driver interface. Each encoder is expected to support a specific
    format."""

    def __init__(self, output):
        """Create a new encoder. output can either be a filename or a python callback
        function/method for streaming mode.

        The streaming callback prototype is: callback(data, eod)
        Where data is a block of binary data of an undetermined size, and eod
        True when end-of-data is reached."""

        # implementation: the constructor must always accept the output argument. It may
        # accept extra arguments such as bitrate, depth, etc.., but these must
        # be optionnal

    @staticmethod
    def format():
        """Return the encode/encoding format as a short string
        Example: "MP3", "OGG", "AVI", ...
        """

    @staticmethod
    def description():
        """Return a string describing what this encode format provides, is good
        for, etc... The description is meant to help the end user decide what
        format is good for him/her
        """

    @staticmethod
    def file_extension():
        """Return the filename extension corresponding to this encode format"""

    @staticmethod
    def mime_type():
        """Return the mime type corresponding to this encode format"""

    def set_metadata(self, metadata):
        """Set the metadata to be embedded in the encoded output.

        In non-streaming mode, this method updates the metadata directly into the
        output file, without re-encoding the audio data, provided this file already
        exists.

        It isn't required to call this method, but if called, it must be before
        process()."""


class IDecoder(IProcessor):

    """Decoder driver interface. Decoders are different of encoders in that
    a given driver may support several input formats, hence this interface doesn't
    export any static method, all informations are dynamic."""

    def __init__(self, filename):
        """Create a new decoder for filename."""
        # implementation: additional optionnal arguments are allowed

    def format():
        """Return a user-friendly file format string"""

    def encoding():
        """Return a user-friendly encoding string"""

    def resolution():
        """Return the sample width (8, 16, etc..) of original audio file/stream,
           or None if not applicable/known"""

    def metadata(self):
        """Return the metadata embedded into the encoded stream, if any."""

    def mime_type():
        """Return the mime type corresponding to this decoded format"""


class IGrapher(IProcessor):

    """Media item visualizer driver interface"""

    # implementation: graphers which need to know the total number of frames
    # should raise an exception in setup() if the totalframes argument is None

    def __init__(self, width, height):
        """Create a new grapher. width and height are generally
        in pixels but could be something else for eg. svg rendering, etc.. """

        # implementation: additional optionnal arguments are allowed

    @staticmethod
    def name():
        """Return the graph name, such as "Waveform", "Spectral view",
        etc..  """

    def set_colors(self, background=None, scheme=None):
        """Set the colors used for image generation. background is a RGB tuple,
        and scheme a a predefined color theme name"""

    def render(self, output=None):
        """Return a PIL Image object visually representing all of the data passed
        by repeatedly calling process() and write the image to the output if specified"""


class IAnalyzer(IProcessor):

    """Media item analyzer driver interface. This interface is abstract, it doesn't
    describe a particular type of analyzer but is rather meant to group analyzers.
    In particular, the way the result is returned may greatly vary from sub-interface
    to sub-interface. For example the IValueAnalyzer returns a final single numeric
    result at the end of the whole analysis. But some other analyzers may return
    numpy arrays, and this, either at the end of the analysis, or from process()
    for each block of data (as in Vamp)."""

    def __init__(self):
        """Create a new analyzer."""
        # implementation: additional optionnal arguments are allowed

    @staticmethod
    def name():
        """Return the analyzer name, such as "Mean Level", "Max level",
        "Total length, etc..  """

    @staticmethod
    def unit():
        """Return the unit of the data such as "dB", "seconds", etc...  """


class IValueAnalyzer(IAnalyzer):

    """Interface for analyzers which return a single numeric value from result()"""

    def result():
        """Return the final result of the analysis performed over the data passed by
        repeatedly calling process()"""

    def results():
        """Return the final results of the analysis performed over the data passed by
        repeatedly calling process()"""

    def __str__(self):
        """Return a human readable string containing both result and unit
        ('5.30dB', '4.2s', etc...)"""


class IEffect(IProcessor):

    """Effect processor interface"""

    def __init__(self):
        """Create a new effect."""
        # implementation: additional optionnal arguments are allowed

    @staticmethod
    def name():
        """Return the effect name"""

########NEW FILE########
__FILENAME__ = component
# -*- coding: utf-8 -*-
#
# Copyright (c) 2009 Olivier Guilyardi <olivier@samalyse.com>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


# This file defines a generic object interface mechanism and
# a way to determine which components implements a given interface.
#
# For example, the following defines the Music class as implementing the
# listenable interface.
#
# class Listenable(Interface):
#     pass
#
# class Music(Component):
#    implements(Listenable)
#
# Several class can implements a such interface, and it is possible to
# discover which class implements it with implementations():
#
# list_of_classes = implementations(Listenable)
#
# This mechanism support inheritance of interfaces: a class implementing a given
# interface is also considered to implement all the ascendants of this interface.
#
# However, inheritance is not supported for components. The descendants of a class
# implementing a given interface are not automatically considered to implement this
# interface too.

__all__ = ['Component', 'MetaComponent', 'implements', 'abstract',
           'interfacedoc', 'Interface', 'implementations', 'ComponentError']


class Interface(object):

    """Marker base class for interfaces."""


def implements(*interfaces):
    """Registers the interfaces implemented by a component when placed in the
    class header"""
    MetaComponent.implements.extend(interfaces)


def abstract():
    """Declare a component as abstract when placed in the class header"""
    MetaComponent.abstract = True


def implementations(interface, recurse=True, abstract=False):
    """Returns the components implementing interface, and if recurse, any of
    the descendants of interface. If abstract is True, also return the
    abstract implementations."""
    result = []
    find_implementations(interface, recurse, abstract, result)
    return result


def interfacedoc(func):
    if isinstance(func, staticmethod):
        raise ComponentError(
            "@interfacedoc can't handle staticmethod (try to put @staticmethod above @interfacedoc)")

    if not func.__doc__:
        func.__doc__ = "@interfacedoc"
        func._interfacedoc = True
    return func


class MetaComponent(type):

    """Metaclass of the Component class, used mainly to register the interface
    declared to be implemented by a component."""

    implementations = []
    implements = []
    abstract = False

    def __new__(cls, name, bases, d):
        new_class = type.__new__(cls, name, bases, d)

        # Register implementations
        if MetaComponent.implements:
            for i in MetaComponent.implements:
                MetaComponent.implementations.append({
                    'interface': i,
                    'class': new_class,
                    'abstract': MetaComponent.abstract})

        # Propagate @interfacedoc
        for name in new_class.__dict__:
            member = new_class.__dict__[name]
            if isinstance(member, staticmethod):
                member = getattr(new_class, name)

            if member.__doc__ == "@interfacedoc":
                if_member = None
                for i in MetaComponent.implements:
                    if hasattr(i, name):
                        if_member = getattr(i, name)
                if not if_member:
                    raise ComponentError("@interfacedoc: %s.%s: no such member in implemented interfaces: %s"
                                         % (new_class.__name__, name, str(MetaComponent.implements)))
                member.__doc__ = if_member.__doc__

        MetaComponent.implements = []
        MetaComponent.abstract = False

        return new_class


class Component(object):

    """Base class of all components"""
    __metaclass__ = MetaComponent


def extend_unique(list1, list2):
    """Extend list1 with list2 as list.extend(), but doesn't append duplicates
    to list1"""
    for item in list2:
        if item not in list1:
            list1.append(item)


def find_implementations(interface, recurse, abstract, result):
    """Find implementations of an interface or of one of its descendants and
    extend result with the classes found."""
    for item in MetaComponent.implementations:
        if (item['interface'] == interface and (abstract or not item['abstract'])):
            extend_unique(result, [item['class']])

    if recurse:
        subinterfaces = interface.__subclasses__()
        if subinterfaces:
            for i in subinterfaces:
                find_implementations(i, recurse, abstract, result)


class ComponentError(Exception):
    pass

########NEW FILE########
__FILENAME__ = core
# -*- coding: utf-8 -*-
#
# Copyright (c) 2009-2013 Parisson SARL
# Copyright (c) 2009 Olivier Guilyardi <olivier@samalyse.com>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

from .component import Component, MetaComponent, abstract
from .component import implements, implementations, interfacedoc
from .api import IProcessor
from .exceptions import Error, PIDError, ApiError

import re
import numpy
import uuid

import gobject
gobject.threads_init()

__all__ = ['Processor', 'MetaProcessor', 'implements', 'abstract',
           'interfacedoc', 'processors', 'get_processor', 'ProcessPipe',
           'FixedSizeInputAdapter']

_processors = {}


class MetaProcessor(MetaComponent):
    """Metaclass of the Processor class, used mainly for ensuring
    that processor id's are wellformed and unique"""

    valid_id = re.compile("^[a-z][_a-z0-9]*$")

    def __new__(cls, name, bases, d):
        new_class = MetaComponent.__new__(cls, name, bases, d)
        if new_class in implementations(IProcessor):
            id = str(new_class.id())
            if id in _processors:
                # Doctest test can duplicate a processor
                # This can be identify by the conditon "module == '__main__'"
                if new_class.__module__ == '__main__':
                    new_class = _processors[id]
                elif _processors[id].__module__ == '__main__':
                    pass
                else:
                    raise ApiError("%s and %s have the same id: '%s'"
                                   % (new_class.__name__,
                                      _processors[id].__name__, id))
            if not MetaProcessor.valid_id.match(id):
                raise ApiError("%s has a malformed id: '%s'"
                               % (new_class.__name__, id))

            _processors[id] = new_class

        return new_class


class Processor(Component):

    """Base component class of all processors


    Attributes:
              parents :  List of parent Processors that must be processed
                         before the current Processor
              pipe :     The ProcessPipe in which the Processor will run
        """
    __metaclass__ = MetaProcessor

    abstract()
    implements(IProcessor)

    def __init__(self):
        super(Processor, self).__init__()

        self.parents = []
        self.source_mediainfo = None
        self.process_pipe = None
        self.UUID = uuid.uuid4()

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        self.source_channels = channels
        self.source_samplerate = samplerate
        self.source_blocksize = blocksize
        self.source_totalframes = totalframes

        # If empty Set default values for input_* attributes
        # may be setted by the processor during __init__()
        if not hasattr(self, 'input_channels'):
            self.input_channels = self.source_channels
        if not hasattr(self, 'input_samplerate'):
            self.input_samplerate = self.source_samplerate
        if not hasattr(self, 'input_blocksize'):
            self.input_blocksize = self.source_blocksize
        if not hasattr(self, 'input_stepsize'):
            self.input_stepsize = self.source_blocksize

    # default channels(), samplerate() and blocksize() implementations returns
    # the source characteristics, but processors may change this behaviour by
    # overloading those methods
    @interfacedoc
    def channels(self):
        return self.source_channels

    @interfacedoc
    def samplerate(self):
        return self.source_samplerate

    @interfacedoc
    def blocksize(self):
        return self.source_blocksize

    @interfacedoc
    def totalframes(self):
        return self.source_totalframes

    @interfacedoc
    def process(self, frames, eod):
        return frames, eod

    @interfacedoc
    def post_process(self):
        pass

    @interfacedoc
    def release(self):
        pass

    @interfacedoc
    def mediainfo(self):
        return self.source_mediainfo

    @interfacedoc
    def uuid(self):
        return str(self.UUID)

    def __del__(self):
        self.release()

    def __or__(self, other):
        return ProcessPipe(self, other)


class FixedSizeInputAdapter(object):

    """Utility to make it easier to write processors which require fixed-sized
    input buffers."""

    def __init__(self, buffer_size, channels, pad=False):
        """Construct a new adapter: buffer_size is the desired buffer size in frames,
        channels the number of channels, and pad indicates whether the last block should
        be padded with zeros."""

        self.buffer = numpy.empty((buffer_size, channels))
        self.buffer_size = buffer_size
        self.len = 0
        self.pad = pad

    def blocksize(self, input_totalframes):
        """Return the total number of frames that this adapter will output according to the
        input_totalframes argument"""

        blocksize = input_totalframes
        if self.pad:
            mod = input_totalframes % self.buffer_size
            if mod:
                blocksize += self.buffer_size - mod

        return blocksize

    def process(self, frames, eod):
        """Returns an iterator over tuples of the form (buffer, eod) where buffer is a
        fixed-sized block of data, and eod indicates whether this is the last block.
        In case padding is deactivated the last block may be smaller than the buffer size.
        """
        src_index = 0
        remaining = len(frames)

        while remaining:
            space = self.buffer_size - self.len
            copylen = remaining < space and remaining or space
            src = frames[src_index:src_index + copylen]
            if self.len == 0 and copylen == self.buffer_size:
                # avoid unnecessary copy
                buffer = src
            else:
                buffer = self.buffer
                buffer[self.len:self.len + copylen] = src

            remaining -= copylen
            src_index += copylen
            self.len += copylen

            if self.len == self.buffer_size:
                yield buffer, (eod and not remaining)
                self.len = 0

        if eod and self.len:
            block = self.buffer
            if self.pad:
                self.buffer[self.len:self.buffer_size] = 0
            else:
                block = self.buffer[0:self.len]

            yield block, True
            self.len = 0


def processors(interface=IProcessor, recurse=True):
    """Returns the processors implementing a given interface and, if recurse,
    any of the descendants of this interface."""
    return implementations(interface, recurse)


def get_processor(processor_id):
    """Return a processor by its id"""
    if not processor_id in _processors:
        raise PIDError("No processor registered with id: '%s'"
                    % processor_id)

    return _processors[processor_id]


def list_processors(interface=IProcessor, prefix=""):
    print prefix + interface.__name__
    subinterfaces = interface.__subclasses__()
    for i in subinterfaces:
        list_processors(interface=i, prefix=prefix + "  ")
    procs = processors(interface, False)
    for p in procs:
        print prefix + "  %s [%s]" % (p.__name__, p.id())


class ProcessPipe(object):

    """Handle a pipe of processors

    Attributes:
        processor: List of all processors in the Process pipe
        results : Results Container for all the analyzers of the Pipe process
"""

    def __init__(self, *others):
        self.processors = []
        self._streamer = None
        self._stream_thread = False
        self._is_running = False

        self |= others

        from timeside.analyzer.core import AnalyzerResultContainer
        self.results = AnalyzerResultContainer()

    def __or__(self, other):
        self |= other
        return self

    def __ior__(self, other):
        if isinstance(other, Processor):
            for parent in other.parents:
                self |= parent
            self.processors.append(other)
            other.process_pipe = self
        elif isinstance(other, ProcessPipe):
            self.processors.extend(other.processors)
        else:
            try:
                iter(other)
            except TypeError:
                raise Error(
                    "Can not add this type of object to a pipe: %s", str(other))

            for item in other:
                self |= item

        return self

    def __repr__(self):
        pipe = ''
        for item in self.processors:
            pipe += item.id()
            if item != self.processors[-1]:
                pipe += ' | '
        return pipe

    def run(self, channels=None, samplerate=None, blocksize=None):
        """Setup/reset all processors in cascade"""

        source = self.processors[0]
        items = self.processors[1:]
        source.setup(channels=channels, samplerate=samplerate,
                     blocksize=blocksize)
        source.SIG_STOP = False
        last = source

        # setup/reset processors and configure properties throughout the pipe
        for item in items:
            item.source_mediainfo = source.mediainfo()
            item.setup(channels=last.channels(),
                       samplerate=last.samplerate(),
                       blocksize=last.blocksize(),
                       totalframes=last.totalframes())
            self._register_streamer(item)
            last = item

        # now stream audio data along the pipe
        if self._stream_thread:
            self._running_cond.acquire()
        self._is_running = True
        if self._stream_thread:
            self._running_cond.notify()
            self._running_cond.release()

        eod = False

        if source.id() == 'gst_live_dec':
            # Set handler for Interruption signal
            import signal

            def signal_handler(signum, frame):
                source.stop()

            signal.signal(signal.SIGINT, signal_handler)

        while not eod:
            frames, eod = source.process()
            for item in items:
                frames, eod = item.process(frames, eod)

        if source.id() == 'gst_live_dec':
            # Restore default handler for Interruption signal
            signal.signal(signal.SIGINT, signal.SIG_DFL)

        # Post-processing
        for item in items:
            item.post_process()

        # Release source
        source.release()
        # Release processors
        for item in items:
            item.release()
            self.processors.remove(item)

        self._is_running = False

    def stream(self):
        self._stream_thread = True

        import threading

        class PipeThread(threading.Thread):

            def __init__(self, process_pipe):
                super(PipeThread, self).__init__(name='pipe_thread')
                self.process_pipe = process_pipe

            def run(self):
                self.process_pipe.run()

        pipe_thread = PipeThread(self)
        pipe_thread.start()

        # wait for pipe thread to be ready to stream
        self._running_cond = threading.Condition(threading.Lock())
        self._running_cond.acquire()
        while not self._is_running:
            self._running_cond.wait()
        self._running_cond.release()

        if self._streamer is None:
            raise TypeError('Function only available in streaming mode')

        while pipe_thread.is_alive():
            # yield count
            chunk = self._streamer.get_stream_chunk()
            if chunk is not None:
                yield chunk
            else:
                break

    def _register_streamer(self, processor):
        if hasattr(processor, 'streaming') and processor.streaming:
            if self._streamer is None:
                self._streamer = processor
            else:
                raise TypeError('More than one streaming processor in pipe')

########NEW FILE########
__FILENAME__ = array
#!/usr/bin/python
# -*- coding: utf-8 -*-

# Copyright (c) 2007-2013 Parisson
# Copyright (c) 2007 Olivier Guilyardi <olivier@samalyse.com>
# Copyright (c) 2007-2013 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (c) 2010-2013 Paul Brossier <piem@piem.org>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors:
# Paul Brossier <piem@piem.org>
# Guillaume Pellerin <yomguy@parisson.com>
# Thomas Fillon <thomas@parisson.com>

from timeside.core import implements, interfacedoc
from timeside.decoder.core import Decoder, IDecoder
import numpy as np


class ArrayDecoder(Decoder):

    """ Decoder taking Numpy array as input"""
    implements(IDecoder)

    output_blocksize = 8 * 1024

    # IProcessor methods

    @staticmethod
    @interfacedoc
    def id():
        return "array_dec"

    def __init__(self, samples, samplerate=44100, start=0, duration=None):
        '''
            Construct a new ArrayDecoder from an numpy array

            Parameters
            ----------
            samples : numpy array of dimension 1 (mono) or 2 (multichannel)
                    if shape = (n) or (n,1) : n samples, mono
                    if shape = (n,m) : n samples with m channels
            start : float
                start time of the segment in seconds
            duration : float
                duration of the segment in seconds
        '''
        super(ArrayDecoder, self).__init__(start=start, duration=duration)

        # Check array dimension
        if samples.ndim > 2:
            raise TypeError('Wrong number of dimensions for argument samples')
        if samples.ndim == 1:
            samples = samples[:, np.newaxis]  # reshape to 2D array

        self.samples = samples.astype('float32')  # Create a 2 dimensions array
        self.input_samplerate = samplerate
        self.input_channels = self.samples.shape[1]

        self.uri = '_'.join(['raw_audio_array',
                            'x'.join([str(dim) for dim in samples.shape]),
                             samples.dtype.type.__name__])
        from .utils import sha1sum_numpy
        self._sha1 = sha1sum_numpy(self.samples)
        self.frames = self.get_frames()

    def setup(self, channels=None, samplerate=None, blocksize=None):

        # the output data format we want
        if blocksize:
            self.output_blocksize = blocksize
        if samplerate:
            self.output_samplerate = int(samplerate)
        if channels:
            self.output_channels = int(channels)

        if self.uri_duration is None:
            self.uri_duration = (len(self.samples) / self.input_samplerate
                                 - self.uri_start)

        if self.is_segment:
            start_index = self.uri_start * self.input_samplerate
            stop_index = start_index + int(np.ceil(self.uri_duration
                                           * self.input_samplerate))
            stop_index = min(stop_index, len(self.samples))
            self.samples = self.samples[start_index:stop_index]

        if not self.output_samplerate:
            self.output_samplerate = self.input_samplerate

        if not self.output_channels:
            self.output_channels = self.input_channels

        self.input_totalframes = len(self.samples)
        self.input_duration = self.input_totalframes / self.input_samplerate
        self.input_width = self.samples.itemsize * 8

    def get_frames(self):
        "Define an iterator that will return frames at the given blocksize"
        nb_frames = self.input_totalframes // self.output_blocksize

        if self.input_totalframes % self.output_blocksize == 0:
            nb_frames -= 1  # Last frame must send eod=True

        for index in xrange(0,
                            nb_frames * self.output_blocksize,
                            self.output_blocksize):
            yield (self.samples[index:index + self.output_blocksize], False)

        yield (self.samples[nb_frames * self.output_blocksize:], True)

    @interfacedoc
    def process(self):
        return self.frames.next()

    # IDecoder methods
    @interfacedoc
    def format(self):
        import re
        base_type = re.search('^[a-z]*', self.samples.dtype.name).group(0)
        return 'audio/x-raw-' + base_type

    @interfacedoc
    def metadata(self):
        return None

    @interfacedoc
    def release(self):
        self.frames = self.get_frames()

if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = core
#!/usr/bin/python
# -*- coding: utf-8 -*-

# Copyright (c) 2007-2013 Parisson
# Copyright (c) 2007 Olivier Guilyardi <olivier@samalyse.com>
# Copyright (c) 2007-2013 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (c) 2010-2013 Paul Brossier <piem@piem.org>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors:
# Paul Brossier <piem@piem.org>
# Guillaume Pellerin <yomguy@parisson.com>
# Thomas Fillon <thomas@parisson.com>

from __future__ import division

from timeside.core import Processor, implements, interfacedoc, abstract
from timeside.api import IDecoder


class Decoder(Processor):

    """General abstract base class for Decoder
    """
    implements(IDecoder)
    abstract()

    type = 'decoder'

    mimetype = ''
    output_samplerate = None
    output_channels = None

    def __init__(self, start=0, duration=None):
        super(Decoder, self).__init__()

        self.uri_start = float(start)
        if duration:
            self.uri_duration = float(duration)
        else:
            self.uri_duration = duration

        if start == 0 and duration is None:
            self.is_segment = False
        else:
            self.is_segment = True

    @interfacedoc
    def channels(self):
        return self.output_channels

    @interfacedoc
    def samplerate(self):
        return self.output_samplerate

    @interfacedoc
    def blocksize(self):
        return self.output_blocksize

    @interfacedoc
    def totalframes(self):
        return self.input_totalframes

    @interfacedoc
    def release(self):
        pass

    @interfacedoc
    def mediainfo(self):
        return dict(uri=self.uri,
                    duration=self.uri_duration,
                    start=self.uri_start,
                    is_segment=self.is_segment,
                    samplerate=self.input_samplerate,
                    sha1=self.sha1)

    @property
    def sha1(self):
        return self._sha1

    def __del__(self):
        self.release()

    @interfacedoc
    def encoding(self):
        return self.format().split('/')[-1]

    @interfacedoc
    def resolution(self):
        return self.input_width

########NEW FILE########
__FILENAME__ = file
#!/usr/bin/python
# -*- coding: utf-8 -*-

# Copyright (c) 2007-2013 Parisson
# Copyright (c) 2007 Olivier Guilyardi <olivier@samalyse.com>
# Copyright (c) 2007-2013 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (c) 2010-2013 Paul Brossier <piem@piem.org>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors:
# Paul Brossier <piem@piem.org>
# Guillaume Pellerin <yomguy@parisson.com>
# Thomas Fillon <thomas@parisson.com>

from __future__ import division

from timeside.decoder.core import Decoder, IDecoder, implements, interfacedoc
from timeside.tools.gstutils import MainloopThread, gobject
from timeside.tools.gstutils import gst_buffer_to_numpy_array
import threading

from timeside.decoder.utils import get_uri, get_media_uri_info, stack, get_sha1

import Queue
from gst import _gst as gst

GST_APPSINK_MAX_BUFFERS = 10
QUEUE_SIZE = 10

import numpy as np


class FileDecoder(Decoder):

    """ gstreamer-based decoder """
    implements(IDecoder)

    output_blocksize = 8 * 1024

    pipeline = None
    mainloopthread = None

    # IProcessor methods

    @staticmethod
    @interfacedoc
    def id():
        return "gst_dec"

    def __init__(self, uri, start=0, duration=None, stack=False, sha1=None):
        """
        Construct a new FileDecoder

        Parameters
        ----------
        uri : str
            uri of the media
        start : float
            start time of the segment in seconds
        duration : float
            duration of the segment in seconds
        stack : boolean
            keep decoded data in the stack
        sha1 : boolean
            compute the sha1 hash of the data

        """

        super(FileDecoder, self).__init__(start=start, duration=duration)

        self.from_stack = False
        self.stack = stack

        self.uri = get_uri(uri).encode('utf8')

        if not sha1:
            self._sha1 = get_sha1(uri)
        else:
            self._sha1 = sha1.encode('utf8')

        self.uri_total_duration = get_media_uri_info(self.uri)['duration']

        self.mimetype = None

    def setup(self, channels=None, samplerate=None, blocksize=None):

        self.eod = False
        self.last_buffer = None

        if self.from_stack:
            self._frames_iterator = iter(self.process_pipe.frames_stack)
            return

        if self.stack:
            self.process_pipe.frames_stack = []

        if self.uri_duration is None:
            # Set the duration from the length of the file
            self.uri_duration = self.uri_total_duration - self.uri_start

        if self.is_segment:
            # Check start and duration value
            if self.uri_start > self.uri_total_duration:
                raise ValueError(('Segment start time value exceed media ' +
                                  'duration'))

            if self.uri_start + self.uri_duration > self.uri_total_duration:
                    raise ValueError("""Segment duration value is too large \
                                        given the media duration""")

        # a lock to wait wait for gstreamer thread to be ready
        self.discovered_cond = threading.Condition(threading.Lock())
        self.discovered = False

        # the output data format we want
        if blocksize:
            self.output_blocksize = blocksize
        if samplerate:
            self.output_samplerate = int(samplerate)
        if channels:
            self.output_channels = int(channels)

        if self.is_segment:
            # Create the pipe with Gnonlin gnlurisource
            self.pipe = ''' gnlurisource name=src uri={uri}
                            start=0
                            duration={uri_duration}
                            media-start={uri_start}
                            media-duration={uri_duration}
                            ! audioconvert name=audioconvert
                            ! audioresample
                            ! appsink name=sink sync=False async=True
                            '''.format(uri=self.uri,
                                       uri_start=np.uint64(
                                           round(self.uri_start * gst.SECOND)),
                                       uri_duration=np.int64(round(self.uri_duration * gst.SECOND)))
                                       # convert uri_start and uri_duration to
                                       # nanoseconds
        else:
            # Create the pipe with standard Gstreamer uridecodebin
            self.pipe = ''' uridecodebin name=src uri={uri}
                           ! audioconvert name=audioconvert
                           ! audioresample
                           ! appsink name=sink sync=False async=True
                           '''.format(uri=self.uri)

        self.pipeline = gst.parse_launch(self.pipe)

        if self.output_channels:
            caps_channels = int(self.output_channels)
        else:
            caps_channels = "[ 1, 2 ]"
        if self.output_samplerate:
            caps_samplerate = int(self.output_samplerate)
        else:
            caps_samplerate = "{ 8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000, 96000 }"
        sink_caps = gst.Caps("""audio/x-raw-float,
            endianness=(int)1234,
            channels=(int)%s,
            width=(int)32,
            rate=(int)%s""" % (caps_channels, caps_samplerate))

        self.src = self.pipeline.get_by_name('src')
        if not self.is_segment:
            self.src.connect("autoplug-continue", self._autoplug_cb)
        else:
            uridecodebin = self.src.get_by_name('internal-uridecodebin')
            uridecodebin.connect("autoplug-continue", self._autoplug_cb)

        self.conv = self.pipeline.get_by_name('audioconvert')
        self.conv.get_pad("sink").connect("notify::caps", self._notify_caps_cb)

        self.sink = self.pipeline.get_by_name('sink')
        self.sink.set_property("caps", sink_caps)
        self.sink.set_property('max-buffers', GST_APPSINK_MAX_BUFFERS)
        self.sink.set_property("drop", False)
        self.sink.set_property('emit-signals', True)
        self.sink.connect("new-buffer", self._on_new_buffer_cb)

        self.bus = self.pipeline.get_bus()
        self.bus.add_signal_watch()
        self.bus.connect('message', self._on_message_cb)

        self.queue = Queue.Queue(QUEUE_SIZE)

        self.mainloop = gobject.MainLoop()
        self.mainloopthread = MainloopThread(self.mainloop)
        self.mainloopthread.start()
        #self.mainloopthread = get_loop_thread()
        ##self.mainloop = self.mainloopthread.mainloop

        # start pipeline
        self.pipeline.set_state(gst.STATE_PLAYING)

        self.discovered_cond.acquire()
        while not self.discovered:
            # print 'waiting'
            self.discovered_cond.wait()
        self.discovered_cond.release()

        if not hasattr(self, 'input_samplerate'):
            if hasattr(self, 'error_msg'):
                raise IOError(self.error_msg)
            else:
                raise IOError('no known audio stream found')

    def _autoplug_cb(self, src, arg0, arg1):
        # use the autoplug-continue callback from uridecodebin
        # to get the mimetype string
        if not self.mimetype:
            self.mimetype = arg1.to_string().split(',')[0]
        return True

    def _notify_caps_cb(self, pad, args):
        self.discovered_cond.acquire()

        caps = pad.get_negotiated_caps()
        if not caps:
            pad.info("no negotiated caps available")
            self.discovered = True
            self.discovered_cond.notify()
            self.discovered_cond.release()
            return
        # the caps are fixed
        # We now get the total length of that stream
        q = gst.query_new_duration(gst.FORMAT_TIME)
        pad.info("sending duration query")
        if pad.get_peer().query(q):
            format, length = q.parse_duration()
            if format == gst.FORMAT_TIME:
                pad.info("got duration (time) : %s" % (gst.TIME_ARGS(length),))
            else:
                pad.info("got duration : %d [format:%d]" % (length, format))
        else:
            length = -1
            gst.warning("duration query failed")

        # We store the caps and length in the proper location
        if "audio" in caps.to_string():
            self.input_samplerate = caps[0]["rate"]
            if not self.output_samplerate:
                self.output_samplerate = self.input_samplerate
            self.input_channels = caps[0]["channels"]
            if not self.output_channels:
                self.output_channels = self.input_channels
            self.input_duration = length / 1.e9

            self.input_totalframes = int(
                self.input_duration * self.input_samplerate)
            if "x-raw-float" in caps.to_string():
                self.input_width = caps[0]["width"]
            else:
                self.input_width = caps[0]["depth"]

        self.discovered = True
        self.discovered_cond.notify()
        self.discovered_cond.release()

    def _on_message_cb(self, bus, message):
        t = message.type
        if t == gst.MESSAGE_EOS:
            self.queue.put(gst.MESSAGE_EOS)
            self.pipeline.set_state(gst.STATE_NULL)
            self.mainloop.quit()
        elif t == gst.MESSAGE_ERROR:
            self.pipeline.set_state(gst.STATE_NULL)
            err, debug = message.parse_error()
            self.discovered_cond.acquire()
            self.discovered = True
            self.mainloop.quit()
            self.error_msg = "Error: %s" % err, debug
            self.discovered_cond.notify()
            self.discovered_cond.release()
        elif t == gst.MESSAGE_TAG:
            # TODO
            # msg.parse_tags()
            pass

    def _on_new_buffer_cb(self, sink):
        buf = sink.emit('pull-buffer')
        new_array = gst_buffer_to_numpy_array(buf, self.output_channels)
        # print 'processing new buffer', new_array.shape
        if self.last_buffer is None:
            self.last_buffer = new_array
        else:
            self.last_buffer = np.concatenate(
                (self.last_buffer, new_array), axis=0)
        while self.last_buffer.shape[0] >= self.output_blocksize:
            new_block = self.last_buffer[:self.output_blocksize]
            self.last_buffer = self.last_buffer[self.output_blocksize:]
            # print 'queueing', new_block.shape, 'remaining',
            # self.last_buffer.shape
            self.queue.put([new_block, False])

    @interfacedoc
    @stack
    def process(self):
        buf = self.queue.get()
        if buf == gst.MESSAGE_EOS:
            return self.last_buffer, True
        frames, eod = buf
        return frames, eod

    @interfacedoc
    def totalframes(self):
        if self.input_samplerate == self.output_samplerate:
            return self.input_totalframes
        else:
            ratio = self.output_samplerate / self.input_samplerate
            return int(self.input_totalframes * ratio)

    @interfacedoc
    def release(self):
        if self.stack:
            self.stack = False
            self.from_stack = True

    # IDecoder methods

    @interfacedoc
    def format(self):
        return self.mime_type()

    @interfacedoc
    def mime_type(self):
        if self.mimetype == 'application/x-id3':
            self.mimetype = 'audio/mpeg'
        return self.mimetype

    @interfacedoc
    def encoding(self):
        # TODO check
        return self.mime_type().split('/')[-1]

    @interfacedoc
    def resolution(self):
        # TODO check: width or depth?
        return self.input_width

    @interfacedoc
    def metadata(self):
        # TODO check
        return self.tags

    def stop(self):
        self.src.send_event(gst.event_new_eos())

if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = live
#!/usr/bin/python
# -*- coding: utf-8 -*-

# Copyright (c) 2007-2013 Parisson
# Copyright (c) 2007 Olivier Guilyardi <olivier@samalyse.com>
# Copyright (c) 2007-2013 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (c) 2010-2013 Paul Brossier <piem@piem.org>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors:
# Paul Brossier <piem@piem.org>
# Guillaume Pellerin <yomguy@parisson.com>
# Thomas Fillon <thomas@parisson.com>

from __future__ import division

from timeside.decoder.core import Decoder, IDecoder, interfacedoc, implements
from timeside.tools.gstutils import MainloopThread, gobject
from . file import FileDecoder
import Queue
import threading

from gst import _gst as gst

GST_APPSINK_MAX_BUFFERS = 10
QUEUE_SIZE = 10


class LiveDecoder(FileDecoder):
    """ gstreamer-based decoder from live source"""
    implements(IDecoder)

    # IProcessor methods

    @staticmethod
    @interfacedoc
    def id():
        return "gst_live_dec"

    def __init__(self, num_buffers=-1, input_src='autoaudiosrc'):
        """
        Construct a new LiveDecoder capturing audio from alsasrc

        Parameters
        ----------
        num_buffers :
            Number of buffers to output before sending EOS (-1 = unlimited).
            (Allowed values: >= -1, Default value: -1)


        Examples
        --------

        >>> import timeside

        >>> from timeside.core import get_processor
        >>> live = timeside.decoder.live.LiveDecoder(num_buffers=5)
        >>> a = get_processor('waveform_analyzer')()
        >>> e = timeside.encoder.mp3.Mp3Encoder('/tmp/test_live.mp3',
        ...                                 overwrite=True)
        >>> pipe = (live | a | e)
        >>> pipe.run() # doctest: +SKIP
        >>> pipe.run() # doctest: +SKIP

        >>> import matplotlib.pyplot as plt # doctest: +SKIP
        >>> plt.plot(a.results['waveform_analyzer'].time, # doctest: +SKIP
                 a.results['waveform_analyzer'].data) # doctest: +SKIP
        >>> plt.show() # doctest: +SKIP

        """

        super(Decoder, self).__init__()
        self.num_buffers = num_buffers
        self.uri = None
        self.uri_start = 0
        self.uri_duration = None
        self.is_segment = False
        self.input_src = input_src
        self._sha1 = ''

    def setup(self, channels=None, samplerate=None, blocksize=None):

        self.eod = False
        self.last_buffer = None

        # a lock to wait wait for gstreamer thread to be ready
        self.discovered_cond = threading.Condition(threading.Lock())
        self.discovered = False

        # the output data format we want
        if blocksize:
            self.output_blocksize = blocksize
        if samplerate:
            self.output_samplerate = int(samplerate)
        if channels:
            self.output_channels = int(channels)

        # Create the pipe with standard Gstreamer uridecodbin
        self.pipe = '''%s num-buffers=%d name=src
                       ! audioconvert name=audioconvert
                       ! audioresample
                       ! appsink name=sink sync=False async=True
                       ''' % (self.input_src, self.num_buffers)

        self.pipeline = gst.parse_launch(self.pipe)

        if self.output_channels:
            caps_channels = int(self.output_channels)
        else:
            caps_channels = "[ 1, 2 ]"
        if self.output_samplerate:
            caps_samplerate = int(self.output_samplerate)
        else:
            caps_samplerate = "{ 8000, 11025, 12000, 16000, 22050, 24000, 32000, 44100, 48000, 96000 }"
        sink_caps = gst.Caps("""audio/x-raw-float,
            endianness=(int)1234,
            channels=(int)%s,
            width=(int)32,
            rate=(int)%s""" % (caps_channels, caps_samplerate))

        self.src = self.pipeline.get_by_name('src')
        self.conv = self.pipeline.get_by_name('audioconvert')
        self.conv.get_pad("sink").connect("notify::caps", self._notify_caps_cb)

        self.sink = self.pipeline.get_by_name('sink')
        self.sink.set_property("caps", sink_caps)
        self.sink.set_property('max-buffers', GST_APPSINK_MAX_BUFFERS)
        self.sink.set_property("drop", False)
        self.sink.set_property('emit-signals', True)
        self.sink.connect("new-buffer", self._on_new_buffer_cb)

        self.bus = self.pipeline.get_bus()
        self.bus.add_signal_watch()
        self.bus.connect('message', self._on_message_cb)

        self.queue = Queue.Queue(QUEUE_SIZE)

        self.mainloop = gobject.MainLoop()
        self.mainloopthread = MainloopThread(self.mainloop)
        self.mainloopthread.start()
        #self.mainloopthread = get_loop_thread()
        ##self.mainloop = self.mainloopthread.mainloop

        # start pipeline
        self.pipeline.set_state(gst.STATE_PLAYING)

        self.discovered_cond.acquire()
        while not self.discovered:
            # print 'waiting'
            self.discovered_cond.wait()
        self.discovered_cond.release()

        if not hasattr(self, 'input_samplerate'):
            if hasattr(self, 'error_msg'):
                raise IOError(self.error_msg)
            else:
                raise IOError('no known audio stream found')

    @interfacedoc
    def process(self):
        buf = self.queue.get()
        if buf == gst.MESSAGE_EOS:
            return self.last_buffer, True

        frames, eod = buf
        return frames, eod

    def release(self):
        # TODO : check if stack support is needed here
        #if self.stack:
        #    self.stack = False
        #    self.from_stack = True
        pass

    # IDecoder methods

########NEW FILE########
__FILENAME__ = utils
# -*- coding: utf-8 -*-

# Copyright (c) 2007-2013 Parisson
# Copyright (c) 2007-2013 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (c) 2010-2013 Paul Brossier <piem@piem.org>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors:
# Paul Brossier <piem@piem.org>
# Guillaume Pellerin <yomguy@parisson.com>
# Thomas Fillon <thomas@parisson.com>

from __future__ import division

import numpy as np


class Noise(object):

    """A class that mimics audiolab.sndfile but generates noise instead of reading
    a wave file. Additionally it can be told to have a "broken" header and thus crashing
    in the middle of the file. Also useful for testing ultra-short files of 20 samples."""

    def __init__(self, num_frames, has_broken_header=False):
        self.seekpoint = 0
        self.num_frames = num_frames
        self.has_broken_header = has_broken_header

    def seek(self, seekpoint):
        self.seekpoint = seekpoint

    def get_nframes(self):
        return self.num_frames

    def get_samplerate(self):
        return 44100

    def get_channels(self):
        return 1

    def read_frames(self, frames_to_read):
        if self.has_broken_header and self.seekpoint + frames_to_read > self.num_frames // 2:
            raise IOError()

        num_frames_left = self.num_frames - self.seekpoint
        if num_frames_left < frames_to_read:
            will_read = num_frames_left
        else:
            will_read = frames_to_read
        self.seekpoint += will_read
        return np.random.random(will_read) * 2 - 1


def path2uri(path):
    """
    Return a valid uri (file scheme) from absolute path name of a file

    >>> path2uri('/home/john/my_file.wav')
    'file:///home/john/my_file.wav'

    >>> path2uri('C:\Windows\my_file.wav')
    'file:///C%3A%5CWindows%5Cmy_file.wav'
    """
    import urlparse
    import urllib

    return urlparse.urljoin('file:', urllib.pathname2url(path))


def source_info(source):
    import os.path

    src_info = {'is_file': False,
                'uri': '',
                'pathname': ''}

    if os.path.exists(source):
        src_info['is_file'] = True
        # get the absolute path
        src_info['pathname'] = os.path.abspath(source)
        # and make a uri of it
        src_info['uri'] = path2uri(src_info['pathname'])
    return src_info


def get_uri(source):
    """
    Check a media source as a valid file or uri and return the proper uri
    """

    import gst

    src_info = source_info(source)

    if src_info['is_file']:  # Is this a file?
        return get_uri(src_info['uri'])

    elif gst.uri_is_valid(source):  # Is this a valid URI source for Gstreamer
        uri_protocol = gst.uri_get_protocol(source)
        if gst.uri_protocol_is_supported(gst.URI_SRC, uri_protocol):
            return source
        else:
            raise IOError('Invalid URI source for Gstreamer')
    else:
        raise IOError('Failed getting uri for path %s: no such file' % source)


def get_media_uri_info(uri):

    from gst.pbutils import Discoverer
    from gst import SECOND as GST_SECOND
    from glib import GError
    #import gobject
    GST_DISCOVER_TIMEOUT = 5000000000L
    uri_discoverer = Discoverer(GST_DISCOVER_TIMEOUT)
    try:
        uri_info = uri_discoverer.discover_uri(uri)
    except GError as e:
        raise IOError(e)
    info = dict()

    # Duration in seconds
    info['duration'] = uri_info.get_duration() / GST_SECOND

    audio_streams = uri_info.get_audio_streams()
    info['streams'] = []
    for stream in audio_streams:
        stream_info = {'bitrate': stream.get_bitrate(),
                       'channels': stream.get_channels(),
                       'depth': stream.get_depth(),
                       'max_bitrate': stream.get_max_bitrate(),
                       'samplerate': stream.get_sample_rate()
                       }
        info['streams'].append(stream_info)

    return info


def stack(process_func):

    import functools

    @functools.wraps(process_func)
    def wrapper(decoder):
        # Processing
        if not decoder.from_stack:
            frames, eod = process_func(decoder)
            if decoder.stack:
                decoder.process_pipe.frames_stack.append((frames, eod))
            return frames, eod
        else:
            return decoder._frames_iterator.next()

    return wrapper


def get_sha1(source):
    src_info = source_info(source)

    if src_info['is_file']:  # Is this a file?
        return sha1sum_file(src_info['pathname'])
    else:  # Then it should be an url
        return sha1sum_url(source)


def sha1sum_file(filename):
    '''
    Return the secure hash digest with sha1 algorithm for a given file

    >>> wav_file = 'tests/samples/guitar.wav' # doctest: +SKIP
    >>> print sha1sum_file(wav_file) # doctest: +SKIP
    #08301c3f9a8d60926f31e253825cc74263e52ad1
    '''
    import hashlib
    import io

    sha1 = hashlib.sha1()
    chunk_size = sha1.block_size * io.DEFAULT_BUFFER_SIZE

    with open(filename, 'rb') as f:
        for chunk in iter(lambda: f.read(chunk_size), b''):
            sha1.update(chunk)
    return sha1.hexdigest()


def sha1sum_url(url):
    '''Return the secure hash digest with sha1 algorithm for a given url

    >>> url = 'https://github.com/yomguy/timeside-samples/raw/master/samples/guitar.wav'
    >>> print sha1sum_url(url)
    08301c3f9a8d60926f31e253825cc74263e52ad1
    >>> wav_file = 'tests/samples/guitar.wav' # doctest: +SKIP
    >>> uri = get_uri(wav_file)
    >>> print sha1sum_url(uri)
    08301c3f9a8d60926f31e253825cc74263e52ad1

    '''
    import hashlib
    import urllib
    from contextlib import closing

    sha1 = hashlib.sha1()
    chunk_size = sha1.block_size * 8192

    max_file_size = 10 * 1024 * 1024  # 10Mo limit in case of very large file

    total_read = 0
    with closing(urllib.urlopen(url)) as url_obj:
        for chunk in iter(lambda: url_obj.read(chunk_size), b''):
            sha1.update(chunk)
            total_read += chunk_size
            if total_read > max_file_size:
                break

    return sha1.hexdigest()


def sha1sum_numpy(np_array):
    '''
    Return the secure hash digest with sha1 algorithm for a numpy array
    '''
    import hashlib
    return hashlib.sha1(np_array.view(np.uint8)).hexdigest()


# Define global variables for use with doctest
DOCTEST_ALIAS = {'wav_file':
                 'https://github.com/yomguy/timeside-samples/raw/master/samples/guitar.wav'}

if __name__ == "__main__":
    import doctest

    doctest.testmod(extraglobs=DOCTEST_ALIAS)

########NEW FILE########
__FILENAME__ = audiosink
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2014 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2013-2014 Thomas Fillon <thomas.fillon@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Thomas Fillon <thomas.fillon@parisson.com>

from timeside.core import implements, interfacedoc
from timeside.encoder.core import GstEncoder
from timeside.api import IEncoder


class AudioSink(GstEncoder):

    """gstreamer-based Audio Sink

    This encoder plays the decoded audio stream to the sound card


    >>> import timeside
    >>> wav_file = 'tests/samples/guitar.wav' # doctest: +SKIP
    >>> d = timeside.decoder.file.FileDecoder(wav_file)
    >>> e = timeside.encoder.audiosink.AudioSink()
    >>> (d|e).run() # doctest: +SKIP
    """

    implements(IEncoder)

    def __init__(self, output_sink='autoaudiosink'):

        super(GstEncoder, self).__init__()
        self.streaming = False

        self.output_sink = output_sink

        import threading
        self.end_cond = threading.Condition(threading.Lock())

        self.eod = False
        self.metadata = None
        self.num_samples = 0

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(AudioSink, self).setup(channels, samplerate, blocksize,
                                     totalframes)

        self.pipe = ''' appsrc name=src ! audioconvert
                        ! %s ''' % self.output_sink

        self.start_pipeline(channels, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "gst_audio_sink_enc"

    @staticmethod
    @interfacedoc
    def description():
        return "GStreamer based audio sink encoder"

    @staticmethod
    @interfacedoc
    def format():
        return ""

    @staticmethod
    @interfacedoc
    def file_extension():
        return ""

    @staticmethod
    @interfacedoc
    def mime_type():
        return 'audio/x-raw'

    @interfacedoc
    def set_metadata(self, metadata):
        self.metadata = metadata


# Define global variables for use with doctest
DOCTEST_ALIAS = {'wav_file':
                 'https://github.com/yomguy/timeside-samples/raw/master/samples/guitar.wav'}

if __name__ == "__main__":
    import doctest

    doctest.testmod(extraglobs=DOCTEST_ALIAS)

########NEW FILE########
__FILENAME__ = core
#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2014 Parisson SARL
# Copyright (c) 2006-2014 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (c) 2010-2014 Paul Brossier <piem@piem.org>
# Copyright (c) 2013-2014 Thomas Fillon <thomas@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import Processor, implements, interfacedoc
from timeside.component import abstract
from timeside.api import IEncoder
from timeside.tools.gstutils import numpy_array_to_gst_buffer, MainloopThread

import pygst
pygst.require('0.10')
import gst

import gobject
gobject.threads_init()

import threading

# Streaming queue configuration
QUEUE_SIZE = 10
GST_APPSINK_MAX_BUFFERS = 10


class GstEncoder(Processor):
    implements(IEncoder)
    abstract()

    type = 'encoder'

    def __init__(self, output, streaming=False, overwrite=False):

        super(GstEncoder, self).__init__()

        if isinstance(output, basestring):
            import os.path
            if os.path.isdir(output):
                raise IOError("Encoder output must be a file, not a directory")
            elif os.path.isfile(output) and not overwrite:
                raise IOError(
                    "Encoder output %s exists, but overwrite set to False")
            self.filename = output
        else:
            self.filename = None
        self.streaming = streaming

        if not self.filename and not self.streaming:
            raise Exception('Must give an output')

        self.end_cond = threading.Condition(threading.Lock())
        self.eod = False
        self.metadata = None
        self.num_samples = 0

        self._chunk_len = 0

    @interfacedoc
    def release(self):
        if hasattr(self, 'eod') and hasattr(self, 'mainloopthread'):
            self.end_cond.acquire()
            while not hasattr(self, 'end_reached'):
                self.end_cond.wait()
            self.end_cond.release()
        if hasattr(self, 'error_msg'):
            raise IOError(self.error_msg)

    def __del__(self):
        self.release()

    def start_pipeline(self, channels, samplerate):
        self.pipeline = gst.parse_launch(self.pipe)
        # store a pointer to appsrc in our encoder object
        self.src = self.pipeline.get_by_name('src')

        if self.streaming:
            import Queue
            self._streaming_queue = Queue.Queue(QUEUE_SIZE)
            # store a pointer to appsink in our encoder object
            self.app = self.pipeline.get_by_name('app')
            self.app.set_property('max-buffers', GST_APPSINK_MAX_BUFFERS)
            self.app.set_property("drop", False)
            self.app.set_property('emit-signals', True)
            self.app.connect("new-buffer", self._on_new_buffer_streaming)
            #self.app.connect('new-preroll', self._on_new_preroll_streaming)

        srccaps = gst.Caps("""audio/x-raw-float,
            endianness=(int)1234,
            channels=(int)%s,
            width=(int)32,
            rate=(int)%d""" % (int(channels), int(samplerate)))
        self.src.set_property("caps", srccaps)
        self.src.set_property('emit-signals', True)
        self.src.set_property('num-buffers', -1)
        self.src.set_property('block', False)
        self.src.set_property('do-timestamp', True)

        self.bus = self.pipeline.get_bus()
        self.bus.add_signal_watch()
        self.bus.connect("message", self._on_message_cb)

        self.mainloop = gobject.MainLoop()
        self.mainloopthread = MainloopThread(self.mainloop)
        self.mainloopthread.start()

        # start pipeline
        self.pipeline.set_state(gst.STATE_PLAYING)

    def _on_message_cb(self, bus, message):
        t = message.type
        if t == gst.MESSAGE_EOS:
            self.end_cond.acquire()
            if self.streaming:
                self._streaming_queue.put(gst.MESSAGE_EOS)

            self.pipeline.set_state(gst.STATE_NULL)
            self.mainloop.quit()
            self.end_reached = True
            self.end_cond.notify()
            self.end_cond.release()

        elif t == gst.MESSAGE_ERROR:
            self.end_cond.acquire()
            self.pipeline.set_state(gst.STATE_NULL)
            self.mainloop.quit()
            self.end_reached = True
            err, debug = message.parse_error()
            self.error_msg = "Error: %s" % err, debug
            self.end_cond.notify()
            self.end_cond.release()

    def _on_new_buffer_streaming(self, appsink):
        # print 'pull-buffer'
        chunk = appsink.emit('pull-buffer')
        self._streaming_queue.put(chunk)

    def _on_new_preroll_streaming(self, appsink):
        # print 'preroll'
        chunk = appsink.emit('pull-preroll')
        self._streaming_queue.put(chunk)

    @interfacedoc
    def set_metadata(self, metadata):
        self.metadata = metadata

    @interfacedoc
    def process(self, frames, eod=False):
        self.eod = eod
        if eod:
            self.num_samples += frames.shape[0]
        else:
            self.num_samples += self.blocksize()

        buf = numpy_array_to_gst_buffer(frames, frames.shape[0],
                                        self.num_samples, self.samplerate())

        self.src.emit('push-buffer', buf)
        if self.eod:
            self.src.emit('end-of-stream')

        return frames, eod

    def get_stream_chunk(self):
        if self.streaming:
            chunk = self._streaming_queue.get(block=True)
            if chunk == gst.MESSAGE_EOS:
                return None
            else:
                self._streaming_queue.task_done()
                return chunk

        else:
            raise TypeError('function only available in streaming mode')

if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = flac
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2009 Guillaume Pellerin <yomguy@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Guillaume Pellerin <yomguy@parisson.com>

from timeside.core import implements, interfacedoc
from timeside.encoder.core import GstEncoder
from timeside.api import IEncoder


class FlacEncoder(GstEncoder):

    """ gstreamer-based FLAC encoder """
    implements(IEncoder)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(FlacEncoder, self).setup(
            channels, samplerate, blocksize, totalframes)

        self.pipe = ''' appsrc name=src ! audioconvert
                        ! flacenc '''

        if self.filename and self.streaming:
            self.pipe += ''' ! tee name=t
            ! queue ! filesink location=%s
            t. ! queue ! appsink name=app sync=False
            ''' % self.filename

        elif self.filename:
            self.pipe += '! filesink location=%s async=False sync=False ' % self.filename
        else:
            self.pipe += '! queue ! appsink name=app sync=False '

        self.start_pipeline(channels, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "gst_flac_enc"

    @staticmethod
    @interfacedoc
    def description():
        return "FLAC GStreamer based encoder"

    @staticmethod
    @interfacedoc
    def format():
        return "FLAC"

    @staticmethod
    @interfacedoc
    def file_extension():
        return "flac"

    @staticmethod
    @interfacedoc
    def mime_type():
        return 'audio/x-flac'

    @interfacedoc
    def set_metadata(self, metadata):
        self.metadata = metadata

########NEW FILE########
__FILENAME__ = m4a
# -*- coding: utf-8 -*-
#
# Copyright (c) 2010 Paul Brossier <piem@piem.org>
# Copyright (c) 2010 Guillaume Pellerin <yomguy@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.encoder.core import GstEncoder
from timeside.api import IEncoder


class AacEncoder(GstEncoder):

    """ gstreamer-based AAC encoder """
    implements(IEncoder)

    def __init__(self, output, streaming=False, overwrite=False):
        super(AacEncoder, self).__init__(output, streaming, overwrite)
        if self.streaming:
            raise Exception("Streaming not supported")

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(AacEncoder, self).setup(
            channels, samplerate, blocksize, totalframes)

        self.streaming = False
        self.pipe = ''' appsrc name=src
            ! audioconvert
            ! voaacenc
            ! mp4mux
            '''

        if self.filename and self.streaming:
            self.pipe += ''' ! tee name=t
            ! queue ! filesink location=%s
            t. ! queue ! appsink name=app sync=False
            ''' % self.filename

        elif self.filename:
            self.pipe += '! filesink location=%s async=False sync=False ' % self.filename
        else:
            self.pipe += '! queue ! appsink name=app sync=False '

        self.start_pipeline(channels, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "gst_aac_enc"

    @staticmethod
    @interfacedoc
    def description():
        return "AAC GStreamer based encoder"

    @staticmethod
    @interfacedoc
    def format():
        return "AAC"

    @staticmethod
    @interfacedoc
    def file_extension():
        return "m4a"

    @staticmethod
    @interfacedoc
    def mime_type():
        return "audio/x-m4a"

    @interfacedoc
    def set_metadata(self, metadata):
        self.metadata = metadata

########NEW FILE########
__FILENAME__ = metadata
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2009 Parisson
# Copyright (c) 2007 Olivier Guilyardi <olivier@samalyse.com>
# Copyright (c) 2007-2009 Guillaume Pellerin <pellerin@parisson.com>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


class Metadata(object):
    pass

########NEW FILE########
__FILENAME__ = mp3
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2014 Parisson SARL
# Copyright (c) 2006-2014 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (c) 2010-2014 Paul Brossier <piem@piem.org>
# Copyright (c) 2009-2010 Olivier Guilyardi <olivier@samalyse.com>
# Copyright (c) 2013-2014 Thomas Fillon <thomas@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors: Guillaume Pellerin <yomguy@parisson.com>
#          Paul Brossier <piem@piem.org>
#          Thomas Fillon <thomas@parisson.com>

from timeside.core import implements, interfacedoc
from timeside.encoder.core import GstEncoder
from timeside.api import IEncoder


class Mp3Encoder(GstEncoder):

    """ gstreamer-based MP3 encoder """
    implements(IEncoder)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(Mp3Encoder, self).setup(channels, samplerate, blocksize,
                                      totalframes)

        self.pipe = '''appsrc name=src
                  ! audioconvert ! audioresample
                  ! lamemp3enc target=quality quality=2 encoding-engine-quality=standard
                  ! xingmux
                  ! id3v2mux
                  '''

        if self.filename and self.streaming:
            self.pipe += ''' ! tee name=t
            ! queue ! filesink location=%s
            t. ! queue! appsink name=app sync=False
            ''' % self.filename

        elif self.filename:
            self.pipe += '! filesink location=%s async=False sync=False ' % self.filename
        else:
            self.pipe += '! queue ! appsink name=app sync=False'

        self.start_pipeline(channels, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "gst_mp3_enc"

    @staticmethod
    @interfacedoc
    def description():
        return "MP3 GStreamer based encoder"

    @staticmethod
    @interfacedoc
    def format():
        return "MP3"

    @staticmethod
    @interfacedoc
    def file_extension():
        return "mp3"

    @staticmethod
    @interfacedoc
    def mime_type():
        return "audio/mpeg"

    def write_metadata(self):
        """Write all ID3v2.4 tags to file from self.metadata"""
        import mutagen
        from mutagen import id3

        id3 = id3.ID3(self.filename)
        for tag in self.metadata.keys():
            value = self.metadata[tag]
            frame = mutagen.id3.Frames[tag](3, value)
            try:
                id3.add(frame)
            except:
                raise IOError('EncoderError: cannot tag "' + tag + '"')
        try:
            id3.save()
        except:
            raise IOError('EncoderError: cannot write tags')

########NEW FILE########
__FILENAME__ = ogg
# -*- coding: utf-8 -*-
#
# Copyright (c) 2010 Paul Brossier <piem@piem.org>
# Copyright (c) 2010 Guillaume Pellerin <yomguy@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.encoder.core import GstEncoder
from timeside.api import IEncoder


class VorbisEncoder(GstEncoder):

    """ gstreamer-based OGG Vorbis encoder """
    implements(IEncoder)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(VorbisEncoder, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.pipe = ''' appsrc name=src
                  ! audioconvert ! audioresample
                  ! vorbisenc quality=0.9
                  ! oggmux
                  '''

        if self.filename and self.streaming:
            self.pipe += ''' ! tee name=t
            ! queue ! filesink location=%s
            t. ! queue ! appsink name=app sync=False
            ''' % self.filename

        elif self.filename:
            self.pipe += '! filesink location=%s async=False sync=False ' % self.filename
        else:
            self.pipe += '! queue ! appsink name=app sync=False '

        self.start_pipeline(channels, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "gst_vorbis_enc"

    @staticmethod
    @interfacedoc
    def description():
        return "Vorbis GStreamer based encoder"

    @staticmethod
    @interfacedoc
    def format():
        return "OGG"

    @staticmethod
    @interfacedoc
    def file_extension():
        return "ogg"

    @staticmethod
    @interfacedoc
    def mime_type():
        return "application/ogg"

    @interfacedoc
    def set_metadata(self, metadata):
        self.metadata = metadata

########NEW FILE########
__FILENAME__ = opus
# -*- coding: utf-8 -*-
#
# Copyright (C) 2007-2014 Parisson SARL
# Copyright (c) 2006-2014 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (c) 2010-2014 Paul Brossier <piem@piem.org>
# Copyright (c) 2009-2010 Olivier Guilyardi <olivier@samalyse.com>
# Copyright (c) 2013-2014 Thomas Fillon <thomas@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors: Guillaume Pellerin <yomguy@parisson.com>
#          Paul Brossier <piem@piem.org>
#          Thomas Fillon <thomas@parisson.com>

from timeside.core import implements, interfacedoc
from timeside.encoder.core import GstEncoder
from timeside.api import IEncoder


class OpusEncoder(GstEncoder):

    """ gstreamer-based Opus encoder """
    implements(IEncoder)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(OpusEncoder, self).setup(channels, samplerate, blocksize,
                                       totalframes)

        self.pipe = '''appsrc name=src
                  ! audioconvert ! audioresample
                  ! opusenc audio=true bitrate=128000
                  ! oggmux
                  '''

        if self.filename and self.streaming:
            self.pipe += ''' ! tee name=t
            ! queue ! filesink location=%s
            t. ! queue! appsink name=app sync=False
            ''' % self.filename

        elif self.filename:
            self.pipe += '! filesink location=%s async=False sync=False ' % self.filename
        else:
            self.pipe += '! queue ! appsink name=app sync=False'

        self.start_pipeline(channels, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "gst_opus_enc"

    @staticmethod
    @interfacedoc
    def description():
        return "Opus GStreamer based encoder"

    @staticmethod
    @interfacedoc
    def format():
        return "Opus"

    @staticmethod
    @interfacedoc
    def file_extension():
        return "opus"

    @staticmethod
    @interfacedoc
    def mime_type():
        return "audio/ogg"

    @interfacedoc
    def set_metadata(self, metadata):
        self.metadata = metadata

########NEW FILE########
__FILENAME__ = wav
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2010 Parisson
# Copyright (c) 2010 Paul Brossier <piem@piem.org>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Paul Brossier <piem@piem.org>

from timeside.core import implements, interfacedoc
from timeside.encoder.core import GstEncoder
from timeside.api import IEncoder


class WavEncoder(GstEncoder):

    """ gstreamer-based WAV encoder """
    implements(IEncoder)

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(WavEncoder, self).setup(
            channels, samplerate, blocksize, totalframes)

        self.pipe = ''' appsrc name=src
                  ! audioconvert
                  ! wavenc
                  '''
        if self.filename and self.streaming:
            self.pipe += ''' ! tee name=t
            ! queue ! filesink location=%s
            t. ! queue ! appsink name=app sync=False
            ''' % self.filename

        elif self.filename:
            self.pipe += '! filesink location=%s async=False sync=False ' % self.filename
        else:
            self.pipe += '! queue ! appsink name=app sync=False '

        self.start_pipeline(channels, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "gst_wav_enc"

    @staticmethod
    @interfacedoc
    def description():
        return "Wav GStreamer based encoder"

    @staticmethod
    @interfacedoc
    def format():
        return "WAV"

    @staticmethod
    @interfacedoc
    def file_extension():
        return "wav"

    @staticmethod
    @interfacedoc
    def mime_type():
        return "audio/x-wav"

    @interfacedoc
    def set_metadata(self, metadata):
        # TODO
        pass

########NEW FILE########
__FILENAME__ = webm
# -*- coding: utf-8 -*-
#
# Copyright (c) 2010 Paul Brossier <piem@piem.org>
# Copyright (c) 2010 Guillaume Pellerin <yomguy@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.encoder.core import GstEncoder
from timeside.api import IEncoder


class WebMEncoder(GstEncoder):

    """ gstreamer-based WebM encoder """
    implements(IEncoder)

    def __init__(self, output, streaming=False, overwrite=False, video=False):
        super(WebMEncoder, self).__init__(output, streaming, overwrite)
        self.video = video

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(WebMEncoder, self).setup(channels, samplerate, blocksize,
                                       totalframes)
        from numpy import ceil
        framerate = 30
        num_buffers = ceil(self.mediainfo()['duration'] *
                           framerate).astype(int)
        self.pipe = ''
        if self.video:
            self.pipe += '''videotestsrc pattern=black num_buffers=%d ! ffmpegcolorspace ! queue ! vp8enc speed=2 threads=4 quality=9.0 ! queue ! mux.
                         ''' % num_buffers
        self.pipe += '''
              appsrc name=src ! queue ! audioconvert ! vorbisenc quality=0.9 ! queue ! mux.
              webmmux streamable=true name=mux
                  '''
        if self.filename and self.streaming:
            self.pipe += ''' ! tee name=t
            ! queue ! filesink location=%s
            t. ! queue ! appsink name=app sync=False
            ''' % self.filename

        elif self.filename:
            self.pipe += '! filesink location=%s async=False sync=False ' % self.filename
        else:
            self.pipe += '! queue ! appsink name=app sync=False '

        self.start_pipeline(channels, samplerate)

    @staticmethod
    @interfacedoc
    def id():
        return "gst_webm_enc"

    @staticmethod
    @interfacedoc
    def description():
        return "WebM GStreamer based encoder"

    @staticmethod
    @interfacedoc
    def format():
        return "WebM"

    @staticmethod
    @interfacedoc
    def file_extension():
        return "webm"

    @staticmethod
    @interfacedoc
    def mime_type():
        return "video/webm"

    @interfacedoc
    def set_metadata(self, metadata):
        self.metadata = metadata

if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = exceptions
# -*- coding: utf-8 -*-
#
# Copyright (c) 2009 Olivier Guilyardi <olivier@samalyse.com>
#
# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


class Error(Exception):

    """Exception base class for errors in TimeSide."""


class ApiError(Exception):

    """Exception base class for errors in TimeSide."""


class SubProcessError(Error):

    """Exception for reporting errors from a subprocess"""

    def __init__(self, message, command, subprocess):
        self.message = message
        self.command = str(command)
        self.subprocess = subprocess

    def __str__(self):
        if self.subprocess.stderr is not None:
            error = self.subprocess.stderr.read()
        else:
            error = ''
        return "%s ; command: %s; error: %s" % (self.message,
                                                self.command,
                                                error)


class PIDError(KeyError):
    "Exception for reporting missing Processor ID in registered processors"


class VampImportError(ImportError):
    "Can't import module depending on Vamp because vamp host is missing"

########NEW FILE########
__FILENAME__ = color_schemes


default_color_schemes = {
    'default': {
        'waveform': [(50, 0, 200), (0, 220, 80), (255, 224, 0), (255, 0, 0)],
        'spectrogram': [(0, 0, 0), (58 / 4, 68 / 4, 65 / 4), (80 / 2, 100 / 2, 153 / 2), (90, 180, 100),
                        (224, 224, 44), (255, 60, 30), (255, 255, 255)]
    },
    'iso': {
        'waveform': [(0, 0, 255), (0, 255, 255), (255, 255, 0), (255, 0, 0)],
        'spectrogram': [(0, 0, 0), (58 / 4, 68 / 4, 65 / 4), (80 / 2, 100 / 2, 153 / 2), (90, 180, 100),
                        (224, 224, 44), (255, 60, 30), (255, 255, 255)]
    },
    'purple': {
        'waveform': [(173, 173, 173), (147, 149, 196), (77, 80, 138), (108, 66, 0)],
        'spectrogram': [(0, 0, 0), (58 / 4, 68 / 4, 65 / 4), (80 / 2, 100 / 2, 153 / 2), (90, 180, 100),
                        (224, 224, 44), (255, 60, 30), (255, 255, 255)]
    },
    'awdio': {
        'waveform': [(255, 255, 255), (255, 255, 255), (255, 255, 255), (255, 255, 255)],
        'spectrogram': [(0, 0, 0), (58 / 4, 68 / 4, 65 / 4), (80 / 2, 100 / 2, 153 / 2), (90, 180, 100),
                        (224, 224, 44), (255, 60, 30), (255, 255, 255)]
    },
}

########NEW FILE########
__FILENAME__ = core
#!/usr/bin/env python
# -*- coding: utf-8 -*-

# Copyright (C) 2008 MUSIC TECHNOLOGY GROUP (MTG)
#                    UNIVERSITAT POMPEU FABRA
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
#
# Authors:
#   Bram de Jong <bram.dejong at domain.com where domain in gmail>
#   Guillaume Pellerin <yomguy@parisson.com>


import math
import numpy

try:
    from PIL import Image, ImageDraw
except ImportError:
    import Image
    import ImageDraw

from timeside.core import Processor, implements, interfacedoc, abstract
from timeside.core import FixedSizeInputAdapter
from timeside.api import IGrapher
from . utils import smooth, im_watermark, normalize


class Spectrum(object):

    """ FFT based frequency analysis of audio frames."""

    def __init__(self, fft_size, samplerate, blocksize,
                 totalframes, lower, higher, window_function=None):
        self.fft_size = fft_size
        self.window = window_function(self.fft_size)
        self.window_function = window_function
        self.spectrum_range = None
        self.lower = lower
        self.higher = higher
        self.blocksize = blocksize
        self.lower_log = math.log10(self.lower)
        self.higher_log = math.log10(self.higher)
        self.clip = lambda val, low, high: min(high, max(low, val))
        self.totalframes = totalframes
        self.samplerate = samplerate
        self.window_function = window_function
        self.window = self.window_function(self.blocksize)
        # Hanning window by default
        if self.window_function:
            self.window = self.window_function(self.blocksize)
        else:
            self.window_function = numpy.hanning
            self.window = self.window_function(self.blocksize)

    def process(self, frames, eod, spec_range=120.0):
        """ Returns a tuple containing the spectral centroid and
        the spectrum (dB scales) of the input audio frames.
        FFT window sizes are adatable to the input frame size."""

        samples = frames[:, 0]
        nsamples = len(frames[:, 0])
        if nsamples != self.blocksize:
            self.window = self.window_function(nsamples)
        samples *= self.window

        while nsamples > self.fft_size:
            self.fft_size = 2 * self.fft_size

        zeros_p = numpy.zeros(self.fft_size / 2 - int(nsamples / 2))
        if nsamples % 2:
            zeros_n = numpy.zeros(self.fft_size / 2 - int(nsamples / 2) - 1)
        else:
            zeros_n = numpy.zeros(self.fft_size / 2 - int(nsamples / 2))
        samples = numpy.concatenate((zeros_p, samples, zeros_n), axis=0)

        fft = numpy.fft.fft(samples)
        # normalized abs(FFT) between 0 and 1
        spectrum = numpy.abs(fft[:fft.shape[0] / 2 + 1]) / float(nsamples)
        length = numpy.float64(spectrum.shape[0])

        # scale the db spectrum from [- spec_range db ... 0 db] > [0..1]
        db_spectrum = ((20 * (numpy.log10(spectrum + 1e-30)))
                       .clip(-spec_range, 0.0) + spec_range) / spec_range
        energy = spectrum.sum()
        spectral_centroid = 0

        if energy > 1e-20:
            # calculate the spectral centroid
            if self.spectrum_range is None:
                self.spectrum_range = numpy.arange(length)
            spectral_centroid = (spectrum * self.spectrum_range).sum() / \
                (energy * (length - 1)) * \
                self.samplerate * 0.5
            # clip > log10 > scale between 0 and 1
            spectral_centroid = (math.log10(self.clip(spectral_centroid,
                                                      self.lower,
                                                      self.higher)) -
                                 self.lower_log) / (self.higher_log -
                                                    self.lower_log)

        return (spectral_centroid, db_spectrum)


class Grapher(Processor):

    '''
    Generic abstract class for the graphers
    '''

    type = 'grapher'

    fft_size = 0x1000
    frame_cursor = 0
    pixel_cursor = 0
    lower_freq = 20

    implements(IGrapher)
    abstract()

    def __init__(self, width=1024, height=256, bg_color=None, color_scheme='default'):
        super(Grapher, self).__init__()
        self.bg_color = bg_color
        self.color_scheme = color_scheme
        self.graph = None
        self.image_width = width
        self.image_height = height
        self.bg_color = bg_color
        self.color_scheme = color_scheme
        self.previous_x, self.previous_y = None, None

    @staticmethod
    def id():
        return "generic_grapher"

    @staticmethod
    def name():
        return "Generic grapher"

    def set_colors(self, bg_color, color_scheme):
        self.bg_color = bg_color
        self.color_color_scheme = color_scheme

    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(Grapher, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.sample_rate = samplerate
        self.higher_freq = self.sample_rate / 2
        self.block_size = blocksize
        self.total_frames = totalframes
        self.image = Image.new(
            "RGBA", (self.image_width, self.image_height), self.bg_color)
        self.samples_per_pixel = self.total_frames / float(self.image_width)
        self.buffer_size = int(round(self.samples_per_pixel, 0))
        self.pixels_adapter = FixedSizeInputAdapter(
            self.buffer_size, 1, pad=False)
        self.pixels_adapter_totalframes = self.pixels_adapter.blocksize(
            self.total_frames)
        self.spectrum = Spectrum(
            self.fft_size, self.sample_rate, self.block_size, self.total_frames,
            self.lower_freq, self.higher_freq, numpy.hanning)
        self.pixel = self.image.load()
        self.draw = ImageDraw.Draw(self.image)

    @interfacedoc
    def render(self, output=None):
        if output:
            try:
                self.image.save(output)
            except AttributeError:
                print "Pixel %s x %d" % (self.image_width, self.image_height)
                self.image.savefig(output, dpi=341)
            return
        return self.image

    def watermark(self, text, font=None, color=(255, 255, 255), opacity=.6, margin=(5, 5)):
        self.image = im_watermark(
            self.image, text, color=color, opacity=opacity, margin=margin)

    def draw_peaks(self, x, peaks, line_color):
        """Draw 2 peaks at x"""

        y1 = self.image_height * 0.5 - peaks[0] * (self.image_height - 4) * 0.5
        y2 = self.image_height * 0.5 - peaks[1] * (self.image_height - 4) * 0.5

        if self.previous_y:
            self.draw.line(
                [self.previous_x, self.previous_y, x, y1, x, y2], line_color)
        else:
            self.draw.line([x, y1, x, y2], line_color)

        self.draw_anti_aliased_pixels(x, y1, y2, line_color)
        self.previous_x, self.previous_y = x, y2

    def draw_peaks_inverted(self, x, peaks, line_color):
        """Draw 2 inverted peaks at x"""

        y1 = self.image_height * 0.5 - peaks[0] * (self.image_height - 4) * 0.5
        y2 = self.image_height * 0.5 - peaks[1] * (self.image_height - 4) * 0.5

        if self.previous_y and x < self.image_width - 1:
            if y1 < y2:
                self.draw.line((x, 0, x, y1), line_color)
                self.draw.line((x, self.image_height, x, y2), line_color)
            else:
                self.draw.line((x, 0, x, y2), line_color)
                self.draw.line((x, self.image_height, x, y1), line_color)
        else:
            self.draw.line((x, 0, x, self.image_height), line_color)
        self.draw_anti_aliased_pixels(x, y1, y2, line_color)
        self.previous_x, self.previous_y = x, y1

    def draw_anti_aliased_pixels(self, x, y1, y2, color):
        """ vertical anti-aliasing at y1 and y2 """

        y_max = max(y1, y2)
        y_max_int = int(y_max)
        alpha = y_max - y_max_int

        if alpha > 0.0 and alpha < 1.0 and y_max_int + 1 < self.image_height:
            current_pix = self.pixel[int(x), y_max_int + 1]
            r = int((1 - alpha) * current_pix[0] + alpha * color[0])
            g = int((1 - alpha) * current_pix[1] + alpha * color[1])
            b = int((1 - alpha) * current_pix[2] + alpha * color[2])
            self.pixel[x, y_max_int + 1] = (r, g, b)

        y_min = min(y1, y2)
        y_min_int = int(y_min)
        alpha = 1.0 - (y_min - y_min_int)

        if alpha > 0.0 and alpha < 1.0 and y_min_int - 1 >= 0:
            current_pix = self.pixel[x, y_min_int - 1]
            r = int((1 - alpha) * current_pix[0] + alpha * color[0])
            g = int((1 - alpha) * current_pix[1] + alpha * color[1])
            b = int((1 - alpha) * current_pix[2] + alpha * color[2])
            self.pixel[x, y_min_int - 1] = (r, g, b)

    def draw_peaks_contour(self):
        contour = self.contour.copy()
        contour = smooth(contour, window_len=16)
        contour = normalize(contour)

        # Scaling
        #ratio = numpy.mean(contour)/numpy.sqrt(2)
        ratio = 1
        contour = normalize(numpy.expm1(contour / ratio)) * (1 - 10 ** -6)

        # Spline
        #contour = cspline1d(contour)
        #contour = cspline1d_eval(contour, self.x, dx=self.dx1, x0=self.x[0])

        if self.symetry:
            height = int(self.image_height / 2)
        else:
            height = self.image_height

        # Multicurve rotating
        for i in range(0, self.ndiv):
            self.previous_x, self.previous_y = None, None

            bright_color = int(255 * (1 - float(i) / (self.ndiv * 2)))
            bright_color = 255 - bright_color + self.color_offset
            #line_color = self.color_lookup[int(self.centroids[j]*255.0)]
            line_color = (bright_color, bright_color, bright_color)

            # Linear
            #contour = contour*(1.0-float(i)/self.ndiv)
            #contour = contour*(1-float(i)/self.ndiv)

            # Cosinus
            contour = contour * \
                numpy.arccos(float(i) / self.ndiv) * 2 / numpy.pi
            #contour = self.contour*(1-float(i)*numpy.arccos(float(i)/self.ndiv)*2/numpy.pi/self.ndiv)
            #contour = contour + ((1-contour)*2/numpy.pi*numpy.arcsin(float(i)/self.ndiv))

            curve = (height - 1) * contour
            #curve = contour*(height-2)/2+height/2

            for x in self.x:
                x = int(x)
                y = curve[x]
                if not x == 0:
                    if not self.symetry:
                        self.draw.line(
                            [self.previous_x, self.previous_y, x, y], line_color)
                        self.draw_anti_aliased_pixels(x, y, y, line_color)
                    else:
                        self.draw.line(
                            [self.previous_x, self.previous_y + height, x, y + height], line_color)
                        self.draw_anti_aliased_pixels(
                            x, y + height, y + height, line_color)
                        self.draw.line(
                            [self.previous_x, -self.previous_y + height, x, -y + height], line_color)
                        self.draw_anti_aliased_pixels(
                            x, -y + height, -y + height, line_color)
                else:
                    if not self.symetry:
                        self.draw.point((x, y), line_color)
                    else:
                        self.draw.point((x, y + height), line_color)
                self.previous_x, self.previous_y = x, y


if __name__ == "__main__":
    import doctest
    doctest.testmod()

########NEW FILE########
__FILENAME__ = render_analyzers
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2014 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2013-2014 Thomas Fillon <thomas@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but _WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

from __future__ import division

from ..core import implements, interfacedoc, abstract, get_processor
from ..api import IGrapher
from .core import Grapher
from ..exceptions import PIDError


class DisplayAnalyzer(Grapher):

    """
    Builds a PIL image from analyzer result
    This is an Abstract base class
    """
    dpi = 72  # Web default value for Telemeta

    implements(IGrapher)
    abstract()

    @interfacedoc
    def __init__(self, width=1024, height=256, bg_color=(0, 0, 0),
                 color_scheme='default'):
        super(DisplayAnalyzer, self).__init__(width, height, bg_color,
                                              color_scheme)

        self._result_id = None
        self._id = NotImplemented
        self._name = NotImplemented

    @interfacedoc
    def process(self, frames, eod=False):
        return frames, eod

    @interfacedoc
    def post_process(self):
        parent_result = self.process_pipe.results[self._result_id]

        self.image = parent_result._render_PIL((self.image_width,
                                                self.image_height), self.dpi)

    @classmethod
    def create(cls, analyzer, result_id, grapher_id, grapher_name):

        class NewGrapher(cls):

            _id = grapher_id

            implements(IGrapher)

            @interfacedoc
            def __init__(self, width=1024, height=256, bg_color=(0, 0, 0),
                         color_scheme='default'):
                super(NewGrapher, self).__init__(width, height, bg_color,
                                                 color_scheme)

                self.parents.append(analyzer)
                # TODO : make it generic when analyzer will be "atomize"
                self._result_id = result_id

            @staticmethod
            @interfacedoc
            def id():
                return grapher_id

            @staticmethod
            @interfacedoc
            def name():
                return grapher_name

            __doc__ = """Builds a PIL image representing """ + grapher_name

        NewGrapher.__name__ = 'Display' + '.' + result_id

        return NewGrapher


# From here define new Grapher based on Analyzers
try:
    aubiopitch = get_processor('aubio_pitch')
    DisplayAubioPitch = DisplayAnalyzer.create(analyzer=aubiopitch,
                                               result_id='aubio_pitch.pitch',
                                               grapher_id='grapher_aubio_pitch',
                                               grapher_name='Aubio Pitch')
except PIDError:
    pass

odf = get_processor('odf')
DisplayOnsetDetectionFunction = DisplayAnalyzer.create(analyzer=odf,
                                                       result_id='odf',
                                                       grapher_id='grapher_odf',
                                                       grapher_name='Onset detection function')
wav = get_processor('waveform_analyzer')
DisplayWaveform = DisplayAnalyzer.create(analyzer=wav,
                                         result_id='waveform_analyzer',
                                         grapher_id='grapher_waveform',
                                         grapher_name='Waveform from Analyzer')

irit4hz = get_processor('irit_speech_4hz')
Display4hzSpeechSegmentation = DisplayAnalyzer.create(analyzer=irit4hz,
                                                      result_id='irit_speech_4hz.segments',
                                                      grapher_id='grapher_irit_speech_4hz_segments',
                                                      grapher_name='Irit 4Hz Speech Segmentation')

########NEW FILE########
__FILENAME__ = spectrogram_lin
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2010 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2010 Olivier Guilyardi <olivier@samalyse.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.api import IGrapher
#from timeside.grapher.core import *
from timeside.grapher.spectrogram_log import SpectrogramLog


class SpectrogramLinear(SpectrogramLog):

    """ Builds a PIL image representing a spectrogram of the audio stream (level vs. frequency vs. time).
    Adds pixels iteratively thanks to the adapter providing fixed size frame buffers."""

    implements(IGrapher)

    @interfacedoc
    def __init__(self, width=1024, height=256, bg_color=(0, 0, 0), color_scheme='default'):
        super(SpectrogramLinear, self).__init__(
            width, height, bg_color, color_scheme)

    @staticmethod
    @interfacedoc
    def id():
        return "spectrogram_lin"

    @staticmethod
    @interfacedoc
    def name():
        return "Spectrogram Lin"

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(SpectrogramLinear, self).setup(
            channels, samplerate, blocksize, totalframes)

    def set_scale(self):
        """generate the lookup which translates y-coordinate to fft-bin"""

        f_min = float(self.lower_freq)
        f_max = float(self.higher_freq)
        y_min = f_min
        y_max = f_max
        for y in range(self.image_height):
            freq = y_min + y / (self.image_height - 1.0) * (y_max - y_min)
            fft_bin = freq / f_max * (self.fft_size / 2 + 1)
            if fft_bin < self.fft_size / 2:
                alpha = fft_bin - int(fft_bin)
                self.y_to_bin.append((int(fft_bin), alpha * 255))

########NEW FILE########
__FILENAME__ = spectrogram_log
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2010 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2010 Olivier Guilyardi <olivier@samalyse.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.api import IGrapher
from timeside.grapher.core import Grapher, Image
from timeside.grapher.color_schemes import default_color_schemes
from . utils import interpolate_colors
import math


class SpectrogramLog(Grapher):

    """ Builds a PIL image representing a spectrogram of the audio stream
    (level vs. frequency vs. time).
    Adds pixels iteratively thanks to the adapter providing
    fixed size frame buffers."""

    implements(IGrapher)

    @interfacedoc
    def __init__(self, width=1024, height=256, bg_color=(0, 0, 0),
                 color_scheme='default'):
        super(SpectrogramLog, self).__init__(
            width, height, bg_color, color_scheme)
        self.lower_freq = 100
        self.colors = default_color_schemes[color_scheme]['spectrogram']
        self.pixels = []
        self.y_to_bin = []

    @staticmethod
    @interfacedoc
    def id():
        return "spectrogram_log"

    @staticmethod
    @interfacedoc
    def name():
        return "Spectrogram Log"

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(SpectrogramLog, self).setup(
            channels, samplerate, blocksize, totalframes)
        self.image = self.image.convert("P")
        self.image = self.image.transpose(Image.ROTATE_90)
        self.image.putpalette(interpolate_colors(self.colors, True))
        self.set_scale()

    def set_scale(self):
        """generate the lookup which translates y-coordinate to fft-bin"""

        f_min = float(self.lower_freq)
        f_max = float(self.higher_freq)
        y_min = math.log10(f_min)
        y_max = math.log10(f_max)
        for y in range(self.image_height):
            freq = math.pow(
                10.0, y_min + y / (self.image_height - 1.0) * (y_max - y_min))
            fft_bin = freq / f_max * (self.fft_size / 2 + 1)
            if fft_bin < self.fft_size / 2:
                alpha = fft_bin - int(fft_bin)
                self.y_to_bin.append((int(fft_bin), alpha * 255))

    def draw_spectrum(self, x, spectrum):
        for (index, alpha) in self.y_to_bin:
            self.pixels.append(
                int(((255.0 - alpha) * spectrum[index] + alpha * spectrum[index + 1])))
        for y in range(len(self.y_to_bin), self.image_height):
            self.pixels.append(0)

    @interfacedoc
    def process(self, frames, eod=False):
        if len(frames) != 1:
            chunk = frames[:, 0].copy()
            chunk.shape = (len(chunk), 1)
            for samples, end in self.pixels_adapter.process(chunk, eod):
                if self.pixel_cursor < self.image_width:
                    (spectral_centroid, db_spectrum) = self.spectrum.process(
                        samples, True)
                    self.draw_spectrum(self.pixel_cursor, db_spectrum)
                    self.pixel_cursor += 1
        return frames, eod

    @interfacedoc
    def post_process(self):
        """ Apply last 2D transforms"""
        self.image.putdata(self.pixels)
        self.image = self.image.transpose(Image.ROTATE_90)

########NEW FILE########
__FILENAME__ = utils
# -*- coding: utf-8 -*-
#
# Copyright (C) 2009-2013 Parisson SARL
# Copyright (c) 2009-2012 Guillaume Pellerin <pellerin@parisson.com>
# Copyright (C) 2008 MUSIC TECHNOLOGY GROUP (MTG)
#                    UNIVERSITAT POMPEU FABRA

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


# Authors:
#   Bram de Jong <bram.dejong at domain.com where domain in gmail>
#   Guillaume Pellerin <yomguy@parisson.com>

try:
    from PIL import Image, ImageDraw, ImageColor, ImageEnhance
except ImportError:
    import Image
    import ImageDraw
    import ImageColor
    import ImageEnhance

import numpy


def interpolate_colors(colors, flat=False, num_colors=256):
    """ Given a list of colors, create a larger list of colors interpolating
    the first one. If flatten is True a list of numers will be returned. If
    False, a list of (r,g,b) tuples. num_colors is the number of colors wanted
    in the final list """

    palette = []

    for i in range(num_colors):
        index = (i * (len(colors) - 1)) / (num_colors - 1.0)
        index_int = int(index)
        alpha = index - float(index_int)

        if alpha > 0:
            r = (1.0 - alpha) * colors[index_int][
                0] + alpha * colors[index_int + 1][0]
            g = (1.0 - alpha) * colors[index_int][
                1] + alpha * colors[index_int + 1][1]
            b = (1.0 - alpha) * colors[index_int][
                2] + alpha * colors[index_int + 1][2]
        else:
            r = (1.0 - alpha) * colors[index_int][0]
            g = (1.0 - alpha) * colors[index_int][1]
            b = (1.0 - alpha) * colors[index_int][2]

        if flat:
            palette.extend((int(r), int(g), int(b)))
        else:
            palette.append((int(r), int(g), int(b)))

    return palette


def downsample(vector, factor):
    """
    downsample(vector, factor):
        Downsample (by averaging) a vector by an integer factor.
    """
    if (len(vector) % factor):
        print "Length of 'vector' is not divisible by 'factor'=%d!" % factor
        return 0
    vector.shape = (len(vector) / factor, factor)
    return numpy.mean(vector, axis=1)


def smooth(x, window_len=10, window='hanning'):
    """
    Smooth the data using a window with requested size.

    This method is based on the convolution of a scaled window with the signal.
    The signal is prepared by introducing reflected copies of the signal
    (with the window size) in both ends so that transient parts are minimized
    in the begining and end part of the output signal.

    Parameters
    ----------
    x : numpy.array
        the input signal
    window_len : int
        the dimension of the smoothing window
    window : str
        the type of window from 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'
        flat window will produce a moving average smoothing.

    Returns
    -------
    The smoothed signal

    See Also
    -------

    numpy.hanning, numpy.hamming, numpy.bartlett, numpy.blackman, numpy.convolve
    scipy.signal.lfilter

    Examples
    --------

    >>> import numpy as np
    >>> from timeside.grapher.utils import smooth
    >>> t = np.arange(-2,2,0.1)
    >>> x = np.sin(t)+np.random.randn(len(t))*0.1
    >>> y = smooth(x)
    >>> import matplotlib.pyplot as plt
    >>> plt.plot(x) # doctest: +SKIP
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.plot(y) # doctest: +SKIP
    [<matplotlib.lines.Line2D object at 0x...>]
    >>> plt.legend(['Source signal', 'Smoothed signal']) # doctest: +SKIP
    <matplotlib.legend.Legend object at 0x...>
    >>> plt.show() # doctest: +SKIP
    """

    # TODO: the window parameter could be the window itself if an array
    # instead of a string

    if x.ndim != 1:
        raise ValueError("smooth only accepts 1 dimension arrays.")
    if x.size < window_len:
        raise ValueError("Input vector needs to be bigger than window size.")
    if window_len < 3:
        return x
    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:
        raise ValueError("Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'")

    s = numpy.r_[2 * x[0] - x[window_len:1:-1],
                 x, 2 * x[-1] - x[-1:-window_len:-1]]

    if window == 'flat':  # moving average
        w = numpy.ones(window_len, 'd')
    else:
        w = getattr(numpy, window)(window_len)

    y = numpy.convolve(w / w.sum(), s, mode='same')
    return y[window_len - 1:-window_len + 1]


def reduce_opacity(im, opacity):
    """Returns an image with reduced opacity."""
    assert opacity >= 0 and opacity <= 1
    if im.mode != 'RGBA':
        im = im.convert('RGBA')
    else:
        im = im.copy()
    alpha = im.split()[3]
    alpha = ImageEnhance.Brightness(alpha).enhance(opacity)
    im.putalpha(alpha)
    return im


def im_watermark(im, inputtext, font=None, color=None, opacity=.6, margin=(30, 30)):
    """imprints a PIL image with the indicated text in lower-right corner"""
    if im.mode != "RGBA":
        im = im.convert("RGBA")
    textlayer = Image.new("RGBA", im.size, (0, 0, 0, 0))
    textdraw = ImageDraw.Draw(textlayer)
    textsize = textdraw.textsize(inputtext, font=font)
    textpos = [im.size[i] - textsize[i] - margin[i] for i in [0, 1]]
    textdraw.text(textpos, inputtext, font=font, fill=color)
    if opacity != 1:
        textlayer = reduce_opacity(textlayer, opacity)
    return Image.composite(textlayer, im, textlayer)


def peaks(samples):
    """ Find the minimum and maximum peak of the samples.
    Returns that pair in the order they were found.
    So if min was found first, it returns (min, max) else the other way around. """
    max_index = numpy.argmax(samples)
    max_value = samples[max_index]

    min_index = numpy.argmin(samples)
    min_value = samples[min_index]

    if min_index < max_index:
        return (min_value, max_value)
    else:
        return (max_value, min_value)


def color_from_value(self, value):
    """ given a value between 0 and 1, return an (r,g,b) tuple """
    return ImageColor.getrgb("hsl(%d,%d%%,%d%%)" % (int((1.0 - value) * 360), 80, 50))


def mean(samples):
    return numpy.mean(samples)


def normalize(contour):
    contour = contour - min(contour)
    return contour / max(contour)

########NEW FILE########
__FILENAME__ = waveform_centroid
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2010 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2010 Olivier Guilyardi <olivier@samalyse.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.api import IGrapher
from . utils import peaks, interpolate_colors
from timeside.grapher.waveform_simple import Waveform
from timeside.grapher.color_schemes import default_color_schemes


class WaveformCentroid(Waveform):

    """ Builds a PIL image representing a waveform of the audio stream.
    Peaks are colored relatively to the spectral centroids of each frame buffer. """

    implements(IGrapher)

    @interfacedoc
    def __init__(self, width=1024, height=256, bg_color=(0, 0, 0), color_scheme='default'):
        super(WaveformCentroid, self).__init__(
            width, height, bg_color, color_scheme)
        self.lower_freq = 200
        colors = default_color_schemes[color_scheme]['waveform']
        self.color_lookup = interpolate_colors(colors)

    @staticmethod
    @interfacedoc
    def id():
        return "waveform_centroid"

    @staticmethod
    @interfacedoc
    def name():
        return "Waveform spectral"

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(WaveformCentroid, self).setup(
            channels, samplerate, blocksize, totalframes)

    @interfacedoc
    def process(self, frames, eod=False):
        if len(frames) != 1:
            buffer = frames[:, 0].copy()
            buffer.shape = (len(buffer), 1)
            for samples, end in self.pixels_adapter.process(buffer, eod):
                if self.pixel_cursor < self.image_width:
                    (spectral_centroid, db_spectrum) = self.spectrum.process(
                        samples, True)
                    line_color = self.color_lookup[
                        int(spectral_centroid * 255.0)]
                    self.draw_peaks(
                        self.pixel_cursor, peaks(samples), line_color)
                    self.pixel_cursor += 1
        return frames, eod

########NEW FILE########
__FILENAME__ = waveform_contour
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2010 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2010 Olivier Guilyardi <olivier@samalyse.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.api import IGrapher
#from timeside.grapher.core import *
from . waveform_simple import Waveform
from . utils import peaks

import numpy


class WaveformContourBlack(Waveform):

    """ Builds a PIL image representing an amplitude coutour (envelop) of the audio stream.
    """

    implements(IGrapher)

    @interfacedoc
    def __init__(self, width=1024, height=256, bg_color=(0, 0, 0), color_scheme='default'):
        super(WaveformContourBlack, self).__init__(
            width, height, bg_color, color_scheme)
        self.contour = numpy.zeros(self.image_width)
        self.ndiv = 4
        self.x = numpy.r_[0:self.image_width - 1:1]
        self.symetry = True
        self.color_offset = 160

    @staticmethod
    @interfacedoc
    def id():
        return "waveform_contour_black"

    @staticmethod
    @interfacedoc
    def name():
        return "Contour black"

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(WaveformContourBlack, self).setup(
            channels, samplerate, blocksize, totalframes)

    @interfacedoc
    def process(self, frames, eod=False):
        if len(frames) != 1:
            buffer = frames[:, 0].copy()
            buffer.shape = (len(buffer), 1)
            for samples, end in self.pixels_adapter.process(buffer, eod):
                if self.pixel_cursor < self.image_width:
                    self.contour[self.pixel_cursor] = numpy.max(peaks(samples))
                    self.pixel_cursor += 1
        if eod:
            self.draw_peaks_contour()
        return frames, eod


class WaveformContourWhite(WaveformContourBlack):

    """ Builds a PIL image representing an amplitude coutour (envelop) of the audio stream.
    """

    implements(IGrapher)

    @interfacedoc
    def __init__(self, width=1024, height=256, bg_color=(255, 255, 255), color_scheme='default'):
        super(WaveformContourWhite, self).__init__(
            width, height, bg_color, color_scheme)
        self.color_offset = 60

    @staticmethod
    @interfacedoc
    def id():
        return "waveform_contour_white"

    @staticmethod
    @interfacedoc
    def name():
        return "Contour white"

########NEW FILE########
__FILENAME__ = waveform_simple
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2010 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2010 Olivier Guilyardi <olivier@samalyse.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.api import IGrapher
from timeside.grapher.core import Grapher
from . utils import peaks


class Waveform(Grapher):

    """ Builds a PIL image representing a simple waveform of the audio stream.
    """

    implements(IGrapher)

    @interfacedoc
    def __init__(self, width=1024, height=256, bg_color=(255, 255, 255), color_scheme='default'):
        super(Waveform, self).__init__(width, height, bg_color, color_scheme)
        self.line_color = (0, 0, 0)

    @staticmethod
    @interfacedoc
    def id():
        return "waveform_simple"

    @staticmethod
    @interfacedoc
    def name():
        return "Waveform simple"

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None, totalframes=None):
        super(Waveform, self).setup(
            channels, samplerate, blocksize, totalframes)

    @interfacedoc
    def process(self, frames, eod=False):
        if len(frames) != 1:
            if len(frames.shape) > 1:
                buffer = frames[:, 0]
            else:
                buffer = frames
            buffer.shape = (len(buffer), 1)
            for samples, end in self.pixels_adapter.process(buffer, eod):
                if self.pixel_cursor < self.image_width - 1:
                    self.draw_peaks(
                        self.pixel_cursor, peaks(samples), self.line_color)
                    self.pixel_cursor += 1
            if self.pixel_cursor == self.image_width - 1:
                self.draw_peaks(
                    self.pixel_cursor, peaks(samples), self.line_color)
                self.pixel_cursor += 1
        return frames, eod

    @interfacedoc
    def post_process(self, output=None):
        a = 1
        for x in range(self.image_width):
            self.pixel[x, self.image_height / 2] = tuple(
                map(lambda p: p + a, self.pixel[x, self.image_height / 2]))

########NEW FILE########
__FILENAME__ = waveform_transparent
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2010 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2010 Olivier Guilyardi <olivier@samalyse.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.


from timeside.core import implements, interfacedoc
from timeside.api import IGrapher
#from timeside.grapher.core import *
from timeside.grapher.waveform_simple import Waveform
from . utils import peaks


class WaveformTransparent(Waveform):

    """ Builds a PIL image representing a transparent waveform
    of the audio stream.
    """

    implements(IGrapher)

    @interfacedoc
    def __init__(self, width=1024, height=256, bg_color=None,
                 color_scheme='default'):
        super(WaveformTransparent, self).__init__(
            width, height, bg_color, color_scheme)
        self.line_color = (255, 255, 255)

    @staticmethod
    @interfacedoc
    def id():
        return "waveform_transparent"

    @staticmethod
    @interfacedoc
    def name():
        return "Waveform transparent"

    @interfacedoc
    def setup(self, channels=None, samplerate=None, blocksize=None,
              totalframes=None):
        super(WaveformTransparent, self).setup(
            channels, samplerate, blocksize, totalframes)

    @interfacedoc
    def process(self, frames, eod=False):
        if len(frames) != 1:
            buffer = frames[:, 0]
            buffer.shape = (len(buffer), 1)
            for samples, end in self.pixels_adapter.process(buffer, eod):
                if self.pixel_cursor < self.image_width - 1:
                    self.draw_peaks_inverted(
                        self.pixel_cursor, peaks(samples), self.line_color)
                    self.pixel_cursor += 1
            if self.pixel_cursor == self.image_width - 1:
                self.draw_peaks_inverted(
                    self.pixel_cursor, peaks(samples), self.line_color)
                self.pixel_cursor += 1
        return frames, eod

########NEW FILE########
__FILENAME__ = admin

from django.contrib import admin
from timeside.server.models import *

admin.site.register(Selection)
admin.site.register(Item)
admin.site.register(Experience)
admin.site.register(Processor)
admin.site.register(Preset)
admin.site.register(Result)
admin.site.register(Task)


########NEW FILE########
__FILENAME__ = celery

from __future__ import absolute_import

from celery import Celery

app = Celery('timeside',
             broker='amqp://',
             backend='amqp://',
             include=['timeside.tasks'])

# Optional configuration, see the application user guide.
app.conf.update(
    CELERY_TASK_RESULT_EXPIRES=3600,
)

if __name__ == '__main__':
    app.start()

########NEW FILE########
__FILENAME__ = 0001_initial
# -*- coding: utf-8 -*-
from south.utils import datetime_utils as datetime
from south.db import db
from south.v2 import SchemaMigration
from django.db import models


class Migration(SchemaMigration):

    def forwards(self, orm):
        # Adding model 'Selection'
        db.create_table('timeside_selections', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('date_added', self.gf('django.db.models.fields.DateTimeField')(auto_now_add=True, blank=True)),
            ('date_modified', self.gf('django.db.models.fields.DateTimeField')(auto_now=True, null=True, blank=True)),
            ('uuid', self.gf('django.db.models.fields.CharField')(unique=True, max_length=512, blank=True)),
            ('title', self.gf('django.db.models.fields.CharField')(max_length=512, blank=True)),
            ('description', self.gf('django.db.models.fields.TextField')(blank=True)),
            ('author', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='selections', null=True, on_delete=models.SET_NULL, to=orm['auth.User'])),
        ))
        db.send_create_signal('server', ['Selection'])

        # Adding M2M table for field items on 'Selection'
        m2m_table_name = db.shorten_name('timeside_selections_items')
        db.create_table(m2m_table_name, (
            ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)),
            ('selection', models.ForeignKey(orm['server.selection'], null=False)),
            ('item', models.ForeignKey(orm['server.item'], null=False))
        ))
        db.create_unique(m2m_table_name, ['selection_id', 'item_id'])

        # Adding M2M table for field selections on 'Selection'
        m2m_table_name = db.shorten_name('timeside_selections_selections')
        db.create_table(m2m_table_name, (
            ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)),
            ('from_selection', models.ForeignKey(orm['server.selection'], null=False)),
            ('to_selection', models.ForeignKey(orm['server.selection'], null=False))
        ))
        db.create_unique(m2m_table_name, ['from_selection_id', 'to_selection_id'])

        # Adding model 'Item'
        db.create_table('timeside_items', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('date_added', self.gf('django.db.models.fields.DateTimeField')(auto_now_add=True, blank=True)),
            ('date_modified', self.gf('django.db.models.fields.DateTimeField')(auto_now=True, null=True, blank=True)),
            ('uuid', self.gf('django.db.models.fields.CharField')(unique=True, max_length=512, blank=True)),
            ('title', self.gf('django.db.models.fields.CharField')(max_length=512, blank=True)),
            ('description', self.gf('django.db.models.fields.TextField')(blank=True)),
            ('file', self.gf('django.db.models.fields.files.FileField')(max_length=1024, blank=True)),
            ('url', self.gf('django.db.models.fields.URLField')(max_length=1024, blank=True)),
            ('sha1', self.gf('django.db.models.fields.CharField')(max_length=512, blank=True)),
            ('mime_type', self.gf('django.db.models.fields.CharField')(max_length=256, blank=True)),
            ('hdf5', self.gf('django.db.models.fields.files.FileField')(max_length=1024, blank=True)),
            ('author', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='items', null=True, on_delete=models.SET_NULL, to=orm['auth.User'])),
            ('lock', self.gf('django.db.models.fields.BooleanField')(default=False)),
        ))
        db.send_create_signal('server', ['Item'])

        # Adding model 'Experience'
        db.create_table('timeside_experiences', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('date_added', self.gf('django.db.models.fields.DateTimeField')(auto_now_add=True, blank=True)),
            ('date_modified', self.gf('django.db.models.fields.DateTimeField')(auto_now=True, null=True, blank=True)),
            ('uuid', self.gf('django.db.models.fields.CharField')(unique=True, max_length=512, blank=True)),
            ('title', self.gf('django.db.models.fields.CharField')(max_length=512, blank=True)),
            ('description', self.gf('django.db.models.fields.TextField')(blank=True)),
            ('author', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='experiences', null=True, on_delete=models.SET_NULL, to=orm['auth.User'])),
            ('is_public', self.gf('django.db.models.fields.BooleanField')(default=False)),
        ))
        db.send_create_signal('server', ['Experience'])

        # Adding M2M table for field presets on 'Experience'
        m2m_table_name = db.shorten_name('timeside_experiences_presets')
        db.create_table(m2m_table_name, (
            ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)),
            ('experience', models.ForeignKey(orm['server.experience'], null=False)),
            ('preset', models.ForeignKey(orm['server.preset'], null=False))
        ))
        db.create_unique(m2m_table_name, ['experience_id', 'preset_id'])

        # Adding M2M table for field experiences on 'Experience'
        m2m_table_name = db.shorten_name('timeside_experiences_experiences')
        db.create_table(m2m_table_name, (
            ('id', models.AutoField(verbose_name='ID', primary_key=True, auto_created=True)),
            ('from_experience', models.ForeignKey(orm['server.experience'], null=False)),
            ('to_experience', models.ForeignKey(orm['server.experience'], null=False))
        ))
        db.create_unique(m2m_table_name, ['from_experience_id', 'to_experience_id'])

        # Adding model 'Processor'
        db.create_table('timeside_processors', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('pid', self.gf('django.db.models.fields.CharField')(max_length=256)),
            ('version', self.gf('django.db.models.fields.CharField')(max_length=64, blank=True)),
        ))
        db.send_create_signal('server', ['Processor'])

        # Adding model 'Preset'
        db.create_table('timeside_presets', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('date_added', self.gf('django.db.models.fields.DateTimeField')(auto_now_add=True, blank=True)),
            ('date_modified', self.gf('django.db.models.fields.DateTimeField')(auto_now=True, null=True, blank=True)),
            ('uuid', self.gf('django.db.models.fields.CharField')(unique=True, max_length=512, blank=True)),
            ('processor', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='presets', null=True, to=orm['server.Processor'])),
            ('parameters', self.gf('django.db.models.fields.TextField')(blank=True)),
            ('author', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='presets', null=True, on_delete=models.SET_NULL, to=orm['auth.User'])),
            ('is_public', self.gf('django.db.models.fields.BooleanField')(default=False)),
        ))
        db.send_create_signal('server', ['Preset'])

        # Adding model 'Result'
        db.create_table('timeside_results', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('date_added', self.gf('django.db.models.fields.DateTimeField')(auto_now_add=True, blank=True)),
            ('date_modified', self.gf('django.db.models.fields.DateTimeField')(auto_now=True, null=True, blank=True)),
            ('uuid', self.gf('django.db.models.fields.CharField')(unique=True, max_length=512, blank=True)),
            ('item', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='results', null=True, on_delete=models.SET_NULL, to=orm['server.Item'])),
            ('preset', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='results', null=True, on_delete=models.SET_NULL, to=orm['server.Preset'])),
            ('hdf5', self.gf('django.db.models.fields.files.FileField')(max_length=1024, blank=True)),
            ('file', self.gf('django.db.models.fields.files.FileField')(max_length=1024, blank=True)),
            ('mime_type', self.gf('django.db.models.fields.CharField')(max_length=256, blank=True)),
            ('status', self.gf('django.db.models.fields.IntegerField')(default=1)),
            ('author', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='results', null=True, on_delete=models.SET_NULL, to=orm['auth.User'])),
        ))
        db.send_create_signal('server', ['Result'])

        # Adding model 'Task'
        db.create_table('timeside_tasks', (
            ('id', self.gf('django.db.models.fields.AutoField')(primary_key=True)),
            ('date_added', self.gf('django.db.models.fields.DateTimeField')(auto_now_add=True, blank=True)),
            ('date_modified', self.gf('django.db.models.fields.DateTimeField')(auto_now=True, null=True, blank=True)),
            ('uuid', self.gf('django.db.models.fields.CharField')(unique=True, max_length=512, blank=True)),
            ('experience', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='task', null=True, to=orm['server.Experience'])),
            ('selection', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='task', null=True, to=orm['server.Selection'])),
            ('status', self.gf('django.db.models.fields.IntegerField')(default=1)),
            ('author', self.gf('django.db.models.fields.related.ForeignKey')(blank=True, related_name='tasks', null=True, on_delete=models.SET_NULL, to=orm['auth.User'])),
        ))
        db.send_create_signal('server', ['Task'])


    def backwards(self, orm):
        # Deleting model 'Selection'
        db.delete_table('timeside_selections')

        # Removing M2M table for field items on 'Selection'
        db.delete_table(db.shorten_name('timeside_selections_items'))

        # Removing M2M table for field selections on 'Selection'
        db.delete_table(db.shorten_name('timeside_selections_selections'))

        # Deleting model 'Item'
        db.delete_table('timeside_items')

        # Deleting model 'Experience'
        db.delete_table('timeside_experiences')

        # Removing M2M table for field presets on 'Experience'
        db.delete_table(db.shorten_name('timeside_experiences_presets'))

        # Removing M2M table for field experiences on 'Experience'
        db.delete_table(db.shorten_name('timeside_experiences_experiences'))

        # Deleting model 'Processor'
        db.delete_table('timeside_processors')

        # Deleting model 'Preset'
        db.delete_table('timeside_presets')

        # Deleting model 'Result'
        db.delete_table('timeside_results')

        # Deleting model 'Task'
        db.delete_table('timeside_tasks')


    models = {
        'auth.group': {
            'Meta': {'object_name': 'Group'},
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'name': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '80'}),
            'permissions': ('django.db.models.fields.related.ManyToManyField', [], {'to': "orm['auth.Permission']", 'symmetrical': 'False', 'blank': 'True'})
        },
        'auth.permission': {
            'Meta': {'ordering': "('content_type__app_label', 'content_type__model', 'codename')", 'unique_together': "(('content_type', 'codename'),)", 'object_name': 'Permission'},
            'codename': ('django.db.models.fields.CharField', [], {'max_length': '100'}),
            'content_type': ('django.db.models.fields.related.ForeignKey', [], {'to': "orm['contenttypes.ContentType']"}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'name': ('django.db.models.fields.CharField', [], {'max_length': '50'})
        },
        'auth.user': {
            'Meta': {'object_name': 'User'},
            'date_joined': ('django.db.models.fields.DateTimeField', [], {'default': 'datetime.datetime.now'}),
            'email': ('django.db.models.fields.EmailField', [], {'max_length': '75', 'blank': 'True'}),
            'first_name': ('django.db.models.fields.CharField', [], {'max_length': '30', 'blank': 'True'}),
            'groups': ('django.db.models.fields.related.ManyToManyField', [], {'to': "orm['auth.Group']", 'symmetrical': 'False', 'blank': 'True'}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'is_active': ('django.db.models.fields.BooleanField', [], {'default': 'True'}),
            'is_staff': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),
            'is_superuser': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),
            'last_login': ('django.db.models.fields.DateTimeField', [], {'default': 'datetime.datetime.now'}),
            'last_name': ('django.db.models.fields.CharField', [], {'max_length': '30', 'blank': 'True'}),
            'password': ('django.db.models.fields.CharField', [], {'max_length': '128'}),
            'user_permissions': ('django.db.models.fields.related.ManyToManyField', [], {'to': "orm['auth.Permission']", 'symmetrical': 'False', 'blank': 'True'}),
            'username': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '30'})
        },
        'contenttypes.contenttype': {
            'Meta': {'ordering': "('name',)", 'unique_together': "(('app_label', 'model'),)", 'object_name': 'ContentType', 'db_table': "'django_content_type'"},
            'app_label': ('django.db.models.fields.CharField', [], {'max_length': '100'}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'model': ('django.db.models.fields.CharField', [], {'max_length': '100'}),
            'name': ('django.db.models.fields.CharField', [], {'max_length': '100'})
        },
        'server.experience': {
            'Meta': {'object_name': 'Experience', 'db_table': "'timeside_experiences'"},
            'author': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'experiences'", 'null': 'True', 'on_delete': 'models.SET_NULL', 'to': "orm['auth.User']"}),
            'date_added': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),
            'date_modified': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'null': 'True', 'blank': 'True'}),
            'description': ('django.db.models.fields.TextField', [], {'blank': 'True'}),
            'experiences': ('django.db.models.fields.related.ManyToManyField', [], {'blank': 'True', 'related_name': "'other_experiences'", 'null': 'True', 'symmetrical': 'False', 'to': "orm['server.Experience']"}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'is_public': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),
            'presets': ('django.db.models.fields.related.ManyToManyField', [], {'blank': 'True', 'related_name': "'experiences'", 'null': 'True', 'symmetrical': 'False', 'to': "orm['server.Preset']"}),
            'title': ('django.db.models.fields.CharField', [], {'max_length': '512', 'blank': 'True'}),
            'uuid': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '512', 'blank': 'True'})
        },
        'server.item': {
            'Meta': {'ordering': "['title']", 'object_name': 'Item', 'db_table': "'timeside_items'"},
            'author': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'items'", 'null': 'True', 'on_delete': 'models.SET_NULL', 'to': "orm['auth.User']"}),
            'date_added': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),
            'date_modified': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'null': 'True', 'blank': 'True'}),
            'description': ('django.db.models.fields.TextField', [], {'blank': 'True'}),
            'file': ('django.db.models.fields.files.FileField', [], {'max_length': '1024', 'blank': 'True'}),
            'hdf5': ('django.db.models.fields.files.FileField', [], {'max_length': '1024', 'blank': 'True'}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'lock': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),
            'mime_type': ('django.db.models.fields.CharField', [], {'max_length': '256', 'blank': 'True'}),
            'sha1': ('django.db.models.fields.CharField', [], {'max_length': '512', 'blank': 'True'}),
            'title': ('django.db.models.fields.CharField', [], {'max_length': '512', 'blank': 'True'}),
            'url': ('django.db.models.fields.URLField', [], {'max_length': '1024', 'blank': 'True'}),
            'uuid': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '512', 'blank': 'True'})
        },
        'server.preset': {
            'Meta': {'object_name': 'Preset', 'db_table': "'timeside_presets'"},
            'author': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'presets'", 'null': 'True', 'on_delete': 'models.SET_NULL', 'to': "orm['auth.User']"}),
            'date_added': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),
            'date_modified': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'null': 'True', 'blank': 'True'}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'is_public': ('django.db.models.fields.BooleanField', [], {'default': 'False'}),
            'parameters': ('django.db.models.fields.TextField', [], {'blank': 'True'}),
            'processor': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'presets'", 'null': 'True', 'to': "orm['server.Processor']"}),
            'uuid': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '512', 'blank': 'True'})
        },
        'server.processor': {
            'Meta': {'object_name': 'Processor', 'db_table': "'timeside_processors'"},
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'pid': ('django.db.models.fields.CharField', [], {'max_length': '256'}),
            'version': ('django.db.models.fields.CharField', [], {'max_length': '64', 'blank': 'True'})
        },
        'server.result': {
            'Meta': {'object_name': 'Result', 'db_table': "'timeside_results'"},
            'author': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'results'", 'null': 'True', 'on_delete': 'models.SET_NULL', 'to': "orm['auth.User']"}),
            'date_added': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),
            'date_modified': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'null': 'True', 'blank': 'True'}),
            'file': ('django.db.models.fields.files.FileField', [], {'max_length': '1024', 'blank': 'True'}),
            'hdf5': ('django.db.models.fields.files.FileField', [], {'max_length': '1024', 'blank': 'True'}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'item': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'results'", 'null': 'True', 'on_delete': 'models.SET_NULL', 'to': "orm['server.Item']"}),
            'mime_type': ('django.db.models.fields.CharField', [], {'max_length': '256', 'blank': 'True'}),
            'preset': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'results'", 'null': 'True', 'on_delete': 'models.SET_NULL', 'to': "orm['server.Preset']"}),
            'status': ('django.db.models.fields.IntegerField', [], {'default': '1'}),
            'uuid': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '512', 'blank': 'True'})
        },
        'server.selection': {
            'Meta': {'object_name': 'Selection', 'db_table': "'timeside_selections'"},
            'author': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'selections'", 'null': 'True', 'on_delete': 'models.SET_NULL', 'to': "orm['auth.User']"}),
            'date_added': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),
            'date_modified': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'null': 'True', 'blank': 'True'}),
            'description': ('django.db.models.fields.TextField', [], {'blank': 'True'}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'items': ('django.db.models.fields.related.ManyToManyField', [], {'blank': 'True', 'related_name': "'selections'", 'null': 'True', 'symmetrical': 'False', 'to': "orm['server.Item']"}),
            'selections': ('django.db.models.fields.related.ManyToManyField', [], {'blank': 'True', 'related_name': "'other_selections'", 'null': 'True', 'symmetrical': 'False', 'to': "orm['server.Selection']"}),
            'title': ('django.db.models.fields.CharField', [], {'max_length': '512', 'blank': 'True'}),
            'uuid': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '512', 'blank': 'True'})
        },
        'server.task': {
            'Meta': {'object_name': 'Task', 'db_table': "'timeside_tasks'"},
            'author': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'tasks'", 'null': 'True', 'on_delete': 'models.SET_NULL', 'to': "orm['auth.User']"}),
            'date_added': ('django.db.models.fields.DateTimeField', [], {'auto_now_add': 'True', 'blank': 'True'}),
            'date_modified': ('django.db.models.fields.DateTimeField', [], {'auto_now': 'True', 'null': 'True', 'blank': 'True'}),
            'experience': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'task'", 'null': 'True', 'to': "orm['server.Experience']"}),
            'id': ('django.db.models.fields.AutoField', [], {'primary_key': 'True'}),
            'selection': ('django.db.models.fields.related.ForeignKey', [], {'blank': 'True', 'related_name': "'task'", 'null': 'True', 'to': "orm['server.Selection']"}),
            'status': ('django.db.models.fields.IntegerField', [], {'default': '1'}),
            'uuid': ('django.db.models.fields.CharField', [], {'unique': 'True', 'max_length': '512', 'blank': 'True'})
        }
    }

    complete_apps = ['server']
########NEW FILE########
__FILENAME__ = models
# -*- coding: utf-8 -*-
#
# Copyright (c) 2014 Parisson SARL
# Copyright (c) 2014 Guillaume Pellerin <yomguy@parisson.com>
# Copyright (c) 2014 Thomas Fillon <thomas@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Authors:
# Guillaume Pellerin <yomguy@parisson.com>
# Thomas Fillon <thomas@parisson.com>

import timeside, os, uuid, time, hashlib, mimetypes

from timeside.analyzer.core import AnalyzerResultContainer, AnalyzerResult
from timeside.decoder.utils import sha1sum_file

from django.db import models
from django.utils.translation import ugettext_lazy as _
from django.contrib.auth.models import User
from django.db.models.signals import post_save
from django.conf import settings

app = 'timeside'

processors = timeside.core.processors(timeside.api.IProcessor)

PROCESSOR_PIDS = [(processor.id(), processor.id())  for processor in processors]

STATUS = ((0, _('failed')), (1, _('draft')), (2, _('pending')),
                         (3, _('running')), (4, _('done')))

def get_mime_type(path):
    return mimetypes.guess_type(path)[0]

def get_processor(pid):
    for proc in processors:
        if proc.id() == pid:
            return proc
    raise ValueError('Processor %s does not exists' % pid) 


class MetaCore:

    app_label = 'server'
 

class BaseResource(models.Model):

    date_added = models.DateTimeField(_('date added'), auto_now_add=True)
    date_modified = models.DateTimeField(_('date modified'), auto_now=True, null=True)
    uuid = models.CharField(_('uuid'), unique=True, blank=True, max_length=512)

    class Meta(MetaCore):
        abstract = True
    
    def save(self, **kwargs):
        if not self.uuid:
            self.uuid = uuid.uuid4()
        super(BaseResource, self).save(**kwargs)


class DocBaseResource(BaseResource):

    title = models.CharField(_('title'), blank=True, max_length=512)
    description = models.TextField(_('description'), blank=True)

    def __unicode__(self):
        return self.title    
    
    class Meta(MetaCore):
        abstract = True
    

class Selection(DocBaseResource):

    items = models.ManyToManyField('Item', related_name="selections", verbose_name=_('items'), blank=True, null=True)
    selections = models.ManyToManyField('Selection', related_name="other_selections", verbose_name=_('other selections'), blank=True, null=True)
    author = models.ForeignKey(User, related_name="selections", verbose_name=_('author'), blank=True, null=True, on_delete=models.SET_NULL)

    class Meta(MetaCore):
        db_table = app + '_selections'
        verbose_name = _('selection')


class Item(DocBaseResource):

    file = models.FileField(_('file'), upload_to='items/%Y/%m/%d', blank=True, max_length=1024)
    url = models.URLField(_('URL'), blank=True, max_length=1024)
    sha1 = models.CharField(_('sha1'), blank=True, max_length=512)
    mime_type = models.CharField(_('mime type'), blank=True, max_length=256)
    hdf5 = models.FileField(_('HDF5 result file'), upload_to='results/%Y/%m/%d', blank=True, max_length=1024)
    author = models.ForeignKey(User, related_name="items", verbose_name=_('author'), blank=True, null=True, on_delete=models.SET_NULL)
    lock = models.BooleanField(default=False)

    class Meta(MetaCore):
        db_table = app + '_items'
        ordering = ['title']
        verbose_name = _('item')

    def results(self):
        return [result for result in self.results.all()]

    def lock_setter(self, lock):
        self.lock = lock
        self.save()


class Experience(DocBaseResource):

    presets = models.ManyToManyField('Preset', related_name="experiences", verbose_name=_('presets'), blank=True, null=True)
    experiences = models.ManyToManyField('Experience', related_name="other_experiences", verbose_name=_('other experiences'), blank=True, null=True)
    author = models.ForeignKey(User, related_name="experiences", verbose_name=_('author'), blank=True, null=True, on_delete=models.SET_NULL)    
    is_public = models.BooleanField(default=False)

    class Meta(MetaCore):
        db_table = app + '_experiences'
        verbose_name = _('Experience')


class Processor(models.Model):
    
    pid = models.CharField(_('pid'), choices=PROCESSOR_PIDS, max_length=256)
    version = models.CharField(_('version'), max_length=64, blank=True)

    class Meta(MetaCore):
        db_table = app + '_processors'
        verbose_name = _('processor')

    def __unicode__(self):
        return '_'.join([self.pid, str(self.id)])
    
    def save(self, **kwargs):
        if not self.version:
            self.version = timeside.__version__
        super(Processor, self).save(**kwargs)
        

class Preset(BaseResource):

    processor = models.ForeignKey('Processor', related_name="presets", verbose_name=_('processor'), blank=True, null=True)
    parameters = models.TextField(_('Parameters'), blank=True)
    author = models.ForeignKey(User, related_name="presets", verbose_name=_('author'), blank=True, null=True, on_delete=models.SET_NULL)    
    is_public = models.BooleanField(default=False)

    class Meta(MetaCore):
        db_table = app + '_presets'
        verbose_name = _('Preset')
        verbose_name_plural = _('Presets')

    def __unicode__(self):
        return '_'.join([unicode(self.processor), str(self.id)])

    
class Result(BaseResource):

    item = models.ForeignKey('Item', related_name="results", verbose_name=_('item'), blank=True, null=True, on_delete=models.SET_NULL)
    preset = models.ForeignKey('Preset', related_name="results", verbose_name=_('preset'), blank=True, null=True, on_delete=models.SET_NULL)
    hdf5 = models.FileField(_('HDF5 result file'), upload_to='results/%Y/%m/%d', blank=True, max_length=1024)
    file = models.FileField(_('Output file'), upload_to='results/%Y/%m/%d', blank=True, max_length=1024)
    mime_type = models.CharField(_('Output file MIME type'), blank=True, max_length=256)
    status = models.IntegerField(_('status'), choices=STATUS, default=1)
    author = models.ForeignKey(User, related_name="results", verbose_name=_('author'), blank=True, null=True, on_delete=models.SET_NULL)    

    class Meta(MetaCore):
        db_table = app + '_results'
        verbose_name = _('Result')
        verbose_name_plural = _('Results')

    def status_setter(self, status):
        self.status = status
        self.save()

    def __unicode__(self):
        return '_'.join([self.item.title, unicode(self.parameters.processor)])


class Task(BaseResource):

    experience = models.ForeignKey('Experience', related_name="task", verbose_name=_('experience'), blank=True, null=True)
    selection = models.ForeignKey('Selection', related_name="task", verbose_name=_('selection'), blank=True, null=True)
    status = models.IntegerField(_('status'), choices=STATUS, default=1)
    author = models.ForeignKey(User, related_name="tasks", verbose_name=_('author'), blank=True, null=True, on_delete=models.SET_NULL)    

    class Meta(MetaCore):
        db_table = app + '_tasks'
        verbose_name = _('Task')
        verbose_name_plural = _('Tasks')

    def __unicode__(self):
        return '_'.join([unicode(self.experience), unicode(self.id)])

    def status_setter(self, status):
        self.status = status
        self.save()

    def run(self):
        self.status_setter(3)

        results_root = 'results'
        if not os.path.exists(settings.MEDIA_ROOT + results_root):
            os.makedirs(settings.MEDIA_ROOT + results_root)

        for item in self.selection.items.all():
            path = results_root + os.sep + item.uuid + os.sep
            if not os.path.exists(settings.MEDIA_ROOT + os.sep + path):
                os.makedirs(settings.MEDIA_ROOT + os.sep + path)
            
            pipe = timeside.decoder.FileDecoder(item.file.path, sha1=item.sha1)
            
            presets = {}
            for preset in self.experience.presets.all():
                proc = get_processor(preset.processor.pid)
                if proc.type == 'encoder':
                    result, c = Result.objects.get_or_create(preset=preset, item=item)
                    result.file = path + str(result.uuid) + '.' + proc.file_extension()
                    result.save()
                    proc = proc(result.file.path, overwrite=True)
                else:
                    proc = proc()
                #proc.set_parameters(preset.parameters)
                presets[preset] = proc
                pipe = pipe | proc

            # while item.lock:
            #     time.sleep(30)
            
            if not item.hdf5:
                item.hdf5 =  path + str(self.experience.uuid) + '.hdf5'
                item.save()

            pipe.run()
            item.lock_setter(True)
            pipe.results.to_hdf5(item.hdf5.path)
            item.lock_setter(False)
            
            for preset in presets.keys():
                proc = presets[preset]
                if proc.type == 'analyzer':                    
                    for processor_id in proc.results.keys():
                        parameters = proc.results[processor_id].parameters
                        preset, c = Preset.objects.get_or_create(processor=preset.processor, parameters=unicode(parameters))
                        result, c = Result.objects.get_or_create(preset=preset, item=item)
                        result.hdf5 = path + str(result.uuid) + '.hdf5'
                        proc.results.to_hdf5(result.hdf5.path)
                        result.status_setter(4)
                elif proc.type == 'grapher':
                    parameters = {}
                    result, c = Result.objects.get_or_create(preset=preset, item=item)
                    result.file = path + str(result.uuid) + '.png'
                    proc.render(output=result.file.path)
                    result.status_setter(4)
                elif proc.type == 'encoder':
                    result = Result.objects.get(preset=preset, item=item)
                    result.status_setter(4)
                del proc
            
            # except:
            #     self.status_setter(0)
            #     item.lock_setter(False)
            #     break
        
        self.status_setter(4)
        del pipe


def set_mimetype(sender, **kwargs):
    instance = kwargs['instance']
    if instance.file:
        if not instance.mime_type:
            instance.mime_type = get_mime_type(instance.file.path)

def set_hash(sender, **kwargs):
    instance = kwargs['instance']
    if instance.file:
        if not instance.sha1:
            instance.sha1 = sha1sum_file(instance.file.path)

def run(sender, **kwargs):
    instance = kwargs['instance']
    if instance.status == 2:
        instance.run()


post_save.connect(set_mimetype, sender=Item)
post_save.connect(set_hash, sender=Item)
post_save.connect(set_mimetype, sender=Result)
post_save.connect(run, sender=Task)


########NEW FILE########
__FILENAME__ = manage
#!/usr/bin/env python
import os
import sys

if __name__ == "__main__":
    os.environ.setdefault("DJANGO_SETTINGS_MODULE", "settings")

    from django.core.management import execute_from_command_line

    execute_from_command_line(sys.argv)

########NEW FILE########
__FILENAME__ = settings
# Django settings for server project.

DEBUG = True
TEMPLATE_DEBUG = DEBUG

import os, sys
sys.dont_write_bytecode = True

ADMINS = (
    # ('Your Name', 'your_email@example.com'),
)

MANAGERS = ADMINS

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3', # Add 'postgresql_psycopg2', 'mysql', 'sqlite3' or 'oracle'.
        'NAME': 'timeside.sql',                      # Or path to database file if using sqlite3.
        'USER': '',                      # Not used with sqlite3.
        'PASSWORD': '',                  # Not used with sqlite3.
        'HOST': '',                      # Set to empty string for localhost. Not used with sqlite3.
        'PORT': '',                      # Set to empty string for default. Not used with sqlite3.
    }
}

# Hosts/domain names that are valid for this site; required if DEBUG is False
# See https://docs.djangoproject.com/en/1.4/ref/settings/#allowed-hosts
ALLOWED_HOSTS = []

# Local time zone for this installation. Choices can be found here:
# http://en.wikipedia.org/wiki/List_of_tz_zones_by_name
# although not all choices may be available on all operating systems.
# In a Windows environment this must be set to your system time zone.
TIME_ZONE = 'Europe/Paris'

# Language code for this installation. All choices can be found here:
# http://www.i18nguy.com/unicode/language-identifiers.html
LANGUAGE_CODE = 'fr-fr'

SITE_ID = 1

# If you set this to False, Django will make some optimizations so as not
# to load the internationalization machinery.
USE_I18N = True

# If you set this to False, Django will not format dates, numbers and
# calendars according to the current locale.
USE_L10N = True

# If you set this to False, Django will not use timezone-aware datetimes.
USE_TZ = True

# Full filesystem path to the project.
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))

# Absolute filesystem path to the directory that will hold user-uploaded files.
# Example: "/home/media/media.lawrence.com/media/"
MEDIA_ROOT = PROJECT_ROOT + '/media/'

# URL that handles the media served from MEDIA_ROOT. Make sure to use a
# trailing slash.
# Examples: "http://media.lawrence.com/media/", "http://example.com/media/"
MEDIA_URL = ''

# Absolute path to the directory static files should be collected to.
# Don't put anything in this directory yourself; store your static files
# in apps' "static/" subdirectories and in STATICFILES_DIRS.
# Example: "/home/media/media.lawrence.com/static/"
STATIC_ROOT = ''

# URL prefix for static files.
# Example: "http://media.lawrence.com/static/"
STATIC_URL = '/static/'

# Additional locations of static files
STATICFILES_DIRS = (
    # Put strings here, like "/home/html/static" or "C:/www/django/static".
    # Always use forward slashes, even on Windows.
    # Don't forget to use absolute paths, not relative paths.
)

# List of finder classes that know how to find static files in
# various locations.
STATICFILES_FINDERS = (
    'django.contrib.staticfiles.finders.FileSystemFinder',
    'django.contrib.staticfiles.finders.AppDirectoriesFinder',
#    'django.contrib.staticfiles.finders.DefaultStorageFinder',
)

# Make this unique, and don't share it with anybody.
SECRET_KEY = '5%z&amp;a3r@t0=xr2eaio+400qf-32$b5zp897pr*wh5i^s4(-+3('

# List of callables that know how to import templates from various sources.
TEMPLATE_LOADERS = (
    'django.template.loaders.filesystem.Loader',
    'django.template.loaders.app_directories.Loader',
#    'django.template.loaders.eggs.Loader',
)

MIDDLEWARE_CLASSES = (
    'django.middleware.common.CommonMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    # Uncomment the next line for simple clickjacking protection:
    # 'django.middleware.clickjacking.XFrameOptionsMiddleware',
)

ROOT_URLCONF = 'urls'

# Python dotted path to the WSGI application used by Django's runserver.
WSGI_APPLICATION = 'wsgi.application'

TEMPLATE_DIRS = (
    # Put strings here, like "/home/html/django_templates" or "C:/www/django/templates".
    # Always use forward slashes, even on Windows.
    # Don't forget to use absolute paths, not relative paths.
)

INSTALLED_APPS = (
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.sites',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    # Uncomment the next line to enable the admin:
    'django.contrib.admin',
    # Uncomment the next line to enable admin documentation:
    # 'django.contrib.admindocs',
    'django_extensions',
    'south',
    'timeside.server',
    'timeside.player',
    'rest_framework',
)

# A sample logging configuration. The only tangible logging
# performed by this configuration is to send an email to
# the site admins on every HTTP 500 error when DEBUG=False.
# See http://docs.djangoproject.com/en/dev/topics/logging for
# more details on how to customize your logging configuration.
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'filters': {
        'require_debug_false': {
            '()': 'django.utils.log.RequireDebugFalse'
        }
    },
    'handlers': {
        'mail_admins': {
            'level': 'ERROR',
            'filters': ['require_debug_false'],
            'class': 'django.utils.log.AdminEmailHandler'
        }
    },
    'loggers': {
        'django.request': {
            'handlers': ['mail_admins'],
            'level': 'ERROR',
            'propagate': True,
        },
    }
}

REST_FRAMEWORK = {
}
########NEW FILE########
__FILENAME__ = urls
from django.conf.urls import patterns, include, url

# Uncomment the next two lines to enable the admin:
from django.contrib import admin
admin.autodiscover()

urlpatterns = patterns('',

    url(r'^', include('timeside.server.urls')),

    # Examples:
    # url(r'^$', 'server.views.home', name='home'),
    # url(r'^server/', include('server.foo.urls')),

    # Uncomment the admin/doc line below to enable admin documentation:
    # url(r'^admin/doc/', include('django.contrib.admindocs.urls')),

    # Uncomment the next line to enable the admin:
    url(r'^admin/', include(admin.site.urls)),
)

########NEW FILE########
__FILENAME__ = wsgi
"""
WSGI config for server project.

This module contains the WSGI application used by Django's development server
and any production WSGI deployments. It should expose a module-level variable
named ``application``. Django's ``runserver`` and ``runfcgi`` commands discover
this application via the ``WSGI_APPLICATION`` setting.

Usually you will have the standard Django WSGI application here, but it also
might make sense to replace the whole Django WSGI application with a custom one
that later delegates to the Django one. For example, you could introduce WSGI
middleware here, or combine a Django application with an application of another
framework.

"""
import os

os.environ.setdefault("DJANGO_SETTINGS_MODULE", "sandbox.settings")

# This application object is used by any WSGI server configured to use this
# file. This includes Django's development server, if the WSGI_APPLICATION
# setting points here.
from django.core.wsgi import get_wsgi_application
application = get_wsgi_application()

# Apply WSGI middleware here.
# from helloworld.wsgi import HelloWorldApplication
# application = HelloWorldApplication(application)

########NEW FILE########
__FILENAME__ = serializers
# -*- coding: utf-8 -*-
#
# Copyright (c) 2007-2014 Guillaume Pellerin <yomguy@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

from timeside.server.models import *
from rest_framework import serializers
import django.db.models
from django.contrib.auth.models import User


class SelectionSerializer(serializers.ModelSerializer):

    class Meta:
        model = Selection
        # fields = ('id', 'items', 'selections', 'author')


class ItemSerializer(serializers.ModelSerializer):

    class Meta:
        model = Item
        # fields = ('id', 'title', 'file', 'mime_type', 'author')


class ExperienceSerializer(serializers.ModelSerializer):

    class Meta:
        model = Experience
        # fields = ('id', 'presets', 'experiences', 'is_public', 'author')


class ProcessorSerializer(serializers.ModelSerializer):

    class Meta:
        model = Processor
        # fields = ('id', 'pid', 'version')


class ResultSerializer(serializers.ModelSerializer):

    class Meta:
        model = Result
        # fields = ('id', 'item', 'preset', 'status', 'hdf5', 'file')


class PresetSerializer(serializers.ModelSerializer):

    class Meta:
        model = Preset
        # fields = ('id', 'processor', 'parameters', 'is_public')


class TaskSerializer(serializers.ModelSerializer):

    class Meta:
        model = Task
        # fields = ('id', 'experience', 'selection', 'status', 'author')


class UserSerializer(serializers.ModelSerializer):

    class Meta:
        model = User



########NEW FILE########
__FILENAME__ = tasks

from __future__ import absolute_import

from timeside.server.celery import app


@app.task
def process(pipe):
    pipe.run()

########NEW FILE########
__FILENAME__ = urls
# -*- coding: utf-8 -*-

from django.conf.urls import patterns, include, url
from django.contrib import admin
from rest_framework import routers
from timeside.server import views

admin.autodiscover()

api_router = routers.DefaultRouter()
api_router.register(r'selections', views.SelectionViewSet)
api_router.register(r'items', views.ItemViewSet)
api_router.register(r'experiences', views.ExperienceViewSet)
api_router.register(r'processors', views.ProcessorViewSet)
api_router.register(r'results', views.ResultViewSet)
api_router.register(r'presets', views.PresetViewSet)
api_router.register(r'tasks', views.TaskViewSet)
api_router.register(r'users', views.UserViewSet)

urlpatterns = patterns(
    '',
    url(r'^admin/', include(admin.site.urls)),
    url(r'^api/', include(api_router.urls)),
    url(r'^$', views.IndexView.as_view(), name="timeside-index"),
    url(r'^results/(?P<pk>.*)/json/$', views.ResultAnalyzerView.as_view(),
        name="timeside-result-json"),
    url(r'^results/(?P<pk>.*)/png/$', views.ResultGrapherView.as_view(),
        name="timeside-result-png"),
    )

########NEW FILE########
__FILENAME__ = views
# -*- coding: utf-8 -*-
#
# Copyright (c) 2014 Parisson SARL
# Copyright (c) 2014 Guillaume Pellerin <yomguy@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.
#
# Author : Guillaume Pellerin <yomguy@parisson.com>


from django.views.generic import *
from django.http import HttpResponse, HttpResponseRedirect

from rest_framework import viewsets

import timeside
from timeside.server.models import *
from timeside.server.serializers import *


def stream_from_file(file):
    chunk_size = 0x10000
    f = open(file, 'r')
    while True:
        chunk = f.read(chunk_size)
        if not len(chunk):
            f.close()
            break
        yield chunk


class SelectionViewSet(viewsets.ModelViewSet):

    model = Selection
    serializer_class = SelectionSerializer


class ItemViewSet(viewsets.ModelViewSet):

    model = Item
    serializer_class = ItemSerializer


class ExperienceViewSet(viewsets.ModelViewSet):

    model = Experience
    serializer_class = ExperienceSerializer


class ProcessorViewSet(viewsets.ModelViewSet):

    model = Processor
    serializer_class = ProcessorSerializer


class ResultViewSet(viewsets.ModelViewSet):

    model = Result
    serializer_class = ResultSerializer


class PresetViewSet(viewsets.ModelViewSet):

    model = Preset
    serializer_class = PresetSerializer


class TaskViewSet(viewsets.ModelViewSet):

    model = Task
    serializer_class = TaskSerializer


class UserViewSet(viewsets.ModelViewSet):

    model = User
    serializer_class = UserSerializer


class IndexView(ListView):

    model = Item
    template_name = 'timeside/index.html'

    def get_context_data(self, **kwargs):
        context = super(IndexView, self).get_context_data(**kwargs)
        return context

    def dispatch(self, *args, **kwargs):
        return super(IndexView, self).dispatch(*args, **kwargs)


class ResultAnalyzerView(View):

    model = Result

    def get(self, request, *args, **kwargs):
        result = Result.objects.get(pk=kwargs['pk'])
        container = AnalyzerResultContainer()
        return HttpResponse(container.from_hdf5(result.hdf5.path).to_json(),
                            mimetype='application/json')


class ResultGrapherView(View):

    model = Result

    def get(self, request, *args, **kwargs):
        result = Result.objects.get(pk=kwargs['pk'])
        return HttpResponse(stream_from_file(result.file.path), 
                            mimetype='image/png')


########NEW FILE########
__FILENAME__ = cache
#!/usr/bin/python
# -*- coding: utf-8 -*-
#
# Copyright (C) 2006-2010 Guillaume Pellerin

# <yomguy@parisson.com>

# This software is a computer program whose purpose is to stream audio
# and video data through icecast2 servers.

# This software is governed by the CeCILL license under French law and
# abiding by the rules of distribution of free software. You can use,
# modify and/ or redistribute the software under the terms of the CeCILL
# license as circulated by CEA, CNRS and INRIA at the following URL
# "http://www.cecill.info".

# As a counterpart to the access to the source code and  rights to copy,
# modify and redistribute granted by the license, users are provided only
# with a limited warranty and the software's author, the holder of the
# economic rights, and the successive licensors have only limited
# liability.

# In this respect, the user's attention is drawn to the risks associated
# with loading, using,  modifying and/or developing or reproducing the
# software by the user in light of its specific status of free software,
# that may mean that it is complicated to manipulate, and that also
# therefore means that it is reserved for developers and  experienced
# professionals having in-depth computer knowledge. Users are therefore
# encouraged to load and test the software's suitability as regards their
# requirements in conditions enabling the security of their systems and/or
# data to be ensured and, more generally, to use and operate it in the
# same conditions as regards security.

# The fact that you are presently reading this means that you have had
# knowledge of the CeCILL license and that you accept its terms.

# Author: Guillaume Pellerin <yomguy@parisson.com>

import os
import xml.dom.minidom


class Cache(object):

    def __init__(self, dir, params=None):
        self.dir = dir
        self.params = params
        self.files = self.get_files()

    def get_files(self):
        list = []
        for root, dirs, files in os.walk(self.dir):
            for file in files:
                list.append(file)
        return list

    def exists(self, file):
        self.files = self.get_files()
        return file in self.files

    def write_bin(self, data, file):
        path = self.dir + os.sep + file
        f = open(path, 'w')
        f.write(data)
        f.close()

    def read_bin(self, file):
        path = self.dir + os.sep + file
        f = open(path, 'r')
        data = f.read()
        f.close()
        return data

    def read_stream_bin(self, file):
        path = self.dir + os.sep + file
        chunk_size = 0x1000
        f = open(path, 'r')
        while True:
            _chunk = f.read(chunk_size)
            if not len(_chunk):
                break
            yield _chunk
        f.close()

    def write_stream_bin(self, chunk, file_object):
        file_object.write(chunk)

    def read_analyzer_xml(self, file):
        list = []
        path = self.dir + os.sep + file
        doc = xml.dom.minidom.parse(path)
        for data in doc.documentElement.getElementsByTagName('data'):
            name = data.getAttribute('name')
            id = data.getAttribute('id')
            unit = data.getAttribute('unit')
            value = data.getAttribute('value')
            list.append({'name': name, 'id': id, 'unit': unit, 'value': value})
        return list

    def write_analyzer_xml(self, data_list, file):
        path = self.dir + os.sep + file
        doc = xml.dom.minidom.Document()
        root = doc.createElement('telemeta')
        doc.appendChild(root)
        for data in data_list:
            name = data['name']
            id = data['id']
            unit = data['unit']
            value = data['value']
            node = doc.createElement('data')
            node.setAttribute('name', name)
            node.setAttribute('id', id)
            node.setAttribute('unit', unit)
            node.setAttribute('value', str(value))
            root.appendChild(node)
        f = open(path, "w")
        f.write(xml.dom.minidom.Document.toprettyxml(doc))
        f.close()

########NEW FILE########
__FILENAME__ = gstutils
from numpy import getbuffer, frombuffer

import pygst
pygst.require('0.10')
import gst
import gobject
gobject.threads_init()

import threading


def numpy_array_to_gst_buffer(frames, chunk_size, num_samples, sample_rate):
    from gst import Buffer
    """ gstreamer buffer to numpy array conversion """
    buf = Buffer(getbuffer(frames.astype("float32")))
    # Set its timestamp and duration
    buf.timestamp = gst.util_uint64_scale(num_samples, gst.SECOND, sample_rate)
    buf.duration = gst.util_uint64_scale(chunk_size, gst.SECOND, sample_rate)
    return buf


def gst_buffer_to_numpy_array(buf, chan):
    """ gstreamer buffer to numpy array conversion """
    samples = frombuffer(buf.data, dtype='float32').reshape((-1, chan))
    return samples


class MainloopThread(threading.Thread):

    def __init__(self, mainloop):
        threading.Thread.__init__(self)
        self.mainloop = mainloop

    def run(self):
        self.mainloop.run()

########NEW FILE########
__FILENAME__ = logger
#!/usr/bin/python
# -*- coding: utf-8 -*-

import logging


class Logger:

    """A logging object"""

    def __init__(self, file):
        self.logger = logging.getLogger('myapp')
        self.hdlr = logging.FileHandler(file)
        self.formatter = logging.Formatter(
            '%(asctime)s %(levelname)s %(message)s')
        self.hdlr.setFormatter(self.formatter)
        self.logger.addHandler(self.hdlr)
        self.logger.setLevel(logging.INFO)

    def write_info(self, message):
        self.logger.info(message)

    def write_error(self, message):
        self.logger.error(message)

########NEW FILE########
__FILENAME__ = package
# -*- coding: utf-8 -*-
#
# Copyright (c) 2013-2014 Thomas Fillon <thomas.fillon@parisson.com>

# This file is part of TimeSide.

# TimeSide is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 2 of the License, or
# (at your option) any later version.

# TimeSide is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with TimeSide.  If not, see <http://www.gnu.org/licenses/>.

# Author: Thomas Fillon <thomas.fillon@parisson.com>

from ..exceptions import VampImportError

from importlib import import_module
import warnings


def discover_modules(subpackage, package=None):
    import pkgutil

    if package:
        _pkg = import_module('.' + subpackage, package)
    else:
        _pkg = import_module(subpackage)

    pkg_path = _pkg.__path__
    pkg_prefix = _pkg.__name__ + '.'

    _list = [import_module_with_exceptions(modname)
             for importer, modname, ispkg
             in pkgutil.walk_packages(pkg_path, pkg_prefix)]

    modules_list = [mod for mod in _list if mod is not None]
    return modules_list


def import_module_with_exceptions(name, package=None):
    """Wrapper around importlib.import_module to import TimeSide subpackage
    and ignoring ImportError if Aubio, Yaafe and Vamp Host are not available"""

    from timeside import _WITH_AUBIO, _WITH_YAAFE, _WITH_VAMP

    if name.count('.server.'):
        # TODO:
        # Temporary skip all timeside.server submodules before check dependencies
        return
    try:
        import_module(name, package)
    except VampImportError:
        # No Vamp Host
        if _WITH_VAMP:
            raise VampImportError
        else:
            # Ignore Vamp ImportError
            return
    except ImportError as e:
        if str(e).count('yaafelib') and not _WITH_YAAFE:
            # Ignore Yaafe ImportError
            return
        elif str(e).count('aubio') and not _WITH_AUBIO:
            # Ignore Aubio ImportError
            return
        elif str(e).count('DJANGO_SETTINGS_MODULE'):
            # Ignore module requiring DJANGO_SETTINGS_MODULE in environnement
            return
        else:
            raise e
    return name


# Check Availability of external Audio feature extraction librairies
def check_aubio():
    "Check Aubio availability"
    try:
        import aubio
    except ImportError:
        warnings.warn('Aubio librairy is not available', ImportWarning,
                      stacklevel=2)
        _WITH_AUBIO = False
    else:
        _WITH_AUBIO = True
        del aubio

    return _WITH_AUBIO


def check_yaafe():
    "Check Aubio availability"
    try:
        import yaafelib
    except ImportError:
        warnings.warn('Yaafe librairy is not available', ImportWarning,
                      stacklevel=2)
        _WITH_YAAFE = False
    else:
        _WITH_YAAFE = True
        del yaafelib
    return _WITH_YAAFE


def check_vamp():
    "Check Vamp host availability"

    try:
        from ..analyzer import vamp_plugin
    except VampImportError:
        warnings.warn('Vamp host is not available', ImportWarning,
                      stacklevel=2)
        _WITH_VAMP = False
    else:
        _WITH_VAMP = True
        del vamp_plugin

    return _WITH_VAMP

########NEW FILE########
