__FILENAME__ = conf
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# livestreamer documentation build configuration file, created by
# sphinx-quickstart on Fri Aug 24 00:12:10 2012.
#
# This file is execfile()d with the current directory set to its containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys, os

from livestreamer import __version__ as livestreamer_version

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration -----------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be extensions
# coming with Sphinx (named 'sphinx.ext.*') or your custom ones.
extensions = ['sphinx.ext.autodoc', 'sphinxcontrib.issuetracker']

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'Livestreamer'
copyright = '2011-2014, Christopher Rosell'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.

#
# The short X.Y version.
version = livestreamer_version
# The full version, including alpha/beta/rc tags.
release = livestreamer_version

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = ['_build']

# The reST default role (used for this markup: `text`) to use for all documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
#pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []


# -- Options for HTML output ---------------------------------------------------

sys.path.append(os.path.abspath('_themes'))

html_theme_path = ['_themes']
html_theme = 'cr_small'
#html_theme = 'korean'

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
#html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
# html_theme_options = { "github_fork": "chrippa/livestreamer" }

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

#html_sidebars = {
#    'index': ['sidebarintro.html', 'sourcelink.html', 'searchbox.html'],
#    '**': ['sidebarlogo.html', 'localtoc.html', 'relations.html',
#           'sourcelink.html', 'searchbox.html']
#}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
html_domain_indices = False

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
html_show_sourcelink = False

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'livestreamerdoc'


# -- Options for LaTeX output --------------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title, author, documentclass [howto/manual]).
latex_documents = [
  ('index', 'livestreamer.tex', 'livestreamer Documentation',
   'Christopher Rosell', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output --------------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('cli', 'livestreamer', 'extracts streams from various services and pipes them into a video player of choice', ['Christopher Rosell'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output ------------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'livestreamer', 'livestreamer Documentation',
   'Christopher Rosell', 'livestreamer', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

issuetracker = 'github'
issuetracker_project = 'chrippa/livestreamer'

########NEW FILE########
__FILENAME__ = flask_theme_support
# flasky extensions.  flasky pygments style based on tango style
from pygments.style import Style
from pygments.token import Keyword, Name, Comment, String, Error, \
     Number, Operator, Generic, Whitespace, Punctuation, Other, Literal


class HangulizeStyle(Style):
    background_color = '#333333'
    default_style = ''

    styles = {
        Comment:             '#aa9977',      # class: 'c'
        Comment.Single:      'italic',       # class: 'c1'
        Keyword:             '#faec8d',      # class: 'k'
        Keyword.Constant:    '#78c3c0',      # class: 'kc'
        Keyword.Declaration: '#ce6049',      # class: 'kd'
        Operator:            '#9e7da2',      # class: 'o'
        Punctuation:         '#999',         # class: 'p'
        Name:                '#ccc',         # class: 'n'
        Name.Attribute:      '#ce6049',      # class: 'na'
        Name.Builtin:        '#78c3c0',      # class: 'nb'
        Name.Tag:            'bold #6d7e9c', # class: 'nt'
        Number:              '#ce6049',      # class: 'm'
        String:              '#8db269',      # class: 's'
        String.Escape:       '#9e7da2',      # class: 'se'
        Generic.Output:      '#b8ad9d',      # class: 'go'
        Generic.Prompt:      '#78c3c0',      # class: 'gp'
    }


class FlaskyStyle(Style):
    background_color = "#f8f8f8"
    default_style = ""

    styles = {
        # No corresponding class for the following:
        #Text:                     "", # class:  ''
        Whitespace:                "underline #f8f8f8",      # class: 'w'
        Error:                     "#a40000 border:#ef2929", # class: 'err'
        Other:                     "#000000",                # class 'x'

        Comment:                   "italic #8f5902", # class: 'c'
        Comment.Preproc:           "noitalic",       # class: 'cp'

        Keyword:                   "bold #004461",   # class: 'k'
        Keyword.Constant:          "bold #004461",   # class: 'kc'
        Keyword.Declaration:       "bold #004461",   # class: 'kd'
        Keyword.Namespace:         "bold #004461",   # class: 'kn'
        Keyword.Pseudo:            "bold #004461",   # class: 'kp'
        Keyword.Reserved:          "bold #004461",   # class: 'kr'
        Keyword.Type:              "bold #004461",   # class: 'kt'

        Operator:                  "#582800",   # class: 'o'
        Operator.Word:             "bold #004461",   # class: 'ow' - like keywords

        Punctuation:               "bold #000000",   # class: 'p'

        # because special names such as Name.Class, Name.Function, etc.
        # are not recognized as such later in the parsing, we choose them
        # to look the same as ordinary variables.
        Name:                      "#000000",        # class: 'n'
        Name.Attribute:            "#c4a000",        # class: 'na' - to be revised
        Name.Builtin:              "#004461",        # class: 'nb'
        Name.Builtin.Pseudo:       "#3465a4",        # class: 'bp'
        Name.Class:                "#000000",        # class: 'nc' - to be revised
        Name.Constant:             "#000000",        # class: 'no' - to be revised
        Name.Decorator:            "#888",           # class: 'nd' - to be revised
        Name.Entity:               "#ce5c00",        # class: 'ni'
        Name.Exception:            "bold #cc0000",   # class: 'ne'
        Name.Function:             "#000000",        # class: 'nf'
        Name.Property:             "#000000",        # class: 'py'
        Name.Label:                "#f57900",        # class: 'nl'
        Name.Namespace:            "#000000",        # class: 'nn' - to be revised
        Name.Other:                "#000000",        # class: 'nx'
        Name.Tag:                  "bold #004461",   # class: 'nt' - like a keyword
        Name.Variable:             "#000000",        # class: 'nv' - to be revised
        Name.Variable.Class:       "#000000",        # class: 'vc' - to be revised
        Name.Variable.Global:      "#000000",        # class: 'vg' - to be revised
        Name.Variable.Instance:    "#000000",        # class: 'vi' - to be revised

        Number:                    "#990000",        # class: 'm'

        Literal:                   "#000000",        # class: 'l'
        Literal.Date:              "#000000",        # class: 'ld'

        String:                    "#4e9a06",        # class: 's'
        String.Backtick:           "#4e9a06",        # class: 'sb'
        String.Char:               "#4e9a06",        # class: 'sc'
        String.Doc:                "italic #8f5902", # class: 'sd' - like a comment
        String.Double:             "#4e9a06",        # class: 's2'
        String.Escape:             "#4e9a06",        # class: 'se'
        String.Heredoc:            "#4e9a06",        # class: 'sh'
        String.Interpol:           "#4e9a06",        # class: 'si'
        String.Other:              "#4e9a06",        # class: 'sx'
        String.Regex:              "#4e9a06",        # class: 'sr'
        String.Single:             "#4e9a06",        # class: 's1'
        String.Symbol:             "#4e9a06",        # class: 'ss'

        Generic:                   "#000000",        # class: 'g'
        Generic.Deleted:           "#a40000",        # class: 'gd'
        Generic.Emph:              "italic #000000", # class: 'ge'
        Generic.Error:             "#ef2929",        # class: 'gr'
        Generic.Heading:           "bold #000080",   # class: 'gh'
        Generic.Inserted:          "#00A000",        # class: 'gi'
        Generic.Output:            "#888",           # class: 'go'
        Generic.Prompt:            "#745334",        # class: 'gp'
        Generic.Strong:            "bold #000000",   # class: 'gs'
        Generic.Subheading:        "bold #800080",   # class: 'gu'
        Generic.Traceback:         "bold #a40000",   # class: 'gt'
    }

########NEW FILE########
__FILENAME__ = gst-player
#!/usr/bin/env python2

from __future__ import print_function
from livestreamer import Livestreamer, StreamError, PluginError, NoPluginError

import gobject
gobject.threads_init()

import pygst
pygst.require("0.10")

import gst
import sys

def exit(msg):
    print(msg, file=sys.stderr)
    sys.exit()

class LivestreamerPlayer(object):
    def __init__(self):
        self.fd = None
        self.mainloop = gobject.MainLoop()

        # This creates a playbin pipeline and using the appsrc source
        # we can feed it our stream data
        self.pipeline = gst.element_factory_make("playbin2", None)
        self.pipeline.set_property("uri", "appsrc://")

        # When the playbin creates the appsrc source it will call
        # this callback and allow us to configure it
        self.pipeline.connect("source-setup", self.on_source_setup)

        # Creates a bus and set callbacks to receive errors
        self.bus = self.pipeline.get_bus()
        self.bus.add_signal_watch()
        self.bus.connect("message::eos", self.on_eos)
        self.bus.connect("message::error", self.on_error)

    def exit(self, msg):
        self.stop()
        exit(msg)

    def stop(self):
        # Stop playback and exit mainloop
        self.pipeline.set_state(gst.STATE_NULL)
        self.mainloop.quit()

        # Close the stream
        if self.fd:
            self.fd.close()

    def play(self, stream):
        # Attempt to open the stream
        try:
            self.fd = stream.open()
        except StreamError as err:
            self.exit("Failed to open stream: {0}".format(err))

        # Start playback
        self.pipeline.set_state(gst.STATE_PLAYING)
        self.mainloop.run()

    def on_source_setup(self, element, source):
        # When this callback is called the appsrc expects
        # us to feed it more data
        source.connect("need-data", self.on_source_need_data)

    def on_source_need_data(self, source, length):
        # Attempt to read data from the stream
        try:
            data = self.fd.read(length)
        except IOError as err:
            self.exit("Failed to read data from stream: {0}".format(err))

        # If data is empty it's the end of stream
        if not data:
            source.emit("end-of-stream")
            return

        # Convert the Python bytes into a GStreamer Buffer
        # and then push it to the appsrc
        buf = gst.Buffer(data)
        source.emit("push-buffer", buf)

    def on_eos(self, bus, msg):
        # Stop playback on end of stream
        self.stop()

    def on_error(self, bus, msg):
        # Print error message and exit on error
        error = msg.parse_error()[1]
        self.exit(error)


def main():
    if len(sys.argv) < 3:
        exit("Usage: {0} <url> <quality>".format(sys.argv[0]))

    # Collect arguments
    url = sys.argv[1]
    quality = sys.argv[2]

    # Create the Livestreamer session
    livestreamer = Livestreamer()

    # Enable logging
    livestreamer.set_loglevel("info")
    livestreamer.set_logoutput(sys.stdout)

    # Attempt to find a plugin for this URL
    try:
        plugin = livestreamer.resolve_url(url)
    except NoPluginError:
        exit("Livestreamer is unable to handle the URL '{0}'".format(url))

    # Attempt to fetch streams
    try:
        streams = plugin.get_streams()
    except PluginError as err:
        exit("Plugin error: {0}".format(err))

    if len(streams) == 0:
        exit("No streams found on URL '{0}'".format(url))

    # Look for specified stream
    if quality not in streams:
        exit("Unable to find '{0}' stream on URL '{1}'".format(quality, url))

    # We found the stream
    stream = streams[quality]

    # Create the player and start playback
    player = LivestreamerPlayer()

    # Blocks until playback is done
    player.play(stream)

if __name__ == "__main__":
    main()

########NEW FILE########
__FILENAME__ = buffers
from collections import deque
from io import BytesIO
from threading import Event, Lock


class Chunk(BytesIO):
    """A single chunk, part of the buffer."""

    def __init__(self, buf):
        self.length = len(buf)
        BytesIO.__init__(self, buf)

    @property
    def empty(self):
        return self.tell() == self.length


class Buffer(object):
    """Simple buffer for use in single-threaded consumer/filler.

    Stores chunks in a deque to avoid inefficient reallocating
    of large buffers.
    """

    def __init__(self):
        self.chunks = deque()
        self.current_chunk = None
        self.closed = False
        self.length = 0

    def _iterate_chunks(self, size):
        bytes_left = size

        while bytes_left:
            try:
                current_chunk = (self.current_chunk or
                                 Chunk(self.chunks.popleft()))
            except IndexError:
                break

            data = current_chunk.read(bytes_left)
            bytes_left -= len(data)

            if current_chunk.empty:
                self.current_chunk = None
            else:
                self.current_chunk = current_chunk

            yield data

    def write(self, data):
        if not self.closed:
            data = bytes(data)  # Copy so that original buffer may be reused
            self.chunks.append(data)
            self.length += len(data)

    def read(self, size=-1):
        if size < 0 or size > self.length:
            size = self.length

        if not size:
            return b""

        data = b"".join(self._iterate_chunks(size))
        self.length -= len(data)

        return data

    def close(self):
        self.closed = True


class RingBuffer(Buffer):
    """Circular buffer for use in multi-threaded consumer/filler."""

    def __init__(self, size=8192*4):
        Buffer.__init__(self)

        self.buffer_size = size
        self.buffer_lock = Lock()

        self.event_free = Event()
        self.event_free.set()
        self.event_used = Event()

    def _check_events(self):
        if self.length > 0:
            self.event_used.set()
        else:
            self.event_used.clear()

        if self.is_full:
            self.event_free.clear()
        else:
            self.event_free.set()

    def _read(self, size=-1):
        with self.buffer_lock:
            data = Buffer.read(self, size)

            self._check_events()

        return data

    def read(self, size=-1, block=True, timeout=None):
        if block and not self.closed:
            self.event_used.wait(timeout)

            # If the event is still not set it's a timeout
            if not self.event_used.is_set() and self.length == 0:
                raise IOError("Read timeout")

        return self._read(size)

    def write(self, data):
        if self.closed:
            return

        data_left = len(data)
        data_total = len(data)

        while data_left > 0:
            self.event_free.wait()

            if self.closed:
                return

            with self.buffer_lock:
                write_len = min(self.free, data_left)
                written = data_total - data_left

                Buffer.write(self, data[written:written+write_len])
                data_left -= write_len

                self._check_events()

    def resize(self, size):
        with self.buffer_lock:
            self.buffer_size = size

            self._check_events()

    def wait_free(self, timeout=None):
        self.event_free.wait(timeout)

    def wait_used(self, timeout=None):
        self.event_used.wait(timeout)

    def close(self):
        Buffer.close(self)

        # Make sure we don't let a .write() and .read() block forever
        self.event_free.set()
        self.event_used.set()

    @property
    def free(self):
        return max(self.buffer_size - self.length, 0)

    @property
    def is_full(self):
        return self.free == 0

__all__ = ["Buffer", "RingBuffer"]

########NEW FILE########
__FILENAME__ = cache
import json
import os
import shutil
import tempfile

from time import time
from .compat import is_win32

if is_win32:
    xdg_cache = os.environ.get("APPDATA",
                               os.path.expanduser("~"))
else:
    xdg_cache = os.environ.get("XDG_CACHE_HOME",
                               os.path.expanduser("~/.cache"))

cache_dir = os.path.join(xdg_cache, "livestreamer")


class Cache(object):
    """Caches Python values as JSON and prunes expired entries."""

    def __init__(self, filename, key_prefix=""):
        self.key_prefix = key_prefix
        self.filename = os.path.join(cache_dir, filename)

        self._cache = {}

    def _load(self):
        if os.path.exists(self.filename):
            try:
                with open(self.filename, "r") as fd:
                    self._cache = json.load(fd)
            except:
                self._cache = {}
        else:
            self._cache = {}

    def _prune(self):
        now = time()
        pruned = []

        for key, value in self._cache.items():
            expires = value.get("expires", time())
            if expires <= now:
                pruned.append(key)

        for key in pruned:
            self._cache.pop(key, None)

        return len(pruned) > 0

    def _save(self):
        fd, tempname = tempfile.mkstemp()
        fd = os.fdopen(fd, "w")
        json.dump(self._cache, fd, indent=2, separators=(",", ": "))
        fd.close()

        # Silently ignore errors
        try:
            if not os.path.exists(os.path.dirname(self.filename)):
                os.makedirs(os.path.dirname(self.filename))

            shutil.move(tempname, self.filename)
        except (IOError, OSError):
            os.remove(tempname)

    def set(self, key, value, expires=60 * 60 * 24 * 7):
        self._load()
        self._prune()

        if self.key_prefix:
            key = "{0}:{1}".format(self.key_prefix, key)

        expires += time()

        self._cache[key] = dict(value=value, expires=expires)
        self._save()

    def get(self, key, default=None):
        self._load()

        if self._prune():
            self._save()

        if self.key_prefix:
            key = "{0}:{1}".format(self.key_prefix, key)

        if key in self._cache and "value" in self._cache[key]:
            return self._cache[key]["value"]
        else:
            return default

__all__ = ["Cache"]

########NEW FILE########
__FILENAME__ = compat
import os
import sys

is_py2 = (sys.version_info[0] == 2)
is_py3 = (sys.version_info[0] == 3)
is_py33 = (sys.version_info[0] == 3 and sys.version_info[1] == 3)
is_win32 = os.name == "nt"

if is_py2:
    _str = str
    str = unicode
    range = xrange

    def bytes(b, enc="ascii"):
        return _str(b)

elif is_py3:
    bytes = bytes
    str = str
    range = range

try:
    from urllib.parse import urlparse, urljoin, quote, unquote, parse_qsl
    import queue
except ImportError:
    from urlparse import urlparse, urljoin, parse_qsl
    from urllib import quote, unquote
    import Queue as queue

__all__ = ["is_py2", "is_py3", "is_py33", "is_win32", "str", "bytes",
           "urlparse", "urljoin", "parse_qsl", "quote", "unquote", "queue",
           "range"]

########NEW FILE########
__FILENAME__ = exceptions
class LivestreamerError(Exception):
    """Any error caused by Livestreamer will be caught
       with this exception."""


class PluginError(LivestreamerError):
    """Plugin related error."""


class NoStreamsError(LivestreamerError):
    def __init__(self, url):
        self.url = url

        Exception.__init__(self, "No streams found on this "
                                 "URL: {0}".format(url))


class NoPluginError(PluginError):
    """No relevant plugin has been loaded.

    This exception is raised by :meth:`Livestreamer.resolve_url`,
    when no relevant plugin can be found.

    """


class StreamError(LivestreamerError):
    """Stream related error."""


__all__ = ["LivestreamerError", "PluginError", "NoPluginError",
           "NoStreamsError", "StreamError"]

########NEW FILE########
__FILENAME__ = logger
import sys

from threading import Lock


class Logger(object):
    Levels = ["none", "error", "warning", "info", "debug"]
    Format = "[{module}][{level}] {msg}\n"

    def __init__(self):
        self.output = sys.stdout
        self.level = 0
        self.lock = Lock()

    def new_module(self, module):
        return LoggerModule(self, module)

    def set_level(self, level):
        try:
            index = Logger.Levels.index(level)
        except ValueError:
            return

        self.level = index

    def set_output(self, output):
        self.output = output

    def msg(self, module, level, msg, *args, **kwargs):
        if self.level < level or level > len(Logger.Levels):
            return

        msg = msg.format(*args, **kwargs)

        with self.lock:
            self.output.write(Logger.Format.format(module=module,
                                                   level=Logger.Levels[level],
                                                   msg=msg))
            if hasattr(self.output, "flush"):
                self.output.flush()


class LoggerModule(object):
    def __init__(self, manager, module):
        self.manager = manager
        self.module = module

    def error(self, msg, *args, **kwargs):
        self.manager.msg(self.module, 1, msg, *args, **kwargs)

    def warning(self, msg, *args, **kwargs):
        self.manager.msg(self.module, 2, msg, *args, **kwargs)

    def info(self, msg, *args, **kwargs):
        self.manager.msg(self.module, 3, msg, *args, **kwargs)

    def debug(self, msg, *args, **kwargs):
        self.manager.msg(self.module, 4, msg, *args, **kwargs)

__all__ = ["Logger"]

########NEW FILE########
__FILENAME__ = options
class Options(object):
    def __init__(self, defaults=None):
        if not defaults:
            defaults = {}

        self.defaults = defaults
        self.options = defaults.copy()

    def set(self, key, value):
        self.options[key] = value

    def get(self, key):
        if key in self.options:
            return self.options[key]

__all__ = ["Options"]

########NEW FILE########
__FILENAME__ = amf
from .error import AMFError
from .packet import Packet
from .types import AMF0String, AMF0Value, U8, U16BE, U32BE


class AMFHeader(Packet):
    exception = AMFError

    def __init__(self, name, value, must_understand=False):
        self.name = name
        self.value = value
        self.must_understand = must_understand

    @property
    def size(self):
        size = 4+1
        size += AMF0String.size(self.name)
        size += AMF0Value.size(self.value)

        return size

    def _serialize(self, packet):
        packet += AMF0String(self.name)
        packet += U8(int(self.must_understand))
        packet += U32BE(self.size)
        packet += AMF0Value(self.value)

    @classmethod
    def _deserialize(cls, io):
        name = AMF0String.read(io)
        must_understand = bool(U8.read(io))
        length = U32BE.read(io)
        value = AMF0Value.read(io)

        return cls(name, value, must_understand)


class AMFMessage(Packet):
    exception = AMFError

    def __init__(self, target_uri, response_uri, value):
        self.target_uri = target_uri
        self.response_uri = response_uri
        self.value = value

    @property
    def size(self):
        size = 4
        size += AMF0String.size(self.target_uri)
        size += AMF0String.size(self.response_uri)
        size += AMF0Value.size(self.value)

        return size

    def _serialize(self, packet):
        packet += AMF0String(self.target_uri)
        packet += AMF0String(self.response_uri)
        packet += U32BE(self.size)
        packet += AMF0Value.pack(self.value)

    @classmethod
    def _deserialize(cls, io):
        target_uri = AMF0String.read(io)
        response_uri = AMF0String.read(io)
        length = U32BE.read(io)
        value = AMF0Value.read(io)

        return cls(target_uri, response_uri, value)


class AMFPacket(Packet):
    exception = AMFError

    def __init__(self, version, headers=None, messages=None):
        if headers is None:
            headers = []

        if messages is None:
            messages = []

        self.version = version
        self.headers = headers
        self.messages = messages

    @property
    def size(self):
        size = 2+2+2

        for header in self.headers:
            size += header.size

        for message in self.messages:
            size += message.size

        return size

    def _serialize(self, packet):
        packet += U16BE(self.version)
        packet += U16BE(len(self.headers))

        for header in self.headers:
            header.serialize(packet)

        packet += U16BE(len(self.messages))
        for message in self.messages:
            message.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        version = U16BE.read(io)

        if not version in (0, 3):
            raise AMFError("AMF version must be 0 or 3")

        headers = []
        header_count = U16BE.read(io)

        for i in range(header_count):
            header = AMFHeader.deserialize(io)
            headers.append(header)

        messages = []
        message_count = U16BE.read(io)
        for i in range(message_count):
            message = AMFMessage.deserialize(io)
            messages.append(message)

        return cls(version, headers, messages)

__all__ = ["AMFPacket", "AMFHeader", "AMFMessage"]

########NEW FILE########
__FILENAME__ = box
from ctypes import BigEndianStructure, Union, c_uint8, c_uint16, c_uint32
from io import BytesIO

from .compat import *
from .error import *
from .packet import *
from .types import *
from .util import *


class Box(Packet):
    exception = F4VError

    def __init__(self, type, payload, extended_size=False):
        self.type = type
        self.payload = payload
        self.extended_size = extended_size

    @property
    def size(self):
        size = 8
        size += self.payload.size

        if size > 0xFFFFFFFF or self.extended_size:
            size += 8

        return size

    @classmethod
    def _deserialize(cls, io, strict=False, raw_payload=False):
        size = U32BE.read(io)
        type_ = FourCC.read(io)
        header_size = 8
        extended_size = False

        if size == 1:
            size = U64BE.read(io)
            header_size += 8
            extended_size = True

        if size == 0:
            data = io.read()
        else:
            data = chunked_read(io, size - header_size, exception=F4VError)

        if type_ in PayloadTypes and not raw_payload:
            payloadcls = PayloadTypes[type_]
            payloadio = BytesIO(data)
            payload = payloadcls.deserialize(payloadio)
        else:
            payload = RawPayload(data)

        box = cls(type_, payload, extended_size)

        if strict and box.size != size:
            raise F4VError("Data size mismatch when deserialising tag")

        return box

    def _serialize(self, packet):
        size = self.payload.size

        if size > 0xFFFFFFFF or self.extended_size:
            packet += U32BE(1)
        else:
            packet += U32BE(size + 8)

        packet += FourCC(self.type)

        if size > 0xFFFFFFFF or self.extended_size:
            packet += U64BE(size + 16)

        if isinstance(self.payload, BoxPayload):
            self.payload.serialize(packet)
        else:
            packetwrite(self.payload)

class BoxPayload(Packet):
    exception = F4VError

    @property
    def size(self):
        return 0

    @classmethod
    def box(cls, *args, **kw):
        type_ = None

        for name, kls in PayloadTypes.items():
            if kls == cls:
                type_ = name
                break

        payload = cls(*args, **kw)

        return Box(type_, 0, payload)

class BoxContainer(BoxPayload):
    def __init__(self, boxes):
        self.boxes = boxes

    @property
    def size(self):
        size = 0
        for box in self.boxes:
            size += box.size

        return size

    def _serialize(self, packet):
        for box in self.boxes:
            box.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        boxes = []

        while True:
            try:
                box = Box.deserialize(io)
            except IOError:
                break

            boxes.append(box)

        return cls(boxes)


class BoxContainerSingle(BoxPayload):
    def __init__(self, box):
        self.box = box

    @property
    def size(self):
        return self.box.size

    def _serialize(self, packet):
        self.box.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        box = Box.deserialize(io)

        return cls(box)

class RawPayload(BoxPayload):
    def __init__(self, data):
        self.data = data

    def __repr__(self):
        return "<RawPayload size={0}>".format(self.size)

    @property
    def size(self):
        return len(self.data)

    @classmethod
    def _deserialize(cls, io):
        data = io.read()
        return cls(data)

    def _serialize(self, packet):
        packet += self.data

class BoxPayloadFTYP(BoxPayload):
    def __init__(self, major_brand="f4v", minor_version=0,
                 compatible_brands=["isom", "mp42", "m4v"]):
        self.major_brand = major_brand
        self.minor_version = minor_version
        self.compatible_brands = compatible_brands

    @property
    def size(self):
        return 4+4+(len(self.compatible_brands)*4)

    def _serialize(self, packet):
        packet += FourCC(self.major_brand)
        packet += U32BE(self.minor_version)

        for brand in self.compatible_brands:
            packet += FourCC(brand)

    @classmethod
    def _deserialize(cls, io):
        major_brand = FourCC.read(io)
        minor_version = U32BE.read(io)
        compatible_brands = []

        while True:
            try:
                brand = FourCC.read(io)
            except IOError:
                break

            compatible_brands.append(brand)

        return cls(major_brand, minor_version,
                   compatible_brands)


class BoxPayloadMVHD(BoxPayload):
    def __init__(self, version=0, creation_time=0, modification_time=0,
                 time_scale=1000, duration=0, rate=1.0, volume=1.0,
                 matrix=[65536, 0, 0, 0, 65536, 0, 0, 0, 1073741824],
                 next_track_id=0):
        self.version = version
        self.creation_time = creation_time
        self.modification_time = modification_time
        self.time_scale = time_scale
        self.duration = duration
        self.rate = rate
        self.volume = volume
        self.matrix = matrix
        self.next_track_id = next_track_id

    @property
    def size(self):
        size = 1+3+4+4+2+2+4+4+(9*4)+(6*4)+4

        if self.version == 1:
            size += 3*8
        else:
            size += 3*4

        return size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(0) # Reserved

        packet += U3264(self.creation_time, self.version)
        packet += U3264(self.modification_time, self.version)
        packet += U32BE(self.time_scale)
        packet += U3264(self.duration, self.version)

        packet += S16BE_16(self.rate)
        packet += S8_8BE(self.volume)

        packet += U16BE(0) # Reserved
        packet += U32BE(0) # Reserved
        packet += U32BE(0) # Reserved

        for m in self.matrix:
            packet += U32BE(m)

        for i in range(6):
            packet += U32BE(0) # Reserved

        packet += U32BE(self.next_track_id)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        U24BE.read(io) # Reserved

        creation_time = U3264.read(io, version)
        modification_time = U3264.read(io, version)
        time_scale = U32BE.read(io)
        duration = U3264.read(io, version)

        rate = S16_16.read(io)
        volume = S8_8BE.read(io)

        U16BE.read(io) # Reserved
        U32BE.read(io) # Reserved
        U32BE.read(io) # Reserved

        matrix = []
        for i in range(9):
            matrix.append(U32BE.read(io))

        for i in range(6):
            U32BE.read(io) # Reserved

        next_track_id = U32BE.read(io)

        return cls(version, creation_time,
                   modification_time, time_scale, duration,
                   rate, volume, matrix, next_track_id)


class SampleFlags(BoxPayload):
    class Flags(Union):
        class Bits(BigEndianStructure):
            _fields_ = [("reserved", c_uint8, 6),
                        ("sample_depends_on", c_uint8, 2),
                        ("sample_is_depended_on", c_uint8, 2),
                        ("sample_has_redundancy", c_uint8, 2),
                        ("sample_padding_value", c_uint8, 3),
                        ("sample_is_difference_sample", c_uint8, 1),
                        ("sample_degradation_priority", c_uint16, 16)]

        _fields_ = [("bit", Bits), ("byte", c_uint32)]

    def __init__(self, sample_depends_on, sample_is_depended_on,
                 sample_has_redundancy, sample_padding_value,
                 sample_is_difference_sample, sample_degradation_priority):

        self.flags = self.Flags()
        self.flags.bit.reserved = 0 # Reserved
        self.flags.bit.sample_depends_on = sample_depends_on
        self.flags.bit.sample_is_depended_on = sample_is_depended_on
        self.flags.bit.sample_has_redundancy = sample_has_redundancy
        self.flags.bit.sample_padding_value = sample_padding_value
        self.flags.bit.sample_is_difference_sample = sample_is_difference_sample
        self.flags.bit.sample_degradation_priority = sample_degradation_priority

    @property
    def size(self):
        return 4

    def _serialize(self, packet):
        packet += U32BE(self.flags.byte)

    @classmethod
    def _deserialize(cls, io):
        flags = cls.Flags()
        flags.byte = U32BE.read(io)

        return cls(flags.bit.sample_depends_on, flags.bit.sample_is_depended_on,
                   flags.bit.sample_has_redundancy, flags.bit.sample_padding_value,
                   flags.bit.sample_is_difference_sample, flags.bit.sample_degradation_priority)


class BoxPayloadTREX(BoxPayload):
    def __init__(self, version, track_id,
                 default_sample_description_index,
                 default_sample_duration, default_sample_size,
                 default_sample_flags):
        self.version = version
        self.track_id = track_id
        self.default_sample_description_index = default_sample_description_index
        self.default_sample_duration = default_sample_duration
        self.default_sample_size = default_sample_size
        self.default_sample_flags = default_sample_flags

    @property
    def size(self):
        return 1+3+4+4+4+4+self.default_sample_flags.size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(0) # Reserved
        packet += U32BE(self.track_id)
        packet += U32BE(self.default_sample_description_index)
        packet += U32BE(self.default_sample_duration)
        packet += U32BE(self.default_sample_size)
        self.default_sample_flags.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io)
        track_id = U32BE.read(io)
        default_sample_description_index = U32BE.read(io)
        default_sample_duration = U32BE.read(io)
        default_sample_size = U32BE.read(io)
        default_sample_flags = SampleFlags.deserialize(io)

        return cls(version, track_id,
                   default_sample_description_index,
                   default_sample_duration, default_sample_size,
                   default_sample_flags)


class BoxPayloadTKHD(BoxPayload):
    def __init__(self, version=0, flags=1, creation_time=0, modification_time=0,
                 track_id=1, duration=0, layer=0, alternate_group=0, volume=0.0,
                 transform_matrix=[65536, 0, 0, 0, 65536, 0, 0, 0, 1073741824],
                 width=0.0, height=0.0):
        self.version = version
        self.flags = flags
        self.creation_time = creation_time
        self.modification_time = modification_time
        self.track_id = track_id
        self.duration = duration
        self.layer = layer
        self.alternate_group = alternate_group
        self.volume = volume
        self.transform_matrix = transform_matrix
        self.width = width
        self.height = height

    @property
    def size(self):
        size = 1+3+4+4+4+4+4+(4*2)+2+2+2+2+(9*4)+4+4

        if self.version == 1:
            size += 4*3

        return size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(self.flags)

        packet += U3264(self.creation_time, self.version)
        packet += U3264(self.modification_time, self.version)
        packet += U32BE(self.track_id)
        packet += U32BE(0) # Reserved
        packet += U3264(self.duration, self.version)

        for i in range(2):
            packet += U32BE(0) # Reserved

        packet += S16BE(self.layer)
        packet += S16BE(self.alternate_group)
        packet += S8_8BE(self.volume)
        packet += U16BE(0) # Reserved

        for i in range(9):
            packet += U32BE(self.transform_matrix[i])

        packet += S16BE_16(self.width)
        packet += S16BE_16(self.height)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io)

        creation_time = U3264.read(io, version)
        modification_time = U3264.read(io, version)
        track_id = U32BE.read(io)
        U32BE.read(io) # Reserved
        duration = U3264.read(io, version)

        for i in range(2):
            U32BE.read(io) # Reserved

        layer = S16BE.read(io)
        alternate_group = S16BE.read(io)
        volume = S8_8BE.read(io)
        U16BE.read(io) # Reserved

        transform_matrix = []
        for i in range(9):
            transform_matrix.append(S32BE.read(io))

        width = S16_16.read(io)
        height = S16_16.read(io)

        return cls(version, flags, creation_time, modification_time,
                   track_id, duration, layer, alternate_group, volume,
                   transform_matrix, width, height)


class BoxPayloadMDHD(BoxPayload):
    def __init__(self, version=0, creation_time=0, modification_time=0,
                 time_scale=1000, duration=0, language="eng"):
        self.version = version
        self.creation_time = creation_time
        self.modification_time = modification_time
        self.time_scale = time_scale
        self.duration = duration
        self.language = language

    @property
    def size(self):
        size = 1+3+4+4+4+4+2+2

        if self.version == 1:
            size += 4*3

        return size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(0) # Reserved

        packet += U3264(self.creation_time, self.version)
        packet += U3264(self.modification_time, self.version)
        packet += U32BE(self.time_scale)
        packet += U3264(self.duration, self.version)

        packet += S16BE(iso639_to_lang(self.language))
        packet += U16BE(0) # Reserved

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        U24BE.read(io) # Reserved

        creation_time = U3264.read(io, version)
        modification_time = U3264.read(io, version)
        time_scale = U32BE.read(io)
        duration = U3264.read(io, version)

        language = lang_to_iso639(U16BE.read(io))
        U16BE.read(io) # Reserved

        return cls(version, creation_time, modification_time,
                   time_scale, duration, language)


class BoxPayloadHDLR(BoxPayload):
    def __init__(self, version=0, predefined=0, handler_type="vide",
                 name=""):
        self.version = version
        self.predefined = predefined
        self.handler_type = handler_type
        self.name = name

    @property
    def size(self):
        size = 1+3+4+4+(3*4)
        size += len(self.name)

        return size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(0) # Reserved
        packet += U32BE(self.predefined)
        packet += FourCC(self.handler_type)

        for i in range(3):
            packet += U32BE(0) # Reserved

        #packet += self.name.encode("utf8", "ignore")
        packet += CString(self.name)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io) # Reserved

        predefined = U32BE.read(io)
        handler_type = FourCC.read(io)

        for i in range(3):
            U32BE.read(io) # Reserved

        name = CString.read(io)

        return cls(version, predefined, handler_type,
                   name)


class BoxPayloadVMHD(BoxPayload):
    def __init__(self, version=0, flags=1, graphics_mode=0, op_color=[0, 0, 0]):
        self.version = version
        self.flags = flags
        self.graphics_mode = graphics_mode
        self.op_color = op_color

    @property
    def size(self):
        return 1+3+2+(3*2)

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(self.flags)
        packet += U16BE(self.graphics_mode)

        for i in range(3):
            packet += U16BE(self.op_color[i])

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io)

        graphics_mode = U16BE.read(io)
        op_color = []
        for i in range(3):
            op_color.append(U16BE.read(io))

        return cls(version, flags, graphics_mode, op_color)


class BoxPayloadDREF(BoxContainer):
    def __init__(self, version=0, boxes=[]):
        self.version = version
        self.boxes = boxes

    @property
    def size(self):
        size = 1+3+4

        for box in self.boxes:
            size += box.size

        return size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(0) # Reserved
        packet += U32BE(len(self.boxes))

        for box in self.boxes:
            box.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io)

        entry_count = U32BE.read(io)
        boxes = []
        for i in range(entry_count):
            box = Box.deserialize(io)
            boxes.append(box)

        return cls(version, boxes)

class BoxPayloadURL(BoxPayload):
    def __init__(self, version=0, flags=1):
        self.version = version
        self.flags = flags

    @property
    def size(self):
        return 4

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(self.flags)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io)

        return cls(version, flags)

class BoxPayloadSTSD(BoxContainer):
    def __init__(self, version=0, descriptions=[]):
        self.version = version
        self.descriptions = descriptions

    @property
    def size(self):
        size = 4+4

        for description in self.descriptions:
            size += description.size

        return size

    @property
    def boxes(self):
        return self.descriptions

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(0) # Reserved
        packet += U32BE(len(self.descriptions))

        for description in self.descriptions:
            description.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io)
        count = U32BE.read(io)

        descriptions = []
        for i in range(count):
            box = Box.deserialize(io)
            descriptions.append(box)

        return cls(version, descriptions)

class BoxPayloadVisualSample(BoxContainer):
    def __init__(self, data_reference_index=0, width=0, height=0,
                 horiz_resolution=0.0, vert_resolution=0.0, frame_count=0,
                 compressor_name="", depth=0, boxes=[]):
        self.data_reference_index = data_reference_index
        self.width = width
        self.height = height
        self.horiz_resolution = horiz_resolution
        self.vert_resolution = vert_resolution
        self.frame_count = frame_count
        self.compressor_name = compressor_name
        slef.depth = depth
        self.boxes = boxes

    @property
    def size(self):
        return 4

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(self.flags)

    @classmethod
    def _deserialize(cls, io):
        for i in range(4):
            U8.read(io)


        return cls(version, flags)




class BoxPayloadMDAT(RawPayload):
    def __repr__(self):
        return "<BoxPayloadMDAT size={0}>".format(self.size)

class BoxPayloadSKIP(RawPayload):
    def __repr__(self):
        return "<BoxPayloadSKIP size={0}>".format(self.size)

class BoxPayloadFREE(RawPayload):
    def __repr__(self):
        return "<BoxPayloadFREE size={0}>".format(self.size)


class BoxPayloadABST(BoxPayload):
    class Flags(Union):
        class Bits(BigEndianStructure):
            _fields_ = [("profile", c_uint8, 2),
                        ("live", c_uint8, 1),
                        ("update", c_uint8, 1),
                        ("reserved", c_uint8, 4)]

        _fields_ = [("bit", Bits), ("byte", c_uint8)]

    def __init__(self, version, bootstrap_info_version, profile, live, update,
                       time_scale, current_media_time, smpte_time_code_offset,
                       movie_identifier, server_entry_table, quality_entry_table,
                       drm_data, metadata, segment_run_table_entries,
                       fragment_run_table_entries):
        self.version = version
        self.bootstrap_info_version = bootstrap_info_version
        self.flags = self.Flags()
        self.flags.bit.profile = profile
        self.flags.bit.live = live
        self.flags.bit.update = update
        self.flags.bit.reserved = 0
        self.time_scale = time_scale
        self.current_media_time = current_media_time
        self.smpte_time_code_offset = smpte_time_code_offset
        self.movie_identifier = movie_identifier
        self.server_entry_table = server_entry_table
        self.quality_entry_table = quality_entry_table
        self.drm_data = drm_data
        self.metadata = metadata
        self.segment_run_table_entries = segment_run_table_entries
        self.fragment_run_table_entries = fragment_run_table_entries

    profile = flagproperty("flags", "profile")
    update = flagproperty("flags", "update", True)
    live = flagproperty("flags", "live", True)

    @property
    def size(self):
        size = 1+3+4+1+4+8+8
        size += len(self.movie_identifier) + 1

        size += 1
        for server in self.server_entry_table:
            size += len(server) + 1

        size += 1
        for quality_entry in self.quality_entry_table:
            size += len(quality_entry) + 1

        size += len(self.drm_data) + 1
        size += len(self.metadata) + 1

        size += 1
        for segment_run_table in self.segment_run_table_entries:
            size += segment_run_table.size

        size += 1
        for fragment_run_table in self.fragment_run_table_entries:
            size += fragment_run_table.size

        return size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(0) # Reserved
        packet += U32BE(self.bootstrap_info_version)
        packet += U8(self.flags.byte)
        packet += U32BE(self.time_scale)
        packet += U64BE(self.current_media_time)
        packet += U64BE(self.smpte_time_code_offset)
        packet += CString(self.movie_identifier)

        packet += U8(len(self.server_entry_table))
        for server_entry in self.server_entry_table:
            packet += CString(server_entry)

        packet += U8(len(self.quality_entry_table))
        for quality_entry in self.quality_entry_table:
            packet += CString(quality_entry)

        packet += CString(self.drm_data)
        packet += CString(self.metadata)

        packet += U8(len(self.segment_run_table_entries))
        for segment_run_table in self.segment_run_table_entries:
            segment_run_table.serialize(packet)

        packet += U8(len(self.fragment_run_table_entries))
        for fragment_run_table in self.fragment_run_table_entries:
            fragment_run_table.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        U24BE.read(io) # Reserved
        bootstrap_info_version = U32BE.read(io)
        flags = cls.Flags()
        flags.byte = U8.read(io)
        time_scale = U32BE.read(io)
        current_media_time = U64BE.read(io)
        smpte_time_code_offset = U64BE.read(io)
        movie_identifier = CString.read(io)

        server_entry_table = []
        server_entry_count = U8.read(io)

        for i in range(server_entry_count):
            server_entry = CString.read(io)
            server_entry_table.append(server_entry)

        quality_entry_table = []
        quality_entry_count = U8.read(io)

        for i in range(quality_entry_count):
            quality_entry = CString.read(io)
            quality_entry_table.append(quality_entry)

        drm_data = CString.read(io)
        metadata = CString.read(io)

        segment_run_table_entries = []
        segment_run_table_count = U8.read(io)

        for i in range(segment_run_table_count):
            segment_run_table = Box.deserialize(io)
            segment_run_table_entries.append(segment_run_table)

        fragment_run_table_entries = []
        fragment_run_table_count = U8.read(io)

        for i in range(fragment_run_table_count):
            fragment_run_table = Box.deserialize(io)
            fragment_run_table_entries.append(fragment_run_table)

        return cls(version, bootstrap_info_version, flags.bit.profile,
                   flags.bit.live, flags.bit.update, time_scale,
                   current_media_time, smpte_time_code_offset, movie_identifier,
                   server_entry_table, quality_entry_table, drm_data,
                   metadata, segment_run_table_entries, fragment_run_table_entries)


class SegmentRunEntry(BoxPayload):
    def __init__(self, first_segment, fragments_per_segment):
        self.first_segment = first_segment
        self.fragments_per_segment = fragments_per_segment

    @property
    def size(self):
        return 8

    def _serialize(self, packet):
        packet += U32BE(self.first_segment)
        packet += U32BE(self.fragments_per_segment)

    @classmethod
    def _deserialize(cls, io):
        first_segment = U32BE.read(io)
        fragments_per_segment = U32BE.read(io)

        return cls(first_segment, fragments_per_segment)


class BoxPayloadASRT(BoxPayload):
    def __init__(self, version, flags, quality_segment_url_modifiers,
                 segment_run_entry_table):
        self.version = version
        self.flags = flags
        self.quality_segment_url_modifiers = quality_segment_url_modifiers
        self.segment_run_entry_table = segment_run_entry_table

    @property
    def size(self):
        size = 1+3+1+4

        for quality in self.quality_segment_url_modifiers:
            size += len(quality) + 1

        for segment_run_entry in self.segment_run_entry_table:
            size += segment_run_entry.size

        return size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(self.flags)
        packet += U8(len(self.quality_segment_url_modifiers))

        for quality in self.quality_segment_url_modifiers:
            packet += CString(quality)

        packet += U32BE(len(self.segment_run_entry_table))
        for segment_run_entry in self.segment_run_entry_table:
            segment_run_entry.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io)

        quality_segment_url_modifiers = []
        quality_entry_count = U8.read(io)

        for i in range(quality_entry_count):
            quality = CString.read(io)
            quality_segment_url_modifiers.append(quality)

        segment_run_entry_count = U32BE.read(io)
        segment_run_entry_table = []

        for i in range(segment_run_entry_count):
            segment_run_entry = SegmentRunEntry.deserialize(io)
            segment_run_entry_table.append(segment_run_entry)

        return cls(version, flags, quality_segment_url_modifiers,
                   segment_run_entry_table)


class FragmentRunEntry(BoxPayload):
    def __init__(self, first_fragment, first_fragment_timestamp,
                 fragment_duration, discontinuity_indicator):
        self.first_fragment = first_fragment
        self.first_fragment_timestamp = first_fragment_timestamp
        self.fragment_duration = fragment_duration
        self.discontinuity_indicator = discontinuity_indicator

    @property
    def size(self):
        size = 4+8+4

        if self.fragment_duration == 0:
            size += 1

        return size

    def _serialize(self, packet):
        packet += U32BE(self.first_fragment)
        packet += U64BE(self.first_fragment_timestamp)
        packet += U32BE(self.fragment_duration)

        if self.fragment_duration == 0:
            packet += U8(self.discontinuity_indicator)

    @classmethod
    def _deserialize(cls, io):
        first_fragment = U32BE.read(io)
        first_fragment_timestamp = U64BE.read(io)
        fragment_duration = U32BE.read(io)

        if fragment_duration == 0:
            discontinuity_indicator = U8.read(io)
        else:
            discontinuity_indicator = None

        return cls(first_fragment, first_fragment_timestamp,
                   fragment_duration, discontinuity_indicator)


class BoxPayloadAFRT(BoxPayload):
    def __init__(self, version, flags, time_scale,
                 quality_segment_url_modifiers,
                 fragment_run_entry_table):
        self.version = version
        self.flags = flags
        self.time_scale = time_scale
        self.quality_segment_url_modifiers = quality_segment_url_modifiers
        self.fragment_run_entry_table = fragment_run_entry_table

    @property
    def size(self):
        size = 1+3+4+1+4

        for quality in self.quality_segment_url_modifiers:
            size += len(quality) + 1

        for fragment_run_entry in self.fragment_run_entry_table:
            size += fragment_run_entry.size

        return size

    def _serialize(self, packet):
        packet += U8(self.version)
        packet += U24BE(self.flags)
        packet += U32BE(self.time_scale)
        packet += U8(len(self.quality_segment_url_modifiers))

        for quality in self.quality_segment_url_modifiers:
            packet += CString(quality)

        packet += U32BE(len(self.fragment_run_entry_table))
        for fragment_run_entry in self.fragment_run_entry_table:
            fragment_run_entry.serialize(packet)

    @classmethod
    def _deserialize(cls, io):
        version = U8.read(io)
        flags = U24BE.read(io)
        time_scale = U32BE.read(io)

        quality_segment_url_modifiers = []
        quality_entry_count = U8.read(io)

        for i in range(quality_entry_count):
            quality = CString.read(io)
            quality_segment_url_modifiers.append(quality)

        fragment_run_entry_count = U32BE.read(io)
        fragment_run_entry_table = []

        for i in range(fragment_run_entry_count):
            fragment_run_entry = FragmentRunEntry.deserialize(io)
            fragment_run_entry_table.append(fragment_run_entry)

        return cls(version, flags, time_scale,
                   quality_segment_url_modifiers,
                   fragment_run_entry_table)


class BoxPayloadMVEX(BoxContainer):
    pass

class BoxPayloadMFRA(BoxContainer):
    pass

class BoxPayloadTRAK(BoxContainer):
    pass

class BoxPayloadMDIA(BoxContainer):
    pass

class BoxPayloadMINF(BoxContainer):
    pass

class BoxPayloadSTBL(BoxContainer):
    pass

class BoxPayloadMOOV(BoxContainer):
    pass

class BoxPayloadMOOF(BoxContainer):
    pass

class BoxPayloadMETA(BoxContainer):
    pass


class BoxPayloadDINF(BoxContainerSingle):
    pass

PayloadTypes = {
    "ftyp": BoxPayloadFTYP,
    "mvhd": BoxPayloadMVHD,
    "trex": BoxPayloadTREX,
    "tkhd": BoxPayloadTKHD,
    "mdhd": BoxPayloadMDHD,
    "hdlr": BoxPayloadHDLR,
    "vmhd": BoxPayloadVMHD,
    "dref": BoxPayloadDREF,
    "url":  BoxPayloadURL,
    "stsd": BoxPayloadSTSD,
    "mdat": BoxPayloadMDAT,

    "abst": BoxPayloadABST,
    "asrt": BoxPayloadASRT,
    "afrt": BoxPayloadAFRT,
    "skip": BoxPayloadSKIP,
    "free": BoxPayloadFREE,

    # Containers
    "moov": BoxPayloadMOOV,
    "moof": BoxPayloadMOOF,
    "mvex": BoxPayloadMVEX,
    "mdia": BoxPayloadMDIA,
    "minf": BoxPayloadMINF,
    "meta": BoxPayloadMETA,
    "mfra": BoxPayloadMFRA,
    "stbl": BoxPayloadSTBL,
    "trak": BoxPayloadTRAK,
    "dinf": BoxPayloadDINF,
}


########NEW FILE########
__FILENAME__ = compat
import os
import sys

is_py2 = (sys.version_info[0] == 2)
is_py3 = (sys.version_info[0] == 3)
is_win32 = os.name == "nt"

if is_py2:
    _str = str
    str = unicode
    range = xrange
    string_types = (_str, unicode)
    integer_types = (int, long)

    def bytes(b=None, enc="ascii"):
        if b is None:
            return ""
        elif isinstance(b, list) or isinstance(b, tuple):
            return "".join([chr(i) for i in b])
        else:
            return _str(b)

elif is_py3:
    bytes = bytes
    str = str
    range = range
    string_types = (str,)
    integer_types = (int,)


try:
    from collections import OrderedDict
except ImportError:
    from .ordereddict import OrderedDict

__all__ = ["is_py2", "is_py3", "is_win32", "str", "bytes", "range",
           "OrderedDict"]

########NEW FILE########
__FILENAME__ = error
#!/usr/bin/env python

class FLVError(Exception):
    pass

class F4VError(Exception):
    pass

class AMFError(Exception):
    pass

__all__ = ["FLVError", "F4VError", "AMFError"]

########NEW FILE########
__FILENAME__ = f4v
#!/usr/bin/env python

from .box import Box, RawPayload
from .compat import is_py2

class F4V(object):
    def __init__(self, fd, strict=False, raw_payload=False):
        self.fd = fd
        self.raw_payload = raw_payload
        self.strict = strict

    def __iter__(self):
        return self

    def __next__(self):
        try:
            box = Box.deserialize(self.fd,
                                  strict=self.strict,
                                  raw_payload=self.raw_payload)
        except IOError:
            raise StopIteration

        return box

    if is_py2:
        next = __next__


__all__ = ["F4V"]

########NEW FILE########
__FILENAME__ = flv
#!/usr/bin/env python

from .error import FLVError
from .compat import is_py2
from .tag import Header, Tag

class FLV(object):
    def __init__(self, fd=None, strict=False):
        self.fd = fd
        self.header = Header.deserialize(self.fd)
        self.strict = strict

    def __iter__(self):
        return self

    def __next__(self):
        try:
            tag = Tag.deserialize(self.fd, strict=self.strict)
        except (IOError, FLVError):
            raise StopIteration

        return tag

    if is_py2:
        next = __next__


__all__ = ["FLV"]

########NEW FILE########
__FILENAME__ = ordereddict
# Source: http://code.activestate.com/recipes/576693/

# Backport of OrderedDict() class that runs on Python 2.4, 2.5, 2.6, 2.7 and pypy.
# Passes Python2.7's test suite and incorporates all the latest updates.

try:
    from thread import get_ident as _get_ident
except ImportError:
    from dummy_thread import get_ident as _get_ident

try:
    from _abcoll import KeysView, ValuesView, ItemsView
except ImportError:
    pass


class OrderedDict(dict):
    'Dictionary that remembers insertion order'
    # An inherited dict maps keys to values.
    # The inherited dict provides __getitem__, __len__, __contains__, and get.
    # The remaining methods are order-aware.
    # Big-O running times for all methods are the same as for regular dictionaries.

    # The internal self.__map dictionary maps keys to links in a doubly linked list.
    # The circular doubly linked list starts and ends with a sentinel element.
    # The sentinel element never gets deleted (this simplifies the algorithm).
    # Each link is stored as a list of length three:  [PREV, NEXT, KEY].

    def __init__(self, *args, **kwds):
        '''Initialize an ordered dictionary.  Signature is the same as for
        regular dictionaries, but keyword arguments are not recommended
        because their insertion order is arbitrary.

        '''
        if len(args) > 1:
            raise TypeError('expected at most 1 arguments, got %d' % len(args))
        try:
            self.__root
        except AttributeError:
            self.__root = root = []                     # sentinel node
            root[:] = [root, root, None]
            self.__map = {}
        self.__update(*args, **kwds)

    def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
        'od.__setitem__(i, y) <==> od[i]=y'
        # Setting a new item creates a new link which goes at the end of the linked
        # list, and the inherited dictionary is updated with the new key/value pair.
        if key not in self:
            root = self.__root
            last = root[0]
            last[1] = root[0] = self.__map[key] = [last, root, key]
        dict_setitem(self, key, value)

    def __delitem__(self, key, dict_delitem=dict.__delitem__):
        'od.__delitem__(y) <==> del od[y]'
        # Deleting an existing item uses self.__map to find the link which is
        # then removed by updating the links in the predecessor and successor nodes.
        dict_delitem(self, key)
        link_prev, link_next, key = self.__map.pop(key)
        link_prev[1] = link_next
        link_next[0] = link_prev

    def __iter__(self):
        'od.__iter__() <==> iter(od)'
        root = self.__root
        curr = root[1]
        while curr is not root:
            yield curr[2]
            curr = curr[1]

    def __reversed__(self):
        'od.__reversed__() <==> reversed(od)'
        root = self.__root
        curr = root[0]
        while curr is not root:
            yield curr[2]
            curr = curr[0]

    def clear(self):
        'od.clear() -> None.  Remove all items from od.'
        try:
            for node in self.__map.itervalues():
                del node[:]
            root = self.__root
            root[:] = [root, root, None]
            self.__map.clear()
        except AttributeError:
            pass
        dict.clear(self)

    def popitem(self, last=True):
        '''od.popitem() -> (k, v), return and remove a (key, value) pair.
        Pairs are returned in LIFO order if last is true or FIFO order if false.

        '''
        if not self:
            raise KeyError('dictionary is empty')
        root = self.__root
        if last:
            link = root[0]
            link_prev = link[0]
            link_prev[1] = root
            root[0] = link_prev
        else:
            link = root[1]
            link_next = link[1]
            root[1] = link_next
            link_next[0] = root
        key = link[2]
        del self.__map[key]
        value = dict.pop(self, key)
        return key, value

    # -- the following methods do not depend on the internal structure --

    def keys(self):
        'od.keys() -> list of keys in od'
        return list(self)

    def values(self):
        'od.values() -> list of values in od'
        return [self[key] for key in self]

    def items(self):
        'od.items() -> list of (key, value) pairs in od'
        return [(key, self[key]) for key in self]

    def iterkeys(self):
        'od.iterkeys() -> an iterator over the keys in od'
        return iter(self)

    def itervalues(self):
        'od.itervalues -> an iterator over the values in od'
        for k in self:
            yield self[k]

    def iteritems(self):
        'od.iteritems -> an iterator over the (key, value) items in od'
        for k in self:
            yield (k, self[k])

    def update(*args, **kwds):
        '''od.update(E, **F) -> None.  Update od from dict/iterable E and F.

        If E is a dict instance, does:           for k in E: od[k] = E[k]
        If E has a .keys() method, does:         for k in E.keys(): od[k] = E[k]
        Or if E is an iterable of items, does:   for k, v in E: od[k] = v
        In either case, this is followed by:     for k, v in F.items(): od[k] = v

        '''
        if len(args) > 2:
            raise TypeError('update() takes at most 2 positional '
                            'arguments (%d given)' % (len(args),))
        elif not args:
            raise TypeError('update() takes at least 1 argument (0 given)')
        self = args[0]
        # Make progressively weaker assumptions about "other"
        other = ()
        if len(args) == 2:
            other = args[1]
        if isinstance(other, dict):
            for key in other:
                self[key] = other[key]
        elif hasattr(other, 'keys'):
            for key in other.keys():
                self[key] = other[key]
        else:
            for key, value in other:
                self[key] = value
        for key, value in kwds.items():
            self[key] = value

    __update = update  # let subclasses override update without breaking __init__

    __marker = object()

    def pop(self, key, default=__marker):
        '''od.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised.

        '''
        if key in self:
            result = self[key]
            del self[key]
            return result
        if default is self.__marker:
            raise KeyError(key)
        return default

    def setdefault(self, key, default=None):
        'od.setdefault(k[,d]) -> od.get(k,d), also set od[k]=d if k not in od'
        if key in self:
            return self[key]
        self[key] = default
        return default

    def __repr__(self, _repr_running={}):
        'od.__repr__() <==> repr(od)'
        call_key = id(self), _get_ident()
        if call_key in _repr_running:
            return '...'
        _repr_running[call_key] = 1
        try:
            if not self:
                return '%s()' % (self.__class__.__name__,)
            return '%s(%r)' % (self.__class__.__name__, self.items())
        finally:
            del _repr_running[call_key]

    def __reduce__(self):
        'Return state information for pickling'
        items = [[k, self[k]] for k in self]
        inst_dict = vars(self).copy()
        for k in vars(OrderedDict()):
            inst_dict.pop(k, None)
        if inst_dict:
            return (self.__class__, (items,), inst_dict)
        return self.__class__, (items,)

    def copy(self):
        'od.copy() -> a shallow copy of od'
        return self.__class__(self)

    @classmethod
    def fromkeys(cls, iterable, value=None):
        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
        and values equal to v (which defaults to None).

        '''
        d = cls()
        for key in iterable:
            d[key] = value
        return d

    def __eq__(self, other):
        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
        while comparison to a regular mapping is order-insensitive.

        '''
        if isinstance(other, OrderedDict):
            return len(self)==len(other) and self.items() == other.items()
        return dict.__eq__(self, other)

    def __ne__(self, other):
        return not self == other

    # -- the following methods are only used in Python 2.7 --

    def viewkeys(self):
        "od.viewkeys() -> a set-like object providing a view on od's keys"
        return KeysView(self)

    def viewvalues(self):
        "od.viewvalues() -> an object providing a view on od's values"
        return ValuesView(self)

    def viewitems(self):
        "od.viewitems() -> a set-like object providing a view on od's items"
        return ItemsView(self)

########NEW FILE########
__FILENAME__ = packet
#!/usr/bin/env python

import struct

class Packet(object):
    exception = IOError

    @classmethod
    def _deserialize(cls, fd):
        raise NotImplementedError

    @classmethod
    def _deserialize_from(cls, buf, offset, **kw):
        raise NotImplementedError

    @classmethod
    def deserialize(cls, fd, **kw):
        try:
            return cls._deserialize(fd, **kw)
        except (struct.error, IOError) as err:
            raise cls.exception(err)

    @classmethod
    def deserialize_from(cls, buf, offset, **kw):
        try:
            return cls._deserialize_from(buf, offset, **kw)
        except (struct.error, IOError) as err:
            raise cls.exception(err)

    def _serialize(self):
        raise NotImplementedError

    def _serialize_into(self, buf, offset):
        raise NotImplementedError

    def serialize(self, packet=None, **kw):
        if packet is None:
            packet = bytearray()

        self._serialize(packet, **kw)

        return packet

    def serialize2(self):
        buf = bytearray(self.size)
        self.serialize_into(buf, 0)
        return buf

    def serialize_into(self, buf, offset):
        return self._serialize_into(buf, offset)

    def __bytes__(self):
        return self.serialize()

class TagData(Packet):
    @property
    def size(self):
        if isinstance(self.data, Packet):
            return self.data.size
        else:
            return len(self.data)

__all__ = ["Packet", "TagData"]

########NEW FILE########
__FILENAME__ = tag
#!/usr/bin/env python

from ctypes import BigEndianStructure, Union, c_uint8
from io import BytesIO

from .compat import *
from .error import *
from .packet import *
from .types import *
from .util import *

TAG_TYPE_AUDIO = 8
TAG_TYPE_VIDEO = 9
TAG_TYPE_SCRIPT = 18

AUDIO_CODEC_ID_PCM = 0
AUDIO_CODEC_ID_ADPCM = 1
AUDIO_CODEC_ID_MP3 = 2
AUDIO_CODEC_ID_PCM_LE = 3
AUDIO_CODEC_ID_NELLYMOSSER_16 = 4
AUDIO_CODEC_ID_NELLYMOSSER_8 = 5
AUDIO_CODEC_ID_NELLYMOSSER = 6
AUDIO_CODEC_ID_G711_A = 7
AUDIO_CODEC_ID_G711_MU = 8
AUDIO_CODEC_ID_AAC = 10
AUDIO_CODEC_ID_SPEEX = 11
AUDIO_CODEC_ID_MP3_8 = 14
AUDIO_CODEC_ID_DEVICE = 15

AUDIO_RATE_5_5_KHZ = 0
AUDIO_RATE_11_KHZ = 1
AUDIO_RATE_22_KHZ = 2
AUDIO_RATE_44_KHZ = 3

AUDIO_BIT_RATE_8 = 0
AUDIO_BIT_RATE_16 = 1

AUDIO_TYPE_MONO = 0
AUDIO_TYPE_STEREO = 1

AAC_PACKET_TYPE_SEQUENCE_HEADER = 0
AAC_PACKET_TYPE_RAW = 1

VIDEO_FRAME_TYPE_KEY_FRAME = 1
VIDEO_FRAME_TYPE_INTER_FRAME = 2
VIDEO_FRAME_TYPE_DIS_INTER_FRAME = 3
VIDEO_FRAME_TYPE_GEN_KEY_FRAME = 4
VIDEO_FRAME_TYPE_COMMAND_FRAME = 5

VIDEO_CODEC_ID_H263 = 2
VIDEO_CODEC_ID_SCREEN_VIDEO = 3
VIDEO_CODEC_ID_VP6 = 4
VIDEO_CODEC_ID_VP6A = 5
VIDEO_CODEC_ID_SCREEN_VIDEO_2 = 6
VIDEO_CODEC_ID_AVC = 7

AVC_PACKET_TYPE_SEQUENCE_HEADER = 0
AVC_PACKET_TYPE_NALU = 1
AVC_PACKET_TYPE_END_OF_SEQUENCE = 2


class TypeFlags(Union):
    class Bits(BigEndianStructure):
        _fields_ = [("rsv1", c_uint8, 5),
                    ("audio", c_uint8, 1),
                    ("rsv2", c_uint8, 1),
                    ("video", c_uint8, 1)]

    _fields_ = [("bit", Bits), ("byte", c_uint8)]


class TagFlags(Union):
    class Bits(BigEndianStructure):
        _fields_ = [("rsv", c_uint8, 2),
                    ("filter", c_uint8, 1),
                    ("type", c_uint8, 5)]

    _fields_ = [("bit", Bits), ("byte", c_uint8)]


class AudioFlags(Union):
    class Bits(BigEndianStructure):
        _fields_ = [("codec", c_uint8, 4),
                    ("rate", c_uint8, 2),
                    ("bits", c_uint8, 1),
                    ("type", c_uint8, 1)]

    _fields_ = [("bit", Bits), ("byte", c_uint8)]


class VideoFlags(Union):
    class Bits(BigEndianStructure):
        _fields_ = [("type", c_uint8, 4),
                    ("codec", c_uint8, 4)]

    _fields_ = [("bit", Bits), ("byte", c_uint8)]


class Header(Packet):
    exception = FLVError

    def __init__(self, version=1, has_audio=False, has_video=False, data_offset=9, tag0_size=0):
        self.version = version
        self.flags = TypeFlags()
        self.flags.bit.audio = int(has_audio)
        self.flags.bit.video = int(has_video)
        self.data_offset = data_offset
        self.tag0_size = tag0_size

    def __repr__(self):
        reprformat = "<Header version={version} has_audio={has_audio} has_video={has_video} data_offset={offset}>"
        return reprformat.format(version=self.version, offset=self.data_offset,
                                 has_audio=self.has_audio, has_video=self.has_video)

    @property
    def size(self):
        return 13

    has_audio = flagproperty("flags", "audio", True)
    has_video = flagproperty("flags", "video", True)

    @classmethod
    def _deserialize(cls, io):
        head = io.read(3)

        if head != b"FLV":
            raise FLVError("Invalid FLV header")

        version = U8.read(io)
        flags = TypeFlags()
        flags.byte = U8.read(io)
        offset = U32BE.read(io)
        tag0_size = U32BE.read(io)

        return Header(version, bool(flags.bit.audio), bool(flags.bit.video),
                      offset, tag0_size)

    @classmethod
    def _deserialize_from(cls, buf, offset):
        head = buf[offset:offset + 3]
        offset += 3

        if head != b"FLV":
            raise FLVError("Invalid FLV header")

        flags = TypeFlags()

        (version, flags.byte, tag0_offset,
         tag0_size) = unpack_many_from(buf, offset, (U8, U8, U32BE, U32BE))

        rval = Header(version, bool(flags.bit.audio), bool(flags.bit.video),
                      tag0_offset, tag0_size)

        offset += 10

        return (rval, offset)

    def _serialize(self, packet):
        packet += b"FLV"
        packet += U8(self.version)
        packet += U8(self.flags.byte)
        packet += U32BE(self.data_offset)
        packet += U32BE(self.tag0_size)

    def _serialize_into(self, packet, offset):
        offset = pack_bytes_into(packet, offset, b"FLV")
        offset = pack_many_into(packet, offset,
                                (U8, U8, U32BE, U32BE),
                                (self.version, self.flags.byte,
                                 self.data_offset, self.tag0_size))

        return offset


class Tag(Packet):
    exception = FLVError

    def __init__(self, typ=TAG_TYPE_SCRIPT, timestamp=0, data=None,
                 streamid=0, filter=False, padding=None):
        self.flags = TagFlags()
        self.flags.bit.rsv = 0
        self.flags.bit.type = typ
        self.flags.bit.filter = int(filter)

        if not data:
            data = RawData()

        if not padding:
            padding = b""

        self.data = data
        self.streamid = streamid
        self.timestamp = timestamp
        self.padding = padding

    def __repr__(self):
        reprformat = "<Tag type={type} timestamp={timestamp} streamid={streamid} filter={filter} data={data}>"
        return reprformat.format(type=self.type, timestamp=self.timestamp,
                                 streamid=self.streamid, filter=self.filter,
                                 data=repr(self.data))

    type = flagproperty("flags", "type")
    filter = flagproperty("flags", "filter", True)

    @property
    def data_size(self):
        return self.data.size

    @property
    def tag_size(self):
        return 11 + self.data_size + len(self.padding)

    @property
    def size(self):
        return 4 + self.tag_size

    @classmethod
    def _deserialize(cls, io, strict=False, raw_data=False):
        header = io.read(11)

        if len(header) < 11:
            raise FLVError("Insufficient tag header")

        (flagb, data_size, timestamp, timestamp_ext,
         streamid) = unpack_many_from(header, 0, (U8, U24BE, U24BE, U8, U24BE))

        flags = TagFlags()
        flags.byte = flagb
        timestamp |= timestamp_ext << 24

        # Don't parse encrypted data
        if flags.bit.filter == 1:
            raw_data = True

        if flags.bit.type in TagDataTypes:
            datacls = TagDataTypes[flags.bit.type]
        else:
            raise FLVError("Unknown tag type!")

        tag_data = chunked_read(io, data_size, exception=FLVError)

        if data_size > 0 and not raw_data:
            tag_data_io = BytesIO(tag_data)
            data = datacls.deserialize(tag_data_io)
            padding = tag_data_io.read()
        else:
            data = RawData(tag_data)
            padding = b""

        tag = Tag(flags.bit.type, timestamp, data,
                  streamid, bool(flags.bit.filter), padding)

        tag_size = U32BE.read(io)

        if strict and tag.tag_size != tag_size:
            raise FLVError("Data size mismatch when deserialising tag")

        return tag

    @classmethod
    def _deserialize_from(cls, buf, offset, strict=False,
                          raw_data=False):
        (flagb, data_size, timestamp, timestamp_ext,
         streamid) = unpack_many_from(buf, offset, (U8, U24BE, U24BE, U8, U24BE))

        offset += 11

        flags = TagFlags()
        flags.byte = flagb
        timestamp |= timestamp_ext << 24

        # Don't parse encrypted data
        if flags.bit.filter == 1:
            raw_data = True

        if flags.bit.type in TagDataTypes:
            datacls = TagDataTypes[flags.bit.type]
        else:
            raise FLVError("Unknown tag type!")

        if data_size > 0 and not raw_data:
            data, doffset = datacls.deserialize_from(buf, offset, buf_size=data_size)
            padding = buf[doffset:offset + data_size]
        else:
            data = RawData(buf[offset:offset + data_size])
            padding = b""

        offset += data_size

        tag = Tag(flags.bit.type, timestamp, data,
                  streamid, bool(flags.bit.filter), padding)

        tag_size = U32BE.unpack_from(buf, offset)[0]
        offset += U32BE.size

        if strict and tag.tag_size != tag_size:
            raise FLVError("Data size mismatch when deserialising tag")

        return (tag, offset)

    def _serialize(self, packet, strict=True):
        packet += U8(self.flags.byte)
        packet += U24BE(self.data_size)

        packet += U24BE(self.timestamp & 0xFFFFFF)
        packet += U8((self.timestamp >> 24) & 0x7F)
        packet += U24BE(self.streamid)

        self.data.serialize(packet)
        packet += self.padding

        if strict and self.tag_size != len(packet):
            raise FLVError("Data size mismatch when serialising tag")

        packet += U32BE(self.tag_size)

    def _serialize_into(self, packet, offset):
        offset = pack_many_into(packet, offset,
                                (U8, U24BE, U24BE, U8, U24BE),
                                (self.flags.byte, self.data_size,
                                 self.timestamp & 0xFFFFFF,
                                 (self.timestamp >> 24) & 0x7F,
                                 self.streamid))

        offset = self.data.serialize_into(packet, offset)
        offset = pack_bytes_into(packet, offset, self.padding)

        U32BE.pack_into(packet, offset, self.tag_size)
        offset += 4

        return offset


class FrameData(TagData):
    def __init__(self, type=1, data=b""):
        self.type = type
        self.data = data

    def __repr__(self):
        if not isinstance(self.data, Packet):
            data = ("<{0}>").format(type(self.data).__name__)
        else:
            data = repr(self.data)

        reprformat = "<{cls} type={type} data={data}>"
        return reprformat.format(cls=type(self).__name__, type=self.type, data=data)

    @property
    def size(self):
        return TagData.size.__get__(self) + 1

    @classmethod
    def _deserialize(cls, io):
        typ = U8.read(io)
        data = io.read()

        return cls(typ, data)

    @classmethod
    def _deserialize_from(cls, buf, offset, buf_size=None):
        if not buf_size:
            buf_size = len(buf)

        typ = U8.unpack_from(buf, offset)[0]
        offset += U8.size
        buf_size -= U8.size

        data = buf[offset:offset + buf_size]
        offset += buf_size

        return (cls(typ, data), offset)

    def _serialize(self, packet):
        packet += U8(self.type)
        packet += self.data

    def _serialize_into(self, packet, offset):
        U8.pack_into(packet, offset, self.type)
        offset += U8.size
        offset = pack_bytes_into(packet, offset, self.data)

        return offset


class RawData(TagData):
    def __init__(self, data=None):
        if not data:
            data = b""

        self.data = data

    def __repr__(self):
        return "<RawData>"

    @classmethod
    def _deserialize(cls, io):
        return cls(io.read())

    @classmethod
    def _deserialize_from(cls, buf, offset, buf_size=None):
        if not data_size:
            buf_size = len(buf)

        data = buf[offset:offset + buf_size]
        rval = cls(data)
        offset += len(data)

        return (rval, offset)

    def _serialize(self, packet):
        packet += self.data

    def _serialize_into(self, packet, offset):
        return pack_bytes_into(packet, offset, self.data)


class AudioData(TagData):
    def __init__(self, codec=0, rate=0, bits=0, type=0, data=None):
        self.flags = AudioFlags()
        self.flags.bit.codec = codec
        self.flags.bit.rate = rate
        self.flags.bit.bits = bits
        self.flags.bit.type = type
        self.data = data

    codec = flagproperty("flags", "codec")
    rate = flagproperty("flags", "rate")
    bits = flagproperty("flags", "bits")
    type = flagproperty("flags", "type")

    def __repr__(self):
        if not isinstance(self.data, Packet):
            data = ("<{0}>").format(type(self.data).__name__)
        else:
            data = repr(self.data)

        reprformat = "<AudioData type={type} codec={codec} rate={rate} bits={bits} data={data}>"
        return reprformat.format(type=self.type, codec=self.codec, rate=self.rate,
                                 bits=self.bits, data=data)

    @property
    def size(self):
        return TagData.size.__get__(self) + 1

    @classmethod
    def _deserialize(cls, io):
        flags = AudioFlags()
        flags.byte = U8.read(io)

        if flags.bit.codec == AUDIO_CODEC_ID_AAC:
            data = AACAudioData.deserialize(io)
        else:
            data = io.read()

        return cls(flags.bit.codec, flags.bit.rate, flags.bit.bits,
                   flags.bit.type, data)

    @classmethod
    def _deserialize_from(cls, buf, offset, buf_size=None):
        if not buf_size:
            buf_size = len(buf)

        flags = AudioFlags()
        flags.byte = U8.unpack_from(buf, offset)[0]
        offset += U8.size
        buf_size -= U8.size

        if flags.bit.codec == 10:
            data, offset = AACAudioData.deserialize_from(buf, offset,
                                                         buf_size=buf_size)
        else:
            data = buf[offset:offset + buf_size]
            offset += buf_size

        obj = cls(flags.bit.codec, flags.bit.rate, flags.bit.bits,
                  flags.bit.type, data)

        return (obj, offset)

    def _serialize(self, packet):
        packet += U8(self.flags.byte)

        if isinstance(self.data, Packet):
            self.data.serialize(packet)
        else:
            packet += self.data

    def _serialize_into(self, packet, offset):
        U8.pack_into(packet, offset, self.flags.byte)
        offset += 1

        if isinstance(self.data, Packet):
            offset = self.data.serialize_into(packet, offset)
        else:
            offset = pack_bytes_into(packet, offset, self.data)

        return offset


class AACAudioData(FrameData):
    pass


class VideoData(TagData):
    def __init__(self, type=0, codec=0, data=None):
        self.flags = VideoFlags()
        self.flags.bit.type = type
        self.flags.bit.codec = codec

        if not data:
            data = b""

        self.data = data

    def __repr__(self):
        if not isinstance(self.data, Packet):
            data = ("<{0}>").format(type(self.data).__name__)
        else:
            data = repr(self.data)

        reprformat = "<VideoData type={type} codec={codec} data={data}>"
        return reprformat.format(type=self.type, codec=self.codec, data=data)

    type = flagproperty("flags", "type")
    codec = flagproperty("flags", "codec")

    @property
    def size(self):
        return TagData.size.__get__(self) + 1

    @classmethod
    def _deserialize(cls, io):
        flags = VideoFlags()
        flags.byte = U8.read(io)

        if flags.bit.type == VIDEO_FRAME_TYPE_COMMAND_FRAME:
            data = VideoCommandFrame.deserialize(io)
        else:
            if flags.bit.codec == VIDEO_CODEC_ID_AVC:
                data = AVCVideoData.deserialize(io)
            else:
                data = io.read()

        return cls(flags.bit.type, flags.bit.codec, data)

    @classmethod
    def _deserialize_from(cls, buf, offset, buf_size=None):
        if not buf_size:
            buf_size = len(buf)

        flags = VideoFlags()
        flags.byte = U8.unpack_from(buf, offset)[0]
        offset += U8.size
        buf_size -= U8.size

        if flags.bit.type == VIDEO_FRAME_TYPE_COMMAND_FRAME:
            data, offset = VideoCommandFrame.deserialize_from(buf, offset,
                                                              buf_size=buf_size)
        else:
            if flags.bit.codec == VIDEO_CODEC_ID_AVC:
                data, offset = AVCVideoData.deserialize_from(buf, offset,
                                                             buf_size=buf_size)
            else:
                data = buf[offset:offset + buf_size]
                offset += buf_size

        obj = cls(flags.bit.type, flags.bit.codec, data)

        return (obj, offset)

    def _serialize(self, packet):
        packet += U8(self.flags.byte)

        if isinstance(self.data, Packet):
            self.data.serialize(packet)
        else:
            packet += self.data

    def _serialize_into(self, packet, offset):
        U8.pack_into(packet, offset, self.flags.byte)
        offset += 1

        if isinstance(self.data, Packet):
            offset = self.data.serialize_into(packet, offset)
        else:
            offset = pack_bytes_into(packet, offset, self.data)

        return offset


class VideoCommandFrame(FrameData):
    pass


class AVCVideoData(TagData):
    def __init__(self, type=1, composition_time=0, data=None):
        self.type = type
        self.composition_time = composition_time

        if not data:
            data = b""

        self.data = data

    def __repr__(self):
        if not isinstance(self.data, Packet):
            data = ("<{0}>").format(type(self.data).__name__)
        else:
            data = repr(self.data)

        reprformat = "<AVCVideoData type={type} composition_time={composition_time} data={data}>"
        return reprformat.format(type=self.type, composition_time=self.composition_time,
                                 data=data)

    @property
    def size(self):
        return TagData.size.__get__(self) + 4

    @classmethod
    def _deserialize(cls, io):
        typ = U8.read(io)
        composition_time = S24BE.read(io)
        data = io.read()

        return cls(typ, composition_time, data)

    @classmethod
    def _deserialize_from(cls, buf, offset, buf_size=None):
        if not buf_size:
            buf_size = None

        typ = U8.unpack_from(buf, offset)[0]
        offset += U8.size

        composition_time = S24BE.unpack_from(buf, offset)[0]
        offset += S24BE.size

        buf_size -= U8.size + S24BE.size
        data = buf[offset:offset + buf_size]
        offset += len(data)

        obj = cls(typ, composition_time, data)

        return (obj, offset)

    def _serialize(self, packet):
        packet += U8(self.type)
        packet += S24BE(self.composition_time)
        packet += self.data

    def _serialize_into(self, packet, offset):
        offset = pack_many_into(packet, offset,
                                (U8, S24BE),
                                (self.type, self.composition_time))

        offset = pack_bytes_into(packet, offset, self.data)

        return offset



class ScriptData(TagData):
    def __init__(self, name=None, value=None):
        self.name = name
        self.value = value

    def __repr__(self):
        reprformat = "<ScriptData name={name} value={value}>"
        return reprformat.format(name=self.name, value=self.value)

    @property
    def size(self):
        size = ScriptDataValue.size(self.name)
        size += ScriptDataValue.size(self.value)

        return size

    @classmethod
    def _deserialize(cls, io):
        name  = ScriptDataValue.read(io)
        value = ScriptDataValue.read(io)

        return ScriptData(name, value)

    @classmethod
    def _deserialize_from(cls, buf, offset, buf_size=None):
        name, offset = ScriptDataValue.unpack_from(buf, offset)
        value, offset = ScriptDataValue.unpack_from(buf, offset)

        return (ScriptData(name, value), offset)

    def _serialize(self, packet):
        packet += ScriptDataValue.pack(self.name)
        packet += ScriptDataValue.pack(self.value)

    def _serialize_into(self, packet, offset):
        offset = ScriptDataValue.pack_into(packet, offset, self.name)
        offset = ScriptDataValue.pack_into(packet, offset, self.value)

        return offset


TagDataTypes = {
    TAG_TYPE_AUDIO: AudioData,
    TAG_TYPE_VIDEO: VideoData,
    TAG_TYPE_SCRIPT: ScriptData
}



__all__ = ["Header", "Tag", "FrameData", "AudioData", "AACAudioData",
           "VideoData", "VideoCommandFrame", "AVCVideoData",
           "ScriptData", "TAG_TYPE_VIDEO", "TAG_TYPE_AUDIO", "TAG_TYPE_SCRIPT"]

########NEW FILE########
__FILENAME__ = types
from .compat import OrderedDict, is_py2, str, bytes, integer_types, string_types
from .util import pack_bytes_into

from collections import namedtuple
from struct import Struct, error as struct_error
from inspect import getargspec

(SCRIPT_DATA_TYPE_NUMBER, SCRIPT_DATA_TYPE_BOOLEAN,
 SCRIPT_DATA_TYPE_STRING, SCRIPT_DATA_TYPE_OBJECT,
 SCRIPT_DATA_TYPE_RESERVED, SCRIPT_DATA_TYPE_NULL,
 SCRIPT_DATA_TYPE_UNDEFINED, SCRIPT_DATA_TYPE_REFERENCE,
 SCRIPT_DATA_TYPE_ECMAARRAY, SCRIPT_DATA_TYPE_OBJECTEND,
 SCRIPT_DATA_TYPE_STRICTARRAY, SCRIPT_DATA_TYPE_DATE,
 SCRIPT_DATA_TYPE_LONGSTRING) = range(13)

SCRIPT_DATA_TYPE_AMF3 = 0x11

(AMF3_TYPE_UNDEFINED, AMF3_TYPE_NULL, AMF3_TYPE_FALSE, AMF3_TYPE_TRUE,
 AMF3_TYPE_INTEGER, AMF3_TYPE_DOUBLE, AMF3_TYPE_STRING, AMF3_TYPE_XML_DOC,
 AMF3_TYPE_DATE, AMF3_TYPE_ARRAY, AMF3_TYPE_OBJECT, AMF3_TYPE_XML,
 AMF3_TYPE_BYTE_ARRAY, AMF3_TYPE_VECTOR_INT, AMF3_TYPE_VECTOR_UINT,
 AMF3_TYPE_VECTOR_DOUBLE, AMF3_TYPE_VECTOR_OBJECT, AMF3_TYPE_DICT) = range(0x12)

AMF3_EMPTY_STRING = 0x01
AMF3_DYNAMIC_OBJECT = 0x0b
AMF3_CLOSE_DYNAMIC_OBJECT = 0x01
AMF3_CLOSE_DYNAMIC_ARRAY = 0x01
AMF3_MIN_INTEGER = -268435456
AMF3_MAX_INTEGER = 268435455


class PrimitiveType(Struct):
    def __call__(self, *args):
        return self.pack(*args)

    def read(self, fd):
        data = fd.read(self.size)

        if len(data) != self.size:
            raise IOError("Unable to read required amount of data")

        return self.unpack(data)[0]

class PrimitiveClassType(PrimitiveType):
    def __init__(self, format, cls):
        self.cls = cls

        PrimitiveType.__init__(self, format)

    def pack(self, val):
        return PrimitiveType.pack(self, *val)

    def pack_into(self, buf, offset, val):
        return PrimitiveType.pack_into(self, buf, offset, *val)

    def unpack(self, data):
        vals = PrimitiveType.unpack(self, data)
        rval = self.cls(*vals)

        return (rval,)

    def unpack_from(self, buf, offset):
        vals = PrimitiveType.unpack_from(self, buf, offset)
        rval = self.cls(*vals)

        return (rval,)


class DynamicType(object):
    def __new__(cls, *args, **kwargs):
        return cls.pack(*args, **kwargs)

    @classmethod
    def size(cls, val):
        raise NotImplementedError

    @classmethod
    def pack(cls, val):
        raise NotImplementedError

    @classmethod
    def pack_into(cls, buf, offset, val):
        raise NotImplementedError

    @classmethod
    def read(cls, fd):
        raise NotImplementedError

    @classmethod
    def unpack_from(cls, buf, offset):
        raise NotImplementedError

    @classmethod
    def unpack(cls, buf):
        return cls.unpack_from(buf, 0)


class TwosComplement(PrimitiveType):
    def __init__(self, primitive):
        self.primitive = primitive

        bits = self.primitive.size * 8

        self.maxval = 1 << bits
        self.midval = self.maxval >> 1

        self.upper = self.midval - 1
        self.lower = -self.midval

    @property
    def size(self):
        return 3

    def pack(self, val):
        if val < self.lower or val > self.upper:
            msg = "{0} format requires {1} <= number <= {2}".format(self.primitive.format,
                                                                    self.lower, self.upper)
            raise struct_error(msg)

        if val < 0:
            val = val + self.maxval

        return self.primitive.pack(val)

    def pack_into(self, buf, offset, val):
        if val < self.lower or val > self.upper:
            msg = "{0} format requires {1} <= number <= {2}".format(self.primitive.format,
                                                                    self.lower, self.upper)
            raise struct_error(msg)

        if val < 0:
            val = val + self.maxval

        return self.primitive.pack_into(buf, offset, val)

    def unpack(self, data):
        val = self.primitive.unpack(data)[0]

        if val & self.midval:
            val = val - self.maxval

        return (val,)

    def unpack_from(self, buf, offset):
        val = self.primitive.unpack_from(buf, offset)[0]

        if val & self.midval:
            val = val - self.maxval

        return (val,)


class HighLowCombo(PrimitiveType):
    def __init__(self, format, highbits, reverse=True):
        PrimitiveType.__init__(self, format)

        self.highbits = highbits
        self.lowmask = (1 << highbits) - 1
        self.reverse = reverse
        self.lower = 0
        self.upper = (1 << (self.size * 8)) - 1

    def pack(self, val):
        if val < self.lower or val > self.upper:
            msg = "{0} format requires {1} <= number <= {2}".format(self.format,
                                                                    self.lower, self.upper)
            raise struct_error(msg)

        if self.reverse:
            high = val >> self.highbits
            low = val & self.lowmask
        else:
            high = val & self.lowmask
            low = val >> self.highbits

        return PrimitiveType.pack(self, high, low)

    def pack_into(self, buf, offset, val):
        if val < self.lower or val > self.upper:
            msg = "{0} format requires {1} <= number <= {2}".format(self.format,
                                                                    self.lower, self.upper)
            raise struct_error(msg)

        if self.reverse:
            high = val >> self.highbits
            low = val & self.lowmask
        else:
            high = val & self.lowmask
            low = val >> self.highbits

        return PrimitiveType.pack_into(self, buf, offset, high, low)

    def unpack(self, data):
        high, low = PrimitiveType.unpack(self, data)

        if self.reverse:
            ret = high << self.highbits
            ret |= low
        else:
            ret = high
            ret |= low << self.highbits

        return (ret,)

    def unpack_from(self, buf, offset):
        high, low = PrimitiveType.unpack_from(self, buf, offset)

        if self.reverse:
            ret = high << self.highbits
            ret |= low
        else:
            ret = high
            ret |= low << self.highbits

        return (ret,)



class FixedPoint(PrimitiveType):
    def __init__(self, format, bits):
        self.divider = float(1 << bits)

        PrimitiveType.__init__(self, format)

    def pack(self, val):
        val *= self.divider

        return PrimitiveType.pack(self, int(val))

    def pack_into(self, buf, offset, val):
        val *= self.divider

        return PrimitiveType.pack_into(self, buf, offset, int(val))

    def unpack(self, data):
        val = PrimitiveType.unpack(self, data)[0]
        val /= self.divider

        return (val,)

    def unpack_from(self, buf, offset):
        val = PrimitiveType.unpack_from(self, buf, offset)[0]
        val /= self.divider

        return (val,)

class PaddedBytes(PrimitiveType):
    def __init__(self, size, padding):
        self.padded_size = size
        self.padding = bytes(padding, "ascii")

    @property
    def size(self):
        return self.padded_size

    def pack(self, val):
        rval = bytes(val[:self.size], "ascii")

        if len(rval) < self.size:
            paddinglen = self.size - len(rval)
            rval += self.padding * paddinglen

        return rval

    def pack_into(self, buf, offset, val):
        rval = bytes(val[:self.size], "ascii")
        offset = pack_bytes_into(buf, offset, rval)

        if len(rval) < self.size:
            paddinglen = self.size - len(rval)
            offset = pack_bytes_into(buf, offset, self.padding * paddinglen)

    def unpack(self, data):
        return (str(data.rstrip(self.padding), "ascii"),)

    def unpack_from(self, buf, offset):
        data = buf[offset:offset + self.padded_size]
        return (str(data.rstrip(self.padding), "ascii"),)


""" 8-bit integer """

U8 = PrimitiveType("B")
S8 = PrimitiveType("b")


""" 16-bit integer """

U16BE = PrimitiveType(">H")
S16BE = PrimitiveType(">h")
U16LE = PrimitiveType("<H")
S16LE = PrimitiveType("<h")


""" 24-bit integer """

U24BE = HighLowCombo(">HB", 8, True)
S24BE = TwosComplement(U24BE)
U24LE = HighLowCombo("<HB", 16, False)
S24LE = TwosComplement(U24LE)


""" 32-bit integer """

U32BE = PrimitiveType(">I")
S32BE = PrimitiveType(">i")
U32LE = PrimitiveType("<I")
S32LE = PrimitiveType("<i")


""" 64-bit integer """

U64BE = PrimitiveType(">Q")
U64LE = PrimitiveType("<Q")


""" Fixed point numbers """

U8_8BE = FixedPoint(">H", 8)
S8_8BE = FixedPoint(">h", 8)
U16_16BE = FixedPoint("<I", 16)
S16_16BE = FixedPoint("<i", 16)

U8_8LE = FixedPoint("<H", 8)
S8_8LE = FixedPoint("<h", 8)
U16_16LE = FixedPoint("<I", 16)
S16_16LE = FixedPoint("<i", 16)

DoubleLE = PrimitiveType("<d")
DoubleBE = PrimitiveType(">d")


""" Various types """

FourCC = PaddedBytes(4, " ")


""" Script data types """

ScriptDataNumber = DoubleBE
ScriptDataBoolean = PrimitiveType("?")

class U3264(DynamicType):
    @classmethod
    def size(cls, val, version):
        if version == 1:
            return U64BE.size
        else:
            return U32BE.size

    @classmethod
    def pack(cls, val, version):
        if version == 1:
            return U64BE(val)
        else:
            return U32BE(val)

    @classmethod
    def pack_into(cls, buf, offset, val, version):
        if version == 1:
            prim = U64BE
        else:
            prim = U32BE

        prim.pack_into(buf, offset, val)

        return offset + prim.size

    @classmethod
    def read(cls, fd, version):
        if version == 1:
            return U64BE.read(fd)
        else:
            return U32BE.read(fd)

    @classmethod
    def unpack_from(cls, buf, offset, version):
        if version == 1:
            prim = U64BE
        else:
            prim = U32BE

        rval = prim.unpack_from(buf, offset)
        offset += prim.size

        return (rval, offset)


class String(DynamicType):
    @classmethod
    def size(cls, *args, **kwargs):
        return len(cls.pack(*args, **kwargs))

    @classmethod
    def pack(cls, val, encoding="utf8", errors="ignore"):
        rval = val.encode(encoding, errors)

        return rval

    @classmethod
    def pack_into(cls, buf, offset, val,
                  encoding="utf8", errors="ignore"):

        return pack_bytes_into(buf, offset,
                               val.encode(encoding, errors))

class CString(String):
    EndMarker = b"\x00"

    @classmethod
    def pack(cls, *args, **kwargs):
        rval = String.pack(*args, **kwargs)
        rval += CString.EndMarker

        return rval

    @classmethod
    def pack_into(cls, buf, offset, *args, **kwargs):
        offset = String.pack_into(buf, offset, *args, **kwargs)
        U8.pack_into(buf, offset, 0)

        return offset + 1

    @classmethod
    def read(cls, fd, encoding="utf8", errors="ignore"):
        rval = b""

        while True:
            ch = fd.read(1)

            if len(ch) == 0 or ch == CString.EndMarker:
                break

            rval += ch

        return rval.decode(encoding, errors)

    @classmethod
    def unpack_from(cls, buf, offset, encoding="utf8", errors="ignore"):
        end = buf[offset:].find(b"\x00")
        rval = buf[offset:offset + end].decode(encoding, errors)
        offset += end + 1

        return (rval, offset)


class ScriptDataType(object):
    __identifier__ = 0

class ScriptDataString(String):
    __size_primitive__ = U16BE

    @classmethod
    def pack(cls, val, *args, **kwargs):
        rval = String.pack(val, *args, **kwargs)
        size = cls.__size_primitive__(len(rval))

        return size + rval

    @classmethod
    def pack_into(cls, buf, offset, val, *args, **kwargs):
        noffset = String.pack_into(buf, offset + cls.__size_primitive__.size,
                                   val, *args, **kwargs)

        cls.__size_primitive__.pack_into(buf, offset,
                                         (noffset - offset) - cls.__size_primitive__.size)

        return noffset

    @classmethod
    def read(cls, fd, encoding="utf8", errors="ignore"):
        size = cls.__size_primitive__.read(fd)
        data = fd.read(size)

        return data.decode(encoding, errors)

    @classmethod
    def unpack_from(cls, buf, offset, encoding="utf8", errors="ignore"):
        size = cls.__size_primitive__.unpack_from(buf, offset)[0]
        offset += cls.__size_primitive__.size

        data = buf[offset:offset + size].decode(encoding, errors)
        offset += size

        return (data, offset)

class ScriptDataLongString(ScriptDataString):
    __size_primitive__ = U32BE


class ScriptDataObjectEnd(Exception):
    pass

class ScriptDataObject(OrderedDict, ScriptDataType):
    __identifier__ = SCRIPT_DATA_TYPE_OBJECT

    @classmethod
    def size(cls, val):
        size = 3

        for key, value in val.items():
            size += ScriptDataString.size(key)
            size += ScriptDataValue.size(value)

        return size

    @classmethod
    def pack(cls, val):
        rval = b""

        for key, value in val.items():
            rval += ScriptDataString(key)
            rval += ScriptDataValue.pack(value)

        # Zero length key + object end identifier ends object
        rval += ScriptDataString("")
        rval += U8(SCRIPT_DATA_TYPE_OBJECTEND)

        return rval

    @classmethod
    def pack_into(cls, buf, offset, val):
        for key, value in val.items():
            offset = ScriptDataString.pack_into(buf, offset, key)
            offset = ScriptDataValue.pack_into(buf, offset, value)

        # Zero length key + object end identifier ends object
        offset = ScriptDataString.pack_into(buf, offset, "")
        U8.pack_into(buf, offset, SCRIPT_DATA_TYPE_OBJECTEND)

        return offset + U8.size

    @classmethod
    def read(cls, fd):
        rval = cls()

        while True:
            try:
                key = ScriptDataString.read(fd)
                value = ScriptDataValue.read(fd)
            except ScriptDataObjectEnd:
                break

            if len(key) == 0:
                break

            rval[key] = value

        return rval

    @classmethod
    def unpack_from(cls, buf, offset):
        rval = cls()

        while True:
            try:
                key, offset = ScriptDataString.unpack_from(buf, offset)
                value, offset = ScriptDataValue.unpack_from(buf, offset)
            except ScriptDataObjectEnd:
                offset += 1
                break

            if len(key) == 0:
                break

            rval[key] = value

        return (rval, offset)


class ScriptDataECMAArray(ScriptDataObject):
    __identifier__ = SCRIPT_DATA_TYPE_ECMAARRAY

    @classmethod
    def size(cls, val):
        return 4 + ScriptDataObject.size(val)

    @classmethod
    def pack(cls, val):
        rval = U32BE(len(val))
        rval += ScriptDataObject.pack(val)

        return rval

    @classmethod
    def pack_into(cls, buf, offset, val):
        U32BE.pack_into(buf, offset, len(val))

        return ScriptDataObject.pack_into(buf, offset + U32BE.size,
                                          val)

    @classmethod
    def read(cls, fd):
        U32BE.read(fd) # Length
        val = ScriptDataObject.read(fd)

        return cls(val)

    @classmethod
    def unpack_from(cls, buf, offset):
        U32BE.unpack_from(buf, offset) # Length
        offset += U32BE.size

        val, offset = ScriptDataObject.unpack_from(buf, offset)

        return (cls(val), offset)

class ScriptDataStrictArray(DynamicType):
    @classmethod
    def size(cls, val):
        size = 4

        for sdval in val:
            size += ScriptDataValue.size(sdval)

        return size

    @classmethod
    def pack(cls, val):
        rval = U32BE(len(val))

        for sdval in val:
            rval += ScriptDataValue.pack(sdval)

        return rval

    @classmethod
    def pack_into(cls, buf, offset, val):
        U32BE.pack_into(buf, offset, len(val))
        offset += U32BE.size

        for sdval in val:
            offset = ScriptDataValue.pack_into(buf, offset, sdval)

        return offset

    @classmethod
    def read(cls, fd):
        length = U32BE.read(fd)
        rval = []

        for i in range(length):
            val = ScriptDataValue.read(fd)
            rval.append(val)

        return rval

    @classmethod
    def unpack_from(cls, buf, offset):
        length = U32BE.unpack_from(buf, offset)[0]
        offset += U32BE.size
        rval = []

        for i in range(length):
            val, offset = ScriptDataValue.unpack_from(buf, offset)
            rval.append(val)

        return (rval, offset)


ScriptDataDate = namedtuple("ScriptDataDate", ["timestamp", "offset"])
ScriptDataDateStruct = PrimitiveClassType(">dh", ScriptDataDate)
ScriptDataDate.__identifier__ = SCRIPT_DATA_TYPE_DATE
ScriptDataDate.__packer__ = ScriptDataDateStruct

ScriptDataReference = namedtuple("ScriptDataReference", ["reference"])
ScriptDataReferenceStruct = PrimitiveClassType(">H", ScriptDataReference)
ScriptDataReference.__identifier__ = SCRIPT_DATA_TYPE_REFERENCE
ScriptDataReference.__packer__ = ScriptDataReferenceStruct


class ScriptDataValue(DynamicType, ScriptDataType):
    # key: identifier, value: unpacker class
    PrimitiveReaders = {
        SCRIPT_DATA_TYPE_NUMBER: ScriptDataNumber,
        SCRIPT_DATA_TYPE_BOOLEAN: ScriptDataBoolean,
        SCRIPT_DATA_TYPE_REFERENCE: ScriptDataReferenceStruct,
        SCRIPT_DATA_TYPE_DATE: ScriptDataDateStruct,
    }

    DynamicReaders = {
        SCRIPT_DATA_TYPE_STRING: ScriptDataString,
        SCRIPT_DATA_TYPE_LONGSTRING: ScriptDataLongString,
        SCRIPT_DATA_TYPE_OBJECT: ScriptDataObject,
        SCRIPT_DATA_TYPE_ECMAARRAY: ScriptDataECMAArray,
        SCRIPT_DATA_TYPE_STRICTARRAY: ScriptDataStrictArray,
    }

    Readers = PrimitiveReaders.copy()
    Readers.update(DynamicReaders)

    @classmethod
    def size(cls, val):
        size = 1

        if isinstance(val, bool):
            size += ScriptDataBoolean.size

        elif isinstance(val, (int, float)):
            size += ScriptDataNumber.size

        elif isinstance(val, list):
            size += ScriptDataStrictArray.size(val)

        elif isinstance(val, string_types):
            if len(val) > 0xFFFF:
                size += ScriptDataLongString.size(val)
            else:
                size += ScriptDataString.size(val)

        elif isinstance(val, ScriptDataType):
            cls = type(val)
            size += cls.size(val)

        elif type(val) in (ScriptDataDate, ScriptDataReference):
            cls = type(val)
            packer = cls.__packer__
            size += packer.size

        elif isinstance(val, AMF3ObjectBase):
            size += U8.size
            size += AMF3Value.size(val)

        return size

    @classmethod
    def pack(cls, val):
        rval = b""

        if isinstance(val, bool):
            rval += U8(SCRIPT_DATA_TYPE_BOOLEAN)
            rval += ScriptDataBoolean(val)

        elif isinstance(val, (int, float)):
            rval += U8(SCRIPT_DATA_TYPE_NUMBER)
            rval += ScriptDataNumber(val)

        elif isinstance(val, list):
            rval += U8(SCRIPT_DATA_TYPE_STRICTARRAY)
            rval += ScriptDataStrictArray(val)

        elif isinstance(val, string_types):
            if len(val) > 0xFFFF:
                rval += U8(SCRIPT_DATA_TYPE_LONGSTRING)
                rval += ScriptDataLongString(val)
            else:
                rval += U8(SCRIPT_DATA_TYPE_STRING)
                rval += ScriptDataString(val)

        elif val is None:
            rval += U8(SCRIPT_DATA_TYPE_NULL)

        elif isinstance(val, ScriptDataType):
            cls = type(val)
            rval += U8(cls.__identifier__)
            rval += cls.pack(val)

        elif type(val) in (ScriptDataDate, ScriptDataReference):
            cls = type(val)
            packer = cls.__packer__

            rval += U8(cls.__identifier__)
            rval += packer.pack(val)

        elif isinstance(val, AMF3ObjectBase):
            rval += U8(SCRIPT_DATA_TYPE_AMF3)
            rval += AMF3Value.pack(val)

        else:
            raise ValueError("Unable to pack value of type {0}".format(type(val)))

        return rval

    @classmethod
    def pack_into(cls, buf, offset, val):
        if isinstance(val, bool):
            U8.pack_into(buf, offset, SCRIPT_DATA_TYPE_BOOLEAN)
            offset += U8.size

            ScriptDataBoolean.pack_into(buf, offset, val)
            offset += ScriptDataBoolean.size

        elif isinstance(val, (int, float)):
            U8.pack_into(buf, offset, SCRIPT_DATA_TYPE_NUMBER)
            offset += U8.size

            ScriptDataNumber.pack_into(buf, offset, val)
            offset += ScriptDataNumber.size

        elif isinstance(val, list):
            U8.pack_into(buf, offset, SCRIPT_DATA_TYPE_STRICTARRAY)
            offset += U8.size
            offset = ScriptDataStrictArray.pack_into(buf, offset, val)

        elif isinstance(val, string_types):
            if len(val) > 0xFFFF:
                U8.pack_into(buf, offset, SCRIPT_DATA_TYPE_LONGSTRING)
                offset += U8.size
                offset = ScriptDataLongString.pack_into(buf, offset, val)
            else:
                U8.pack_into(buf, offset, SCRIPT_DATA_TYPE_STRING)
                offset += U8.size
                offset = ScriptDataString.pack_into(buf, offset, val)

        elif val is None:
            U8.pack_into(buf, offset, SCRIPT_DATA_TYPE_NULL)

        elif isinstance(val, ScriptDataType):
            cls = type(val)
            U8.pack_into(buf, offset, cls.__identifier__)
            offset += U8.size
            offset = cls.pack_into(buf, offset, val)

        elif type(val) in (ScriptDataDate, ScriptDataReference):
            cls = type(val)
            packer = cls.__packer__

            U8.pack_into(buf, offset, cls.__identifier__)
            offset += U8.size

            packer.pack_into(buf, offset, val)
            offset += packer.size

        else:
            raise ValueError("Unable to pack value of type {0}".format(type(val)))

        return offset

    @classmethod
    def read(cls, fd, marker=None):
        if marker is None:
            type_ = U8.read(fd)
        else:
            type_ = marker

        if type_ == SCRIPT_DATA_TYPE_AMF3:
            return AMF3Value.read(fd)

        elif type_ in ScriptDataValue.Readers:
            return ScriptDataValue.Readers[type_].read(fd)

        elif type_ == SCRIPT_DATA_TYPE_OBJECTEND:
            raise ScriptDataObjectEnd

        elif (type_ == SCRIPT_DATA_TYPE_NULL or
              type_ == SCRIPT_DATA_TYPE_UNDEFINED):

            return None

        else:
            raise IOError("Unhandled script data type: {0}".format(type_))

    @classmethod
    def unpack_from(cls, buf, offset):
        type_ = U8.unpack_from(buf, offset)[0]
        offset += U8.size

        if type_ in ScriptDataValue.DynamicReaders:
            return ScriptDataValue.Readers[type_].unpack_from(buf, offset)

        elif type_ in ScriptDataValue.PrimitiveReaders:
            reader = ScriptDataValue.PrimitiveReaders[type_]
            rval = reader.unpack_from(buf, offset)[0]
            offset += reader.size

            return (rval, offset)

        elif type_ == SCRIPT_DATA_TYPE_OBJECTEND:
            raise ScriptDataObjectEnd

        elif (type_ == SCRIPT_DATA_TYPE_NULL or
              type_ == SCRIPT_DATA_TYPE_UNDEFINED):

            return (None, offset)

        else:
            raise IOError("Unhandled script data type: {0}".format(hex(type_)))


class AMF0Value(ScriptDataValue):
    pass

class AMF0String(ScriptDataString):
    pass

AMF0Number = ScriptDataNumber

AMF3Double = ScriptDataNumber

class AMF3Type(ScriptDataType):
    pass

class AMF3Integer(DynamicType, AMF3Type):
    __identifier__ = AMF3_TYPE_INTEGER

    @classmethod
    def size(cls, val):
        val &= 0x1fffffff

        if val < 0x80:
            return 1
        elif val < 0x4000:
            return 2
        elif val < 0x200000:
            return 3
        elif val < 0x40000000:
            return 4

    @classmethod
    def pack(cls, val):
        size = cls.size(val)
        buf = bytearray(size)
        offset = cls.pack_into(buf, 0, val)

        return bytes(buf[:offset])

    @classmethod
    def pack_into(cls, buf, offset, val):
        val &= 0x1fffffff

        if val < 0x80:
            buf[offset] = val
            offset += 1
        elif val < 0x4000:
            buf[offset] = (val >> 7 & 0x7f) | 0x80
            buf[offset+1] = val & 0x7f
            offset += 2
        elif val < 0x200000:
            buf[offset] = (val >> 14 & 0x7f) | 0x80
            buf[offset+1] = (val >> 7 & 0x7f) | 0x80
            buf[offset+2] = val & 0x7f
            offset += 3
        elif val < 0x40000000:
            buf[offset] = (val >> 22 & 0x7f) | 0x80
            buf[offset+1] = (val >> 15 & 0x7f) | 0x80
            buf[offset+2] = (val >> 8 & 0x7f) | 0x80
            buf[offset+3] = val & 0xff
            offset += 4

        return offset

    @classmethod
    def read(cls, fd):
        rval, byte_count = 0, 0
        byte = U8.read(fd)

        while (byte & 0x80) != 0 and byte_count < 3:
            rval <<= 7
            rval |= byte & 0x7f

            byte = U8.read(fd)
            byte_count += 1

        if byte_count < 3:
            rval <<= 7
            rval |= byte & 0x7F
        else:
            rval <<= 8
            rval |= byte & 0xff

        if (rval & 0x10000000) != 0:
            rval -= 0x20000000

        return rval


class AMF3String(String):
    @classmethod
    def size(cls, val, cache):
        data = String.pack(val, "utf8", "ignore")
        size = len(data)

        if size == 0:
            return U8.size
        elif val in cache:
            index = cache.index(val)
            return AMF3Integer.size(index << 1)
        else:
            cache.append(val)
            return AMF3Integer.size(size << 1 | 1) + size

    @classmethod
    def pack(cls, val, cache):
        data = String.pack(val, "utf8", "ignore")
        size = len(data)

        if size == 0:
            return U8(AMF3_EMPTY_STRING)
        elif val in cache:
            index = cache.index(val)
            return AMF3Integer(index << 1)
        else:
            cache.append(val)

            chunks = []
            chunks.append(AMF3Integer(size << 1 | 1))
            chunks.append(data)

            return b"".join(chunks)

    @classmethod
    def read(cls, fd, cache):
        header = AMF3Integer.read(fd)

        if (header & 1) == 0:
            index = header >> 1

            return cache[index]
        else:
            size = header >> 1
            data = fd.read(size)
            rval = data.decode("utf8", "ignore")

            if len(data) > 0:
                cache.append(rval)

            return rval


class AMF3ObjectBase(object):
    __dynamic__ = False
    __externalizable__ = False
    __members__ = []

    _registry = {}

    def __init__(self, *args, **kwargs):
        for key, value in kwargs.items():
            setattr(self, key, value)

    def __repr__(self):
        return "<{0} {1!r}".format(self.__class__.__name__, self.__dict__)

    @classmethod
    def register(cls, name):
        def deco(amfcls):
            amfcls.__name__ = name

            if not amfcls.__members__:
                amfcls.__members__ = getargspec(amfcls.__init__).args[1:]

            cls._registry[name] = amfcls

            return amfcls

        return deco

    @classmethod
    def lookup(cls, name):
        return cls._registry.get(name, None)

    @classmethod
    def create(cls, name, externalizable, dynamic, members):
        if is_py2:
            name = name.encode("utf8")

        amfcls = type(name, (cls,), {})
        amfcls.__externalizable__ = externalizable
        amfcls.__members__ = members

        return amfcls


class AMF3Object(OrderedDict, AMF3ObjectBase):
    __dynamic__ = True


class AMF3ObjectPacker(DynamicType, AMF3Type):
    __identifier__ = AMF3_TYPE_OBJECT

    @classmethod
    def size(cls, val, str_cache, object_cache, traits_cache):
        if val in object_cache:
            index = object_cache.index(val)
            return AMF3Integer.size(index << 1)
        else:
            object_cache.append(val)
            size = 0
            traits = type(val)

            if traits in traits_cache:
                index = traits_cache.index(traits)
                size += AMF3Integer.size(index << 2 | 0x01)
            else:
                header = 0x03

                if traits.__dynamic__:
                    header |= 0x02 << 2

                if traits.__externalizable__:
                    header |= 0x01 << 2

                header |= (len(traits.__members__)) << 4
                size += AMF3Integer.size(header)

                if isinstance(val, AMF3Object):
                    size += U8.size
                else:
                    size += AMF3String.size(traits.__name__, cache=str_cache)
                    traits_cache.append(traits)

                for member in traits.__members__:
                    size += AMF3String.size(member, cache=str_cache)


            for member in traits.__members__:
                value = getattr(val, member)
                size += AMF3Value.size(value, str_cache=str_cache,
                                       object_cache=object_cache,
                                       traits_cache=traits_cache)

            if traits.__dynamic__:
                if isinstance(val, AMF3Object):
                    iterator = val.items()
                else:
                    iterator = val.__dict__.items()

                for key, value in iterator:
                    if key in traits.__members__:
                        continue

                    size += AMF3String.size(key, cache=str_cache)
                    size += AMF3Value.size(value, str_cache=str_cache,
                                           object_cache=object_cache,
                                           traits_cache=traits_cache)

                size += U8.size

            return size

    @classmethod
    def pack(cls, val, str_cache, object_cache, traits_cache):
        chunks = []

        if val in object_cache:
            index = object_cache.index(val)
            return AMF3Integer(index << 1)
        else:
            object_cache.append(val)
            chunks = []
            traits = type(val)

            if traits in traits_cache:
                index = traits_cache.index(traits)
                chunks.append(AMF3Integer(index << 2 | 0x01))
            else:
                header = 0x03

                if traits.__dynamic__:
                    header |= 0x02 << 2

                if traits.__externalizable__:
                    header |= 0x01 << 2

                header |= (len(traits.__members__)) << 4
                chunks.append(AMF3Integer(header))

                if isinstance(val, AMF3Object):
                    chunks.append(U8(AMF3_EMPTY_STRING))
                else:
                    chunks.append(AMF3String(traits.__name__, cache=str_cache))
                    traits_cache.append(traits)

                for member in traits.__members__:
                    chunks.append(AMF3String(member, cache=str_cache))


            for member in traits.__members__:
                value = getattr(val, member)
                value = AMF3Value.pack(value, str_cache=str_cache,
                                       object_cache=object_cache,
                                       traits_cache=traits_cache)
                chunks.append(value)


            if traits.__dynamic__:
                if isinstance(val, AMF3Object):
                    iterator = val.items()
                else:
                    iterator = val.__dict__.items()

                for key, value in iterator:
                    if key in traits.__members__:
                        continue

                    key = AMF3String(key, cache=str_cache)
                    value = AMF3Value.pack(value, str_cache=str_cache,
                                           object_cache=object_cache,
                                           traits_cache=traits_cache)

                    chunks.append(key)
                    chunks.append(value)

                # Empty string is end of dynamic values
                chunks.append(U8(AMF3_CLOSE_DYNAMIC_ARRAY))

            return b"".join(chunks)

    @classmethod
    def read(cls, fd, str_cache, object_cache, traits_cache):
        header = AMF3Integer.read(fd)
        obj = None

        if (header & 1) == 0:
            index = header >> 1
            obj = object_cache[index]
        else:
            header >>= 1

            if (header & 1) == 0:
                index = header >> 1
                traits = traits_cache[index]
            else:
                externalizable = (header & 2) != 0
                dynamic = (header & 4) != 0
                members_len = header >> 3
                class_name = AMF3String.read(fd, cache=str_cache)
                members = []

                for i in range(members_len):
                    member_name = AMF3String.read(fd, cache=str_cache)
                    members.append(member_name)

                if len(class_name) == 0:
                    traits = AMF3Object
                elif AMF3ObjectBase.lookup(class_name):
                    traits = AMF3ObjectBase.lookup(class_name)
                    traits.__members__ = members
                    traits.__dynamic__ = dynamic
                    traits_cache.append(traits)
                else:
                    traits = AMF3ObjectBase.create(class_name, externalizable,
                                                   dynamic, members)
                    traits_cache.append(traits)

            values = OrderedDict()

            for member in traits.__members__:
                value = AMF3Value.read(fd, str_cache=str_cache,
                                       object_cache=object_cache,
                                       traits_cache=traits_cache)

                values[member] = value

            if traits.__dynamic__:
                key = AMF3String.read(fd, cache=str_cache)
                while len(key) > 0:
                    value = AMF3Value.read(fd, str_cache=str_cache,
                                           object_cache=object_cache,
                                           traits_cache=traits_cache)
                    values[key] = value
                    key = AMF3String.read(fd, cache=str_cache)

            if traits == AMF3Object:
                obj = traits(values)
            else:
                obj = traits(**values)

        return obj

class AMF3Array(OrderedDict):
    def __init__(self, *args, **kwargs):
        if args and isinstance(args[0], list):
            OrderedDict.__init__(self, **kwargs)

            for i, value in enumerate(args[0]):
                self[i] = value
        else:
            OrderedDict.__init__(self, *args, **kwargs)

    def dense_keys(self):
        dense_keys = []

        for i in range(len(self)):
            if i in self:
                dense_keys.append(i)

        return dense_keys

    def dense_values(self):
        for key in self.dense_keys():
            yield self[key]

class AMF3ArrayPacker(DynamicType, AMF3Type):
    __identifier__ = AMF3_TYPE_ARRAY

    @classmethod
    def size(cls, val, str_cache, object_cache, traits_cache):
        if val in object_cache:
            index = object_cache.index(val)
            return AMF3Integer.size(index << 1)
        else:
            object_cache.append(val)
            size = 0

            if isinstance(val, AMF3Array):
                dense_keys = val.dense_keys()
                length = len(dense_keys)
            else:
                length = len(val)
                dense_keys = list(range(length))

            header = length << 1 | 1
            size += AMF3Integer.size(header)

            if isinstance(val, AMF3Array):
                for key, value in val.items():
                    if key in dense_keys:
                        continue

                    size += AMF3String.size(key, cache=str_cache)
                    size += AMF3Value.size(value, str_cache=str_cache,
                                           object_cache=object_cache,
                                           traits_cache=traits_cache)

            size += U8.size

            for key in dense_keys:
                value = val[key]
                size += AMF3Value.size(value, str_cache=str_cache,
                                       object_cache=object_cache,
                                       traits_cache=traits_cache)

            return size

    @classmethod
    def pack(cls, val, str_cache, object_cache, traits_cache):
        if val in object_cache:
            index = object_cache.index(val)
            return AMF3Integer(index << 1)
        else:
            object_cache.append(val)
            chunks = []

            if isinstance(val, AMF3Array):
                dense_keys = val.dense_keys()
                length = len(dense_keys)
            else:
                length = len(val)
                dense_keys = list(range(length))

            header = length << 1 | 1
            chunks.append(AMF3Integer(header))

            if isinstance(val, AMF3Array):
                for key, value in val.items():
                    if key in dense_keys:
                        continue

                    chunks.append(AMF3String(key, cache=str_cache))

                    value = AMF3Value.pack(value, str_cache=str_cache,
                                           object_cache=object_cache,
                                           traits_cache=traits_cache)
                    chunks.append(value)

            # Empty string is end of dynamic values
            chunks.append(U8(AMF3_CLOSE_DYNAMIC_ARRAY))

            for key in dense_keys:
                value = val[key]
                value = AMF3Value.pack(value, str_cache=str_cache,
                                       object_cache=object_cache,
                                       traits_cache=traits_cache)
                chunks.append(value)

            return b"".join(chunks)

    @classmethod
    def read(cls, fd, str_cache, object_cache, traits_cache):
        header = AMF3Integer.read(fd)
        obj = None

        if (header & 1) == 0:
            index = header >> 1
            obj = object_cache[index]
        else:
            header >>= 1
            obj = AMF3Array()
            object_cache.append(obj)

            key = AMF3String.read(fd, cache=str_cache)
            while len(key) > 0:
                value = AMF3Value.read(fd, str_cache=str_cache,
                                       object_cache=object_cache,
                                       traits_cache=traits_cache)
                obj[key] = value
                key = AMF3String.read(fd, cache=str_cache)

            for i in range(header):
                value = AMF3Value.read(fd, str_cache=str_cache,
                                       object_cache=object_cache,
                                       traits_cache=traits_cache)
                obj[i] = value

        return obj


class AMF3Date(object):
    def __init__(self, time):
        self.time = time

class AMF3DatePacker(DynamicType, AMF3Type):
    __identifier__ = AMF3_TYPE_ARRAY

    @classmethod
    def size(cls, val, cache):
        if val in cache:
            index = cache.index(val)
            return AMF3Integer.size(index << 1)
        else:
            cache.append(val)

            return AMF3Double.size + U8.size

    @classmethod
    def pack(cls, val, cache):
        if val in cache:
            index = cache.index(val)
            return AMF3Integer(index << 1)
        else:
            cache.append(val)
            chunks = [U8(AMF3_TYPE_NULL),
                      AMF3Double(val.time)]

            return b"".join(chunks)

    @classmethod
    def read(cls, fd, cache):
        header = AMF3Integer.read(fd)

        if (header & 1) == 0:
            index = header >> 1
            return cache[index]
        else:
            time = AMF3Double.read(fd)
            date = AMF3Date(time)
            cache.append(date)

            return date

class AMF3Value(DynamicType):
    PrimitiveReaders = {
        AMF3_TYPE_DOUBLE: AMF3Double,
    }

    DynamicReaders = {
        AMF3_TYPE_INTEGER: AMF3Integer,
    }

    Readers = PrimitiveReaders.copy()
    Readers.update(DynamicReaders)

    @classmethod
    def size(cls, val, str_cache=None, object_cache=None, traits_cache=None):
        if str_cache is None:
            str_cache = []

        if object_cache is None:
            object_cache = []

        if traits_cache is None:
            traits_cache = []

        size = U8.size

        if isinstance(val, bool) and val in (False, True):
            pass

        elif val is None:
            pass

        elif isinstance(val, integer_types):
            if val < AMF3_MIN_INTEGER or val > AMF3_MAX_INTEGER:
                size += AMF3Double.size
            else:
                size += AMF3Integer.size(val)

        elif isinstance(val, float):
            size += AMF3Double.size

        elif isinstance(val, (AMF3Array, list)):
            size += AMF3ArrayPacker.size(val, str_cache=str_cache,
                                         object_cache=object_cache,
                                         traits_cache=traits_cache)

        elif isinstance(val, string_types):
            size += AMF3String.size(val, cache=str_cache)

        elif isinstance(val, AMF3ObjectBase):
            size += AMF3ObjectPacker.size(val, str_cache=str_cache,
                                          object_cache=object_cache,
                                          traits_cache=traits_cache)

        elif isinstance(val, AMF3Date):
            size += AMF3DatePacker.size(val, cache=object_cache)

        else:
            raise ValueError("Unable to pack value of type {0}".format(type(val)))

        return size

    @classmethod
    def pack(cls, val, str_cache=None, object_cache=None, traits_cache=None):
        if str_cache is None:
            str_cache = []

        if object_cache is None:
            object_cache = []

        if traits_cache is None:
            traits_cache = []

        chunks = []

        if isinstance(val, bool):
            if val is False:
                chunks.append(U8(AMF3_TYPE_FALSE))
            elif val is True:
                chunks.append(U8(AMF3_TYPE_TRUE))

        elif val is None:
            chunks.append(U8(AMF3_TYPE_NULL))

        elif isinstance(val, integer_types):
            if val < AMF3_MIN_INTEGER or val > AMF3_MAX_INTEGER:
                chunks.append(U8(AMF3_TYPE_DOUBLE))
                chunks.append(AMF3Double(val))
            else:
                chunks.append(U8(AMF3_TYPE_INTEGER))
                chunks.append(AMF3Integer(val))

        elif isinstance(val, float):
            chunks.append(U8(AMF3_TYPE_DOUBLE))
            chunks.append(AMF3Double(val))

        elif isinstance(val, (AMF3Array, list)):
            chunks.append(U8(AMF3_TYPE_ARRAY))
            chunks.append(AMF3ArrayPacker.pack(val, str_cache=str_cache,
                                              object_cache=object_cache,
                                              traits_cache=traits_cache))

        elif isinstance(val, string_types):
            chunks.append(U8(AMF3_TYPE_STRING))
            chunks.append(AMF3String.pack(val, cache=str_cache))

        elif isinstance(val, AMF3ObjectBase):
            chunks.append(U8(AMF3_TYPE_OBJECT))
            chunks.append(AMF3ObjectPacker.pack(val, str_cache=str_cache,
                                                object_cache=object_cache,
                                                traits_cache=traits_cache))

        elif isinstance(val, AMF3Date):
            chunks.append(U8(AMF3_TYPE_DATE))
            chunks.append(AMF3DatePacker.pack(val, cache=object_cache))

        else:
            raise ValueError("Unable to pack value of type {0}".format(type(val)))

        return b"".join(chunks)

    @classmethod
    def read(cls, fd, str_cache=None, object_cache=None, traits_cache=None):
        type_ = U8.read(fd)

        if str_cache is None:
            str_cache = []

        if object_cache is None:
            object_cache = []

        if traits_cache is None:
            traits_cache = []

        if type_ == AMF3_TYPE_UNDEFINED or type_ == AMF3_TYPE_NULL:
            return None

        elif type_ == AMF3_TYPE_FALSE:
            return False

        elif type_ == AMF3_TYPE_TRUE:
            return True

        elif type_ == AMF3_TYPE_STRING:
            return AMF3String.read(fd, cache=str_cache)

        elif type_ == AMF3_TYPE_ARRAY:
            return AMF3ArrayPacker.read(fd, str_cache=str_cache,
                                         object_cache=object_cache,
                                         traits_cache=traits_cache)

        elif type_ == AMF3_TYPE_OBJECT:
            return AMF3ObjectPacker.read(fd, str_cache=str_cache, object_cache=object_cache,
                                         traits_cache=traits_cache)

        elif type_ == AMF3_TYPE_DATE:
            return AMF3DatePacker.read(fd, cache=object_cache)

        elif type_ in cls.Readers:
            return cls.Readers[type_].read(fd)

        else:
            raise IOError("Unhandled AMF3 type: {0}".format(hex(type_)))


########NEW FILE########
__FILENAME__ = util
#!/usr/bin/env python

from .compat import bytes, is_py2, string_types

import struct

def byte(ordinal):
    if isinstance(ordinal, string_types):
        ordinal = ord(ordinal)

    return bytes((ordinal,))

class flagproperty(object):
    def __init__(self, flags, attr, boolean=False):
        self.flags = flags
        self.attr = attr
        self.boolean = boolean

    def __get__(self, obj, cls):
        flags = getattr(obj, self.flags)
        val = getattr(flags.bit, self.attr)

        if self.boolean:
            val = bool(val)

        return val

    def __set__(self, obj, val):
        flags = getattr(obj, self.flags)
        setattr(flags.bit, self.attr, int(val))

def lang_to_iso639(lang):
    res = [0, 0, 0]

    for i in reversed(range(3)):
        res[i] = chr(0x60 + (lang & 0x1f))
        lang = lang >> 5

    return "".join(res)


def iso639_to_lang(iso639):
    res = 0

    for i in range(3):
        c = ord(iso639[i]) - 0x60
        res = res << 5
        res = res | c

    return res


def pack_many_into(buf, offset, types, values):
    for packer, value in zip(types, values):
        packer.pack_into(buf, offset, value)
        offset += packer.size

    return offset

def pack_bytes_into(buf, offset, data):
    size = len(data)
    fmt = str(size) + "s"
    struct.pack_into(fmt, buf, offset, data)

    return offset + size

def unpack_many_from(buf, offset, types):
    rval = tuple()

    for unpacker in types:
        rval += unpacker.unpack_from(buf, offset)
        offset += unpacker.size

    return rval

def chunked_read(fd, length, chunk_size=8192, exception=IOError):
    chunks = []
    data_left = length

    while data_left > 0:
        try:
            data = fd.read(min(8192, data_left))
        except IOError as err:
            raise exception("Failed to read data: {0}".format(str(err)))

        if not data:
            raise exception("End of stream before requied data could be read")

        data_left -= len(data)
        chunks.append(data)

    return b"".join(chunks)


__all__ = ["byte", "flagproperty", "lang_to_iso639",
           "iso639_to_lang", "pack_many_into", "pack_bytes_into",
           "unpack_many_from", "chunked_read"]


########NEW FILE########
__FILENAME__ = pbs
#===============================================================================
# Copyright (C) 2011-2012 by Andrew Moffat
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.
#===============================================================================



import subprocess as subp
import sys
import traceback
import os
import re
from glob import glob as original_glob
from types import ModuleType
from functools import partial
import warnings
import platform


__version__ = "0.110"
__project_url__ = "https://github.com/amoffat/pbs"

IS_PY3 = sys.version_info[0] == 3
if IS_PY3:
    raw_input = input
    unicode = str
else:
    pass

DEFAULT_ENCODING = "utf-8"

class ErrorReturnCode(Exception):
    truncate_cap = 200

    def __init__(self, full_cmd, stdout, stderr):
        self.full_cmd = full_cmd
        self.stdout = stdout
        self.stderr = stderr

        if self.stdout is None: tstdout = "<redirected>"
        else:
            tstdout = self.stdout[:self.truncate_cap]
            out_delta = len(self.stdout) - len(tstdout)
            if out_delta:
                tstdout += ("... (%d more, please see e.stdout)" % out_delta).encode()

        if self.stderr is None: tstderr = "<redirected>"
        else:
            tstderr = self.stderr[:self.truncate_cap]
            err_delta = len(self.stderr) - len(tstderr)
            if err_delta:
                tstderr += ("... (%d more, please see e.stderr)" % err_delta).encode()

        msg = "\n\nRan: %r\n\nSTDOUT:\n\n  %s\n\nSTDERR:\n\n  %s" %\
            (full_cmd, tstdout.decode(DEFAULT_ENCODING, "replace"),
             tstderr.decode(DEFAULT_ENCODING, "replace"))
        super(ErrorReturnCode, self).__init__(msg)

class CommandNotFound(Exception): pass

rc_exc_regex = re.compile("ErrorReturnCode_(\d+)")
rc_exc_cache = {}

def get_rc_exc(rc):
    rc = int(rc)
    try: return rc_exc_cache[rc]
    except KeyError: pass

    name = "ErrorReturnCode_%d" % rc
    exc = type(name, (ErrorReturnCode,), {})
    rc_exc_cache[rc] = exc
    return exc




def which(program):
    def is_exe(fpath):
        return os.path.exists(fpath) and os.access(fpath, os.X_OK)

    fpath, fname = os.path.split(program)
    if fpath:
        if is_exe(program): return program
    else:
        for path in os.environ["PATH"].split(os.pathsep):
            exe_file = os.path.join(path, program)
            if is_exe(exe_file):
                return exe_file

    return None

def resolve_program(program):
    path = which(program)
    if not path:
        # our actual command might have a dash in it, but we can't call
        # that from python (we have to use underscores), so we'll check
        # if a dash version of our underscore command exists and use that
        # if it does
        if "_" in program: path = which(program.replace("_", "-"))
        if not path: return None
    return path


def glob(arg):
    return original_glob(arg) or arg


def create_command(cmd):
    return Command._create(cmd)


class RunningCommand(object):
    def __init__(self, command_ran, process, call_args, stdin=None):
        self.command_ran = command_ran
        self.process = process
        self._stdout = None
        self._stderr = None
        self.call_args = call_args

        # we're running in the background, return self and let us lazily
        # evaluate
        if self.call_args["bg"]:
            if self.process.stdin:
                self.process.stdin.close()
            return

        # we're running this command as a with context, don't do anything
        # because nothing was started to run from Command.__call__
        if self.call_args["with"]: return

        # run and block
        if stdin: stdin = stdin.encode(DEFAULT_ENCODING)
        self._stdout, self._stderr = self.process.communicate(stdin)
        self._handle_exit_code(self.process.wait())

    def __enter__(self):
        # we don't actually do anything here because anything that should
        # have been done would have been done in the Command.__call__ call.
        # essentially all that has to happen is the comand be pushed on
        # the prepend stack.
        pass

    def __exit__(self, typ, value, traceback):
        if self.call_args["with"] and Command._prepend_stack:
            Command._prepend_stack.pop()

    def __str__(self):
        if IS_PY3: return self.__unicode__()
        else: return unicode(self).encode(DEFAULT_ENCODING)

    def __unicode__(self):
        if self.process:
            if self.call_args["bg"]: self.wait()
            if self._stdout: return self.stdout()
            else: return ""

    def __eq__(self, other):
        return unicode(self) == unicode(other)
    __hash__ = None  # Avoid DeprecationWarning in Python < 3

    def __contains__(self, item):
        return item in str(self)

    def __getattr__(self, p):
        # let these three attributes pass through to the Popen object
        if p in ("send_signal", "terminate", "kill"):
            if self.process: return getattr(self.process, p)
            else: raise AttributeError
        return getattr(unicode(self), p)

    def __repr__(self):
        return "<RunningCommand %r, pid:%d, special_args:%r" % (
            self.command_ran, self.process.pid, self.call_args)

    def __long__(self):
        return long(str(self).strip())

    def __float__(self):
        return float(str(self).strip())

    def __int__(self):
        return int(str(self).strip())

    def stdout(self):
        if self.call_args["bg"]: self.wait()
        return self._stdout.decode(DEFAULT_ENCODING, "replace")

    def stderr(self):
        if self.call_args["bg"]: self.wait()
        return self._stderr.decode(DEFAULT_ENCODING, "replace")

    def wait(self):
        if self.process.returncode is not None: return
        self._stdout, self._stderr = self.process.communicate()
        self._handle_exit_code(self.process.wait())
        return str(self)

    def _handle_exit_code(self, rc):
        if rc not in self.call_args["ok_code"]:
            raise get_rc_exc(rc)(self.command_ran, self._stdout, self._stderr)

    def __len__(self):
        return len(str(self))




class Command(object):
    _prepend_stack = []

    call_args = {
        "fg": False, # run command in foreground
        "bg": False, # run command in background
        "with": False, # prepend the command to every command after it
        "out": None, # redirect STDOUT
        "err": None, # redirect STDERR
        "err_to_out": None, # redirect STDERR to STDOUT
        "in": None,
        "env": os.environ,
        "cwd": None,

        # this is for commands that may have a different exit status than the
        # normal 0.  this can either be an integer or a list/tuple of ints
        "ok_code": 0,
    }

    @classmethod
    def _create(cls, program):
        path = resolve_program(program)
        if not path: raise CommandNotFound(program)
        return cls(path)

    def __init__(self, path):
        self._path = path
        self._partial = False
        self._partial_baked_args = []
        self._partial_call_args = {}

    def __getattribute__(self, name):
        # convenience
        getattr = partial(object.__getattribute__, self)
        if name.startswith("_"): return getattr(name)
        if name == "bake": return getattr("bake")
        return getattr("bake")(name)


    @staticmethod
    def _extract_call_args(kwargs):
        kwargs = kwargs.copy()
        call_args = Command.call_args.copy()
        for parg, default in call_args.items():
            key = "_" + parg
            if key in kwargs:
                call_args[parg] = kwargs[key]
                del kwargs[key]
        return call_args, kwargs


    def _format_arg(self, arg):
        if IS_PY3:
            arg = str(arg)
        else:
            try:
                arg = unicode(arg, DEFAULT_ENCODING).encode(DEFAULT_ENCODING)
            except TypeError:
                arg = unicode(arg).encode(DEFAULT_ENCODING)

        if self._partial:
            escaped = arg.replace('"', '\\"')
            escaped = escaped.replace("$", "\$")
            escaped = escaped.replace("`", "\`")

            arg = '"{0}"'.format(escaped)

        return arg

    def _compile_args(self, args, kwargs):
        processed_args = []

        # aggregate positional args
        for arg in args:
            if isinstance(arg, (list, tuple)):
                if not arg:
                    warnings.warn("Empty list passed as an argument to %r. \
If you're using glob.glob(), please use pbs.glob() instead." % self.path, stacklevel=3)
                for sub_arg in arg: processed_args.append(self._format_arg(sub_arg))
            else: processed_args.append(self._format_arg(arg))

        # aggregate the keyword arguments
        for k,v in kwargs.items():
            # we're passing a short arg as a kwarg, example:
            # cut(d="\t")
            if len(k) == 1:
                processed_args.append("-"+k)
                if v is not True: processed_args.append(self._format_arg(v))

            # we're doing a long arg
            else:
                k = k.replace("_", "-")

                if v is True: processed_args.append("--"+k)
                else: processed_args.append("--%s=%s" % (k, self._format_arg(v)))

        return processed_args


    def bake(self, *args, **kwargs):
        fn = Command(self._path)
        fn._partial = True

        call_args, kwargs = self._extract_call_args(kwargs)

        pruned_call_args = call_args
        for k,v in Command.call_args.items():
            try:
                if pruned_call_args[k] == v:
                    del pruned_call_args[k]
            except KeyError: continue

        fn._partial_call_args.update(self._partial_call_args)
        fn._partial_call_args.update(pruned_call_args)
        fn._partial_baked_args.extend(self._partial_baked_args)
        fn._partial_baked_args.extend(fn._compile_args(args, kwargs))
        return fn

    def __str__(self):
        if IS_PY3: return self.__unicode__()
        else: return unicode(self).encode(DEFAULT_ENCODING)

    def __repr__(self):
        return str(self)

    def __unicode__(self):
        baked_args = " ".join(self._partial_baked_args)
        if baked_args: baked_args = " " + baked_args
        return self._path + baked_args

    def __eq__(self, other):
        try: return str(self) == str(other)
        except: return False
    __hash__ = None  # Avoid DeprecationWarning in Python < 3


    def __enter__(self):
        Command._prepend_stack.append([self._path])

    def __exit__(self, typ, value, traceback):
        Command._prepend_stack.pop()


    def __call__(self, *args, **kwargs):

        kwargs = kwargs.copy()
        args = list(args)

        cmd = []

        # aggregate any with contexts
        for prepend in self._prepend_stack: cmd.extend(prepend)

        cmd.append(self._path)


        call_args, kwargs = self._extract_call_args(kwargs)
        call_args.update(self._partial_call_args)


        # here we normalize the ok_code to be something we can do
        # "if return_code in call_args["ok_code"]" on
        if not isinstance(call_args["ok_code"], (tuple, list)):
            call_args["ok_code"] = [call_args["ok_code"]]

        # set pipe to None if we're outputting straight to CLI
        pipe = None if call_args["fg"] else subp.PIPE

        # check if we're piping via composition
        input_stream = pipe
        input_data = None
        if args:
            first_arg = args.pop(0)
            if isinstance(first_arg, RunningCommand):
                # it makes sense that if the input pipe of a command is running
                # in the background, then this command should run in the
                # background as well
                if first_arg.call_args["bg"]:
                    call_args["bg"] = True
                    input_stream = first_arg.process.stdout
                else:
                    input_data = first_arg.stdout()
            else: args.insert(0, first_arg)

        processed_args = self._compile_args(args, kwargs)

        # makes sure our arguments are broken up correctly
        split_args = self._partial_baked_args + processed_args
        final_args = split_args

        cmd.extend(final_args)
        command_ran = " ".join(cmd)


        # with contexts shouldn't run at all yet, they prepend
        # to every command in the context
        if call_args["with"]:
            Command._prepend_stack.append(cmd)
            return RunningCommand(command_ran, None, call_args)


        # stdin from string
        input = call_args["in"]
        if input:
            input_data = input

        # stdout redirection
        stdout = pipe
        out = call_args["out"]
        if out:
            if hasattr(out, "write"): stdout = out
            else: stdout = open(str(out), "w")

        # stderr redirection
        stderr = pipe
        err = call_args["err"]

        if err:
            if hasattr(err, "write"): stderr = err
            else: stderr = open(str(err), "w")

        if call_args["err_to_out"]: stderr = subp.STDOUT

        # leave shell=False
        process = subp.Popen(cmd, shell=False, env=call_args["env"],
            cwd=call_args["cwd"],
            stdin=input_stream, stdout=stdout, stderr=stderr)

        return RunningCommand(command_ran, process, call_args, input_data)




########NEW FILE########
__FILENAME__ = http_session
from requests import Session, __build__ as requests_version
from requests.adapters import HTTPAdapter
from requests.exceptions import RequestException

try:
    from requests.packages.urllib3.util import Timeout
    TIMEOUT_ADAPTER_NEEDED = requests_version < 0x020300
except ImportError:
    TIMEOUT_ADAPTER_NEEDED = False

from ...exceptions import PluginError
from ...utils import parse_json, parse_xml

__all__ = ["HTTPSession"]


def _parse_keyvalue_list(val):
    for keyvalue in val.split(";"):
        try:
            key, value = keyvalue.split("=")
            yield key.strip(), value.strip()
        except ValueError:
            continue


class HTTPAdapterWithReadTimeout(HTTPAdapter):
    """This is a backport of the timeout behaviour from requests 2.3.0+
       where timeout is applied to both connect and read."""

    def get_connection(self, *args, **kwargs):
        conn = HTTPAdapter.get_connection(self, *args, **kwargs)

        # Override the urlopen method on this connection
        if not hasattr(conn.urlopen, "wrapped"):
            orig_urlopen = conn.urlopen

            def urlopen(*args, **kwargs):
                timeout = kwargs.pop("timeout", None)
                if isinstance(timeout, Timeout):
                    timeout = Timeout.from_float(timeout.connect_timeout)

                return orig_urlopen(*args, timeout=timeout, **kwargs)

            conn.urlopen = urlopen
            conn.urlopen.wrapped = True

        return conn


class HTTPSession(Session):
    def __init__(self, *args, **kwargs):
        Session.__init__(self, *args, **kwargs)

        self.timeout = 20.0

        if TIMEOUT_ADAPTER_NEEDED:
            self.mount("http://", HTTPAdapterWithReadTimeout())
            self.mount("https://", HTTPAdapterWithReadTimeout())

    @classmethod
    def json(cls, res, *args, **kwargs):
        """Parses JSON from a response."""
        return parse_json(res.text, *args, **kwargs)

    @classmethod
    def xml(cls, res, *args, **kwargs):
        """Parses XML from a response."""
        return parse_xml(res.text, *args, **kwargs)

    def parse_cookies(self, cookies, **kwargs):
        """Parses a semi-colon delimited list of cookies.

        Example: foo=bar;baz=qux
        """
        for name, value in _parse_keyvalue_list(cookies):
            self.cookies.set(name, value, **kwargs)

    def parse_headers(self, headers):
        """Parses a semi-colon delimited list of headers.

        Example: foo=bar;baz=qux
        """
        for name, value in _parse_keyvalue_list(headers):
            self.headers[name] = value

    def parse_query_params(self, cookies, **kwargs):
        """Parses a semi-colon delimited list of query parameters.

        Example: foo=bar;baz=qux
        """
        for name, value in _parse_keyvalue_list(cookies):
            self.params[name] = value

    def resolve_url(self, url):
        """Resolves any redirects and returns the final URL."""
        return self.get(url, stream=True).url

    def request(self, method, url, *args, **kwargs):
        exception = kwargs.pop("exception", PluginError)
        headers = kwargs.pop("headers", {})
        params = kwargs.pop("params", {})
        proxies = kwargs.pop("proxies", self.proxies)
        session = kwargs.pop("session", None)
        timeout = kwargs.pop("timeout", self.timeout)

        if session:
            headers.update(session.headers)
            params.update(session.params)

        try:
            res = Session.request(self, method, url,
                                  headers=headers,
                                  params=params,
                                  timeout=timeout,
                                  proxies=proxies,
                                  *args, **kwargs)
            res.raise_for_status()
        except (RequestException, IOError) as rerr:
            err = exception("Unable to open URL: {url} ({err})".format(url=url,
                                                                       err=rerr))
            err.err = rerr
            raise err

        return res

########NEW FILE########
__FILENAME__ = plugin
import operator
import re

from functools import partial

from ..cache import Cache
from ..exceptions import PluginError, NoStreamsError
from ..options import Options


QUALITY_WEIGTHS_EXTRA = {
    "other": {
        "live": 1080,
    },
    "tv": {
        "hd": 1080,
        "sd": 576,
    },
    "quality": {
        "ehq": 720,
        "hq":  576,
        "sq":  360,
    },
}


FILTER_OPERATORS = {
    "<": operator.lt,
    "<=": operator.le,
    ">": operator.gt,
    ">=": operator.ge,
}



def stream_weight(stream):
    for group, weights in QUALITY_WEIGTHS_EXTRA.items():
        if stream in weights:
            return weights[stream], group

    match = re.match("^(\d+)([k]|[p])?([\+])?$", stream)

    if match:
        if match.group(2) == "k":
            bitrate = int(match.group(1))

            # FIXME: This is a crude attempt at making a bitrate's
            # weight end up similar to the weight of a resolution.
            # Someone who knows math, please fix.
            weight = bitrate / 2.8

            return weight, "bitrate"

        elif match.group(2) == "p":
            weight = int(match.group(1))

            if match.group(3) == "+":
                weight += 1

            return weight, "pixels"

    return 0, "none"


def iterate_streams(streams):
    for name, stream in streams.items():
        if isinstance(stream, list):
            for sub_stream in stream:
                yield (name, sub_stream)
        else:
            yield (name, stream)


def stream_type_priority(stream_types, stream):
    stream_type = type(stream[1]).shortname()

    try:
        prio = stream_types.index(stream_type)
    except ValueError:
        prio = 99

    return prio


def stream_sorting_filter(expr, stream_weight):
    match = re.match(r"(?P<op><=|>=|<|>)?(?P<value>[\w\+]+)", expr)

    if not match:
        raise PluginError("Invalid filter expression: {0}".format(expr))

    op, value = match.group("op", "value")
    op = FILTER_OPERATORS.get(op, operator.eq)
    filter_weight, filter_group = stream_weight(value)

    def func(quality):
        weight, group = stream_weight(quality)

        if group == filter_group:
            return not op(weight, filter_weight)

        return True

    return func


class Plugin(object):
    """A plugin can retrieve stream information from the URL specified.

    :param url: URL that the plugin will operate on
    """

    cache = None
    logger = None
    module = "unknown"
    options = Options()
    session = None

    @classmethod
    def bind(cls, session, module):
        cls.cache = Cache(filename="plugin-cache.json",
                          key_prefix=module)
        cls.logger = session.logger.new_module("plugin." + module)
        cls.module = module
        cls.session = session

    def __init__(self, url):
        self.url = url

    @classmethod
    def can_handle_url(cls, url):
        raise NotImplementedError

    @classmethod
    def set_option(cls, key, value):
        cls.options.set(key, value)

    @classmethod
    def get_option(cls, key):
        return cls.options.get(key)

    @classmethod
    def stream_weight(cls, stream):
        return stream_weight(stream)

    @classmethod
    def default_stream_types(cls, streams):
        stream_types = ["rtmp", "hls", "hds", "http"]

        for name, stream in iterate_streams(streams):
            stream_type = type(stream).shortname()

            if stream_type not in stream_types:
                stream_types.append(stream_type)

        return stream_types

    def get_streams(self, stream_types=None, sorting_excludes=None):
        """Attempts to extract available streams.

        Returns a :class:`dict` containing the streams, where the key is
        the name of the stream, most commonly the quality and the value
        is a :class:`Stream` object.

        The result can contain the synonyms **best** and **worst** which
        points to the streams which are likely to be of highest and
        lowest quality respectively.

        If multiple streams with the same name are found, the order of
        streams specified in *stream_types* will determine which stream
        gets to keep the name while the rest will be renamed to
        "<name>_<stream type>".

        The synonyms can be fine tuned with the *sorting_excludes*
        parameter. This can be either of these types:

            - A list of filter expressions in the format
              *[operator]<value>*. For example the filter ">480p" will
              exclude streams ranked higher than "480p" from the list
              used in the synonyms ranking. Valid operators are >, >=, <
              and <=. If no operator is specified then equality will be
              tested.

            - A function that is passed to filter() with a list of
              stream names as input.


        :param stream_types: A list of stream types to return.
        :param sorting_excludes: Specify which streams to exclude from
                                 the best/worst synonyms.


        .. versionchanged:: 1.4.2
           Added *priority* parameter.

        .. versionchanged:: 1.5.0
           Renamed *priority* to *stream_types* and changed behaviour
           slightly.

        .. versionchanged:: 1.5.0
           Added *sorting_excludes* parameter.

        .. versionchanged:: 1.6.0
           *sorting_excludes* can now be a list of filter expressions
           or a function that is passed to filter().


        """

        try:
            ostreams = self._get_streams()
        except NoStreamsError:
            return {}
        except (IOError, OSError, ValueError) as err:
            raise PluginError(err)

        if not ostreams:
            return {}

        streams = {}

        if stream_types is None:
            stream_types = self.default_stream_types(ostreams)

        # Add streams depending on stream type and priorities
        sorted_streams = sorted(iterate_streams(ostreams),
                                key=partial(stream_type_priority,
                                            stream_types))

        for name, stream in sorted_streams:
            stream_type = type(stream).shortname()

            if stream_type not in stream_types:
                continue

            if name in streams:
                name = "{0}_{1}".format(name, stream_type)

            # Validate stream name and discard the stream if it's bad.
            match = re.match("([A-z0-9_+]+)", name)
            if match:
                name = match.group(1)
            else:
                self.logger.debug("The stream '{0}' has been ignored "
                                  "since it is badly named.", name)
                continue

            # Force lowercase name and replace space with underscore.
            streams[name.lower()] = stream

        # Create the best/worst synonmys
        stream_weight_only = lambda s: (self.stream_weight(s)[0] or
                                        (len(streams) == 1 and 1))
        stream_names = filter(stream_weight_only, streams.keys())
        sorted_streams = sorted(stream_names, key=stream_weight_only)

        if isinstance(sorting_excludes, list):
            for expr in sorting_excludes:
                filter_func = stream_sorting_filter(expr, self.stream_weight)
                sorted_streams = list(filter(filter_func, sorted_streams))
        elif callable(sorting_excludes):
            sorted_streams = list(filter(sorting_excludes, sorted_streams))

        if len(sorted_streams) > 0:
            best = sorted_streams[-1]
            worst = sorted_streams[0]
            streams["best"] = streams[best]
            streams["worst"] = streams[worst]

        return streams

    def _get_streams(self):
        raise NotImplementedError


__all__ = ["Plugin"]

########NEW FILE########
__FILENAME__ = afreecatv
import re

from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HLSStream


USER_AGENT = "Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)"
HEADERS = {"User-Agent": USER_AGENT}

PLAYLIST_URL = "http://m.afreeca.com/live/stream/a/hls/broad_no/{0}"
CHANNEL_URL = "http://afbbs.afreeca.com:8080/api/video/get_bj_liveinfo.php"
CHANNEL_REGEX = "http(s)?://(\w+\.)?afreeca.com/(?P<username>\w+)"


class AfreecaTV(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return re.match(CHANNEL_REGEX, url)

    def _find_broadcast(self, username):
        res = http.get(CHANNEL_URL, headers=HEADERS,
                       params=dict(szBjId=username))

        match = re.search(r"<thumb>.+\/(\d+)\.gif</thumb>", res.text)
        if match:
            return match.group(1)

    def _get_streams(self):
        match = re.match(CHANNEL_REGEX, self.url)
        if not match:
            return

        username = match.group("username")
        broadcast = self._find_broadcast(username)

        if not broadcast:
            return

        return HLSStream.parse_variant_playlist(self.session,
                                                PLAYLIST_URL.format(broadcast))

__plugin__ = AfreecaTV

########NEW FILE########
__FILENAME__ = alieztv
from livestreamer.compat import unquote
from livestreamer.stream import RTMPStream
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.exceptions import NoStreamsError

import re

class Aliez(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return "aliez.tv" in url

    def _get_streams(self):
        self.logger.debug("Fetching stream info")
        res = http.get(self.url)

        match = re.search("\"file\":[\t]+\"([^\"]+)\".+embedSWF\(\"([^\"]+)\"", res.text, re.DOTALL)
        if not match:
            raise NoStreamsError(self.url)

        rtmp = unquote(match.group(1))
        swfurl = match.group(2)

        streams = {}
        streams["live"] = RTMPStream(self.session, {
            "rtmp": rtmp,
            "pageUrl": self.url,
            "swfVfy": swfurl,
            "live": True
        }, redirect=True)

        return streams

__plugin__ = Aliez

########NEW FILE########
__FILENAME__ = azubutv
import re

from io import BytesIO
from operator import attrgetter
from time import sleep

from livestreamer.exceptions import PluginError
from livestreamer.packages.flashmedia import AMFPacket, AMFMessage
from livestreamer.packages.flashmedia.types import AMF3ObjectBase
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import AkamaiHDStream

AMF_GATEWAY = "http://c.brightcove.com/services/messagebroker/amf"
AMF_MESSAGE_PREFIX = "af6b88c640c8d7b4cc75d22f7082ad95603bc627"
STREAM_NAMES = ["360p", "480p", "720p", "1080p"]
HTTP_HEADERS = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1944.9 Safari/537.36"
}


@AMF3ObjectBase.register("com.brightcove.experience.ViewerExperienceRequest")
class ViewerExperienceRequest(AMF3ObjectBase):
    __members__ = ["contentOverrides",
                   "experienceId",
                   "URL",
                   "playerKey",
                   "deliveryType",
                   "TTLToken"]

    def __init__(self, URL, contentOverrides, experienceId, playerKey, TTLToken=""):
        self.URL = URL
        self.deliveryType = float("nan")
        self.contentOverrides = contentOverrides
        self.experienceId = experienceId
        self.playerKey = playerKey
        self.TTLToken = TTLToken


@AMF3ObjectBase.register("com.brightcove.experience.ContentOverride")
class ContentOverride(AMF3ObjectBase):
    __members__ = ["featuredRefId",
                   "contentRefIds",
                   "contentId",
                   "contentType",
                   "contentIds",
                   "featuredId",
                   "contentRefId",
                   "target"]

    def __init__(self, contentId=float("nan"), contentRefId=None, contentType=0,
                 target="videoPlayer"):
        self.contentType = contentType
        self.contentId = contentId
        self.target = target
        self.contentIds = None
        self.contentRefId = contentRefId
        self.contentRefIds = None
        self.contentType = 0
        self.featuredId = float("nan")
        self.featuredRefId = None


class AzubuTV(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return "azubu.tv" in url

    def _create_amf_request(self, key, video_player, player_id):
        if video_player.startswith("ref:"):
            content_override = ContentOverride(contentRefId=video_player[4:])
        else:
            content_override = ContentOverride(contentId=int(video_player))
        viewer_exp_req = ViewerExperienceRequest(self.url,
                                                [content_override],
                                                int(player_id), key)

        req = AMFPacket(version=3)
        req.messages.append(AMFMessage(
            "com.brightcove.experience.ExperienceRuntimeFacade.getDataForExperience",
            "/1",
            [AMF_MESSAGE_PREFIX, viewer_exp_req]
        ))

        return req

    def _send_amf_request(self, req, key):
        headers = { "content-type": "application/x-amf" }
        res = http.post(AMF_GATEWAY, data=bytes(req.serialize()),
                        headers=headers, params=dict(playerKey=key))

        return AMFPacket.deserialize(BytesIO(res.content))

    def _get_player_params(self, retries=5):
        try:
            res = http.get(self.url, headers=HTTP_HEADERS)
        except PluginError as err:
            # The server sometimes gives us 404 for no reason
            if "404" in str(err) and retries:
                sleep(1)
                return self._get_player_params(retries - 1)
            else:
                raise

        match = re.search("<param name=\"playerKey\" value=\"(.+)\" />", res.text)
        if not match:
            # The HTML returned sometimes doesn't contain the parameters
            if not retries:
                raise PluginError("Missing key 'playerKey' in player params")
            else:
                sleep(1)
                return self._get_player_params(retries - 1)

        key = match.group(1)
        match = re.search("AZUBU.setVar\(\"firstVideoRefId\", \"(.+)\"\);", res.text)
        if not match:
            # The HTML returned sometimes doesn't contain the parameters
            if not retries:
                raise PluginError("Unable to find video reference")
            else:
                sleep(1)
                return self._get_player_params(retries - 1)

        video_player = "ref:" + match.group(1)
        match = re.search("<param name=\"playerID\" value=\"(\d+)\" />", res.text)
        if not match:
            # The HTML returned sometimes doesn't contain the parameters
            if not retries:
                raise PluginError("Missing key 'playerID' in player params")
            else:
                sleep(1)
                return self._get_player_params(retries - 1)

        player_id = match.group(1)
        match = re.search("<!-- live on -->", res.text)
        if not match:
            match = re.search("<div id=\"channel_live\">", res.text)
        is_live = not not match

        return key, video_player, player_id, is_live

    def _parse_result(self, res):
        streams = {}

        if not hasattr(res, "programmedContent"):
            raise PluginError("Invalid result")

        player = res.programmedContent["videoPlayer"]

        if not hasattr(player, "mediaDTO"):
            raise PluginError("Invalid result")

        renditions = sorted(player.mediaDTO.renditions.values(),
                            key=attrgetter("encodingRate"))

        for stream_name, rendition in zip(STREAM_NAMES, renditions):
            stream = AkamaiHDStream(self.session, rendition.defaultURL)
            streams[stream_name] = stream

        return streams

    def _get_streams(self):
        key, video_player, player_id, is_live = self._get_player_params()

        if not is_live:
            return

        req = self._create_amf_request(key, video_player, player_id)
        res = self._send_amf_request(req, key)

        streams = {}
        for message in res.messages:
            if message.target_uri == "/1/onResult":
                streams = self._parse_result(message.value)

        return streams

__plugin__ = AzubuTV

########NEW FILE########
__FILENAME__ = bambuser
from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HTTPStream, RTMPStream
from livestreamer.utils import verifyjson

import random
import re

PLAYER_URL = "http://player-c.api.bambuser.com/getVideo.json"

class Bambuser(Plugin):

    @classmethod
    def can_handle_url(self, url):
        return "bambuser.com/v/" in url

    def _get_streams(self):
        match = re.search("/v/(\d+)", self.url)
        if not match:
            return

        vid = match.group(1)
        params = dict(client_name="Bambuser AS2", context="b_broadcastpage",
                      raw_user_input=1, api_key="005f64509e19a868399060af746a00aa",
                      vid=vid, r=random.random())

        self.logger.debug("Fetching stream info")
        res = http.get(PLAYER_URL, params=params)
        json = http.json(res)

        error = json and json.get("errorCode")
        if error:
            error = error and json.get("error")
            self.logger.error(error)
            return

        json = verifyjson(json, "result")
        playpath = verifyjson(json, "id")
        url = verifyjson(json, "url")
        (width, height) = verifyjson(json, "size").split("x")
        name = "{0}p".format(height)

        parsed = urlparse(url)
        streams  = {}

        if parsed.scheme.startswith("rtmp"):
            if not RTMPStream.is_usable(self.session):
                raise PluginError("rtmpdump is not usable and required by Bambuser plugin")
            streams[name] = RTMPStream(self.session, {
                "rtmp": url,
                "playpath": playpath,
                "pageUrl": self.url,
                "live": True
            })
        elif parsed.scheme == "http":
            streams[name] = HTTPStream(self.session, url)

        return streams


__plugin__ = Bambuser

########NEW FILE########
__FILENAME__ = beattv
import re

from collections import namedtuple
try:
    from Crypto.Cipher import AES
    CAN_DECRYPT = True
except ImportError:
    CAN_DECRYPT = False
from io import BytesIO

from livestreamer.compat import range
from livestreamer.exceptions import StreamError, PluginError
from livestreamer.packages.flashmedia.tag import (AACAudioData, AudioData,
                                                  AVCVideoData, RawData, Tag,
                                                  VideoData)
from livestreamer.packages.flashmedia.tag import (AAC_PACKET_TYPE_RAW,
                                                  AAC_PACKET_TYPE_SEQUENCE_HEADER,
                                                  AUDIO_BIT_RATE_16,
                                                  AUDIO_CODEC_ID_AAC,
                                                  AUDIO_RATE_44_KHZ,
                                                  AUDIO_TYPE_STEREO,
                                                  AVC_PACKET_TYPE_NALU,
                                                  AVC_PACKET_TYPE_SEQUENCE_HEADER,
                                                  TAG_TYPE_AUDIO,
                                                  TAG_TYPE_VIDEO,
                                                  VIDEO_CODEC_ID_AVC,
                                                  VIDEO_FRAME_TYPE_INTER_FRAME,
                                                  VIDEO_FRAME_TYPE_KEY_FRAME)
from livestreamer.packages.flashmedia.types import U8, U16BE, U32BE
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import Stream, StreamIOIterWrapper
from livestreamer.stream.flvconcat import FLVTagConcat
from livestreamer.stream.segmented import (SegmentedStreamReader,
                                           SegmentedStreamWriter,
                                           SegmentedStreamWorker)


HEADERS = {"User-Agent": "Mozilla/5.0"}
BEAT_PROGRAM = "http://www.be-at.tv/{0}.program"
BEAT_URL = "http://www.be-at.tv/{0}/{1}/{2}.{3}"

QUALITY_MAP = {"audio_mono": 0, "audio_stereo": 1,
               "mobile_low": 5, "mobile_medium": 6,
               "web_medium": 10, "web_high": 11, "web_hd": 12}

Chunk = namedtuple("Chunk", "recording quality sequence extension")


class BeatFLVTagConcat(FLVTagConcat):
    def __init__(self, *args, **kwargs):
        FLVTagConcat.__init__(self, *args, **kwargs)

    def decrypt_data(self, key, iv, data):
        decryptor = AES.new(key, AES.MODE_CBC, iv)
        return decryptor.decrypt(data)

    def iter_tags(self, fd=None, buf=None, skip_header=None):
        flags = U8.read(fd)
        quality = flags & 15
        version = flags >> 4
        lookup_size = U16BE.read(fd)
        enc_table = fd.read(lookup_size)

        key = b""
        iv = b""

        for i in range(16):
            key += fd.read(1)
            iv += fd.read(1)

        if not (key and iv):
            return

        dec_table = self.decrypt_data(key, iv, enc_table)
        dstream = BytesIO(dec_table)

        # Decode lookup table (ported from K-S-V BeatConvert.php)
        while True:
            flags = U8.read(dstream)
            if not flags:
                break

            typ = flags >> 4
            encrypted = (flags & 4) > 0
            keyframe = (flags & 2) > 0
            config = (flags & 1) > 0
            time = U32BE.read(dstream)
            data_length = U32BE.read(dstream)

            if encrypted:
                raw_length = U32BE.read(dstream)
            else:
                raw_length = data_length

            # Decrypt encrypted tags
            data = fd.read(data_length)
            if encrypted:
                data = self.decrypt_data(key, iv, data)
                data = data[:raw_length]

            # Create video tag
            if typ == 1:
                if version == 2:
                    if config:
                        avc = AVCVideoData(AVC_PACKET_TYPE_SEQUENCE_HEADER,
                                           data=data)
                    else:
                        avc = AVCVideoData(AVC_PACKET_TYPE_NALU, data=data)

                    if keyframe:
                        videodata = VideoData(VIDEO_FRAME_TYPE_KEY_FRAME,
                                              VIDEO_CODEC_ID_AVC, avc)
                    else:
                        videodata = VideoData(VIDEO_FRAME_TYPE_INTER_FRAME,
                                              VIDEO_CODEC_ID_AVC, avc)
                else:
                    videodata = RawData(data)

                yield Tag(TAG_TYPE_VIDEO, time, videodata)

            # Create audio tag
            if typ == 2:
                if version == 2:
                    if config:
                        aac = AACAudioData(AAC_PACKET_TYPE_SEQUENCE_HEADER,
                                           data)
                    else:
                        aac = AACAudioData(AAC_PACKET_TYPE_RAW, data)

                    audiodata = AudioData(codec=AUDIO_CODEC_ID_AAC,
                                          rate=AUDIO_RATE_44_KHZ,
                                          bits=AUDIO_BIT_RATE_16,
                                          type=AUDIO_TYPE_STEREO,
                                          data=aac)
                else:
                    audiodata = RawData(data)

                yield Tag(TAG_TYPE_AUDIO, time, audiodata)


class BeatStreamWriter(SegmentedStreamWriter):
    def __init__(self, *args, **kwargs):
        SegmentedStreamWriter.__init__(self, *args, **kwargs)

        self.concater = BeatFLVTagConcat(flatten_timestamps=True)

    def open_chunk(self, chunk, retries=3):
        while retries and not self.closed:
            try:
                url = BEAT_URL.format(chunk.recording,
                                      chunk.quality,
                                      chunk.sequence,
                                      chunk.extension)
                return self.session.http.get(url,
                                             stream=True,
                                             headers=HEADERS,
                                             timeout=10,
                                             exception=StreamError)
            except StreamError as err:
                self.logger.error("Failed to open chunk {0}/{1}/{2}: {3}",
                                  chunk.recording,
                                  chunk.quality,
                                  chunk.sequence, err)
            retries -= 1

    def write(self, chunk, chunk_size=8192):
        res = self.open_chunk(chunk)
        if not res:
            return

        try:
            fd = StreamIOIterWrapper(res.iter_content(8192))
            for data in self.concater.iter_chunks(fd=fd, skip_header=True):
                self.reader.buffer.write(data)
                if self.closed:
                    return

            self.logger.debug("Download of chunk {0}/{1}/{2} complete",
                              chunk.recording,
                              chunk.quality,
                              chunk.sequence)
        except IOError as err:
            self.logger.error("Failed to read chunk {0}/{1}/{2}: {3}",
                              chunk.recording,
                              chunk.quality,
                              chunk.sequence, err)


class BeatStreamWorker(SegmentedStreamWorker):
    def __init__(self, *args, **kwargs):
        SegmentedStreamWorker.__init__(self, *args, **kwargs)

    def iter_segments(self):
        quality = QUALITY_MAP[self.stream.quality]
        for part in self.stream.parts:
            duration = part.get("duration")
            if not part.get("recording"):
                recording = part.get("id")
                extension = "part"
            else:
                recording = part.get("recording")
                extension = "rec"
            chunks = int(duration / 12) + 1
            start = int(part.get("start", 0) / 12)
            for sequence in range(start, chunks + start):
                if self.closed:
                    return
                self.logger.debug("Adding chunk {0}/{1}/{2} to queue",
                                  recording,
                                  quality,
                                  sequence)
                yield Chunk(recording, quality, sequence, extension)


class BeatStreamReader(SegmentedStreamReader):
    __worker__ = BeatStreamWorker
    __writer__ = BeatStreamWriter

    def __init__(self, stream, *args, **kwargs):
        self.logger = stream.session.logger.new_module("stream.beat")

        SegmentedStreamReader.__init__(self, stream, *args, **kwargs)


class BeatStream(Stream):
    __shortname__ = "beat"

    def __init__(self, session, parts, quality):
        Stream.__init__(self, session)

        self.parts = parts
        self.quality = quality

    def __repr__(self):
        return ("<BeatStream({0!r}, {1!r}>").format(len(self.parts),
                                                    self.quality)

    def __json__(self):
        return dict(parts=self.parts, quality=self.quality,
                    **Stream.__json__(self))

    def open(self):
        reader = BeatStreamReader(self)
        reader.open()

        return reader


class BeatTV(Plugin):

    @classmethod
    def can_handle_url(self, url):
        return "be-at.tv" in url

    @classmethod
    def stream_weight(cls, key):
        weight = QUALITY_MAP.get(key)
        if weight:
            return weight, "beat"

        return Plugin.stream_weight(key)

    def _get_stream_info(self, url):
        res = http.get(url, headers=HEADERS)
        match = re.search("embed.swf\?p=(\d+)", res.text)
        if not match:
            return
        program = match.group(1)
        res = http.get(BEAT_PROGRAM.format(program), headers=HEADERS)

        return http.json(res)

    def _get_streams(self):
        if not CAN_DECRYPT:
            raise PluginError("Need pyCrypto installed to decrypt streams")

        json = self._get_stream_info(self.url)

        if not json:
            return

        if json.get("status", 0) == 0:
            return

        parts = []
        for media in json.get("media", []):
            if media.get("id") < 0:
                continue
            for part in media.get("parts", []):
                if part.get("duration") < 0:
                    continue
                parts.append(part)

        if not parts:
            return

        streams = {}
        for quality in QUALITY_MAP:
            streams[quality] = BeatStream(self.session, parts, quality)

        return streams


__plugin__ = BeatTV

########NEW FILE########
__FILENAME__ = cast3d
from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HTTPStream

import re

class Cast3d(Plugin):
    SWFURL = "http://www.cast3d.biz/player.swf"
    PlayerURL = "http://www.cast3d.tv/embed.php"

    @classmethod
    def can_handle_url(self, url):
        return "cast3d.tv" in url

    def _get_streams(self):
        channelname = urlparse(self.url).path.rstrip("/").rpartition("/")[-1].lower()

        self.logger.debug("Fetching stream info")

        headers = {
            "Referer": self.url,
            "Accept-Encoding": "deflate"
        }

        options = dict(channel=channelname, vw="580", vh="390",
                       domain="www.cast3d.tv")

        res = http.get(self.PlayerURL, headers=headers, params=options)

        match = re.search(".+?'streamer':'(.+?)'", res.text)
        if not match:
            raise NoStreamsError(self.url)

        streams = {}
        url = urlparse(match.group(1))
        if url.scheme.startswith("rtmp"):
            redirect = False
            rtmp = match.group(1)
            if "redirect" in rtmp:
                redirect = True

            streams["live"] = RTMPStream(self.session, {
                "rtmp": rtmp,
                "pageUrl": self.url,
                "swfVfy": self.SWFURL,
                "playpath": channelname,
                "live": True
            }, redirect=redirect)

        elif url.scheme.startswith("http"):
            streams["live"] = HTTPStream(self.session, match.group(1))
        else:
            raise PluginError(("Invalid stream type: {0}").format(url.scheme))

        return streams


__plugin__ = Cast3d

########NEW FILE########
__FILENAME__ = chaturbate
from livestreamer.exceptions import NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.stream import HLSStream
from livestreamer.plugin.api import http

import re

class Chaturbate(Plugin):
    _reSrc = re.compile(r'html \+= \"src=\'([^\']+)\'\";')
    
    @classmethod
    def can_handle_url(self, url):
        return "chaturbate.com" in url

    def _get_streams(self):
        res = http.get(self.url)
        match = self._reSrc.search(res.text)
        if not match:
            raise NoStreamsError(self.url)
        return HLSStream.parse_variant_playlist(self.session, match.group(1))
        
__plugin__ = Chaturbate

########NEW FILE########
__FILENAME__ = common_swf
from collections import namedtuple
from io import BytesIO

from livestreamer.utils import swfdecompress
from livestreamer.packages.flashmedia.types import U16LE, U32LE

__all__ = ["parse_swf"]

Rect = namedtuple("Rect", "data")
Tag = namedtuple("Tag", "type data")
SWF = namedtuple("SWF", "frame_size frame_rate frame_count tags")


def read_rect(fd):
    header = ord(fd.read(1))
    nbits = header >> 3
    nbytes = int(((5 + 4 * nbits) + 7) / 8)
    data = fd.read(nbytes - 1)

    return Rect(data)


def read_tag(fd):
    header = U16LE.read(fd)
    tag_type = header >> 6
    tag_length = header & 0x3f
    if tag_length == 0x3f:
        tag_length = U32LE.read(fd)

    tag_data = fd.read(tag_length)

    return Tag(tag_type, tag_data)


def read_tags(fd):
    while True:
        try:
            yield read_tag(fd)
        except IOError:
            break


def parse_swf(data):
    data = swfdecompress(data)
    fd = BytesIO(data[8:])
    frame_size = read_rect(fd)
    frame_rate = U16LE.read(fd)
    frame_count = U16LE.read(fd)
    tags = list(read_tags(fd))

    return SWF(frame_size, frame_rate, frame_count, tags)


########NEW FILE########
__FILENAME__ = crunchyroll
from __future__ import unicode_literals

import string
import random
import datetime

from livestreamer import options, plugin, exceptions, stream
from livestreamer.plugin.api import http

API_URL = 'https://api.crunchyroll.com/{0}.0.json'
API_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (PLAYSTATION 3; 4.46)',
    'Host': 'api.crunchyroll.com',
    'Accept-Encoding': 'gzip, deflate',
    'Accept': '*/*',
    'Content-Type': 'application/x-www-form-urlencoded'
}
API_VERSION = '1.0.1'
API_LOCALE = 'enUS'
API_ACCESS_TOKEN = 'S7zg3vKx6tRZ0Sf'
API_DEVICE_TYPE = 'com.crunchyroll.ps3'


def parse_timestamp(ts):
    '''Takes ISO 8601 format(string) and converts into a utc datetime(naive)'''
    dt = datetime.datetime.strptime(ts[:-7], '%Y-%m-%dT%H:%M:%S') +\
        datetime.timedelta(hours=int(ts[-5:-3]), minutes=int(ts[-2:])) *\
        int(ts[-6:-5] + '1')

    return dt


class APIError(Exception):
    '''Exception throw by the CrunchyrollAPI when an error occurs'''
    pass


class CrunchyrollAPI(object):
    def __init__(self, session_id=None, auth=None):
        '''Abstract the API to access to Crunchyroll data.
        Can take saved credentials to use on it's calls to the API.
        '''
        self.session_id = session_id
        self.auth = auth

    def _api_call(self, entrypoint, params):
        '''Makes a call against the api.
        :param entrypoint: API method to call.
        :param params: parameters to include in the request data.
        '''
        url = API_URL.format(entrypoint)

        # default params
        params.update({
            'version': API_VERSION,
            'locale': API_LOCALE,
        })

        if self.session_id:
            params['session_id'] = self.session_id

        # The certificate used by Crunchyroll cannot be verified in some
        # environments.
        response = http.get(url, params=params, headers=API_HEADERS,
                            verify=False)
        json_response = http.json(response)

        if json_response['error']:
            raise APIError(json_response['message'])

        return json_response

    def start_session(self, device_id):
        '''Starts a session against Crunchyroll's server.
        Is recommended that you call this method before making any other calls
        to make sure you have a valid session against the server.
        '''
        params = {
            'device_id': device_id,
            'device_type': API_DEVICE_TYPE,
            'access_token': API_ACCESS_TOKEN,
        }

        if self.auth:
            params['auth'] = self.auth

        response = self._api_call('start_session', params)
        self.session_id = response['data']['session_id']

        return datetime.datetime.utcnow() + datetime.timedelta(hours=4)

    def login(self, username, password):
        '''Authenticates the session to be able to access restricted data from
        the server (e.g. premium restricted videos).
        '''
        params = {
            'account': username,
            'password': password
        }

        response = self._api_call('login', params)
        self.auth = response['data']['auth']

        return parse_timestamp(response['data']['expires'])

    def get_info(self, media_id, fields=None):
        '''Returns the data for a certain media item.

        :param media_id: id that identifies the media item to be accessed.
        :param fields: list of the media's field to be returned. By default the
        API returns some fields, but others are not returned unless they are
        explicity asked for. I have no real documentation on the fields, but
        they all seem to start with the 'media.' prefix (e.g. media.name,
        media.stream_data).
        '''
        params = {
            'media_id': media_id
        }

        if fields:
            params['fields'] = ','.join(fields)

        response = self._api_call('info', params)

        return response['data']


class Crunchyroll(plugin.Plugin):

    options = options.Options({
        'username': None,
        'password': None,
        'purge_credentials': None,
    })

    WEIGHTS = {
        'low': 240,
        'mid': 420,
        'high': 720,
        'ultra': 1080,
    }

    @classmethod
    def can_handle_url(self, url):
        return 'crunchyroll.com' in url

    @classmethod
    def stream_weight(cls, key):
        weight = cls.WEIGHTS.get(key)

        if weight:
            return weight, "crunchyroll"

        return plugin.Plugin.stream_weight(key)

    def _get_streams(self):
        # create a new api
        api = self._create_api()

        try:
            # parse the media id from the url
            media_id = int(self.url.split('/')[-1].split('-')[-1])
        except ValueError:
            raise exceptions.PluginError('Invalid url')

        try:
            # try to obtain the info on streams for this media item
            stream_data = api.get_info(
                media_id, fields=['media.stream_data']
            )['stream_data']
        except APIError as e:
            raise exceptions.PluginError(
                'Media lookup error: {0}'.format(e.args[0]))

        if stream_data:
            streams_raw = stream_data['streams']
        else:
            raise exceptions.NoStreamsError(self.url)

        # convert the raw stream data into the stream list expected by
        # livestreamer (adaptive get's filtered since it isn't supported)
        streams = dict(
            (s['quality'], stream.HLSStream(self.session, s['url']))
            for s in streams_raw
            if s['quality'] != 'adaptive'
        )

        return streams

    def _get_device_id(self):
        '''Returns the saved device id or creates a new one an saves it'''
        device_id = self.cache.get('device_id')

        if not device_id:
            # create a random device id
            char_set = string.ascii_letters + string.digits
            device_id = ''.join(random.sample(char_set, 32))
            self.cache.set('device_id', device_id, 31536000)

        return device_id

    def _create_api(self):
        '''Creates a new CrunchyrollAPI object, initiates it's session and
        tries to authenticate it either by using saved credentials or the
        user's username and password.
        '''
        if self.options.get('purge_credentials'):
            self.cache.set('session_id', None, 0)
            self.cache.set('auth', None, 0)

        current_time = datetime.datetime.utcnow()
        api = CrunchyrollAPI(
            self.cache.get('session_id'), self.cache.get('auth'))

        self.logger.debug('Creating session...')
        try:
            expires = api.start_session(self._get_device_id())
        except APIError as e:
            if e.args[0] == 'Unauthenticated request':
                self.logger.info('Aparently credentials got debunked')
                api = CrunchyrollAPI()
                expires = api.start_session(self._get_device_id())
            else:
                raise e

        self.cache.set(
            'session_id',
            api.session_id,
            (expires - current_time).total_seconds()
        )
        self.logger.debug('Success!')

        if api.auth:
            self.logger.info('Using saved credentials')
        elif self.options.get('username'):
            try:
                self.logger.info(
                    'Trying to login using user and password...')
                expires = api.login(
                    self.options.get('username'),
                    self.options.get('password')
                )
                self.cache.set(
                    'auth',
                    api.auth,
                    (expires - current_time).total_seconds()
                )

                self.logger.info('Success!')
            except APIError as e:
                raise exceptions.PluginError(
                    'Authentication error: {0}'.format(e.args[0]))
        else:
            self.logger.warning(
                "No authentication provided, you won't be able to access "
                "premium restricted content"
            )

        return api


__plugin__ = Crunchyroll

########NEW FILE########
__FILENAME__ = cybergame
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream

import re

PLAYLIST_URL = "http://api.cybergame.tv/p/playlist.smil"
CONFIG_URL = "http://api.cybergame.tv/p/config.php"

class Cybergame(Plugin):

    @classmethod
    def can_handle_url(self, url):
        return "cybergame.tv" in url

    def _get_rtmp_streams(self, params, alternative=""):
        res = http.get(PLAYLIST_URL, params=params)
        root = http.xml(res)
        rtmp = root.find("./head/meta").attrib.get("base")
        if not rtmp:
            raise NoStreamsError(self.url)

        tmpsteams = {}

        videos = root.findall("./body/switch/video") or root.findall("./body/video")
        for video in videos:
            src = video.attrib.get("src")
            height = video.attrib.get("height")
            quality = "{0}p{1}".format(height, alternative)
            tmpsteams[quality] = RTMPStream(self.session, {
                "rtmp": "{0}/{1}".format(rtmp,src),
                "pageUrl": self.url,
                "live": True
            })

        return tmpsteams

    def _get_vod_streams(self):
        match = re.search("/videos/(\d+)", self.url)
        if not match:
            return
        params = dict(vod=match.group(1))
        return self._get_rtmp_streams(params)

    def _get_streams(self):
        if not RTMPStream.is_usable(self.session):
            raise PluginError("rtmpdump is not usable and required by Cybergame plugin")

        if "/videos/" in self.url:
            return self._get_vod_streams()

        self.logger.debug("Fetching live stream info")
        res = http.get(self.url)

        match = re.search("channel=([^\"]+)", res.text)
        if not match:
            raise NoStreamsError(self.url)

        channelname = match.group(1)

        res = http.get(CONFIG_URL, params=dict(c=channelname, ports="y"))
        json = http.json(res)
        servers = json.get("servers")
        if not servers:
            raise NoStreamsError(self.url)

        alternative = ""
        streams  = {}

        for server in servers:
            srv, port = server.split(":")
            params = dict(channel=channelname, server=srv, port=port)
            tmpstreams = self._get_rtmp_streams(params, alternative)
            streams.update(tmpstreams)
            if not alternative:
                alternative = "_alt"
            else:
                break

        return streams


__plugin__ = Cybergame

########NEW FILE########
__FILENAME__ = dailymotion
import re

from functools import reduce

from livestreamer.compat import urlparse, unquote, range
from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HDSStream, HTTPStream, RTMPStream
from livestreamer.stream.playlist import FLVPlaylist
from livestreamer.utils import verifyjson

METADATA_URL = "https://api.dailymotion.com/video/{0}"
QUALITY_MAP = {
    "ld": "240p",
    "sd": "360p",
    "hq": "480p",
    "hd720": "720p",
    "hd1080": "1080p",
    "custom": "live",
    "auto": "hds"
}
RTMP_SPLIT_REGEX = r"(?P<host>rtmp://[^/]+)/(?P<app>[^/]+)/(?P<playpath>.+)"
STREAM_INFO_URL = "http://www.dailymotion.com/sequence/full/{0}"


class DailyMotion(Plugin):
    @classmethod
    def can_handle_url(self, url):
        # valid urls are of the form dailymotion.com/video/[a-z]{5}.*
        # but we make "video/" optional and allow for dai.ly as shortcut
        # Gamecreds uses Dailymotion as backend so we support it through this plugin.
        return ("dailymotion.com" in url) or ("dai.ly" in url) or ("video.gamecreds.com" in url)

    def _check_channel_live(self, channelname):
        url = METADATA_URL.format(channelname)
        res = http.get(url, params=dict(fields="mode"))
        json = http.json(res)

        if not isinstance(json, dict):
            raise PluginError("Invalid JSON response")

        mode = verifyjson(json, "mode")

        return mode == "live"

    def _get_channel_name(self, url):
        name = None
        if ("dailymotion.com" in url) or ("dai.ly" in url):
            rpart = urlparse(url).path.rstrip("/").rpartition("/")[-1].lower()
            name = re.sub("_.*", "", rpart)
        elif ("video.gamecreds.com" in url):
            res = http.get(url)
            # The HTML is broken (unclosed meta tags) and minidom fails to parse.
            # Since we are not manipulating the DOM, we get away with a simple grep instead of fixing it.
            match = re.search("<meta property=\"og:video\" content=\"http://www.dailymotion.com/swf/video/([a-z0-9]{6})", res.text)
            if match: name = match.group(1)

        return name

    def _get_node_by_name(self, parent, name):
        res = None
        for node in parent:
            if node["name"] == name:
                res = node
                break

        return res

    def _get_rtmp_streams(self, channelname):
        self.logger.debug("Fetching stream info")
        res = http.get(STREAM_INFO_URL.format(channelname))
        json = http.json(res)

        if not isinstance(json, dict):
            raise PluginError("Invalid JSON response")

        if not json:
            raise PluginError("JSON is empty")

        # This is ugly, not sure how to fix it.
        back_json_node = json["sequence"][0]["layerList"][0]
        if back_json_node["name"] != "background":
            raise PluginError("JSON data has unexpected structure")

        rep_node = self._get_node_by_name(back_json_node["sequenceList"], "reporting")["layerList"]
        main_node = self._get_node_by_name(back_json_node["sequenceList"], "main")["layerList"]

        if not (rep_node and main_node):
            raise PluginError("Error parsing stream RTMP url")

        swfurl = self._get_node_by_name(rep_node, "reporting")["param"]["extraParams"]["videoSwfURL"]
        feeds_params = self._get_node_by_name(main_node, "video")["param"]

        if not (swfurl and feeds_params):
            raise PluginError("Error parsing stream RTMP url")


        # Different feed qualities are available are a dict under "live"
        # In some cases where there's only 1 quality available,
        # it seems the "live" is absent. We use the single stream available
        # under the "customURL" key.
        streams = {}
        if "mode" in feeds_params and feeds_params["mode"] == "live":
            for key, quality in QUALITY_MAP.items():
                url = feeds_params.get("{0}URL".format(key))
                if not url:
                    continue

                try:
                    res = http.get(url, exception=IOError)
                except IOError:
                    continue

                if quality == "hds":
                    hds_streams = HDSStream.parse_manifest(self.session,
                                                           res.url)
                    streams.update(hds_streams)
                else:
                    match = re.match(RTMP_SPLIT_REGEX, res.text)
                    if not match:
                        self.logger.warning("Failed to split RTMP URL: {0}",
                                            res.text)
                        continue

                    stream = RTMPStream(self.session, {
                        "rtmp": match.group("host"),
                        "app": match.group("app"),
                        "playpath": match.group("playpath"),
                        "swfVfy": swfurl,
                        "live": True
                    })

                    self.logger.debug("Adding URL: {0}", res.text)
                    streams[quality] = stream

        return streams

    def _create_flv_playlist(self, template):
        res = http.get(template)
        json = http.json(res)

        if not isinstance(json, dict):
            raise PluginError("Invalid JSON response")

        parsed = urlparse(template)
        try:
            url_template = '{0}://{1}{2}'.format(
                parsed.scheme, parsed.netloc, json['template']
            )
            segment_max = reduce(lambda i,j: i+j[0], json['fragments'], 0)
            duration = json['duration']
        except KeyError:
            raise PluginError('Unexpected JSON response')

        substreams = [HTTPStream(self.session,
                                 url_template.replace('$fragment$', str(i)))
                      for i in range(1, segment_max + 1)]

        return FLVPlaylist(self.session, streams=substreams,
                           duration=duration, skip_header=True,
                           flatten_timestamps=True)

    def _get_vod_streams(self, channelname):
        res = http.get(self.url)
        match = re.search('autoURL%22%3A%22(.*?)%22', res.text)
        if not match:
            raise PluginError('Error retrieving manifest url')
        manifest_url = unquote(match.group(1)).replace('\\', '')

        try:
            res = http.get(manifest_url)
            manifest = http.json(res)
        except:
            raise PluginError('Error retrieving manifest')

        # A fallback host (http://proxy-xx...) is sometimes provided
        # that we could make us of.
        streams = {}
        for params in manifest.get('alternates', []):
            name = params.get('name')
            template = params.get('template')
            if not (name and template):
                continue

            name = '{0}p'.format(name)
            streams[name] = self._create_flv_playlist(template)

        return streams

    def _get_streams(self):
        channelname = self._get_channel_name(self.url)

        if not channelname:
            return

        if self._check_channel_live(channelname):
            return self._get_rtmp_streams(channelname)
        else:
            return self._get_vod_streams(channelname)


__plugin__ = DailyMotion


# vim: expandtab tabstop=4 shiftwidth=4

########NEW FILE########
__FILENAME__ = dmcloud
from livestreamer.exceptions import NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HLSStream
from livestreamer.utils import parse_json, rtmpparse, swfdecompress

import re

class DMCloud(Plugin):

    @classmethod
    def can_handle_url(self, url):
        return "api.dmcloud.net" in url

    def _get_rtmp_streams(self, swfurl):
        if not RTMPStream.is_usable(self.session):
            raise NoStreamsError(self.url)

        self.logger.debug("Fetching RTMP stream info")

        res = http.get(swfurl)
        swf = swfdecompress(res.content)
        match = re.search("customURL[^h]+(https://.*?)\\\\", swf)

        if not match:
            raise NoStreamsError(self.url)

        res = http.get(match.group(1))
        rtmp, playpath = rtmpparse(res.text)

        params = {
            "rtmp": rtmp,
            "pageUrl": self.url,
            "playpath": playpath,
            "live": True
        }

        match = re.search("file[^h]+(https?://.*?.swf)", swf)
        if match:
            params["swfUrl"] = match.group(1)

        return RTMPStream(self.session, params)

    def _get_streams(self):
        self.logger.debug("Fetching stream info")
        res = http.get(self.url)

        match = re.search("var info = (.*);", res.text)
        if not match:
            raise NoStreamsError(self.url)

        json = parse_json(match.group(1))
        if not isinstance(json, dict):
            return

        ios_url = json.get("ios_url")
        swf_url = json.get("swf_url")
        streams = {}

        if ios_url:
            hls = HLSStream.parse_variant_playlist(self.session, ios_url)
            streams.update(hls)

        if swf_url:
            try:
                streams["live"] = self._get_rtmp_streams(swf_url)
            except NoStreamsError:
                pass

        return streams


__plugin__ = DMCloud

########NEW FILE########
__FILENAME__ = dmcloud_embed
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http

import re

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:25.0) Gecko/20100101 Firefox/25.0"
}
URL_REGEX = r"http(s)?://api.dmcloud.net/player/embed/[\w\?=&\/;\-]+"
URLS = [
    r"http(s)?://(\w+\.)?action24.gr"
]


class DMCloudEmbed(Plugin):
    @classmethod
    def can_handle_url(self, url):
        for site in URLS:
            if re.match(site, url):
                return True

    def _get_streams(self):
        res = http.get(self.url, headers=HEADERS)

        match = re.search(URL_REGEX, res.text)
        if match:
            url = match.group(0)
            plugin = self.session.resolve_url(url)
            return plugin.get_streams()


__plugin__ = DMCloudEmbed

########NEW FILE########
__FILENAME__ = euronews
from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream


class Euronews(Plugin):
    SWFURL = "http://euronews.com/media/player_live_1_14.swf"
    APIURL = "http://euronews.hexaglobe.com/json/"
    GEOIPURL = "http://freegeoip.net/json/"

    @classmethod
    def can_handle_url(self, url):
        return "euronews.com" in url

    def _get_streams(self):
        country_code = urlparse(self.url).netloc.split(".")[0]

        self.logger.debug("Fetching stream info")
        res = http.get(self.APIURL)
        json = http.json(res)

        if not isinstance(json, dict):
            raise PluginError("Invalid JSON response")
        elif not ("primary" in json or "secondary" in json):
            raise PluginError("Invalid JSON response")

        if not RTMPStream.is_usable(self.session):
            raise PluginError("rtmpdump is not usable and required by Euronews plugin")

        streams = {}

        self.logger.debug("Euronews Countries:{0}", " ".join(json["primary"].keys()))

        if not (country_code in json["primary"] or country_code in json["secondary"]):
            res = http.get(self.GEOIPURL)
            geo = http.json(res)
            if isinstance(json, dict) and "country_code" in geo:
                country_code = geo["country_code"].lower()
                if not (country_code in json["primary"] or country_code in json["secondary"]):
                    country_code = "en"
            else:
                country_code = "en"

        for site in ("primary", "secondary"):
            for quality in json[site][country_code]["rtmp_flash"]:
                stream = json[site][country_code]["rtmp_flash"][quality]
                name = quality + "k"
                if site == "secondary":
                    name += "_alt"
                streams[name] = RTMPStream(self.session, {
                    "rtmp": stream["server"],
                    "playpath" : stream["name"],
                    "swfUrl": self.SWFURL,
                    "live": True
                })

        if len(streams) == 0:
            raise NoStreamsError(self.url)

        return streams


__plugin__ = Euronews

########NEW FILE########
__FILENAME__ = filmon
import re

from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream

AJAX_HEADERS = {
    "Referer": "http://www.filmon.com",
    "X-Requested-With": "XMLHttpRequest",
    "User-Agent": "Mozilla/5.0"
}
CHINFO_URL = "http://www.filmon.com/ajax/getChannelInfo"
VODINFO_URL = "http://www.filmon.com/vod/info/{0}"
QUALITY_WEIGHTS = {
    "high": 720,
    "low": 480
}
SWF_URL = "http://www.filmon.com/tv/modules/FilmOnTV/files/flashapp/filmon/FilmonPlayer.swf"


class Filmon(Plugin):
    @classmethod
    def can_handle_url(cls, url):
        return re.match("^http(s)?://(\w+\.)?filmon.com/(tv|vod).+", url)

    @classmethod
    def stream_weight(cls, key):
        weight = QUALITY_WEIGHTS.get(key)
        if weight:
            return weight, "filmon"

        return Plugin.stream_weight(key)

    def _get_rtmp_app(self, rtmp):
        parsed = urlparse(rtmp)
        if not parsed.scheme.startswith("rtmp"):
            return

        if parsed.query:
            app = "{0}?{1}".format(parsed.path[1:], parsed.query)
        else:
            app = parsed.path[1:]

        return app

    def _get_streams(self):
        if not RTMPStream.is_usable(self.session):
            raise PluginError("rtmpdump is not usable and required by Filmon plugin")

        self.logger.debug("Fetching stream info")
        res = http.get(self.url)

        match = re.search("movie_id=(\d+)", res.text)
        if match:
            return self._get_vod_stream(match.group(1))

        match = re.search("/channels/(\d+)/extra_big_logo.png", res.text)
        if not match:
            return

        channel_id = match.group(1)
        streams = {}
        for quality in ("low", "high"):
            try:
                streams[quality] = self._get_stream(channel_id, quality)
            except NoStreamsError:
                pass

        return streams

    def _get_stream(self, channel_id, quality):
        params = dict(channel_id=channel_id, quality=quality)
        res = http.post(CHINFO_URL, data=params, headers=AJAX_HEADERS)
        json = http.json(res)

        if not json:
            raise NoStreamsError(self.url)

        rtmp = json.get("serverURL")
        playpath = json.get("streamName")
        if not (rtmp and playpath):
            raise NoStreamsError(self.url)

        app = self._get_rtmp_app(rtmp)
        if not app:
            raise NoStreamsError(self.url)

        return RTMPStream(self.session, {
            "rtmp": rtmp,
            "pageUrl": self.url,
            "swfUrl": SWF_URL,
            "playpath": playpath,
            "app": app,
            "live": True
        })

    def _get_vod_stream(self, movie_id):
        res = http.get(VODINFO_URL.format(movie_id), headers=AJAX_HEADERS)
        json = http.json(res)
        json = json and json.get("data")
        json = json and json.get("streams")

        if not json:
            raise NoStreamsError(self.url)

        streams = {}
        for quality in ("low", "high"):
            stream = json.get(quality)
            if not stream:
                continue

            rtmp = stream.get("url")
            app = self._get_rtmp_app(rtmp)
            if not app:
                continue

            playpath = stream.get("name")
            if ".mp4" in playpath:
                playpath = "mp4:" + playpath

            streams[quality] = RTMPStream(self.session, {
                "rtmp": rtmp,
                "pageUrl": self.url,
                "swfUrl": SWF_URL,
                "playpath": playpath,
                "app": app,
            })

        return streams


__plugin__ = Filmon

########NEW FILE########
__FILENAME__ = filmon_us
import re

from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HTTPStream
from livestreamer.utils import prepend_www

RTMP_URL = "rtmp://204.107.26.73/battlecam"
RTMP_UPLOAD_URL = "rtmp://204.107.26.75/streamer"
SWF_URL = "http://www.filmon.us/application/themes/base/flash/broadcast/VideoChatECCDN_debug_withoutCenteredOwner.swf"
SWF_UPLOAD_URL = "http://www.battlecam.com/application/themes/base/flash/MediaPlayer.swf"


class Filmon_us(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return "filmon.us" in url

    def _get_streams(self):
        if not RTMPStream.is_usable(self.session):
            raise PluginError("rtmpdump is not usable and required by Filmon_us plugin")

        streams = {}

        try:
            # history video
            if "filmon.us/history" in self.url or "filmon.us/video/history/hid" in self.url:
                streams['default'] = self._get_history()
            # uploaded video
            elif "filmon.us/video" in self.url:
                streams['default'] = self._get_stream_upload()
            # live video
            else:
                streams['default'] = self._get_stream_live()
        except NoStreamsError:
            pass

        return streams

    def _get_history(self):
        video_id = self.url.rstrip("/").rpartition("/")[2]

        self.logger.debug("Testing if video exist")
        history_url = 'http://www.filmon.us/video/history/hid/' + video_id
        if http.url_resolve(prepend_www(history_url)) == "http://www.filmon.us/channels":
            raise PluginError("history number " + video_id + " don't exist")

        self.logger.debug("Fetching video URL")
        res = http.get(history_url)
        match = re.search("http://cloud.battlecam.com/([/\w]+).flv", res.text)
        if not match:
            return
        url = match.group(0)

        return HTTPStream(self.session, url)

    def _get_stream_upload(self):
        video = urlparse(self.url).path

        if http.resolve_url(prepend_www(self.url)) == 'http://www.filmon.us/channels':
            raise PluginError(video + " don't exist")

        playpath = "mp4:resources" + video + '/v_3.mp4'

        rtmp = RTMP_UPLOAD_URL
        parsed = urlparse(rtmp)
        app = parsed.path[1:]

        return RTMPStream(self.session, {
            "rtmp": rtmp,
            "pageUrl": self.url,
            "swfUrl": SWF_UPLOAD_URL,
            "playpath": playpath,
            "app": app,
            "live": True
        })

    def _get_stream_live(self):
        self.logger.debug("Fetching room_id")
        res = http.get(self.url)
        match = re.search("room/id/(\d+)", res.text)
        if not match:
            return
        room_id = match.group(1)

        self.logger.debug("Comparing channel name with URL")
        match = re.search("<meta property=\"og:url\" content=\"http://www.filmon.us/(\w+)", res.text)
        if not match:
            return
        channel_name = match.group(1)
        base_name = self.url.rstrip("/").rpartition("/")[2]

        if (channel_name != base_name):
            return

        playpath = "mp4:bc_" + room_id
        if not playpath:
            raise NoStreamsError(self.url)

        rtmp = RTMP_URL
        parsed = urlparse(rtmp)
        app = parsed.path[1:]

        return RTMPStream(self.session, {
            "rtmp": RTMP_URL,
            "pageUrl": self.url,
            "swfUrl": SWF_URL,
            "playpath": playpath,
            "app": app,
            "live": True
        })

__plugin__ = Filmon_us

########NEW FILE########
__FILENAME__ = freedocast
from livestreamer.exceptions import NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream

import re

class Freedocast(Plugin):
    SWFURL = "http://cdn.freedocast.com/player-octo/yume/v5/infinite-hd-player-FREEDOCAST.SWF"
    PlayerURL = "http://www.freedocast.com/forms/watchstream.aspx?sc={0}"

    @classmethod
    def can_handle_url(self, url):
        return "freedocast.com" in url

    def _get_streams(self):
        self.logger.debug("Fetching stream info")
        res = http.get(self.url)

        match = re.search("\"User_channelid\".+?value=\"(.+?)\"", res.text)
        if not match:
            raise NoStreamsError(self.url)

        headers = {
            "Referer": self.url
        }

        res = http.get(self.PlayerURL.format(match.group(1)), headers=headers)

        match = re.search("stream:\s+'(rtmp://.+?)'", res.text)
        if not match:
            raise NoStreamsError(self.url)

        rtmp = match.group(1)
        streams = {}
        streams["live"] = RTMPStream(self.session, {
            "rtmp": rtmp,
            "pageUrl": self.url,
            "swfVfy": self.SWFURL,
            "live": True
        })

        return streams


__plugin__ = Freedocast

########NEW FILE########
__FILENAME__ = furstream
import re

from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream


class Furstream(Plugin):
    @classmethod
    def can_handle_url(cls, url):
        return re.match("^http(s)?://(\w+\.)?furstre\.am/stream.+", url)

    def _get_streams(self):
        if not RTMPStream.is_usable(self.session):
            raise PluginError("rtmpdump is not usable and required by Furstream plugin")

        self.logger.debug("Fetching stream info")
        res = http.get(self.url)

        match = re.search("rtmp://(?:(?!\").)*", res.text)
        if match:
            self.logger.debug("Stream URL: " + match.group(0))
            rtmp = match.group(0)
        else:
            return

        streams = {}
        streams["live"] = RTMPStream(self.session, {
            "rtmp": rtmp,
            "pageUrl": self.url,
            "live": True
        })

        return streams

__plugin__ = Furstream

########NEW FILE########
__FILENAME__ = gomexp
"""Plugin for GOMeXP live streams.

This plugin is using the same API as the mobile app.
"""

from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HLSStream
from livestreamer.utils import parse_xml

import re

API_BASE = "http://gox.gomexp.com/cgi-bin"
API_URL_APP = API_BASE + "/app_api.cgi"
API_URL_LIVE = API_BASE + "/gox_live.cgi"


class GOMeXP(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return re.match(r"http(s)?://(www\.)?gomexp.com", url)

    def _get_live_cubeid(self):
        res = http.get(API_URL_APP, params=dict(mode="get_live"))
        root = parse_xml(res.text.encode("utf8"))
        return root.findtext("./cube/cubeid")

    def _get_streams(self):
        cubeid = self._get_live_cubeid()
        if not cubeid:
            return

        res = http.get(API_URL_LIVE, params=dict(cubeid=cubeid))
        root = parse_xml(res.text.encode("utf8"))
        streams = {}

        for entry in root.findall("./ENTRY/*/[@reftype='live'][@href]"):
            url = entry.get("href")

            try:
                hls_streams = HLSStream.parse_variant_playlist(self.session,
                                                               url)
                streams.update(hls_streams)
            except IOError as err:
                self.logger.error("Failed to open playlist: {0}", err)

        return streams

__plugin__ = GOMeXP

########NEW FILE########
__FILENAME__ = hashd
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream

import math

class Hashd(Plugin):
    SWFURL = "http://cdn.hashd.tv/player/player.swf"
    GEOIPURL = "http://freegeoip.net/json/"
    GEOURL = "http://maps.googleapis.com/maps/api/geocode/json?address="

    @classmethod
    def can_handle_url(self, url):
        return "hashd.tv" in url

    def _distance(self, origin, destination):
        lat1, lon1 = origin
        lat2, lon2 = destination
        radius = 6371 # km

        dlat = math.radians(lat2-lat1)
        dlon = math.radians(lon2-lon1)
        a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \
            * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        d = radius * c

        return d

    def _choose_server(self, json):
        res = http.get(self.GEOIPURL)
        loc = http.json(res)
        loc = [loc["latitude"], loc["longitude"]]
        sel_dist = float("inf")
        i = 0
        primary = -1
        secondary = -1

        for server in json["server"]:
            res = http.get(self.GEOURL+server["server"]["name"]+"&sensor=false")
            cord = http.json(res)
            cord = [cord["results"][0]["geometry"]["location"]["lat"], cord["results"][0]["geometry"]["location"]["lng"]]
            cur_dist = self._distance(loc, cord)

            if cur_dist < sel_dist:
                sel_dist = cur_dist

                if server["server"]["used"] < 90:
                    # nearest server with load < 90%
                    primary = i
                else:
                    # nearest server with load > 90%
                    secondary = i

            i += 1

        if primary == -1:
            # if all servers have load over 90% use nearest one
            return secondary

        return primary

    def _parse_vod(self, json):
        streams = {}

        if json["stream_protocol"] != "rtmp":
            # Just in case. I coudn't find any non-rtmp streams.
            raise NoStreamsError(self.url)

        streams["vod"] = RTMPStream(self.session, {
            "rtmp": json["stream_url"]+"/"+json["file"],
            "pageUrl": self.url,
            "swfUrl": self.SWFURL,
            "live": True
        })

        return streams

    def _parse_live(self, json):
        streams = {}
        app = json["ingest"]["name"]
        playpath = json["name_seo"]
        i = 0
        id = self._choose_server(json)

        for server in json["server"]:
            name = server["server"]["name"]
            height = str(json["current_video_height"])+"p"

            if id != i:
                height+="_alt_"+name

            streams[height] = RTMPStream(self.session, {
                "rtmp": "rtmp://"+server["server"]["hostname"],
                "app": app,
                "playpath": playpath,
                "pageUrl": self.url,
                "swfUrl": self.SWFURL,
                "live": True
            })
            i += 1


        return streams

    def _get_streams(self):
        if not RTMPStream.is_usable(self.session):
            raise PluginError("rtmpdump is not usable and required by Hashd plugin")

        self.logger.debug("Fetching stream info")
        res = http.get(self.url.rstrip("/").lower()+".json?first=true")
        json = http.json(res)

        if not isinstance(json, dict):
            raise PluginError("Invalid JSON response")
        elif not ("live" in json or "file" in json):
            raise PluginError("Invalid JSON response")

        if "file" in json:
            streams = self._parse_vod(json)
        elif json["live"]:
            streams = self._parse_live(json)
        else:
            raise NoStreamsError(self.url)

        return streams


__plugin__ = Hashd

########NEW FILE########
__FILENAME__ = hitbox
import re

from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HTTPStream
from livestreamer.utils import verifyjson

LIVE_API = "http://www.hitbox.tv/api/media/live/{0}?showHidden=true"
PLAYER_API = "http://www.hitbox.tv/api/player/config/{0}/{1}?embed=false&showHidden=true"
SWF_BASE = "http://edge.vie.hitbox.tv/static/player/flowplayer/"
SWF_URL = SWF_BASE + "flowplayer.commercial-3.2.16.swf"


class Hitbox(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return "hitbox.tv" in url

    def _get_quality(self, label):
        match = re.search(r".*?(\d+p)", label)
        if match:
            return match.group(1)
        return "live"

    def _get_streams(self):
        self.logger.debug("Fetching stream info")
        media_is_live = 0

        match = re.search(r".*hitbox.tv/([^/]*)/?(\d+)?", self.url)
        if not match:
            return

        stream_name, media_id = match.groups()
        if stream_name != "video":
            res = http.get(LIVE_API.format(stream_name))
            json = http.json(res)
            livestream = verifyjson(json, "livestream")
            media_id = verifyjson(livestream[0], "media_id")
            media_is_live = int(verifyjson(livestream[0], "media_is_live"))
            if not media_is_live:
                return

        media_type = "live" if media_is_live else "video"
        res = http.get(PLAYER_API.format(media_type, media_id))
        json = http.json(res)
        clip = verifyjson(json, "clip")
        live = verifyjson(clip, "live")
        plugins = verifyjson(json, "plugins")

        streams = {}
        if live:
            playlists = verifyjson(json, "playlist") or []
            swf_url = SWF_URL
            for playlist in playlists:
                bitrates = playlist.get("bitrates")
                provider = playlist.get("connectionProvider")
                rtmp = None

                if bitrates:
                    rtmp = playlist.get("netConnectionUrl")
                elif provider and provider in plugins:
                    provider = plugins[provider]
                    swf_name = verifyjson(provider, "url")
                    swf_url = SWF_BASE + swf_name
                    rtmp = verifyjson(provider, "netConnectionUrl")
                    bitrates = clip.get("bitrates", [])
                else:
                    continue

                for bitrate in bitrates:
                    quality = self._get_quality(verifyjson(bitrate, "label"))
                    url = verifyjson(bitrate, "url")
                    stream = RTMPStream(self.session, {
                        "rtmp": rtmp,
                        "pageUrl": self.url,
                        "playpath": url,
                        "swfVfy": swf_url,
                        "live": True
                    })
                    if quality in streams:
                        quality += "_alt"

                    streams[quality] = stream
        else:
            bitrates = verifyjson(clip, "bitrates")
            for bitrate in bitrates:
                base_url = verifyjson(clip, "baseUrl")
                url = verifyjson(bitrate, "url")
                quality = self._get_quality(verifyjson(bitrate, "label"))
                streams[quality] = HTTPStream(self.session,
                                              base_url + "/" + url)

        return streams

__plugin__ = Hitbox

########NEW FILE########
__FILENAME__ = ilive
from livestreamer.compat import urlparse
from livestreamer.stream import HLSStream, RTMPStream
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.exceptions import NoStreamsError

import re

MOBILE_URL = "http://www.ilive.to/m/channel.php"


class ILive(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return "ilive.to" in url

    def _get_streams(self):
        streams = {}
        try:
            streams = self._get_desktop_streams()
        except NoStreamsError:
            pass
        try:
            hlsstreams = self._get_mobile_streams()
            if hlsstreams:
                streams.update(hlsstreams)
        except IOError as err:
            self.logger.warning("Failed to get variant playlist: {0}", err)

        return streams

    def _get_mobile_streams(self):
        match = re.search("view/(\d+)", self.url)
        if not match:
            return

        res = http.get(MOBILE_URL, params=dict(n=match.group(1)))

        match = re.search("[^\"]+playlist.m3u8[^\"]+", res.content)
        if not match:
            return

        ios_url = match.group(0)
        ios_url = ios_url.replace("\\", "")

        return HLSStream.parse_variant_playlist(self.session, ios_url)

    def _get_desktop_streams(self):
        self.logger.debug("Fetching stream info")
        res = http.get(self.url)

        match = re.search("flashplayer: \"(.+.swf)\".+streamer: \"(.+)\""
                          ".+file: \"(.+).flv\"", res.text, re.DOTALL)
        if not match:
            raise NoStreamsError(self.url)

        rtmpurl = match.group(2).replace("\\/", "/")
        parsed = urlparse(rtmpurl)

        if parsed.query:
            app = "{0}?{1}".format(parsed.path[1:], parsed.query)
        else:
            app = parsed.path[1:]

        params = {
            "rtmp": rtmpurl,
            "app": app,
            "pageUrl": self.url,
            "swfVfy": match.group(1),
            "playpath" : match.group(3),
            "live": True
        }

        match = re.search("(http(s)?://.+/server\d?.php\?id=\d+)",
                          res.text)
        if match:
            token_url = match.group(1)
            res = http.get(token_url, headers=dict(Referer=self.url))
            res = http.json(res)
            token = res.get("token")
            if token:
                params["token"] = token

        streams = {}
        streams["live"] = RTMPStream(self.session, params)

        return streams


__plugin__ = ILive

########NEW FILE########
__FILENAME__ = justintv
import re

from collections import defaultdict

from livestreamer.exceptions import PluginError

# Import base classes from a support plugin that must exist in the
# same directory as this plugin.
from livestreamer.plugin.api.support_plugin import justintv_common

JustinTVPluginBase = justintv_common.PluginBase
JustinTVAPIBase = justintv_common.APIBase


def convert_video_xml(dom):
    data = dict(play_offset=0, start_offset=0, end_offset=0,
                chunks=defaultdict(list), restrictions={})
    total_duration = 0

    for archive in dom.findall("archive"):
        duration = int(archive.findtext("length", 0))
        total_duration += duration

        # Add 'source' chunk
        chunk = dict(url=archive.findtext("video_file_url"),
                     length=duration)
        data["chunks"]["source"].append(chunk)

        # Find transcode chunks
        for transcode in archive.find("transcode_file_urls"):
            match = re.match("transcode_(\w+)", transcode.tag)
            if match:
                name = match.group(1)
                chunk = dict(url=transcode.text,
                             length=duration)
                data["chunks"][name].append(chunk)

    data["play_offset"] = dom.findtext("bracket_start") or 0
    data["start_offset"] = dom.findtext("bracket_start") or 0
    data["end_offset"] = dom.findtext("bracket_end") or total_duration

    restrictions = dom.findtext("archive_restrictions/restriction")
    if restrictions == "archives":
        data["restrictions"] = dict((n, "chansub") for n in data["chunks"])

    return data


class JustinTVAPI(JustinTVAPIBase):
    def __init__(self):
        JustinTVAPIBase.__init__(self, host="justin.tv")

    def video_broadcast(self, broadcast_id):
        res = self.call("/api/broadcast/by_archive/{0}".format(broadcast_id),
                        format="xml")
        return res

    def video_clip(self, clip_id):
        res = self.call("/api/broadcast/by_chapter/{0}".format(clip_id),
                        format="xml")
        return res


class JustinTV(JustinTVPluginBase):
    @classmethod
    def can_handle_url(self, url):
        return "justin.tv" in url

    def __init__(self, url):
        JustinTVPluginBase.__init__(self, url)

        self.api = JustinTVAPI()

    def _get_video_streams(self):
        try:
            if self.video_type == "b":
                res = self.api.video_broadcast(self.video_id)
            elif self.video_type == "c":
                res = self.api.video_clip(self.video_id)
            else:
                return
        except PluginError as err:
            if "404 Client Error" in str(err):
                return
            else:
                raise

        videos = convert_video_xml(res)

        return self._create_playlist_streams(videos)

__plugin__ = JustinTV

########NEW FILE########
__FILENAME__ = justintv_common
import re
import requests

from itertools import starmap
from random import random

try:
    from itertools import izip
except ImportError:
    izip = zip

from livestreamer.compat import urlparse, urljoin
from livestreamer.exceptions import NoStreamsError, PluginError, StreamError
from livestreamer.options import Options
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import (HTTPStream, HLSStream, FLVPlaylist,
                                 extract_flv_header_tags)
from livestreamer.utils import parse_json, parse_qsd, verifyjson

__all__ = ["PluginBase", "APIBase"]

QUALITY_WEIGHTS = {
    "source": 1080,
    "high": 720,
    "medium": 480,
    "low": 240,
    "mobile": 120,
}
USHER_SELECT_PATH = "/select/{0}.json"

_url_re = re.compile(r"""
    http(s)?://
    (?P<subdomain>[\w\.]+)?
    (?P<domain>twitch.tv|justin.tv)
    /
    (?P<channel>[^/]+)
    (?:
        /
        (?P<video_type>[bc])
        /
        (?P<video_id>\d+)
    )?
""", re.VERBOSE)


class UsherService(object):
    def __init__(self, host="justin.tv"):
        self.host = host

    def url(self, path, *args, **kwargs):
        path = path.format(*args, **kwargs)
        return urljoin("http://usher." + self.host, path)

    def select(self, channel, password=None, **extra_params):
        url = self.url(USHER_SELECT_PATH, channel)
        params = dict(p=int(random() * 999999), type="any",
                      allow_source="true", private_code=password or "null",
                      **extra_params)

        req = requests.Request("GET", url, params=params)
        # prepare_request is only available in requests 2.0+
        if hasattr(http, "prepare_request"):
            req = http.prepare_request(req)
        else:
            req = req.prepare()

        return req.url


class APIBase(object):
    def __init__(self, host="justin.tv", beta=False):
        self.beta = beta
        self.host = host
        self.oauth_token = None
        self.subdomain = beta and "betaapi" or "api"

    def add_cookies(self, cookies):
        http.parse_cookies(cookies, domain=self.host)

    def call(self, path, format="json", host=None, **extra_params):
        params = dict(as3="t", **extra_params)

        if self.oauth_token:
            params["oauth_token"] = self.oauth_token

        url = "https://{0}.{1}{2}.{3}".format(self.subdomain, host or self.host,
                                              path, format)
        # The certificate used by Twitch cannot be verified in some environments.
        res = http.get(url, params=params, verify=False)

        if format == "json":
            return http.json(res)
        elif format == "xml":
            return http.xml(res)
        else:
            return res

    def channel_access_token(self, channel):
        res = self.call("/api/channels/{0}/access_token".format(channel),
                        host="twitch.tv")

        return res.get("sig"), res.get("token")

    def token(self):
        res = self.call("/api/viewer/token", host="twitch.tv")

        return res.get("token")

    def viewer_info(self):
        return self.call("/api/viewer/info", host="twitch.tv")


class PluginBase(Plugin):
    options = Options({
        "cookie": None,
        "password": None,
    })

    @classmethod
    def stream_weight(cls, key):
        weight = QUALITY_WEIGHTS.get(key)
        if weight:
            return weight, "justintv"

        return Plugin.stream_weight(key)

    def __init__(self, url):
        Plugin.__init__(self, url)

        try:
            match = _url_re.match(url).groupdict()
            self.channel = match.get("channel").lower()
            self.subdomain = match.get("subdomain")
            self.video_type = match.get("video_type")
            self.video_id = match.get("video_id")
            self.usher = UsherService(match.get("domain"))

            parsed = urlparse(url)
            self.params = parse_qsd(parsed.query)
        except AttributeError:
            self.channel = None
            self.params = None
            self.subdomain = None
            self.video_id = None
            self.video_type = None
            self.usher = None

    def _create_playlist_streams(self, videos):
        start_offset = int(videos.get("start_offset", 0))
        stop_offset = int(videos.get("end_offset", 0))
        streams = {}

        for quality, chunks in videos.get("chunks").items():
            if not chunks:
                if videos.get("restrictions", {}).get(quality) == "chansub":
                    self.logger.warning("The quality '{0}' is not available "
                                        "since it requires a subscription.",
                                        quality)
                continue

            # Rename 'live' to 'source'
            if quality == "live":
                quality = "source"

            chunks_duration = sum(c.get("length") for c in chunks)

            # If it's a full broadcast we just use all the chunks
            if start_offset == 0 and chunks_duration == stop_offset:
                # No need to use the FLV concat if it's just one chunk
                if len(chunks) == 1:
                    url = chunks[0].get("url")
                    stream = HTTPStream(self.session, url)
                else:
                    chunks = [HTTPStream(self.session, c.get("url")) for c in chunks]
                    stream = FLVPlaylist(self.session, chunks,
                                         duration=chunks_duration)
            else:
                try:
                    stream = self._create_video_clip(chunks,
                                                     start_offset,
                                                     stop_offset)
                except StreamError as err:
                    self.logger.error("Error while creating video clip '{0}': {1}",
                                      quality, err)
                    continue

            streams[quality] = stream

        return streams

    def _create_video_clip(self, chunks, start_offset, stop_offset):
        playlist_duration = stop_offset - start_offset
        playlist_offset = 0
        playlist_streams = []
        playlist_tags = []

        for chunk in chunks:
            chunk_url = chunk.get("url")
            chunk_length = chunk.get("length")
            chunk_start = playlist_offset
            chunk_stop = chunk_start + chunk_length
            chunk_stream = HTTPStream(self.session, chunk_url)

            if start_offset >= chunk_start and start_offset <= chunk_stop:
                try:
                    headers = extract_flv_header_tags(chunk_stream)
                except IOError as err:
                    raise StreamError("Error while parsing FLV: {0}", err)

                if not headers.metadata:
                    raise StreamError("Missing metadata tag in the first chunk")

                metadata = headers.metadata.data.value
                keyframes = metadata.get("keyframes")

                if not keyframes:
                    raise StreamError("Missing keyframes info in the first chunk")

                keyframe_offset = None
                keyframe_offsets = keyframes.get("filepositions")
                keyframe_times = [playlist_offset + t for t in keyframes.get("times")]
                for time, offset in izip(keyframe_times, keyframe_offsets):
                    if time > start_offset:
                        break

                    keyframe_offset = offset

                if keyframe_offset is None:
                    raise StreamError("Unable to find a keyframe to seek to "
                                      "in the first chunk")

                chunk_headers = dict(Range="bytes={0}-".format(int(keyframe_offset)))
                chunk_stream = HTTPStream(self.session, chunk_url,
                                          headers=chunk_headers)
                playlist_streams.append(chunk_stream)
                for tag in headers:
                    playlist_tags.append(tag)
            elif chunk_start >= start_offset and chunk_start < stop_offset:
                playlist_streams.append(chunk_stream)

            playlist_offset += chunk_length

        return FLVPlaylist(self.session, playlist_streams,
                           tags=playlist_tags, duration=playlist_duration)

    def _get_streams(self):
        if not self.channel:
            return

        if self.video_id:
            return self._get_video_streams()
        else:
            return self._get_live_streams()

    def _authenticate(self):
        cookies = self.options.get("cookie")

        if cookies and not self.api.oauth_token:
            self.logger.info("Attempting to authenticate using cookies")

            self.api.add_cookies(cookies)
            self.api.oauth_token = self.api.token()

            viewer = self.api.viewer_info()
            login = viewer.get("login")

            if login:
                self.logger.info("Successfully logged in as {0}", login)
            else:
                self.logger.error("Failed to authenticate, your cookies "
                                  "may have expired")

    def _access_token(self):
        try:
            sig, token = self.api.channel_access_token(self.channel)
        except PluginError as err:
            if "404 Client Error" in str(err):
                raise NoStreamsError(self.url)
            else:
                raise

        return sig, token

    def _get_live_streams(self):
        self._authenticate()
        sig, token = self._access_token()
        url = self.usher.select(self.channel,
                                password=self.options.get("password"),
                                nauthsig=sig,
                                nauth=token)

        try:
            streams = HLSStream.parse_variant_playlist(self.session, url)
        except IOError as err:
            err = str(err)
            if "404 Client Error" in err or "Failed to parse playlist" in err:
                return
            else:
                raise PluginError(err)

        try:
            token = parse_json(token)
            chansub = verifyjson(token, "chansub")
            restricted_bitrates = verifyjson(chansub, "restricted_bitrates")

            for name in filter(lambda n: not re.match(r"(.+_)?archives|live", n),
                               restricted_bitrates):
                self.logger.warning("The quality '{0}' is not available "
                                    "since it requires a subscription.",
                                    name)
        except PluginError:
            pass

        return dict(starmap(self._check_stream_name, streams.items()))

    def _get_video_streams(self):
        pass

    def _check_stream_name(self, name, stream):
        if name.startswith("iphone"):
            name = name.replace("iphone", "")

        return name, stream


########NEW FILE########
__FILENAME__ = livestation
from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HLSStream
from livestreamer.options import Options

from time import time
import re


class Livestation(Plugin):
    SWFURL = "http://beta.cdn.livestation.com/player/5.10/livestation-player.swf"
    APIURL = "http://tokens.api.livestation.com/channels/{0}/tokens.json?{1}"
    LOGINPAGEURL = "http://www.livestation.com/en/users/new"
    LOGINPOSTURL = "http://www.livestation.com/en/sessions.json"

    options = Options({
        "email": "",
        "password": ""
    })

    @classmethod
    def can_handle_url(self, url):
        return "livestation.com" in url

    def _get_rtmp_streams(self, text):
        match = re.search("streamer=(rtmp://.+?)&", text)
        if not match:
            raise PluginError(("No RTMP streamer found on URL {0}").format(self.url))

        rtmp = match.group(1)

        match = re.search("<meta content=\"(http://.+?\.swf)\?", text)
        if not match:
            self.logger.warning("Failed to get player SWF URL location on URL {0}", self.url)
        else:
            self.SWFURL = match.group(1)
            self.logger.debug("Found player SWF URL location {0}", self.SWFURL)

        match = re.search("<meta content=\"(.+)\" name=\"item-id\" />", text)
        if not match:
            raise PluginError(("Missing channel item-id on URL {0}").format(self.url))

        res = http.get(self.APIURL.format(match.group(1), time()), params=dict(output="json"))
        json = http.json(res)

        if not isinstance(json, list):
            raise PluginError("Invalid JSON response")

        rtmplist = {}

        for jdata in json:
            if "stream_name" not in jdata or "type" not in jdata:
                continue

            if "rtmp" not in jdata["type"]:
                continue

            playpath = jdata["stream_name"]

            if "token" in jdata and jdata["token"]:
                playpath += jdata["token"]

            if len(json) == 1:
                stream_name = "live"
            else:
                stream_name = jdata["stream_name"]

            rtmplist[stream_name] = RTMPStream(self.session, {
                "rtmp": rtmp,
                "pageUrl": self.url,
                "swfVfy": self.SWFURL,
                "playpath": playpath,
                "live": True
            })

        return rtmplist

    def _get_hls_streams(self, text):
        match = re.search("\"(http://.+\.m3u8)\"", text)
        if not match:
            raise PluginError(("No HLS playlist found on URL {0}").format(self.url))

        playlisturl = match.group(1)
        self.logger.debug("Playlist URL is {0}", playlisturl)
        playlist = {}

        try:
            playlist = HLSStream.parse_variant_playlist(self.session, playlisturl)
        except IOError as err:
            raise PluginError(err)

        return playlist

    def _get_streams(self):
        # If email option given, try to login
        if self.options.get("email"):
            res = http.get(self.LOGINPAGEURL)
            match = re.search('<meta content="([^"]+)" name="csrf-token"', res.text)
            if not match:
                raise PluginError("Missing CSRF Token: " + self.LOGINPAGEURL)
            csrf_token = match.group(1)
            
            email = self.options.get("email")
            password = self.options.get("password")
            
            res = http.post(
                self.LOGINPOSTURL,
                data = {
                    'authenticity_token': csrf_token,
                    'channel_id': '',
                    'commit': 'Login',
                    'plan_id': '',
                    'session[email]': email,
                    'session[password]': password,
                    'utf8': "\xE2\x9C\x93", # Check Mark Character
                }
            )
            
            self.logger.debug("Login account info: {0}", res.text)
            result = http.json(res)
            if result.get('email', 'no-mail') != email:
                raise PluginError("Invalid account")

        res = http.get(self.url)

        streams = {}

        if RTMPStream.is_usable(self.session):
            try:
                rtmpstreams = self._get_rtmp_streams(res.text)
                streams.update(rtmpstreams)
            except PluginError as err:
                self.logger.error("Error when fetching RTMP stream info: {0}", str(err))
        else:
            self.logger.warning("rtmpdump is not usable, only HLS streams will be available")

        try:
            hlsstreams = self._get_hls_streams(res.text)
            streams.update(hlsstreams)
        except PluginError as err:
            self.logger.error("Error when fetching HLS stream info: {0}", str(err))

        return streams


__plugin__ = Livestation


########NEW FILE########
__FILENAME__ = livestream
import re

from collections import defaultdict

from livestreamer.compat import urljoin
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import AkamaiHDStream, HLSStream
from livestreamer.utils import verifyjson, parse_json


class Livestream(Plugin):
    @classmethod
    def default_stream_types(cls, streams):
        return ["akamaihd", "hls"]

    @classmethod
    def can_handle_url(self, url):
        return "new.livestream.com" in url

    def _get_stream_info(self):
        res = http.get(self.url)
        match = re.search("window.config = ({.+})", res.text)
        if match:
            config = match.group(1)
            return parse_json(config, "config JSON")

    def _parse_smil(self, url, swfurl):
        res = http.get(url)
        smil = http.xml(res, "SMIL config")

        streams = {}
        httpbase = smil.find("{http://www.w3.org/2001/SMIL20/Language}head/"
                             "{http://www.w3.org/2001/SMIL20/Language}meta[@name='httpBase']")

        if not (httpbase is not None and httpbase.attrib.get("content")):
            raise PluginError("Missing HTTP base in SMIL")

        httpbase = httpbase.attrib.get("content")

        videos = smil.findall("{http://www.w3.org/2001/SMIL20/Language}body/"
                              "{http://www.w3.org/2001/SMIL20/Language}switch/"
                              "{http://www.w3.org/2001/SMIL20/Language}video")

        for video in videos:
            url = urljoin(httpbase, video.attrib.get("src"))
            bitrate = int(video.attrib.get("system-bitrate"))
            streams[bitrate] = AkamaiHDStream(self.session, url,
                                              swf=swfurl)

        return streams

    def _get_streams(self):
        self.logger.debug("Fetching stream info")
        info = self._get_stream_info()

        if not info:
            raise NoStreamsError(self.url)

        event = verifyjson(info, "event")
        streaminfo = verifyjson(event, "stream_info")

        if not streaminfo or not streaminfo.get("is_live"):
            raise NoStreamsError(self.url)

        streams = defaultdict(list)
        play_url = streaminfo.get("play_url")
        if play_url:
            swfurl = info.get("viewerPlusSwfUrl") or info.get("hdPlayerSwfUrl")
            if not swfurl.startswith("http"):
                swfurl = "http://" + swfurl

            qualities = streaminfo.get("qualities", [])
            smil = self._parse_smil(streaminfo["play_url"], swfurl)
            for bitrate, stream in smil.items():
                name = "{0}k".format(bitrate/1000)
                for quality in qualities:
                    if quality["bitrate"] == bitrate:
                        name = "{0}p".format(quality["height"])

                streams[name].append(stream)

        m3u8_url = streaminfo.get("m3u8_url")
        if m3u8_url:
            hls_streams = HLSStream.parse_variant_playlist(self.session,
                                                           m3u8_url,
                                                           namekey="pixels")
            for name, stream in hls_streams.items():
                streams[name].append(stream)

        return streams

__plugin__ = Livestream

########NEW FILE########
__FILENAME__ = mips
from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream

import re


class Mips(Plugin):
    SWFURL = "http://mips.tv/content/scripts/eplayer.swf"
    PlayerURL = "http://mips.tv/embedplayer/{0}/1/500/400"
    BalancerURL = "http://www.mips.tv:1935/loadbalancer"

    @classmethod
    def can_handle_url(self, url):
        return "mips.tv" in url

    def _get_streams(self):
        channelname = urlparse(self.url).path.rstrip("/").rpartition("/")[-1].lower()

        self.logger.debug("Fetching stream info")

        headers = {
            "Referer": self.url
        }

        res = http.get(self.PlayerURL.format(channelname), headers=headers)
        match = re.search("'FlashVars', '(id=\d+)&s=(.+?)&", res.text)
        if not match:
            raise NoStreamsError(self.url)

        channelname = "{0}?{1}".format(match.group(2), match.group(1))
        res = http.get(self.BalancerURL, headers=headers)

        match = re.search("redirect=(.+)", res.text)
        if not match:
            raise PluginError("Error retrieving RTMP address from loadbalancer")

        rtmp = match.group(1)
        streams = {}
        streams["live"] = RTMPStream(self.session, {
            "rtmp": "rtmp://{0}/live/{1}".format(rtmp, channelname),
            "pageUrl": self.url,
            "swfVfy": self.SWFURL,
            "conn": "S:OK",
            "live": True
        })

        return streams


__plugin__ = Mips

########NEW FILE########
__FILENAME__ = mlgtv
import re

from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HDSStream, HLSStream
from livestreamer.utils import verifyjson


CONFIG_API_URL = "http://www.majorleaguegaming.com/player/config.json"
STREAM_API_URL = "http://streamapi.majorleaguegaming.com/service/streams/playback/{0}"
STREAM_ID_REGEX = r"<meta content='.+/([\w_-]+).+' property='og:video'>"
STREAM_TYPES = {
    "hls": HLSStream.parse_variant_playlist,
    "hds": HDSStream.parse_manifest
}
URL_REGEX = r"http(s)?://(\w+\.)?(majorleaguegaming\.com|mlg\.tv)"


def valid_stream(stream):
    if not isinstance(stream, dict):
        return

    return stream.get("url") and stream.get("format") in STREAM_TYPES


class MLGTV(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return re.match(URL_REGEX, url)

    def _find_channel_id(self, text):
        match = re.search(STREAM_ID_REGEX, text)
        if match:
            return match.group(1)

    def _get_stream_id(self, channel_id):
        res = http.get(CONFIG_API_URL, params=dict(id=channel_id))
        config = http.json(res)
        media = verifyjson(config, "media")

        if not (media and isinstance(media, list)):
            return

        media = media[0]
        if not isinstance(media, dict):
            return

        return media.get("channel")

    def _get_streams(self):
        res = http.get(self.url)
        channel_id = self._find_channel_id(res.text)
        if not channel_id:
            return

        stream_id = self._get_stream_id(channel_id)
        if not stream_id:
            return

        res = http.get(STREAM_API_URL.format(stream_id),
                       params=dict(format="all"))
        json = http.json(res)
        data = verifyjson(json, "data")
        items = verifyjson(data, "items")

        streams = {}
        for stream in filter(valid_stream, items):
            parser = STREAM_TYPES[stream["format"]]

            try:
                streams.update(parser(self.session, stream["url"]))
            except IOError as err:
                if not re.search(r"(404|400) Client Error", str(err)):
                    self.logger.error("Failed to extract {0} streams: {1}",
                                      stream["format"].upper(), err)

        return streams

__plugin__ = MLGTV

########NEW FILE########
__FILENAME__ = nrk
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HLSStream

import re

COOKIES = {
    'NRK_PLAYER_SETTINGS_TV': 'devicetype=desktop&preferred-player-odm=hlslink&preferred-player-live=hlslink'
}


class NRK(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return 'tv.nrk.no' in url

    def _get_streams(self):
        self.logger.debug('Extracting media URL')
        res = http.get(self.url, cookies=COOKIES)
        m = re.search(r'<div[^>]*?id="playerelement"[^>]+data-media="([^"]+)"',
                      res.text)
        if not m:
            return

        return HLSStream.parse_variant_playlist(self.session, m.group(1))

__plugin__ = NRK

########NEW FILE########
__FILENAME__ = oldlivestream
from livestreamer.compat import urlparse
from livestreamer.plugin import Plugin
from livestreamer.stream import HLSStream


class OldLivestream(Plugin):
    PlaylistURL = "http://x{0}x.api.channel.livestream.com/3.0/playlist.m3u8"

    @classmethod
    def can_handle_url(self, url):
        return "livestream.com" in url and not "new.livestream.com" in url

    def _get_streams(self):
        channelname = urlparse(self.url).path.rstrip("/").rpartition("/")[-1].lower()
        channelname = channelname.replace("_", "-")

        try:
            streams = HLSStream.parse_variant_playlist(self.session,
                                                       self.PlaylistURL.format(channelname))
        except IOError:
            return

        return streams


__plugin__ = OldLivestream

########NEW FILE########
__FILENAME__ = ongamenet
from livestreamer.exceptions import NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream

import re


class Ongamenet(Plugin):
    StreamURL = "http://dostream.lab.so/stream.php"
    SWFURL = "http://www.ongamenet.com/front/ongame/live/CJPlayer.swf"
    PageURL = "http://www.ongamenet.com"

    @classmethod
    def can_handle_url(self, url):
        return "ongamenet.com" in url

    def _get_streams(self):
        res = http.get(self.StreamURL, data={"from": "ongamenet"})

        match = re.search("var stream = \"(.+?)\";", res.text)
        if not match:
            raise NoStreamsError(self.url)

        stream = match.group(1)

        match = re.search("var server = \"(.+?)\";", res.text)
        if not match:
            raise NoStreamsError(self.url)

        server = match.group(1)

        streams = {}
        streams["live"] = RTMPStream(self.session, {
            "rtmp": server,
            "playpath": stream,
            "swfUrl": self.SWFURL,
            "pageUrl": self.PageURL,
            "live": True,
        })

        return streams

__plugin__ = Ongamenet

########NEW FILE########
__FILENAME__ = picarto
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.stream import RTMPStream
from livestreamer.compat import urlparse
from livestreamer.utils import parse_qsd

class Picarto(Plugin):

    @classmethod
    def can_handle_url(self, url):
        return "picarto.tv" in url

    def _get_streams(self):
        params = parse_qsd(urlparse(self.url).query)
        if not 'watch' in params:
            raise NoStreamsError(self.url)
        channel = params['watch']
        
        if not RTMPStream.is_usable(self.session):
            raise PluginError("rtmpdump is not usable but required by Picarto plugin")
        
        streams = {}
        streams["live"] = RTMPStream(self.session, {
            "rtmp": "rtmp://199.189.86.17/dsapp/{0}.flv".format(channel),
            "pageUrl": self.url,
            "live": True
        })
        return streams
        
__plugin__ = Picarto
########NEW FILE########
__FILENAME__ = speedrunslive
from livestreamer.plugin import Plugin

import re

URL_REGEX = r"http://(?:www\.)?speedrunslive.com/#!/(?P<user>\w+)"
TWITCH_URL = "http://www.twitch.tv/"

class SpeedRunsLive(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return re.search(URL_REGEX, url)

    def _get_streams(self):
        match = re.search(URL_REGEX, self.url)
        if match:
            url = TWITCH_URL + match.group("user")
            plugin = self.session.resolve_url(url)
            return plugin.get_streams()


__plugin__ = SpeedRunsLive

########NEW FILE########
__FILENAME__ = stream
from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.stream import (AkamaiHDStream, HDSStream, HLSStream,
                                 HTTPStream, RTMPStream)

import ast
import re

PROTOCOL_MAP = {
    "akamaihd": AkamaiHDStream,
    "hds": HDSStream.parse_manifest,
    "hls": HLSStream,
    "hlsvariant": HLSStream.parse_variant_playlist,
    "httpstream": HTTPStream,
    "rtmp": RTMPStream,
    "rtmpe": RTMPStream,
    "rtmps": RTMPStream,
    "rtmpt": RTMPStream,
    "rtmpte": RTMPStream
}
PARAMS_REGEX = r"(\w+)=({.+?}|\[.+?\]|\(.+?\)|'(?:[^'\\]|\\')*'|\"(?:[^\"\\]|\\\")*\"|\S+)"

class StreamURL(Plugin):
    @classmethod
    def can_handle_url(self, url):
        parsed = urlparse(url)

        return parsed.scheme in PROTOCOL_MAP

    def _parse_params(self, params):
        rval = {}
        matches = re.findall(PARAMS_REGEX, params)

        for key, value in matches:
            try:
                value = ast.literal_eval(value)
            except Exception:
                pass

            rval[key] = value

        return rval

    def _get_streams(self):
        parsed = urlparse(self.url)
        cls = PROTOCOL_MAP.get(parsed.scheme)

        if not cls:
            return

        split = self.url.split(" ")
        url = split[0]
        urlnoproto = re.match("^\w+://(.+)", url).group(1)

        # Prepend http:// if needed.
        if cls != RTMPStream and not re.match("^http(s)?://", urlnoproto):
            urlnoproto = "http://{0}".format(urlnoproto)

        params = (" ").join(split[1:])
        params = self._parse_params(params)

        if cls == RTMPStream:
            params["rtmp"] = url

            for boolkey in ("live", "realtime", "quiet", "verbose", "debug"):
                if boolkey in params:
                    params[boolkey] = bool(params[boolkey])

            stream = cls(self.session, params)
        elif cls == HLSStream.parse_variant_playlist or cls == HDSStream.parse_manifest:
            try:
                streams = cls(self.session, urlnoproto, **params)
            except IOError as err:
                raise PluginError(err)

            return streams
        else:
            stream = cls(self.session, urlnoproto, **params)

        return dict(live=stream)


__plugin__ = StreamURL

########NEW FILE########
__FILENAME__ = streamingvideoprovider
from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HLSStream

from time import time
import re


class Streamingvideoprovider(Plugin):
    SWFURL = "http://play.streamingvideoprovider.com/player2.swf"
    APIURL = "http://player.webvideocore.net/index.php"

    @classmethod
    def can_handle_url(self, url):
        return "streamingvideoprovider.co.uk" in url

    def _get_hls_streams(self, channelname):
        options = dict(l="info", a="ajax_video_info", file=channelname,
                       rid=time())
        res = http.get(self.APIURL, params=options)

        match = re.search("'(http://.+\.m3u8)'", res.text)
        if not match:
            raise PluginError(("No HLS playlist found on URL {0}").format(self.url))

        playlisturl = match.group(1)
        self.logger.debug("Playlist URL is {0}", playlisturl)
        playlist = {}
        playlist["hls"] = HLSStream(self.session, playlisturl)

        return playlist

    def _get_rtmp_streams(self, channelname):
        options = dict(l="info", a="xmlClipPath", clip_id=channelname,
                       rid=time())
        res = http.get(self.APIURL, params=options)
        clip = http.xml(res)
        rtmpurl = clip.findtext("./info/url")

        if rtmpurl is None:
            raise PluginError(("No RTMP Streams found on URL {0}").format(self.url))

        rtmplist = {}
        rtmplist["live"] = RTMPStream(self.session, {
            "rtmp": rtmpurl,
            "swfVfy": self.SWFURL,
            "live": True
        })

        return rtmplist

    def _get_streams(self):
        channelname = urlparse(self.url).path.rstrip("/").rpartition("/")[-1].lower()
        streams = {}

        if RTMPStream.is_usable(self.session):
            try:
                rtmpstreams = self._get_rtmp_streams(channelname)
                streams.update(rtmpstreams)
            except PluginError as err:
                self.logger.error("Error when fetching RTMP stream info: {0}", str(err))
        else:
            self.logger.warning("rtmpdump is not usable, only HLS streams will be available")

        try:
            hlsstreams = self._get_hls_streams(channelname)
            streams.update(hlsstreams)
        except PluginError as err:
            self.logger.error("Error when fetching HLS stream info: {0}", str(err))

        return streams


__plugin__ = Streamingvideoprovider

########NEW FILE########
__FILENAME__ = svtplay
import re

from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HLSStream, HDSStream
from livestreamer.utils import verifyjson

SWF_URL = "http://www.svtplay.se/public/swf/video/svtplayer-2012.15.swf"
PAGE_URL = "http://www.svtplay.se"


class SVTPlay(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return re.match("http(s)?://(www\.)?(svtplay|svtflow|oppetarkiv).se/", url)

    def _get_streams(self):
        self.logger.debug("Fetching stream info")
        res = http.get(self.url, params=dict(output="json"))
        json = http.json(res)

        if not isinstance(json, dict):
            raise PluginError("Invalid JSON response")

        streams = {}
        video = verifyjson(json, "video")
        videos = verifyjson(video, "videoReferences")

        for video in videos:
            if not ("url" in video and "playerType" in video):
                continue

            url = video["url"]

            if video["playerType"] == "flash":
                if url.startswith("rtmp"):
                    stream = RTMPStream(self.session, {
                        "rtmp": url,
                        "pageUrl": PAGE_URL,
                        "swfVfy": SWF_URL,
                        "live": True
                    })
                    streams[str(video["bitrate"]) + "k"] = stream
                elif "manifest.f4m" in url:
                    try:
                        hdsstreams = HDSStream.parse_manifest(self.session, url)
                        streams.update(hdsstreams)
                    except IOError as err:
                        self.logger.warning("Failed to get HDS manifest: {0}", err)

            elif video["playerType"] == "ios":
                try:
                    hlsstreams = HLSStream.parse_variant_playlist(self.session, url)
                    streams.update(hlsstreams)
                except IOError as err:
                    self.logger.warning("Failed to get variant playlist: {0}", err)

        return streams

__plugin__ = SVTPlay

########NEW FILE########
__FILENAME__ = twitch
import re

from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.options import Options

# Import base classes from a support plugin that must exist in the
# same directory as this plugin.
from livestreamer.plugin.api.support_plugin import justintv_common

JustinTVPluginBase = justintv_common.PluginBase
JustinTVAPIBase = justintv_common.APIBase


def time_to_offset(t):
    match = re.match(r"((?P<hours>\d+)h)?((?P<minutes>\d+)m)?((?P<seconds>\d+)s)?", t)
    if match:
        offset = int(match.group("hours") or "0") * 60 * 60
        offset += int(match.group("minutes") or "0") * 60
        offset += int(match.group("seconds") or "0")
    else:
        offset = 0

    return offset


class TwitchAPI(JustinTVAPIBase):
    def channel_info(self, channel):
        return self.call("/api/channels/{0}".format(channel))

    def channel_subscription(self, channel):
        return self.call("/api/channels/{0}/subscription".format(channel))

    def channel_viewer_info(self, channel):
        return self.call("/api/channels/{0}/viewer".format(channel))

    def user(self):
        return self.call("/kraken/user")

    def videos(self, video_id):
        return self.call("/api/videos/{0}".format(video_id))


class Twitch(JustinTVPluginBase):
    options = Options({
        "cookie": None,
        "oauth_token": None,
        "password": None
    })

    @classmethod
    def can_handle_url(self, url):
        return "twitch.tv" in url

    def __init__(self, url):
        JustinTVPluginBase.__init__(self, url)

        self.api = TwitchAPI(host="twitch.tv",
                             beta=self.subdomain == "beta")

    def _authenticate(self):
        oauth_token = self.options.get("oauth_token")

        if oauth_token and not self.api.oauth_token:
            self.logger.info("Attempting to authenticate using OAuth token")
            self.api.oauth_token = oauth_token
            user = self.api.user().get("display_name")

            if user:
                self.logger.info("Successfully logged in as {0}", user)
            else:
                self.logger.error("Failed to authenticate, the access token "
                                  "is not valid")
        else:
            return JustinTVPluginBase._authenticate(self)

    def _get_video_streams(self):
        self._authenticate()

        if self.video_type == "b":
            self.video_type = "a"

        try:
            videos = self.api.videos(self.video_type + self.video_id)
        except PluginError as err:
            if "HTTP/1.1 0 ERROR" in str(err):
                raise NoStreamsError(self.url)
            else:
                raise

        # Parse the "t" query parameter on broadcasts and adjust
        # start offset if needed.
        time_offset = self.params.get("t")
        if time_offset:
            videos["start_offset"] += time_to_offset(self.params.get("t"))

        return self._create_playlist_streams(videos)


__plugin__ = Twitch

########NEW FILE########
__FILENAME__ = ustreamtv
import re

from collections import defaultdict, namedtuple
from functools import partial
from io import BytesIO
from random import randint
from time import sleep

from livestreamer.compat import urlparse, urljoin, range
from livestreamer.exceptions import StreamError, PluginError, NoStreamsError
from livestreamer.options import Options
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HLSStream, HTTPStream, Stream
from livestreamer.stream.flvconcat import FLVTagConcat
from livestreamer.stream.segmented import (SegmentedStreamReader,
                                           SegmentedStreamWriter,
                                           SegmentedStreamWorker)
from livestreamer.packages.flashmedia import AMFPacket, AMFError

try:
    import librtmp
    HAS_LIBRTMP = True
except ImportError:
    HAS_LIBRTMP = False


CDN_KEYS = ["cdnStreamUrl", "cdnStreamName"]
PROVIDER_KEYS = ["streams", "name", "url"]

AMF_URL = "http://cgw.ustream.tv/Viewer/getStream/1/{0}.amf"
HLS_PLAYLIST_URL = "http://iphone-streaming.ustream.tv/uhls/{0}/streams/live/iphone/playlist.m3u8"
RECORDED_URL = "http://tcdn.ustream.tv/video/{0}"
RECORDED_URL_PATTERN = r"^(http(s)?://)?(www\.)?ustream.tv/recorded/(?P<video_id>\d+)"
RTMP_URL = "rtmp://r{0}.1.{1}.channel.live.ums.ustream.tv:80/ustream"
SWF_URL = "http://static-cdn1.ustream.tv/swf/live/viewer.rsl:505.swf"


Chunk = namedtuple("Chunk", "num url offset")


def valid_cdn(item):
    name, cdn = item
    return all(cdn.get(key) for key in CDN_KEYS)


def valid_provider(info):
    return isinstance(info, dict) and all(info.get(key) for key in PROVIDER_KEYS)


def validate_module_info(result):
    if (result and isinstance(result, list) and result[0].get("stream")):
        return result[0]


def create_ums_connection(app, media_id, page_url, password,
                          exception=PluginError):
    url = RTMP_URL.format(randint(0, 0xffffff), media_id)
    params = dict(application=app, media=str(media_id), password=password)
    conn = librtmp.RTMP(url, connect_data=params,
                        swfurl=SWF_URL, pageurl=page_url)

    try:
        conn.connect()
    except librtmp.RTMPError:
        raise exception("Failed to connect to RTMP server")

    return conn


class UHSStreamWriter(SegmentedStreamWriter):
    def __init__(self, *args, **kwargs):
        SegmentedStreamWriter.__init__(self, *args, **kwargs)

        self.concater = FLVTagConcat(flatten_timestamps=True,
                                     sync_headers=True)

    def open_chunk(self, chunk, retries=3):
        if not retries or self.closed:
            return

        try:
            params = {}
            if chunk.offset:
                params["start"] = chunk.offset

            return http.get(chunk.url,  params=params, timeout=10,
                            exception=StreamError)
        except StreamError as err:
            self.logger.error("Failed to open chunk {0}: {1}", chunk.num, err)
            return self.open_chunk(chunk, retries - 1)

    def write(self, chunk, chunk_size=8192):
        res = self.open_chunk(chunk)
        if not res:
            return

        try:
            for data in self.concater.iter_chunks(buf=res.content,
                                                  skip_header=not chunk.offset):
                self.reader.buffer.write(data)

                if self.closed:
                    break
            else:
                self.logger.debug("Download of chunk {0} complete", chunk.num)
        except IOError as err:
            self.logger.error("Failed to read chunk {0}: {1}", chunk.num, err)


class UHSStreamWorker(SegmentedStreamWorker):
    def __init__(self, *args, **kwargs):
        SegmentedStreamWorker.__init__(self, *args, **kwargs)

        self.chunk_ranges = {}
        self.chunk_id = None
        self.chunk_id_max = None
        self.chunks = []
        self.filename_format = ""
        self.module_info_reload_time = 2
        self.process_module_info()

    def fetch_module_info(self):
        self.logger.debug("Fetching module info")
        conn = create_ums_connection("channel",
                                     self.stream.channel_id,
                                     self.stream.page_url,
                                     self.stream.password,
                                     exception=StreamError)

        try:
            result = conn.process_packets(invoked_method="moduleInfo",
                                          timeout=10)
        except (IOError, librtmp.RTMPError) as err:
            raise StreamError("Failed to get module info: {0}".format(err))
        finally:
            conn.close()

        return validate_module_info(result)

    def process_module_info(self):
        if self.closed:
            return

        result = self.fetch_module_info()
        if not result:
            return

        providers = result.get("stream")
        if providers == "offline":
            self.logger.debug("Stream went offline")
            self.close()
            return
        elif not isinstance(providers, list):
            return

        for provider in filter(valid_provider, providers):
            if provider.get("name") == self.stream.provider:
                break
        else:
            return

        try:
            stream = provider.get("streams")[self.stream.stream_index]
        except IndexError:
            self.logger.error("Stream index not in result")
            return

        filename_format = stream.get("streamName").replace("%", "%s")
        filename_format = urljoin(provider.get("url"), filename_format)

        self.filename_format = filename_format
        self.update_chunk_info(stream)

    def update_chunk_info(self, result):
        chunk_range = result.get("chunkRange")

        if not chunk_range:
            return

        chunk_id = int(result.get("chunkId"))
        chunk_offset = int(result.get("offset"))
        chunk_range = dict(map(partial(map, int), chunk_range.items()))

        self.chunk_ranges.update(chunk_range)
        self.chunk_id_min = sorted(chunk_range)[0]
        self.chunk_id_max = int(result.get("chunkId"))
        self.chunks = [Chunk(i, self.format_chunk_url(i),
                             not self.chunk_id and i == chunk_id and chunk_offset)
                       for i in range(self.chunk_id_min, self.chunk_id_max + 1)]

        if self.chunk_id is None and self.chunks:
            self.chunk_id = chunk_id

    def format_chunk_url(self, chunk_id):
        chunk_hash = ""
        for chunk_start in sorted(self.chunk_ranges):
            if chunk_id >= chunk_start:
                chunk_hash = self.chunk_ranges[chunk_start]

        return self.filename_format % (chunk_id, chunk_hash)

    def valid_chunk(self, chunk):
        return self.chunk_id and chunk.num >= self.chunk_id

    def iter_segments(self):
        while not self.closed:
            for chunk in filter(self.valid_chunk, self.chunks):
                self.logger.debug("Adding chunk {0} to queue", chunk.num)
                yield chunk

                # End of stream
                if self.closed:
                    return

                self.chunk_id = chunk.num + 1

            if self.wait(self.module_info_reload_time):
                try:
                    self.process_module_info()
                except StreamError as err:
                    self.logger.warning("Failed to process module info: {0}", err)


class UHSStreamReader(SegmentedStreamReader):
    __worker__ = UHSStreamWorker
    __writer__ = UHSStreamWriter

    def __init__(self, stream, *args, **kwargs):
        self.logger = stream.session.logger.new_module("stream.uhs")

        SegmentedStreamReader.__init__(self, stream, *args, **kwargs)


class UHSStream(Stream):
    __shortname__ = "uhs"

    def __init__(self, session, channel_id, page_url, provider,
                 stream_index, password=""):
        Stream.__init__(self, session)

        self.channel_id = channel_id
        self.page_url = page_url
        self.provider = provider
        self.stream_index = stream_index
        self.password = password

    def __repr__(self):
        return ("<UHSStream({0!r}, {1!r}, "
                "{2!r}, {3!r}, {4!r})>").format(self.channel_id,
                                                self.page_url,
                                                self.provider,
                                                self.stream_index,
                                                self.password)

    def __json__(self):
        return dict(channel_id=self.channel_id,
                    page_url=self.page_url,
                    provider=self.provider,
                    stream_index=self.stream_index,
                    password=self.password,
                    **Stream.__json__(self))

    def open(self):
        reader = UHSStreamReader(self)
        reader.open()

        return reader


class UStreamTV(Plugin):
    options = Options({
        "password": ""
    })

    @classmethod
    def can_handle_url(cls, url):
        return "ustream.tv" in url

    @classmethod
    def stream_weight(cls, stream):
        match = re.match("mobile_(\w+)", stream)
        if match:
            weight, group = Plugin.stream_weight(match.group(1))
            weight -= 1
            group = "mobile_ustream"
        elif stream == "recorded":
            weight, group = 720, "ustream"
        else:
            weight, group = Plugin.stream_weight(stream)

        return weight, group

    def _get_channel_id(self, url):
        match = re.search("ustream.tv/embed/(\d+)", url)
        if match:
            return int(match.group(1))

        match = re.search("\"cid\":(\d+)", http.get(url).text)
        if match:
            return int(match.group(1))

    def _get_hls_streams(self, wait_for_transcode=False):
        # HLS streams are created on demand, so we may have to wait
        # for a transcode to be started.
        attempts = wait_for_transcode and 10 or 1
        playlist_url = HLS_PLAYLIST_URL.format(self.channel_id)
        streams = {}
        while attempts and not streams:
            try:
                streams = HLSStream.parse_variant_playlist(self.session,
                                                           playlist_url,
                                                           nameprefix="mobile_")
            except IOError:
                # Channel is probably offline
                break

            attempts -= 1
            sleep(3)

        return streams

    def _create_rtmp_stream(self, cdn, stream_name):
        parsed = urlparse(cdn)
        options = dict(rtmp=cdn, app=parsed.path[1:],
                       playpath=stream_name, pageUrl=self.url,
                       swfUrl=SWF_URL, live=True)

        return RTMPStream(self.session, options)

    def _get_module_info(self, app, media_id, password=""):
        self.logger.debug("Waiting for moduleInfo invoke")
        conn = create_ums_connection(app, media_id, self.url, password)

        attempts = 3
        while conn.connected and attempts:
            try:
                result = conn.process_packets(invoked_method="moduleInfo",
                                              timeout=30)
            except (IOError, librtmp.RTMPError) as err:
                raise PluginError("Failed to get stream info: {0}".format(err))

            result = validate_module_info(result)
            if result:
                break
            else:
                attempts -= 1

        conn.close()

        return result

    def _get_streams_from_rtmp(self):
        password = self.options.get("password")
        module_info = self._get_module_info("channel", self.channel_id,
                                            password)
        if not module_info:
            raise NoStreamsError(self.url)

        providers = module_info.get("stream")
        if providers == "offline":
            raise NoStreamsError(self.url)
        elif not isinstance(providers, list):
            raise PluginError("Invalid stream info: {0}".format(providers))

        streams = {}
        for provider in filter(valid_provider, providers):
            provider_url = provider.get("url")
            provider_name = provider.get("name")
            provider_streams = provider.get("streams")

            for stream_index, stream_info in enumerate(provider_streams):
                stream = None
                stream_height = int(stream_info.get("height", 0))
                stream_name = stream_info.get("description")

                if not stream_name:
                    if stream_height:
                        if not stream_info.get("isTranscoded"):
                            stream_name = "{0}p+".format(stream_height)
                        else:
                            stream_name = "{0}p".format(stream_height)
                    else:
                        stream_name = "live"

                if stream_name in streams:
                    provider_name_clean = provider_name.replace("uhs_", "")
                    stream_name += "_alt_{0}".format(provider_name_clean)

                if provider_name.startswith("uhs_"):
                    stream = UHSStream(self.session, self.channel_id,
                                       self.url, provider_name,
                                       stream_index, password)
                elif (provider_url.startswith("rtmp") and
                      RTMPStream.is_usable(self.session)):
                        playpath = stream_info.get("streamName")
                        stream = self._create_rtmp_stream(provider_url,
                                                          playpath)

                if stream:
                    streams[stream_name] = stream

        return streams

    def _get_streams_from_amf(self):
        if not RTMPStream.is_usable(self.session):
            raise NoStreamsError(self.url)

        res = http.get(AMF_URL.format(self.channel_id))

        try:
            packet = AMFPacket.deserialize(BytesIO(res.content))
        except (IOError, AMFError) as err:
            raise PluginError("Failed to parse AMF packet: {0}".format(err))

        for message in packet.messages:
            if message.target_uri == "/1/onResult":
                result = message.value
                break
        else:
            raise PluginError("No result found in AMF packet")

        streams = {}
        stream_name = result.get("streamName")
        if stream_name:
            cdn = result.get("cdnUrl") or result.get("fmsUrl")
            if cdn:
                stream = self._create_rtmp_stream(cdn, stream_name)

                if "videoCodec" in result and result["videoCodec"]["height"] > 0:
                    stream_name = "{0}p".format(int(result["videoCodec"]["height"]))
                else:
                    stream_name = "live"

                streams[stream_name] = stream
            else:
                self.logger.warning("Missing cdnUrl and fmsUrl from result")

        stream_versions = result.get("streamVersions")
        if stream_versions:
            for version, info in stream_versions.items():
                stream_version_cdn = info.get("streamVersionCdn", {})

                for name, cdn in filter(valid_cdn, stream_version_cdn.items()):
                    stream = self._create_rtmp_stream(cdn["cdnStreamUrl"],
                                                      cdn["cdnStreamName"])
                    stream_name = "live_alt_{0}".format(name)
                    streams[stream_name] = stream

        return streams

    def _get_live_streams(self):
        self.channel_id = self._get_channel_id(self.url)

        if not self.channel_id:
            raise NoStreamsError(self.url)

        streams = defaultdict(list)

        if not RTMPStream.is_usable(self.session):
            self.logger.warning("rtmpdump is not usable. "
                                "Not all streams may be available.")

        if HAS_LIBRTMP:
            desktop_streams = self._get_streams_from_rtmp
        else:
            self.logger.warning("python-librtmp is not installed. "
                                "Not all streams may be available.")
            desktop_streams = self._get_streams_from_amf

        try:
            for name, stream in desktop_streams().items():
                streams[name].append(stream)
        except PluginError as err:
            self.logger.error("Unable to fetch desktop streams: {0}", err)
        except NoStreamsError:
            pass

        try:
            mobile_streams = self._get_hls_streams(wait_for_transcode=not streams)
            for name, stream in mobile_streams.items():
                streams[name].append(stream)
        except PluginError as err:
            self.logger.error("Unable to fetch mobile streams: {0}", err)
        except NoStreamsError:
            pass

        return streams

    def _get_recorded_streams(self, video_id):
        streams = {}

        if HAS_LIBRTMP:
            module_info = self._get_module_info("recorded", video_id)
            if not module_info:
                raise NoStreamsError(self.url)

            providers = module_info.get("stream")
            if not isinstance(providers, list):
                raise PluginError("Invalid stream info: {0}".format(providers))

            for provider in providers:
                base_url = provider.get("url")
                for stream_info in provider.get("streams"):
                    bitrate = int(stream_info.get("bitrate", 0))
                    stream_name = (bitrate > 0 and "{0}k".format(bitrate) or
                                   "recorded")

                    if stream_name in streams:
                        stream_name += "_alt"

                    url = stream_info.get("streamName")
                    if base_url:
                        url = base_url + url

                    if url.startswith("http"):
                        streams[stream_name] = HTTPStream(self.session, url)
                    elif url.startswith("rtmp"):
                        params = dict(rtmp=url, pageUrl=self.url)
                        streams[stream_name] = RTMPStream(self.session, params)

        else:
            self.logger.warning("The proper API could not be used without "
                                "python-librtmp installed. Stream URL may be "
                                "incorrect.")

            url = RECORDED_URL.format(video_id)
            random_hash = "{0:02x}{1:02x}".format(randint(0, 255),
                                                  randint(0, 255))
            params = dict(hash=random_hash)
            stream = HTTPStream(self.session, url, params=params)
            streams["recorded"] = stream

        return streams

    def _get_streams(self):
        recorded = re.match(RECORDED_URL_PATTERN, self.url)
        if recorded:
            return self._get_recorded_streams(recorded.group("video_id"))
        else:
            return self._get_live_streams()

__plugin__ = UStreamTV

########NEW FILE########
__FILENAME__ = veetle
from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError, NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HTTPStream


class Veetle(Plugin):
    APIURL = "http://veetle.com/index.php/stream/ajaxStreamLocation/{0}/flash"

    @classmethod
    def can_handle_url(self, url):
        return "veetle.com" in url

    def _get_streams(self):
        parsed = urlparse(self.url)

        if parsed.fragment:
            channelid = parsed.fragment
        elif "/v/" in parsed.path:
            channelid = parsed.path.rpartition("/v/")[-1]
        else:
            channelid = parsed.path.rpartition("view/")[-1]

        if not channelid:
            raise NoStreamsError(self.url)

        channelid = channelid.lower().replace("/", "_")

        self.logger.debug("Fetching stream info")
        res = http.get(self.APIURL.format(channelid))
        json = http.json(res)

        if not isinstance(json, dict):
            raise PluginError("Invalid JSON response")
        elif not ("success" in json and "payload" in json):
            raise PluginError("Invalid JSON response")
        elif json["success"] == False:
            raise NoStreamsError(self.url)

        streams = {}
        streams["live"] = HTTPStream(self.session, json["payload"])

        return streams


__plugin__ = Veetle

########NEW FILE########
__FILENAME__ = viasat
"""Plugin for Viasat's on demand content sites, such as tv6play.se."""

import re

from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HLSStream, RTMPStream
from livestreamer.utils import rtmpparse, verifyjson

STREAM_API = "http://playapi.mtgx.tv/v1/videos/stream/{0}"
SWF_URL_REGEX = r"data-flashplayer-url=\"([^\"]+)\""
URL_REGEX = (r"http(s)?://(www\.)?"
             r"(tv(3|6|8|10)|viasat4)play\.(dk|ee|lt|lv|no|se)"
             r"/.+/(?P<stream_id>\d+)")


class Viasat(Plugin):
    @classmethod
    def can_handle_url(cls, url):
        return re.match(URL_REGEX, url)

    def _get_swf_url(self):
        res = http.get(self.url)
        match = re.search(SWF_URL_REGEX, res.text)
        if not match:
            raise PluginError("Unable to find SWF URL in the HTML")

        return match.group(1)

    def _get_streams(self):
        match = re.match(URL_REGEX, self.url)
        if not match:
            return

        stream_id = match.group("stream_id")
        res = http.get(STREAM_API.format(stream_id))
        json = http.json(res)
        stream_info = verifyjson(json, "streams")

        streams = {}
        swf_url = None
        for name, stream_url in stream_info.items():
            stream_url = str(stream_url)
            if stream_url.endswith(".m3u8"):
                try:
                    hls_streams = HLSStream.parse_variant_playlist(self.session,
                                                                   stream_url)
                    streams.update(hls_streams)
                except IOError as err:
                    self.logger.error("Failed to fetch HLS streams: {0}", err)
            elif stream_url.startswith("rtmp://"):
                swf_url = swf_url or self._get_swf_url()
                params = {
                    "rtmp": stream_url,
                    "pageUrl": self.url,
                    "swfVfy": swf_url,
                }

                if stream_url.endswith(".mp4"):
                    tcurl, playpath = rtmpparse(stream_url)
                    params["rtmp"] = tcurl
                    params["playpath"] = playpath
                else:
                    params["live"] = True

                streams[name] = RTMPStream(self.session, params)

        return streams

__plugin__ = Viasat

########NEW FILE########
__FILENAME__ = weeb
from livestreamer.compat import urlparse
from livestreamer.exceptions import PluginError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream
from livestreamer.utils import parse_qsd


class Weeb(Plugin):
    SWFURL = "http://static2.weeb.tv/static2/player.swf"
    APIURL = "http://weeb.tv/api/setPlayer"

    @classmethod
    def can_handle_url(self, url):
        return "weeb.tv" in url

    def _get_streams(self):
        channelname = urlparse(self.url).path.rstrip("/").rpartition("/")[-1].lower()
        self.logger.debug("Fetching stream info")

        headers = {
            "Referer": self.SWFURL
        }

        form = dict(cid=channelname, watchTime="0",
                    firstConnect="1", ip="NaN")

        res = http.post(self.APIURL, data=form, headers=headers)

        params = parse_qsd(res.text)

        if "0" in params and int(params["0"]) <= 0:
            raise PluginError("Server refused to send required parameters.")

        rtmp = params["10"]
        playpath = params["11"]
        multibitrate = int(params["20"])
        premiumuser = params["5"]
        blocktype = int(params["13"])

        if blocktype != 0:
            if blocktype == 1:
                blocktime = params["14"]
                reconnectiontime = params["16"]
                msg = ("You have crossed free viewing limit. ",
                       "You have been blocked for %s minutes. " % blocktime,
                       "Try again in %s minutes." % reconnectiontime)
                raise PluginError(msg)
            elif blocktype == 11:
                raise PluginError("No free slots available.")

        if "73" in params:
            token = params["73"]
        else:
            raise PluginError("Server seems busy, please try after some time.")

        if not RTMPStream.is_usable(self.session):
            raise PluginError("rtmpdump is not usable and required by Weeb plugin")

        streams = {}
        stream_name = "sd"

        if multibitrate:
            streams[stream_name] = RTMPStream(self.session, {
                "rtmp": "{0}/{1}".format(rtmp, playpath),
                "pageUrl": self.url,
                "swfVfy": self.SWFURL,
                "weeb": token,
                "live": True
            })
            playpath += "HI"
            stream_name = "hd"

        streams[stream_name] = RTMPStream(self.session, {
            "rtmp": "{0}/{1}".format(rtmp, playpath),
            "pageUrl": self.url,
            "swfVfy": self.SWFURL,
            "weeb": token,
            "live": True
        })

        return streams


__plugin__ = Weeb

########NEW FILE########
__FILENAME__ = youtube
import re

from livestreamer.exceptions import NoStreamsError
from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import HTTPStream, HLSStream
from livestreamer.utils import verifyjson, parse_json, parse_qsd

API_KEY = "AIzaSyBDBi-4roGzWJN4du9TuDMLd_jVTcVkKz4"
API_BASE = "https://www.googleapis.com/youtube/v3"
API_SEARCH_URL = API_BASE + "/search"
HLS_HEADERS = {
    "User-Agent": "Mozilla/5.0"
}


def valid_stream(streaminfo):
    return not not streaminfo.get("url")


class YouTube(Plugin):
    @classmethod
    def can_handle_url(self, url):
        return "youtube.com" in url or "youtu.be" in url

    @classmethod
    def stream_weight(cls, stream):
        match = re.match("(\w+)_3d", stream)
        if match:
            weight, group = Plugin.stream_weight(match.group(1))
            weight -= 1
            group = "youtube_3d"
        else:
            weight, group = Plugin.stream_weight(stream)

        return weight, group

    def _find_config(self, data):
        match = re.search("'PLAYER_CONFIG': (.+)\n.+}\);", data)
        if match:
            return match.group(1)

        match = re.search("yt.playerConfig = (.+)\;\n", data)
        if match:
            return match.group(1)

        match = re.search("ytplayer.config = (.+);\(function", data)
        if match:
            return match.group(1)

        match = re.search("data-swf-config=\"(.+)\"", data)
        if match:
            config = match.group(1)
            config = config.replace("&amp;quot;", "\"")

            return config

    def _find_channel_config(self, data):
        match = re.search(r'meta itemprop="channelId" content="([^"]+)"', data)
        if not match:
            return

        channel_id = match.group(1)
        query = dict(channelId=channel_id, type="video", eventType="live",
                     part="id", key=API_KEY)
        res = http.get(API_SEARCH_URL, params=query)
        res = http.json(res)
        videos = verifyjson(res, "items")

        for video in videos:
            info = verifyjson(video, "id")
            video_id = info.get("videoId")
            url = "http://youtube.com/watch?v={0}".format(video_id)

            config = self._get_stream_info(url)
            if config:
                return config

    def _get_stream_info(self, url):
        match = re.search("/(embed|v)/([^?]+)", url)
        if match:
            url = "http://youtube.com/watch?v={0}".format(match.group(2))

        res = http.get(url)
        match = re.search("/user/([^?/]+)", res.url)
        if match:
            return self._find_channel_config(res.text)
        else:
            config = self._find_config(res.text)

        if config:
            return parse_json(config, "config JSON")

    def _parse_stream_map(self, streammap):
        streams = []

        for stream_qs in streammap.split(","):
            stream = parse_qsd(stream_qs)
            streams.append(stream)

        return streams

    def _parse_format_map(self, formatsmap):
        formats = {}

        if len(formatsmap) == 0:
            return formats

        for format in formatsmap.split(","):
            s = format.split("/")
            (w, h) = s[1].split("x")
            formats[s[0]] = h + "p"

        return formats

    def _get_streams(self):
        info = self._get_stream_info(self.url)

        if not info:
            raise NoStreamsError(self.url)

        args = verifyjson(info, "args")
        uestreammap = verifyjson(args, "url_encoded_fmt_stream_map")
        fmtlist = verifyjson(args, "fmt_list")
        streammap = self._parse_stream_map(uestreammap)
        formatmap = self._parse_format_map(fmtlist)

        streams = {}
        for streaminfo in filter(valid_stream, streammap):
            params = {}
            if "s" in streaminfo and self._decrypt_signature(streaminfo["s"]):
                params["signature"] = self._decrypt_signature(streaminfo["s"])

            stream = HTTPStream(self.session, streaminfo["url"],
                                params=params)

            if streaminfo["itag"] in formatmap:
                quality = formatmap[streaminfo["itag"]]
            else:
                quality = streaminfo["quality"]

            if streaminfo.get("stereo3d") == "1":
                quality += "_3d"

            streams[quality] = stream

        if "hlsvp" in args:
            url = args["hlsvp"]

            try:
                hlsstreams = HLSStream.parse_variant_playlist(self.session, url,
                                                              headers=HLS_HEADERS,
                                                              namekey="pixels")
                streams.update(hlsstreams)
            except IOError as err:
                self.logger.warning("Failed to get variant playlist: {0}", err)

        if not streams and args.get("live_playback", "0") == "0":
            self.logger.warning("VOD support may not be 100% complete. Try youtube-dl instead.")

        return streams

    def _decrypt_signature(self, s):
        """ 
            Turn the encrypted s field into a working signature
            https://github.com/rg3/youtube-dl/blob/master/youtube_dl/extractor/youtube.py
        """

        if len(s) == 92:
            return s[25] + s[3:25] + s[0] + s[26:42] + s[79] + s[43:79] + s[91] + s[80:83]
        elif len(s) == 90:
            return s[25] + s[3:25] + s[2] + s[26:40] + s[77] + s[41:77] + s[89] + s[78:81]
        elif len(s) == 88:
            return s[48] + s[81:67:-1] + s[82] + s[66:62:-1] + s[85] + s[61:48:-1] + s[67] + s[47:12:-1] + s[3] + s[11:3:-1] + s[2] + s[12]
        elif len(s) == 87:
            return s[4:23] + s[86] + s[24:85]
        elif len(s) == 86:
            return s[83:85] + s[26] + s[79:46:-1] + s[85] + s[45:36:-1] + s[30] + s[35:30:-1] + s[46] + s[29:26:-1] + s[82] + s[25:1:-1]
        elif len(s) == 85:
            return s[2:8] + s[0] + s[9:21] + s[65] + s[22:65] + s[84] + s[66:82] + s[21]
        elif len(s) == 84:
            return s[83:36:-1] + s[2] + s[35:26:-1] + s[3] + s[25:3:-1] + s[26]
        elif len(s) == 83:
            return s[6] + s[3:6] + s[33] + s[7:24] + s[0] + s[25:33] + s[53] + s[34:53] + s[24] + s[54:]
        elif len(s) == 82:
            return s[36] + s[79:67:-1] + s[81] + s[66:40:-1] + s[33] + s[39:36:-1] + s[40] + s[35] + s[0] + s[67] + s[32:0:-1] + s[34]
        elif len(s) == 81:
            return s[56] + s[79:56:-1] + s[41] + s[55:41:-1] + s[80] + s[40:34:-1] + s[0] + s[33:29:-1] + s[34] + s[28:9:-1] + s[29] + s[8:0:-1] + s[9]
        elif len(s) == 79:
            return s[54] + s[77:54:-1] + s[39] + s[53:39:-1] + s[78] + s[38:34:-1] + s[0] + s[33:29:-1] + s[34] + s[28:9:-1] + s[29] + s[8:0:-1] + s[9]
        else:
            self.logger.warning("Unable to decrypt signature, key length {0} not supported; retrying might work", len(s))
            return None

__plugin__ = YouTube

########NEW FILE########
__FILENAME__ = zdf_mediathek
import re

from livestreamer.plugin import Plugin
from livestreamer.plugin.api import http
from livestreamer.stream import RTMPStream, HDSStream
from livestreamer.utils import parse_xml

API_URL = "http://www.zdf.de/ZDFmediathek/xmlservice/web/beitragsDetails"
QUALITY_WEIGHTS = {
    "hd": 720,
    "veryhigh": 480,
    "high": 240,
    "med": 176,
    "low": 112
}


class zdf_mediathek(Plugin):
    @classmethod
    def can_handle_url(cls, url):
        return "zdf.de/zdfmediathek" in url.lower()

    @classmethod
    def stream_weight(cls, key):
        weight = QUALITY_WEIGHTS.get(key)
        if weight:
            return weight, "ZDFmediathek"

        return Plugin.stream_weight(key)

    def _get_streams(self):
        if not RTMPStream.is_usable(self.session):
            self.logger.warning("rtmpdump is not usable, only HDS streams will be available")

        self.logger.debug("Fetching stream info")
        match = re.search("/\w*/(live|video)*/(\d+)", self.url)
        if not match:
            return

        stream_id = match.group(2)
        res = http.get(API_URL, params=dict(ak="web", id=stream_id))
        root = parse_xml(res.text.encode("utf8"))

        streams = {}
        for formitaet in root.iter('formitaet'):
            url = formitaet.find('url').text
            quality = formitaet.find('quality').text

            if formitaet.get('basetype') == "h264_aac_f4f_http_f4m_http":
                hds_streams = HDSStream.parse_manifest(self.session, url)
                streams.update(hds_streams)
            elif formitaet.get('basetype') == 'h264_aac_mp4_rtmp_zdfmeta_http':
                streams[quality] = RTMPStream(self.session, {
                    "rtmp": self._get_stream(url),
                    "pageUrl": self.url,
                })

        return streams

    def _get_stream(self, meta_url):
        res = http.get(meta_url)
        root = parse_xml(res.text.encode("utf8"))
        stream_url = root.find("default-stream-url").text
        return stream_url

__plugin__ = zdf_mediathek

########NEW FILE########
__FILENAME__ = session
import imp
import pkgutil
import re
import sys
import traceback

from . import plugins, __version__
from .compat import urlparse, is_win32
from .exceptions import NoPluginError, PluginError
from .logger import Logger
from .options import Options
from .plugin import api


def print_small_exception(start_after):
    type, value, traceback_ = sys.exc_info()

    tb = traceback.extract_tb(traceback_)
    index = 0

    for i, trace in enumerate(tb):
        if trace[2] == start_after:
            index = i+1
            break

    lines = traceback.format_list(tb[index:])
    lines += traceback.format_exception_only(type, value)

    for line in lines:
        sys.stderr.write(line)

    sys.stderr.write("\n")


class Livestreamer(object):
    """A Livestreamer session is used to keep track of plugins,
       options and log settings."""

    def __init__(self):
        self.http = api.HTTPSession()
        self.options = Options({
            "hds-live-edge": 10.0,
            "hds-segment-attempts": 3,
            "hds-segment-timeout": 10.0,
            "hds-timeout": 60.0,
            "hls-live-edge": 3,
            "hls-segment-attempts": 3,
            "hls-segment-timeout": 10.0,
            "hls-timeout": 60.0,
            "http-stream-timeout": 60.0,
            "ringbuffer-size": 1024 * 1024 * 16, # 16 MB
            "rtmp-timeout": 60.0,
            "rtmp-rtmpdump": is_win32 and "rtmpdump.exe" or "rtmpdump",
            "rtmp-proxy": None,
            "subprocess-errorlog": False
        })
        self.plugins = {}
        self.logger = Logger()
        self.load_builtin_plugins()

    def set_option(self, key, value):
        """Sets general options used by plugins and streams originating
        from this session object.

        :param key: key of the option
        :param value: value to set the option to


        **Available options**:

        ======================= =========================================
        hds-live-edge           (float) Specify the time live HDS
                                streams will start from the edge of
                                stream, default: ``10.0``

        hds-segment-attempts    (int) How many attempts should be done
                                to download each HDS segment, default: ``3``

        hds-segment-timeout     (float) HDS segment connect and read
                                timeout, default: ``10.0``

        hds-timeout             (float) Timeout for reading data from
                                HDS streams, default: ``60.0``

        hls-live-edge           (int) How many segments from the end
                                to start live streams on, default: ``3``

        hls-segment-attempts    (int) How many attempts should be done
                                to download each HLS segment, default: ``3``

        hls-segment-timeout     (float) HLS segment connect and read
                                timeout, default: ``10.0``

        hls-timeout             (float) Timeout for reading data from
                                HLS streams, default: ``60.0``

        http-proxy              (str) Specify a HTTP proxy to use for
                                all HTTP requests

        https-proxy             (str) Specify a HTTPS proxy to use for
                                all HTTPS requests

        http-cookies            (dict or str) A dict or a semi-colon (;)
                                delimited str of cookies to add to each
                                HTTP request, e.g. ``foo=bar;baz=qux``

        http-headers            (dict or str) A dict or semi-colon (;)
                                delimited str of headers to add to each
                                HTTP request, e.g. ``foo=bar;baz=qux``

        http-query-params       (dict or str) A dict or a ampersand (&)
                                delimited string of query parameters to
                                add to each HTTP request,
                                e.g. ``foo=bar&baz=qux``

        http-trust-env          (bool) Trust HTTP settings set in the
                                environment, such as environment
                                variables (HTTP_PROXY, etc) and
                                ~/.netrc authentication

        http-ssl-verify         (bool) Verify SSL certificates,
                                default: ``True``

        http-ssl-cert           (str or tuple) SSL certificate to use,
                                can be either a .pem file (str) or a
                                .crt/.key pair (tuple)

        http-timeout            (float) General timeout used by all HTTP
                                requests except the ones covered by
                                other options, default: ``20.0``

        http-stream-timeout     (float) Timeout for reading data from
                                HTTP streams, default: ``60.0``

        subprocess-errorlog     (bool) Log errors from subprocesses to
                                a file located in the temp directory

        ringbuffer-size         (int) The size of the internal ring
                                buffer used by most stream types,
                                default: ``16777216`` (16MB)

        rtmp-proxy              (str) Specify a proxy (SOCKS) that RTMP
                                streams will use

        rtmp-rtmpdump           (str) Specify the location of the
                                rtmpdump executable used by RTMP streams,
                                e.g. ``/usr/local/bin/rtmpdump``

        rtmp-timeout            (float) Timeout for reading data from
                                RTMP streams, default: ``60.0``
        ======================= =========================================

        """

        # Backwards compatibility
        if key == "rtmpdump":
            key = "rtmp-rtmpdump"
        elif key == "rtmpdump-proxy":
            key = "rtmp-proxy"
        elif key == "errorlog":
            key = "subprocess-errorlog"

        if key == "http-proxy":
            if not re.match("^http(s)?://", value):
                value = "http://" + value
            self.http.proxies["http"] = value
        elif key == "https-proxy":
            if not re.match("^http(s)?://", value):
                value = "https://" + value
            self.http.proxies["https"] = value
        elif key == "http-cookies":
            if isinstance(value, dict):
                self.http.cookies.update(value)
            else:
                self.http.parse_cookies(value)
        elif key == "http-headers":
            if isinstance(value, dict):
                self.http.headers.update(value)
            else:
                self.http.parse_headers(value)
        elif key == "http-query-params":
            if isinstance(value, dict):
                self.http.params.update(value)
            else:
                self.http.parse_query_params(value)
        elif key == "http-trust-env":
            self.http.trust_env = value
        elif key == "http-ssl-verify":
            self.http.verify = value
        elif key == "http-ssl-cert":
            self.http.cert = value
        elif key == "http-timeout":
            self.http.timeout = value
        else:
            self.options.set(key, value)

    def get_option(self, key):
        """Returns current value of specified option.

        :param key: key of the option

        """

        return self.options.get(key)

    def set_plugin_option(self, plugin, key, value):
        """Sets plugin specific options used by plugins originating
        from this session object.

        :param plugin: name of the plugin
        :param key: key of the option
        :param value: value to set the option to

        """

        if plugin in self.plugins:
            plugin = self.plugins[plugin]
            plugin.set_option(key, value)

    def get_plugin_option(self, plugin, key):
        """Returns current value of plugin specific option.

        :param plugin: name of the plugin
        :param key: key of the option

        """

        if plugin in self.plugins:
            plugin = self.plugins[plugin]
            return plugin.get_option(key)

    def set_loglevel(self, level):
        """Sets the log level used by this session.

        Valid levels are: "none", "error", "warning", "info"
        and "debug".

        :param level: level of logging to output

        """

        self.logger.set_level(level)

    def set_logoutput(self, output):
        """Sets the log output used by this session.

        :param output: a file-like object with a write method

        """
        self.logger.set_output(output)

    def resolve_url(self, url):
        """Attempts to find a plugin that can use this URL.

        The default protocol (http) will be prefixed to the URL if
        not specified.

        Raises :exc:`NoPluginError` on failure.

        :param url: a URL to match against loaded plugins

        """
        parsed = urlparse(url)

        if len(parsed.scheme) == 0:
            url = "http://" + url

        for name, plugin in self.plugins.items():
            if plugin.can_handle_url(url):
                obj = plugin(url)
                return obj

        # Attempt to handle a redirect URL
        try:
            res = self.http.get(url, stream=True)
            if res.url != url:
                return self.resolve_url(res.url)
        except PluginError:
            pass

        raise NoPluginError

    def get_plugins(self):
        """Returns the loaded plugins for the session."""

        return self.plugins

    def load_builtin_plugins(self):
        self.load_plugins(plugins.__path__[0])

    def load_plugins(self, path):
        """Attempt to load plugins from the path specified.

        :param path: full path to a directory where to look for plugins

        """

        for loader, name, ispkg in pkgutil.iter_modules([path]):
            file, pathname, desc = imp.find_module(name, [path])

            try:
                self.load_plugin(name, file, pathname, desc)
            except Exception:
                sys.stderr.write("Failed to load plugin {0}:\n".format(name))
                print_small_exception("load_plugin")

                continue

    def load_plugin(self, name, file, pathname, desc):
        # Set the global http session for this plugin
        api.http = self.http
        module = imp.load_module(name, file, pathname, desc)

        if hasattr(module, "__plugin__"):
            module_name = getattr(module, "__name__")

            plugin = getattr(module, "__plugin__")
            plugin.bind(self, module_name)

            self.plugins[plugin.module] = plugin

        if file:
            file.close()

    @property
    def version(self):
        return __version__

__all__ = ["Livestreamer"]

########NEW FILE########
__FILENAME__ = akamaihd
import base64
import io
import hashlib
import hmac
import random

from .stream import Stream
from .wrappers import StreamIOIterWrapper

from ..buffers import Buffer
from ..compat import str, bytes, urlparse
from ..exceptions import StreamError
from ..utils import swfdecompress

from ..packages.flashmedia import FLV, FLVError
from ..packages.flashmedia.tag import ScriptData


class TokenGenerator(object):
    def __init__(self, stream):
        self.stream = stream

    def generate(self):
        raise NotImplementedError


class Auth3TokenGenerator(TokenGenerator):
    def generate(self):
        if not self.stream.swf:
            raise StreamError("A SWF URL is required to create session token")

        res = self.stream.session.http.get(self.stream.swf,
                                           exception=StreamError)
        data = swfdecompress(res.content)

        md5 = hashlib.md5()
        md5.update(data)

        data = bytes(self.stream.sessionid, "ascii") + md5.digest()
        sig = hmac.new(b"foo", data, hashlib.sha1)
        b64 = base64.encodestring(sig.digest())
        token = str(b64, "ascii").replace("\n", "")

        return token


def cache_bust_string(length):
    rval = ""

    for i in range(length):
        rval += chr(65 + int(round(random.random() * 25)))

    return rval


class AkamaiHDStreamIO(io.IOBase):
    Version = "2.5.8"
    FlashVersion = "LNX 11,1,102,63"

    StreamURLFormat = "{host}/{streamname}"
    ControlURLFormat = "{host}/control/{streamname}"
    ControlData = b":)"

    TokenGenerators = {
        "c11e59dea648d56e864fc07a19f717b9": Auth3TokenGenerator
    }

    StatusComplete = 3
    StatusError = 4

    Errors = {
        1: "Stream not found",
        2: "Track not found",
        3: "Seek out of bounds",
        4: "Authentication failed",
        5: "DVR disabled",
        6: "Invalid bitrate test"
    }

    def __init__(self, session, url, swf=None, seek=None):
        parsed = urlparse(url)

        self.session = session
        self.logger = self.session.logger.new_module("stream.akamaihd")
        self.host = ("{scheme}://{netloc}").format(scheme=parsed.scheme, netloc=parsed.netloc)
        self.streamname = parsed.path[1:]
        self.swf = swf
        self.seek = seek

    def open(self):
        self.guid = cache_bust_string(12)
        self.islive = None
        self.sessionid = None
        self.flv = None

        self.buffer = Buffer()
        self.completed_handshake = False

        url = self.StreamURLFormat.format(host=self.host, streamname=self.streamname)
        params = self._create_params(seek=self.seek)

        self.logger.debug("Opening host={host} streamname={streamname}",
                          host=self.host, streamname=self.streamname)

        try:
            res = self.session.http.get(url, stream=True, params=params)
            self.fd = StreamIOIterWrapper(res.iter_content(8192))
        except Exception as err:
            raise StreamError(str(err))

        self.handshake(self.fd)

        return self

    def handshake(self, fd):
        try:
            self.flv = FLV(fd)
        except FLVError as err:
            raise StreamError(str(err))

        self.buffer.write(self.flv.header.serialize())
        self.logger.debug("Attempting to handshake")

        for i, tag in enumerate(self.flv):
            if i == 10:
                raise StreamError("No OnEdge metadata in FLV after 10 tags, probably not a AkamaiHD stream")

            self.process_tag(tag, exception=StreamError)

            if self.completed_handshake:
                self.logger.debug("Handshake successful")
                break

    def process_tag(self, tag, exception=IOError):
        if isinstance(tag.data, ScriptData) and tag.data.name == "onEdge":
            self._on_edge(tag.data.value, exception=exception)

        self.buffer.write(tag.serialize())

    def send_token(self, token):
        headers = { "x-Akamai-Streaming-SessionToken": token }

        self.logger.debug("Sending new session token")
        self.send_control("sendingNewToken", headers=headers,
                          swf=self.swf)

    def send_control(self, cmd, headers=None, **params):
        if not headers:
            headers = {}

        url = self.ControlURLFormat.format(host=self.host,
                                           streamname=self.streamname)

        headers["x-Akamai-Streaming-SessionID"] = self.sessionid

        params = self._create_params(cmd=cmd, **params)

        return self.session.http.post(url,
                                      headers=headers,
                                      params=params,
                                      data=self.ControlData,
                                      exception=StreamError)

    def read(self, size=-1):
        if not (self.flv and self.fd):
            return b""

        if self.buffer.length:
            return self.buffer.read(size)
        else:
            return self.fd.read(size)

    def _create_params(self, **extra):
        params = dict(v=self.Version, fp=self.FlashVersion,
                      r=cache_bust_string(5), g=self.guid)
        params.update(extra)

        return params

    def _generate_session_token(self, data64):
        swfdata = base64.decodestring(bytes(data64, "ascii"))
        md5 = hashlib.md5()
        md5.update(swfdata)
        hash = md5.hexdigest()

        if hash in self.TokenGenerators:
            generator = self.TokenGenerators[hash](self)

            return generator.generate()
        else:
            raise StreamError(("No token generator available for hash '{0}'").format(hash))

    def _on_edge(self, data, exception=IOError):
        def updateattr(attr, key):
            if key in data:
                setattr(self, attr, data[key])

        self.logger.debug("onEdge data")
        for key, val in data.items():
            if isinstance(val, str):
                val = val[:50]

            self.logger.debug(" {key}={val}",
                              key=key, val=val)

        updateattr("islive", "isLive")
        updateattr("sessionid", "session")
        updateattr("status", "status")
        updateattr("streamname", "streamName")

        if self.status == self.StatusComplete:
            self.flv = None
        elif self.status == self.StatusError:
            errornum = data["errorNumber"]

            if errornum in self.Errors:
                msg = self.Errors[errornum]
            else:
                msg = "Unknown error"

            raise exception("onEdge error: " + msg)

        if not self.completed_handshake:
            if "data64" in data:
                sessiontoken = self._generate_session_token(data["data64"])
            else:
                sessiontoken = None

            self.send_token(sessiontoken)
            self.completed_handshake = True


class AkamaiHDStream(Stream):
    """
    Implements the AkamaiHD Adaptive Streaming protocol

    *Attributes:*

    - :attr:`url` URL to the stream
    - :attr:`swf` URL to a SWF used by the handshake protocol
    - :attr:`seek` Position to seek to when opening the stream
    """

    __shortname__ = "akamaihd"

    def __init__(self, session, url, swf=None, seek=None):
        Stream.__init__(self, session)

        self.seek = seek
        self.swf = swf
        self.url = url

    def __repr__(self):
        return ("<AkamaiHDStream({0!r}, "
                "swf={1!r})>".format(self.url, self.swf))

    def __json__(self):
        return dict(type=AkamaiHDStream.shortname(),
                    url=self.url, swf=self.swf)

    def open(self):
        stream = AkamaiHDStreamIO(self.session, self.url,
                                  self.swf, self.seek)

        return stream.open()

__all__ = ["AkamaiHDStream"]

########NEW FILE########
__FILENAME__ = flvconcat
from __future__ import division

from collections import namedtuple
from io import IOBase
from itertools import chain, islice
from threading import Thread

from ..buffers import RingBuffer
from ..packages.flashmedia import FLVError
from ..packages.flashmedia.tag import (AudioData, AACAudioData, VideoData,
                                       AVCVideoData, VideoCommandFrame,
                                       Header, ScriptData, Tag)
from ..packages.flashmedia.tag import (AAC_PACKET_TYPE_SEQUENCE_HEADER,
                                       AVC_PACKET_TYPE_SEQUENCE_HEADER,
                                       AUDIO_CODEC_ID_AAC,
                                       VIDEO_CODEC_ID_AVC,
                                       TAG_TYPE_AUDIO,
                                       TAG_TYPE_VIDEO)

__all__ = ["extract_flv_header_tags", "FLVTagConcat", "FLVTagConcatIO"]


FLVHeaderTags = namedtuple("FLVHeaderTags", "metadata aac vc")


def iter_flv_tags(fd=None, buf=None, strict=False, skip_header=False):
    if not (fd or buf):
        return

    offset = 0
    if not skip_header:
        if fd:
            Header.deserialize(fd)
        elif buf:
            header, offset = Header.deserialize_from(buf, offset)

    while fd or buf and offset < len(buf):
        try:
            if fd:
                tag = Tag.deserialize(fd, strict=strict)
            elif buf:
                tag, offset = Tag.deserialize_from(buf, offset, strict=strict)
        except (IOError, FLVError) as err:
            if "Insufficient tag header" in str(err):
                break

            raise IOError(err)

        yield tag


def extract_flv_header_tags(stream):
    fd = stream.open()
    metadata = aac_header = avc_header = None

    for tag_index, tag in enumerate(iter_flv_tags(fd)):
        if isinstance(tag.data, ScriptData) and tag.data.name == "onMetaData":
            metadata = tag
        elif (isinstance(tag.data, VideoData) and
              isinstance(tag.data.data, AVCVideoData)):
            if tag.data.data.type == AVC_PACKET_TYPE_SEQUENCE_HEADER:
                avc_header = tag
        elif (isinstance(tag.data, AudioData) and
              isinstance(tag.data.data, AACAudioData)):
            if tag.data.data.type == AAC_PACKET_TYPE_SEQUENCE_HEADER:
                aac_header = tag

        if aac_header and avc_header and metadata:
            break

        # Give up after 10 tags
        if tag_index == 9:
            break

    return FLVHeaderTags(metadata, aac_header, avc_header)


class FLVTagConcat(object):
    def __init__(self, duration=None, tags=[], has_video=True, has_audio=True,
                 flatten_timestamps=False, sync_headers=False):
        self.duration = duration
        self.flatten_timestamps = flatten_timestamps
        self.has_audio = has_audio
        self.has_video = has_video
        self.sync_headers = sync_headers
        self.tags = tags

        if not (has_audio and has_video):
            self.sync_headers = False

        self.audio_header_written = False
        self.flv_header_written = False
        self.video_header_written = False
        self.timestamps_add = {}
        self.timestamps_orig = {}
        self.timestamps_sub = {}

    @property
    def headers_written(self):
        return self.audio_header_written and self.video_header_written

    def verify_tag(self, tag):
        if tag.filter:
            raise IOError("Tag has filter flag set, probably encrypted")

        # Only AAC and AVC has detectable headers
        if isinstance(tag.data, AudioData) and tag.data.codec != AUDIO_CODEC_ID_AAC:
            self.audio_header_written = True
        if isinstance(tag.data, VideoData) and tag.data.codec != VIDEO_CODEC_ID_AVC:
            self.video_header_written = True

        # Make sure there is no timestamp gap between audio and video when syncing
        if self.sync_headers and self.timestamps_sub and not self.headers_written:
            self.timestamps_sub = {}

        if isinstance(tag.data, AudioData):
            if isinstance(tag.data.data, AACAudioData):
                if tag.data.data.type == AAC_PACKET_TYPE_SEQUENCE_HEADER:
                    if self.audio_header_written:
                        return

                    self.audio_header_written = True
                else:
                    if self.sync_headers and not self.headers_written:
                        return

                    if not self.audio_header_written:
                        return
            else:
                if self.sync_headers and not self.headers_written:
                    return

        elif isinstance(tag.data, VideoData):
            if isinstance(tag.data.data, AVCVideoData):
                if tag.data.data.type == AVC_PACKET_TYPE_SEQUENCE_HEADER:
                    if self.video_header_written:
                        return

                    self.video_header_written = True
                else:
                    if self.sync_headers and not self.headers_written:
                        return

                    if not self.video_header_written:
                        return
            elif isinstance(tag.data.data, VideoCommandFrame):
                return
            else:
                if self.sync_headers and not self.headers_written:
                    return

        elif isinstance(tag.data, ScriptData):
            if tag.data.name == "onMetaData":
                if self.duration:
                    tag.data.value["duration"] = self.duration
                elif "duration" in tag.data.value:
                    del tag.data.value["duration"]

        return True

    def adjust_tag_gap(self, tag):
        timestamp_gap = tag.timestamp - self.timestamps_orig.get(tag.type, 0)
        timestamp_sub = self.timestamps_sub.get(tag.type)
        if timestamp_gap > 1000 and timestamp_sub is not None:
            self.timestamps_sub[tag.type] += timestamp_gap

        self.timestamps_orig[tag.type] = tag.timestamp

    def adjust_tag_timestamp(self, tag):
        timestamp_offset_sub = self.timestamps_sub.get(tag.type)
        if timestamp_offset_sub is None and tag not in self.tags:
            self.timestamps_sub[tag.type] = tag.timestamp
            timestamp_offset_sub = self.timestamps_sub.get(tag.type)

        timestamp_offset_add = self.timestamps_add.get(tag.type)

        if timestamp_offset_add:
            tag.timestamp = max(0, tag.timestamp + timestamp_offset_add)
        elif timestamp_offset_sub:
            tag.timestamp = max(0, tag.timestamp - timestamp_offset_sub)

    def analyze_tags(self, tag_iterator):
        tags = list(islice(tag_iterator, 10))
        audio_tags = len(list(filter(lambda t: t.type == TAG_TYPE_AUDIO, tags)))
        video_tags = len(list(filter(lambda t: t.type == TAG_TYPE_VIDEO, tags)))

        self.has_audio = audio_tags > 0
        self.has_video = video_tags > 0

        if not (self.has_audio and self.has_video):
            self.sync_headers = False

        return tags

    def iter_tags(self, fd=None, buf=None, skip_header=None):
        if skip_header is None:
            skip_header = not not self.tags

        tags_iterator = filter(None, self.tags)
        flv_iterator = iter_flv_tags(fd=fd, buf=buf, skip_header=skip_header)

        for tag in chain(tags_iterator, flv_iterator):
            yield tag

    def iter_chunks(self, fd=None, buf=None, skip_header=None):
        """Reads FLV tags from fd or buf and returns them with adjusted
           timestamps."""
        timestamps = dict(self.timestamps_add)
        tag_iterator = self.iter_tags(fd=fd, buf=buf, skip_header=skip_header)

        if not self.flv_header_written:
            analyzed_tags = self.analyze_tags(tag_iterator)
        else:
            analyzed_tags = []

        for tag in chain(analyzed_tags, tag_iterator):
            if not self.flv_header_written:
                flv_header = Header(has_video=self.has_video,
                                    has_audio=self.has_audio)
                yield flv_header.serialize()
                self.flv_header_written = True

            if self.verify_tag(tag):
                self.adjust_tag_gap(tag)
                self.adjust_tag_timestamp(tag)

                if self.duration:
                    norm_timestamp = tag.timestamp / 1000
                    if norm_timestamp > self.duration:
                        break
                yield tag.serialize()
                timestamps[tag.type] = tag.timestamp

        if not self.flatten_timestamps:
            self.timestamps_add = timestamps

        self.tags = []


class FLVTagConcatWorker(Thread):
    def __init__(self, iterator, stream):
        self.error = None
        self.stream = stream
        self.stream_iterator = iterator
        self.concater = FLVTagConcat(stream.duration, stream.tags,
                                     **stream.concater_params)

        Thread.__init__(self)
        self.daemon = True

    def run(self):
        for fd in self.stream_iterator:
            try:
                chunks = self.concater.iter_chunks(
                    fd, skip_header=self.stream.skip_header
                )
                for chunk in chunks:
                    self.stream.buffer.write(chunk)

                    if not self.running:
                        return
            except IOError as err:
                self.error = err
                break

        self.stop()

    def stop(self):
        self.running = False
        self.stream.buffer.close()

    def start(self):
        self.running = True
        return Thread.start(self)


class FLVTagConcatIO(IOBase):
    __worker__ = FLVTagConcatWorker
    __log_name__ = "stream.flv_concat"

    def __init__(self, session, duration=None, tags=[], skip_header=False,
                 timeout=30, **concater_params):
        self.session = session
        self.timeout = timeout
        self.logger = session.logger.new_module(self.__log_name__)

        self.concater_params = concater_params
        self.duration = duration
        self.skip_header = skip_header
        self.tags = tags

    def open(self, iterator):
        self.buffer = RingBuffer(self.session.get_option("ringbuffer-size"))
        self.worker = self.__worker__(iterator, self)
        self.worker.start()

    def close(self):
        self.worker.stop()

        if self.worker.is_alive():
            self.worker.join()

    def read(self, size=-1):
        if not self.buffer:
            return b""

        if self.worker.error:
            raise self.worker.error

        return self.buffer.read(size, block=self.worker.is_alive(),
                                timeout=self.timeout)

########NEW FILE########
__FILENAME__ = hds
from __future__ import division

import base64
import hmac
import re
import os.path

from binascii import unhexlify
from collections import namedtuple
from hashlib import sha256
from io import BytesIO
from math import ceil

from .flvconcat import FLVTagConcat
from .segmented import (SegmentedStreamReader,
                        SegmentedStreamWriter,
                        SegmentedStreamWorker)
from .stream import Stream
from .wrappers import StreamIOIterWrapper

from ..cache import Cache
from ..compat import parse_qsl, urljoin, urlparse, bytes, range
from ..exceptions import StreamError
from ..utils import absolute_url, swfdecompress

from ..packages.flashmedia import F4V, F4VError
from ..packages.flashmedia.box import Box
from ..packages.flashmedia.tag import ScriptData, Tag, TAG_TYPE_SCRIPT

# Akamai HD player verification key
# Use unhexlify() rather than bytes.fromhex() for compatibility with before
# Python 3. However, in Python 3.2 (not 3.3+), unhexlify only accepts a byte
# string.
AKAMAIHD_PV_KEY = unhexlify(
    b"BD938D5EE6D9F42016F9C56577B6FDCF415FE4B184932B785AB32BCADC9BB592")

# Some streams hosted by Akamai seem to require a hdcore parameter
# to function properly.
HDCORE_VERSION = "3.1.0"

# Fragment URL format
FRAGMENT_URL = "{url}{identifier}{quality}Seg{segment}-Frag{fragment}"

Fragment = namedtuple("Fragment", "segment fragment duration url")


class HDSStreamWriter(SegmentedStreamWriter):
    def __init__(self, *args, **kwargs):
        SegmentedStreamWriter.__init__(self, *args, **kwargs)

        duration, tags = None, []
        if self.stream.metadata:
            duration = self.stream.metadata.value.get("duration")
            tags = [Tag(TAG_TYPE_SCRIPT, timestamp=0,
                        data=self.stream.metadata)]

        self.concater = FLVTagConcat(tags=tags,
                                     duration=duration,
                                     flatten_timestamps=True)
        self.segment_attempts = self.session.options.get("hds-segment-attempts")
        self.segment_timeout = self.session.options.get("hds-segment-timeout")

    def open_fragment(self, fragment, retries=3):
        if self.closed or not retries:
            return

        try:
            return self.session.http.get(fragment.url,
                                         stream=True,
                                         timeout=self.segment_timeout,
                                         exception=StreamError,
                                         **self.stream.request_params)
        except StreamError as err:
            self.logger.error("Failed to open fragment {0}-{1}: {2}",
                              fragment.segment, fragment.fragment, err)
            return self.open_fragment(fragment, retries - 1)

    def write(self, fragment, chunk_size=8192):
        res = self.open_fragment(fragment, self.segment_attempts)
        if not res:
            return

        fd = StreamIOIterWrapper(res.iter_content(8192))
        self.convert_fragment(fragment, fd)

    def convert_fragment(self, fragment, fd):
        mdat = None
        try:
            f4v = F4V(fd, raw_payload=True)
            # Fast forward to mdat box
            for box in f4v:
                if box.type == "mdat":
                    mdat = box.payload.data
                    break
        except F4VError as err:
            self.logger.error("Failed to parse fragment {0}-{1}: {2}",
                              fragment.segment, fragment.fragment, err)
            return

        if not mdat:
            self.logger.error("No MDAT box found in fragment {0}-{1}",
                              fragment.segment, fragment.fragment)
            return

        try:
            for chunk in self.concater.iter_chunks(buf=mdat, skip_header=True):
                self.reader.buffer.write(chunk)

                if self.closed:
                    break
            else:
                self.logger.debug("Download of fragment {0}-{1} complete",
                                  fragment.segment, fragment.fragment)
        except IOError as err:
            if "Unknown tag type" in str(err):
                self.logger.error("Unknown tag type found, this stream is "
                                  "probably encrypted")
                self.close()
                return

            self.logger.error("Error reading fragment {0}-{1}: {2}",
                              fragment.segment, fragment.fragment, err)


class HDSStreamWorker(SegmentedStreamWorker):
    def __init__(self, *args, **kwargs):
        SegmentedStreamWorker.__init__(self, *args, **kwargs)

        self.bootstrap = self.stream.bootstrap
        self.current_segment = -1
        self.current_fragment = -1
        self.first_fragment = 1
        self.last_fragment = -1
        self.end_fragment = None

        self.bootstrap_minimal_reload_time = 2.0
        self.bootstrap_reload_time = self.bootstrap_minimal_reload_time
        self.invalid_fragments = set()
        self.live_edge = self.session.options.get("hds-live-edge")

        self.update_bootstrap()

    def update_bootstrap(self):
        self.logger.debug("Updating bootstrap")

        if isinstance(self.bootstrap, Box):
            bootstrap = self.bootstrap
        else:
            bootstrap = self.fetch_bootstrap(self.bootstrap)

        self.live = bootstrap.payload.live
        self.profile = bootstrap.payload.profile
        self.timestamp = bootstrap.payload.current_media_time
        self.identifier = bootstrap.payload.movie_identifier
        self.time_scale = bootstrap.payload.time_scale
        self.segmentruntable = bootstrap.payload.segment_run_table_entries[0]
        self.fragmentruntable = bootstrap.payload.fragment_run_table_entries[0]

        self.first_fragment, last_fragment = self.fragment_count()
        fragment_duration = self.fragment_duration(last_fragment)

        if last_fragment != self.last_fragment:
            bootstrap_changed = True
            self.last_fragment = last_fragment
        else:
            bootstrap_changed = False

        if self.current_fragment < 0:
            if self.live:
                current_fragment = last_fragment

                # Less likely to hit edge if we don't start with last fragment,
                # default buffer is 10 sec.
                fragment_buffer = int(ceil(self.live_edge / fragment_duration))
                current_fragment = max(self.first_fragment,
                                       current_fragment - (fragment_buffer - 1))

                self.logger.debug("Live edge buffer {0} sec is {1} fragments",
                                  self.live_edge, fragment_buffer)

                # Make sure we don't have a duration set when it's a
                # live stream since it will just confuse players anyway.
                self.writer.concater.duration = None
            else:
                current_fragment = self.first_fragment

            self.current_fragment = current_fragment

        self.logger.debug("Current timestamp: {0}", self.timestamp / self.time_scale)
        self.logger.debug("Current segment: {0}", self.current_segment)
        self.logger.debug("Current fragment: {0}", self.current_fragment)
        self.logger.debug("First fragment: {0}", self.first_fragment)
        self.logger.debug("Last fragment: {0}", self.last_fragment)
        self.logger.debug("End fragment: {0}", self.end_fragment)

        self.bootstrap_reload_time = fragment_duration

        if self.live and not bootstrap_changed:
            self.logger.debug("Bootstrap not changed, shortening timer")
            self.bootstrap_reload_time /= 2

        self.bootstrap_reload_time = max(self.bootstrap_reload_time,
                                         self.bootstrap_minimal_reload_time)

    def fetch_bootstrap(self, url):
        res = self.session.http.get(url,
                                    exception=StreamError,
                                    **self.stream.request_params)
        return Box.deserialize(BytesIO(res.content))

    def fragment_url(self, segment, fragment):
        url = absolute_url(self.stream.baseurl, self.stream.url)
        return FRAGMENT_URL.format(url=url,
                                   segment=segment,
                                   fragment=fragment,
                                   identifier="",
                                   quality="")

    def fragment_count(self):
        table = self.fragmentruntable.payload.fragment_run_entry_table
        first_fragment, end_fragment = None, None

        for i, fragmentrun in enumerate(table):
            if fragmentrun.discontinuity_indicator is not None:
                if fragmentrun.discontinuity_indicator == 0:
                    break
                elif fragmentrun.discontinuity_indicator > 0:
                    continue

            if first_fragment is None:
                first_fragment = fragmentrun.first_fragment

            end_fragment = fragmentrun.first_fragment
            fragment_duration = (fragmentrun.first_fragment_timestamp +
                                 fragmentrun.fragment_duration)

            if self.timestamp > fragment_duration:
                offset = ((self.timestamp - fragment_duration) /
                          fragmentrun.fragment_duration)
                end_fragment += int(offset)

        if first_fragment is None:
            first_fragment = 1

        if end_fragment is None:
            end_fragment = 1

        return first_fragment, end_fragment

    def fragment_duration(self, fragment):
        fragment_duration = 0
        table = self.fragmentruntable.payload.fragment_run_entry_table
        time_scale = self.fragmentruntable.payload.time_scale

        for i, fragmentrun in enumerate(table):
            if fragmentrun.discontinuity_indicator is not None:
                self.invalid_fragments.add(fragmentrun.first_fragment)

                # Check for the last fragment of the stream
                if fragmentrun.discontinuity_indicator == 0:
                    if i > 0:
                        prev = table[i-1]
                        self.end_fragment = prev.first_fragment

                    break
                elif fragmentrun.discontinuity_indicator > 0:
                    continue

            if fragment >= fragmentrun.first_fragment:
                fragment_duration = fragmentrun.fragment_duration / time_scale

        return fragment_duration

    def segment_from_fragment(self, fragment):
        table = self.segmentruntable.payload.segment_run_entry_table

        for segment, start, end in self.iter_segment_table(table):
            if fragment >= (start + 1) and fragment <= (end + 1):
                break
        else:
            segment = 1

        return segment

    def iter_segment_table(self, table):
        # If the first segment in the table starts at the beginning we
        # can go from there, otherwise we start from the end and use the
        # total fragment count to figure out where the last segment ends.
        if table[0].first_segment == 1:
            prev_frag = self.first_fragment - 1
            for segmentrun in table:
                start = prev_frag + 1
                end = prev_frag + segmentrun.fragments_per_segment

                yield segmentrun.first_segment, start, end
                prev_frag = end
        else:
            prev_frag = self.last_fragment + 1
            for segmentrun in reversed(table):
                start = prev_frag - segmentrun.fragments_per_segment
                end = prev_frag - 1

                yield segmentrun.first_segment, start, end
                prev_frag = start

    def valid_fragment(self, fragment):
        return fragment not in self.invalid_fragments

    def iter_segments(self):
        while not self.closed:
            fragments = range(self.current_fragment, self.last_fragment + 1)
            fragments = filter(self.valid_fragment, fragments)

            for fragment in fragments:
                self.current_fragment = fragment + 1
                self.current_segment = self.segment_from_fragment(fragment)

                fragment_duration = int(self.fragment_duration(fragment) * 1000)
                fragment_url = self.fragment_url(self.current_segment, fragment)
                fragment = Fragment(self.current_segment, fragment,
                                    fragment_duration, fragment_url)

                self.logger.debug("Adding fragment {0}-{1} to queue",
                                  fragment.segment, fragment.fragment)
                yield fragment

                # End of stream
                stream_end = self.end_fragment and fragment.fragment >= self.end_fragment
                if self.closed or stream_end:
                    return

            if self.wait(self.bootstrap_reload_time):
                try:
                    self.update_bootstrap()
                except StreamError as err:
                    self.logger.warning("Failed to update bootstrap: {0}", err)


class HDSStreamReader(SegmentedStreamReader):
    __worker__ = HDSStreamWorker
    __writer__ = HDSStreamWriter

    def __init__(self, stream, *args, **kwargs):
        SegmentedStreamReader.__init__(self, stream, *args, **kwargs)

        self.logger = stream.session.logger.new_module("stream.hds")


class HDSStream(Stream):
    """
    Implements the Adobe HTTP Dynamic Streaming protocol

    *Attributes:*

    - :attr:`baseurl` Base URL
    - :attr:`url` Base path of the stream, joined with the base URL when
      fetching fragments
    - :attr:`bootstrap` Either a URL pointing to the bootstrap or a
      bootstrap :class:`Box` object used for initial information about
      the stream
    - :attr:`metadata` Either `None` or a :class:`ScriptData` object
      that contains metadata about the stream, such as height, width and
      bitrate
    """

    __shortname__ = "hds"

    def __init__(self, session, baseurl, url, bootstrap, metadata=None,
                 timeout=60, **request_params):
        Stream.__init__(self, session)

        self.baseurl = baseurl
        self.url = url
        self.bootstrap = bootstrap
        self.metadata = metadata
        self.timeout = timeout
        self.request_params = request_params

    def __repr__(self):
        return ("<HDSStream({0!r}, {1!r}, {2!r},"
                " metadata={3!r}, timeout={4!r})>").format(self.baseurl,
                                                           self.url,
                                                           self.bootstrap,
                                                           self.metadata,
                                                           self.timeout)

    def __json__(self):
        if isinstance(self.bootstrap, Box):
            bootstrap = base64.b64encode(self.bootstrap.serialize())
        else:
            bootstrap = self.bootstrap

        if isinstance(self.metadata, ScriptData):
            metadata = self.metadata.__dict__
        else:
            metadata = self.metadata

        return dict(type=HDSStream.shortname(), baseurl=self.baseurl,
                    url=self.url, bootstrap=bootstrap, metadata=metadata)

    def open(self):
        reader = HDSStreamReader(self)
        reader.open()
        return reader

    @classmethod
    def parse_manifest(cls, session, url, timeout=60, pvswf=None,
                       **request_params):
        """Parses a HDS manifest and returns its substreams.

        :param url: The URL to the manifest.
        :param timeout: How long to wait for data to be returned from
                        from the stream before raising an error.
        :param pvswf: URL of player SWF for Akamai HD player verification.
        """

        if not request_params:
            request_params = {}
            request_params["headers"] = {}
            request_params["params"] = {}

        # These params are reserved for internal use
        request_params.pop("exception", None)
        request_params.pop("stream", None)
        request_params.pop("timeout", None)
        request_params.pop("url", None)

        if "akamaihd" in url:
            request_params["params"]["hdcore"] = HDCORE_VERSION

        res = session.http.get(url, exception=IOError, **request_params)
        manifest = session.http.xml(res, "manifest XML", ignore_ns=True,
                                    exception=IOError)

        parsed = urlparse(url)
        baseurl = manifest.findtext("baseURL")
        baseheight = manifest.findtext("height")
        bootstraps = {}
        streams = {}

        if not baseurl:
            baseurl = urljoin(url, os.path.dirname(parsed.path)) + "/"

        for bootstrap in manifest.findall("bootstrapInfo"):
            name = bootstrap.attrib.get("id") or "_global"
            url = bootstrap.attrib.get("url")

            if url:
                box = absolute_url(baseurl, url)
            else:
                data = base64.b64decode(bytes(bootstrap.text, "utf8"))
                box = Box.deserialize(BytesIO(data))

            bootstraps[name] = box

        pvtoken = manifest.findtext("pv-2.0")
        if pvtoken:
            if not pvswf:
                raise IOError("This manifest requires the 'pvswf' parameter "
                              "to verify the SWF")

            params = cls._pv_params(session, pvswf, pvtoken)
            request_params["params"].update(params)

        for media in manifest.findall("media"):
            url = media.attrib.get("url")
            bootstrapid = media.attrib.get("bootstrapInfoId", "_global")
            href = media.attrib.get("href")

            if url and bootstrapid:
                bootstrap = bootstraps.get(bootstrapid)

                if not bootstrap:
                    continue

                bitrate = media.attrib.get("bitrate")
                streamid = media.attrib.get("streamId")
                height = media.attrib.get("height")

                if height:
                    quality = height + "p"
                elif bitrate:
                    quality = bitrate + "k"
                elif streamid:
                    quality = streamid
                elif baseheight:
                    quality = baseheight + "p"
                else:
                    quality = "live"

                metadata = media.findtext("metadata")

                if metadata:
                    metadata = base64.b64decode(bytes(metadata, "utf8"))
                    metadata = ScriptData.deserialize(BytesIO(metadata))
                else:
                    metadata = None

                stream = HDSStream(session, baseurl, url, bootstrap,
                                   metadata=metadata, timeout=timeout,
                                   **request_params)
                streams[quality] = stream

            elif href:
                url = absolute_url(baseurl, href)
                child_streams = cls.parse_manifest(session, url,
                                                   timeout=timeout,
                                                   **request_params)

                for name, stream in child_streams.items():
                    # Override stream name if bitrate is available in parent
                    # manifest but not the child one.
                    bitrate = media.attrib.get("bitrate")

                    if bitrate and not re.match("^(\d+)k$", name):
                        name = bitrate + "k"

                    streams[name] = stream

        return streams

    @classmethod
    def _pv_params(cls, session, pvswf, pv):
        """Returns any parameters needed for Akamai HD player verification.

        Algorithm originally documented by KSV, source:
        http://stream-recorder.com/forum/showpost.php?p=43761&postcount=13
        """

        (data, hdntl) = pv.split(";")
        cache = Cache(filename="stream.json")
        key = "akamaihd-player:" + pvswf
        cached = cache.get(key)

        headers = dict()
        if cached:
            headers["If-Modified-Since"] = cached["modified"]
        swf = session.http.get(pvswf, headers=headers)

        if cached and swf.status_code == 304:  # Server says not modified
            hash = cached["hash"]
        else:
            # Calculate SHA-256 hash of the uncompressed SWF file, base-64
            # encoded
            hash = sha256()
            hash.update(swfdecompress(swf.content))
            hash = base64.b64encode(hash.digest()).decode("ascii")
            modified = swf.headers.get("Last-Modified", "")

            # Only save in cache if a valid date is given
            if len(modified) < 40:
                cache.set(key, dict(hash=hash, modified=modified))

        msg = "st=0~exp=9999999999~acl=*~data={0}!{1}".format(data, hash)
        auth = hmac.new(AKAMAIHD_PV_KEY, msg.encode("ascii"), sha256)
        pvtoken = "{0}~hmac={1}".format(msg, auth.hexdigest())

        # The "hdntl" parameter can be accepted as a cookie or passed in the
        # query string, but the "pvtoken" parameter can only be in the query
        # string
        params = [("pvtoken", pvtoken)]
        params.extend(parse_qsl(hdntl, keep_blank_values=True))

        return params


########NEW FILE########
__FILENAME__ = hls
from collections import defaultdict, namedtuple

try:
    from Crypto.Cipher import AES
    import struct

    def num_to_iv(n):
        return struct.pack(">8xq", n)

    CAN_DECRYPT = True
except ImportError:
    CAN_DECRYPT = False

from . import hls_playlist
from .http import HTTPStream
from .segmented import (SegmentedStreamReader,
                        SegmentedStreamWriter,
                        SegmentedStreamWorker)
from ..exceptions import StreamError


Sequence = namedtuple("Sequence", "num segment")


class HLSStreamWriter(SegmentedStreamWriter):
    def __init__(self, *args, **kwargs):
        SegmentedStreamWriter.__init__(self, *args, **kwargs)

        self.byterange_offsets = defaultdict(int)
        self.key_data = None
        self.key_uri = None
        self.segment_attempts = self.session.options.get("hls-segment-attempts")
        self.segment_timeout = self.session.options.get("hls-segment-timeout")

    def open_sequence(self, sequence, retries=3):
        if self.closed or not retries:
            return

        try:
            request_params = self.create_request_params(sequence)
            return self.session.http.get(sequence.segment.uri,
                                         timeout=self.segment_timeout,
                                         exception=StreamError,
                                         **request_params)
        except StreamError as err:
            self.logger.error("Failed to open segment {0}: {1}", sequence.num, err)
            return self.open_sequence(sequence, retries - 1)

    def create_decryptor(self, key, sequence):
        if key.method != "AES-128":
            raise StreamError("Unable to decrypt cipher {0}", key.method)

        if not key.uri:
            raise StreamError("Missing URI to decryption key")

        if self.key_uri != key.uri:
            res = self.session.http.get(key.uri, exception=StreamError,
                                        **self.reader.request_params)
            self.key_data = res.content
            self.key_uri = key.uri

        iv = key.iv or num_to_iv(sequence)
        return AES.new(self.key_data, AES.MODE_CBC, iv)

    def create_request_params(self, sequence):
        request_params = dict(self.reader.request_params)
        headers = request_params.pop("headers", {})

        if sequence.segment.byterange:
            bytes_start = self.byterange_offsets[sequence.segment.uri]
            if sequence.segment.byterange.offset is not None:
                bytes_start = sequence.segment.byterange.offset

            bytes_len = max(sequence.segment.byterange.range - 1, 0)
            bytes_end = bytes_start + bytes_len
            headers["Range"] = "bytes={0}-{1}".format(bytes_start, bytes_end)
            self.byterange_offsets[sequence.segment.uri] = bytes_end + 1

        request_params["headers"] = headers

        return request_params

    def write(self, sequence, chunk_size=8192):
        res = self.open_sequence(sequence, self.segment_attempts)
        if not res:
            return

        if sequence.segment.key and sequence.segment.key.method != "NONE":
            try:
                decryptor = self.create_decryptor(sequence.segment.key,
                                                  sequence.num)
            except StreamError as err:
                self.logger.error("Failed to create decryptor: {0}", err)
                self.close()
                return

            # If the input data is not a multiple of 16, cut off any garbage
            garbage_len = len(res.content) % 16
            if garbage_len:
                self.logger.debug("Cutting off {0} bytes of garbage "
                                  "before decrypting", garbage_len)
                content = decryptor.decrypt(res.content[:-(garbage_len)])
            else:
                content = decryptor.decrypt(res.content)
        else:
            content = res.content

        self.reader.buffer.write(content)
        self.logger.debug("Download of segment {0} complete", sequence.num)

class HLSStreamWorker(SegmentedStreamWorker):
    def __init__(self, *args, **kwargs):
        SegmentedStreamWorker.__init__(self, *args, **kwargs)

        self.playlist_changed = False
        self.playlist_end = None
        self.playlist_sequence = -1
        self.playlist_sequences = []
        self.playlist_reload_time = 15
        self.live_edge = self.session.options.get("hls-live-edge")

        self.reload_playlist()

    def reload_playlist(self):
        if self.closed:
            return

        self.reader.buffer.wait_free()
        self.logger.debug("Reloading playlist")
        res = self.session.http.get(self.stream.url,
                                    exception=StreamError,
                                    **self.reader.request_params)

        try:
            playlist = hls_playlist.load(res.text, self.reader.stream.url)
        except ValueError as err:
            raise StreamError(err)

        if playlist.is_master:
            raise StreamError("Attempted to play a variant playlist, use "
                              "'hlsvariant://{0}' instead".format(self.stream.url))

        if playlist.iframes_only:
            raise StreamError("Streams containing I-frames only is not playable")

        media_sequence = playlist.media_sequence or 0
        sequences = [Sequence(media_sequence + i, s)
                     for i, s in enumerate(playlist.segments)]

        if sequences:
            self.process_sequences(playlist, sequences)

    def process_sequences(self, playlist, sequences):
        first_sequence, last_sequence = sequences[0], sequences[-1]

        if (first_sequence.segment.key and
            first_sequence.segment.key.method != "NONE"):

            self.logger.debug("Segments in this playlist are encrypted")
            if not CAN_DECRYPT:
                raise StreamError("Need pyCrypto installed to decrypt this stream")

        self.playlist_changed = ([s.num for s in self.playlist_sequences] !=
                                 [s.num for s in sequences])
        self.playlist_reload_time = (playlist.target_duration or
                                     last_sequence.segment.duration)
        self.playlist_sequences = sequences

        if not self.playlist_changed:
            self.playlist_reload_time = max(self.playlist_reload_time / 2, 1)

        if playlist.is_endlist:
            self.playlist_end = last_sequence.num

        if self.playlist_sequence < 0:
            if self.playlist_end is None:
                edge_index = -(min(len(sequences), max(int(self.live_edge), 1)))
                edge_sequence = sequences[edge_index]
                self.playlist_sequence = edge_sequence.num
            else:
                self.playlist_sequence = first_sequence.num

    def valid_sequence(self, sequence):
        return sequence.num >= self.playlist_sequence

    def iter_segments(self):
        while not self.closed:
            for sequence in filter(self.valid_sequence, self.playlist_sequences):
                self.logger.debug("Adding segment {0} to queue", sequence.num)
                yield sequence

                # End of stream
                stream_end = self.playlist_end and sequence.num >= self.playlist_end
                if self.closed or stream_end:
                    return

                self.playlist_sequence = sequence.num + 1

            if self.wait(self.playlist_reload_time):
                try:
                    self.reload_playlist()
                except StreamError as err:
                    self.logger.warning("Failed to reload playlist: {0}", err)


class HLSStreamReader(SegmentedStreamReader):
    __worker__ = HLSStreamWorker
    __writer__ = HLSStreamWriter

    def __init__(self, stream, *args, **kwargs):
        SegmentedStreamReader.__init__(self, stream, *args, **kwargs)
        self.logger = stream.session.logger.new_module("stream.hls")
        self.request_params = dict(stream.args)
        self.timeout = stream.session.options.get("hls-timeout")

        # These params are reserved for internal use
        self.request_params.pop("exception", None)
        self.request_params.pop("stream", None)
        self.request_params.pop("timeout", None)
        self.request_params.pop("url", None)


class HLSStream(HTTPStream):
    """Implementation of the Apple HTTP Live Streaming protocol

    *Attributes:*

    - :attr:`url` The URL to the HLS playlist.
    - :attr:`args` A :class:`dict` containing keyword arguments passed
                   to :meth:`requests.request`, such as headers and
                   cookies.

    .. versionchanged:: 1.7.0
       Added *args* attribute.

    """

    __shortname__ = "hls"

    def __init__(self, session_, url, **args):
        HTTPStream.__init__(self, session_, url, **args)

    def __repr__(self):
        return "<HLSStream({0!r})>".format(self.url)

    def __json__(self):
        json = HTTPStream.__json__(self)

        # Pretty sure HLS is GET only.
        del json["method"]
        del json["body"]

        return json

    def open(self):
        reader = HLSStreamReader(self)
        reader.open()

        return reader

    @classmethod
    def parse_variant_playlist(cls, session_, url, namekey="name",
                               nameprefix="", **request_params):
        res = session_.http.get(url, exception=IOError, **request_params)

        try:
            parser = hls_playlist.load(res.text, base_uri=url)
        except ValueError as err:
            raise IOError("Failed to parse playlist: {0}".format(err))

        streams = {}
        for playlist in filter(lambda p: not p.is_iframe, parser.playlists):
            names = dict(name=None, pixels=None, bitrate=None)

            for media in playlist.media:
                if media.type == "VIDEO" and media.name:
                    names["name"] = media.name

            if playlist.stream_info.resolution:
                width, height = playlist.stream_info.resolution
                names["pixels"] = "{0}p".format(height)

            if playlist.stream_info.bandwidth:
                bw = playlist.stream_info.bandwidth

                if bw >= 1000:
                    names["bitrate"] = "{0}k".format(int(bw/1000.0))
                else:
                    names["bitrate"] = "{0}k".format(bw/1000.0)

            stream_name = (names.get(namekey) or names.get("name") or
                           names.get("pixels") or names.get("bitrate"))

            if not stream_name or stream_name in streams:
                continue

            stream = HLSStream(session_, playlist.uri, **request_params)
            streams[nameprefix + stream_name] = stream

        return streams


########NEW FILE########
__FILENAME__ = hls_playlist
import re

from binascii import unhexlify
from collections import namedtuple
from itertools import starmap

try:
    from urlparse import urljoin
except ImportError:
    from urllib.parse import urljoin

__all__ = ["load", "M3U8Parser"]


# EXT-X-BYTERANGE
ByteRange = namedtuple("ByteRange", "range offset")

# EXT-X-KEY
Key = namedtuple("Key", "method uri iv key_format key_format_versions")

# EXT-X-MAP
Map = namedtuple("Map", "uri byterange")

# EXT-X-MEDIA
Media = namedtuple("Media", "uri type group_id language name default "
                            "autoselect forced characteristics")

# EXT-X-START
Start = namedtuple("Start", "time_offset precise")

# EXT-X-STREAM-INF
StreamInfo = namedtuple("StreamInfo", "bandwidth program_id codecs resolution "
                                      "audio video subtitles")

# EXT-X-I-FRAME-STREAM-INF
IFrameStreamInfo = namedtuple("IFrameStreamInfo", "bandwidth program_id "
                                                  "codecs resolution video")

Playlist = namedtuple("Playlist", "uri stream_info media is_iframe")
Resolution = namedtuple("Resolution", "width height")
Segment = namedtuple("Segment", "uri duration title key discontinuity "
                                "byterange date map")

ATTRIBUTE_REGEX = (r"([A-Z\-]+)=(\d+\.\d+|0x[0-9A-z]+|\d+x\d+|\d+|"
                   r"\"(.+?)\"|[0-9A-z\-]+)")


class M3U8(object):
    def __init__(self):
        self.is_endlist = False
        self.is_master = False

        self.allow_cache = None
        self.discontinuity_sequence = None
        self.iframes_only = None
        self.media_sequence = None
        self.playlist_type = None
        self.target_duration = None
        self.start = None
        self.version = None

        self.media = []
        self.playlists = []
        self.segments = []


class M3U8Parser(object):
    def __init__(self, base_uri=None):
        self.base_uri = base_uri

    def create_stream_info(self, streaminf, cls=None):
        program_id = streaminf.get("PROGRAM-ID")
        if program_id:
            program_id = int(program_id)

        bandwidth = streaminf.get("BANDWIDTH")
        if bandwidth:
            bandwidth = int(bandwidth)

        resolution = streaminf.get("RESOLUTION")
        if resolution:
            resolution = self.parse_resolution(resolution)

        codecs = streaminf.get("CODECS")
        if codecs:
            codecs = codecs.split(",")
        else:
            codecs = []

        if cls == IFrameStreamInfo:
            return IFrameStreamInfo(bandwidth, program_id, codecs, resolution,
                                    streaminf.get("VIDEO"))
        else:
            return StreamInfo(bandwidth, program_id, codecs, resolution,
                              streaminf.get("AUDIO"), streaminf.get("VIDEO"),
                              streaminf.get("SUBTITLES"))

    def split_tag(self, line):
        match = re.match("#(?P<tag>[\w-]+)(:(?P<value>.+))?", line)

        if match:
            return match.group("tag"), match.group("value").strip()

        return None, None

    def parse_attributes(self, value):
        def map_attribute(key, value, quoted):
            return (key, quoted or value)

        attr = re.findall(ATTRIBUTE_REGEX, value)

        return dict(starmap(map_attribute, attr))

    def parse_bool(self, value):
        return value == "YES"

    def parse_byterange(self, value):
        match = re.match("(?P<range>\d+)(@(?P<offset>.+))?", value)

        if match:
            return ByteRange(int(match.group("range")),
                             int(match.group("offset") or 0))

    def parse_extinf(self, value):
        match = re.match("(?P<duration>\d+(\.\d+)?)(,(?P<title>.+))?", value)
        if match:
            return float(match.group("duration")), match.group("title")

    def parse_hex(self, value):
        return unhexlify(value[2:])

    def parse_resolution(self, value):
        match = re.match("(\d+)x(\d+)", value)

        if match:
            width, height = int(match.group(1)), int(match.group(2))
        else:
            width, height = 0, 0

        return Resolution(width, height)

    def parse_tag(self, line, transform=None):
        tag, value = self.split_tag(line)

        if transform:
            value = transform(value)

        return value

    def parse_line(self, lineno, line):
        if lineno == 0 and not line.startswith("#EXTM3U"):
            raise ValueError("Missing #EXTM3U header")

        if not line.startswith("#"):
            if self.state.pop("expect_segment", None):
                byterange = self.state.pop("byterange", None)
                extinf = self.state.pop("extinf", (0, None))
                date = self.state.pop("date", None)
                map_ = self.state.get("map")
                key = self.state.get("key")

                segment = Segment(self.uri(line), extinf[0],
                                  extinf[1], key,
                                  self.state.pop("discontinuity", False),
                                  byterange, date, map_)
                self.m3u8.segments.append(segment)
            elif self.state.pop("expect_playlist", None):
                streaminf = self.state.pop("streaminf", {})
                stream_info = self.create_stream_info(streaminf)
                playlist = Playlist(self.uri(line), stream_info, [], False)
                self.m3u8.playlists.append(playlist)
        elif line.startswith("#EXTINF"):
            self.state["expect_segment"] = True
            self.state["extinf"] = self.parse_tag(line, self.parse_extinf)
        elif line.startswith("#EXT-X-BYTERANGE"):
            self.state["expect_segment"] = True
            self.state["byterange"] = self.parse_tag(line, self.parse_byterange)
        elif line.startswith("#EXT-X-TARGETDURATION"):
            self.m3u8.target_duration = self.parse_tag(line, int)
        elif line.startswith("#EXT-X-MEDIA-SEQUENCE"):
            self.m3u8.media_sequence = self.parse_tag(line, int)
        elif line.startswith("#EXT-X-KEY"):
            attr = self.parse_tag(line, self.parse_attributes)
            iv = attr.get("IV")
            if iv: iv = self.parse_hex(iv)
            self.state["key"] = Key(attr.get("METHOD"),
                                    self.uri(attr.get("URI")),
                                    iv, attr.get("KEYFORMAT"),
                                    attr.get("KEYFORMATVERSIONS"))
        elif line.startswith("#EXT-X-PROGRAM-DATE-TIME"):
            self.state["date"] = self.parse_tag(line)
        elif line.startswith("#EXT-X-ALLOW-CACHE"):
            self.m3u8.allow_cache = self.parse_tag(line, self.parse_bool)
        elif line.startswith("#EXT-X-STREAM-INF"):
            self.state["streaminf"] = self.parse_tag(line, self.parse_attributes)
            self.state["expect_playlist"] = True
        elif line.startswith("#EXT-X-PLAYLIST-TYPE"):
            self.m3u8.playlist_type = self.parse_tag(line)
        elif line.startswith("#EXT-X-ENDLIST"):
            self.m3u8.is_endlist = True
        elif line.startswith("#EXT-X-MEDIA"):
            attr = self.parse_tag(line, self.parse_attributes)
            media = Media(self.uri(attr.get("URI")), attr.get("TYPE"),
                          attr.get("GROUP-ID"), attr.get("LANGUAGE"),
                          attr.get("NAME"),
                          self.parse_bool(attr.get("DEFAULT")),
                          self.parse_bool(attr.get("AUTOSELECT")),
                          self.parse_bool(attr.get("FORCED")),
                          attr.get("CHARACTERISTICS"))
            self.m3u8.media.append(media)
        elif line.startswith("#EXT-X-DISCONTINUITY"):
            self.state["discontinuity"] = True
            self.state["map"] = None
        elif line.startswith("#EXT-X-DISCONTINUITY-SEQUENCE"):
            self.m3u8.discontinuity_sequence = self.parse_tag(line, int)
        elif line.startswith("#EXT-X-I-FRAMES-ONLY"):
            self.m3u8.iframes_only = True
        elif line.startswith("#EXT-X-MAP"):
            attr = self.parse_tag(line, self.parse_attributes)
            byterange = self.parse_byterange(attr.get("BYTERANGE", ""))
            self.state["map"] = Map(attr.get("URI"), byterange)
        elif line.startswith("#EXT-X-I-FRAME-STREAM-INF"):
            attr = self.parse_tag(line, self.parse_attributes)
            streaminf = self.state.pop("streaminf", attr)
            stream_info = self.create_stream_info(streaminf, IFrameStreamInfo)
            playlist = Playlist(self.uri(attr.get("URI")), stream_info, [], True)
            self.m3u8.playlists.append(playlist)
        elif line.startswith("#EXT-X-VERSION"):
            self.m3u8.version = self.parse_tag(line, int)
        elif line.startswith("#EXT-X-START"):
            attr = self.parse_tag(line, self.parse_attributes)
            start = Start(attr.get("TIME-OFFSET"),
                          self.parse_bool(attr.get("PRECISE", "NO")))
            self.m3u8.start = start

    def parse(self, data):
        self.state = {}
        self.m3u8 = M3U8()

        for lineno, line in enumerate(filter(bool, data.splitlines())):
            self.parse_line(lineno, line)

        # Associate Media entries with each Playlist
        for playlist in self.m3u8.playlists:
            for media_type in ("audio", "video", "subtitles"):
                group_id = getattr(playlist.stream_info, media_type, None)
                if group_id:
                    for media in filter(lambda m: m.group_id == group_id,
                                        self.m3u8.media):
                        playlist.media.append(media)

        self.m3u8.is_master = not not self.m3u8.playlists

        return self.m3u8

    def uri(self, uri):
        if uri and uri.startswith("http"):
            return uri
        elif self.base_uri and uri:
            return urljoin(self.base_uri, uri)
        else:
            return uri


def load(data, base_uri=None, parser=M3U8Parser):
    """Attempts to parse a M3U8 playlist from a string of data.

    If specified, *base_uri* is the base URI that relative URIs will
    be joined together with, otherwise relative URIs will be as is.

    If specified, *parser* can be a M3U8Parser subclass to be used
    to parse the data.

    """
    return parser(base_uri).parse(data)

########NEW FILE########
__FILENAME__ = http
import inspect

import requests

from .stream import Stream
from .wrappers import StreamIOIterWrapper
from ..exceptions import StreamError


def normalize_key(keyval):
    key, val = keyval
    key = hasattr(key, "decode") and key.decode("utf8", "ignore") or key

    return key, val


def valid_args(args):
    argspec = inspect.getargspec(requests.Request.__init__)

    return dict(filter(lambda kv: kv[0] in argspec.args, args.items()))


class HTTPStream(Stream):
    """A HTTP stream using the requests library.

    *Attributes:*

    - :attr:`url`  The URL to the stream, prepared by requests.
    - :attr:`args` A :class:`dict` containing keyword arguments passed
                   to :meth:`requests.request`, such as headers and
                   cookies.

    """

    __shortname__ = "http"

    def __init__(self, session_, url, **args):
        Stream.__init__(self, session_)

        self.args = dict(url=url, **args)

    def __repr__(self):
        return "<HTTPStream({0!r})>".format(self.url)

    def __json__(self):
        method = self.args.get("method", "GET")
        req = requests.Request(method=method, **valid_args(self.args))

        # prepare_request is only available in requests 2.0+
        if hasattr(self.session.http, "prepare_request"):
            req = self.session.http.prepare_request(req)
        else:
            req = req.prepare()

        headers = dict(map(normalize_key, req.headers.items()))

        return dict(type=type(self).shortname(), url=req.url,
                    method=req.method, headers=headers,
                    body=req.body)

    @property
    def url(self):
        method = self.args.get("method", "GET")
        return requests.Request(method=method,
                                **valid_args(self.args)).prepare().url

    def open(self):
        method = self.args.get("method", "GET")
        timeout = self.session.options.get("http-timeout")
        res = self.session.http.request(method=method,
                                        stream=True,
                                        exception=StreamError,
                                        timeout=timeout,
                                        **self.args)

        return StreamIOIterWrapper(res.iter_content(8192))


########NEW FILE########
__FILENAME__ = playlist
from .flvconcat import FLVTagConcatIO
from .stream import Stream
from ..exceptions import StreamError

__all__ = ["Playlist", "FLVPlaylist"]

class Playlist(Stream):
    """Abstract base class for playlist type streams."""

    __shortname__ = "playlist"

    def __init__(self, session, streams, duration=None):
        Stream.__init__(self, session)

        self.streams = streams
        self.duration = duration

    def open(self):
        raise NotImplementedError

    def __json__(self):
        return dict(streams=self.streams, duration=self.duration,
                    **Stream.__json__(self))


class FLVPlaylistIO(FLVTagConcatIO):
    __log_name__ = "stream.flv_playlist"

    def open(self, streams):
        def generator():
            for stream in streams:
                self.logger.debug("Opening substream: {0}", stream)

                try:
                    fd = stream.open()
                except StreamError as err:
                    self.logger.error("Failed to open stream: {0}", err)
                    continue

                yield fd

        return FLVTagConcatIO.open(self, generator())


class FLVPlaylist(Playlist):
    __shortname__ = "flv_playlist"

    def __init__(self, session, streams, duration=None, tags=None,
                 skip_header=False, **concater_params):
        Playlist.__init__(self, session, streams, duration)

        if not tags:
            tags = []

        self.tags = tags
        self.skip_header = skip_header
        self.concater_params = concater_params

    def open(self):
        fd = FLVPlaylistIO(self.session,
                           tags=self.tags,
                           duration=self.duration,
                           skip_header=self.skip_header,
                           **self.concater_params)
        fd.open(self.streams)

        return fd


########NEW FILE########
__FILENAME__ = rtmpdump
from .streamprocess import StreamProcess
from ..compat import str, urljoin
from ..exceptions import StreamError
from ..packages import pbs as sh
from ..utils import rtmpparse

from time import sleep

import re

class RTMPStream(StreamProcess):
    """RTMP stream using rtmpdump.

    *Attributes:*

    - :attr:`params` A :class:`dict` containing parameters passed to rtmpdump
    """

    __shortname__ = "rtmp"

    def __init__(self, session, params, redirect=False):
        StreamProcess.__init__(self, session, params)

        self.cmd = self.session.options.get("rtmp-rtmpdump")
        self.timeout = self.session.options.get("rtmp-timeout")
        self.redirect = redirect
        self.logger = session.logger.new_module("stream.rtmp")

    def __repr__(self):
        return ("<RTMPStream({0!r}, redirect={1!r}>").format(self.params,
                                                             self.redirect)

    def __json__(self):
        return dict(type=RTMPStream.shortname(), params=self.params)

    def open(self):
        if self.session.options.get("rtmp-proxy"):
            if not self._supports_param("socks"):
                raise StreamError("Installed rtmpdump does not support --socks argument")

            self.params["socks"] = self.session.options.get("rtmpdump-proxy")

        if "jtv" in self.params and not self._supports_param("jtv"):
            raise StreamError("Installed rtmpdump does not support --jtv argument")

        if "weeb" in self.params and not self._supports_param("weeb"):
            raise StreamError("Installed rtmpdump does not support --weeb argument")

        if self.redirect:
            self._check_redirect()

        self.params["flv"] = "-"

        return StreamProcess.open(self)

    def _check_redirect(self, timeout=20):
        cmd = self._check_cmd()

        params = self.params.copy()
        params["verbose"] = True
        params["_bg"] = True

        self.logger.debug("Attempting to find tcURL redirect")

        stream = cmd(**params)

        elapsed = 0
        process_alive = True

        while elapsed < timeout and process_alive:
            process_alive = stream.process.returncode is None

            sleep(0.25)
            elapsed += 0.25

        if process_alive:
            try:
                stream.process.kill()
            except:
                pass

        try:
            stderr = stream.stderr()
        except sh.ErrorReturnCode as err:
            self._update_redirect(err.stderr)

    def _update_redirect(self, stderr):
        tcurl, redirect = None, None
        stderr = str(stderr, "utf8")

        m = re.search("DEBUG: Property: <Name:\s+redirect,\s+STRING:\s+(\w+://.+?)>", stderr)
        if m:
            redirect = m.group(1)

        if redirect:
            self.logger.debug("Found redirect tcUrl: {0}", redirect)

            if "rtmp" in self.params:
                tcurl, playpath = rtmpparse(self.params["rtmp"])
                rtmp = urljoin(redirect, playpath)
                self.params["rtmp"] = rtmp

            if "tcUrl" in self.params:
                self.params["tcUrl"] = redirect

    def _supports_param(self, param):
        cmd = self._check_cmd()

        try:
            help = cmd(help=True, _err_to_out=True)
        except sh.ErrorReturnCode as err:
            err = str(err.stdout, "ascii")
            raise StreamError("Error while checking rtmpdump compatibility: {0}".format(err))

        for line in help.splitlines():
            m = re.match("^--(\w+)", line)

            if not m:
                continue

            if m.group(1) == param:
                return True

        return False

    @classmethod
    def is_usable(cls, session):
        cmd = session.options.get("rtmp-rtmpdump")

        return StreamProcess.is_usable(cmd)



########NEW FILE########
__FILENAME__ = segmented
from threading import Thread, Event

from .stream import StreamIO
from ..buffers import RingBuffer
from ..compat import queue



class SegmentedStreamWorker(Thread):
    """The general worker thread.

    This thread is responsible for queueing up segments in the
    writer thread.
    """

    def __init__(self, reader):
        self.closed = False
        self.reader = reader
        self.writer = reader.writer
        self.stream = reader.stream
        self.session = reader.stream.session
        self.logger = reader.logger

        self._wait = None

        Thread.__init__(self)
        self.daemon = True

    def close(self):
        """Shuts down the thread."""
        if not self.closed:
            self.logger.debug("Closing worker thread")

        self.closed = True
        if self._wait:
            self._wait.set()

    def wait(self, time):
        """Pauses the thread for a specified time.

        Returns False if interrupted by another thread and True if the
        time runs out normally.
        """
        self._wait = Event()
        return not self._wait.wait(time)

    def iter_segments(self):
        """The iterator that generates segments for the worker thread.

        Should be overridden by the inheriting class.
        """
        return
        yield

    def run(self):
        for segment in self.iter_segments():
            self.writer.put(segment)

        # End of stream, tells the writer to exit
        self.writer.put(None)
        self.close()


class SegmentedStreamWriter(Thread):
    """The writer thread.

    This thread is responsible for fetching segments, processing them
    and finally writing the data to the buffer.
    """

    def __init__(self, reader, size=10):
        self.closed = False
        self.queue = queue.Queue(size)
        self.reader = reader
        self.stream = reader.stream
        self.session = reader.stream.session
        self.logger = reader.logger

        Thread.__init__(self)
        self.daemon = True

    def close(self):
        """Shuts down the thread."""
        if not self.closed:
            self.logger.debug("Closing writer thread")

        self.closed = True
        self.reader.buffer.close()

    def put(self, segment):
        """Add a segment to the queue."""
        while not self.closed:
            try:
                self.queue.put(segment, block=True, timeout=1)
                break
            except queue.Full:
                continue

    def write(self, segment):
        """Write the segment to the buffer.

        Should be overridden by the inheriting class.
        """
        pass

    def run(self):
        while not self.closed:
            try:
                segment = self.queue.get(block=True, timeout=0.5)
            except queue.Empty:
                continue

            if segment is not None:
                self.write(segment)
            else:
                break

        self.close()


class SegmentedStreamReader(StreamIO):
    __worker__ = SegmentedStreamWorker
    __writer__ = SegmentedStreamWriter

    def __init__(self, stream, timeout=60):
        StreamIO.__init__(self)

        self.session = stream.session
        self.stream = stream
        self.timeout = timeout

    def open(self):
        buffer_size = self.session.get_option("ringbuffer-size")
        self.buffer = RingBuffer(buffer_size)
        self.writer = self.__writer__(self)
        self.worker = self.__worker__(self)

        self.writer.start()
        self.worker.start()

    def close(self):
        self.worker.close()
        self.writer.close()

        for thread in (self.worker, self.writer):
            if thread.is_alive():
                thread.join()

        self.buffer.close()

    def read(self, size):
        if not self.buffer:
            return b""

        return self.buffer.read(size, block=self.writer.is_alive(),
                                timeout=self.timeout)




########NEW FILE########
__FILENAME__ = stream
import io
import json


class Stream(object):
    __shortname__ = "stream"

    """
    This is a base class that should be inherited when implementing
    different stream types. Should only be created by plugins.
    """

    def __init__(self, session):
        self.session = session

    def __repr__(self):
        return "<Stream()>"

    def __json__(self):
        return dict(type=type(self).shortname())

    def open(self):
        """
        Attemps to open a connection to the stream.
        Returns a file-like object that can be used to read the stream data.

        Raises :exc:`StreamError` on failure.
        """
        raise NotImplementedError

    @property
    def json(self):
        obj = self.__json__()
        return json.dumps(obj)

    @classmethod
    def shortname(cls):
        return cls.__shortname__


class StreamIO(io.IOBase):
    pass


__all__ = ["Stream", "StreamIO"]

########NEW FILE########
__FILENAME__ = streamprocess
from .stream import Stream
from .wrappers import StreamIOThreadWrapper
from ..compat import str
from ..exceptions import StreamError
from ..packages import pbs as sh

import os
import time
import tempfile

class StreamProcessIO(StreamIOThreadWrapper):
    def __init__(self, session, process, **kwargs):
        self.process = process

        StreamIOThreadWrapper.__init__(self, session,
                                       process.stdout,
                                       **kwargs)

    def close(self):
        try:
            self.process.kill()
        except Exception:
            pass

        StreamIOThreadWrapper.close(self)


class StreamProcess(Stream):
    def __init__(self, session, params=None, timeout=60.0):
        Stream.__init__(self, session)

        if not params:
            params = {}

        self.params = params
        self.errorlog = self.session.options.get("subprocess-errorlog")
        self.timeout = timeout

    def open(self):
        cmd = self._check_cmd()
        params = self.params.copy()
        params["_bg"] = True

        if self.errorlog:
            tmpfile = tempfile.NamedTemporaryFile(prefix="livestreamer",
                                                  suffix=".err", delete=False)
            params["_err"] = tmpfile
        else:
            params["_err"] = open(os.devnull, "wb")

        with params["_err"]:
            stream = cmd(**params)

        # Wait 0.5 seconds to see if program exited prematurely
        time.sleep(0.5)

        process_alive = stream.process.returncode is None

        if not process_alive:
            if self.errorlog:
                raise StreamError(("Error while executing subprocess, "
                                   "error output logged to: {0}").format(tmpfile.name))
            else:
                raise StreamError("Error while executing subprocess")

        return StreamProcessIO(self.session, stream.process,
                               timeout=self.timeout)

    def _check_cmd(self):
        try:
            cmd = sh.create_command(self.cmd)
        except sh.CommandNotFound as err:
            raise StreamError("Unable to find {0} command".format(err))

        return cmd

    def cmdline(self):
        cmd = self._check_cmd()

        return str(cmd.bake(**self.params))

    @classmethod
    def is_usable(cls, cmd):
        try:
            cmd = sh.create_command(cmd)
        except sh.CommandNotFound:
            return False

        return True


__all__ = ["StreamProcess"]

########NEW FILE########
__FILENAME__ = wrappers
from ..buffers import Buffer, RingBuffer

from threading import Thread

import io

class StreamIOWrapper(io.IOBase):
    """Wraps file-like objects that are not inheriting from IOBase"""

    def __init__(self, fd):
        self.fd = fd

    def read(self, size=-1):
        return self.fd.read(size)

    def close(self):
        if hasattr(self.fd, "close"):
            self.fd.close()


class StreamIOIterWrapper(io.IOBase):
    """Wraps a iterator and turn it into a file-like object"""

    def __init__(self, iterator):
        self.iterator = iterator
        self.buffer = Buffer()

    def read(self, size=-1):
        if size < 0:
            size = self.buffer.length

        while self.buffer.length < size:
            try:
                chunk = next(self.iterator)
                self.buffer.write(chunk)
            except StopIteration:
                break

        return self.buffer.read(size)

    def close(self):
        pass


class StreamIOThreadWrapper(io.IOBase):
    """Wraps a file-like object in a thread.

    Useful for getting control over read timeout where
    timeout handling is missing or out of our control.
    """

    class Filler(Thread):
        def __init__(self, fd, buffer):
            Thread.__init__(self)

            self.error = None
            self.fd = fd
            self.buffer = buffer
            self.daemon = True
            self.running = False

        def run(self):
            self.running = True

            while self.running:
                try:
                    data = self.fd.read(8192)
                except IOError as error:
                    self.error = error
                    break

                if len(data) == 0:
                    break

                self.buffer.write(data)

            self.stop()

        def stop(self):
            self.running = False
            self.buffer.close()

            if hasattr(self.fd, "close"):
                try:
                    self.fd.close()
                except Exception:
                    pass

    def __init__(self, session, fd, timeout=30):
        self.buffer = RingBuffer(session.get_option("ringbuffer-size"))
        self.fd = fd
        self.timeout = timeout

        self.filler = StreamIOThreadWrapper.Filler(self.fd, self.buffer)
        self.filler.start()

    def read(self, size=-1):
        if self.filler.error and self.buffer.length == 0:
            raise self.filler.error

        return self.buffer.read(size, block=self.filler.is_alive(),
                                timeout=self.timeout)

    def close(self):
        self.filler.stop()

        if self.filler.is_alive():
            self.filler.join()


__all__ = ["StreamIOWrapper", "StreamIOIterWrapper", "StreamIOThreadWrapper"]

########NEW FILE########
__FILENAME__ = utils
import json
import re
import zlib

try:
    import xml.etree.cElementTree as ET
except ImportError:
    import xml.etree.ElementTree as ET

from .compat import urljoin, urlparse, parse_qsl
from .exceptions import PluginError


def swfdecompress(data):
    if data[:3] == b"CWS":
        data = b"F" + data[1:8] + zlib.decompress(data[8:])

    return data


def verifyjson(json, key):
    if not isinstance(json, dict):
        raise PluginError("JSON result is not a dict")

    if not key in json:
        raise PluginError("Missing '{0}' key in JSON".format(key))

    return json[key]


def absolute_url(baseurl, url):
    if not url.startswith("http"):
        return urljoin(baseurl, url)
    else:
        return url


def prepend_www(url):
    """Changes google.com to www.google.com"""
    parsed = urlparse(url)
    if parsed.netloc.split(".")[0] != "www":
        return parsed.scheme + "://www." + parsed.netloc + parsed.path
    else:
        return url


def parse_json(data, jsontype="JSON", exception=PluginError):
    try:
        jsondata = json.loads(data)
    except ValueError as err:
        if len(data) > 35:
            snippet = data[:35] + "..."
        else:
            snippet = data

        raise exception("Unable to parse {0}: {1} ({2})".format(jsontype, err,
                                                                snippet))

    return jsondata


def parse_xml(data, xmltype="XML", ignore_ns=False, exception=PluginError):
    if ignore_ns:
        data = re.sub(" xmlns=\"(.+?)\"", "", data)

    try:
        tree = ET.fromstring(data)
    except Exception as err:
        if len(data) > 35:
            snippet = data[:35] + "..."
        else:
            snippet = data

        raise exception("Unable to parse {0}: {1} ({2})".format(xmltype, err,
                                                                snippet))

    return tree


def parse_qsd(*args, **kwargs):
    return dict(parse_qsl(*args, **kwargs))


def rtmpparse(url):
    parse = urlparse(url)
    netloc = "{hostname}:{port}".format(hostname=parse.hostname,
                                        port=parse.port or 1935)
    split = parse.path.split("/")
    app = "/".join(split[1:2])

    if len(split) > 2:
        playpath = "/".join(split[2:])

        if len(parse.query) > 0:
            playpath += "?" + parse.query
    else:
        playpath = ""

    tcurl = "{scheme}://{netloc}/{app}".format(scheme=parse.scheme,
                                               netloc=netloc,
                                               app=app)

    return (tcurl, playpath)


#####################################
# Deprecated functions, do not use. #
#####################################

import requests

def urlget(url, *args, **kwargs):
    """This function is deprecated."""
    data = kwargs.pop("data", None)
    exception = kwargs.pop("exception", PluginError)
    method = kwargs.pop("method", "GET")
    session = kwargs.pop("session", None)
    timeout = kwargs.pop("timeout", 20)

    if data is not None:
        method = "POST"

    try:
        if session:
            res = session.request(method, url, timeout=timeout, data=data,
                                  *args, **kwargs)
        else:
            res = requests.request(method, url, timeout=timeout, data=data,
                                   *args, **kwargs)

        res.raise_for_status()
    except (requests.exceptions.RequestException, IOError) as rerr:
        err = exception("Unable to open URL: {url} ({err})".format(url=url,
                                                                   err=rerr))
        err.err = rerr
        raise err

    return res

urlopen = urlget


def urlresolve(url):
    """This function is deprecated."""
    res = urlget(url, stream=True, allow_redirects=False)

    if res.status_code == 302 and "location" in res.headers:
        return res.headers["location"]
    else:
        return url


def res_xml(res, *args, **kw):
    """This function is deprecated."""
    return parse_xml(res.text, *args, **kw)


def res_json(res, jsontype="JSON", exception=PluginError):
    """This function is deprecated."""
    try:
        jsondata = res.json()
    except ValueError as err:
        if len(res.text) > 35:
            snippet = res.text[:35] + "..."
        else:
            snippet = res.text

        raise exception("Unable to parse {0}: {1} ({2})".format(jsontype, err,
                                                                snippet))

    return jsondata

import hmac
import hashlib

SWF_KEY = b"Genuine Adobe Flash Player 001"

def swfverify(url):
    """This function is deprecated."""
    res = urlopen(url)
    swf = swfdecompress(res.content)

    h = hmac.new(SWF_KEY, swf, hashlib.sha256)

    return h.hexdigest(), len(swf)


__all__ = ["urlopen", "urlget", "urlresolve", "swfdecompress", "swfverify",
           "verifyjson", "absolute_url", "parse_qsd", "parse_json", "res_json",
           "parse_xml", "res_xml", "rtmpparse", "prepend_www"]

########NEW FILE########
__FILENAME__ = argparser
import argparse

from livestreamer import __version__ as livestreamer_version

from .constants import (EXAMPLE_USAGE, STREAM_PASSTHROUGH,
                        DEFAULT_PLAYER_ARGUMENTS)
from .utils import find_default_player

class ArgumentParser(argparse.ArgumentParser):
    def convert_arg_line_to_args(self, line):
        if len(line) == 0:
            return

        if line[0] == "#":
            return

        split = line.find("=")
        if split > 0:
            key = line[:split].strip()
            val = line[split+1:].strip()
            yield "--%s=%s" % (key, val)
        else:
            yield "--%s" % line


def comma_list(values):
    return [val.strip() for val in values.split(",")]


def comma_list_filter(acceptable):
    def func(p):
        values = comma_list(p)
        return list(filter(lambda v: v in acceptable, values))

    return func


def nonzero_num(type):
    def func(value):
        value = type(value)
        if value > 0:
            return value
    func.__name__ = "non-zero {0}".format(type.__name__)
    return func


float = nonzero_num(float)
int = nonzero_num(int)

parser = ArgumentParser(description="Livestreamer is CLI program that "
                                    "extracts streams from various services "
                                    "and pipes them into a video player of "
                                    "choice.",
                        fromfile_prefix_chars="@",
                        formatter_class=argparse.RawDescriptionHelpFormatter,
                        epilog=EXAMPLE_USAGE, add_help=False)

parser.add_argument("url", help="URL to stream", nargs="?")
parser.add_argument("stream", nargs="?", type=comma_list,
                    help="Stream quality to play, use 'best' or 'worst' for "
                         "highest or lowest quality available. "
                         "Fallback streams can be specified by using a "
                         "comma-separated list, e.g. '720p,480p,best'.")
parser.add_argument("-h", "--help", action="store_true",
                    help="Show this help message and exit")
parser.add_argument("-V", "--version", action="version",
                    version="%(prog)s " + livestreamer_version)
parser.add_argument("--plugins", action="store_true",
                    help="Print all currently installed plugins")
parser.add_argument("-l", "--loglevel", metavar="level", default="info",
                    help="Set log level, valid levels: none, error, warning, "
                          "info, debug")
parser.add_argument("-Q", "--quiet", action="store_true",
                    help="Alias for --loglevel none")
parser.add_argument("-j", "--json", action="store_true",
                    help="Output JSON instead of the normal text output and "
                         "disable log output, useful for external scripting")
parser.add_argument("--no-version-check", action="store_true",
                    help="Do not check for new Livestreamer releases")
parser.add_argument("--yes-run-as-root", action="store_true",
                    help=argparse.SUPPRESS)

group = parser.add_argument_group("stream options")
group.add_argument("--retry-streams", metavar="delay", type=float,
                   help="Will retry fetching streams until streams are found "
                        "while waiting <delay> (seconds) between each attempt")
group.add_argument("--retry-open", metavar="attempts", type=int, default=1,
                   help="Will try <attempts> to open the stream until giving up")
group.add_argument("--stream-types", "--stream-priority", metavar="types",
                   type=comma_list,
                   help="A comma-delimited list of stream types to allow. "
                        "The order will be used to separate streams when "
                        "there are multiple streams with the same name "
                        "and different stream types. Default is "
                        "rtmp,hls,hds,http,akamaihd")
group.add_argument("--stream-sorting-excludes", metavar="streams",
                   type=comma_list,
                   help="Fine tune best/worst synonyms by excluding "
                        "unwanted streams. Uses a filter expression in "
                        "the format [operator]<value>. For example the "
                        "filter '>480p' will exclude streams ranked "
                        "higher than '480p'. Valid operators are >, >=, < "
                        "and <=. If no operator is specified then "
                        "equality is tested. Multiple filters can be "
                        "used by separating each expression with a comma. "
                        "For example '>480p,>mobile_medium' will exclude "
                        "streams from two quality types.")
group.add_argument("--best-stream-default", action="store_true",
                   help="Use the 'best' stream if no stream is specified.")

httpopt = parser.add_argument_group("HTTP options")
httpopt.add_argument("--http-proxy", metavar="http://hostname:port/",
                     help="Specify a HTTP proxy to use for all HTTP requests")
httpopt.add_argument("--https-proxy", metavar="https://hostname:port/",
                     help="Specify a HTTPS proxy to use for all HTTPS requests")
httpopt.add_argument("--http-cookies", metavar="cookies",
                     help="A semi-colon (;) delimited list of cookies to "
                          "add to each HTTP request, e.g. foo=bar;baz=qux")
httpopt.add_argument("--http-headers", metavar="headers",
                     help="A semi-colon (;) delimited list of headers to "
                          "add to each HTTP request, e.g. foo=bar;baz=qux")
httpopt.add_argument("--http-query-params", metavar="params",
                     help="A semi-colon (;) delimited list of query parameters "
                          "to add to each HTTP request, e.g. foo=bar;baz=qux")
httpopt.add_argument("--http-ignore-env", action="store_true",
                     help="Ignore HTTP settings set in the environment, "
                          "such as environment variables (HTTP_PROXY, etc) "
                          "and ~/.netrc authentication")
httpopt.add_argument("--http-no-ssl-verify", action="store_true",
                     help="Don't verify SSL certificates. Usually a bad idea")
httpopt.add_argument("--http-ssl-cert", metavar="pem",
                     help="SSL certificate to use (pem)")
httpopt.add_argument("--http-ssl-cert-crt-key", metavar=("crt", "key"),
                     nargs=2, help="SSL certificate to use (crt and key)")
httpopt.add_argument("--http-timeout", metavar="timeout", type=float,
                     help="General timeout used by all HTTP requests except "
                          "the ones covered by other options, default is 20.0")

playeropt = parser.add_argument_group("player options")
playeropt.add_argument("-p", "--player", metavar="command",
                       default=find_default_player(),
                       help="Player command-line to start, by default VLC "
                            "will be used if it is installed.")
playeropt.add_argument("-a", "--player-args", metavar="arguments",
                       default=DEFAULT_PLAYER_ARGUMENTS,
                       help="The arguments passed to the player. These "
                            "formatting variables are available: filename. "
                            "Default is '{0}'".format(DEFAULT_PLAYER_ARGUMENTS))
playeropt.add_argument("-v", "--verbose-player", action="store_true",
                       help="Show all player console output")
playeropt.add_argument("-n", "--player-fifo", "--fifo", action="store_true",
                       help="Make the player read the stream through a named "
                            "pipe (useful if your player can't read from "
                            "stdin)")
playeropt.add_argument("--player-http", action="store_true",
                       help="Make the player read the stream using HTTP "
                            "(useful if your player can't read from stdin)")
playeropt.add_argument("--player-continuous-http", action="store_true",
                       help="Make the player read the stream using HTTP, but "
                            "unlike --player-http will continuously try to "
                            "open the stream if the player requests it. "
                            "This makes it possible to handle stream "
                            "disconnects if your player is capable of "
                            "reconnecting to a HTTP stream, e.g "
                            "'vlc --repeat'")
playeropt.add_argument("--player-passthrough", metavar="types",
                       type=comma_list_filter(STREAM_PASSTHROUGH), default=[],
                       help="A comma-delimited list of stream types to "
                            "pass to the player as a filename rather than "
                            "piping the data. Make sure your player can "
                            "handle the stream type when using this. "
                            "Supported stream types are: "
                            "{0}".format(", ".join(STREAM_PASSTHROUGH)))
playeropt.add_argument("--player-no-close", action="store_true",
                       help="By default Livestreamer will close the "
                            "player when the stream ends. This option "
                            "will let the player decide when to exit.")

outputopt = parser.add_argument_group("file output options")
outputopt.add_argument("-o", "--output", metavar="filename",
                       help="Write stream to file instead of playing it")
outputopt.add_argument("-f", "--force", action="store_true",
                       help="Always write to file even if it already exists")
outputopt.add_argument("-O", "--stdout", action="store_true",
                       help="Write stream to stdout instead of playing it")

streamopt = parser.add_argument_group("stream transport options")
streamopt.add_argument("--hds-live-edge", type=float, metavar="seconds",
                       help="Specify the time live HDS streams will start "
                            "from the edge of stream, default is 10.0")
streamopt.add_argument("--hds-segment-attempts", type=int, metavar="attempts",
                       help="How many attempts should be done to download "
                            "each HDS segment, default is 3")
streamopt.add_argument("--hds-segment-timeout", type=float, metavar="timeout",
                       help="HDS segment connect and read timeout, default is 10.0")
streamopt.add_argument("--hds-timeout", type=float, metavar="timeout",
                       help="Timeout for reading data from HDS streams, "
                            "default is 60.0")
streamopt.add_argument("--hls-live-edge", type=int, metavar="segments",
                       help="How many segments from the end to start "
                            "live HLS streams on, default is 3")
streamopt.add_argument("--hls-segment-attempts", type=int, metavar="attempts",
                       help="How many attempts should be done to download "
                            "each HLS segment, default is 3")
streamopt.add_argument("--hls-segment-timeout", type=float, metavar="timeout",
                       help="HLS segment connect and read timeout, "
                            "default is 10.0")
streamopt.add_argument("--hls-timeout", type=float, metavar="timeout",
                       help="Timeout for reading data from HLS streams, "
                            "default is 60.0")
streamopt.add_argument("--http-stream-timeout", type=float, metavar="timeout",
                       help="Timeout for reading data from HTTP streams, "
                            "default is 60.0")
streamopt.add_argument("--ringbuffer-size", metavar="size", type=int,
                       help="Specify a maximum size (bytes) for the "
                            "ringbuffer, default is 16777216 (16MB)")
streamopt.add_argument("--rtmp-proxy", "--rtmpdump-proxy", metavar="host:port",
                       help="Specify a proxy (SOCKS) that RTMP streams will use")
streamopt.add_argument("--rtmp-rtmpdump", "--rtmpdump", "-r", metavar="path",
                       help="Specify location of the rtmpdump executable "
                            "used by RTMP streams, e.g. /usr/local/bin/rtmpdump")
streamopt.add_argument("--rtmp-timeout", type=float, metavar="timeout",
                       help="Timeout for reading data from RTMP streams, "
                            "default is 60.0")
streamopt.add_argument("--subprocess-cmdline", "--cmdline", "-c",
                       action="store_true",
                       help="Print command-line used internally to play "
                            "stream, this is only available for RTMP streams")
streamopt.add_argument("--subprocess-errorlog", "--errorlog", "-e",
                       action="store_true",
                       help="Log possible errors from internal subprocesses "
                            "to a temporary file, use when debugging rtmpdump "
                            "related issues")

pluginopt = parser.add_argument_group("plugin options")
pluginopt.add_argument("--plugin-dirs", metavar="directory", type=comma_list,
                       help="Attempts to load plugins from these directories. "
                            "Multiple directories can be used by separating "
                            "them with a semicolon (;)")
pluginopt.add_argument("--jtv-cookie", "--twitch-cookie", metavar="cookie",
                       help="Specify Twitch/Justin.tv cookies to allow access "
                            "to subscription channels, e.g. "
                            "'_twitch_session_id=xxxxxx; persistent=xxxxx'")
pluginopt.add_argument("--jtv-password", "--twitch-password",
                       help="Use this to access password protected streams.",
                       metavar="password")
pluginopt.add_argument("--twitch-oauth-token", metavar="token",
                       help="Specify a OAuth token to allow Livestreamer to "
                            "access Twitch using your account.")
pluginopt.add_argument("--twitch-oauth-authenticate", action="store_true",
                       help="Opens a web browser where you can grant "
                            "Livestreamer access to your Twitch account.")
pluginopt.add_argument("--ustream-password",
                       help="Use this to access password protected streams.",
                       metavar="password")
pluginopt.add_argument("--crunchyroll-username", metavar="username",
                       help="Specify Crunchyroll username to allow access to "
                            "restricted streams")
pluginopt.add_argument("--crunchyroll-password", metavar="password",
                       help="Specify Crunchyroll password to allow access to "
                            "restricted streams (if left blank you will be "
                            "prompted)",
                       nargs="?", const=True, default=None)
pluginopt.add_argument("--crunchyroll-purge-credentials", action="store_true",
                       help="Purge Crunchyroll credentials to initiate a new "
                       "session and reauthenticate.")
pluginopt.add_argument("--livestation-email", metavar="email",
                       help="Specify Livestation account email to access "
                            "restricted streams or Premium Quality streams.")
pluginopt.add_argument("--livestation-password", metavar="password",
                       help="Specify Livestation password for account specified.")


# Deprecated options
playeropt.add_argument("-q", "--quiet-player", action="store_true",
                       help=argparse.SUPPRESS)
pluginopt.add_argument("--jtv-legacy-names", "--twitch-legacy-names",
                       action="store_true", help=argparse.SUPPRESS)
pluginopt.add_argument("--gomtv-cookie", metavar="cookie",
                       help=argparse.SUPPRESS)
pluginopt.add_argument("--gomtv-username", metavar="username",
                       help=argparse.SUPPRESS)
pluginopt.add_argument("--gomtv-password", metavar="password",
                       nargs="?", const=True, default=None,
                       help=argparse.SUPPRESS)
streamopt.add_argument("--hds-fragment-buffer", type=int, metavar="fragments",
                       help=argparse.SUPPRESS)

__all__ = ["parser"]

########NEW FILE########
__FILENAME__ = compat
import os
import re
import sys

is_py2 = (sys.version_info[0] == 2)
is_py3 = (sys.version_info[0] == 3)
is_win32 = os.name == "nt"

if is_py2:
    input = raw_input
    stdout = sys.stdout
    file = file
    _find_unsafe = re.compile(r"[^\w@%+=:,./-]").search

elif is_py3:
    input = input
    stdout = sys.stdout.buffer
    from io import IOBase as file

    _find_unsafe = re.compile(r"[^\w@%+=:,./-]", re.ASCII).search

def shlex_quote(s):
    """Return a shell-escaped version of the string *s*.

    Backported from Python 3.3 standard library module shlex.
    """
    if not s:
        return "''"
    if _find_unsafe(s) is None:
        return s

    # use single quotes, and put single quotes into double quotes
    # the string $'b is then quoted as '$'"'"'b'
    return "'" + s.replace("'", "'\"'\"'") + "'"


__all__ = ["is_py2", "is_py3", "is_win32", "input", "stdout", "file",
           "shlex_quote"]

########NEW FILE########
__FILENAME__ = console
from __future__ import unicode_literals

import json
import sys

from getpass import getpass

from .compat import input
from .utils import JSONEncoder


class ConsoleOutput(object):
    def __init__(self, output, livestreamer, json=False):
        self.livestreamer = livestreamer
        self.logger = livestreamer.logger.new_module("cli")

        self.json = json
        self.set_output(output)

    def set_level(self, level):
        self.livestreamer.set_loglevel(level)

    def set_output(self, output):
        self.output = output
        self.livestreamer.set_logoutput(output)

    def ask(self, msg, *args, **kwargs):
        formatted = msg.format(*args, **kwargs)
        sys.stderr.write(formatted)

        try:
            answer = input()
        except:
            answer = ""

        return answer.strip()

    def askpass(self, msg, *args, **kwargs):
        formatted = msg.format(*args, **kwargs)

        return getpass(formatted)

    def msg(self, msg, *args, **kwargs):
        formatted = msg.format(*args, **kwargs)
        formatted = "{0}\n".format(formatted)

        self.output.write(formatted)

    def msg_inplace(self, msg, *args, **kwargs):
        formatted = msg.format(*args, **kwargs)
        formatted = "\r{0}".format(formatted)

        sys.stderr.write(formatted)

    def msg_inplace_end(self):
        sys.stderr.write("\n")

    def msg_json(self, obj):
        if not self.json:
            return

        if hasattr(obj, "__json__"):
            obj = obj.__json__()

        msg = json.dumps(obj, cls=JSONEncoder,
                         indent=2)
        self.msg("{0}", msg)

        if isinstance(obj, dict) and obj.get("error"):
            sys.exit(1)

    def exit(self, msg, *args, **kwargs):
        formatted = msg.format(*args, **kwargs)

        if self.json:
            obj = dict(error=formatted)
            self.msg_json(obj)
        else:
            msg = "error: {0}".format(formatted)
            self.msg("{0}", msg)

        sys.exit(1)

__all__ = ["ConsoleOutput"]

########NEW FILE########
__FILENAME__ = constants
import os
import sys

from .compat import is_win32, is_py2

DEFAULT_PLAYER_ARGUMENTS = "{filename}"

if is_win32:
    APPDATA = os.environ["APPDATA"]
    CONFIG_FILE = os.path.join(APPDATA, "livestreamer", "livestreamerrc")
    PLUGINS_DIR = os.path.join(APPDATA, "livestreamer", "plugins")
else:
    XDG_CONFIG_HOME = os.environ.get("XDG_CONFIG_HOME", "~/.config")
    CONFIG_FILE = os.path.expanduser(XDG_CONFIG_HOME + "/livestreamer/config")
    PLUGINS_DIR = os.path.expanduser(XDG_CONFIG_HOME + "/livestreamer/plugins")

    if not os.path.isfile(CONFIG_FILE):
        CONFIG_FILE = os.path.expanduser("~/.livestreamerrc")

if is_py2:
    PLUGINS_DIR = PLUGINS_DIR.decode(sys.getfilesystemencoding())
    CONFIG_FILE = CONFIG_FILE.decode(sys.getfilesystemencoding())


EXAMPLE_USAGE = """
example usage:

$ livestreamer twitch.tv/thegdstudio
Available streams: high, low, medium, mobile (worst), source (best)
$ livestreamer twitch.tv/thegdstudio high

Stream is now opened in player (default is VLC, if installed).

"""

STREAM_SYNONYMS = ["best", "worst"]
STREAM_PASSTHROUGH = ["hls", "http", "rtmp"]

__all__ = ["EXAMPLE_USAGE", "CONFIG_FILE", "PLUGINS_DIR",
           "STREAM_SYNONYMS", "STREAM_PASSTHROUGH", "DEFAULT_PLAYER_ARGUMENTS"]

########NEW FILE########
__FILENAME__ = main
from __future__ import unicode_literals

import errno
import os
import requests
import sys
import signal
import webbrowser

from contextlib import closing
from time import sleep
from distutils.version import StrictVersion

from livestreamer import (Livestreamer, StreamError, PluginError,
                          NoPluginError)
from livestreamer.cache import Cache
from livestreamer.stream import StreamProcess

from .argparser import parser
from .compat import stdout, is_win32
from .console import ConsoleOutput
from .constants import CONFIG_FILE, PLUGINS_DIR, STREAM_SYNONYMS
from .output import FileOutput, PlayerOutput
from .utils import NamedPipe, HTTPServer, ignored, stream_to_url

ACCEPTABLE_ERRNO = (errno.EPIPE, errno.EINVAL, errno.ECONNRESET)

args = console = livestreamer = plugin = None


def check_file_output(filename, force):
    """Checks if file already exists and ask the user if it should
    be overwritten if it does."""

    console.logger.debug("Checking file output")

    if os.path.isfile(filename) and not force:
        answer = console.ask("File {0} already exists! Overwrite it? [y/N] ",
                             filename)

        if answer.lower() != "y":
            sys.exit()

    return FileOutput(filename)


def create_output():
    """Decides where to write the stream.

    Depending on arguments it can be one of these:
     - The stdout pipe
     - A subprocess' stdin pipe
     - A named pipe that the subprocess reads from
     - A regular file

    """

    if args.output:
        if args.output == "-":
            out = FileOutput(fd=stdout)
        else:
            out = check_file_output(args.output, args.force)
    elif args.stdout:
        out = FileOutput(fd=stdout)
    else:
        http = namedpipe = None

        if not args.player:
            console.exit("The default player (VLC) does not seem to be "
                         "installed. You must specify the path to a player "
                         "executable with --player.")

        if args.player_fifo:
            pipename = "livestreamerpipe-{0}".format(os.getpid())
            console.logger.info("Creating pipe {0}", pipename)

            try:
                namedpipe = NamedPipe(pipename)
            except IOError as err:
                console.exit("Failed to create pipe: {0}", err)
        elif args.player_http:
            http = create_http_server()

        console.logger.info("Starting player: {0}", args.player)
        out = PlayerOutput(args.player, args=args.player_args,
                           quiet=not args.verbose_player,
                           kill=not args.player_no_close,
                           namedpipe=namedpipe, http=http)

    return out


def create_http_server():
    """Creates a HTTP server listening on a random port."""

    try:
        http = HTTPServer()
        http.bind()
    except OSError as err:
        console.exit("Failed to create HTTP server: {0}", err)

    return http


def iter_http_requests(server, player):
    """Accept HTTP connections while the player is running."""

    while player.running:
        try:
            yield server.open(timeout=2.5)
        except OSError:
            continue


def output_stream_http(plugin, streams):
    """Continuously output the stream over HTTP."""

    server = create_http_server()

    if not args.player:
        console.exit("The default player (VLC) does not seem to be "
                     "installed. You must specify the path to a player "
                     "executable with --player.")

    player = PlayerOutput(args.player, args=args.player_args,
                          filename=server.url,
                          quiet=not args.verbose_player)
    stream_names = [resolve_stream_name(streams, s) for s in args.stream]

    try:
        console.logger.info("Starting player: {0}", args.player)
        player.open()
    except OSError as err:
        console.exit("Failed to start player: {0} ({1})",
                     args.player, err)

    for req in iter_http_requests(server, player):
        user_agent = req.headers.get("User-Agent") or "unknown player"
        console.logger.info("Got HTTP request from {0}".format(user_agent))

        stream = stream_fd = None
        while not stream_fd:
            if not player.running:
                break

            try:
                streams = streams or fetch_streams(plugin)
                for stream_name in stream_names:
                    stream = streams.get(stream_name)
                    if stream: break
                else:
                    stream = None

            except PluginError as err:
                console.logger.error("Unable to fetch new streams: {0}",
                                     err)

            if not stream:
                console.logger.info("Stream not available, will re-fetch "
                                    "streams in 10 sec")
                streams = None
                sleep(10)
                continue

            try:
                console.logger.info("Opening stream: {0} ({1})", stream_name,
                                    type(stream).shortname())
                stream_fd, prebuffer = open_stream(stream)
            except StreamError as err:
                console.logger.error("{0}", err)
                stream = streams = None
        else:
            console.logger.debug("Writing stream to player")
            read_stream(stream_fd, server, prebuffer)

        server.close(True)

    player.close()
    server.close()


def output_stream_passthrough(stream):
    """Prepares a filename to be passed to the player."""

    filename = '"{0}"'.format(stream_to_url(stream))
    out = PlayerOutput(args.player, args=args.player_args,
                       filename=filename, call=True,
                       quiet=not args.verbose_player)

    try:
        console.logger.info("Starting player: {0}", args.player)
        out.open()
    except OSError as err:
        console.exit("Failed to start player: {0} ({1})", args.player, err)
        return False

    return True


def open_stream(stream):
    """Opens a stream and reads 8192 bytes from it.

    This is useful to check if a stream actually has data
    before opening the output.

    """

    # Attempts to open the stream
    try:
        stream_fd = stream.open()
    except StreamError as err:
        raise StreamError("Could not open stream: {0}".format(err))

    # Read 8192 bytes before proceeding to check for errors.
    # This is to avoid opening the output unnecessarily.
    try:
        console.logger.debug("Pre-buffering 8192 bytes")
        prebuffer = stream_fd.read(8192)
    except IOError as err:
        raise StreamError("Failed to read data from stream: {0}".format(err))

    if not prebuffer:
        raise StreamError("No data returned from stream")

    return stream_fd, prebuffer


def output_stream(stream):
    """Open stream, create output and finally write the stream to output."""

    for i in range(args.retry_open):
        try:
            stream_fd, prebuffer = open_stream(stream)
            break
        except StreamError as err:
            console.logger.error("{0}", err)
    else:
        return

    output = create_output()

    try:
        output.open()
    except (IOError, OSError) as err:
        if isinstance(output, PlayerOutput):
            console.exit("Failed to start player: {0} ({1})",
                         args.player, err)
        else:
            console.exit("Failed to open output: {0} ({1})",
                         args.output, err)

    with closing(output):
        console.logger.debug("Writing stream to output")
        read_stream(stream_fd, output, prebuffer)

    return True


def read_stream(stream, output, prebuffer):
    """Reads data from stream and then writes it to the output."""

    is_player = isinstance(output, PlayerOutput)
    is_http = isinstance(output, HTTPServer)
    is_fifo = is_player and output.namedpipe
    show_progress = isinstance(output, FileOutput) and output.fd is not stdout
    written = 0

    while True:
        try:
            data = prebuffer or stream.read(8192)
        except IOError as err:
            console.logger.error("Error when reading from stream: {0}",
                                 str(err))
            break

        if len(data) == 0:
            break

        # We need to check if the player process still exists when
        # using named pipes on Windows since the named pipe is not
        # automatically closed by the player.
        if is_win32 and is_fifo:
            output.player.poll()

            if output.player.returncode is not None:
                console.logger.info("Player closed")
                break

        try:
            output.write(data)
        except IOError as err:
            if is_player and err.errno in ACCEPTABLE_ERRNO:
                console.logger.info("Player closed")
            elif is_http and err.errno in ACCEPTABLE_ERRNO:
                console.logger.info("HTTP connection closed")
            else:
                console.logger.error("Error when writing to output: {0}",
                                     err)

            break

        written += len(data)
        prebuffer = None

        if show_progress:
            console.msg_inplace("Written {0} bytes", written)

    if show_progress and written > 0:
        console.msg_inplace_end()

    stream.close()
    console.logger.info("Stream ended")


def handle_stream(plugin, streams, stream_name):
    """Decides what to do with the selected stream.

    Depending on arguments it can be one of these:
     - Output internal command-line
     - Output JSON represenation
     - Continuously output the stream over HTTP
     - Output stream data to selected output

    """

    stream_name = resolve_stream_name(streams, stream_name)
    stream = streams[stream_name]

    # Print internal command-line if this stream
    # uses a subprocess.
    if args.subprocess_cmdline:
        if isinstance(stream, StreamProcess):
            try:
                cmdline = stream.cmdline()
            except StreamError as err:
                console.exit("{0}", err)

            console.msg("{0}", cmdline)
        else:
            console.exit("Stream does not use a command-line")

    # Print JSON representation of the stream
    elif console.json:
        console.msg_json(stream)

    # Output the stream
    else:
        # Find any streams with a '_alt' suffix and attempt
        # to use these in case the main stream is not usable.
        alt_streams = list(filter(lambda k: stream_name + "_alt" in k,
                                  sorted(streams.keys())))
        file_output = args.output or args.stdout

        for stream_name in [stream_name] + alt_streams:
            stream = streams[stream_name]
            stream_type = type(stream).shortname()

            if stream_type in args.player_passthrough and not file_output:
                console.logger.info("Opening stream: {0} ({1})", stream_name,
                                    stream_type)
                success = output_stream_passthrough(stream)
            elif args.player_continuous_http and not file_output:
                return output_stream_http(plugin, streams)
            else:
                console.logger.info("Opening stream: {0} ({1})", stream_name,
                                    stream_type)
                success = output_stream(stream)

            if success:
                break


def fetch_streams(plugin):
    """Fetches streams using correct parameters."""

    return plugin.get_streams(stream_types=args.stream_types,
                              sorting_excludes=args.stream_sorting_excludes)


def fetch_streams_infinite(plugin, interval):
    """Attempts to fetch streams until some are returned."""

    try:
        streams = fetch_streams(plugin)
    except PluginError as err:
        console.logger.error("{0}", err)
        streams = None

    if not streams:
        console.logger.info("Waiting for streams, retrying every {0} "
                            "second(s)", args.retry_streams)
    while not streams:
        sleep(args.retry_streams)

        try:
            streams = fetch_streams(plugin)
        except PluginError as err:
            console.logger.error("{0}", err)

    return streams


def resolve_stream_name(streams, stream_name):
    """Returns the real stream name of a synonym."""

    if stream_name in STREAM_SYNONYMS:
        for name, stream in streams.items():
            if stream is streams[stream_name] and name not in STREAM_SYNONYMS:
                return name

    return stream_name


def format_valid_streams(streams):
    """Formats a dict of streams.

    Filters out synonyms and displays them next to
    the stream they point to.

    """

    delimiter = ", "
    validstreams = []

    for name, stream in sorted(streams.items()):
        if name in STREAM_SYNONYMS:
            continue

        synonymfilter = lambda n: stream is streams[n] and n is not name
        synonyms = list(filter(synonymfilter, streams.keys()))

        if len(synonyms) > 0:
            joined = delimiter.join(synonyms)
            name = "{0} ({1})".format(name, joined)

        validstreams.append(name)

    return delimiter.join(validstreams)


def handle_url():
    """The URL handler.

    Attempts to resolve the URL to a plugin and then attempts
    to fetch a list of available streams.

    Proceeds to handle stream if user specified a valid one,
    otherwise output list of valid streams.

    """

    try:
        plugin = livestreamer.resolve_url(args.url)
        console.logger.info("Found matching plugin {0} for URL {1}",
                            plugin.module, args.url)

        if args.retry_streams:
            streams = fetch_streams_infinite(plugin, args.retry_streams)
        else:
            streams = fetch_streams(plugin)
    except NoPluginError:
        console.exit("No plugin can handle URL: {0}", args.url)
    except PluginError as err:
        console.exit("{0}", err)

    if not streams:
        console.exit("No streams found on this URL: {0}", args.url)

    if args.best_stream_default and not args.stream and not args.json:
        args.stream = ["best"]

    if args.stream:
        validstreams = format_valid_streams(streams)
        for stream_name in args.stream:
            if stream_name in streams:
                console.logger.info("Available streams: {0}", validstreams)
                handle_stream(plugin, streams, stream_name)
                return

        err = ("The specified stream(s) '{0}' could not be "
               "found".format(", ".join(args.stream)))

        if console.json:
            console.msg_json(dict(streams=streams, plugin=plugin.module,
                                  error=err))
        else:
            console.exit("{0}.\n       Available streams: {1}",
                         err, validstreams)
    else:
        if console.json:
            console.msg_json(dict(streams=streams, plugin=plugin.module))
        else:
            validstreams = format_valid_streams(streams)
            console.msg("Available streams: {0}", validstreams)


def print_plugins():
    """Outputs a list of all plugins Livestreamer has loaded."""

    pluginlist = list(livestreamer.get_plugins().keys())
    pluginlist_formatted = ", ".join(sorted(pluginlist))

    if console.json:
        console.msg_json(pluginlist)
    else:
        console.msg("Loaded plugins: {0}", pluginlist_formatted)


def authenticate_twitch_oauth():
    """Opens a web browser to allow the user to grant Livestreamer
       access to their Twitch account."""

    client_id = "ewvlchtxgqq88ru9gmfp1gmyt6h2b93"
    redirect_uri = "http://livestreamer.tanuki.se/en/develop/twitch_oauth.html"
    url = ("https://api.twitch.tv/kraken/oauth2/authorize/"
           "?response_type=token&client_id={0}&redirect_uri="
           "{1}&scope=user_read").format(client_id, redirect_uri)

    console.msg("Attempting to open a browser to let you authenticate "
                "Livestreamer with Twitch")

    try:
        if not webbrowser.open_new_tab(url):
            raise webbrowser.Error
    except webbrowser.Error:
        console.exit("Unable to open a web browser, try accessing this URL "
                     "manually instead:\n{0}".format(url))


def load_plugins(dirs):
    """Attempts to load plugins from a list of directories."""

    dirs = [os.path.expanduser(d) for d in dirs]

    for directory in dirs:
        if os.path.isdir(directory):
            livestreamer.load_plugins(directory)
        else:
            console.logger.warning("Plugin path {0} does not exist or is not "
                                   "a directory!", directory)


def setup_args():
    """Parses arguments."""
    global args

    arglist = sys.argv[1:]

    # Load additional arguments from livestreamerrc
    if os.path.exists(CONFIG_FILE):
        arglist.insert(0, "@" + CONFIG_FILE)

    args = parser.parse_args(arglist)

    # Force lowercase to allow case-insensitive lookup
    if args.stream:
        args.stream = [stream.lower() for stream in args.stream]


def setup_console():
    """Console setup."""
    global console

    # All console related operations is handled via the ConsoleOutput class
    console = ConsoleOutput(sys.stdout, livestreamer)

    # Console output should be on stderr if we are outputting
    # a stream to stdout.
    if args.stdout or args.output == "-":
        console.set_output(sys.stderr)

    # We don't want log output when we are printing JSON or a command-line.
    if not (args.json or args.subprocess_cmdline or args.quiet):
        console.set_level(args.loglevel)

    if args.quiet_player:
        console.logger.warning("The option --quiet-player is deprecated since "
                               "version 1.4.3 as hiding player output is now "
                               "the default.")

    console.json = args.json

    # Handle SIGTERM just like SIGINT
    signal.signal(signal.SIGTERM, signal.default_int_handler)


def setup_http_session():
    """Sets the global HTTP settings, such as proxy and headers."""
    if args.http_proxy:
        livestreamer.set_option("http-proxy", args.http_proxy)

    if args.https_proxy:
        livestreamer.set_option("https-proxy", args.https_proxy)

    if args.http_cookies:
        livestreamer.set_option("http-cookies", args.http_cookies)

    if args.http_headers:
        livestreamer.set_option("http-headers", args.http_headers)

    if args.http_query_params:
        livestreamer.set_option("http-query-params", args.http_query_params)

    if args.http_ignore_env:
        livestreamer.set_option("http-trust-env", False)

    if args.http_no_ssl_verify:
        livestreamer.set_option("http-ssl-verify", False)

    if args.http_ssl_cert:
        livestreamer.set_option("http-ssl-cert", args.http_ssl_cert)

    if args.http_ssl_cert_crt_key:
        livestreamer.set_option("http-ssl-cert", tuple(args.http_ssl_cert_crt_key))

    if args.http_timeout:
        livestreamer.set_option("http-timeout", args.http_timeout)

def setup_plugins():
    """Loads any additional plugins."""
    if os.path.isdir(PLUGINS_DIR):
        load_plugins([PLUGINS_DIR])

    if args.plugin_dirs:
        load_plugins(args.plugin_dirs)


def setup_livestreamer():
    """Creates the Livestreamer session."""
    global livestreamer

    livestreamer = Livestreamer()


def setup_options():
    """Sets Livestreamer options."""
    if args.hls_live_edge:
        livestreamer.set_option("hls-live-edge", args.hls_live_edge)

    if args.hls_segment_attempts:
        livestreamer.set_option("hls-segment-attempts", args.hls_segment_attempts)

    if args.hls_segment_timeout:
        livestreamer.set_option("hls-segment-timeout", args.hls_segment_timeout)

    if args.hls_timeout:
        livestreamer.set_option("hls-timeout", args.hls_timeout)

    if args.hds_live_edge:
        livestreamer.set_option("hds-live-edge", args.hds_live_edge)

    if args.http_stream_timeout:
        livestreamer.set_option("http-stream-timeout", args.http_stream_timeout)

    if args.ringbuffer_size:
        livestreamer.set_option("ringbuffer-size", args.ringbuffer_size)

    if args.rtmp_proxy:
        livestreamer.set_option("rtmp-proxy", args.rtmp_proxy)

    if args.rtmp_rtmpdump:
        livestreamer.set_option("rtmp-rtmpdump", args.rtmp_rtmpdump)

    if args.rtmp_timeout:
        livestreamer.set_option("rtmp-timeout", args.rtmp_timeout)

    livestreamer.set_option("subprocess-errorlog", args.subprocess_errorlog)

    # Deprecated options
    if args.hds_fragment_buffer:
        console.logger.warning("The option --hds-fragment-buffer is deprecated "
                               "and will be removed in the future. Use "
                               "--ringbuffer-size instead")

def setup_plugin_options():
    """Sets Livestreamer plugin options."""
    if args.jtv_cookie:
        livestreamer.set_plugin_option("justintv", "cookie",
                                       args.jtv_cookie)
        livestreamer.set_plugin_option("twitch", "cookie",
                                       args.jtv_cookie)

    if args.jtv_password:
        livestreamer.set_plugin_option("justintv", "password",
                                       args.jtv_password)
        livestreamer.set_plugin_option("twitch", "password",
                                       args.jtv_password)

    if args.twitch_oauth_token:
        livestreamer.set_plugin_option("twitch", "oauth_token",
                                       args.twitch_oauth_token)

    if args.ustream_password:
        livestreamer.set_plugin_option("ustreamtv", "password",
                                       args.ustream_password)

    if args.crunchyroll_username:
        livestreamer.set_plugin_option("crunchyroll", "username",
                                       args.crunchyroll_username)

    if args.crunchyroll_username and not args.crunchyroll_password:
        crunchyroll_password = console.askpass("Enter Crunchyroll password: ")
    else:
        crunchyroll_password = args.crunchyroll_password

    if crunchyroll_password:
        livestreamer.set_plugin_option("crunchyroll", "password",
                                       crunchyroll_password)
    if args.crunchyroll_purge_credentials:
        livestreamer.set_plugin_option("crunchyroll", "purge_credentials",
                                       args.crunchyroll_purge_credentials)

    if args.livestation_email:
        livestreamer.set_plugin_option("livestation", "email",
                                       args.livestation_email)

    if args.livestation_password:
        livestreamer.set_plugin_option("livestation", "password",
                                       args.livestation_password)

    # Deprecated options
    if args.jtv_legacy_names:
        console.logger.warning("The option --jtv/twitch-legacy-names is "
                               "deprecated and will be removed in the future.")

    if args.gomtv_username:
        console.logger.warning("The option --gomtv-username is deprecated "
                               "and will be removed in the future.")

    if args.gomtv_password:
        console.logger.warning("The option --gomtv-password is deprecated "
                               "and will be removed in the future.")

    if args.gomtv_cookie:
        console.logger.warning("The option --gomtv-cookie is deprecated "
                               "and will be removed in the future.")


def check_root():
    if hasattr(os, "getuid"):
        if os.geteuid() == 0 and not args.yes_run_as_root:
            print("livestreamer is not supposed to be run as root. "
                  "If you really must you can do it by passing "
                  "--yes-run-as-root.")
            sys.exit(1)


def check_version():
    cache = Cache(filename="cli.json")
    latest_version = cache.get("latest_version")

    if not latest_version:
        res = requests.get("https://pypi.python.org/pypi/livestreamer/json")
        data = res.json()
        latest_version = data.get("info").get("version")
        cache.set("latest_version", latest_version, (60 * 60 * 24))

    installed_version = StrictVersion(livestreamer.version)
    latest_version = StrictVersion(latest_version)

    if latest_version > installed_version:
        console.logger.info("A new version of Livestreamer ({0}) is "
                            "available!".format(latest_version))


def main():
    setup_args()
    check_root()
    setup_livestreamer()
    setup_console()
    setup_http_session()
    setup_plugins()

    if not args.no_version_check:
        with ignored(Exception):
            check_version()

    if args.plugins:
        print_plugins()
    elif args.url:
        with ignored(KeyboardInterrupt):
            setup_options()
            setup_plugin_options()
            handle_url()
    elif args.twitch_oauth_authenticate:
        authenticate_twitch_oauth()
    else:
        parser.print_help()

########NEW FILE########
__FILENAME__ = output
import os
import shlex
import subprocess
import sys

from time import sleep

from .compat import is_win32, stdout
from .constants import DEFAULT_PLAYER_ARGUMENTS
from .utils import ignored

if is_win32:
    import msvcrt


class Output(object):
    def __init__(self):
        self.opened = False

    def open(self):
        self._open()
        self.opened = True

    def close(self):
        if self.opened:
            self._close()

        self.opened = False

    def write(self, data):
        if not self.opened:
            raise IOError("Output is not opened")

        return self._write(data)

    def _open(self):
        pass

    def _close(self):
        pass

    def _write(self, data):
        pass


class FileOutput(Output):
    def __init__(self, filename=None, fd=None):
        self.filename = filename
        self.fd = fd

    def _open(self):
        if self.filename:
            self.fd = open(self.filename, "wb")

        if is_win32:
            msvcrt.setmode(self.fd.fileno(), os.O_BINARY)

    def _close(self):
        if self.fd is not stdout:
            self.fd.close()

    def _write(self, data):
        self.fd.write(data)


class PlayerOutput(Output):
    def __init__(self, cmd, args=DEFAULT_PLAYER_ARGUMENTS,
                 filename=None, quiet=True, kill=True,
                 call=False, http=False, namedpipe=None):
        self.cmd = cmd
        self.args = args
        self.kill = kill
        self.call = call
        self.quiet = quiet

        self.filename = filename
        self.namedpipe = namedpipe
        self.http = http

        if self.namedpipe or self.filename or self.http:
            self.stdin = sys.stdin
        else:
            self.stdin = subprocess.PIPE

        if self.quiet:
            self.stdout = open(os.devnull, "w")
            self.stderr = open(os.devnull, "w")
        else:
            self.stdout = sys.stdout
            self.stderr = sys.stderr

    @property
    def running(self):
        sleep(0.5)
        self.player.poll()
        return self.player.returncode is None

    def _create_arguments(self):
        if self.namedpipe:
            filename = self.namedpipe.path
        elif self.filename:
            filename = self.filename
        elif self.http:
            filename = self.http.url
        else:
            filename = "-"

        # shlex removes un-escaped backslashes
        cmd = self.cmd.replace("\\", "\\\\")
        args = self.args.format(filename=filename)
        args = args.replace("\\", "\\\\")

        return shlex.split(cmd) + shlex.split(args)

    def _open(self):
        try:
            if self.call and self.filename:
                self._open_call()
            else:
                self._open_subprocess()
        finally:
            if self.quiet:
                # Output streams no longer needed in parent process
                self.stdout.close()
                self.stderr.close()

    def _open_call(self):
        subprocess.call(self._create_arguments(),
                        stdout=self.stdout,
                        stderr=self.stderr)

    def _open_subprocess(self):
        # Force bufsize=0 on all Python versions to avoid writing the
        # unflushed buffer when closing a broken input pipe
        self.player = subprocess.Popen(self._create_arguments(),
                                       stdin=self.stdin, bufsize=0,
                                       stdout=self.stdout,
                                       stderr=self.stderr)

        # Wait 0.5 seconds to see if program exited prematurely
        if not self.running:
            raise OSError("Process exited prematurely")

        if self.namedpipe:
            self.namedpipe.open("wb")
        elif self.http:
            self.http.open()

    def _close(self):
        # Close input to the player first to signal the end of the
        # stream and allow the player to terminate of its own accord
        if self.namedpipe:
            self.namedpipe.close()
        elif self.http:
            self.http.close()
        elif not self.filename:
            self.player.stdin.close()

        if self.kill:
            with ignored(Exception):
                self.player.kill()
        self.player.wait()

    def _write(self, data):
        if self.namedpipe:
            self.namedpipe.write(data)
        elif self.http:
            self.http.write(data)
        else:
            self.player.stdin.write(data)

__all__ = ["PlayerOutput", "FileOutput"]

########NEW FILE########
__FILENAME__ = utils
import json
import os
import socket
import sys
import tempfile

from contextlib import contextmanager
from io import BytesIO

from .compat import is_win32, is_py3, shlex_quote

try:
    from BaseHTTPServer import BaseHTTPRequestHandler
except ImportError:
    from http.server import BaseHTTPRequestHandler


if is_win32:
    from ctypes import windll, cast, c_ulong, c_void_p, byref

    PIPE_ACCESS_OUTBOUND = 0x00000002
    PIPE_TYPE_BYTE = 0x00000000
    PIPE_READMODE_BYTE = 0x00000000
    PIPE_WAIT = 0x00000000
    PIPE_UNLIMITED_INSTANCES = 255
    INVALID_HANDLE_VALUE = -1


class NamedPipe(object):
    def __init__(self, name):
        self.fifo = None
        self.pipe = None

        if is_win32:
            self.path = os.path.join("\\\\.\\pipe", name)
            self.pipe = self._create_named_pipe(self.path)
        else:
            self.path = os.path.join(tempfile.gettempdir(), name)
            self._create_fifo(self.path)

    def _create_fifo(self, name):
        os.mkfifo(name, 0o660)

    def _create_named_pipe(self, path):
        bufsize = 8192

        if is_py3:
            create_named_pipe = windll.kernel32.CreateNamedPipeW
        else:
            create_named_pipe = windll.kernel32.CreateNamedPipeA

        pipe = create_named_pipe(path, PIPE_ACCESS_OUTBOUND,
                                 PIPE_TYPE_BYTE | PIPE_READMODE_BYTE | PIPE_WAIT,
                                 PIPE_UNLIMITED_INSTANCES,
                                 bufsize, bufsize,
                                 0, None)

        if pipe == INVALID_HANDLE_VALUE:
            error_code = windll.kernel32.GetLastError()
            raise IOError("Error code 0x{0:08X}".format(error_code))

        return pipe

    def open(self, mode):
        if not self.pipe:
            self.fifo = open(self.path, mode)

    def write(self, data):
        if self.pipe:
            windll.kernel32.ConnectNamedPipe(self.pipe, None)
            written = c_ulong(0)
            windll.kernel32.WriteFile(self.pipe, cast(data, c_void_p),
                                      len(data), byref(written),
                                      None)
            return written
        else:
            return self.fifo.write(data)

    def close(self):
        if self.pipe:
            windll.kernel32.DisconnectNamedPipe(self.pipe)
        else:
            self.fifo.close()
            os.unlink(self.path)


class JSONEncoder(json.JSONEncoder):
    def default(self, obj):
        if hasattr(obj, "__json__"):
            return obj.__json__()
        elif isinstance(obj, bytes):
            return obj.decode("utf8", "ignore")
        else:
            return json.JSONEncoder.default(self, obj)


class HTTPRequest(BaseHTTPRequestHandler):
    def __init__(self, request_text):
        self.rfile = BytesIO(request_text)
        self.raw_requestline = self.rfile.readline()
        self.error_code = self.error_message = None
        self.parse_request()

    def send_error(self, code, message):
        self.error_code = code
        self.error_message = message


class HTTPServer(object):
    def __init__(self):
        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.conn = self.host = self.port = None
        self.bound = False

    @property
    def url(self):
        return "http://{0}:{1}/".format(self.host, self.port)

    def bind(self, host="127.0.0.1", port=0):
        try:
            self.socket.bind((host, port))
        except socket.error as err:
            raise OSError(err)

        self.socket.listen(1)
        self.bound = True
        self.host, self.port = self.socket.getsockname()

    def open(self, timeout=30):
        self.socket.settimeout(timeout)

        try:
            conn, addr = self.socket.accept()
            conn.settimeout(None)
        except socket.timeout:
            raise OSError("Socket accept timed out")

        try:
            req_data = conn.recv(1024)
        except socket.error:
            raise OSError("Failed to read data from socket")

        req = HTTPRequest(req_data)

        conn.send(b"HTTP/1.1 200 OK\r\n")
        conn.send(b"Server: Livestreamer\r\n")
        conn.send(b"\r\n")
        self.conn = conn

        return req

    def write(self, data):
        if not self.conn:
            raise IOError("No connection")

        self.conn.sendall(data)

    def close(self, client_only=False):
        if self.conn:
            self.conn.close()

        if not client_only:
            self.socket.close()


@contextmanager
def ignored(*exceptions):
    try:
        yield
    except exceptions:
        pass


def check_paths(exes, paths):
    for path in paths:
        for exe in exes:
            path = os.path.join(path, exe)
            if os.path.isfile(path):
                return path


def find_default_player():
    if "darwin" in sys.platform:
        paths = os.environ.get("PATH", "").split(":")
        paths += ["/Applications/VLC.app/Contents/MacOS/"]
        path = check_paths(("VLC", "vlc"), paths)
    elif "win32" in sys.platform:
        exename = "vlc.exe"
        paths = os.environ.get("PATH", "").split(";")
        path = check_paths((exename,), paths)

        if not path:
            subpath = "VideoLAN\\VLC\\"
            envvars = ("PROGRAMFILES", "PROGRAMFILES(X86)", "PROGRAMW6432")
            paths = filter(None, (os.environ.get(var) for var in envvars))
            paths = (os.path.join(p, subpath) for p in paths)
            path = check_paths((exename,), paths)
    else:
        paths = os.environ.get("PATH", "").split(":")
        path = check_paths(("vlc",), paths)

    if path:
        # Quote command because it can contain space
        return shlex_quote(path)

def stream_to_url(stream):
    stream_type = type(stream).shortname()

    if stream_type in ("hls", "http"):
        url = stream.url

    elif stream_type == "rtmp":
        params = [stream.params.pop("rtmp", "")]
        stream_params = dict(stream.params)

        if "swfVfy" in stream.params:
            stream_params["swfUrl"] = stream.params["swfVfy"]
            stream_params["swfVfy"] = True

        if "swfhash" in stream.params:
            stream_params["swfVfy"] = True
            stream_params.pop("swfhash", None)
            stream_params.pop("swfsize", None)

        for key, value in stream_params.items():
            if isinstance(value, bool):
                value = str(int(value))

            # librtmp expects some characters to be escaped
            value = value.replace("\\", "\\5c")
            value = value.replace(" ", "\\20")
            value = value.replace('"', "\\22")

            params.append("{0}={1}".format(key, value))

        url = " ".join(params)

    return url

__all__ = ["NamedPipe", "HTTPServer", "JSONEncoder", "ignored",
           "find_default_player", "stream_to_url"]

########NEW FILE########
__FILENAME__ = testplugin
from livestreamer.plugins import Plugin
from livestreamer.options import Options
from livestreamer.stream import *

from livestreamer.plugin.api.support_plugin import testplugin_support

class TestPlugin(Plugin):
    options = Options({
        "a_option": "default"
    })

    @classmethod
    def can_handle_url(self, url):
        return "test.se" in url

    def _get_streams(self):
        streams = {}
        streams["rtmp"] = RTMPStream(self.session, dict(rtmp="rtmp://test.se"))
        streams["hls"] = HLSStream(self.session, "http://test.se/playlist.m3u8")
        streams["http"] = HTTPStream(self.session, "http://test.se/stream")
        streams["akamaihd"] = AkamaiHDStream(self.session, "http://test.se/stream")

        streams["240p"] = HTTPStream(self.session, "http://test.se/stream")
        streams["360p"] = HTTPStream(self.session, "http://test.se/stream")
        streams["1080p"] = HTTPStream(self.session, "http://test.se/stream")

        streams["350k"] = HTTPStream(self.session, "http://test.se/stream")
        streams["800k"] = HTTPStream(self.session, "http://test.se/stream")
        streams["1500k"] = HTTPStream(self.session, "http://test.se/stream")
        streams["3000k"] = HTTPStream(self.session, "http://test.se/stream")

        streams["480p"] = [HTTPStream(self.session, "http://test.se/stream"),
                           RTMPStream(self.session, dict(rtmp="rtmp://test.se"))]

        streams.update(testplugin_support.get_streams(self.session))

        return streams

__plugin__ = TestPlugin

########NEW FILE########
__FILENAME__ = testplugin_support
from livestreamer.stream import HTTPStream

def get_streams(session):
    return dict(support=HTTPStream(session, "http://test.se/support"))

########NEW FILE########
__FILENAME__ = test_buffer
import unittest

from livestreamer.buffers import Buffer

class TestBuffer(unittest.TestCase):
    def setUp(self):
        self.buffer = Buffer()

    def test_write(self):
        self.buffer.write(b"1" * 8192)
        self.buffer.write(b"2" * 4096)

        self.assertEqual(self.buffer.length, 8192 + 4096)

    def test_read(self):
        self.buffer.write(b"1" * 8192)
        self.buffer.write(b"2" * 4096)

        self.assertEqual(self.buffer.length, 8192 + 4096)
        self.assertEqual(self.buffer.read(4096), b"1" * 4096)
        self.assertEqual(self.buffer.read(4096), b"1" * 4096)
        self.assertEqual(self.buffer.read(), b"2" * 4096)
        self.assertEqual(self.buffer.read(4096), b"")
        self.assertEqual(self.buffer.read(), b"")
        self.assertEqual(self.buffer.length, 0)

    def test_readwrite(self):
        self.buffer.write(b"1" * 8192)
        self.assertEqual(self.buffer.length, 8192)
        self.assertEqual(self.buffer.read(4096), b"1" * 4096)
        self.assertEqual(self.buffer.length, 4096)

        self.buffer.write(b"2" * 4096)
        self.assertEqual(self.buffer.length, 8192)
        self.assertEqual(self.buffer.read(1), b"1")
        self.assertEqual(self.buffer.read(4095), b"1" * 4095)
        self.assertEqual(self.buffer.read(8192), b"2" * 4096)
        self.assertEqual(self.buffer.read(8192), b"")
        self.assertEqual(self.buffer.read(), b"")
        self.assertEqual(self.buffer.length, 0)

    def test_close(self):
        self.buffer.write(b"1" * 8192)
        self.assertEqual(self.buffer.length, 8192)

        self.buffer.close()
        self.buffer.write(b"2" * 8192)
        self.assertEqual(self.buffer.length, 8192)
    
    def test_reuse_input(self):
        """Objects should be reusable after write()"""
        
        original = b"original"
        tests = [bytearray(original)]
        try:
            m = memoryview(bytearray(original))
        except NameError:  # Python 2.6 does not have "memoryview"
            pass
        else:
            # Python 2.7 doesn't do bytes(memoryview) properly
            if bytes(m) == original:
                tests.append(m)
        
        for data in tests:
            self.buffer.write(data)
            data[:] = b"reused!!"
            self.assertEqual(self.buffer.read(), original)


if __name__ == "__main__":
    unittest.main()


########NEW FILE########
__FILENAME__ = test_log
import unittest

from livestreamer.logger import Logger
from livestreamer.compat import is_py2

# Docs says StringIO is suppose to take non-unicode strings
# but it doesn't, so let's use BytesIO instead there...

if is_py2:
    from io import BytesIO as StringIO
else:
    from io import StringIO

class TestSession(unittest.TestCase):
    def setUp(self):
        self.output = StringIO()
        self.manager = Logger()
        self.manager.set_output(self.output)
        self.logger = self.manager.new_module("test")

    def test_level(self):
        self.logger.debug("test")
        self.assertEqual(self.output.tell(), 0)
        self.manager.set_level("debug")
        self.logger.debug("test")
        self.assertNotEqual(self.output.tell(), 0)

    def test_output(self):
        self.manager.set_level("debug")
        self.logger.debug("test")
        self.assertEqual(self.output.getvalue(), "[test][debug] test\n")

if __name__ == "__main__":
    unittest.main()


########NEW FILE########
__FILENAME__ = test_options
import unittest

from livestreamer.options import Options

class TestOptions(unittest.TestCase):
    def setUp(self):
        self.options = Options({
            "a_default": "default"
        })

    def test_options(self):
        self.assertEqual(self.options.get("a_default"), "default")
        self.assertEqual(self.options.get("non_existing"), None)

        self.options.set("a_option", "option")
        self.assertEqual(self.options.get("a_option"), "option")

if __name__ == "__main__":
    unittest.main()


########NEW FILE########
__FILENAME__ = test_plugin_api_http_session
import unittest

from livestreamer.exceptions import PluginError
from livestreamer.plugin.api.http_session import HTTPSession


class TestPluginAPIHTTPSession(unittest.TestCase):
    def test_read_timeout(self):
        session = HTTPSession()

        def stream_data():
            res = session.get("http://httpbin.org/delay/6",
                              timeout=3, stream=True)
            next(res.iter_content(8192))


        self.assertRaises(PluginError, stream_data)

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_plugin_stream
import os
import unittest

from livestreamer import Livestreamer, PluginError, NoPluginError
from livestreamer.plugins import Plugin
from livestreamer.stream import *

class TestPluginStream(unittest.TestCase):
    def setUp(self):
        self.session = Livestreamer()

    def assertDictHas(self, a, b):
        for key, value in a.items():
            self.assertEqual(b[key], value)

    def _test_akamaihd(self, surl, url):
        channel = self.session.resolve_url(surl)
        streams = channel.get_streams()

        self.assertTrue("live" in streams)

        stream = streams["live"]
        self.assertTrue(isinstance(stream, AkamaiHDStream))
        self.assertEqual(stream.url, url)

    def _test_hls(self, surl, url):
        channel = self.session.resolve_url(surl)
        streams = channel.get_streams()

        self.assertTrue("live" in streams)

        stream = streams["live"]
        self.assertTrue(isinstance(stream, HLSStream))
        self.assertEqual(stream.url, url)

    def _test_rtmp(self, surl, url, params):
        channel = self.session.resolve_url(surl)
        streams = channel.get_streams()

        self.assertTrue("live" in streams)

        stream = streams["live"]
        self.assertTrue(isinstance(stream, RTMPStream))
        self.assertEqual(stream.params["rtmp"], url)
        self.assertDictHas(params, stream.params)

    def _test_http(self, surl, url, params):
        channel = self.session.resolve_url(surl)
        streams = channel.get_streams()

        self.assertTrue("live" in streams)

        stream = streams["live"]
        self.assertTrue(isinstance(stream, HTTPStream))
        self.assertEqual(stream.url, url)
        self.assertDictHas(params, stream.args)

    def test_plugin(self):
        self._test_rtmp("rtmp://hostname.se/stream",
                         "rtmp://hostname.se/stream", dict())

        self._test_rtmp("rtmp://hostname.se/stream live=1 num=47",
                        "rtmp://hostname.se/stream", dict(live=True, num=47))

        self._test_rtmp("rtmp://hostname.se/stream live=1 qarg='a \\'string' noq=test",
                        "rtmp://hostname.se/stream", dict(live=True, qarg='a \'string', noq="test"))

        self._test_hls("hls://https://hostname.se/playlist.m3u8",
                       "https://hostname.se/playlist.m3u8")

        self._test_hls("hls://hostname.se/playlist.m3u8",
                       "http://hostname.se/playlist.m3u8")

        self._test_akamaihd("akamaihd://http://hostname.se/stream",
                            "http://hostname.se/stream")

        self._test_akamaihd("akamaihd://hostname.se/stream",
                            "http://hostname.se/stream")

        self._test_http("httpstream://http://hostname.se/auth.php auth=('test','test2')",
                        "http://hostname.se/auth.php", dict(auth=("test", "test2")))

        self._test_http("httpstream://hostname.se/auth.php auth=('test','test2')",
                        "http://hostname.se/auth.php", dict(auth=("test", "test2")))

        self._test_http("httpstream://https://hostname.se/auth.php verify=False params={'key': 'a value'}",
                       "https://hostname.se/auth.php?key=a+value", dict(verify=False, params=dict(key='a value')))




if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_session
import os
import unittest

from livestreamer import Livestreamer, PluginError, NoPluginError
from livestreamer.plugins import Plugin
from livestreamer.stream import *


class TestSession(unittest.TestCase):
    PluginPath = os.path.join(os.path.dirname(__file__), "plugins")

    def setUp(self):
        self.session = Livestreamer()
        self.session.load_plugins(self.PluginPath)

    def test_exceptions(self):
        try:
            self.session.resolve_url("invalid url")
            self.assertTrue(False)
        except NoPluginError:
            self.assertTrue(True)

    def test_load_plugins(self):
        plugins = self.session.get_plugins()
        self.assertTrue(plugins["testplugin"])

    def test_builtin_plugins(self):
        plugins = self.session.get_plugins()
        self.assertTrue("justintv" in plugins)

    def test_resolve_url(self):
        plugins = self.session.get_plugins()
        channel = self.session.resolve_url("http://test.se/channel")
        self.assertTrue(isinstance(channel, Plugin))
        self.assertTrue(isinstance(channel, plugins["testplugin"]))

    def test_options(self):
        self.session.set_option("test_option", "option")
        self.assertEqual(self.session.get_option("test_option"), "option")
        self.assertEqual(self.session.get_option("non_existing"), None)

        self.assertEqual(self.session.get_plugin_option("testplugin", "a_option"), "default")
        self.session.set_plugin_option("testplugin", "another_option", "test")
        self.assertEqual(self.session.get_plugin_option("testplugin", "another_option"), "test")
        self.assertEqual(self.session.get_plugin_option("non_existing", "non_existing"), None)
        self.assertEqual(self.session.get_plugin_option("testplugin", "non_existing"), None)

    def test_plugin(self):
        channel = self.session.resolve_url("http://test.se/channel")
        streams = channel.get_streams()

        self.assertTrue("best" in streams)
        self.assertTrue("worst" in streams)
        self.assertTrue(streams["best"] is streams["1080p"])
        self.assertTrue(streams["worst"] is streams["350k"])
        self.assertTrue(isinstance(streams["rtmp"], RTMPStream))
        self.assertTrue(isinstance(streams["http"], HTTPStream))
        self.assertTrue(isinstance(streams["hls"], HLSStream))
        self.assertTrue(isinstance(streams["akamaihd"], AkamaiHDStream))

    def test_plugin_stream_types(self):
        channel = self.session.resolve_url("http://test.se/channel")
        streams = channel.get_streams(stream_types=["http", "rtmp"])

        self.assertTrue(isinstance(streams["480p"], HTTPStream))
        self.assertTrue(isinstance(streams["480p_rtmp"], RTMPStream))

        streams = channel.get_streams(stream_types=["rtmp", "http"])

        self.assertTrue(isinstance(streams["480p"], RTMPStream))
        self.assertTrue(isinstance(streams["480p_http"], HTTPStream))

    def test_plugin_stream_sorted_excludes(self):
        channel = self.session.resolve_url("http://test.se/channel")
        streams = channel.get_streams(sorting_excludes=["1080p", "3000k"])

        self.assertTrue("best" in streams)
        self.assertTrue("worst" in streams)
        self.assertTrue(streams["best"] is streams["1500k"])

        streams = channel.get_streams(sorting_excludes=[">=1080p", ">1500k"])
        self.assertTrue(streams["best"] is streams["1500k"])

        streams = channel.get_streams(sorting_excludes=lambda q: not q.endswith("p"))
        self.assertTrue(streams["best"] is streams["3000k"])

    def test_plugin_support(self):
        channel = self.session.resolve_url("http://test.se/channel")
        streams = channel.get_streams()

        self.assertTrue("support" in streams)
        self.assertTrue(isinstance(streams["support"], HTTPStream))

if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = test_stream_wrappers
import unittest

from livestreamer.stream import StreamIOIterWrapper

class TestPluginStream(unittest.TestCase):
    def test_iter(self):
        def generator():
            yield b"1" * 8192
            yield b"2" * 4096
            yield b"3" * 2048

        fd = StreamIOIterWrapper(generator())
        self.assertEqual(fd.read(4096), b"1" * 4096)
        self.assertEqual(fd.read(2048), b"1" * 2048)
        self.assertEqual(fd.read(2048), b"1" * 2048)
        self.assertEqual(fd.read(1), b"2")
        self.assertEqual(fd.read(4095), b"2" * 4095)
        self.assertEqual(fd.read(1536), b"3" * 1536)
        self.assertEqual(fd.read(), b"3" * 512)



if __name__ == "__main__":
    unittest.main()

########NEW FILE########
__FILENAME__ = build-bbfreeze
#!/usr/bin/env python
import os
import shutil
import sys

import bbfreeze.recipes

from itertools import ifilter
from bbfreeze import Freezer
from livestreamer import __version__

def recipe_pycparser(mf):
    m = mf.findNode("pycparser")
    if not m:
        return

    mf.import_hook("pycparser", m, ['*'])

    return True

bbfreeze.recipes.recipe_pycparser = recipe_pycparser

build_version = __version__
python_path = sys.prefix
script = os.path.join(python_path, "Scripts\\livestreamer-script.py")
script_exe = os.path.join(python_path, "Scripts\\livestreamer.py")

shutil.copy(script, script_exe)

includes = ("requests", "re", "xml", "xml.dom.minidom",
            "zlib", "ctypes", "argparse", "hmac", "tempfile",
            "os", "sys", "subprocess", "getpass", "msvcrt",
            "urllib", "urlparse", "pkgutil", "imp", "ast",
            "singledispatch", "cffi", "Crypto")
manual_copy = ("librtmp", "librtmp_config", "librtmp_ffi")

freezer_path = os.path.dirname(os.path.abspath(__file__))
dst = "{0}\\..\\build-win32\\livestreamer-{1}-win32\\".format(freezer_path, build_version)
site_packages = next(ifilter(lambda p: p.endswith("site-packages"), sys.path))

f = Freezer(dst, includes=includes)
f.include_py = False
f.addScript(script_exe, gui_only=False)
f()

for pkg in manual_copy:
    src = os.path.join(site_packages, pkg)
    pkgdst = os.path.join(dst, pkg)
    shutil.copytree(src, pkgdst)


########NEW FILE########
