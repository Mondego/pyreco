========
 README
========

The `username-blacklist.txt` file here as a courtesy for
development. It is not what we use in production.

We don't update these files. If you run Kitsune in production,
you'll want to use your own.

=================
Discussion Forums
=================

The "normal," discussion forums, like Contributors and Off-Topic, run
through this app. If you're looking for the Support forums, see the Support
app. This is not the app you're looking for. You can go about your business.
Move along.

This is the contents of the custom jQueryUI bundle here.

- Accordion
- Autocomplete
- Datepicker
- Slider
- Sortable

The bundle include more, but these are things that shuld be checked on the
jQuery UI custom builder. They pull in dependencies like 'Core' or 'Mouse'.
Images should be shared between bundles, but CSS and JS should not be. We use
the UI Lightness theme.

=======
Kitsune
=======

Kitsune is the platform that powers `SuMo (support.mozilla.org)
<https://support.mozilla.org>`_


It is a Django_ application. There is documentation_ online.

.. _Firefox Help: https://support.mozilla.org/
.. _Django: http://www.djangoproject.com/
.. _documentation: http://kitsune.readthedocs.org/en/latest/


You can access the staging site at https://support.allizom.org/

=====================================================================
 Python AMQP 0.9.1 client library
=====================================================================

.. include:: ../includes/intro.txt

generate_skeleton_0_8.py was used to create an initial Python 
module from the AMQP 0.8 spec file.

The 0-8 spec file is available from:

    https://svn.amqp.org/amqp/tags/amqp_spec_0.8/amqp.xml

A skeleton module named 'myskeleton.py' is generated by running
    
    generate_skeleton_0_8.py amqp.xml myskeleton.py

=====================================================================
 Python AMQP 0.9.1 client library
=====================================================================

:Version: 1.4.2
:Web: http://amqp.readthedocs.org/
:Download: http://pypi.python.org/pypi/amqp/
:Source: http://github.com/celery/py-amqp/
:Keywords: amqp, rabbitmq

About
=====

This is a fork of amqplib_ which was originally written by Barry Pederson.
It is maintained by the Celery_ project, and used by `kombu`_ as a pure python
alternative when `librabbitmq`_ is not available.

This library should be API compatible with `librabbitmq`_.

.. _amqplib: http://pypi.python.org/pypi/amqplib
.. _Celery: http://celeryproject.org/
.. _kombu: http://kombu.readthedocs.org/
.. _librabbitmq: http://pypi.python.org/pypi/librabbitmq

Differences from `amqplib`_
===========================

- Supports draining events from multiple channels (``Connection.drain_events``)
- Support for timeouts
- Channels are restored after channel error, instead of having to close the
  connection.
- Support for heartbeats

    - ``Connection.heartbeat_tick(rate=2)`` must called at regular intervals
      (half of the heartbeat value if rate is 2).
    - Or some other scheme by using ``Connection.send_heartbeat``.
- Supports RabbitMQ extensions:
    - Consumer Cancel Notifications
        - by default a cancel results in ``ChannelError`` being raised
        - but not if a ``on_cancel`` callback is passed to ``basic_consume``.
    - Publisher confirms
        - ``Channel.confirm_select()`` enables publisher confirms.
        - ``Channel.events['basic_ack'].append(my_callback)`` adds a callback
          to be called when a message is confirmed. This callback is then
          called with the signature ``(delivery_tag, multiple)``.
    - Exchange-to-exchange bindings: ``exchange_bind`` / ``exchange_unbind``.
        - ``Channel.confirm_select()`` enables publisher confirms.
        - ``Channel.events['basic_ack'].append(my_callback)`` adds a callback
          to be called when a message is confirmed. This callback is then
          called with the signature ``(delivery_tag, multiple)``.
- Support for ``basic_return``
- Uses AMQP 0-9-1 instead of 0-8.
    - ``Channel.access_request`` and ``ticket`` arguments to methods
      **removed**.
    - Supports the ``arguments`` argument to ``basic_consume``.
    - ``internal`` argument to ``exchange_declare`` removed.
    - ``auto_delete`` argument to ``exchange_declare`` deprecated
    - ``insist`` argument to ``Connection`` removed.
    - ``Channel.alerts`` has been removed.
    - Support for ``Channel.basic_recover_async``.
    - ``Channel.basic_recover`` deprecated.
- Exceptions renamed to have idiomatic names:
    - ``AMQPException`` -> ``AMQPError``
    - ``AMQPConnectionException`` -> ConnectionError``
    - ``AMQPChannelException`` -> ChannelError``
    - ``Connection.known_hosts`` removed.
    - ``Connection`` no longer supports redirects.
    - ``exchange`` argument to ``queue_bind`` can now be empty
      to use the "default exchange".
- Adds ``Connection.is_alive`` that tries to detect
  whether the connection can still be used.
- Adds ``Connection.connection_errors`` and ``.channel_errors``,
  a list of recoverable errors.
- Exposes the underlying socket as ``Connection.sock``.
- Adds ``Channel.no_ack_consumers`` to keep track of consumer tags
  that set the no_ack flag.
- Slightly better at error recovery

Further
=======

- Differences between AMQP 0.8 and 0.9.1

    http://www.rabbitmq.com/amqp-0-8-to-0-9-1.html

- AMQP 0.9.1 Quick Reference

    http://www.rabbitmq.com/amqp-0-9-1-quickref.html

- RabbitMQ Extensions

    http://www.rabbitmq.com/extensions.html

- For more information about AMQP, visit

    http://www.amqp.org

- For other Python client libraries see:

    http://www.rabbitmq.com/devtools.html#python-dev

.. image:: https://d2weczhvl823v0.cloudfront.net/celery/celery/trend.png
    :alt: Bitdeli badge
    :target: https://bitdeli.com/free

##############################
anyjson - JSON library wrapper
##############################

Overview
--------

Anyjson loads whichever is the fastest JSON module installed and provides
a uniform API regardless of which JSON implementation is used.

Originally part of carrot (http://github.com/ask/carrot/)

Examples
--------

To serialize a python object to a JSON string, call the `serialize` function:

>>> import anyjson
>>> anyjson.serialize(["test", 1, {"foo": 3.141592}, "bar"])
'["test", 1, {"foo": 3.141592}, "bar"]'

Conversion the other way is done with the `deserialize` call.

>>> anyjson.deserialize("""["test", 1, {"foo": 3.141592}, "bar"]""")
['test', 1, {'foo': 3.1415920000000002}, 'bar']

Regardless of the JSON implementation used, the exceptions will be the same.
This means that trying to serialize something not compatible with JSON
raises a TypeError:

>>> anyjson.serialize([object()])
Traceback (most recent call last):
  <snipped traceback>
TypeError: object is not JSON encodable

And deserializing a JSON string with invalid JSON raises a ValueError:

>>> anyjson.deserialize("""['missing square brace!""")
Traceback (most recent call last):
  <snipped traceback>
ValueError: cannot parse JSON description


Contact
-------

The module is maintaned by Rune F. Halvorsen <runefh@gmail.com>.
The project resides at http://bitbucket.org/runeh/anyjson . Bugs and feature
requests can be submitted there. Patches are also very welcome.

Changelog
---------

See CHANGELOG file

License
-------

see the LICENSE file

Edgewall Documentation Utilities
================================

This repository contains distutils commands for generating offline documentation
from reStructuredText files and Python source code. These tools are shared among
a couple of different Edgewall projects to ensure common style and
functionality.

About Babel
===========

Babel is a Python library that provides an integrated collection of
utilities that assist with internationalizing and localizing Python
applications (in particular web-based applications.)

Details can be found in the HTML files in the `doc` folder.

For more information please visit the Babel web site:

  <http://babel.edgewall.org/>

##############################################
 carrot - AMQP Messaging Framework for Python
##############################################

:Version: 0.10.7

**NOTE** This release contains backward-incompatible changes.
Please read the `Changelog`_ for more information.

.. _`Changelog`: http://ask.github.com/carrot/changelog.html


Introduction
------------

`carrot` is an `AMQP`_ messaging queue framework. AMQP is the Advanced Message
Queuing Protocol, an open standard protocol for message orientation, queuing,
routing, reliability and security.

The aim of `carrot` is to make messaging in Python as easy as possible by
providing a high-level interface for producing and consuming messages. At the
same time it is a goal to re-use what is already available as much as possible.

`carrot` has pluggable messaging back-ends, so it is possible to support
several messaging systems. Currently, there is support for `AMQP`_
(`py-amqplib`_, `pika`_), `STOMP`_ (`python-stomp`_). There's also an
in-memory backend for testing purposes, using the `Python queue module`_.

Several AMQP message broker implementations exists, including `RabbitMQ`_,
`ZeroMQ`_ and `Apache ActiveMQ`_. You'll need to have one of these installed,
personally we've been using `RabbitMQ`_.

Before you start playing with ``carrot``, you should probably read up on
AMQP, and you could start with the excellent article about using RabbitMQ
under Python, `Rabbits and warrens`_. For more detailed information, you can
refer to the `Wikipedia article about AMQP`_.

.. _`RabbitMQ`: http://www.rabbitmq.com/
.. _`ZeroMQ`: http://www.zeromq.org/
.. _`AMQP`: http://amqp.org
.. _`STOMP`: http://stomp.codehaus.org
.. _`python-stomp`: http://bitbucket.org/asksol/python-stomp
.. _`Python Queue module`: http://docs.python.org/library/queue.html
.. _`Apache ActiveMQ`: http://activemq.apache.org/
.. _`Django`: http://www.djangoproject.com/
.. _`Rabbits and warrens`: http://blogs.digitar.com/jjww/2009/01/rabbits-and-warrens/
.. _`py-amqplib`: http://barryp.org/software/py-amqplib/
.. _`pika`: http://github.com/tonyg/pika
.. _`Wikipedia article about AMQP`: http://en.wikipedia.org/wiki/AMQP

Documentation
-------------

Carrot is using Sphinx, and the latest documentation is available at GitHub:

    http://github.com/ask/carrot/

Installation
============

You can install ``carrot`` either via the Python Package Index (PyPI)
or from source.

To install using ``pip``,::

    $ pip install carrot


To install using ``easy_install``,::

    $ easy_install carrot


If you have downloaded a source tarball you can install it
by doing the following,::

    $ python setup.py build
    # python setup.py install # as root


Terminology
===========

There are some concepts you should be familiar with before starting:

    * Publishers

        Publishers sends messages to an exchange.

    * Exchanges

        Messages are sent to exchanges. Exchanges are named and can be
        configured to use one of several routing algorithms. The exchange
        routes the messages to consumers by matching the routing key in the
        message with the routing key the consumer provides when binding to
        the exchange.

    * Consumers

        Consumers declares a queue, binds it to a exchange and receives
        messages from it.

    * Queues

        Queues receive messages sent to exchanges. The queues are declared
        by consumers.

    * Routing keys

        Every message has a routing key.  The interpretation of the routing
        key depends on the exchange type. There are four default exchange
        types defined by the AMQP standard, and vendors can define custom
        types (so see your vendors manual for details).

        These are the default exchange types defined by AMQP/0.8:

            * Direct exchange

                Matches if the routing key property of the message and
                the ``routing_key`` attribute of the consumer are identical.

            * Fan-out exchange

                Always matches, even if the binding does not have a routing
                key.

            * Topic exchange

                Matches the routing key property of the message by a primitive
                pattern matching scheme. The message routing key then consists
                of words separated by dots (``"."``, like domain names), and
                two special characters are available; star (``"*"``) and hash
                (``"#"``). The star matches any word, and the hash matches
                zero or more words. For example ``"*.stock.#"`` matches the
                routing keys ``"usd.stock"`` and ``"eur.stock.db"`` but not
                ``"stock.nasdaq"``.


Examples
========

Creating a connection
---------------------

    You can set up a connection by creating an instance of
    ``carrot.messaging.BrokerConnection``, with the appropriate options for
    your broker:

    >>> from carrot.connection import BrokerConnection
    >>> conn = BrokerConnection(hostname="localhost", port=5672,
    ...                           userid="test", password="test",
    ...                           virtual_host="test")


    If you're using Django you can use the
    ``carrot.connection.DjangoBrokerConnection`` class instead, which loads
    the connection settings from your ``settings.py``::

       BROKER_HOST = "localhost"
       BROKER_PORT = 5672
       BROKER_USER = "test"
       BROKER_PASSWORD = "secret"
       BROKER_VHOST = "/test"

    Then create a connection by doing:

        >>> from carrot.connection import DjangoBrokerConnection
        >>> conn = DjangoBrokerConnection()



Receiving messages using a Consumer
-----------------------------------

First we open up a Python shell and start a message consumer.

This consumer declares a queue named ``"feed"``, receiving messages with
the routing key ``"importer"`` from the ``"feed"`` exchange.

The example then uses the consumers ``wait()`` method to go into consume
mode, where it continuously polls the queue for new messages, and when a
message is received it passes the message to all registered callbacks.

    >>> from carrot.messaging import Consumer
    >>> consumer = Consumer(connection=conn, queue="feed",
    ...                     exchange="feed", routing_key="importer")
    >>> def import_feed_callback(message_data, message):
    ...     feed_url = message_data["import_feed"]
    ...     print("Got feed import message for: %s" % feed_url)
    ...     # something importing this feed url
    ...     # import_feed(feed_url)
    ...     message.ack()
    >>> consumer.register_callback(import_feed_callback)
    >>> consumer.wait() # Go into the consumer loop.

Sending messages using a Publisher
----------------------------------

Then we open up another Python shell to send some messages to the consumer
defined in the last section.

    >>> from carrot.messaging import Publisher
    >>> publisher = Publisher(connection=conn,
    ...                       exchange="feed", routing_key="importer")
    >>> publisher.send({"import_feed": "http://cnn.com/rss/edition.rss"})
    >>> publisher.close()


Look in the first Python shell again (where ``consumer.wait()`` is running),
where the following text has been printed to the screen::

   Got feed import message for: http://cnn.com/rss/edition.rss  


Serialization of Data
-----------------------

By default every message is encoded using `JSON`_, so sending
Python data structures like dictionaries and lists works.
`YAML`_, `msgpack`_ and Python's built-in ``pickle`` module is also supported,
and if needed you can register any custom serialization scheme you
want to use.

.. _`JSON`: http://www.json.org/
.. _`YAML`: http://yaml.org/
.. _`msgpack`: http://msgpack.sourceforge.net/

Each option has its advantages and disadvantages.

``json`` -- JSON is supported in many programming languages, is now
    a standard part of Python (since 2.6), and is fairly fast to 
    decode using the modern Python libraries such as ``cjson or 
    ``simplejson``.
    
    The primary disadvantage to ``JSON`` is that it limits you to 
    the following data types: strings, unicode, floats, boolean, 
    dictionaries, and lists.  Decimals and dates are notably missing.
    
    Also, binary data will be transferred using base64 encoding, which
    will cause the transferred data to be around 34% larger than an 
    encoding which supports native binary types. 
    
    However, if your data fits inside the above constraints and 
    you need cross-language support, the default setting of ``JSON``
    is probably your best choice. 
    
``pickle`` -- If you have no desire to support any language other than
    Python, then using the ``pickle`` encoding will gain you 
    the support of all built-in Python data types (except class instances), 
    smaller messages when sending binary files, and a slight speedup
    over ``JSON`` processing.

``yaml`` -- YAML has many of the same characteristics as ``json``, 
    except that it natively supports more data types (including dates, 
    recursive references, etc.)
    
    However, the Python libraries for YAML are a good bit slower
    than the libraries for JSON. 
    
    If you need a more expressive set of data types and need to maintain
    cross-language compatibility, then ``YAML`` may be a better fit
    than the above. 

To instruct carrot to use an alternate serialization method, 
use one of the following options.

    1.  Set the serialization option on a per-Publisher basis: 
        
            >>> from carrot.messaging import Publisher
            >>> publisher = Publisher(connection=conn,
            ...                       exchange="feed", routing_key="importer",
            ...                       serializer="yaml")

    2.  Set the serialization option on a per-call basis

            >>> from carrot.messaging import Publisher
            >>> publisher = Publisher(connection=conn,
            ...                       exchange="feed", routing_key="importer")
            >>> publisher.send({"import_feed": "http://cnn.com/rss/edition.rss"}, 
            ...                serializer="pickle")
            >>> publisher.close()

Note that ``Consumer``s do not need the serialization method specified in 
their code.  They can auto-detect the serialization method since we supply 
the ``Content-type`` header as part of the AMQP message.


Sending raw data without Serialization
---------------------------------------

In some cases, you don't need your message data to be serialized. If you
pass in a plain string or unicode object as your message, then carrot will
not waste cycles serializing/deserializing the data.

You can optionally specify a ``content_type`` and ``content_encoding``
for the raw data:

    >>> from carrot.messaging import Publisher
    >>> publisher = Publisher(connection=conn,
    ...                       exchange="feed",
                              routing_key="import_pictures")
    >>> publisher.send(open('~/my_picture.jpg','rb').read(), 
                       content_type="image/jpeg", 
                       content_encoding="binary")
    >>> publisher.close()
    
The ``message`` object returned by the ``Consumer`` class will have a 
``content_type`` and ``content_encoding`` attribute. 


Receiving messages without a callback
--------------------------------------

You can also poll the queue manually, by using the ``fetch`` method.
This method returns a ``Message`` object, from where you can get the
message body, de-serialize the body to get the data, acknowledge, reject or
re-queue the message.

    >>> consumer = Consumer(connection=conn, queue="feed",
    ...                     exchange="feed", routing_key="importer")
    >>> message = consumer.fetch()
    >>> if message:
    ...    message_data = message.payload
    ...    message.ack()
    ... else:
    ...     # No messages waiting on the queue.
    >>> consumer.close()

Sub-classing the messaging classes
----------------------------------

The ``Consumer``, and ``Publisher`` classes can also be sub classed. Thus you
can define the above publisher and consumer like so:

    >>> from carrot.messaging import Publisher, Consumer

    >>> class FeedPublisher(Publisher):
    ...     exchange = "feed"
    ...     routing_key = "importer"
    ...
    ...     def import_feed(self, feed_url):
    ...         return self.send({"action": "import_feed",
    ...                           "feed_url": feed_url})

    >>> class FeedConsumer(Consumer):
    ...     queue = "feed"
    ...     exchange = "feed"
    ...     routing_key = "importer"
    ...
    ...     def receive(self, message_data, message):
    ...         action = message_data["action"]
    ...         if action == "import_feed":
    ...             # something importing this feed
    ...             # import_feed(message_data["feed_url"])
                    message.ack()
    ...         else:
    ...             raise Exception("Unknown action: %s" % action)

    >>> publisher = FeedPublisher(connection=conn)
    >>> publisher.import_feed("http://cnn.com/rss/edition.rss")
    >>> publisher.close()

    >>> consumer = FeedConsumer(connection=conn)
    >>> consumer.wait() # Go into the consumer loop.

Getting Help
============

Mailing list
------------

Join the `carrot-users`_ mailing list.

.. _`carrot-users`: http://groups.google.com/group/carrot-users/

Bug tracker
===========

If you have any suggestions, bug reports or annoyances please report them
to our issue tracker at http://github.com/ask/carrot/issues/

Contributing
============

Development of ``carrot`` happens at Github: http://github.com/ask/carrot

You are highly encouraged to participate in the development. If you don't
like Github (for some reason) you're welcome to send regular patches.

License
=======

This software is licensed under the ``New BSD License``. See the ``LICENSE``
file in the top distribution directory for the full license text.

##############################################
 carrot - AMQP Messaging Framework for Python
##############################################

:Version: 0.10.7

**NOTE** This release contains backward-incompatible changes.
Please read the `Changelog`_ for more information.

.. _`Changelog`: http://ask.github.com/carrot/changelog.html


Introduction
------------

`carrot` is an `AMQP`_ messaging queue framework. AMQP is the Advanced Message
Queuing Protocol, an open standard protocol for message orientation, queuing,
routing, reliability and security.

The aim of `carrot` is to make messaging in Python as easy as possible by
providing a high-level interface for producing and consuming messages. At the
same time it is a goal to re-use what is already available as much as possible.

`carrot` has pluggable messaging back-ends, so it is possible to support
several messaging systems. Currently, there is support for `AMQP`_
(`py-amqplib`_, `pika`_), `STOMP`_ (`python-stomp`_). There's also an
in-memory backend for testing purposes, using the `Python queue module`_.

Several AMQP message broker implementations exists, including `RabbitMQ`_,
`ZeroMQ`_ and `Apache ActiveMQ`_. You'll need to have one of these installed,
personally we've been using `RabbitMQ`_.

Before you start playing with ``carrot``, you should probably read up on
AMQP, and you could start with the excellent article about using RabbitMQ
under Python, `Rabbits and warrens`_. For more detailed information, you can
refer to the `Wikipedia article about AMQP`_.

.. _`RabbitMQ`: http://www.rabbitmq.com/
.. _`ZeroMQ`: http://www.zeromq.org/
.. _`AMQP`: http://amqp.org
.. _`STOMP`: http://stomp.codehaus.org
.. _`python-stomp`: http://bitbucket.org/asksol/python-stomp
.. _`Python Queue module`: http://docs.python.org/library/queue.html
.. _`Apache ActiveMQ`: http://activemq.apache.org/
.. _`Django`: http://www.djangoproject.com/
.. _`Rabbits and warrens`: http://blogs.digitar.com/jjww/2009/01/rabbits-and-warrens/
.. _`py-amqplib`: http://barryp.org/software/py-amqplib/
.. _`pika`: http://github.com/tonyg/pika
.. _`Wikipedia article about AMQP`: http://en.wikipedia.org/wiki/AMQP

Documentation
-------------

Carrot is using Sphinx, and the latest documentation is available at GitHub:

    http://github.com/ask/carrot/

Installation
============

You can install ``carrot`` either via the Python Package Index (PyPI)
or from source.

To install using ``pip``,::

    $ pip install carrot


To install using ``easy_install``,::

    $ easy_install carrot


If you have downloaded a source tarball you can install it
by doing the following,::

    $ python setup.py build
    # python setup.py install # as root


Terminology
===========

There are some concepts you should be familiar with before starting:

    * Publishers

        Publishers sends messages to an exchange.

    * Exchanges

        Messages are sent to exchanges. Exchanges are named and can be
        configured to use one of several routing algorithms. The exchange
        routes the messages to consumers by matching the routing key in the
        message with the routing key the consumer provides when binding to
        the exchange.

    * Consumers

        Consumers declares a queue, binds it to a exchange and receives
        messages from it.

    * Queues

        Queues receive messages sent to exchanges. The queues are declared
        by consumers.

    * Routing keys

        Every message has a routing key.  The interpretation of the routing
        key depends on the exchange type. There are four default exchange
        types defined by the AMQP standard, and vendors can define custom
        types (so see your vendors manual for details).

        These are the default exchange types defined by AMQP/0.8:

            * Direct exchange

                Matches if the routing key property of the message and
                the ``routing_key`` attribute of the consumer are identical.

            * Fan-out exchange

                Always matches, even if the binding does not have a routing
                key.

            * Topic exchange

                Matches the routing key property of the message by a primitive
                pattern matching scheme. The message routing key then consists
                of words separated by dots (``"."``, like domain names), and
                two special characters are available; star (``"*"``) and hash
                (``"#"``). The star matches any word, and the hash matches
                zero or more words. For example ``"*.stock.#"`` matches the
                routing keys ``"usd.stock"`` and ``"eur.stock.db"`` but not
                ``"stock.nasdaq"``.


Examples
========

Creating a connection
---------------------

    You can set up a connection by creating an instance of
    ``carrot.messaging.BrokerConnection``, with the appropriate options for
    your broker:

    >>> from carrot.connection import BrokerConnection
    >>> conn = BrokerConnection(hostname="localhost", port=5672,
    ...                           userid="test", password="test",
    ...                           virtual_host="test")


    If you're using Django you can use the
    ``carrot.connection.DjangoBrokerConnection`` class instead, which loads
    the connection settings from your ``settings.py``::

       BROKER_HOST = "localhost"
       BROKER_PORT = 5672
       BROKER_USER = "test"
       BROKER_PASSWORD = "secret"
       BROKER_VHOST = "/test"

    Then create a connection by doing:

        >>> from carrot.connection import DjangoBrokerConnection
        >>> conn = DjangoBrokerConnection()



Receiving messages using a Consumer
-----------------------------------

First we open up a Python shell and start a message consumer.

This consumer declares a queue named ``"feed"``, receiving messages with
the routing key ``"importer"`` from the ``"feed"`` exchange.

The example then uses the consumers ``wait()`` method to go into consume
mode, where it continuously polls the queue for new messages, and when a
message is received it passes the message to all registered callbacks.

    >>> from carrot.messaging import Consumer
    >>> consumer = Consumer(connection=conn, queue="feed",
    ...                     exchange="feed", routing_key="importer")
    >>> def import_feed_callback(message_data, message):
    ...     feed_url = message_data["import_feed"]
    ...     print("Got feed import message for: %s" % feed_url)
    ...     # something importing this feed url
    ...     # import_feed(feed_url)
    ...     message.ack()
    >>> consumer.register_callback(import_feed_callback)
    >>> consumer.wait() # Go into the consumer loop.

Sending messages using a Publisher
----------------------------------

Then we open up another Python shell to send some messages to the consumer
defined in the last section.

    >>> from carrot.messaging import Publisher
    >>> publisher = Publisher(connection=conn,
    ...                       exchange="feed", routing_key="importer")
    >>> publisher.send({"import_feed": "http://cnn.com/rss/edition.rss"})
    >>> publisher.close()


Look in the first Python shell again (where ``consumer.wait()`` is running),
where the following text has been printed to the screen::

   Got feed import message for: http://cnn.com/rss/edition.rss  


Serialization of Data
-----------------------

By default every message is encoded using `JSON`_, so sending
Python data structures like dictionaries and lists works.
`YAML`_, `msgpack`_ and Python's built-in ``pickle`` module is also supported,
and if needed you can register any custom serialization scheme you
want to use.

.. _`JSON`: http://www.json.org/
.. _`YAML`: http://yaml.org/
.. _`msgpack`: http://msgpack.sourceforge.net/

Each option has its advantages and disadvantages.

``json`` -- JSON is supported in many programming languages, is now
    a standard part of Python (since 2.6), and is fairly fast to 
    decode using the modern Python libraries such as ``cjson or 
    ``simplejson``.
    
    The primary disadvantage to ``JSON`` is that it limits you to 
    the following data types: strings, unicode, floats, boolean, 
    dictionaries, and lists.  Decimals and dates are notably missing.
    
    Also, binary data will be transferred using base64 encoding, which
    will cause the transferred data to be around 34% larger than an 
    encoding which supports native binary types. 
    
    However, if your data fits inside the above constraints and 
    you need cross-language support, the default setting of ``JSON``
    is probably your best choice. 
    
``pickle`` -- If you have no desire to support any language other than
    Python, then using the ``pickle`` encoding will gain you 
    the support of all built-in Python data types (except class instances), 
    smaller messages when sending binary files, and a slight speedup
    over ``JSON`` processing.

``yaml`` -- YAML has many of the same characteristics as ``json``, 
    except that it natively supports more data types (including dates, 
    recursive references, etc.)
    
    However, the Python libraries for YAML are a good bit slower
    than the libraries for JSON. 
    
    If you need a more expressive set of data types and need to maintain
    cross-language compatibility, then ``YAML`` may be a better fit
    than the above. 

To instruct carrot to use an alternate serialization method, 
use one of the following options.

    1.  Set the serialization option on a per-Publisher basis: 
        
            >>> from carrot.messaging import Publisher
            >>> publisher = Publisher(connection=conn,
            ...                       exchange="feed", routing_key="importer",
            ...                       serializer="yaml")

    2.  Set the serialization option on a per-call basis

            >>> from carrot.messaging import Publisher
            >>> publisher = Publisher(connection=conn,
            ...                       exchange="feed", routing_key="importer")
            >>> publisher.send({"import_feed": "http://cnn.com/rss/edition.rss"}, 
            ...                serializer="pickle")
            >>> publisher.close()

Note that ``Consumer``s do not need the serialization method specified in 
their code.  They can auto-detect the serialization method since we supply 
the ``Content-type`` header as part of the AMQP message.


Sending raw data without Serialization
---------------------------------------

In some cases, you don't need your message data to be serialized. If you
pass in a plain string or unicode object as your message, then carrot will
not waste cycles serializing/deserializing the data.

You can optionally specify a ``content_type`` and ``content_encoding``
for the raw data:

    >>> from carrot.messaging import Publisher
    >>> publisher = Publisher(connection=conn,
    ...                       exchange="feed",
                              routing_key="import_pictures")
    >>> publisher.send(open('~/my_picture.jpg','rb').read(), 
                       content_type="image/jpeg", 
                       content_encoding="binary")
    >>> publisher.close()
    
The ``message`` object returned by the ``Consumer`` class will have a 
``content_type`` and ``content_encoding`` attribute. 


Receiving messages without a callback
--------------------------------------

You can also poll the queue manually, by using the ``fetch`` method.
This method returns a ``Message`` object, from where you can get the
message body, de-serialize the body to get the data, acknowledge, reject or
re-queue the message.

    >>> consumer = Consumer(connection=conn, queue="feed",
    ...                     exchange="feed", routing_key="importer")
    >>> message = consumer.fetch()
    >>> if message:
    ...    message_data = message.payload
    ...    message.ack()
    ... else:
    ...     # No messages waiting on the queue.
    >>> consumer.close()

Sub-classing the messaging classes
----------------------------------

The ``Consumer``, and ``Publisher`` classes can also be sub classed. Thus you
can define the above publisher and consumer like so:

    >>> from carrot.messaging import Publisher, Consumer

    >>> class FeedPublisher(Publisher):
    ...     exchange = "feed"
    ...     routing_key = "importer"
    ...
    ...     def import_feed(self, feed_url):
    ...         return self.send({"action": "import_feed",
    ...                           "feed_url": feed_url})

    >>> class FeedConsumer(Consumer):
    ...     queue = "feed"
    ...     exchange = "feed"
    ...     routing_key = "importer"
    ...
    ...     def receive(self, message_data, message):
    ...         action = message_data["action"]
    ...         if action == "import_feed":
    ...             # something importing this feed
    ...             # import_feed(message_data["feed_url"])
                    message.ack()
    ...         else:
    ...             raise Exception("Unknown action: %s" % action)

    >>> publisher = FeedPublisher(connection=conn)
    >>> publisher.import_feed("http://cnn.com/rss/edition.rss")
    >>> publisher.close()

    >>> consumer = FeedConsumer(connection=conn)
    >>> consumer.wait() # Go into the consumer loop.

Getting Help
============

Mailing list
------------

Join the `carrot-users`_ mailing list.

.. _`carrot-users`: http://groups.google.com/group/carrot-users/

Bug tracker
===========

If you have any suggestions, bug reports or annoyances please report them
to our issue tracker at http://github.com/ask/carrot/issues/

Contributing
============

Development of ``carrot`` happens at Github: http://github.com/ask/carrot

You are highly encouraged to participate in the development. If you don't
like Github (for some reason) you're welcome to send regular patches.

License
=======

This software is licensed under the ``New BSD License``. See the ``LICENSE``
file in the top distribution directory for the full license text.

Coverage: code coverage testing for Python

Coverage measures code coverage, typically during test execution.  It uses the
code analysis tools and tracing hooks provided in the Python standard library
to determine which lines are executable, and which have been executed.

For more information, see http://nedbatchelder.com/code/coverage

Code repo and issue tracking are at http://bitbucket.org/ned/coveragepy

==========
GitPython
==========

GitPython is a python library used to interact with Git repositories.

GitPython is a port of the grit_ library in Ruby created by 
Tom Preston-Werner and Chris Wanstrath.

.. _grit: http://grit.rubyforge.org

REQUIREMENTS
============

* Git_ tested with 1.5.3.7
* `Python Nose`_ - used for running the tests
* `Mock by Michael Foord`_ used for tests. Requires 0.4

.. _Git: http://git.or.cz/
.. _Python Nose: http://code.google.com/p/python-nose/
.. _Mock by Michael Foord: http://www.voidspace.org.uk/python/mock.html

INSTALL
=======

    python setup.py install

SOURCE
======

GitPython's git repo is available on Gitorious, which can be browsed at:

http://gitorious.org/projects/git-python/

and cloned from:

git://gitorious.org/git-python/mainline.git

LICENSE
=======

New BSD License.  See the LICENSE file.

This is python client library for Google's discovery based APIs.


Installation
============

To install, simply use pip or easy_install:

   $ pip --upgrade google-api-python-client

   $ easy_install --upgrade google-api-python-client

See the Developers Guide for more detailed instructions and documentation:

  https://developers.google.com/api-client-library/python/start/get_started


Third Party Libraries
=====================

These libraries will be installed when you install the client library:

http://code.google.com/p/httplib2
http://code.google.com/p/uri-templates
http://code.google.com/p/python-gflags

Depending on your version of Python, these libraries may also be installed:

http://pypi.python.org/pypi/simplejson/

For development you will also need:

http://pythonpaste.org/webtest/

httplib2 for Python 3

This directory contains a port of httplib2 to Python 3. As you may
know, Python 3 is not backward-compatible with Python 2. The biggest
change in Python 3 (that affects httplib2) is the distinction between
bytes and strings.

To successfully use http2lib for Python 3, you absolutely must
understand the following sentence:

** THE RESPONSE HEADERS ARE STRINGS, BUT THE CONTENT BODY IS BYTES **


Example:

>>> import httplib2, pprint
>>> h = httplib2.Http(".cache")
>>> (resp_headers, content) = h.request("http://example.org/", "GET")
>>> pprint.pprint(resp_headers)
{'accept-ranges': 'bytes',
 'connection': 'close',
 'content-length': '438',
 'content-location': 'http://example.org/',
 'content-type': 'text/html; charset=UTF-8',
 'date': 'Fri, 29 May 2009 03:57:29 GMT',
 'etag': '"b80f4-1b6-80bfd280"',
 'last-modified': 'Tue, 15 Nov 2005 13:24:10 GMT',
 'server': 'Apache/2.2.3 (CentOS)',
 'status': '200'}
>>> type(content)
<class 'bytes'>
>>> content[:49]
b'<HTML>\r\n<HEAD>\r\n  <TITLE>Example Web Page</TITLE>'


Further reading:

  * http://diveintopython3.org/strings.html
  * http://docs.python.org/3.0/whatsnew/3.0.html#text-vs-data-instead-of-unicode-vs-8-bit
  * http://docs.python.org/3.0/howto/unicode.html


--------------------------------------------------------------------
Httplib2 Software License

Copyright (c) 2006 by Joe Gregorio
Copyright (c) 2009 by Mark Pilgrim

Permission is hereby granted, free of charge, to any person 
obtaining a copy of this software and associated documentation 
files (the "Software"), to deal in the Software without restriction, 
including without limitation the rights to use, copy, modify, merge, 
publish, distribute, sublicense, and/or sell copies of the Software, 
and to permit persons to whom the Software is furnished to do so, 
subject to the following conditions:

The above copyright notice and this permission notice shall be 
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, 
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES 
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND 
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS 
BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN 
ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN 
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE 
SOFTWARE.


Httplib2

--------------------------------------------------------------------
Introduction

A comprehensive HTTP client library, httplib2.py supports many 
features left out of other HTTP libraries.

HTTP and HTTPS
    HTTPS support is only available if the socket module was 
    compiled with SSL support. 
Keep-Alive
    Supports HTTP 1.1 Keep-Alive, keeping the socket open and 
    performing multiple requests over the same connection if 
    possible. 
Authentication
    The following three types of HTTP Authentication are 
    supported. These can be used over both HTTP and HTTPS.

        * Digest
        * Basic
        * WSSE

Caching
    The module can optionally operate with a private cache that 
    understands the Cache-Control: header and uses both the ETag 
    and Last-Modified cache validators. 
All Methods
    The module can handle any HTTP request method, not just GET 
    and POST.
Redirects
    Automatically follows 3XX redirects on GETs.
Compression
    Handles both 'deflate' and 'gzip' types of compression.
Lost update support
    Automatically adds back ETags into PUT requests to resources 
    we have already cached. This implements Section 3.2 of 
    Detecting the Lost Update Problem Using Unreserved Checkout.
Unit Tested
    A large and growing set of unit tests. 


For more information on this module, see:

    http://bitworking.org/projects/httplib2/


--------------------------------------------------------------------
Installation

The httplib2 module is shipped as a distutils package.  To install
the library, unpack the distribution archive, and issue the following
command:

    $ python setup.py install


--------------------------------------------------------------------
Usage
A simple retrieval:

  import httplib2
  h = httplib2.Http(".cache")
  (resp_headers, content) = h.request("http://example.org/", "GET")

The 'content' is the content retrieved from the URL. The content 
is already decompressed or unzipped if necessary.

To PUT some content to a server that uses SSL and Basic authentication:

  import httplib2
  h = httplib2.Http(".cache")
  h.add_credentials('name', 'password')
  (resp, content) = h.request("https://example.org/chapter/2", 
                            "PUT", body="This is text", 
                            headers={'content-type':'text/plain'} )

Use the Cache-Control: header to control how the caching operates.

  import httplib2
  h = httplib2.Http(".cache")
  (resp, content) = h.request("http://bitworking.org/", "GET")
  ...
  (resp, content) = h.request("http://bitworking.org/", "GET", 
                            headers={'cache-control':'no-cache'})

The first request will be cached and since this is a request 
to bitworking.org it will be set to be cached for two hours, 
because that is how I have my server configured. Any subsequent 
GET to that URI will return the value from the on-disk cache 
and no request will be made to the server. You can use the 
Cache-Control: header to change the caches behavior and in 
this example the second request adds the Cache-Control: 
header with a value of 'no-cache' which tells the library 
that the cached copy must not be used when handling this request. 


--------------------------------------------------------------------
Httplib2 Software License

Copyright (c) 2006 by Joe Gregorio

Permission is hereby granted, free of charge, to any person 
obtaining a copy of this software and associated documentation 
files (the "Software"), to deal in the Software without restriction, 
including without limitation the rights to use, copy, modify, merge, 
publish, distribute, sublicense, and/or sell copies of the Software, 
and to permit persons to whom the Software is furnished to do so, 
subject to the following conditions:

The above copyright notice and this permission notice shall be 
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, 
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES 
OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND 
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS 
BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN 
ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN 
CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE 
SOFTWARE.


Purpose
========

This package contains the code from importlib as found in Python 2.7. It is
provided so that people who wish to use importlib.import_module() with a
version of Python prior to 2.7 or in 3.0 have the function readily available.
The code in no way deviates from what can be found in the 2.7 trunk.

For documentation, see the `importlib docs`_ for Python 2.7.

.. _importlib docs: http://docs.python.org/dev/library/importlib.html

ASTNG
=====

What's this ?
-------------

The aim of this module is to provide a common base representation of
python source code for projects such as pychecker, pyreverse,
pylint... Well, actually the development of this library is essentially
governed by pylint's needs.

Since 0.18, it provides a compatible representation which may come
from the `compiler` module (for python <= 2.4) pr the `_ast` module
(for python >= 2.5).

It rebuilds the tree generated by the compiler.ast [1] module or by
the builtin _ast module by recursively walking down the AST and
building an extended ast (let's call it astng ;). The new node classes
have additional methods and attributes for different usages.
They include some support for static inference and local name scopes.
Furthermore, astng builds partial trees by inspecting living objects.

Main modules are:

* `bases`, `node_classses` and `scoped_nodes` contain the classes for the
  different type of nodes of the tree.

* the `manager` contains a high level object to get astng trees from
  source files and living objects. It maintains a cache of previously
  constructed tree for quick access


Installation
------------

Extract the tarball, jump into the created directory and run ::

	python setup.py install

For installation options, see ::

	python setup.py install --help


If you have any questions, please mail the
python-project@lists.logilab.org mailing list for support. See
http://lists.logilab.org/mailman/listinfo/python-projects for
subscription information and archives.

Sylvain Thénault
Oct 21, 2005, updated on Aug 26 2009.

XXX deprecated, update by describing the unified tree structure, how we achieve this and remaining differences...

this branch aims to provide compatibility between the `compiler` module and the
new `_ast` module provided by python >= 2.5.

The problem is that there are several differences between both representations:
* class names
* attributes of those classes
* structure of the tree

So whatever the backend used, astng will return a somewhat compatible tree
which is a mix of compiler and _ast tree. Hopefully it will
evolve to stick to the _ast representation, though at this time I want to
minimize backward incompatibilities, so pylint for instance can work with this
new representation without too much modifications.

Nodes' class names will still differ, though the provided visitor will map _ast
class names to compiler class names (e.g. for instance when a `_ast.ClassDef` node
is visited, the `visit_class` method will be called). This is done to ease
compatibility with code using earlier astng version.

Attribute names are made compatible, and I've chosen _ast or compiler's name
by using the most relevant, imo. Those can be found using the `_astng_fields`
attribute on each node class.

In the same way tree structure is made compatible, using the simplest or the
more expressive alternative.

The work is not yet finished: XXX insert what's missing here.
The primary goal is to have test working with python >= 2.5, and then to have
pylint tests green as well when using the _ast backend.



Of course all of this is discussable, and I've made choices to have something
working with the minimal amount of work, both in astng or in client code, even
if as I said above I would like at some point to be as close as possible to
the _ast representation.


Note: this may be interesting at some point:
http://lucumr.pocoo.org/cogitations/2008/03/30/high-level-ast-module-for-python

Logilab's common library
========================

What's this ?
-------------

This package contains some modules used by differents Logilab's
projects.

It is released under the GNU Public License.

There is no documentation available yet but the source code should be
clean and well documented.

Designed to ease:

* handling command line options and configuration files
* writing interactive command line tools
* manipulation files and character strings
* interfacing to OmniORB
* generating SQL queries
* running unit tests
* manipulating tree structures
* generating text and HTML reports
* logging
* parsing XML processing instructions
* more...


Installation
------------

Extract the tarball, jump into the created directory and run ::

	python setup.py install

For installation options, see ::

	python setup.py install --help


Provided modules
----------------

Here is a brief description of the available modules :

* adbh.py:
  helper functions for using database advanced. Supported RDBMS
  include PostgreSQL, MySQL and sqlite. See also db.py.

* astutils:
  Deprecated module. Use logilab.astng.

* bind.py :
  Deprecated module.
  Provides a way to optimize globals in certain functions by binding
  their names to values provided in a dictionary.

* cache.py :
  A cache implementation with a least recently used algorithm.

* clcommands.py:
  helper functions for command line programs handling different
  subcommands

* cli.py :
  Command line interface helper classes (for interactive programs
  using the command line)

* compat.py:
  Transparent compatibility layer between different python version

* configuration.py :
  Two mix-in classes to handle configuration from both command line
  (using optik/optparse) and configuration file.

* corbautils.py:
  Useful functions for use with the OmniORB CORBA library.

* daemon.py :
  A daemon mix-in class.

* date.py:
  date manipulation helper functions

* db.py :
  A generic method to get a database connection. See also adbh.py.

* debugger.py:
  pdb customization

* decorators.py:
  useful decorators (cached, timed...)

* deprecation.py:
  mark functions / classes as deprecated or moved

* fileutils.py :
  Some file / file path manipulation utilities.

* graph.py:
  graph manipulations, dot file generation

* html.py :
  Deprecated module
  Return an html formatted traceback from python exception infos.

* interface.py
  Bases class for interfaces.

* logger.py :
  Deprecated module : use logging from stdlib.
  Define a logger interface and two concrete loggers : one which prints
  everything on stdout, the other using syslog.

* logging_ext.py:
  extensions to stdlib's logging module

* logservice.py:
  Deprecated module. Use logging from stdlib.

* modutils.py :
  Module manipulation utilities.

* monclient.py:
  Deprecated module

* monserver.py:
  Deprecated module

* optik_ext :
  Add an abstraction level to transparently import optik classes from
  optparse (python >= 2.3) or the optik package. It also defines two
  new option types (regexp, csv, color, date...)

* optparser.py:
  extend optparse's OptionParser to support commands

* patricia.py :
  A Python implementation of PATRICIA trie (Practical Algorithm to
  Retrieve Information Coded in Alphanumeric).

* pdf_ext.py:
  pdf and fdf file manipulations, with pdftk.

* pytest.py:
  unittest runner. See testlib

* shellutils.py:
  Some utilities to replace shell scripts with python scripts.

* sqlgen.py :
  Helper class to generate SQL strings to use with python's DB-API.

* table.py:
  manage tabular data (supports column and row names, sorting, grouping...

* testlib.py :
  Generic tests execution methods.

* textutils.py:
  Some text manipulation utilities (ansi colorization, line wrapping,
  rest support...)

* tree.py :
  Base class to represent tree structure, and some others to make it
  works with the visitor implementation (see below).

* umessage.py:
  unicode email support

* ureports:
  Provides a way to create simple reports using python objects
  without care of the final formatting. Some formatters text and html
  are provided.

* vcgutils.py :
  utilities functions to generate file readable with Georg Sander's vcg
  (Visualization of Compiler Graphs).

* visitor.py :
  A generic visitor pattern implementation.

* twisted_distutils.py
  This module enables the installation of plugins.tml files using standard
  distutils syntax. Note that you can use this to install files that
  are not twisted plugins in any package directory of your application.

* xmlrpcutils.py:
  Auth support for XML RPC

Comments, support, bug reports
------------------------------

Project page http://www.logilab.org/project/logilab-common

Use the python-projects@lists.logilab.org mailing list. Since we do not have
publicly available bug tracker yet, bug reports should be emailed
there too.

You can subscribe to this mailing list at
http://lists.logilab.org/mailman/listinfo/python-projects

Archives are available at
http://lists.logilab.org/pipermail/python-projects/

thank you

thank you

thank you

thank you

thank you

This module provides basic functions for parsing mime-type names and matching them against a list of media-ranges.

See section 14.1 of RFC 2616 (the HTTP specification) for a complete explanation.

Testing
=======
The format of the JSON test data file is as follows:
A top-level JSON object which has a key for each of the functions to be tested. The value corresponding to that key is a list of tests. Each test contains: the argument or arguments to the function being tested, the expected results and an optional description.


Python
======
The Python tests require either Python 2.6 or the installation of the SimpleJSON library.

Installing SimpleJson can be done by:
sudo easy_install simplejson

Run the tests by typing:
python mimeparse_test.py

mock is a Python module that provides a core Mock class. It removes the need
to create a host of stubs throughout your test suite. After performing an
action, you can make assertions about which methods / attributes were used and
arguments they were called with. You can also specify return values and set
needed attributes in the normal way.

mock is tested on Python versions 2.4-2.7 and Python 3.

The mock module also provides utility functions / objects to assist with
testing, particularly monkey patching.

* `PDF documentation for 0.7.0
  <http://www.voidspace.org.uk/downloads/mock-0.7.0.pdf>`_
* `mock on google code (repository and issue tracker)
  <http://code.google.com/p/mock/>`_
* `mock documentation
  <http://www.voidspace.org.uk/python/mock/>`_
* `mock on PyPI <http://pypi.python.org/pypi/mock/>`_
* `Mailing list (testing-in-python@lists.idyll.org)
  <http://lists.idyll.org/listinfo/testing-in-python>`_

Mock is very easy to use and is designed for use with
`unittest <http://pypi.python.org/pypi/unittest2>`_. Mock is based on
the 'action -> assertion' pattern instead of 'record -> replay' used by many
mocking frameworks. See the
`mock documentation <http://www.voidspace.org.uk/python/mock/>`_ for full
details.

Mock objects create all attributes and methods as you access them and store
details of how they have been used. You can configure them, to specify return
values or limit what attributes are available, and then make assertions about
how they have been used::

    >>> from mock import Mock
    >>> real = ProductionClass()
    >>> real.method = Mock(return_value=3)
    >>> real.method(3, 4, 5, key='value')
    3
    >>> real.method.assert_called_with(3, 4, 5, key='value')

``side_effect`` allows you to perform side effects, return different values or
raise an exception when a mock is called::

   >>> from mock import Mock
   >>> mock = Mock(side_effect=KeyError('foo'))
   >>> mock()
   Traceback (most recent call last):
    ...
   KeyError: 'foo'
   >>> values = [1, 2, 3]
   >>> def side_effect():
   ...     return values.pop()
   ...
   >>> mock.side_effect = side_effect
   >>> mock(), mock(), mock()
   (3, 2, 1)

Mock has many other ways you can configure it and control its behaviour. For
example the ``spec`` argument configures the mock to take its specification from
another object. Attempting to access attributes or methods on the mock that
don't exist on the spec will fail with an ``AttributeError``.

The ``patch`` decorator / context manager makes it easy to mock classes or
objects in a module under test. The object you specify will be replaced with a
mock (or other object) during the test and restored when the test ends::

    >>> from mock import patch
    >>> @patch('test_module.ClassName1')
    ... @patch('test_module.ClassName2')
    ... def test(MockClass2, MockClass1):
    ...     test_module.ClassName1()
    ...     test_module.ClassName2()

    ...     assert MockClass1.called
    ...     assert MockClass2.called
    ...
    >>> test()

.. note::

   When you nest patch decorators the mocks are passed in to the decorated
   function in the same order they applied (the normal *python* order that
   decorators are applied). This means from the bottom up, so in the example
   above the mock for `test_module.ClassName2` is passed in first.

   With `patch` it matters that you patch objects in the namespace where they
   are looked up. This is normally straightforward, but for a quick guide
   read `where to patch
   <http://www.voidspace.org.uk/python/mock/patch.html#where-to-patch>`_.

As well as a decorator `patch` can be used as a context manager in a with
statement::

    >>> with patch.object(ProductionClass, 'method') as mock_method:
    ...     mock_method.return_value = None
    ...     real = ProductionClass()
    ...     real.method(1, 2, 3)
    ...
    >>> mock_method.assert_called_with(1, 2, 3)

There is also `patch.dict` for setting values in a dictionary just during the
scope of a test and restoring the dictionary to its original state when the
test ends::

   >>> foo = {'key': 'value'}
   >>> original = foo.copy()
   >>> with patch.dict(foo, {'newkey': 'newvalue'}, clear=True):
   ...     assert foo == {'newkey': 'newvalue'}
   ...
   >>> assert foo == original

Mock now supports the mocking of Python magic methods. The easiest way of
using magic methods is with the ``MagicMock`` class. It allows you to do
things like::

    >>> from mock import MagicMock
    >>> mock = MagicMock()
    >>> mock.__str__.return_value = 'foobarbaz'
    >>> str(mock)
    'foobarbaz'
    >>> mock.__str__.assert_called_with()

Mock allows you to assign functions (or other Mock instances) to magic methods
and they will be called appropriately. The MagicMock class is just a Mock
variant that has all of the magic methods pre-created for you (well - all the
useful ones anyway).

The following is an example of using magic methods with the ordinary Mock
class::

    >>> from mock import Mock
    >>> mock = Mock()
    >>> mock.__str__ = Mock()
    >>> mock.__str__.return_value = 'wheeeeee'
    >>> str(mock)
    'wheeeeee'

`mocksignature` is a useful companion to Mock and patch. It creates
copies of functions that delegate to a mock, but have the same signature as the
original function. This ensures that your mocks will fail in the same way as
your production code if they are called incorrectly::

   >>> from mock import mocksignature
   >>> def function(a, b, c):
   ...     pass
   ...
   >>> function2 = mocksignature(function)
   >>> function2.mock.return_value = 'fishy'
   >>> function2(1, 2, 3)
   'fishy'
   >>> function2.mock.assert_called_with(1, 2, 3)
   >>> function2('wrong arguments')
   Traceback (most recent call last):
    ...
   TypeError: <lambda>() takes exactly 3 arguments (1 given)

`mocksignature` can also be used on classes, where it copies the signature of
the `__init__` method, and on callable objects where it copies the signature of
the `__call__` method.

The distribution contains tests and documentation. The tests require
`unittest2 <http://pypi.python.org/pypi/unittest2>`_ to run.


Basic usage
***********

Use the nosetests script (after installation by setuptools):

   nosetests [options] [(optional) test files or directories]

In addition to passing command-line options, you may also put
configuration options in a .noserc or nose.cfg file in your home
directory. These are standard .ini-style config files. Put your
nosetests configuration in a [nosetests] section, with the -- prefix
removed:

   [nosetests]
   verbosity=3
   with-doctest=1

There are several other ways to use the nose test runner besides the
*nosetests* script. You may use nose in a test script:

   import nose
   nose.main()

If you don't want the test script to exit with 0 on success and 1 on
failure (like unittest.main), use nose.run() instead:

   import nose
   result = nose.run()

*result* will be true if the test run succeeded, or false if any test
failed or raised an uncaught exception. Lastly, you can run nose.core
directly, which will run nose.main():

   python /path/to/nose/core.py

Please see the usage message for the nosetests script for information
about how to control which tests nose runs, which plugins are loaded,
and the test output.


Extended usage
==============

nose collects tests automatically from python source files,
directories and packages found in its working directory (which
defaults to the current working directory). Any python source file,
directory or package that matches the testMatch regular expression (by
default: *(?:^|[b_.-])[Tt]est)* will be collected as a test (or source
for collection of tests). In addition, all other packages found in the
working directory will be examined for python source files or
directories that match testMatch. Package discovery descends all the
way down the tree, so package.tests and package.sub.tests and
package.sub.sub2.tests will all be collected.

Within a test directory or package, any python source file matching
testMatch will be examined for test cases. Within a test module,
functions and classes whose names match testMatch and TestCase
subclasses with any name will be loaded and executed as tests. Tests
may use the assert keyword or raise AssertionErrors to indicate test
failure. TestCase subclasses may do the same or use the various
TestCase methods available.


Selecting Tests
---------------

To specify which tests to run, pass test names on the command line:

   nosetests only_test_this.py

Test names specified may be file or module names, and may optionally
indicate the test case to run by separating the module or file name
from the test case name with a colon. Filenames may be relative or
absolute. Examples:

   nosetests test.module
   nosetests another.test:TestCase.test_method
   nosetests a.test:TestCase
   nosetests /path/to/test/file.py:test_function

You may also change the working directory where nose looks for tests
by using the -w switch:

   nosetests -w /path/to/tests

Note, however, that support for multiple -w arguments is now
deprecated and will be removed in a future release. As of nose 0.10,
you can get the same behavior by specifying the target directories
*without* the -w switch:

   nosetests /path/to/tests /another/path/to/tests

Further customization of test selection and loading is possible
through the use of plugins.

Test result output is identical to that of unittest, except for the
additional features (error classes, and plugin-supplied features such
as output capture and assert introspection) detailed in the options
below.


Configuration
-------------

In addition to passing command-line options, you may also put
configuration options in your project's *setup.cfg* file, or a .noserc
or nose.cfg file in your home directory. In any of these standard
.ini-style config files, you put your nosetests configuration in a
``[nosetests]`` section. Options are the same as on the command line,
with the -- prefix removed. For options that are simple switches, you
must supply a value:

   [nosetests]
   verbosity=3
   with-doctest=1

All configuration files that are found will be loaded and their
options combined. You can override the standard config file loading
with the ``-c`` option.


Using Plugins
-------------

There are numerous nose plugins available via easy_install and
elsewhere. To use a plugin, just install it. The plugin will add
command line options to nosetests. To verify that the plugin is
installed, run:

   nosetests --plugins

You can add -v or -vv to that command to show more information about
each plugin.

If you are running nose.main() or nose.run() from a script, you can
specify a list of plugins to use by passing a list of plugins with the
plugins keyword argument.


0.9 plugins
-----------

nose 1.0 can use SOME plugins that were written for nose 0.9. The
default plugin manager inserts a compatibility wrapper around 0.9
plugins that adapts the changed plugin api calls. However, plugins
that access nose internals are likely to fail, especially if they
attempt to access test case or test suite classes. For example,
plugins that try to determine if a test passed to startTest is an
individual test or a suite will fail, partly because suites are no
longer passed to startTest and partly because it's likely that the
plugin is trying to find out if the test is an instance of a class
that no longer exists.


0.10 and 0.11 plugins
---------------------

All plugins written for nose 0.10 and 0.11 should work with nose 1.0.


Options
-------

-V, --version

   Output nose version and exit

-p, --plugins

   Output list of available plugins and exit. Combine with higher
   verbosity for greater detail

-v=DEFAULT, --verbose=DEFAULT

   Be more verbose. [NOSE_VERBOSE]

--verbosity=VERBOSITY

   Set verbosity; --verbosity=2 is the same as -v

-q=DEFAULT, --quiet=DEFAULT

   Be less verbose

-c=FILES, --config=FILES

   Load configuration from config file(s). May be specified multiple
   times; in that case, all config files will be loaded and combined

-w=WHERE, --where=WHERE

   Look for tests in this directory. May be specified multiple times.
   The first directory passed will be used as the working directory,
   in place of the current working directory, which is the default.
   Others will be added to the list of tests to execute. [NOSE_WHERE]

--py3where=PY3WHERE

   Look for tests in this directory under Python 3.x. Functions the
   same as 'where', but only applies if running under Python 3.x or
   above.  Note that, if present under 3.x, this option completely
   replaces any directories specified with 'where', so the 'where'
   option becomes ineffective. [NOSE_PY3WHERE]

-m=REGEX, --match=REGEX, --testmatch=REGEX

   Files, directories, function names, and class names that match this
   regular expression are considered tests.  Default:
   (?:^|[b_./-])[Tt]est [NOSE_TESTMATCH]

--tests=NAMES

   Run these tests (comma-separated list). This argument is useful
   mainly from configuration files; on the command line, just pass the
   tests to run as additional arguments with no switch.

-l=DEFAULT, --debug=DEFAULT

   Activate debug logging for one or more systems. Available debug
   loggers: nose, nose.importer, nose.inspector, nose.plugins,
   nose.result and nose.selector. Separate multiple names with a
   comma.

--debug-log=FILE

   Log debug messages to this file (default: sys.stderr)

--logging-config=FILE, --log-config=FILE

   Load logging config from this file -- bypasses all other logging
   config settings.

-I=REGEX, --ignore-files=REGEX

   Completely ignore any file that matches this regular expression.
   Takes precedence over any other settings or plugins. Specifying
   this option will replace the default setting. Specify this option
   multiple times to add more regular expressions [NOSE_IGNORE_FILES]

-e=REGEX, --exclude=REGEX

   Don't run tests that match regular expression [NOSE_EXCLUDE]

-i=REGEX, --include=REGEX

   This regular expression will be applied to files, directories,
   function names, and class names for a chance to include additional
   tests that do not match TESTMATCH.  Specify this option multiple
   times to add more regular expressions [NOSE_INCLUDE]

-x, --stop

   Stop running tests after the first error or failure

-P, --no-path-adjustment

   Don't make any changes to sys.path when loading tests [NOSE_NOPATH]

--exe

   Look for tests in python modules that are executable. Normal
   behavior is to exclude executable modules, since they may not be
   import-safe [NOSE_INCLUDE_EXE]

--noexe

   DO NOT look for tests in python modules that are executable. (The
   default on the windows platform is to do so.)

--traverse-namespace

   Traverse through all path entries of a namespace package

--first-package-wins, --first-pkg-wins, --1st-pkg-wins

   nose's importer will normally evict a package from sys.modules if
   it sees a package with the same name in a different location. Set
   this option to disable that behavior.

-a=ATTR, --attr=ATTR

   Run only tests that have attributes specified by ATTR [NOSE_ATTR]

-A=EXPR, --eval-attr=EXPR

   Run only tests for whose attributes the Python expression EXPR
   evaluates to True [NOSE_EVAL_ATTR]

-s, --nocapture

   Don't capture stdout (any stdout output will be printed
   immediately) [NOSE_NOCAPTURE]

--nologcapture

   Disable logging capture plugin. Logging configurtion will be left
   intact. [NOSE_NOLOGCAPTURE]

--logging-format=FORMAT

   Specify custom format to print statements. Uses the same format as
   used by standard logging handlers. [NOSE_LOGFORMAT]

--logging-datefmt=FORMAT

   Specify custom date/time format to print statements. Uses the same
   format as used by standard logging handlers. [NOSE_LOGDATEFMT]

--logging-filter=FILTER

   Specify which statements to filter in/out. By default, everything
   is captured. If the output is too verbose, use this option to
   filter out needless output. Example: filter=foo will capture
   statements issued ONLY to  foo or foo.what.ever.sub but not foobar
   or other logger. Specify multiple loggers with comma:
   filter=foo,bar,baz. If any logger name is prefixed with a minus, eg
   filter=-foo, it will be excluded rather than included. Default:
   exclude logging messages from nose itself (-nose). [NOSE_LOGFILTER]

--logging-clear-handlers

   Clear all other logging handlers

--with-coverage

   Enable plugin Coverage:  Activate a coverage report using Ned
   Batchelder's coverage module.  [NOSE_WITH_COVERAGE]

--cover-package=PACKAGE

   Restrict coverage output to selected packages [NOSE_COVER_PACKAGE]

--cover-erase

   Erase previously collected coverage statistics before run

--cover-tests

   Include test modules in coverage report [NOSE_COVER_TESTS]

--cover-inclusive

   Include all python files under working directory in coverage
   report.  Useful for discovering holes in test coverage if not all
   files are imported by the test suite. [NOSE_COVER_INCLUSIVE]

--cover-html

   Produce HTML coverage information

--cover-html-dir=DIR

   Produce HTML coverage information in dir

--pdb

   Drop into debugger on errors

--pdb-failures

   Drop into debugger on failures

--no-deprecated

   Disable special handling of DeprecatedTest exceptions.

--with-doctest

   Enable plugin Doctest:  Activate doctest plugin to find and run
   doctests in non-test modules.  [NOSE_WITH_DOCTEST]

--doctest-tests

   Also look for doctests in test modules. Note that classes, methods
   and functions should have either doctests or non-doctest tests, not
   both. [NOSE_DOCTEST_TESTS]

--doctest-extension=EXT

   Also look for doctests in files with this extension
   [NOSE_DOCTEST_EXTENSION]

--doctest-result-variable=VAR

   Change the variable name set to the result of the last interpreter
   command from the default '_'. Can be used to avoid conflicts with
   the _() function used for text translation.
   [NOSE_DOCTEST_RESULT_VAR]

--doctest-fixtures=SUFFIX

   Find fixtures for a doctest file in module with this name appended
   to the base name of the doctest file

--with-isolation

   Enable plugin IsolationPlugin:  Activate the isolation plugin to
   isolate changes to external modules to a single test module or
   package. The isolation plugin resets the contents of sys.modules
   after each test module or package runs to its state before the
   test. PLEASE NOTE that this plugin should not be used with the
   coverage plugin, or in any other case where module reloading may
   produce undesirable side-effects.  [NOSE_WITH_ISOLATION]

-d, --detailed-errors, --failure-detail

   Add detail to error output by attempting to evaluate failed asserts
   [NOSE_DETAILED_ERRORS]

--with-profile

   Enable plugin Profile:  Use this plugin to run tests using the
   hotshot profiler.   [NOSE_WITH_PROFILE]

--profile-sort=SORT

   Set sort order for profiler output

--profile-stats-file=FILE

   Profiler stats file; default is a new temp file on each run

--profile-restrict=RESTRICT

   Restrict profiler output. See help for pstats.Stats for details

--no-skip

   Disable special handling of SkipTest exceptions.

--with-id

   Enable plugin TestId:  Activate to add a test id (like #1) to each
   test name output. Activate with --failed to rerun failing tests
   only.  [NOSE_WITH_ID]

--id-file=FILE

   Store test ids found in test runs in this file. Default is the file
   .noseids in the working directory.

--failed

   Run the tests that failed in the last test run.

--processes=NUM

   Spread test run among this many processes. Set a number equal to
   the number of processors or cores in your machine for best results.
   [NOSE_PROCESSES]

--process-timeout=SECONDS

   Set timeout for return of results from each test runner process.
   [NOSE_PROCESS_TIMEOUT]

--process-restartworker

   If set, will restart each worker process once their tests are done,
   this helps control memory leaks from killing the system.
   [NOSE_PROCESS_RESTARTWORKER]

--with-xunit

   Enable plugin Xunit: This plugin provides test results in the
   standard XUnit XML format. [NOSE_WITH_XUNIT]

--xunit-file=FILE

   Path to xml file to store the xunit report in. Default is
   nosetests.xml in the working directory [NOSE_XUNIT_FILE]

--all-modules

   Enable plugin AllModules: Collect tests from all python modules.
   [NOSE_ALL_MODULES]

--collect-only

   Enable collect-only:  Collect and output test names only, don't run
   any tests.  [COLLECT_ONLY]

pep8 - Python style guide checker
=================================

pep8 is a tool to check your Python code against some of the style
conventions in `PEP 8`_.

.. _PEP 8: http://www.python.org/dev/peps/pep-0008/


Mailing List
------------
http://groups.google.com/group/pep8


Features
--------

* Plugin architecture: Adding new checks is easy.

* Parseable output: Jump to error location in your editor.

* Small: Just one Python file, requires only stdlib. You can use just
  the pep8.py file for this purpose.

* Easy_installable, of course!


Installation
------------

Just an ``easy_install pep8`` ought to do the trick.


Example usage and output
------------------------

::

  $ pep8 optparse.py
  optparse.py:69:11: E401 multiple imports on one line
  optparse.py:77:1: E302 expected 2 blank lines, found 1
  optparse.py:88:5: E301 expected 1 blank line, found 0
  optparse.py:222:34: W602 deprecated form of raising exception
  optparse.py:347:31: E211 whitespace before '('
  optparse.py:357:17: E201 whitespace after '{'
  optparse.py:472:29: E221 multiple spaces before operator
  optparse.py:544:21: W601 .has_key() is deprecated, use 'in'

You can also make pep8.py show the source code for each error, and
even the relevant text from PEP 8::

  $ pep8 --show-source --show-pep8 testsuite/E111.py
  testsuite/E111.py:2:3: E111 indentation is not a multiple of four
    print x
    ^
      Use 4 spaces per indentation level.

      For really old code that you don't want to mess up, you can
      continue to use 8-space tabs.

Or you can display how often each error was found::

  $ pep8 --statistics -qq --filename=*.py Python-2.5/Lib
  232     E201 whitespace after '['
  599     E202 whitespace before ')'
  631     E203 whitespace before ','
  842     E211 whitespace before '('
  2531    E221 multiple spaces before operator
  4473    E301 expected 1 blank line, found 0
  4006    E302 expected 2 blank lines, found 1
  165     E303 too many blank lines (4)
  325     E401 multiple imports on one line
  3615    E501 line too long (82 characters)
  612     W601 .has_key() is deprecated, use 'in'
  1188    W602 deprecated form of raising exception

Quick help is available on the command line::

  $ pep8 -h
  Usage: pep8.py [options] input ...

  Options:
    --version            show program's version number and exit
    -h, --help           show this help message and exit
    -v, --verbose        print status messages, or debug with -vv
    -q, --quiet          report only file names, or nothing with -qq
    -r, --repeat         show all occurrences of the same error
    --exclude=patterns   exclude files or directories which match these comma
                         separated patterns (default: .svn,CVS,.bzr,.hg,.git)
    --filename=patterns  when parsing directories, only check filenames matching
                         these comma separated patterns (default: *.py)
    --select=errors      select errors and warnings (e.g. E,W6)
    --ignore=errors      skip errors and warnings (e.g. E4,W)
    --show-source        show source code for each error
    --show-pep8          show text of PEP 8 for each error
    --statistics         count errors and warnings
    --count              print total number of errors and warnings to standard
                         error and set exit code to 1 if total is not null
    --benchmark          measure processing speed
    --testsuite=dir      run regression tests from dir
    --doctest            run doctest on myself

Feedback
--------

Your feedback is more than welcome. Write email to
johann@rocholl.net or post bugs and feature requests on github:

http://github.com/jcrocholl/pep8/issues

Source download
---------------

The source code is currently available on github. Fork away!

http://github.com/jcrocholl/pep8/

=====
polib
=====

polib is a library to manipulate, create, modify gettext files (pot, po and mo
files). You can load existing files, iterate through it's entries, add, modify
entries, comments or metadata, etc... or create new po files from scratch.

polib supports out of the box any version of python ranging from 2.4 to latest
3.X version.

polib is pretty stable now and is used by many 
`opensource projects <http://polib.readthedocs.org/en/latest/projects.html>`_.

The project code and bugtracker is hosted on 
`Bitbucket <http://bitbucket.org/izi/polib/>`_. 

polib is generously documented, you can `browse the documentation online 
<http://polib.readthedocs.org/>`_, a good start is to read 
`the quickstart guide  <http://polib.readthedocs.org/en/latest/quickstart.html>`_.

Thanks for downloading polib !

    Mac OS X            	   2         ¼                                      ATTR3*í   ¼      $                     $  com.macromates.caret {
    column = 40;
    line = 141;
}
    Mac OS X            	   2         ¼                                      ATTR3*í   ¼      $                     $  com.macromates.caret {
    column = 40;
    line = 141;
}
=============================
 pyes - Python ElasticSearch
=============================

:Web: http://pypi.python.org/pypi/pyes/
:Download: http://pypi.python.org/pypi/pyes/
:Source: http://github.com/aparo/pyes/
:Keywords: search, elastisearch, distribute search

--

pyes is a connector to use elasticsearch from python.

This version requires elasticsearch 0.15 or above.

Features
========

- Thrift/HTTP protocols
- Bulk insert/delete
- Index management
- Every search query types
- Facet Support
- Geolocalization support
- Highlighting
- River support

Connecting
==========

These function are taken from pycassa.

Import the module:

    >>> import pyes

pyes is able to use standard http or thrift protocol. If your port starts with "92" http protocol is used, otherwise thrift.


For a single connection (which is _not_ thread-safe), pass a list of servers.

For thrift:

    >>> conn = pyes.ES() # Defaults to connecting to the server at '127.0.0.1:9500'
    >>> conn = pyes.ES(['127.0.0.1:9500'])

For http:

    >>> conn = pyes.ES(['127.0.0.1:9200'])

Connections are robust to server failures. Upon a disconnection, it will attempt to connect to each server in the list in turn. If no server is available, it will raise a NoServerAvailable exception.

Timeouts are also supported and should be used in production to prevent a thread from freezing while waiting for the server to return.

    >>> conn = pyes.ES(timeout=3.5) # 3.5 second timeout
    (Make some pyes calls and the connection to the server suddenly becomes unresponsive.)

    Traceback (most recent call last):
    ...
    pyes.connection.NoServerAvailable

Note that this only handles socket timeouts. 


Usage
=====

Creating a connection:

    >>> from pyes import *
    >>> conn = ES('127.0.0.1:9500')

Deleting an index:

    >>> try:
    >>>     conn.delete_index("test-index")
    >>> except:
    >>>     pass

(an exception is fored if the index is not present)

Create an index:

    >>> conn.create_index("test-index")

Creating a mapping:

    >>> mapping = { u'parsedtext': {'boost': 1.0,
    >>>                  'index': 'analyzed',
    >>>                  'store': 'yes',
    >>>                  'type': u'string',
    >>>                  "term_vector" : "with_positions_offsets"},
    >>>          u'name': {'boost': 1.0,
    >>>                     'index': 'analyzed',
    >>>                     'store': 'yes',
    >>>                     'type': u'string',
    >>>                     "term_vector" : "with_positions_offsets"},
    >>>          u'title': {'boost': 1.0,
    >>>                     'index': 'analyzed',
    >>>                     'store': 'yes',
    >>>                     'type': u'string',
    >>>                     "term_vector" : "with_positions_offsets"},
    >>>          u'pos': {'store': 'yes',
    >>>                     'type': u'integer'},
    >>>          u'uuid': {'boost': 1.0,
    >>>                    'index': 'not_analyzed',
    >>>                    'store': 'yes',
    >>>                    'type': u'string'}}
    >>> conn.put_mapping("test-type", {'properties':mapping}, ["test-index"])

Index some documents:

    >>> conn.index({"name":"Joe Tester", "parsedtext":"Joe Testere nice guy", "uuid":"11111", "position":1}, "test-index", "test-type", 1)
    >>> conn.index({"name":"Bill Baloney", "parsedtext":"Joe Testere nice guy", "uuid":"22222", "position":2}, "test-index", "test-type", 2)

Refresh an index:

    >>> conn.refresh(["test-index"])

Execute a query

    >>> q = TermQuery("name", "joe")
    >>> result = self.conn.search(query = q)

For more examples looks at the tests.


Changelog
=========

Note for next release - the order of geolocation parameters expected by
elasticsearch changed between ES 0.14.4 and ES 0.15, from [lat, lon] to [lon,
lat].  Clients will need to update accordingly, or use an object with named
parameters.

v. 0.16.0:

           Updated documentation.

           Added TextQuery and some clean up of code.

           Added percolator (matterkkila).

           Added date_histogram facet (zebuline).

           Added script fields to Search object, also add "fields" to TermFacet  (aguereca).

           Added analyze_wildcard param to StringQuery (available for ES 0.16.0) (zebuline).

           Add ScriptFields object used as parameter script_fields of Search object (aguereca).

           Add IdsQuery, IdsFilter and deleteByQuery (aguereca).

           Bulk delete (acdha).

v. 0.15.0:
	
           Only require simplejson for python < 2.6 (matterkkila)

           Added basic version support to ES.index and Search (merrellb)

           Added scan method to ES.  This is only supported on ES Master (pre 0.16) (merrellb)

           Added GeoPointField to mapping types (merrellb)

           Disable thrift in setup.py. 

           Added missing _routing property in ObjectField 

           Added ExistsFilter 

           Improved HasChildren 

           Add min_similarity and prefix_length to flt. 

           Added _scope to HasChildQuery. (andreiz)

           Added parent/child document in test indexing. Added _scope to HasChildFilter. 

           Added MissingFilter as a subclass of TermFilter 

           Fixed error in checking TermsQuery (merrellb)

           If an analyzer is set on a field, the returned mapping will have an analyzer 

           Add a specific error subtype for mapper parsing exceptions (rboulton)

           Add support for Float numeric field mappings (rboulton)

           ES.get() now accepts "fields" as well as other keyword arguments (eg "routing") (rboulton)

           Allow dump_curl to be passed a filehandle (or still a filename), don't for filenames to be in /tmp, and add a basic test of it. 

           Add alias handling (rboulton)

           Add ElasticSearchIllegalArgumentException - used for example when writing to an alias which refers to more than one index. (rboulton)

           Handle errors produced by deleting a missing document, and add a test for it. (rboulton)

           Split Query object into a Search object, for the search specific parts, and a Query base class.  Allow ES.search() to take a query or a search object.  Make some of the methods of Query base classes chainable, where that is an obviously reasonable thing to do. (rboulton)

v. 0.14.0: Added delete of mapping type.

           Embedded urllib3 to be buildout safe and for users sake.

           Some code cleanup.

           Added reindex by query (usable only with my elasticsearch git branch).

           Added contrib with mailman indexing.

           Autodetect if django is available and added related functions.

           Code cleanup and PEP8.

           Reactivated the morelikethis query.

           Fixed river support plus unittest. (Tavis Aitken)

           Added autorefresh to sync search and write.

           Added QueryFilter.

           Forced name attribute in multifield declaration.

           Added is_empty to ConstantScoreQuery and fixed some bad behaviour.

           Added CustomScoreQuery.

           Added parent/children indexing.

           Added dump commands in a script file "curl" way.

           Added a lot of fix from Richard Boulton.

v. 0.13.1: Added jython support (HTTP only for now).

v. 0.13.0: API Changes: errors -> exceptions.
           
           Splitting of query/filters.
           
           Added open/close of index.

           Added the number of retries if server is down.

           Refactory Range query. (Andrei)

           Improved HTTP connection timeout/retries. (Sandymahalo)

           Cleanup some imports. (Sandymahalo)

v. 0.12.1: Added collecting server info.

           Version 0.12 or above requirement.

           Fixed attachment plugin. 

           Updated bulk insert to use new api. 

           Added facet support (except geotypes).

           Added river support. 

           Cleanup some method.

           Added default_indexes variable.

           Added datetime deserialization.

           Improved performance and memory usage in bulk insert replacing list with StringIO.

           Initial propagation of elasticsearch exception to python.

v. 0.12.0: added http transport, added autodetect of transport, updated thrift interface. 

v. 0.10.3: added bulk insert, explain and facet. 

v. 0.10.2: added new geo query type. 

v. 0.10.1: added new connection pool system based on pycassa one.

v. 0.10.0: initial working version.


TODO
----

- more docs
- more tests
- cleanup
- add coverage
- add jython native client protocol

License
=======

This software is licensed under the ``New BSD License``. See the ``LICENSE``
file in the top distribution directory for the full license text.

.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround

=============================
 pyes - Python ElasticSearch
=============================

:Web: http://pypi.python.org/pypi/pyes/
:Download: http://pypi.python.org/pypi/pyes/
:Source: http://github.com/aparo/pyes/
:Keywords: search, elastisearch, distribute search

--

pyes is a connector to use elasticsearch from python.

This version requires elasticsearch 0.15 or above.

Features
========

- Thrift/HTTP protocols
- Bulk insert/delete
- Index management
- Every search query types
- Facet Support
- Geolocalization support
- Highlighting
- River support

Connecting
==========

These function are taken from pycassa.

Import the module:

    >>> import pyes

pyes is able to use standard http or thrift protocol. If your port starts with "92" http protocol is used, otherwise thrift.


For a single connection (which is _not_ thread-safe), pass a list of servers.

For thrift:

    >>> conn = pyes.ES() # Defaults to connecting to the server at '127.0.0.1:9500'
    >>> conn = pyes.ES(['127.0.0.1:9500'])

For http:

    >>> conn = pyes.ES(['127.0.0.1:9200'])

Connections are robust to server failures. Upon a disconnection, it will attempt to connect to each server in the list in turn. If no server is available, it will raise a NoServerAvailable exception.

Timeouts are also supported and should be used in production to prevent a thread from freezing while waiting for the server to return.

    >>> conn = pyes.ES(timeout=3.5) # 3.5 second timeout
    (Make some pyes calls and the connection to the server suddenly becomes unresponsive.)

    Traceback (most recent call last):
    ...
    pyes.connection.NoServerAvailable

Note that this only handles socket timeouts. 


Usage
=====

Creating a connection:

    >>> from pyes import *
    >>> conn = ES('127.0.0.1:9500')

Deleting an index:

    >>> try:
    >>>     conn.delete_index("test-index")
    >>> except:
    >>>     pass

(an exception is fored if the index is not present)

Create an index:

    >>> conn.create_index("test-index")

Creating a mapping:

    >>> mapping = { u'parsedtext': {'boost': 1.0,
    >>>                  'index': 'analyzed',
    >>>                  'store': 'yes',
    >>>                  'type': u'string',
    >>>                  "term_vector" : "with_positions_offsets"},
    >>>          u'name': {'boost': 1.0,
    >>>                     'index': 'analyzed',
    >>>                     'store': 'yes',
    >>>                     'type': u'string',
    >>>                     "term_vector" : "with_positions_offsets"},
    >>>          u'title': {'boost': 1.0,
    >>>                     'index': 'analyzed',
    >>>                     'store': 'yes',
    >>>                     'type': u'string',
    >>>                     "term_vector" : "with_positions_offsets"},
    >>>          u'pos': {'store': 'yes',
    >>>                     'type': u'integer'},
    >>>          u'uuid': {'boost': 1.0,
    >>>                    'index': 'not_analyzed',
    >>>                    'store': 'yes',
    >>>                    'type': u'string'}}
    >>> conn.put_mapping("test-type", {'properties':mapping}, ["test-index"])

Index some documents:

    >>> conn.index({"name":"Joe Tester", "parsedtext":"Joe Testere nice guy", "uuid":"11111", "position":1}, "test-index", "test-type", 1)
    >>> conn.index({"name":"Bill Baloney", "parsedtext":"Joe Testere nice guy", "uuid":"22222", "position":2}, "test-index", "test-type", 2)

Refresh an index:

    >>> conn.refresh(["test-index"])

Execute a query

    >>> q = TermQuery("name", "joe")
    >>> result = self.conn.search(query = q)

For more examples looks at the tests.


Changelog
=========

Note for next release - the order of geolocation parameters expected by
elasticsearch changed between ES 0.14.4 and ES 0.15, from [lat, lon] to [lon,
lat].  Clients will need to update accordingly, or use an object with named
parameters.

v. 0.16.0:

           Updated documentation.

           Added TextQuery and some clean up of code.

           Added percolator (matterkkila).

           Added date_histogram facet (zebuline).

           Added script fields to Search object, also add "fields" to TermFacet  (aguereca).

           Added analyze_wildcard param to StringQuery (available for ES 0.16.0) (zebuline).

           Add ScriptFields object used as parameter script_fields of Search object (aguereca).

           Add IdsQuery, IdsFilter and deleteByQuery (aguereca).

           Bulk delete (acdha).

v. 0.15.0:
	
           Only require simplejson for python < 2.6 (matterkkila)

           Added basic version support to ES.index and Search (merrellb)

           Added scan method to ES.  This is only supported on ES Master (pre 0.16) (merrellb)

           Added GeoPointField to mapping types (merrellb)

           Disable thrift in setup.py. 

           Added missing _routing property in ObjectField 

           Added ExistsFilter 

           Improved HasChildren 

           Add min_similarity and prefix_length to flt. 

           Added _scope to HasChildQuery. (andreiz)

           Added parent/child document in test indexing. Added _scope to HasChildFilter. 

           Added MissingFilter as a subclass of TermFilter 

           Fixed error in checking TermsQuery (merrellb)

           If an analyzer is set on a field, the returned mapping will have an analyzer 

           Add a specific error subtype for mapper parsing exceptions (rboulton)

           Add support for Float numeric field mappings (rboulton)

           ES.get() now accepts "fields" as well as other keyword arguments (eg "routing") (rboulton)

           Allow dump_curl to be passed a filehandle (or still a filename), don't for filenames to be in /tmp, and add a basic test of it. 

           Add alias handling (rboulton)

           Add ElasticSearchIllegalArgumentException - used for example when writing to an alias which refers to more than one index. (rboulton)

           Handle errors produced by deleting a missing document, and add a test for it. (rboulton)

           Split Query object into a Search object, for the search specific parts, and a Query base class.  Allow ES.search() to take a query or a search object.  Make some of the methods of Query base classes chainable, where that is an obviously reasonable thing to do. (rboulton)

v. 0.14.0: Added delete of mapping type.

           Embedded urllib3 to be buildout safe and for users sake.

           Some code cleanup.

           Added reindex by query (usable only with my elasticsearch git branch).

           Added contrib with mailman indexing.

           Autodetect if django is available and added related functions.

           Code cleanup and PEP8.

           Reactivated the morelikethis query.

           Fixed river support plus unittest. (Tavis Aitken)

           Added autorefresh to sync search and write.

           Added QueryFilter.

           Forced name attribute in multifield declaration.

           Added is_empty to ConstantScoreQuery and fixed some bad behaviour.

           Added CustomScoreQuery.

           Added parent/children indexing.

           Added dump commands in a script file "curl" way.

           Added a lot of fix from Richard Boulton.

v. 0.13.1: Added jython support (HTTP only for now).

v. 0.13.0: API Changes: errors -> exceptions.
           
           Splitting of query/filters.
           
           Added open/close of index.

           Added the number of retries if server is down.

           Refactory Range query. (Andrei)

           Improved HTTP connection timeout/retries. (Sandymahalo)

           Cleanup some imports. (Sandymahalo)

v. 0.12.1: Added collecting server info.

           Version 0.12 or above requirement.

           Fixed attachment plugin. 

           Updated bulk insert to use new api. 

           Added facet support (except geotypes).

           Added river support. 

           Cleanup some method.

           Added default_indexes variable.

           Added datetime deserialization.

           Improved performance and memory usage in bulk insert replacing list with StringIO.

           Initial propagation of elasticsearch exception to python.

v. 0.12.0: added http transport, added autodetect of transport, updated thrift interface. 

v. 0.10.3: added bulk insert, explain and facet. 

v. 0.10.2: added new geo query type. 

v. 0.10.1: added new connection pool system based on pycassa one.

v. 0.10.0: initial working version.


TODO
----

- more docs
- more tests
- cleanup
- add coverage
- add jython native client protocol

License
=======

This software is licensed under the ``New BSD License``. See the ``LICENSE``
file in the top distribution directory for the full license text.

.. # vim: syntax=rst expandtab tabstop=4 shiftwidth=4 shiftround

README for PyLint
=================

Dependencies
------------
Pylint requires the logilab-astng (version >= 0.17.4), logilab-common
(version >= 0.38) and the optik (only for python < 2.3) packages. 
Pylint should be compatible with any python >= 2.2.

* http://www.logilab.org/projects/astng
* http://www.logilab.org/projects/common
* http://optik.sourceforge.net/

Install
-------
From the source distribution, extract the tarball and run ::

    python setup.py install

You'll have to install dependencies in a similar way. For debian and
rpm packages, use your usual tools according to your Linux distribution. 

More information about installation and available distribution format
may be found in the user manual in the *doc* subdirectory.

Documentation
-------------
Look in the doc/ subdirectory.

Comments, support, bug reports
------------------------------

Project page on : 
http://www.logilab.org/project/pylint

Use the python-projects@logilab.org mailing list. Since we do not have
publicly available bug tracker yet, bug reports should be emailed
there too. 

You can subscribe to this mailing list at
http://lists.logilab.org/mailman/listinfo/python-projects

Archives are available at 
http://lists.logilab.org/pipermail/python-projects/

Contributors
------------
* Sylvain Thénault: main author / maintainer
* Alexandre Fayolle: TkInter gui, documentation, debian support
* Mads Kiilerich: various patches
* Brian van den Broek: windows installation documentation
* Amaury Forgeot d'Arc: patch to check names imported from a module
  exists in the module
* Benjamin Niemann: patch to allow block level enabling/disabling of messages
* Nathaniel Manista: suspicious lambda checking
* Wolfgang Grafen, Axel Muller, Fabio Zadrozny, Pierre Rouleau,  
  Maarten ter Huurne, Mirko Friedenhagen (among others): 
  bug reports, feedback, feature requests...
* All the Logilab's team: daily use, bug reports, feature requests
* Other people have contributed by their feedback, if I've forgotten
  you, send me a note !

<HTML>
<title>pyparsing Examples</title>
<body>
<h1>pyparsing Examples</h1>
<p>
This directory contains a number of Python scripts that can get you started in learning to use pyparsing.

<ul>
<li><a href="greeting.py">greeting.py</a><br>
Parse "Hello, World!".
</li>
<p>

<li><a href="greetingInKorean.py">greetingInKorean.py</a> <i>~ submission by June Kim</i><br>
Unicode example to parse "Hello, World!" in Korean.
</li>
<p>

<li><a href="greetingInGreek.py">greetingInGreek.py</a> <i>~ submission by ???</i><br>
Unicode example to parse "Hello, World!" in Greek.
</li>
<p>

<li><a href="holaMundo.py">holaMundo.py</a> <i>~ submission by Marco Alfonso</i><br>
"Hello, World!" example translated to Spanish, from Marco Alfonso's blog.
</li>
<p>

<li><a href="chemicalFormulas.py">chemicalFormulas.py</a><br>
Simple example to demonstrate the use of ParseResults returned from parseString().  
Parses a chemical formula (such as "H2O" or "C6H5OH"), and walks the returned list of tokens to calculate the molecular weight.
</li>
<p>

<li><a href="wordsToNum.py">wordsToNum.py</a><br>
A sample program that reads a number in words (such as "fifteen hundred and sixty four"), and returns the actual number (1564).
Also demonstrates some processing of ParseExceptions, including marking where the parse failure was found.
</li>
<p>

<li><a href="pythonGrammarparser.py">pythonGrammarparser.py</a> <i>~ suggested by JH Stovall</i><br>
A sample program that parses the EBNF used in the Python source code to define the Python grammar.  From this parser,
one can generate Python grammar documentation tools, such as railroad track diagrams.  Also demonstrates use of
Dict class.
</li>
<p>

<li><a href="commasep.py">commasep.py</a><br>
Demonstration of the use of the commaSeparatedList helper.  Shows examples of
proper handling of commas within quotes, trimming of whitespace around delimited entries, and handling of consecutive commas (null arguments).  Includes comparison with simple string.split(',').
</li>
<p>

<li><a href="dictExample.py">dictExample.py</a><br>
A demonstration of using the Dict class, to parse a table of ASCII tabulated data.
</li>
<p>

<li><a href="dictExample2.py">dictExample2.py</a> <i>~ submission by Mike Kelly</i><br>
An extended version of dictExample.py, in which Mike Kelly also parses the column headers, and generates a transposed version of the original table!
</li>
<p>

<li><a href="scanExamples.py">scanExamples.py</a><br>
Some examples of using scanString and transformString, as alternative parsing methods to parseString, to do macro substitution, and selection and/or removal of matching strings within a source file.
</li>
<p>

<li><a href="urlExtractor.py">urlExtractor.py</a><br>
Another example using scanString, this time to extract all HREF references found on Yahoo!'s home page, and return them as a dictionary.
</li>
<p>

<li><a href="makeHTMLTagExample.py">makeHTMLTagExample.py</a><br>
A sample program showing sample definitions and applications of HTML tag expressions
created using makeHTMLTags helper function.  Very useful for scraping data from HTML pages.
</li>
<p>

<li><a href="urlExtractorNew.py">urlExtractorNew.py</a><br>
Another updated version of urlExtractor.py, using the new makeHTMLTags() method.
</li>
<p>

<li><a href="fourFn.py">fourFn.py</a><br>
A simple algebraic expression parser, that performs +,-,*,/, and ^ arithmetic operations.  (With suggestions and bug-fixes graciously offered by Andrea Griffini.)
</li>
<p>

<li><a href="SimpleCalc.py">SimpleCalc.py</a> <i>~ submission by Steven Siew</i><br>
An interactive version of fourFn.py, with support for variables.
</li>
<p>

<li><a href="LAParser.py">LAParser.py</a> <i>~ submission by Mike Ellis</i><br>
An interactive Linear Algebra Parser, an extension of SimpleCalc.py.  Supports linear algebra (LA) notation for vectors, matrices, and scalars,
including matrix operations such as inversion and determinants.  Converts LA expressions to C code - uses a separate C library for runtime
evaluation of results.
</li>
<p>

<li><a href="configParse.py">configParse.py</a><br>
A simple alternative to Python's ConfigParse module, demonstrating the use of the Dict class to return nested dictionary access to configuration values.
</li>
<p>

<li><a href="getNTPservers.py">getNTPservers.py</a><br>
Yet another scanString example, to read/extract the list of NTP servers from NIST's web site.
</li>
<p>

<li><a href="getNTPserversNew.py">getNTPserversNew.py</a><br>
An updated version of getNTPservers.py, using the new makeHTMLTags() method.
</li>
<p>

<li><a href="httpServerLogParser.py">httpServerLogParser.py</a><br>
Parser for Apache server log files.
</li>
<p>

<li><a href="idlParse.py">idlParse.py</a><br>
Parser for CORBA IDL files.
</li>
<p>

<li><a href="mozillaCalendarParser.py">mozillaCalendarParser.py</a> 
<i>~ submission by Petri Savolainen</i><br>
Parser for Mozilla calendar (*.ics) files.
</li>
<p>

<li><a href="pgn.py">pgn.py</a> <i>~ submission by Alberto Santini</i><br>
Parser for PGN (Portable Game Notation) files, the standard form for documenting the moves in chess games.
</li>
<p>

<li><a href="simpleSQL.py">simpleSQL.py</a><br>
A simple parser that will extract table and column names from SQL SELECT statements..
</li>
<p>

<li><a href="dfmparse.py">dfmparse.py</a> <i>~ submission by Dan Griffith</i><br>
Parser for Delphi forms.
</li>
<p>

<li><a href="ebnf.py">ebnf.py / ebnftest.py</a> <i>~ submission by Seo Sanghyeon</i><br>
An EBNF-compiler that reads EBNF and generates a pyparsing grammar!  Including a test that compiles... EBNF itself!
</li>
<p>

<li><a href="searchparser.py">searchparser.py</a> <i>~ submission by Steven Mooij and Rudolph Froger</i><br>
An expression parser that parses search strings, with special keyword and expression operations using (), not, and, or, and quoted strings.
</li>
<p>

<li><a href="sparser.py">sparser.py</a> <i>~ submission by Tim Cera</i><br>
A configurable parser module that can be configured with a list of tuples, giving a high-level definition for parsing common sets
of water table data files.  Tim had to contend with several different styles of data file formats, each with slight variations of its own.
Tim created a configurable parser (or "SPECIFIED parser" - hence the name "sparser"), that simply works from a config variable listing
the field names and data types, and implicitly, their order in the source data file.
<p>
See <a href="mayport_florida_8720220_data_def.txt">mayport_florida_8720220_data_def.txt</a> for an
example configuration file.
</li>
<p>

<li><a href="romanNumerals.py">romanNumerals.py</a><br>
A Roman numeral generator and parser example, showing the power of parse actions 
to compile Roman numerals into their integer values.
</li>
<p>

<li><a href="removeLineBreaks.py">removeLineBreaks.py</a><br>
A string transformer that converts text files with hard line-breaks into one with line breaks
only between paragraphs.  Useful when converting downloads from 
<a href="http://www.gutenberg.org">Project Gutenberg</a> to import to word processing apps 
that can reformat paragraphs once hard line-breaks are removed, or for loading into your Palm Pilot for portable perusal.
<p>
See <a href="Successful Methods of Public Speaking.txt">Successful Methods of Public Speaking.txt</a> and 
<a href="Successful Methods of Public Speaking(2).txt">Successful Methods of Public Speaking(2).txt</a> for a sample 
before and after (text file courtesy of Project Gutenberg).
</li>
<p>

<li><a href="listAllMatches.py">listAllMatches.py</a><br>
An example program showing the utility of the listAllMatches option when specifying results naming.
</li>
<p>

<li><a href="linenoExample.py">linenoExample.py</a><br>
An example program showing how to use the string location to extract line and column numbers, or the 
source line of text.
</li>
<p>

<li><a href="parseListString.py">parseListString.py</a><br>
An example program showing a progression of steps, how to parse a string representation of a Python 
list back into a true list.
</li>
<p>

<li><a href="parsePythonValue.py">parsePythonValue.py</a><br>
An extension of parseListString.py to parse tuples and dicts, including nested values,
returning a Python value of the original type.
</li>
<p>

<li><a href="indentedGrammarExample.py">indentedGrammarExample.py</a><br>
An example program showing how to parse a grammar using indentation for grouping, 
such as is done in Python.
</li>
<p>

<li><a href="simpleArith.py">simpleArith.py</a><br>
An example program showing how to use the new operatorPrecedence helper method to define a 6-function
(+, -, *, /, ^, and !) arithmetic expression parser, with unary plus and minus signs.
</li>
<p>

<li><a href="simpleBool.py">simpleBool.py</a><br>
An example program showing how to use the new operatorPrecedence helper method to define a 
boolean expression parser, with parse actions associated with each operator to "compile" the expression
into a data structure that will evaluate the expression's boolean value.
</li>
<p>

<li><a href="simpleWiki.py">simpleWiki.py</a><br>
An example program showing how to use transformString to implement a simple Wiki markup parser.
</li>
<p>

<li><a href="sql2dot.py">sql2dot.py</a><i>~ submission by EnErGy [CSDX]</i><br>
A nice graphing program that generates schema diagrams from SQL table definition statements.
</li>
<p>

<li><a href="htmlStripper.py">htmlStripper.py</a><br>
An example implementation of a common application, removing HTML markup tags from an HTML page,
leaving just the text content.
</li>
<p>

<li><a href="macroExpansion.py">macroExpansion.py</a><br>
An example implementation of a simple preprocessor, that will read embedded macro definitions
and replace macro references with the defined substitution string.
</li>
<p>

<li><a href="sexpParser.py">sexpParser.py</a><br>
A parser that uses a recursive grammar to parse S-expressions.
</li>
<p>

<li><a href="nested.py">nested.py</a><br>
An example using nestedExpr, a helper method to simplify definitions of expressions of nested lists.
</li>
<p>

<li><a href="withAttribute.py">withAttribute.py</a><br>
An example using withAttribute, a helper method to define parse actions to validate matched HTML tags
using additional attributes.  Especially helpful for matching common tags such as &lt;DIV&gt; and &lt;TD&gt;.
</li>
<p>

<li><a href="stackish.py">stackish.py</a><br>
<b>New in version 1.4.12</b><br>
A parser for the data representation format, Stackish.
</li>
<p>

</ul>

</body></html>
<HTML>
<title>pyparsing Examples</title>
<body>
<h1>pyparsing Examples</h1>
<p>
This directory contains a number of Python scripts that can get you started in learning to use pyparsing.

<ul>
<li><a href="greeting.py">greeting.py</a><br>
Parse "Hello, World!".
</li>
<p>

<li><a href="greetingInKorean.py">greetingInKorean.py</a> <i>~ submission by June Kim</i><br>
Unicode example to parse "Hello, World!" in Korean.
</li>
<p>

<li><a href="greetingInGreek.py">greetingInGreek.py</a> <i>~ submission by ???</i><br>
Unicode example to parse "Hello, World!" in Greek.
</li>
<p>

<li><a href="holaMundo.py">holaMundo.py</a> <i>~ submission by Marco Alfonso</i><br>
"Hello, World!" example translated to Spanish, from Marco Alfonso's blog.
</li>
<p>

<li><a href="chemicalFormulas.py">chemicalFormulas.py</a><br>
Simple example to demonstrate the use of ParseResults returned from parseString().  
Parses a chemical formula (such as "H2O" or "C6H5OH"), and walks the returned list of tokens to calculate the molecular weight.
</li>
<p>

<li><a href="wordsToNum.py">wordsToNum.py</a><br>
A sample program that reads a number in words (such as "fifteen hundred and sixty four"), and returns the actual number (1564).
Also demonstrates some processing of ParseExceptions, including marking where the parse failure was found.
</li>
<p>

<li><a href="pythonGrammarparser.py">pythonGrammarparser.py</a> <i>~ suggested by JH Stovall</i><br>
A sample program that parses the EBNF used in the Python source code to define the Python grammar.  From this parser,
one can generate Python grammar documentation tools, such as railroad track diagrams.  Also demonstrates use of
Dict class.
</li>
<p>

<li><a href="commasep.py">commasep.py</a><br>
Demonstration of the use of the commaSeparatedList helper.  Shows examples of
proper handling of commas within quotes, trimming of whitespace around delimited entries, and handling of consecutive commas (null arguments).  Includes comparison with simple string.split(',').
</li>
<p>

<li><a href="dictExample.py">dictExample.py</a><br>
A demonstration of using the Dict class, to parse a table of ASCII tabulated data.
</li>
<p>

<li><a href="dictExample2.py">dictExample2.py</a> <i>~ submission by Mike Kelly</i><br>
An extended version of dictExample.py, in which Mike Kelly also parses the column headers, and generates a transposed version of the original table!
</li>
<p>

<li><a href="scanExamples.py">scanExamples.py</a><br>
Some examples of using scanString and transformString, as alternative parsing methods to parseString, to do macro substitution, and selection and/or removal of matching strings within a source file.
</li>
<p>

<li><a href="urlExtractor.py">urlExtractor.py</a><br>
Another example using scanString, this time to extract all HREF references found on Yahoo!'s home page, and return them as a dictionary.
</li>
<p>

<li><a href="makeHTMLTagExample.py">makeHTMLTagExample.py</a><br>
A sample program showing sample definitions and applications of HTML tag expressions
created using makeHTMLTags helper function.  Very useful for scraping data from HTML pages.
</li>
<p>

<li><a href="urlExtractorNew.py">urlExtractorNew.py</a><br>
Another updated version of urlExtractor.py, using the new makeHTMLTags() method.
</li>
<p>

<li><a href="fourFn.py">fourFn.py</a><br>
A simple algebraic expression parser, that performs +,-,*,/, and ^ arithmetic operations.  (With suggestions and bug-fixes graciously offered by Andrea Griffini.)
</li>
<p>

<li><a href="SimpleCalc.py">SimpleCalc.py</a> <i>~ submission by Steven Siew</i><br>
An interactive version of fourFn.py, with support for variables.
</li>
<p>

<li><a href="LAParser.py">LAParser.py</a> <i>~ submission by Mike Ellis</i><br>
An interactive Linear Algebra Parser, an extension of SimpleCalc.py.  Supports linear algebra (LA) notation for vectors, matrices, and scalars,
including matrix operations such as inversion and determinants.  Converts LA expressions to C code - uses a separate C library for runtime
evaluation of results.
</li>
<p>

<li><a href="configParse.py">configParse.py</a><br>
A simple alternative to Python's ConfigParse module, demonstrating the use of the Dict class to return nested dictionary access to configuration values.
</li>
<p>

<li><a href="getNTPservers.py">getNTPservers.py</a><br>
Yet another scanString example, to read/extract the list of NTP servers from NIST's web site.
</li>
<p>

<li><a href="getNTPserversNew.py">getNTPserversNew.py</a><br>
An updated version of getNTPservers.py, using the new makeHTMLTags() method.
</li>
<p>

<li><a href="httpServerLogParser.py">httpServerLogParser.py</a><br>
Parser for Apache server log files.
</li>
<p>

<li><a href="idlParse.py">idlParse.py</a><br>
Parser for CORBA IDL files.
</li>
<p>

<li><a href="mozillaCalendarParser.py">mozillaCalendarParser.py</a> 
<i>~ submission by Petri Savolainen</i><br>
Parser for Mozilla calendar (*.ics) files.
</li>
<p>

<li><a href="pgn.py">pgn.py</a> <i>~ submission by Alberto Santini</i><br>
Parser for PGN (Portable Game Notation) files, the standard form for documenting the moves in chess games.
</li>
<p>

<li><a href="simpleSQL.py">simpleSQL.py</a><br>
A simple parser that will extract table and column names from SQL SELECT statements..
</li>
<p>

<li><a href="dfmparse.py">dfmparse.py</a> <i>~ submission by Dan Griffith</i><br>
Parser for Delphi forms.
</li>
<p>

<li><a href="ebnf.py">ebnf.py / ebnftest.py</a> <i>~ submission by Seo Sanghyeon</i><br>
An EBNF-compiler that reads EBNF and generates a pyparsing grammar!  Including a test that compiles... EBNF itself!
</li>
<p>

<li><a href="searchparser.py">searchparser.py</a> <i>~ submission by Steven Mooij and Rudolph Froger</i><br>
An expression parser that parses search strings, with special keyword and expression operations using (), not, and, or, and quoted strings.
</li>
<p>

<li><a href="sparser.py">sparser.py</a> <i>~ submission by Tim Cera</i><br>
A configurable parser module that can be configured with a list of tuples, giving a high-level definition for parsing common sets
of water table data files.  Tim had to contend with several different styles of data file formats, each with slight variations of its own.
Tim created a configurable parser (or "SPECIFIED parser" - hence the name "sparser"), that simply works from a config variable listing
the field names and data types, and implicitly, their order in the source data file.
<p>
See <a href="mayport_florida_8720220_data_def.txt">mayport_florida_8720220_data_def.txt</a> for an
example configuration file.
</li>
<p>

<li><a href="romanNumerals.py">romanNumerals.py</a><br>
A Roman numeral generator and parser example, showing the power of parse actions 
to compile Roman numerals into their integer values.
</li>
<p>

<li><a href="removeLineBreaks.py">removeLineBreaks.py</a><br>
A string transformer that converts text files with hard line-breaks into one with line breaks
only between paragraphs.  Useful when converting downloads from 
<a href="http://www.gutenberg.org">Project Gutenberg</a> to import to word processing apps 
that can reformat paragraphs once hard line-breaks are removed, or for loading into your Palm Pilot for portable perusal.
<p>
See <a href="Successful Methods of Public Speaking.txt">Successful Methods of Public Speaking.txt</a> and 
<a href="Successful Methods of Public Speaking(2).txt">Successful Methods of Public Speaking(2).txt</a> for a sample 
before and after (text file courtesy of Project Gutenberg).
</li>
<p>

<li><a href="listAllMatches.py">listAllMatches.py</a><br>
An example program showing the utility of the listAllMatches option when specifying results naming.
</li>
<p>

<li><a href="linenoExample.py">linenoExample.py</a><br>
An example program showing how to use the string location to extract line and column numbers, or the 
source line of text.
</li>
<p>

<li><a href="parseListString.py">parseListString.py</a><br>
An example program showing a progression of steps, how to parse a string representation of a Python 
list back into a true list.
</li>
<p>

<li><a href="parsePythonValue.py">parsePythonValue.py</a><br>
An extension of parseListString.py to parse tuples and dicts, including nested values,
returning a Python value of the original type.
</li>
<p>

<li><a href="indentedGrammarExample.py">indentedGrammarExample.py</a><br>
An example program showing how to parse a grammar using indentation for grouping, 
such as is done in Python.
</li>
<p>

<li><a href="simpleArith.py">simpleArith.py</a><br>
An example program showing how to use the new operatorPrecedence helper method to define a 6-function
(+, -, *, /, ^, and !) arithmetic expression parser, with unary plus and minus signs.
</li>
<p>

<li><a href="simpleBool.py">simpleBool.py</a><br>
An example program showing how to use the new operatorPrecedence helper method to define a 
boolean expression parser, with parse actions associated with each operator to "compile" the expression
into a data structure that will evaluate the expression's boolean value.
</li>
<p>

<li><a href="simpleWiki.py">simpleWiki.py</a><br>
An example program showing how to use transformString to implement a simple Wiki markup parser.
</li>
<p>

<li><a href="sql2dot.py">sql2dot.py</a><i>~ submission by EnErGy [CSDX]</i><br>
A nice graphing program that generates schema diagrams from SQL table definition statements.
</li>
<p>

<li><a href="htmlStripper.py">htmlStripper.py</a><br>
An example implementation of a common application, removing HTML markup tags from an HTML page,
leaving just the text content.
</li>
<p>

<li><a href="macroExpansion.py">macroExpansion.py</a><br>
An example implementation of a simple preprocessor, that will read embedded macro definitions
and replace macro references with the defined substitution string.
</li>
<p>

<li><a href="sexpParser.py">sexpParser.py</a><br>
A parser that uses a recursive grammar to parse S-expressions.
</li>
<p>

<li><a href="nested.py">nested.py</a><br>
An example using nestedExpr, a helper method to simplify definitions of expressions of nested lists.
</li>
<p>

<li><a href="withAttribute.py">withAttribute.py</a><br>
An example using withAttribute, a helper method to define parse actions to validate matched HTML tags
using additional attributes.  Especially helpful for matching common tags such as &lt;DIV&gt; and &lt;TD&gt;.
</li>
<p>

<li><a href="stackish.py">stackish.py</a><br>
<b>New in version 1.4.12</b><br>
A parser for the data representation format, Stackish.
</li>
<p>

</ul>

</body></html>
====================================
PyParsing -- A Python Parsing Module
====================================

Introduction
============

The pyparsing module is an alternative approach to creating and executing 
simple grammars, vs. the traditional lex/yacc approach, or the use of 
regular expressions.  The pyparsing module provides a library of classes 
that client code uses to construct the grammar directly in Python code.

Here is a program to parse "Hello, World!" (or any greeting of the form 
"<salutation>, <addressee>!"):

    from pyparsing import Word, alphas
    greet = Word( alphas ) + "," + Word( alphas ) + "!"
    hello = "Hello, World!"
    print hello, "->", greet.parseString( hello )

The program outputs the following:

    Hello, World! -> ['Hello', ',', 'World', '!']

The Python representation of the grammar is quite readable, owing to the 
self-explanatory class names, and the use of '+', '|' and '^' operator 
definitions.

The parsed results returned from parseString() can be accessed as a 
nested list, a dictionary, or an object with named attributes.

The pyparsing module handles some of the problems that are typically 
vexing when writing text parsers:
- extra or missing whitespace (the above program will also handle 
  "Hello,World!", "Hello  ,  World  !", etc.)
- quoted strings
- embedded comments

The .zip file includes examples of a simple SQL parser, simple CORBA IDL 
parser, a config file parser, a chemical formula parser, and a four-
function algebraic notation parser.  It also includes a simple how-to 
document, and a UML class diagram of the library's classes.



Installation
============

Do the usual:

    python setup.py install
    
(pyparsing requires Python 2.3.2 or later.)


Documentation
=============

See:

    HowToUsePyparsing.html


License
=======

    MIT License. See header of pyparsing.py

History
=======

    See CHANGES file.

pyquery: a jquery-like library for python
=========================================

pyquery allows you to make jquery queries on xml documents.
The API is as much as possible the similar to jquery. pyquery uses lxml for fast
xml and html manipulation.

This is not (or at least not yet) a library to produce or interact with
javascript code. I just liked the jquery API and I missed it in python so I
told myself "Hey let's make jquery in python". This is the result.

It can be used for many purposes, one idea that I might try in the future is to
use it for templating with pure http templates that you modify using pyquery.
I can also be used for web scrapping or for theming applications with
`Deliverance`_.

The `project`_ is being actively developped on a mercurial repository on
Bitbucket. I have the policy of giving push access to anyone who wants it
and then to review what he does. So if you want to contribute just email me.

The full documentation is available on `pyquery.org`_.

.. _deliverance: http://www.gawel.org/weblog/en/2008/12/skinning-with-pyquery-and-deliverance
.. _project: http://www.bitbucket.org/olauzanne/pyquery/
.. _pyquery.org: http://pyquery.org/

Quickstart
==========

You can use the PyQuery class to load an xml document from a string, a lxml
document, from a file or from an url::

    >>> from pyquery import PyQuery as pq
    >>> from lxml import etree
    >>> import urllib
    >>> d = pq("<html></html>")
    >>> d = pq(etree.fromstring("<html></html>"))
    >>> d = pq(url='http://google.com/')
    >>> d = pq(url='http://google.com/', opener=lambda url: urllib.urlopen(url).read())
    >>> d = pq(filename=path_to_html_file)

Now d is like the $ in jquery::

    >>> d("#hello")
    [<p#hello.hello>]
    >>> p = d("#hello")
    >>> p.html()
    'Hello world !'
    >>> p.html("you know <a href='http://python.org/'>Python</a> rocks")
    [<p#hello.hello>]
    >>> p.html()
    u'you know <a href="http://python.org/">Python</a> rocks'
    >>> p.text()
    'you know Python rocks'

You can use some of the pseudo classes that are available in jQuery but that
are not standard in css such as :first :last :even :odd :eq :lt :gt :checked
:selected :file::

    >>> d('p:first')
    [<p#hello.hello>]


## This file is in the moin format. The latest version is found
## at https://moin.conectiva.com.br/DateUtil

== Contents ==
[[TableOfContents]]

== Description ==
The '''dateutil''' module provides powerful extensions to
the standard '''datetime''' module, available in Python 2.3+.

== Features ==

  * Computing of relative deltas (next month, next year,
  next monday, last week of month, etc);

  * Computing of relative deltas between two given
  date and/or datetime objects;

  * Computing of dates based on very flexible recurrence rules,
  using a superset of the
  [ftp://ftp.rfc-editor.org/in-notes/rfc2445.txt iCalendar]
  specification. Parsing of RFC strings is supported as well.

  * Generic parsing of dates in almost any string format;

  * Timezone (tzinfo) implementations for tzfile(5) format
  files (/etc/localtime, /usr/share/zoneinfo, etc), TZ
  environment string (in all known formats), iCalendar
  format files, given ranges (with help from relative deltas),
  local machine timezone, fixed offset timezone, UTC timezone,
  and Windows registry-based time zones.

  * Internal up-to-date world timezone information based on
  Olson's database.

  * Computing of Easter Sunday dates for any given year,
  using Western, Orthodox or Julian algorithms;

  * More than 400 test cases.

== Quick example ==
Here's a snapshot, just to give an idea about the power of the
package. For more examples, look at the documentation below.

Suppose you want to know how much time is left, in
years/months/days/etc, before the next easter happening on a
year with a Friday 13th in August, and you want to get today's
date out of the "date" unix system command. Here is the code:
{{{
from dateutil.relativedelta import *
from dateutil.easter import *
from dateutil.rrule import *
from dateutil.parser import *
from datetime import *
import commands
import os
now = parse(commands.getoutput("date"))
today = now.date()
year = rrule(YEARLY,bymonth=8,bymonthday=13,byweekday=FR)[0].year
rdelta = relativedelta(easter(year), today)
print "Today is:", today
print "Year with next Aug 13th on a Friday is:", year
print "How far is the Easter of that year:", rdelta
print "And the Easter of that year is:", today+rdelta
}}}

And here's the output:
{{{
Today is: 2003-10-11
Year with next Aug 13th on a Friday is: 2004
How far is the Easter of that year: relativedelta(months=+6)
And the Easter of that year is: 2004-04-11
}}}

{i} Being exactly 6 months ahead was '''really''' a coincidence :)

== Download ==
The following files are available.
  * attachment:python-dateutil-1.0.tar.bz2
  * attachment:python-dateutil-1.0-1.noarch.rpm

== Author ==
The dateutil module was written by GustavoNiemeyer <gustavo@niemeyer.net>.

== Documentation ==
The following modules are available.

=== relativedelta ===
This module offers the '''relativedelta''' type, which is based 
on the specification of the excelent work done by M.-A. Lemburg in his
[http://www.egenix.com/files/python/mxDateTime.html mxDateTime]
extension. However, notice that this type '''does not''' implement the
same algorithm as his work. Do not expect it to behave like
{{{mxDateTime}}}'s counterpart.

==== relativedelta type ====

There's two different ways to build a relativedelta instance. The
first one is passing it two {{{date}}}/{{{datetime}}} instances:
{{{
relativedelta(datetime1, datetime2)
}}}

This will build the relative difference between {{{datetime1}}} and
{{{datetime2}}}, so that the following constraint is always true:
{{{
datetime2+relativedelta(datetime1, datetime2) == datetime1
}}}

Notice that instead of {{{datetime}}} instances, you may use
{{{date}}} instances, or a mix of both.

And the other way is to use any of the following keyword arguments:

  year, month, day, hour, minute, second, microsecond::
  Absolute information.

  years, months, weeks, days, hours, minutes, seconds, microseconds::
  Relative information, may be negative.

  weekday::
  One of the weekday instances ({{{MO}}}, {{{TU}}}, etc). These
  instances may receive a parameter {{{n}}}, specifying the {{{n}}}th
  weekday, which could be positive or negative (like {{{MO(+2)}}} or
  {{{MO(-3)}}}. Not specifying it is the same as specifying {{{+1}}}.
  You can also use an integer, where {{{0=MO}}}. Notice that,
  for example, if the calculated date is already Monday, using
  {{{MO}}} or {{{MO(+1)}}} (which is the same thing in this context),
  won't change the day.

  leapdays::
  Will add given days to the date found, but only if the computed
  year is a leap year and the computed date is post 28 of february.

  yearday, nlyearday::
  Set the yearday or the non-leap year day (jump leap days).
  These are converted to {{{day}}}/{{{month}}}/{{{leapdays}}}
  information.

==== Behavior of operations ====
If you're curious about exactly how the relative delta will act
on operations, here is a description of its behavior.

  1. Calculate the absolute year, using the {{{year}}} argument, or the
  original datetime year, if the argument is not present.
  1. Add the relative {{{years}}} argument to the absolute year.
  1. Do steps 1 and 2 for {{{month}}}/{{{months}}}.
  1. Calculate the absolute day, using the {{{day}}} argument, or the
  original datetime day, if the argument is not present. Then, subtract
  from the day until it fits in the year and month found after their
  operations.
  1. Add the relative {{{days}}} argument to the absolute day. Notice
  that the {{{weeks}}} argument is multiplied by 7 and added to {{{days}}}.
  1. If {{{leapdays}}} is present, the computed year is a leap year, and
  the computed month is after february, remove one day from the found date.
  1. Do steps 1 and 2 for {{{hour}}}/{{{hours}}}, {{{minute}}}/{{{minutes}}},
  {{{second}}}/{{{seconds}}}, {{{microsecond}}}/{{{microseconds}}}.
  1. If the {{{weekday}}} argument is present, calculate the {{{n}}}th
  occurrence of the given weekday.

==== Examples ====

Let's begin our trip.
{{{
>>> from datetime import *; from dateutil.relativedelta import *
>>> import calendar
}}}

Store some values.
{{{
>>> NOW = datetime.now()
>>> TODAY = date.today()
>>> NOW
datetime.datetime(2003, 9, 17, 20, 54, 47, 282310)
>>> TODAY
datetime.date(2003, 9, 17)
}}}

Next month.
{{{
>>> NOW+relativedelta(months=+1)
datetime.datetime(2003, 10, 17, 20, 54, 47, 282310)
}}}

Next month, plus one week.
{{{
>>> NOW+relativedelta(months=+1, weeks=+1)
datetime.datetime(2003, 10, 24, 20, 54, 47, 282310)
}}}

Next month, plus one week, at 10am.
{{{
>>> TODAY+relativedelta(months=+1, weeks=+1, hour=10)
datetime.datetime(2003, 10, 24, 10, 0)
}}}

Let's try the other way around. Notice that the
hour setting we get in the relativedelta is relative,
since it's a difference, and the weeks parameter
has gone.
{{{
>>> relativedelta(datetime(2003, 10, 24, 10, 0), TODAY)
relativedelta(months=+1, days=+7, hours=+10)
}}}

One month before one year.
{{{
>>> NOW+relativedelta(years=+1, months=-1)
datetime.datetime(2004, 8, 17, 20, 54, 47, 282310)
}}}

How does it handle months with different numbers of days?
Notice that adding one month will never cross the month
boundary.
{{{
>>> date(2003,1,27)+relativedelta(months=+1)
datetime.date(2003, 2, 27)
>>> date(2003,1,31)+relativedelta(months=+1)
datetime.date(2003, 2, 28)
>>> date(2003,1,31)+relativedelta(months=+2)
datetime.date(2003, 3, 31)
}}}

The logic for years is the same, even on leap years.
{{{
>>> date(2000,2,28)+relativedelta(years=+1)
datetime.date(2001, 2, 28)
>>> date(2000,2,29)+relativedelta(years=+1)
datetime.date(2001, 2, 28)

>>> date(1999,2,28)+relativedelta(years=+1)
datetime.date(2000, 2, 28)
>>> date(1999,3,1)+relativedelta(years=+1)
datetime.date(2000, 3, 1)

>>> date(2001,2,28)+relativedelta(years=-1)
datetime.date(2000, 2, 28)
>>> date(2001,3,1)+relativedelta(years=-1)
datetime.date(2000, 3, 1)
}}}

Next friday.
{{{
>>> TODAY+relativedelta(weekday=FR)
datetime.date(2003, 9, 19)

>>> TODAY+relativedelta(weekday=calendar.FRIDAY)
datetime.date(2003, 9, 19)
}}}

Last friday in this month.
{{{
>>> TODAY+relativedelta(day=31, weekday=FR(-1))
datetime.date(2003, 9, 26)
}}}

Next wednesday (it's today!).
{{{
>>> TODAY+relativedelta(weekday=WE(+1))
datetime.date(2003, 9, 17)
}}}

Next wednesday, but not today.
{{{
>>> TODAY+relativedelta(days=+1, weekday=WE(+1))
datetime.date(2003, 9, 24)
}}}

Following
[http://www.cl.cam.ac.uk/~mgk25/iso-time.html ISO year week number notation]
find the first day of the 15th week of 1997.
{{{
>>> datetime(1997,1,1)+relativedelta(day=4, weekday=MO(-1), weeks=+14)
datetime.datetime(1997, 4, 7, 0, 0)
}}}

How long ago has the millennium changed?
{{{
>>> relativedelta(NOW, date(2001,1,1))
relativedelta(years=+2, months=+8, days=+16,
	      hours=+20, minutes=+54, seconds=+47, microseconds=+282310)
}}}

How old is John?
{{{
>>> johnbirthday = datetime(1978, 4, 5, 12, 0)
>>> relativedelta(NOW, johnbirthday)
relativedelta(years=+25, months=+5, days=+12,
	      hours=+8, minutes=+54, seconds=+47, microseconds=+282310)
}}}

It works with dates too.
{{{
>>> relativedelta(TODAY, johnbirthday)
relativedelta(years=+25, months=+5, days=+11, hours=+12)
}}}

Obtain today's date using the yearday:
{{{
>>> date(2003, 1, 1)+relativedelta(yearday=260)
datetime.date(2003, 9, 17)
}}}

We can use today's date, since yearday should be absolute
in the given year:
{{{
>>> TODAY+relativedelta(yearday=260)
datetime.date(2003, 9, 17)
}}}

Last year it should be in the same day:
{{{
>>> date(2002, 1, 1)+relativedelta(yearday=260)
datetime.date(2002, 9, 17)
}}}

But not in a leap year:
{{{
>>> date(2000, 1, 1)+relativedelta(yearday=260)
datetime.date(2000, 9, 16)
}}}

We can use the non-leap year day to ignore this:
{{{
>>> date(2000, 1, 1)+relativedelta(nlyearday=260)
datetime.date(2000, 9, 17)
}}}

=== rrule ===
The rrule module offers a small, complete, and very fast, implementation
of the recurrence rules documented in the 
[ftp://ftp.rfc-editor.org/in-notes/rfc2445.txt iCalendar RFC], including
support for caching of results.

==== rrule type ====
That's the base of the rrule operation. It accepts all the keywords
defined in the RFC as its constructor parameters (except {{{byday}}},
which was renamed to {{{byweekday}}}) and more. The constructor
prototype is:
{{{
rrule(freq)
}}}

Where {{{freq}}} must be one of {{{YEARLY}}}, {{{MONTHLY}}},
{{{WEEKLY}}}, {{{DAILY}}}, {{{HOURLY}}}, {{{MINUTELY}}},
or {{{SECONDLY}}}.

Additionally, it supports the following keyword arguments:

    cache::
    If given, it must be a boolean value specifying to enable
    or disable caching of results. If you will use the same
    {{{rrule}}} instance multiple times, enabling caching will
    improve the performance considerably.

    dtstart::
    The recurrence start. Besides being the base for the
    recurrence, missing parameters in the final recurrence
    instances will also be extracted from this date. If not
    given, {{{datetime.now()}}} will be used instead.

    interval::
    The interval between each {{{freq}}} iteration. For example,
    when using {{{YEARLY}}}, an interval of {{{2}}} means
    once every two years, but with {{{HOURLY}}}, it means
    once every two hours. The default interval is {{{1}}}.

    wkst::
    The week start day. Must be one of the {{{MO}}}, {{{TU}}},
    {{{WE}}} constants, or an integer, specifying the first day
    of the week. This will affect recurrences based on weekly
    periods. The default week start is got from
    {{{calendar.firstweekday()}}}, and may be modified by
    {{{calendar.setfirstweekday()}}}.

    count::
    How many occurrences will be generated.

    until::
    If given, this must be a {{{datetime}}} instance, that will
    specify the limit of the recurrence. If a recurrence instance
    happens to be the same as the {{{datetime}}} instance given
    in the {{{until}}} keyword, this will be the last occurrence.

    bysetpos::
    If given, it must be either an integer, or a sequence of
    integers, positive or negative. Each given integer will
    specify an occurrence number, corresponding to the nth
    occurrence of the rule inside the frequency period. For
    example, a {{{bysetpos}}} of {{{-1}}} if combined with a
    {{{MONTHLY}}} frequency, and a {{{byweekday}}} of
    {{{(MO, TU, WE, TH, FR)}}}, will result in the last work
    day of every month.

    bymonth::
    If given, it must be either an integer, or a sequence of
    integers, meaning the months to apply the recurrence to.

    bymonthday::
    If given, it must be either an integer, or a sequence of
    integers, meaning the month days to apply the recurrence to.

    byyearday::
    If given, it must be either an integer, or a sequence of
    integers, meaning the year days to apply the recurrence to.

    byweekno::
    If given, it must be either an integer, or a sequence of
    integers, meaning the week numbers to apply the recurrence
    to. Week numbers have the meaning described in ISO8601,
    that is, the first week of the year is that containing at
    least four days of the new year.
    
    byweekday::
    If given, it must be either an integer ({{{0 == MO}}}), a
    sequence of integers, one of the weekday constants
    ({{{MO}}}, {{{TU}}}, etc), or a sequence of these constants.
    When given, these variables will define the weekdays where
    the recurrence will be applied. It's also possible to use
    an argument {{{n}}} for the weekday instances, which will
    mean the {{{n}}}''th'' occurrence of this weekday in the
    period. For example, with {{{MONTHLY}}}, or with
    {{{YEARLY}}} and {{{BYMONTH}}}, using {{{FR(+1)}}}
    in {{{byweekday}}} will specify the first friday of the
    month where the recurrence happens. Notice that in the RFC
    documentation, this is specified as {{{BYDAY}}}, but was
    renamed to avoid the ambiguity of that keyword.

    byhour::
    If given, it must be either an integer, or a sequence of
    integers, meaning the hours to apply the recurrence to.

    byminute::
    If given, it must be either an integer, or a sequence of
    integers, meaning the minutes to apply the recurrence to.

    bysecond::
    If given, it must be either an integer, or a sequence of
    integers, meaning the seconds to apply the recurrence to.

    byeaster::
    If given, it must be either an integer, or a sequence of
    integers, positive or negative. Each integer will define
    an offset from the Easter Sunday. Passing the offset
    {{{0}}} to {{{byeaster}}} will yield the Easter Sunday
    itself. This is an extension to the RFC specification.

==== rrule methods ====
The following methods are available in {{{rrule}}} instances:

    rrule.before(dt, inc=False)::
    Returns the last recurrence before the given {{{datetime}}}
    instance. The {{{inc}}} keyword defines what happens if
    {{{dt}}} '''is''' an occurrence. With {{{inc == True}}},
    if {{{dt}}} itself is an occurrence, it will be returned.

    rrule.after(dt, inc=False)::
    Returns the first recurrence after the given {{{datetime}}}
    instance. The {{{inc}}} keyword defines what happens if
    {{{dt}}} '''is''' an occurrence. With {{{inc == True}}},
    if {{{dt}}} itself is an occurrence, it will be returned.

    rrule.between(after, before, inc=False)::
    Returns all the occurrences of the rrule between {{{after}}}
    and {{{before}}}. The {{{inc}}} keyword defines what happens
    if {{{after}}} and/or {{{before}}} are themselves occurrences.
    With {{{inc == True}}}, they will be included in the list,
    if they are found in the recurrence set.

    rrule.count()::
    Returns the number of recurrences in this set. It will have
    go trough the whole recurrence, if this hasn't been done
    before.

Besides these methods, {{{rrule}}} instances also support
the {{{__getitem__()}}} and {{{__contains__()}}} special methods,
meaning that these are valid expressions:
{{{
rr = rrule(...)
if datetime(...) in rr:
    ...
print rr[0]
print rr[-1]
print rr[1:2]
print rr[::-2]
}}}

The getitem/slicing mechanism is smart enough to avoid getting the whole
recurrence set, if possible.

==== Notes ====

  * The rrule type has no {{{byday}}} keyword. The equivalent keyword
  has been replaced by the {{{byweekday}}} keyword, to remove the
  ambiguity present in the original keyword.

  * Unlike documented in the RFC, the starting datetime ({{{dtstart}}})
  is not the first recurrence instance, unless it does fit in the
  specified rules. In a python module context, this behavior makes more
  sense than otherwise. Notice that you can easily get the original
  behavior by using a rruleset and adding the {{{dtstart}}} as an
  {{{rdate}}} recurrence.

  * Unlike documented in the RFC, every keyword is valid on every
  frequency (the RFC documents that {{{byweekno}}} is only valid
  on yearly frequencies, for example).

  * In addition to the documented keywords, a {{{byeaster}}} keyword
  was introduced, making it easy to compute recurrent events relative
  to the Easter Sunday.

==== rrule examples ====
These examples were converted from the RFC.

Prepare the environment.
{{{
>>> from dateutil.rrule import *
>>> from dateutil.parser import *
>>> from datetime import *

>>> import pprint
>>> import sys
>>> sys.displayhook = pprint.pprint
}}}

Daily, for 10 occurrences.
{{{
>>> list(rrule(DAILY, count=10,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 3, 9, 0),
 datetime.datetime(1997, 9, 4, 9, 0),
 datetime.datetime(1997, 9, 5, 9, 0),
 datetime.datetime(1997, 9, 6, 9, 0),
 datetime.datetime(1997, 9, 7, 9, 0),
 datetime.datetime(1997, 9, 8, 9, 0),
 datetime.datetime(1997, 9, 9, 9, 0),
 datetime.datetime(1997, 9, 10, 9, 0),
 datetime.datetime(1997, 9, 11, 9, 0)]
}}}

Daily until December 24, 1997
{{{
>>> list(rrule(DAILY,
	       dtstart=parse("19970902T090000"),
	       until=parse("19971224T000000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 3, 9, 0),
 datetime.datetime(1997, 9, 4, 9, 0),
 (...)
 datetime.datetime(1997, 12, 21, 9, 0),
 datetime.datetime(1997, 12, 22, 9, 0),
 datetime.datetime(1997, 12, 23, 9, 0)]
}}}

Every other day, 5 occurrences.
{{{
>>> list(rrule(DAILY, interval=2, count=5,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 4, 9, 0),
 datetime.datetime(1997, 9, 6, 9, 0),
 datetime.datetime(1997, 9, 8, 9, 0),
 datetime.datetime(1997, 9, 10, 9, 0)]
}}}

Every 10 days, 5 occurrences.
{{{
>>> list(rrule(DAILY, interval=10, count=5,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 12, 9, 0),
 datetime.datetime(1997, 9, 22, 9, 0),
 datetime.datetime(1997, 10, 2, 9, 0),
 datetime.datetime(1997, 10, 12, 9, 0)]
}}}

Everyday in January, for 3 years.
{{{
>>> list(rrule(YEARLY, bymonth=1, byweekday=range(7),
	       dtstart=parse("19980101T090000"),
	       until=parse("20000131T090000")))
[datetime.datetime(1998, 1, 1, 9, 0),
 datetime.datetime(1998, 1, 2, 9, 0),
 (...)
 datetime.datetime(1998, 1, 30, 9, 0),
 datetime.datetime(1998, 1, 31, 9, 0),
 datetime.datetime(1999, 1, 1, 9, 0),
 datetime.datetime(1999, 1, 2, 9, 0),
 (...)
 datetime.datetime(1999, 1, 30, 9, 0),
 datetime.datetime(1999, 1, 31, 9, 0),
 datetime.datetime(2000, 1, 1, 9, 0),
 datetime.datetime(2000, 1, 2, 9, 0),
 (...)
 datetime.datetime(2000, 1, 29, 9, 0),
 datetime.datetime(2000, 1, 31, 9, 0)]
}}} 

Same thing, in another way.
{{{
>>> list(rrule(DAILY, bymonth=1,
               dtstart=parse("19980101T090000"),
	       until=parse("20000131T090000")))
(...)
}}}

Weekly for 10 occurrences.
{{{
>>> list(rrule(WEEKLY, count=10,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 9, 9, 0),
 datetime.datetime(1997, 9, 16, 9, 0),
 datetime.datetime(1997, 9, 23, 9, 0),
 datetime.datetime(1997, 9, 30, 9, 0),
 datetime.datetime(1997, 10, 7, 9, 0),
 datetime.datetime(1997, 10, 14, 9, 0),
 datetime.datetime(1997, 10, 21, 9, 0),
 datetime.datetime(1997, 10, 28, 9, 0),
 datetime.datetime(1997, 11, 4, 9, 0)]
}}}

Every other week, 6 occurrences.
{{{
>>> list(rrule(WEEKLY, interval=2, count=6,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 16, 9, 0),
 datetime.datetime(1997, 9, 30, 9, 0),
 datetime.datetime(1997, 10, 14, 9, 0),
 datetime.datetime(1997, 10, 28, 9, 0),
 datetime.datetime(1997, 11, 11, 9, 0)]
}}}

Weekly on Tuesday and Thursday for 5 weeks.
{{{
>>> list(rrule(WEEKLY, count=10, wkst=SU, byweekday=(TU,TH),
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 4, 9, 0),
 datetime.datetime(1997, 9, 9, 9, 0),
 datetime.datetime(1997, 9, 11, 9, 0),
 datetime.datetime(1997, 9, 16, 9, 0),
 datetime.datetime(1997, 9, 18, 9, 0),
 datetime.datetime(1997, 9, 23, 9, 0),
 datetime.datetime(1997, 9, 25, 9, 0),
 datetime.datetime(1997, 9, 30, 9, 0),
 datetime.datetime(1997, 10, 2, 9, 0)]
}}}

Every other week on Tuesday and Thursday, for 8 occurrences.
{{{
>>> list(rrule(WEEKLY, interval=2, count=8,
	       wkst=SU, byweekday=(TU,TH),
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 4, 9, 0),
 datetime.datetime(1997, 9, 16, 9, 0),
 datetime.datetime(1997, 9, 18, 9, 0),
 datetime.datetime(1997, 9, 30, 9, 0),
 datetime.datetime(1997, 10, 2, 9, 0),
 datetime.datetime(1997, 10, 14, 9, 0),
 datetime.datetime(1997, 10, 16, 9, 0)]
}}}

Monthly on the 1st Friday for ten occurrences.
{{{
>>> list(rrule(MONTHLY, count=10, byweekday=FR(1),
	       dtstart=parse("19970905T090000")))
[datetime.datetime(1997, 9, 5, 9, 0),
 datetime.datetime(1997, 10, 3, 9, 0),
 datetime.datetime(1997, 11, 7, 9, 0),
 datetime.datetime(1997, 12, 5, 9, 0),
 datetime.datetime(1998, 1, 2, 9, 0),
 datetime.datetime(1998, 2, 6, 9, 0),
 datetime.datetime(1998, 3, 6, 9, 0),
 datetime.datetime(1998, 4, 3, 9, 0),
 datetime.datetime(1998, 5, 1, 9, 0),
 datetime.datetime(1998, 6, 5, 9, 0)]
}}}

Every other month on the 1st and last Sunday of the month for 10 occurrences.
{{{
>>> list(rrule(MONTHLY, interval=2, count=10,
	       byweekday=(SU(1), SU(-1)),
	       dtstart=parse("19970907T090000")))
[datetime.datetime(1997, 9, 7, 9, 0),
 datetime.datetime(1997, 9, 28, 9, 0),
 datetime.datetime(1997, 11, 2, 9, 0),
 datetime.datetime(1997, 11, 30, 9, 0),
 datetime.datetime(1998, 1, 4, 9, 0),
 datetime.datetime(1998, 1, 25, 9, 0),
 datetime.datetime(1998, 3, 1, 9, 0),
 datetime.datetime(1998, 3, 29, 9, 0),
 datetime.datetime(1998, 5, 3, 9, 0),
 datetime.datetime(1998, 5, 31, 9, 0)]
}}}

Monthly on the second to last Monday of the month for 6 months.
{{{
>>> list(rrule(MONTHLY, count=6, byweekday=MO(-2),
	       dtstart=parse("19970922T090000")))
[datetime.datetime(1997, 9, 22, 9, 0),
 datetime.datetime(1997, 10, 20, 9, 0),
 datetime.datetime(1997, 11, 17, 9, 0),
 datetime.datetime(1997, 12, 22, 9, 0),
 datetime.datetime(1998, 1, 19, 9, 0),
 datetime.datetime(1998, 2, 16, 9, 0)]
}}}

Monthly on the third to the last day of the month, for 6 months.
{{{
>>> list(rrule(MONTHLY, count=6, bymonthday=-3,
	       dtstart=parse("19970928T090000")))
[datetime.datetime(1997, 9, 28, 9, 0),
 datetime.datetime(1997, 10, 29, 9, 0),
 datetime.datetime(1997, 11, 28, 9, 0),
 datetime.datetime(1997, 12, 29, 9, 0),
 datetime.datetime(1998, 1, 29, 9, 0),
 datetime.datetime(1998, 2, 26, 9, 0)]
}}}

Monthly on the 2nd and 15th of the month for 5 occurrences.
{{{
>>> list(rrule(MONTHLY, count=5, bymonthday=(2,15),
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 15, 9, 0),
 datetime.datetime(1997, 10, 2, 9, 0),
 datetime.datetime(1997, 10, 15, 9, 0),
 datetime.datetime(1997, 11, 2, 9, 0)]
}}}

Monthly on the first and last day of the month for 3 occurrences.
{{{
>>> list(rrule(MONTHLY, count=5, bymonthday=(-1,1,),
               dtstart=parse("1997090
2T090000")))
[datetime.datetime(1997, 9, 30, 9, 0),
 datetime.datetime(1997, 10, 1, 9, 0),
 datetime.datetime(1997, 10, 31, 9, 0),
 datetime.datetime(1997, 11, 1, 9, 0),
 datetime.datetime(1997, 11, 30, 9, 0)]
}}}

Every 18 months on the 10th thru 15th of the month for 10 occurrences.
{{{
>>> list(rrule(MONTHLY, interval=18, count=10,
	       bymonthday=range(10,16),
	       dtstart=parse("19970910T090000")))
[datetime.datetime(1997, 9, 10, 9, 0),
 datetime.datetime(1997, 9, 11, 9, 0),
 datetime.datetime(1997, 9, 12, 9, 0),
 datetime.datetime(1997, 9, 13, 9, 0),
 datetime.datetime(1997, 9, 14, 9, 0),
 datetime.datetime(1997, 9, 15, 9, 0),
 datetime.datetime(1999, 3, 10, 9, 0),
 datetime.datetime(1999, 3, 11, 9, 0),
 datetime.datetime(1999, 3, 12, 9, 0),
 datetime.datetime(1999, 3, 13, 9, 0)]
}}}

Every Tuesday, every other month, 6 occurences.
{{{
>>> list(rrule(MONTHLY, interval=2, count=6, byweekday=TU,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 9, 9, 0),
 datetime.datetime(1997, 9, 16, 9, 0),
 datetime.datetime(1997, 9, 23, 9, 0),
 datetime.datetime(1997, 9, 30, 9, 0),
 datetime.datetime(1997, 11, 4, 9, 0)]
}}}

Yearly in June and July for 10 occurrences.
{{{
>>> list(rrule(YEARLY, count=4, bymonth=(6,7),
	       dtstart=parse("19970610T0900
00")))
[datetime.datetime(1997, 6, 10, 9, 0),
 datetime.datetime(1997, 7, 10, 9, 0),
 datetime.datetime(1998, 6, 10, 9, 0),
 datetime.datetime(1998, 7, 10, 9, 0)]
}}}

Every 3rd year on the 1st, 100th and 200th day for 4 occurrences.
{{{
>>> list(rrule(YEARLY, count=4, interval=3, byyearday=(1,100,200),
	       dtstart=parse("19970101T090000")))
[datetime.datetime(1997, 1, 1, 9, 0),
 datetime.datetime(1997, 4, 10, 9, 0),
 datetime.datetime(1997, 7, 19, 9, 0),
 datetime.datetime(2000, 1, 1, 9, 0)]
}}}

Every 20th Monday of the year, 3 occurrences.
{{{
>>> list(rrule(YEARLY, count=3, byweekday=MO(20),
	       dtstart=parse("19970519T090000")))
[datetime.datetime(1997, 5, 19, 9, 0),
 datetime.datetime(1998, 5, 18, 9, 0),
 datetime.datetime(1999, 5, 17, 9, 0)]
}}}

Monday of week number 20 (where the default start of the week is Monday),
3 occurrences.
{{{
>>> list(rrule(YEARLY, count=3, byweekno=20, byweekday=MO,
	       dtstart=parse("19970512T090000")))
[datetime.datetime(1997, 5, 12, 9, 0),
 datetime.datetime(1998, 5, 11, 9, 0),
 datetime.datetime(1999, 5, 17, 9, 0)]
}}}

The week number 1 may be in the last year.
{{{
>>> list(rrule(WEEKLY, count=3, byweekno=1, byweekday=MO,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 12, 29, 9, 0),
 datetime.datetime(1999, 1, 4, 9, 0),
 datetime.datetime(2000, 1, 3, 9, 0)]
}}}

And the week numbers greater than 51 may be in the next year.
{{{
>>> list(rrule(WEEKLY, count=3, byweekno=52, byweekday=SU,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 12, 28, 9, 0),
 datetime.datetime(1998, 12, 27, 9, 0),
 datetime.datetime(2000, 1, 2, 9, 0)]
}}}

Only some years have week number 53:
{{{
>>> list(rrule(WEEKLY, count=3, byweekno=53, byweekday=MO,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1998, 12, 28, 9, 0),
 datetime.datetime(2004, 12, 27, 9, 0),
 datetime.datetime(2009, 12, 28, 9, 0)]
}}}

Every Friday the 13th, 4 occurrences.
{{{
>>> list(rrule(YEARLY, count=4, byweekday=FR, bymonthday=13,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1998, 2, 13, 9, 0),
 datetime.datetime(1998, 3, 13, 9, 0),
 datetime.datetime(1998, 11, 13, 9, 0),
 datetime.datetime(1999, 8, 13, 9, 0)]
}}}

Every four years, the first Tuesday after a Monday in November,
3 occurrences (U.S. Presidential Election day):
{{{
>>> list(rrule(YEARLY, interval=4, count=3, bymonth=11,
	       byweekday=TU, bymonthday=(2,3,4,5,6,7,8),
	       dtstart=parse("19961105T090000")))
[datetime.datetime(1996, 11, 5, 9, 0),
 datetime.datetime(2000, 11, 7, 9, 0),
 datetime.datetime(2004, 11, 2, 9, 0)]
}}}

The 3rd instance into the month of one of Tuesday, Wednesday or
Thursday, for the next 3 months:
{{{
>>> list(rrule(MONTHLY, count=3, byweekday=(TU,WE,TH),
	       bysetpos=3, dtstart=parse("19970904T090000")))
[datetime.datetime(1997, 9, 4, 9, 0),
 datetime.datetime(1997, 10, 7, 9, 0),
 datetime.datetime(1997, 11, 6, 9, 0)]
}}}

The 2nd to last weekday of the month, 3 occurrences.
{{{
>>> list(rrule(MONTHLY, count=3, byweekday=(MO,TU,WE,TH,FR),
	       bysetpos=-2, dtstart=parse("19970929T090000")))
[datetime.datetime(1997, 9, 29, 9, 0),
 datetime.datetime(1997, 10, 30, 9, 0),
 datetime.datetime(1997, 11, 27, 9, 0)]
}}}

Every 3 hours from 9:00 AM to 5:00 PM on a specific day.
{{{
>>> list(rrule(HOURLY, interval=3,
	       dtstart=parse("19970902T090000"),
	       until=parse("19970902T170000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 2, 12, 0),
 datetime.datetime(1997, 9, 2, 15, 0)]
}}}

Every 15 minutes for 6 occurrences.
{{{
>>> list(rrule(MINUTELY, interval=15, count=6,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 2, 9, 15),
 datetime.datetime(1997, 9, 2, 9, 30),
 datetime.datetime(1997, 9, 2, 9, 45),
 datetime.datetime(1997, 9, 2, 10, 0),
 datetime.datetime(1997, 9, 2, 10, 15)]
}}}

Every hour and a half for 4 occurrences.
{{{
>>> list(rrule(MINUTELY, interval=90, count=4,
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 2, 10, 30),
 datetime.datetime(1997, 9, 2, 12, 0),
 datetime.datetime(1997, 9, 2, 13, 30)]
}}}

Every 20 minutes from 9:00 AM to 4:40 PM for two days.
{{{
>>> list(rrule(MINUTELY, interval=20, count=48,
	       byhour=range(9,17), byminute=(0,20,40),
	       dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 2, 9, 20),
 (...)
 datetime.datetime(1997, 9, 2, 16, 20),
 datetime.datetime(1997, 9, 2, 16, 40),
 datetime.datetime(1997, 9, 3, 9, 0),
 datetime.datetime(1997, 9, 3, 9, 20),
 (...)
 datetime.datetime(1997, 9, 3, 16, 20),
 datetime.datetime(1997, 9, 3, 16, 40)]
}}}

An example where the days generated makes a difference because of {{{wkst}}}.
{{{
>>> list(rrule(WEEKLY, interval=2, count=4,
	       byweekday=(TU,SU), wkst=MO,
	       dtstart=parse("19970805T090000")))
[datetime.datetime(1997, 8, 5, 9, 0),
 datetime.datetime(1997, 8, 10, 9, 0),
 datetime.datetime(1997, 8, 19, 9, 0),
 datetime.datetime(1997, 8, 24, 9, 0)]

>>> list(rrule(WEEKLY, interval=2, count=4,
	       byweekday=(TU,SU), wkst=SU,
	       dtstart=parse("19970805T090000")))
[datetime.datetime(1997, 8, 5, 9, 0),
 datetime.datetime(1997, 8, 17, 9, 0),
 datetime.datetime(1997, 8, 19, 9, 0),
 datetime.datetime(1997, 8, 31, 9, 0)]
}}}

==== rruleset type ====
The {{{rruleset}}} type allows more complex recurrence setups, mixing
multiple rules, dates, exclusion rules, and exclusion dates.
The type constructor takes the following keyword arguments:

    cache::
    If True, caching of results will be enabled, improving performance
    of multiple queries considerably.

==== rruleset methods ====
The following methods are available:

    rruleset.rrule(rrule)::
    Include the given {{{rrule}}} instance in the recurrence set
    generation.

    rruleset.rdate(dt)::
    Include the given {{{datetime}}} instance in the recurrence
    set generation.
    
    rruleset.exrule(rrule)::
    Include the given {{{rrule}}} instance in the recurrence set
    exclusion list. Dates which are part of the given recurrence
    rules will not be generated, even if some inclusive {{{rrule}}}
    or {{{rdate}}} matches them.

    rruleset.exdate(dt)::
    Include the given {{{datetime}}} instance in the recurrence set
    exclusion list. Dates included that way will not be generated,
    even if some inclusive {{{rrule}}} or {{{rdate}}} matches them.

    rruleset.before(dt, inc=False)::
    Returns the last recurrence before the given {{{datetime}}}
    instance. The {{{inc}}} keyword defines what happens if
    {{{dt}}} '''is''' an occurrence. With {{{inc == True}}},
    if {{{dt}}} itself is an occurrence, it will be returned.

    rruleset.after(dt, inc=False)::
    Returns the first recurrence after the given {{{datetime}}}
    instance. The {{{inc}}} keyword defines what happens if
    {{{dt}}} '''is''' an occurrence. With {{{inc == True}}},
    if {{{dt}}} itself is an occurrence, it will be returned.

    rruleset.between(after, before, inc=False)::
    Returns all the occurrences of the rrule between {{{after}}}
    and {{{before}}}. The {{{inc}}} keyword defines what happens
    if {{{after}}} and/or {{{before}}} are themselves occurrences.
    With {{{inc == True}}}, they will be included in the list,
    if they are found in the recurrence set.

    rruleset.count()::
    Returns the number of recurrences in this set. It will have
    go trough the whole recurrence, if this hasn't been done
    before.

Besides these methods, {{{rruleset}}} instances also support
the {{{__getitem__()}}} and {{{__contains__()}}} special methods,
meaning that these are valid expressions:
{{{
set = rruleset(...)
if datetime(...) in set:
    ...
print set[0]
print set[-1]
print set[1:2]
print set[::-2]
}}}

The getitem/slicing mechanism is smart enough to avoid getting the whole
recurrence set, if possible.

==== rruleset examples ====
Daily, for 7 days, jumping Saturday and Sunday occurrences.
{{{
>>> set = rruleset()
>>> set.rrule(rrule(DAILY, count=7,
		    dtstart=parse("19970902T090000")))
>>> set.exrule(rrule(YEARLY, byweekday=(SA,SU),
		     dtstart=parse("19970902T090000")))
>>> list(set)
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 3, 9, 0),
 datetime.datetime(1997, 9, 4, 9, 0),
 datetime.datetime(1997, 9, 5, 9, 0),
 datetime.datetime(1997, 9, 8, 9, 0)]
}}}

Weekly, for 4 weeks, plus one time on day 7, and not on day 16.
{{{
>>> set = rruleset()
>>> set.rrule(rrule(WEEKLY, count=4,
		    dtstart=parse("19970902T090000")))
>>> set.rdate(datetime.datetime(1997, 9, 7, 9, 0))
>>> set.exdate(datetime.datetime(1997, 9, 16, 9, 0))
>>> list(set)
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 7, 9, 0),
 datetime.datetime(1997, 9, 9, 9, 0),
 datetime.datetime(1997, 9, 23, 9, 0)]
}}}

==== rrulestr() function ====
The {{{rrulestr()}}} function is a parser for ''RFC-like'' syntaxes.
The function prototype is:
{{{
rrulestr(str)
}}}

The string passed as parameter may be a multiple line string, a
single line string, or just the {{{RRULE}}} property value.

Additionally, it accepts the following keyword arguments:

    cache::
    If {{{True}}}, the {{{rruleset}}} or {{{rrule}}} created instance
    will cache its results. Default is not to cache.

    dtstart::
    If given, it must be a {{{datetime}}} instance that will be used
    when no {{{DTSTART}}} property is found in the parsed string. If
    it is not given, and the property is not found, {{{datetime.now()}}}
    will be used instead.

    unfold::
    If set to {{{True}}}, lines will be unfolded following the RFC
    specification. It defaults to {{{False}}}, meaning that spaces
    before every line will be stripped.

    forceset::
    If set to {{{True}}} a {{{rruleset}}} instance will be returned,
    even if only a single rule is found. The default is to return an
    {{{rrule}}} if possible, and an {{{rruleset}}} if necessary.

    compatible::
    If set to {{{True}}}, the parser will operate in RFC-compatible
    mode. Right now it means that {{{unfold}}} will be turned on,
    and if a {{{DTSTART}}} is found, it will be considered the first     
    recurrence instance, as documented in the RFC.

    ignoretz::
    If set to {{{True}}}, the date parser will ignore timezone
    information available in the {{{DTSTART}}} property, or the
    {{{UNTIL}}} attribute.

    tzinfos::
    If set, it will be passed to the datetime string parser to
    resolve unknown timezone settings. For more information about
    what could be used here, check the parser documentation.

==== rrulestr() examples ====

Every 10 days, 5 occurrences.
{{{
>>> list(rrulestr("""
... DTSTART:19970902T090000
... RRULE:FREQ=DAILY;INTERVAL=10;COUNT=5
... """))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 12, 9, 0),
 datetime.datetime(1997, 9, 22, 9, 0),
 datetime.datetime(1997, 10, 2, 9, 0),
 datetime.datetime(1997, 10, 12, 9, 0)]
}}}

Same thing, but passing only the {{{RRULE}}} value.
{{{
>>> list(rrulestr("FREQ=DAILY;INTERVAL=10;COUNT=5",
		  dtstart=parse("19970902T090000")))
[datetime.datetime(1997, 9, 2, 9, 0),
 datetime.datetime(1997, 9, 12, 9, 0),
 datetime.datetime(1997, 9, 22, 9, 0),
 datetime.datetime(1997, 10, 2, 9, 0),
 datetime.datetime(1997, 10, 12, 9, 0)]
}}}

Notice that when using a single rule, it returns an
{{{rrule}}} instance, unless {{{forceset}}} was used.
{{{
>>> rrulestr("FREQ=DAILY;INTERVAL=10;COUNT=5")
<dateutil.rrule.rrule instance at 0x30269f08>

>>> rrulestr("""
... DTSTART:19970902T090000
... RRULE:FREQ=DAILY;INTERVAL=10;COUNT=5
... """)
<dateutil.rrule.rrule instance at 0x302699e0>

>>> rrulestr("FREQ=DAILY;INTERVAL=10;COUNT=5", forceset=True)
<dateutil.rrule.rruleset instance at 0x30269f08>
}}}

But when an {{{rruleset}}} is needed, it is automatically used.
{{{
>>> rrulestr("""
... DTSTART:19970902T090000
... RRULE:FREQ=DAILY;INTERVAL=10;COUNT=5
... RRULE:FREQ=DAILY;INTERVAL=5;COUNT=3
... """)
<dateutil.rrule.rruleset instance at 0x302699e0>
}}}

=== parser ===
This module offers a generic date/time string parser which is
able to parse most known formats to represent a date and/or
time.

==== parse() function ====
That's probably the only function you'll need from this module.
It offers you an interface to access the parser functionality and
extract a {{{datetime}}} type out of a string.

The prototype of this function is:
{{{
parse(timestr)
}}}

Additionally, the following keyword arguments are available:

    default::
    If given, this must be a {{{datetime}}} instance. Any fields
    missing in the parsed date will be copied from this instance.
    The default value is the current date, at 00:00:00am.

    ignoretz::
    If this is true, even if a timezone is found in the string,
    the parser will not use it.

    tzinfos::
    Using this keyword argument you may provide custom timezones
    to the parser. If given, it must be either a dictionary with
    the timezone abbreviation as key, or a function accepting a
    timezone abbreviation and offset as argument. The dictionary
    values and the function return must be a timezone offset
    in seconds, a tzinfo subclass, or a string defining the
    timezone (in the TZ environment variable format).

    dayfirst::
    This option allow one to change the precedence in which
    days are parsed in date strings. The default is given in the
    parserinfo instance (the default parserinfo has it set to
    False). If {{{dayfirst}}} is False, the {{{MM-DD-YYYY}}}
    format will have precedence over {{{DD-MM-YYYY}}} in an
    ambiguous date.

    yearfirst::
    This option allow one to change the precedence in which
    years are parsed in date strings. The default is given in
    the parserinfo instance (the default parserinfo has it set
    to False). If {{{yearfirst}}} is false, the {{{MM-DD-YY}}}
    format will have precedence over {{{YY-MM-DD}}} in an
    ambiguous date.

    fuzzy::
    If {{{fuzzy}}} is set to True, unknown tokens in the string
    will be ignored.

    parserinfo::
    This parameter allows one to change how the string is parsed,
    by using a different parserinfo class instance. Using it you
    may, for example, intenationalize the parser strings, or make
    it ignore additional words.

==== Format precedence ====
Whenever an ambiguous date is found, the {{{dayfirst}}} and
{{{yearfirst}}} parameters will control how the information
is processed. Here is the precedence in each case:

If {{{dayfirst}}} is {{{False}}} and {{{yearfirst}}} is {{{False}}},
(default, if no parameter is given):

    * {{{MM-DD-YY}}}
    * {{{DD-MM-YY}}}
    * {{{YY-MM-DD}}}

If {{{dayfirst}}} is {{{True}}} and {{{yearfirst}}} is {{{False}}}:

    * {{{DD-MM-YY}}}
    * {{{MM-DD-YY}}}
    * {{{YY-MM-DD}}}

If {{{dayfirst}}} is {{{False}}} and {{{yearfirst}}} is {{{True}}}:

    * {{{YY-MM-DD}}}
    * {{{MM-DD-YY}}}
    * {{{DD-MM-YY}}}

If {{{dayfirst}}} is {{{True}}} and {{{yearfirst}}} is {{{True}}}:

    * {{{YY-MM-DD}}}
    * {{{DD-MM-YY}}}
    * {{{MM-DD-YY}}}

==== Converting two digit years ====
When a two digit year is found, it is processed considering
the current year, so that the computed year is never more
than 49 years after the current year, nor 50 years before the
current year. In other words, if we are in year 2003, and the
year 30 is found, it will be considered as 2030, but if the
year 60 is found, it will be considered 1960.

==== Examples ====
The following code will prepare the environment:
{{{
>>> from dateutil.parser import *
>>> from dateutil.tz import *
>>> from datetime import *
>>> TZOFFSETS = {"BRST": -10800}
>>> BRSTTZ = tzoffset(-10800, "BRST")
>>> DEFAULT = datetime(2003, 9, 25)
}}}

Some simple examples based on the {{{date}}} command, using the
{{{TZOFFSET}}} dictionary to provide the BRST timezone offset.
{{{
>>> parse("Thu Sep 25 10:36:28 BRST 2003", tzinfos=TZOFFSETS)
datetime.datetime(2003, 9, 25, 10, 36, 28,
		  tzinfo=tzoffset('BRST', -10800))

>>> parse("2003 10:36:28 BRST 25 Sep Thu", tzinfos=TZOFFSETS)
datetime.datetime(2003, 9, 25, 10, 36, 28,
		  tzinfo=tzoffset('BRST', -10800))
}}}

Notice that since BRST is my local timezone, parsing it without
further timezone settings will yield a {{{tzlocal}}} timezone.
{{{
>>> parse("Thu Sep 25 10:36:28 BRST 2003")
datetime.datetime(2003, 9, 25, 10, 36, 28, tzinfo=tzlocal())
}}}

We can also ask to ignore the timezone explicitly:
{{{
>>> parse("Thu Sep 25 10:36:28 BRST 2003", ignoretz=True)
datetime.datetime(2003, 9, 25, 10, 36, 28)
}}}

That's the same as processing a string without timezone:
{{{
>>> parse("Thu Sep 25 10:36:28 2003")
datetime.datetime(2003, 9, 25, 10, 36, 28)
}}}

Without the year, but passing our {{{DEFAULT}}} datetime to return
the same year, no mattering what year we currently are in:
{{{
>>> parse("Thu Sep 25 10:36:28", default=DEFAULT)
datetime.datetime(2003, 9, 25, 10, 36, 28)
}}}

Strip it further:
{{{
>>> parse("Thu Sep 10:36:28", default=DEFAULT)
datetime.datetime(2003, 9, 25, 10, 36, 28)

>>> parse("Thu 10:36:28", default=DEFAULT)
datetime.datetime(2003, 9, 25, 10, 36, 28)

>>> parse("Thu 10:36", default=DEFAULT)
datetime.datetime(2003, 9, 25, 10, 36)

>>> parse("10:36", default=DEFAULT)
datetime.datetime(2003, 9, 25, 10, 36)
>>> 
}}}

Strip in a different way:
{{{
>>> parse("Thu Sep 25 2003")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("Sep 25 2003")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("Sep 2003", default=DEFAULT)
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("Sep", default=DEFAULT)
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("2003", default=DEFAULT)
datetime.datetime(2003, 9, 25, 0, 0)
}}}

Another format, based on {{{date -R}}} (RFC822):
{{{
>>> parse("Thu, 25 Sep 2003 10:49:41 -0300")
datetime.datetime(2003, 9, 25, 10, 49, 41,
		  tzinfo=tzoffset(None, -10800))
}}}

ISO format:
{{{
>>> parse("2003-09-25T10:49:41.5-03:00")
datetime.datetime(2003, 9, 25, 10, 49, 41, 500000,
		  tzinfo=tzoffset(None, -10800))
}}}

Some variations:
{{{
>>> parse("2003-09-25T10:49:41")
datetime.datetime(2003, 9, 25, 10, 49, 41)

>>> parse("2003-09-25T10:49")
datetime.datetime(2003, 9, 25, 10, 49)

>>> parse("2003-09-25T10")
datetime.datetime(2003, 9, 25, 10, 0)

>>> parse("2003-09-25")
datetime.datetime(2003, 9, 25, 0, 0)
}}}

ISO format, without separators:
{{{
>>> parse("20030925T104941.5-0300")
datetime.datetime(2003, 9, 25, 10, 49, 41, 500000,
		  tzinfo=tzinfo=tzoffset(None, -10800))

>>> parse("20030925T104941-0300")
datetime.datetime(2003, 9, 25, 10, 49, 41,
		  tzinfo=tzoffset(None, -10800))

>>> parse("20030925T104941")
datetime.datetime(2003, 9, 25, 10, 49, 41)

>>> parse("20030925T1049")
datetime.datetime(2003, 9, 25, 10, 49)

>>> parse("20030925T10")
datetime.datetime(2003, 9, 25, 10, 0)

>>> parse("20030925")
datetime.datetime(2003, 9, 25, 0, 0)
}}}

Everything together.
{{{
>>> parse("199709020900")
datetime.datetime(1997, 9, 2, 9, 0)
>>> parse("19970902090059")
datetime.datetime(1997, 9, 2, 9, 0, 59)
}}}

Different date orderings:
{{{
>>> parse("2003-09-25")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("2003-Sep-25")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("25-Sep-2003")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("Sep-25-2003")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("09-25-2003")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("25-09-2003")
datetime.datetime(2003, 9, 25, 0, 0)
}}}

Check some ambiguous dates:
{{{
>>> parse("10-09-2003")
datetime.datetime(2003, 10, 9, 0, 0)

>>> parse("10-09-2003", dayfirst=True)
datetime.datetime(2003, 9, 10, 0, 0)

>>> parse("10-09-03")
datetime.datetime(2003, 10, 9, 0, 0)

>>> parse("10-09-03", yearfirst=True)
datetime.datetime(2010, 9, 3, 0, 0)
}}}

Other date separators are allowed:
{{{
>>> parse("2003.Sep.25")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("2003/09/25")
datetime.datetime(2003, 9, 25, 0, 0)
}}}

Even with spaces:
{{{
>>> parse("2003 Sep 25")
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("2003 09 25")
datetime.datetime(2003, 9, 25, 0, 0)
}}}

Hours with letters work:
{{{
>>> parse("10h36m28.5s", default=DEFAULT)
datetime.datetime(2003, 9, 25, 10, 36, 28, 500000)

>>> parse("01s02h03m", default=DEFAULT)
datetime.datetime(2003, 9, 25, 2, 3, 1)

>>> parse("01h02m03", default=DEFAULT)
datetime.datetime(2003, 9, 3, 1, 2)

>>> parse("01h02", default=DEFAULT)
datetime.datetime(2003, 9, 2, 1, 0)

>>> parse("01h02s", default=DEFAULT)
datetime.datetime(2003, 9, 25, 1, 0, 2)
}}}

With AM/PM:
{{{
>>> parse("10h am", default=DEFAULT)
datetime.datetime(2003, 9, 25, 10, 0)

>>> parse("10pm", default=DEFAULT)
datetime.datetime(2003, 9, 25, 22, 0)

>>> parse("12:00am", default=DEFAULT)
datetime.datetime(2003, 9, 25, 0, 0)

>>> parse("12pm", default=DEFAULT)
datetime.datetime(2003, 9, 25, 12, 0)
}}}

Some special treating for ''pertain'' relations:
{{{
>>> parse("Sep 03", default=DEFAULT)
datetime.datetime(2003, 9, 3, 0, 0)

>>> parse("Sep of 03", default=DEFAULT)
datetime.datetime(2003, 9, 25, 0, 0)
}}}

Fuzzy parsing:
{{{
>>> s = "Today is 25 of September of 2003, exactly " \
...     "at 10:49:41 with timezone -03:00."
>>> parse(s, fuzzy=True)
datetime.datetime(2003, 9, 25, 10, 49, 41,
		  tzinfo=tzoffset(None, -10800))
}}}

Other random formats:
{{{
>>> parse("Wed, July 10, '96")
datetime.datetime(1996, 7, 10, 0, 0)

>>> parse("1996.07.10 AD at 15:08:56 PDT", ignoretz=True)
datetime.datetime(1996, 7, 10, 15, 8, 56)

>>> parse("Tuesday, April 12, 1952 AD 3:30:42pm PST", ignoretz=True)
datetime.datetime(1952, 4, 12, 15, 30, 42)

>>> parse("November 5, 1994, 8:15:30 am EST", ignoretz=True)
datetime.datetime(1994, 11, 5, 8, 15, 30)

>>> parse("3rd of May 2001")
datetime.datetime(2001, 5, 3, 0, 0)

>>> parse("5:50 A.M. on June 13, 1990")
datetime.datetime(1990, 6, 13, 5, 50)
}}}

=== easter ===
This module offers a generic easter computing method for
any given year, using Western, Orthodox or Julian algorithms.

==== easter() function ====
This method was ported from the work done by
[http://users.chariot.net.au/~gmarts/eastalg.htm GM Arts],
on top of the algorithm by
[http://www.tondering.dk/claus/calendar.html Claus Tondering],
which was based in part on the algorithm of Ouding (1940),
as quoted in "Explanatory Supplement to the Astronomical
Almanac", P.  Kenneth Seidelmann, editor.

This algorithm implements three different easter
calculation methods:

    1. Original calculation in Julian calendar, valid in
    dates after 326 AD
    1. Original method, with date converted to Gregorian
    calendar, valid in years 1583 to 4099
    1. Revised method, in Gregorian calendar, valid in
    years 1583 to 4099 as well

These methods are represented by the constants:
{{{
EASTER_JULIAN   = 1
EASTER_ORTHODOX = 2
EASTER_WESTERN  = 3
}}}

The default method is method 3.

=== tz ===
This module offers timezone implementations subclassing
the abstract {{{datetime.tzinfo}}} type. There are
classes to handle [http://www.twinsun.com/tz/tz-link.htm tzfile]
format files (usually are in /etc/localtime,
/usr/share/zoneinfo, etc), TZ environment string (in all
known formats), given ranges (with help from relative
deltas), local machine timezone, fixed offset timezone,
and UTC timezone.

==== tzutc type ====
This type implements a basic UTC timezone. The constructor of this
type accepts no parameters.

==== tzutc examples ====
{{{
>>> from datetime import *
>>> from dateutil.tz import *

>>> datetime.now()
datetime.datetime(2003, 9, 27, 9, 40, 1, 521290)

>>> datetime.now(tzutc())
datetime.datetime(2003, 9, 27, 12, 40, 12, 156379, tzinfo=tzutc())

>>> datetime.now(tzutc()).tzname()
'UTC'
}}}

==== tzoffset type ====
This type implements a fixed offset timezone, with no
support to daylight saving times. Here is the prototype of the
type constructor:
{{{
tzoffset(name, offset)
}}}

The {{{name}}} parameter may be optionally set to {{{None}}}, and
{{{offset}}} must be given in seconds.

==== tzoffset examples ====
{{{
>>> from datetime import *
>>> from dateutil.tz import *

>>> datetime.now(tzoffset("BRST", -10800))
datetime.datetime(2003, 9, 27, 9, 52, 43, 624904,
		  tzinfo=tzinfo=tzoffset('BRST', -10800))

>>> datetime.now(tzoffset("BRST", -10800)).tzname()
'BRST'

>>> datetime.now(tzoffset("BRST", -10800)).astimezone(tzutc())
datetime.datetime(2003, 9, 27, 12, 53, 11, 446419,
		  tzinfo=tzutc())
}}}

==== tzlocal type ====
This type implements timezone settings as known by the
operating system. The constructor of this type accepts no
parameters.

==== tzlocal examples ====
{{{
>>> from datetime import *
>>> from dateutil.tz import *

>>> datetime.now(tzlocal())
datetime.datetime(2003, 9, 27, 10, 1, 43, 673605,
		  tzinfo=tzlocal())

>>> datetime.now(tzlocal()).tzname()
'BRST'

>>> datetime.now(tzlocal()).astimezone(tzoffset(None, 0))
datetime.datetime(2003, 9, 27, 13, 3, 0, 11493,
		  tzinfo=tzoffset(None, 0))
}}}

==== tzstr type ====
This type implements timezone settings extracted from a
string in known TZ environment variable formats. Here is the prototype
of the constructor:
{{{
tzstr(str)
}}}

==== tzstr examples ====
Here are examples of the recognized formats:

  * {{{EST5EDT}}}
  * {{{EST5EDT,4,0,6,7200,10,0,26,7200,3600}}}
  * {{{EST5EDT,4,1,0,7200,10,-1,0,7200,3600}}}
  * {{{EST5EDT4,M4.1.0/02:00:00,M10-5-0/02:00}}}
  * {{{EST5EDT4,95/02:00:00,298/02:00}}}
  * {{{EST5EDT4,J96/02:00:00,J299/02:00}}}

Notice that if daylight information is not present, but a
daylight abbreviation was provided, {{{tzstr}}} will follow the
convention of using the first sunday of April to start daylight
saving, and the last sunday of October to end it. If start or
end time is not present, 2AM will be used, and if the daylight
offset is not present, the standard offset plus one hour will
be used. This convention is the same as used in the GNU libc.

This also means that some of the above examples are exactly
equivalent, and all of these examples are equivalent
in the year of 2003.

Here is the example mentioned in the
[http://www.python.org/doc/current/lib/module-time.html time module documentation].
{{{
>>> os.environ['TZ'] = 'EST+05EDT,M4.1.0,M10.5.0'
>>> time.tzset()
>>> time.strftime('%X %x %Z')
'02:07:36 05/08/03 EDT'
>>> os.environ['TZ'] = 'AEST-10AEDT-11,M10.5.0,M3.5.0'
>>> time.tzset()
>>> time.strftime('%X %x %Z')
'16:08:12 05/08/03 AEST'
}}}

And here is an example showing the same information using {{{tzstr}}},
without touching system settings.
{{{
>>> tz1 = tzstr('EST+05EDT,M4.1.0,M10.5.0')
>>> tz2 = tzstr('AEST-10AEDT-11,M10.5.0,M3.5.0')
>>> dt = datetime(2003, 5, 8, 2, 7, 36, tzinfo=tz1)
>>> dt.strftime('%X %x %Z')
'02:07:36 05/08/03 EDT'
>>> dt.astimezone(tz2).strftime('%X %x %Z')
'16:07:36 05/08/03 AEST'
}}}

Are these really equivalent?
{{{
>>> tzstr('EST5EDT') == tzstr('EST5EDT,4,1,0,7200,10,-1,0,7200,3600')
True
}}}

Check the daylight limit.
{{{
>>> datetime(2003, 4, 6, 1, 59, tzinfo=tz).tzname()
'EST'
>>> datetime(2003, 4, 6, 2, 00, tzinfo=tz).tzname()
'EDT'
>>> datetime(2003, 10, 26, 0, 59, tzinfo=tz).tzname()
'EDT'
>>> datetime(2003, 10, 26, 1, 00, tzinfo=tz).tzname()
'EST'
}}}  

==== tzrange type ====
This type offers the same functionality as the {{{tzstr}}} type, but
instead of timezone strings, information is passed using
{{{relativedelta}}}s which are applied to a datetime set to the first
day of the year. Here is the prototype of this type's constructor:
{{{
tzrange(stdabbr, stdoffset=None, dstabbr=None, dstoffset=None,
	start=None, end=None):
}}}

Offsets must be given in seconds. Information not provided will be
set to the defaults, as explained in the {{{tzstr}}} section above.

==== tzrange examples ====
{{{
>>> tzstr('EST5EDT') == tzrange("EST", -18000, "EDT")
True

>>> from dateutil.relativedelta import *
>>> range1 = tzrange("EST", -18000, "EDT")
>>> range2 = tzrange("EST", -18000, "EDT", -14400,
...                  relativedelta(hours=+2, month=4, day=1,
				   weekday=SU(+1)),
...                  relativedelta(hours=+1, month=10, day=31,
				   weekday=SU(-1)))
>>> tzstr('EST5EDT') == range1 == range2
True
}}}

Notice a minor detail in the last example: while the DST should end
at 2AM, the delta will catch 1AM. That's because the daylight saving
time should end at 2AM standard time (the difference between STD and
DST is 1h in the given example) instead of the DST time. That's how
the {{{tzinfo}}} subtypes should deal with the extra hour that happens
when going back to the standard time. Check
[http://www.python.org/doc/current/lib/datetime-tzinfo.html tzinfo documentation]
for more information.

==== tzfile type ====
This type allows one to use tzfile(5) format timezone files to extract
current and historical zone information. Here is the type constructor
prototype:
{{{
tzfile(fileobj)
}}}

Where {{{fileobj}}} is either a filename or a file-like object with
a {{{read()}}} method.

==== tzfile examples ====
{{{
>>> tz = tzfile("/etc/localtime")
>>> datetime.now(tz)
datetime.datetime(2003, 9, 27, 12, 3, 48, 392138,
		  tzinfo=tzfile('/etc/localtime'))

>>> datetime.now(tz).astimezone(tzutc())
datetime.datetime(2003, 9, 27, 15, 3, 53, 70863,
		  tzinfo=tzutc())

>>> datetime.now(tz).tzname()
'BRST'
>>> datetime(2003, 1, 1, tzinfo=tz).tzname()
'BRDT'
}}}

Check the daylight limit.
{{{
>>> tz = tzfile('/usr/share/zoneinfo/EST5EDT')
>>> datetime(2003, 4, 6, 1, 59, tzinfo=tz).tzname()
'EST'
>>> datetime(2003, 4, 6, 2, 00, tzinfo=tz).tzname()
'EDT'
>>> datetime(2003, 10, 26, 0, 59, tzinfo=tz).tzname()
'EDT'
>>> datetime(2003, 10, 26, 1, 00, tzinfo=tz).tzname()
'EST'
}}}  

==== tzical type ====
This type is able to parse
[ftp://ftp.rfc-editor.org/in-notes/rfc2445.txt iCalendar]
style {{{VTIMEZONE}}} sessions into a Python timezone object.
The constuctor prototype is:
{{{
tzical(fileobj)
}}}

Where {{{fileobj}}} is either a filename or a file-like object with
a {{{read()}}} method.

==== tzical methods ====

    tzical.get(tzid=None)::
    Since a single iCalendar file may contain more than one timezone,
    you must ask for the timezone you want with this method. If there's
    more than one timezone in the parsed file, you'll need to pass the
    {{{tzid}}} parameter. Otherwise, leaving it empty will yield the only
    available timezone.

==== tzical examples ====
Here is a sample file extracted from the RFC. This file defines
the {{{EST5EDT}}} timezone, and will be used in the following example.
{{{
BEGIN:VTIMEZONE
TZID:US-Eastern
LAST-MODIFIED:19870101T000000Z
TZURL:http://zones.stds_r_us.net/tz/US-Eastern
BEGIN:STANDARD
DTSTART:19671029T020000
RRULE:FREQ=YEARLY;BYDAY=-1SU;BYMONTH=10
TZOFFSETFROM:-0400
TZOFFSETTO:-0500
TZNAME:EST
END:STANDARD
BEGIN:DAYLIGHT
DTSTART:19870405T020000
RRULE:FREQ=YEARLY;BYDAY=1SU;BYMONTH=4
TZOFFSETFROM:-0500
TZOFFSETTO:-0400
TZNAME:EDT
END:DAYLIGHT
END:VTIMEZONE
}}}

And here is an example exploring a {{{tzical}}} type:
{{{
>>> from dateutil.tz import *; from datetime import *

>>> tz = tzical('EST5EDT.ics')
>>> tz.keys()
['US-Eastern']

>>> est = tz.get('US-Eastern')
>>> est
<tzicalvtz 'US-Eastern'>

>>> datetime.now(est)
datetime.datetime(2003, 10, 6, 19, 44, 18, 667987,
		  tzinfo=<tzicalvtz 'US-Eastern'>)

>>> est == tz.get()
True
}}}

Let's check the daylight ranges, as usual:
{{{
>>> datetime(2003, 4, 6, 1, 59, tzinfo=est).tzname()
'EST'
>>> datetime(2003, 4, 6, 2, 00, tzinfo=est).tzname()
'EDT'

>>> datetime(2003, 10, 26, 0, 59, tzinfo=est).tzname()
'EDT'
>>> datetime(2003, 10, 26, 1, 00, tzinfo=est).tzname()
'EST'
}}}

==== tzwin type ====
This type offers access to internal registry-based Windows timezones.
The constuctor prototype is:
{{{
tzwin(name)
}}}

Where {{{name}}} is the timezone name. There's a static {{{tzwin.list()}}}
method to check the available names,

==== tzwin methods ====

    tzwin.display()::
    This method returns the timezone extended name.

    tzwin.list()::
    This static method lists all available timezone names.

==== tzwin examples ====
{{{
>>> tz = tzwin("E. South America Standard Time")
}}}

==== tzwinlocal type ====
This type offers access to internal registry-based Windows timezones.
The constructor accepts no parameters, so the prototype is:
{{{
tzwinlocal()
}}}

==== tzwinlocal methods ====

    tzwinlocal.display()::
    This method returns the timezone extended name, and returns
    {{{None}}} if one is not available.

==== tzwinlocal examples ====
{{{
>>> tz = tzwinlocal()
}}}

==== gettz() function ====
This function is a helper that will try its best to get the right
timezone for your environment, or for the given string. The prototype
is as follows:
{{{
gettz(name=None)
}}}

If given, the parameter may be a filename, a path relative to the base
of the timezone information path (the base could be
{{{/usr/share/zoneinfo}}}, for example), a string timezone
specification, or a timezone abbreviation. If {{{name}}} is not given,
and the {{{TZ}}} environment variable is set, it's used instead. If the
parameter is not given, and {{{TZ}}} is not set, the default tzfile
paths will be tried. Then, if no timezone information is found,
an internal compiled database of timezones is used. When running
on Windows, the internal registry-based Windows timezones are also
considered.

Example:
{{{
>>> from dateutil.tz import *
>>> gettz()
tzfile('/etc/localtime')

>>> gettz("America/Sao Paulo")
tzfile('/usr/share/zoneinfo/America/Sao_Paulo')

>>> gettz("EST5EDT")
tzfile('/usr/share/zoneinfo/EST5EDT')

>>> gettz("EST5")
tzstr('EST5')

>>> gettz('BRST')
tzlocal()

>>> os.environ["TZ"] = "America/Sao Paulo"
>>> gettz()
tzfile('/usr/share/zoneinfo/America/Sao_Paulo')

>>> os.environ["TZ"] = "BRST"
>>> gettz()
tzlocal()

>>> gettz("Unavailable")
>>> 
}}}

=== zoneinfo ===
This module provides direct access to the internal compiled
database of timezones. The timezone data and the compiling tools
are obtained from the following project:

  http://www.twinsun.com/tz/tz-link.htm

==== gettz() function ====
This function will try to retrieve the given timezone information
from the internal compiled database, and will cache its results.

Example:
{{{
>>> from dateutil import zoneinfo
>>> zoneinfo.gettz("Brazil/East")
tzfile('Brazil/East')
}}}

## vim:ft=moin

The list of files here isn't complete.  For a step-by-step guide on
how to set this package up correctly, check out
    http://www.debian.org/doc/maint-guide/

Most of the files that are in this directory are boilerplate.
However, you may need to change the list of binary-arch dependencies
in 'rules'.

This repository contains a python implementation of the Google commandline
flags module.

 GFlags defines a *distributed* command line system, replacing systems like
 getopt(), optparse and manual argument processing. Rather than an application
 having to define all flags in or near main(), each python module defines flags
 that are useful to it.  When one python module imports another, it gains
 access to the other's flags.

 It includes the ability to define flag types (boolean, float, interger, list),
 autogeneration of help (in both human and machine readable format) and reading
 arguments from a file. It also includes the ability to automatically generate
 man pages from the help flags.

Documentation for implementation is at the top of gflags.py file.

To install the python module, run
   python ./setup.py install

When you install this library, you also get a helper application,
gflags2man.py, installed into /usr/local/bin.  You can run gflags2man.py to
create an instant man page, with all the commandline flags and their docs, for
any C++ or python program you've written using the gflags library.

This software is a 100% Python interface to the memcached memory cache
daemon.  It is the client side software which allows storing values in one
or more, possibly remote, memcached servers.  Search google for memcached
for more information.

This package was originally written by Evan Martin of Danga.
Please do not contact Evan about maintenance.
Sean Reifschneider of tummy.com, ltd. has taken over maintenance of it.

pytz - World Timezone Definitions for Python
============================================

:Author: Stuart Bishop <stuart@stuartbishop.net>

Introduction
~~~~~~~~~~~~

pytz brings the Olson tz database into Python. This library allows
accurate and cross platform timezone calculations using Python 2.4
or higher. It also solves the issue of ambiguous times at the end
of daylight savings, which you can read more about in the Python
Library Reference (``datetime.tzinfo``).

Almost all of the Olson timezones are supported.

Note that this library differs from the documented Python API for
tzinfo implementations; if you want to create local wallclock
times you need to use the ``localize()`` method documented in this
document. In addition, if you perform date arithmetic on local
times that cross DST boundaries, the result may be in an incorrect
timezone (ie. subtract 1 minute from 2002-10-27 1:00 EST and you get
2002-10-27 0:59 EST instead of the correct 2002-10-27 1:59 EDT). A
``normalize()`` method is provided to correct this. Unfortunately these
issues cannot be resolved without modifying the Python datetime
implementation.


Installation
~~~~~~~~~~~~

This package can either be installed from a .egg file using setuptools,
or from the tarball using the standard Python distutils.

If you are installing from a tarball, run the following command as an
administrative user::

    python setup.py install

If you are installing using setuptools, you don't even need to download
anything as the latest version will be downloaded for you
from the Python package index::

    easy_install --upgrade pytz

If you already have the .egg file, you can use that too::

    easy_install pytz-2008g-py2.6.egg


Example & Usage
~~~~~~~~~~~~~~~

Localized times and date arithmetic
-----------------------------------

>>> from datetime import datetime, timedelta
>>> from pytz import timezone
>>> import pytz
>>> utc = pytz.utc
>>> utc.zone
'UTC'
>>> eastern = timezone('US/Eastern')
>>> eastern.zone
'US/Eastern'
>>> amsterdam = timezone('Europe/Amsterdam')
>>> fmt = '%Y-%m-%d %H:%M:%S %Z%z'

This library only supports two ways of building a localized time. The
first is to use the ``localize()`` method provided by the pytz library.
This is used to localize a naive datetime (datetime with no timezone
information):

>>> loc_dt = eastern.localize(datetime(2002, 10, 27, 6, 0, 0))
>>> print(loc_dt.strftime(fmt))
2002-10-27 06:00:00 EST-0500

The second way of building a localized time is by converting an existing
localized time using the standard ``astimezone()`` method:

>>> ams_dt = loc_dt.astimezone(amsterdam)
>>> ams_dt.strftime(fmt)
'2002-10-27 12:00:00 CET+0100'

Unfortunately using the tzinfo argument of the standard datetime
constructors ''does not work'' with pytz for many timezones.

>>> datetime(2002, 10, 27, 12, 0, 0, tzinfo=amsterdam).strftime(fmt)
'2002-10-27 12:00:00 AMT+0020'

It is safe for timezones without daylight savings trasitions though, such
as UTC:

>>> datetime(2002, 10, 27, 12, 0, 0, tzinfo=pytz.utc).strftime(fmt)
'2002-10-27 12:00:00 UTC+0000'

The preferred way of dealing with times is to always work in UTC,
converting to localtime only when generating output to be read
by humans.

>>> utc_dt = datetime(2002, 10, 27, 6, 0, 0, tzinfo=utc)
>>> loc_dt = utc_dt.astimezone(eastern)
>>> loc_dt.strftime(fmt)
'2002-10-27 01:00:00 EST-0500'

This library also allows you to do date arithmetic using local
times, although it is more complicated than working in UTC as you
need to use the ``normalize()`` method to handle daylight savings time
and other timezone transitions. In this example, ``loc_dt`` is set
to the instant when daylight savings time ends in the US/Eastern
timezone.

>>> before = loc_dt - timedelta(minutes=10)
>>> before.strftime(fmt)
'2002-10-27 00:50:00 EST-0500'
>>> eastern.normalize(before).strftime(fmt)
'2002-10-27 01:50:00 EDT-0400'
>>> after = eastern.normalize(before + timedelta(minutes=20))
>>> after.strftime(fmt)
'2002-10-27 01:10:00 EST-0500'

Creating local times is also tricky, and the reason why working with
local times is not recommended. Unfortunately, you cannot just pass
a ``tzinfo`` argument when constructing a datetime (see the next
section for more details)

>>> dt = datetime(2002, 10, 27, 1, 30, 0)
>>> dt1 = eastern.localize(dt, is_dst=True)
>>> dt1.strftime(fmt)
'2002-10-27 01:30:00 EDT-0400'
>>> dt2 = eastern.localize(dt, is_dst=False)
>>> dt2.strftime(fmt)
'2002-10-27 01:30:00 EST-0500'

Converting between timezones also needs special attention. We also need
to use the ``normalize()`` method to ensure the conversion is correct.

>>> utc_dt = utc.localize(datetime.utcfromtimestamp(1143408899))
>>> utc_dt.strftime(fmt)
'2006-03-26 21:34:59 UTC+0000'
>>> au_tz = timezone('Australia/Sydney')
>>> au_dt = au_tz.normalize(utc_dt.astimezone(au_tz))
>>> au_dt.strftime(fmt)
'2006-03-27 08:34:59 EST+1100'
>>> utc_dt2 = utc.normalize(au_dt.astimezone(utc))
>>> utc_dt2.strftime(fmt)
'2006-03-26 21:34:59 UTC+0000'

You can take shortcuts when dealing with the UTC side of timezone
conversions. ``normalize()`` and ``localize()`` are not really
necessary when there are no daylight savings time transitions to
deal with.

>>> utc_dt = datetime.utcfromtimestamp(1143408899).replace(tzinfo=utc)
>>> utc_dt.strftime(fmt)
'2006-03-26 21:34:59 UTC+0000'
>>> au_tz = timezone('Australia/Sydney')
>>> au_dt = au_tz.normalize(utc_dt.astimezone(au_tz))
>>> au_dt.strftime(fmt)
'2006-03-27 08:34:59 EST+1100'
>>> utc_dt2 = au_dt.astimezone(utc)
>>> utc_dt2.strftime(fmt)
'2006-03-26 21:34:59 UTC+0000'


``tzinfo`` API
--------------

The ``tzinfo`` instances returned by the ``timezone()`` function have
been extended to cope with ambiguous times by adding an ``is_dst``
parameter to the ``utcoffset()``, ``dst()`` && ``tzname()`` methods.

>>> tz = timezone('America/St_Johns')

>>> normal = datetime(2009, 9, 1)
>>> ambiguous = datetime(2009, 10, 31, 23, 30)

The ``is_dst`` parameter is ignored for most timestamps. It is only used
during DST transition ambiguous periods to resulve that ambiguity.

>>> tz.utcoffset(normal, is_dst=True)
datetime.timedelta(-1, 77400)
>>> tz.dst(normal, is_dst=True)
datetime.timedelta(0, 3600)
>>> tz.tzname(normal, is_dst=True)
'NDT'

>>> tz.utcoffset(ambiguous, is_dst=True)
datetime.timedelta(-1, 77400)
>>> tz.dst(ambiguous, is_dst=True)
datetime.timedelta(0, 3600)
>>> tz.tzname(ambiguous, is_dst=True)
'NDT'

>>> tz.utcoffset(normal, is_dst=False)
datetime.timedelta(-1, 77400)
>>> tz.dst(normal, is_dst=False)
datetime.timedelta(0, 3600)
>>> tz.tzname(normal, is_dst=False)
'NDT'

>>> tz.utcoffset(ambiguous, is_dst=False)
datetime.timedelta(-1, 73800)
>>> tz.dst(ambiguous, is_dst=False)
datetime.timedelta(0)
>>> tz.tzname(ambiguous, is_dst=False)
'NST'

If ``is_dst`` is not specified, ambiguous timestamps will raise
an ``pytz.exceptions.AmbiguousTimeError`` exception.

>>> tz.utcoffset(normal)
datetime.timedelta(-1, 77400)
>>> tz.dst(normal)
datetime.timedelta(0, 3600)
>>> tz.tzname(normal)
'NDT'

>>> import pytz.exceptions
>>> try:
...     tz.utcoffset(ambiguous)
... except pytz.exceptions.AmbiguousTimeError:
...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)
pytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00
>>> try:
...     tz.dst(ambiguous)
... except pytz.exceptions.AmbiguousTimeError:
...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)
pytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00
>>> try:
...     tz.tzname(ambiguous)
... except pytz.exceptions.AmbiguousTimeError:
...     print('pytz.exceptions.AmbiguousTimeError: %s' % ambiguous)
pytz.exceptions.AmbiguousTimeError: 2009-10-31 23:30:00


Problems with Localtime
~~~~~~~~~~~~~~~~~~~~~~~

The major problem we have to deal with is that certain datetimes
may occur twice in a year. For example, in the US/Eastern timezone
on the last Sunday morning in October, the following sequence
happens:

    - 01:00 EDT occurs
    - 1 hour later, instead of 2:00am the clock is turned back 1 hour
      and 01:00 happens again (this time 01:00 EST)

In fact, every instant between 01:00 and 02:00 occurs twice. This means
that if you try and create a time in the 'US/Eastern' timezone using
the standard datetime syntax, there is no way to specify if you meant
before of after the end-of-daylight-savings-time transition.

>>> loc_dt = datetime(2002, 10, 27, 1, 30, 00, tzinfo=eastern)
>>> loc_dt.strftime(fmt)
'2002-10-27 01:30:00 EST-0500'

As you can see, the system has chosen one for you and there is a 50%
chance of it being out by one hour. For some applications, this does
not matter. However, if you are trying to schedule meetings with people
in different timezones or analyze log files it is not acceptable. 

The best and simplest solution is to stick with using UTC.  The pytz
package encourages using UTC for internal timezone representation by
including a special UTC implementation based on the standard Python
reference implementation in the Python documentation.

The UTC timezone unpickles to be the same instance, and pickles to a
smaller size than other pytz tzinfo instances.  The UTC implementation
can be obtained as pytz.utc, pytz.UTC, or pytz.timezone('UTC').

>>> import pickle, pytz
>>> dt = datetime(2005, 3, 1, 14, 13, 21, tzinfo=utc)
>>> naive = dt.replace(tzinfo=None)
>>> p = pickle.dumps(dt, 1)
>>> naive_p = pickle.dumps(naive, 1)
>>> len(p) - len(naive_p)
17
>>> new = pickle.loads(p)
>>> new == dt
True
>>> new is dt
False
>>> new.tzinfo is dt.tzinfo
True
>>> pytz.utc is pytz.UTC is pytz.timezone('UTC')
True

Note that this instance is not the same instance (or implementation) as
other timezones with the same meaning (GMT, Greenwich, Universal, etc.).

>>> utc is pytz.timezone('GMT')
False

If you insist on working with local times, this library provides a
facility for constructing them unambiguously:

>>> loc_dt = datetime(2002, 10, 27, 1, 30, 00)
>>> est_dt = eastern.localize(loc_dt, is_dst=True)
>>> edt_dt = eastern.localize(loc_dt, is_dst=False)
>>> print(est_dt.strftime(fmt) + ' / ' + edt_dt.strftime(fmt))
2002-10-27 01:30:00 EDT-0400 / 2002-10-27 01:30:00 EST-0500

If you pass None as the is_dst flag to localize(), pytz will refuse to
guess and raise exceptions if you try to build ambiguous or non-existent
times.

For example, 1:30am on 27th Oct 2002 happened twice in the US/Eastern
timezone when the clocks where put back at the end of Daylight Savings
Time:

>>> dt = datetime(2002, 10, 27, 1, 30, 00)
>>> try:
...     eastern.localize(dt, is_dst=None)
... except pytz.exceptions.AmbiguousTimeError:
...     print('pytz.exceptions.AmbiguousTimeError: %s' % dt)
pytz.exceptions.AmbiguousTimeError: 2002-10-27 01:30:00

Similarly, 2:30am on 7th April 2002 never happened at all in the
US/Eastern timezone, as the clocks where put forward at 2:00am skipping
the entire hour:

>>> dt = datetime(2002, 4, 7, 2, 30, 00)
>>> try:
...     eastern.localize(dt, is_dst=None)
... except pytz.exceptions.NonExistentTimeError:
...     print('pytz.exceptions.NonExistentTimeError: %s' % dt)
pytz.exceptions.NonExistentTimeError: 2002-04-07 02:30:00

Both of these exceptions share a common base class to make error handling
easier:

>>> isinstance(pytz.AmbiguousTimeError(), pytz.InvalidTimeError)
True
>>> isinstance(pytz.NonExistentTimeError(), pytz.InvalidTimeError)
True

Although ``localize()`` handles many cases, it is still not possible
to handle all. In cases where countries change their timezone definitions,
cases like the end-of-daylight-savings-time occur with no way of resolving
the ambiguity. For example, in 1915 Warsaw switched from Warsaw time to
Central European time. So at the stroke of midnight on August 5th 1915
the clocks were wound back 24 minutes creating an ambiguous time period
that cannot be specified without referring to the timezone abbreviation
or the actual UTC offset. In this case midnight happened twice, neither
time during a daylight savings time period:

>>> warsaw = pytz.timezone('Europe/Warsaw')
>>> loc_dt1 = warsaw.localize(datetime(1915, 8, 4, 23, 59, 59), is_dst=False)
>>> loc_dt1.strftime(fmt)
'1915-08-04 23:59:59 WMT+0124'
>>> loc_dt2 = warsaw.localize(datetime(1915, 8, 5, 00, 00, 00), is_dst=False)
>>> loc_dt2.strftime(fmt)
'1915-08-05 00:00:00 CET+0100'
>>> str(loc_dt2 - loc_dt1)
'0:24:01'

The only way of creating a time during the missing 24 minutes is
converting from another timezone - because neither of the timezones
involved where in daylight savings mode the API simply provides no way
to express it:

>>> utc_dt = datetime(1915, 8, 4, 22, 36, tzinfo=pytz.utc)
>>> utc_dt.astimezone(warsaw).strftime(fmt)
'1915-08-04 23:36:00 CET+0100'

The standard Python way of handling all these ambiguities is not to
handle them, such as demonstrated in this example using the US/Eastern
timezone definition from the Python documentation (Note that this
implementation only works for dates between 1987 and 2006 - it is
included for tests only!):

>>> from pytz.reference import Eastern # pytz.reference only for tests
>>> dt = datetime(2002, 10, 27, 0, 30, tzinfo=Eastern)
>>> str(dt)
'2002-10-27 00:30:00-04:00'
>>> str(dt + timedelta(hours=1))
'2002-10-27 01:30:00-05:00'
>>> str(dt + timedelta(hours=2))
'2002-10-27 02:30:00-05:00'
>>> str(dt + timedelta(hours=3))
'2002-10-27 03:30:00-05:00'

Notice the first two results? At first glance you might think they are
correct, but taking the UTC offset into account you find that they are
actually two hours appart instead of the 1 hour we asked for.

>>> from pytz.reference import UTC # pytz.reference only for tests
>>> str(dt.astimezone(UTC))
'2002-10-27 04:30:00+00:00'
>>> str((dt + timedelta(hours=1)).astimezone(UTC))
'2002-10-27 06:30:00+00:00'


Country Information
~~~~~~~~~~~~~~~~~~~

A mechanism is provided to access the timezones commonly in use
for a particular country, looked up using the ISO 3166 country code.
It returns a list of strings that can be used to retrieve the relevant
tzinfo instance using ``pytz.timezone()``:

>>> print(' '.join(pytz.country_timezones['nz']))
Pacific/Auckland Pacific/Chatham

The Olson database comes with a ISO 3166 country code to English country
name mapping that pytz exposes as a dictionary:

>>> print(pytz.country_names['nz'])
New Zealand


What is UTC
~~~~~~~~~~~

'UTC' is Universal Time, also known as Greenwich Mean Time or GMT
in the United Kingdom. All other timezones are given as offsets from
UTC. No daylight savings time occurs in UTC, making it a useful timezone
to perform date arithmetic without worrying about the confusion and
ambiguities caused by daylight savings time transitions, your country
changing its timezone, or mobile computers that move roam through
multiple timezones.


Helpers
~~~~~~~

There are two lists of timezones provided.

``all_timezones`` is the exhaustive list of the timezone names that can
be used.

>>> from pytz import all_timezones
>>> len(all_timezones) >= 500
True
>>> 'Etc/Greenwich' in all_timezones
True

``common_timezones`` is a list of useful, current timezones. It doesn't
contain deprecated zones or historical zones, except for a few I've
deemed in common usage, such as US/Eastern (open a bug report if you
think other timezones are deserving of being included here). It is also
a sequence of strings.

>>> from pytz import common_timezones
>>> len(common_timezones) < len(all_timezones)
True
>>> 'Etc/Greenwich' in common_timezones
False
>>> 'Australia/Melbourne' in common_timezones
True
>>> 'US/Eastern' in common_timezones
True
>>> 'Canada/Eastern' in common_timezones
True
>>> 'US/Pacific-New' in all_timezones
True
>>> 'US/Pacific-New' in common_timezones
False

Both ``common_timezones`` and ``all_timezones`` are alphabetically
sorted:

>>> common_timezones_dupe = common_timezones[:]
>>> common_timezones_dupe.sort()
>>> common_timezones == common_timezones_dupe
True
>>> all_timezones_dupe = all_timezones[:]
>>> all_timezones_dupe.sort()
>>> all_timezones == all_timezones_dupe
True

``all_timezones`` and ``common_timezones`` are also available as sets.

>>> from pytz import all_timezones_set, common_timezones_set
>>> 'US/Eastern' in all_timezones_set
True
>>> 'US/Eastern' in common_timezones_set
True
>>> 'Australia/Victoria' in common_timezones_set
False

You can also retrieve lists of timezones used by particular countries
using the ``country_timezones()`` function. It requires an ISO-3166
two letter country code.

>>> from pytz import country_timezones
>>> print(' '.join(country_timezones('ch')))
Europe/Zurich
>>> print(' '.join(country_timezones('CH')))
Europe/Zurich


License
~~~~~~~

MIT license.

This code is also available as part of Zope 3 under the Zope Public
License,  Version 2.1 (ZPL).

I'm happy to relicense this code if necessary for inclusion in other
open source projects.


Latest Versions
~~~~~~~~~~~~~~~

This package will be updated after releases of the Olson timezone
database.  The latest version can be downloaded from the `Python Package
Index <http://pypi.python.org/pypi/pytz/>`_.  The code that is used
to generate this distribution is hosted on launchpad.net and available
using the `Bazaar version control system <http://bazaar-vcs.org>`_
using::

    bzr branch lp:pytz


Bugs, Feature Requests & Patches
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Bugs can be reported using `Launchpad <https://bugs.launchpad.net/pytz>`_.


Issues & Limitations
~~~~~~~~~~~~~~~~~~~~

- Offsets from UTC are rounded to the nearest whole minute, so timezones
  such as Europe/Amsterdam pre 1937 will be up to 30 seconds out. This
  is a limitation of the Python datetime library.

- If you think a timezone definition is incorrect, I probably can't fix
  it. pytz is a direct translation of the Olson timezone database, and
  changes to the timezone definitions need to be made to this source.
  If you find errors they should be reported to the time zone mailing
  list, linked from http://www.twinsun.com/tz/tz-link.htm


Further Reading
~~~~~~~~~~~~~~~

More info than you want to know about timezones:
http://www.twinsun.com/tz/tz-link.htm


Contact
~~~~~~~

Stuart Bishop <stuart@stuartbishop.net>



======================
Selenium Client Driver
======================

Introduction
============

Python language bindings for Selenium WebDriver.

The `selenium` package is used automate web browser interaction from Python.

+-----------+-----------------------------------------------------------------------------------+
| **Home**: | http://www.seleniumhq.org                                                         |
+-----------+-----------------------------------------------------------------------------------+
| **Docs**: | `selenium package API <http://selenium.googlecode.com/git/docs/api/py/api.html>`_ |
+-----------+-----------------------------------------------------------------------------------+
| **Dev**:  | https://code.google.com/p/selenium/                                               |
+-----------+-----------------------------------------------------------------------------------+
| **PyPI**: | https://pypi.python.org/pypi/selenium                                             |
+-----------+-----------------------------------------------------------------------------------+
| **IRC**:  | **#selenium** channel on freenode                                                 |
+-----------+-----------------------------------------------------------------------------------+

Several browsers/drivers are supported (Firefox, Chrome, Internet Explorer, PhantomJS), as well as the Remote protocol.

Supported Python Versions
=========================

* Python 2.6, 2.7
* Python 3.2, 3.3

Installing
==========

If you have `pip <http://www.pip-installer.org>`_ on your system, you can simply install or upgrade the Python bindings::

    pip install -U selenium

Alternately, you can download the source distribution from `PyPI <http://pypi.python.org/pypi/selenium>`_ (e.g. selenium-2.41.tar.gz), unarchive it, and run::

    python setup.py install

Note: both of the methods described above install `selenium` as a system-wide package  That will require administrative/root access to ther machine.  You may consider using a `virtualenv <http://www.virtualenv.org/>`_ to create isolated Python environments instead.

Example 0:
==========

* open a new Firefox browser
* load the page at the given URL

::

    from selenium import webdriver

    browser = webdriver.Firefox()
    browser.get('http://seleniumhq.org/')

Example 1:
==========

* open a new Firefox browser
* load the Yahoo homepage
* search for "seleniumhq"
* close the browser

::

    from selenium import webdriver
    from selenium.webdriver.common.keys import Keys

    browser = webdriver.Firefox()

    browser.get('http://www.yahoo.com')
    assert 'Yahoo!' in browser.title

    elem = browser.find_element_by_name('p')  # Find the search box
    elem.send_keys('seleniumhq' + Keys.RETURN)

    browser.quit()

Example 2:
==========

Selenium WebDriver is often used as a basis for testing web applications.  Here is a simple example uisng Python's standard `unittest <http://docs.python.org/3/library/unittest.html>`_ library:

::

    import unittest

    class GoogleTestCase(unittest.TestCase):

        def setUp(self):
            self.browser = webdriver.Firefox()
            self.addCleanup(self.browser.quit)

        def testPageTitle(self):
            self.browser.get('http://www.google.com')
            self.assertIn('Google', self.browser.title)

    if __name__ == '__main__':
        unittest.main(verbosity=2)

Selenium Server (optional)
==========================

For normal WebDriver scripts (non-Remote), the Java server is not needed.

However, to use Selenium Webdriver Remote or the legacy Selenium API (Selenium-RC), you need to also run the Selenium server.  The server requires a Java Runtime Environment (JRE).

Download the server separately, from: http://selenium-release.storage.googleapis.com/2.41/selenium-server-standalone-2.41.0.jar

Run the server from the command line::

    java -jar selenium-server-standalone-2.41.0.jar

Then run your Python client scripts.

Use The Source Luke!
====================

View source code online:

+-----------+-------------------------------------------------------+
| official: | https://code.google.com/p/selenium/source/browse/py   |
+-----------+-------------------------------------------------------+
| mirror:   | https://github.com/SeleniumHQ/selenium/tree/master/py |
+-----------+-------------------------------------------------------+

===============================
Installing and Using Setuptools
===============================

.. contents:: **Table of Contents**


-------------------------
Installation Instructions
-------------------------

Windows
=======

Install setuptools using the provided ``.exe`` installer.  If you've previously
installed older versions of setuptools, please delete all ``setuptools*.egg``
and ``setuptools.pth`` files from your system's ``site-packages`` directory
(and any other ``sys.path`` directories) FIRST.

If you are upgrading a previous version of setuptools that was installed using
an ``.exe`` installer, please be sure to also *uninstall that older version*
via your system's "Add/Remove Programs" feature, BEFORE installing the newer
version.

Once installation is complete, you will find an ``easy_install.exe`` program in
your Python ``Scripts`` subdirectory.  Be sure to add this directory to your
``PATH`` environment variable, if you haven't already done so.


RPM-Based Systems
=================

Install setuptools using the provided source RPM.  The included ``.spec`` file
assumes you are installing using the default ``python`` executable, and is not
specific to a particular Python version.  The ``easy_install`` executable will
be installed to a system ``bin`` directory such as ``/usr/bin``.

If you wish to install to a location other than the default Python
installation's default ``site-packages`` directory (and ``$prefix/bin`` for
scripts), please use the ``.egg``-based installation approach described in the
following section.


Cygwin, Mac OS X, Linux, Other
==============================

1. Download the appropriate egg for your version of Python (e.g.
   ``setuptools-0.6c9-py2.4.egg``).  Do NOT rename it.

2. Run it as if it were a shell script, e.g. ``sh setuptools-0.6c9-py2.4.egg``.
   Setuptools will install itself using the matching version of Python (e.g.
   ``python2.4``), and will place the ``easy_install`` executable in the
   default location for installing Python scripts (as determined by the
   standard distutils configuration files, or by the Python installation).

If you want to install setuptools to somewhere other than ``site-packages`` or
your default distutils installation locations for libraries and scripts, you
may include EasyInstall command-line options such as ``--prefix``,
``--install-dir``, and so on, following the ``.egg`` filename on the same
command line.  For example::

    sh setuptools-0.6c9-py2.4.egg --prefix=~

You can use ``--help`` to get a full options list, but we recommend consulting
the `EasyInstall manual`_ for detailed instructions, especially `the section
on custom installation locations`_.

.. _EasyInstall manual: http://peak.telecommunity.com/DevCenter/EasyInstall
.. _the section on custom installation locations: http://peak.telecommunity.com/DevCenter/EasyInstall#custom-installation-locations


Cygwin Note
-----------

If you are trying to install setuptools for the **Windows** version of Python
(as opposed to the Cygwin version that lives in ``/usr/bin``), you must make
sure that an appropriate executable (``python2.3``, ``python2.4``, or
``python2.5``) is on your **Cygwin** ``PATH`` when invoking the egg.  For
example, doing the following at a Cygwin bash prompt will install setuptools
for the **Windows** Python found at ``C:\\Python24``::

    ln -s /cygdrive/c/Python24/python.exe python2.4
    PATH=.:$PATH sh setuptools-0.6c9-py2.4.egg
    rm python2.4


Downloads
=========

All setuptools downloads can be found at `the project's home page in the Python
Package Index`_.  Scroll to the very bottom of the page to find the links.

.. _the project's home page in the Python Package Index: http://pypi.python.org/pypi/setuptools#files

In addition to the PyPI downloads, the development version of ``setuptools``   
is available from the `Python SVN sandbox`_, and in-development versions of the 
`0.6 branch`_ are available as well.

.. _0.6 branch: http://svn.python.org/projects/sandbox/branches/setuptools-0.6/#egg=setuptools-dev06

.. _Python SVN sandbox: http://svn.python.org/projects/sandbox/trunk/setuptools/#egg=setuptools-dev

--------------------------------
Using Setuptools and EasyInstall
--------------------------------

Here are some of the available manuals, tutorials, and other resources for
learning about Setuptools, Python Eggs, and EasyInstall:

* `The EasyInstall user's guide and reference manual`_
* `The setuptools Developer's Guide`_
* `The pkg_resources API reference`_
* `Package Compatibility Notes`_ (user-maintained)
* `The Internal Structure of Python Eggs`_

Questions, comments, and bug reports should be directed to the `distutils-sig
mailing list`_.  If you have written (or know of) any tutorials, documentation,
plug-ins, or other resources for setuptools users, please let us know about
them there, so this reference list can be updated.  If you have working,
*tested* patches to correct problems or add features, you may submit them to
the `setuptools bug tracker`_.

.. _setuptools bug tracker: http://bugs.python.org/setuptools/
.. _Package Compatibility Notes: http://peak.telecommunity.com/DevCenter/PackageNotes
.. _The Internal Structure of Python Eggs: http://peak.telecommunity.com/DevCenter/EggFormats
.. _The setuptools Developer's Guide: http://peak.telecommunity.com/DevCenter/setuptools
.. _The pkg_resources API reference: http://peak.telecommunity.com/DevCenter/PkgResources
.. _The EasyInstall user's guide and reference manual: http://peak.telecommunity.com/DevCenter/EasyInstall
.. _distutils-sig mailing list: http://mail.python.org/pipermail/distutils-sig/


-------
Credits
-------

* The original design for the ``.egg`` format and the ``pkg_resources`` API was
  co-created by Phillip Eby and Bob Ippolito.  Bob also implemented the first
  version of ``pkg_resources``, and supplied the OS X operating system version
  compatibility algorithm.

* Ian Bicking implemented many early "creature comfort" features of
  easy_install, including support for downloading via Sourceforge and
  Subversion repositories.  Ian's comments on the Web-SIG about WSGI
  application deployment also inspired the concept of "entry points" in eggs,
  and he has given talks at PyCon and elsewhere to inform and educate the
  community about eggs and setuptools.

* Jim Fulton contributed time and effort to build automated tests of various
  aspects of ``easy_install``, and supplied the doctests for the command-line
  ``.exe`` wrappers on Windows.

* Phillip J. Eby is the principal author and maintainer of setuptools, and
  first proposed the idea of an importable binary distribution format for
  Python application plug-ins.

* Significant parts of the implementation of setuptools were funded by the Open
  Source Applications Foundation, to provide a plug-in infrastructure for the
  Chandler PIM application.  In addition, many OSAF staffers (such as Mike
  "Code Bear" Taylor) contributed their time and stress as guinea pigs for the
  use of eggs and setuptools, even before eggs were "cool".  (Thanks, guys!)

.. _files:

simplejson is a simple, fast, complete, correct and extensible
JSON <http://json.org> encoder and decoder for Python 2.5+
and Python 3.3+.  It is pure Python code with no dependencies,
but includes an optional C extension for a serious speed boost.

The latest documentation for simplejson can be read online here:
http://simplejson.readthedocs.org/

simplejson is the externally maintained development version of the
json library included with Python 2.6 and Python 3.0, but maintains
backwards compatibility with Python 2.5.

The encoder may be subclassed to provide serialization in any kind of
situation, without any special support by the objects to be serialized
(somewhat like pickle).

The decoder can handle incoming JSON strings of any specified encoding
(UTF-8 by default).


Six is a Python 2 and 3 compatibility library.  It provides utility functions
for smoothing over the differences between the Python versions with the goal of
writing Python code that is compatible on both Python versions.  See the
documentation for more information on what is provided.

Six supports every Python version since 2.4.  It is contained in only one Python
file, so it can be easily copied into your project. (The copyright and license
notice must be retained.)

Online documentation is at http://pythonhosted.org/six/.

Bugs can be reported to http://bitbucket.org/gutworth/six.  The code can also be
found there.

For questions about six or porting in general, email the python-porting mailing
list: http://mail.python.org/mailman/listinfo/python-porting

This is South, a Django application to provide schema and data migrations.

Documentation on South is currently available on our project site;
you can find it at http://south.aeracode.org/docs/

South is compatable with Django 1.2 and higher, and Python 2.6 and higher.

SQLAlchemy
++++++++++

The Python SQL Toolkit and Object Relational Mapper

Requirements
------------

SQLAlchemy requires Python 2.4 or higher.  One or more DB-API implementations
are also required for database access.  See docs/intro.html for more
information on supported DB-API implementations.

Python 3 Compatibility
----------------------

Please see README.py3k for Python 3 installation and testing instructions.

Installation Tools
------------------

Installation is supported with standard Python distutils, as well
as with setuptools or Distribute.  Distribute is recommended.
Distribute can be installed using the provided "distribute_setup.py" 
script.  The original setuptools may be installed using the 
"ez_setup.py" script if preferred, or simply do nothing and distutils
will be used.

Installing
----------

To install::

  python setup.py install

To use without installation, include the ``lib`` directory in your Python
path.

Installing the C extension
--------------------------

If installing with Setuptools or Distribute, the C extensions are built 
and installed using the --with-cextensions flag:

  python setup.py --with-cextensions install

If using plain Distutils, change the BUILD_CEXTENSIONS flag in setup.py
to "True".

Running Tests
-------------

Please see README.unittests for full instructions on running unit tests.

Package Contents
----------------

  doc/
     HTML documentation, including tutorials and API reference.  Point
     a browser to the "index.html" to start.

  examples/
     Fully commented and executable implementations for a variety of tasks.

  lib/
     SQLAlchemy.

  test/
     Unit tests for SQLAlchemy.

Help
----

Mailing lists, wiki, and more are available on-line at
http://www.sqlalchemy.org.

License
-------

SQLAlchemy is distributed under the `MIT license
<http://www.opensource.org/licenses/mit-license.php>`_.


=================
PYTHON 3 SUPPORT
=================

Current Python 3k support in SQLAlchemy is provided by a customized
2to3 script which wraps Python's 2to3 tool.

Installing Distribute
---------------------

Distribute should be installed with the Python3 installation.  The
distribute bootloader is included.

Running as a user with permission to modify the Python distribution,
install Distribute:

    python3 distribute_setup.py
    

Installing SQLAlchemy in Python 3
---------------------------------

Once Distribute is installed, SQLAlchemy can be installed directly.  
The 2to3 process will kick in which takes several minutes:

    python3 setup.py install

Converting Tests, Examples, Source to Python 3
----------------------------------------------

To convert all files in the source distribution, run 
SQLAlchemys "sa2to3.py" script, which monkeypatches a preprocessor
onto the 2to3 tool:

    python3 sa2to3.py --no-diffs -w lib test examples

The above will rewrite all files in-place in Python 3 format.

Running Tests
-------------

To run the unit tests, ensure Distribute is installed as above,
and also that at least the ./lib/ and ./test/ directories have been converted
to Python 3 using the source tool above.   A Python 3 version of Nose
can be acquired from Bitbucket using Mercurial:

    hg clone http://bitbucket.org/jpellerin/nose3/
    cd nose3
    python3 setup.py install

The tests can then be run using the "nosetests3" script installed by the above,
using the same instructions in README.unittests.

Current 3k Issues
-----------------

Current bugs and tickets related to Py3k are on the Py3k milestone in trac:

http://www.sqlalchemy.org/trac/query?status=new&status=assigned&status=reopened&milestone=py3k


=====================
SQLALCHEMY UNIT TESTS
=====================

SQLAlchemy unit tests by default run using Python's built-in sqlite3 
module.  If running on Python 2.4, pysqlite must be installed.

Unit tests are run using nose.  Note that in most cases,
nose needs to be installed manually.  Documentation and
downloads for nose are available at:

http://somethingaboutorange.com/mrl/projects/nose/0.11.1/index.html

Or using setuptools:

    $ easy_install nose

SQLAlchemy implements a nose plugin that must be present when tests are run.
This plugin is available when SQLAlchemy is installed via setuptools.

INSTANT TEST RUNNER
-------------------

A plain vanilla run of all tests using sqlite can be run via setup.py:

    $ python setup.py test
    
(NOTE: this command is broken for Python 2.7 with nose 0.11.3, see 
Nose issue 340.  You will need to use 'nosetests' directly, see below.)
    
Setuptools will take care of the rest !   To run nose directly and have
its full set of options available, read on...

SETUP
-----

All that's required is for SQLAlchemy to be installed via setuptools.
For example, to create a local install in a source distribution directory:

    $ export PYTHONPATH=.
    $ python setup.py develop -d .

The above will create a setuptools "development" distribution in the local
path, which allows the Nose plugin to be available when nosetests is run.
The plugin is enabled using the "with-sqlalchemy=True" configuration
in setup.cfg.

RUNNING ALL TESTS
-----------------
To run all tests:

    $ nosetests

(NOTE: if running with Python 2.7 and nose 0.11.3, add "-w test/" to the command.
Again this is a Nose issue, see Nose issue 342.)

If you're running the tests on Microsoft Windows, then there is an additional
argument that must be passed to nosetests:

    > nosetests --first-package-wins=True

This is required because noseâs importer will normally evict a package from
sys.modules if it sees a package with the same name in a different location.
Setting this argument disables that behavior.

Assuming all tests pass, this is a very unexciting output.  To make it more 
intersesting:

    $ nosetests -v

RUNNING INDIVIDUAL TESTS
-------------------------
Any directory of test modules can be run at once by specifying the directory
path:

    $ nosetest test/dialect

Any test module can be run directly by specifying its module name:

    $ nosetests test.orm.test_mapper

To run a specific test within the module, specify it as module:ClassName.methodname:

    $ nosetests test.orm.test_mapper:MapperTest.test_utils


COMMAND LINE OPTIONS
--------------------
Help is available via --help:

    $ nosetests --help

The --help screen is a combination of common nose options and options which 
the SQLAlchemy nose plugin adds.  The most commonly SQLAlchemy-specific 
options used are '--db' and '--dburi'.


DATABASE TARGETS
----------------

Tests will target an in-memory SQLite database by default.  To test against
another database, use the --dburi option with any standard SQLAlchemy URL:

    --dburi=postgresql://user:password@localhost/test

Use an empty database and a database user with general DBA privileges.  
The test suite will be creating and dropping many tables and other DDL, and
preexisting tables will interfere with the tests.

Several tests require alternate usernames or schemas to be present, which
are used to test dotted-name access scenarios.  On some databases such
as Oracle or Sybase, these are usernames, and others such as Postgresql
and MySQL they are schemas.   The requirement applies to all backends
except SQLite and Firebird.  The names are:

    test_schema
    test_schema_2 (only used on Postgresql)

Please refer to your vendor documentation for the proper syntax to create 
these namespaces - the database user must have permission to create and drop
tables within these schemas.  Its perfectly fine to run the test suite
without these namespaces present, it only means that a handful of tests which
expect them to be present will fail.

Additional steps specific to individual databases are as follows:

    ORACLE: a user named "test_schema" is created.
    
    The primary database user needs to be able to create and drop tables,
    synonyms, and constraints within the "test_schema" user.   For this
    to work fully, including that the user has the "REFERENCES" role
    in a remote shcema for tables not yet defined (REFERENCES is per-table),
    it is required that the test the user be present in the "DBA" role:
    
        grant dba to scott;
    
    SYBASE: Similar to Oracle, "test_schema" is created as a user, and the
    primary test user needs to have the "sa_role". 
 
    It's also recommened to turn on "trunc log on chkpt" and to use a
    separate transaction log device - Sybase basically seizes up when 
    the transaction log is full otherwise.

    A full series of setup assuming sa/master: 
   
        disk init name="translog", physname="/opt/sybase/data/translog.dat", size="10M"
        create database sqlalchemy on default log on translog="10M"
        sp_dboption sqlalchemy, "trunc log on chkpt", true
        sp_addlogin scott, "tiger7"
        sp_addlogin test_schema, "tiger7"
        use sqlalchemy
        sp_adduser scott
        sp_adduser test_schema
        grant all to scott
        sp_role "grant", sa_role, scott

    Sybase will still freeze for up to a minute when the log becomes
    full.  To manually dump the log:

        dump tran sqlalchemy with truncate_only

    MSSQL: Tests that involve multiple connections require Snapshot Isolation
    ability implented on the test database in order to prevent deadlocks that
    will occur with record locking isolation. This feature is only available
    with MSSQL 2005 and greater. You must enable snapshot isolation at the
    database level and set the default cursor isolation with two SQL commands:
    
     ALTER DATABASE MyDatabase SET ALLOW_SNAPSHOT_ISOLATION ON
    
     ALTER DATABASE MyDatabase SET READ_COMMITTED_SNAPSHOT ON

    MSSQL+zxJDBC: Trying to run the unit tests on Windows against SQL Server
    requires using a test.cfg configuration file as the cmd.exe shell won't
    properly pass the URL arguments into the nose test runner.

If you'll be running the tests frequently, database aliases can save a lot of
typing.  The --dbs option lists the built-in aliases and their matching URLs:

    $ nosetests --dbs
    Available --db options (use --dburi to override)
               mysql    mysql://scott:tiger@127.0.0.1:3306/test
              oracle    oracle://scott:tiger@127.0.0.1:1521
            postgresql    postgresql://scott:tiger@127.0.0.1:5432/test
    [...]

To run tests against an aliased database:

    $ nosetests --db=postgresql

To customize the URLs with your own users or hostnames, make a simple .ini
file called `test.cfg` at the top level of the SQLAlchemy source distribution
or a `.satest.cfg` in your home directory:

    [db]
    postgresql=postgresql://myuser:mypass@localhost/mydb

Your custom entries will override the defaults and you'll see them reflected
in the output of --dbs.

CONFIGURING LOGGING
-------------------
SQLAlchemy logs its activity and debugging through Python's logging package.
Any log target can be directed to the console with command line options, such
as:

    $ nosetests test.orm.unitofwork --log-info=sqlalchemy.orm.mapper \
      --log-debug=sqlalchemy.pool --log-info=sqlalchemy.engine

This would log mapper configuration, connection pool checkouts, and SQL
statement execution.


BUILT-IN COVERAGE REPORTING
------------------------------
Coverage is tracked using Nose's coverage plugin.   See the nose 
documentation for details.  Basic usage is:

    $ nosetests test.sql.test_query --with-coverage

BIG COVERAGE TIP !!!  There is an issue where existing .pyc files may
store the incorrect filepaths, which will break the coverage system.  If
coverage numbers are coming out as low/zero, try deleting all .pyc files.

TESTING NEW DIALECTS
--------------------
You can use the SQLAlchemy test suite to test any new database dialect in
development.  All possible database features will be exercised by default.
Test decorators are provided that can exclude unsupported tests for a
particular dialect.  You'll see them all over the source, feel free to add
your dialect to them or apply new decorations to existing tests as required.

It's fine to start out with very broad exclusions, e.g. "2-phase commit is not
supported on this database" and later refine that as needed "2-phase commit is
not available until server version 8".

To be considered for inclusion in the SQLAlchemy distribution, a dialect must
be integrated with the standard test suite.  Dialect-specific tests can be
placed in the 'dialects/' directory.  Comprehensive testing of
database-specific column types and their proper reflection are a very good
place to start.

When working through the tests, start with 'engine' and 'sql' tests.  'engine'
performs a wide range of transaction tests that might deadlock on a brand-new
dialect- try disabling those if you're having problems and revisit them later.

Once the 'sql' tests are passing, the 'orm' tests should pass as well, modulo
any adjustments needed for SQL features the ORM uses that might not be
available in your database.  But if an 'orm' test requires changes to your
dialect or the SQLAlchemy core to pass, there's a test missing in 'sql'!  Any
time you can spend boiling down the problem to it's essential sql roots and
adding a 'sql' test will be much appreciated.

The test suite is very effective at illuminating bugs and inconsistencies in
an underlying DB-API (or database!) implementation.  Workarounds are almost
always possible.  If you hit a wall, join us on the mailing list or, better,
IRC!



python-sqlparse - Parse SQL statements
======================================

sqlparse is a non-validating SQL parser module for Python.


Install
-------

Run

  python setup.py install

with root privileges to install python-sqlparse on your system.


Run Tests
---------

  python test/run_tests.py


Links
-----

Project Page:  http://python-sqlparse.googlecode.com
Source Code:   http://bitbucket.org/andialbrecht/python-sqlparse
Documentation: http://python-sqlparse.googlecode.com/svn/docs/api/index.html
Discussions:   http://groups.google.com/group/sqlparse
Issues/Bugs:   http://code.google.com/p/python-sqlparse/issues/list
Online Demo:   http://sqlformat.appspot.com


python-sqlparse is licensed under the BSD license.

Parts of the code are based on pygments written by Georg Brandl and others.
pygments-Homepage: http://pygments.org/


translate/README
User documentation
==================
The files under the user/ directory is user documentation that is generated 
from the translate toolkit section of the Translate wiki at
  http://translate.sourceforge.net/wiki/toolkit/index

The online versions should always be more up to date, but might already reflect
changes in versions newer than the one you downloaded. Please contribute to the
wiki rather than working on these files here.

API documenation
================
The files under the api/ directory is API documentation for programmers that 
want to use the toolkit as a library. It is generated with epydoc as part of
the release process. The files packaged with a released version corresponds to 
that particular release. You might want to make sure where current developement
is heading and rather work against the current development trunk in version 
control.

This directory contains miscellaneous code for translate
It includes code written specifically for translate
and also other modules that are included with Python 2.3
but have been included here for backwards compatibility with
earlier versions of Python.

translate is distributed under the GPL; some of the code in this
directory is distributed under other open source licenses.
Please see each relevant file for details...

quote.py is a standard translate module that is used for quoting/unquoting
and escaping/unescaping strings. It is released under the GPL

The csv module is defined in csv.py and _csv.c
Since some of this code is in C, it needs to be compiled and installed
on your Python distribution if you are using a version of Python before 
Python 2.3. To do this, run:
  setup.py install
(This will require the standard C compiler for your operating system)

optparse.py is the standard Python command line options parser, previously
known as Optik. It also requires textwrap.py which is a standard Python 2.3
module, and which is also included here.



Translate Toolkit
-----------------

The Translate Toolkit is a set of software and documentation designed to help
make the lives of localizers both more productive and less frustrating.  
The Toolkit is part of the translate.sourceforge.net project, 
hosted at http://translate.sourceforge.net/

The software includes programs to covert localization formats to the common 
PO, and emerging XLIFF format.  There are also programs to check and manage PO 
and XLIFF files.  Online documentation includes guides on using the tools, 
running a localization project and how to localize various projects from 
OpenOffice.org to Mozilla.

At its core the software contains a set of classes for handling various 
localization storage formats: DTD, properties, OpenOffice.org GSI/SDF,
CSV, MO, Qt .ts, TMX, TBX, WordFast txt, Gettext .mo, Windows RC, and 
of course PO and XLIFF.  It also provides scripts to convert between 
these formats.

Also part of the Toolkit are Python programs to create word counts, merge
translations and perform various checks on translation files.


Download
--------
The latest version of the Translate Toolkit can be downloaded from:
http://sourceforge.net/project/showfiles.php?group_id=91920

The latest documentation is always available at:
http://translate.sourceforge.net/wiki/toolkit/index
Documentation is also included in the doc directory.


Copying
-------
The Translate Toolkit is developed and Copyright:
	Zuza Software Foundation (Translate.org.za), and
	St James Software

and is released under the GPL license.

The Translate Toolkit Documentation is Copyright:
	Dwayne Bailey
	Javier SOLA
	David Fraser
	Friedel Wolff
	and others

and is released under the GPL.

Where useful emails have been quoted we have attempted to preserve the authors
name and assume that their work may be republished.

Joining the Translate Project
-----------------------------
If you would like to join the translate project mailing list then visit:
http://lists.sourceforge.net/lists/listinfo/translate-devel

The vision of the Translate Project is to be a meta project for localizers
built on the premise that your language deserves to be a project on its own
right not a poor cousin of the main project.

Most projects are inattentive to the needs and difficulties experienced by
localizers. To that end the aim is to work towards creating tools and
documentation that allows localizers to focus on what they do best: translating
software.

Requirements
------------
Python 2.4 or later is recommended.

The Toolkit mostly still works using Python 2.3 but is now most extensively 
tested using Python 2.4.  If you experience any errors and are using Python 2.2 
or 2.3, please first check that the error also occurs in 2.4 or 2.5 before 
reporting it as a bug.

The package lxml is needed for XML file processing. Version 1.3.4 and upwards 
should work, but lxml 2.1.0 or later is strongly recommended.
http://codespeak.net/lxml/
Depending on your platform, the easiest way to install might be through your
system's package management. Alternatively you can try
  easy_install lxml
which should install the newest version from the web. See the easy_install
documentation for more details on how to force installation of a certain
version, or to specify upgrade options, etc.

For Mac OSX, the following pages might be of help:
http://codespeak.net/lxml/build.html#providing-newer-library-versions-on-mac-os-x
http://codespeak.net/lxml/installation.html#macos-x

The package lxml has dependencies on libxml2 and libxslt. Please check the lxml
site for the recommended versions of these libraries if you need to install
them separately at all. Most packaged versions of lxml will already contain
these dependencies.

Python 2.5 includes pysqlite, but pysqlite2 needs to be installed if you are 
using an older version of Python.
http://www.initd.org/tracker/pysqlite/wiki/pysqlite

When the environment variable USECPO is set to 1, the toolkit will attempt to 
use libgettextpo from the gettext-tools package (it might have a slightly 
different name on your distribution). This can greatly speed up access to PO 
files, but has not yet been tested as extensively. Feedback is most welcome.

Psyco can help to speed up several of the programs in the toolkit. It is
optional, but highly recommended.
http://psyco.sourceforge.net/

The python wrapper to htmltidy is needed for po2html.
http://utidylib.berlios.de/

The package iniparse is necessary for ini2po and po2ini.
http://code.google.com/p/iniparse/

The python-Levenshtein package will improve performance for fuzzy matching if
it is available. This can improve the performance of pot2po, for example.  It 
is optional and no functionality is lost if it is not installed, only speed.
https://sourceforge.net/project/showfiles.php?group_id=91920&package_id=260161

Functions in the lang.data module can supply functions to translate language 
names using the iso-codes package. It can even translate names in the format 
  Language (Country)
such as
  English (South Africa)
This is used by Pootle 1.0 and later. If the package is not installed, the 
language names will simply appear in English. It is therefore recommended you 
install the iso-codes package for your distribution, but it is optional.
Alternatively, it is also available from
http://packages.debian.org/unstable/source/iso-codes

The package vobject is needed for ical2po and po2ical.  Versions from
0.6.0 have been tested, 0.6.5 is required to fix an issue related to
Lotus Notes calendars.
http://vobject.skyhouseconsulting.com/

The subtitle editing program Gaupol is needed for sub2po and
po2sub. Some Unicode encoded files (including most files from
http://dotsub.com) require latest development version of Gaupol.
http://home.gna.org/gaupol/
You will also need the 'Universal Encoding Detector'
http://chardet.feedparser.org/

The programs have been tested on Linux and Windows.


Installation
------------

To install the Translate Toolkit

* Windows
Double Click on translate-toolkit-N.N-setup.exe (the larger download file).
This installer contains all dependencies you will need, including Python. To 
use any of the command line tools, just type their name in a command window.
For example:
  moz2po --version

Alternatively you can install the smaller translate-toolkit-N.N.N.win32.exe
This needs an existing Python installation, and assumes you will install all 
the dependencies yourself. You will probably need to edit your PATH environment
variable to be able to use the tools in any command window. 

* Linux
tar xzf translate-N.N.tar.gz
cd translate-N.N
su -c ./setup.py install

If you get this error along the lines of
Unable to open /usr/lib/python2.N/config/Makefile (no such file or directory)
while running setup.py, you need to install python-dev or libpython2.N-devel
package. Try to install python2.N-dev or libpython2.N-devel or something 
similar with your distribution's package manager.


Bugs
----
We think there might be some :)

Please send your bug reports to:
  translate-devel at lists.sourceforge.net
or report them at our bugzilla server at
  http://bugs.locamotion.org/

Some help in writing useful bug reports are mentioned here:
  http://translate.sourceforge.net/wiki/developers/reporting_bugs

Documentation
-------------
Please read our documentation online at 
  http://translate.sourceforge.net/wiki/toolkit/index
There they are constantly being updated. Please feel free to contribute new 
sections and suggest corrections.

Most tools support the options --help and --manpage of which the output is 
automatically generated. The output of --manpage produces output suitable for 
formatting as a standard manpage. This can be viewed on UNIX platforms with 
  nroff -Tutf8 -mandoc
With pot2po as example:
  pot2po --manpage| /usr/bin/nroff -Tutf8 -mandoc|less
This is probably most useful for packagers to help them generate manual pages 
for the packaged versions.

Program overview
----------------

Use --help to find the syntax and options for all programs.

* Converters
oo2po    - convert between OpenOffice.org GSI files and PO
oo2xliff - convert between OpenOffice.org GSI files and XLIFF
moz2po   - convert from a Mozilla XPI file and PO.  Including unpacking
           and building a translated XPI.
csv2po   - convert PO format to CSV for editing in a spreadsheet program
php2po   - PHP localisable string arrays converter.
ts2po    - convert Qt Linguist (.ts) files to PO
txt2po   - convert simple text files to PO
html2po  - convert HTML to PO (beta)
xliff2po - XLIFF (XML Localisation Interchange File Format) converter
prop2po  - convert Java .properties files to PO
po2wordfast - Wordfast Translation Memory converter
po2tmx   - TMX (Translation Memory Exchange) converter
pot2po   - PO file initialiser
csv2tbx  - Create TBX (TermBase eXchange) files from Comma Separated Value (CSV) files
ini2po   - convert .ini files to to PO
ical2po  - Convert iCalendar files (*.ics) to PO
sub2po   - Convert many subtitle files to PO

* Tools (Quality Assurance)
pofilter - run any of the 40+ checks on your PO files
pomerge  - merge corrected translations from pofilter back into your existing
           PO files.
poconflicts - identify conflicting use of terms
porestructure - restructures po files according to poconflict directives
pogrep   - find words in PO files

* Tools (Other)
pocompile - create a Gettext MO files from PO or XLIFF files
pocount   - count translatable file formats (PO, XLIFF)
podebug   - Create comment in your PO files' msgstr which can then be used to quickly 
            track down mistranslations as the comments appear in the application.
posegment - Break a PO or XLIFF files into sentence segments, useful 
            for creating a segmented translation memory.
poswap    - uses a translation of another language that you would rather use 
            than English as source language
poterminology - analyse PO or POT files to build a list of frequently occurring
                words and phrases


This directory contains data files that serve as language models for language
recognition. They are in the format used by libtextcat and obtained from the
current openoffice.org-common Ubuntu package. You might find them in your
installation in a place like
    basis3.1/share/fingerprint/

Note that several files were removed due to incorrect encodings or other
problems. Here is a summary of some issues encountered:

Arabic (ar): No frequencies
Belarus (be): No frequencies
Chinese (zh): No frequencies
Croatian (hr): Possibly broken
Esperanto (eo): Possibly broken
Japanese (jp): No frequencies
Latvian (lv): Possible orthography issues
Lithuanian (lt): Division signs
Middle Frisian (??): Applicable?
Mingo (??): What is this?
Polish (pl): Incorrect encoding?
Romanian (ro): Missing non-ASCII characters. Incorrect encoding?
Serbian@latin: Language code needs Cyrillic model as well
Turkish (tr): Missing non-ASCII characters.
Ukrainian (uk): No frequencies
Vietnamese (vi): Encoding issues in model


Classified incorrectly:
* Norwegian (no): Classified as Danish

=======
urllib3
=======

.. image:: https://travis-ci.org/shazow/urllib3.png?branch=master
        :target: https://travis-ci.org/shazow/urllib3


Highlights
==========

- Re-use the same socket connection for multiple requests
  (``HTTPConnectionPool`` and ``HTTPSConnectionPool``)
  (with optional client-side certificate verification).
- File posting (``encode_multipart_formdata``).
- Built-in redirection and retries (optional).
- Supports gzip and deflate decoding.
- Thread-safe and sanity-safe.
- Works with AppEngine, gevent, and eventlib.
- Tested on Python 2.6+ and Python 3.2+, 100% unit test coverage.
- Small and easy to understand codebase perfect for extending and building upon.
  For a more comprehensive solution, have a look at
  `Requests <http://python-requests.org/>`_ which is also powered by urllib3.

What's wrong with urllib and urllib2?
=====================================

There are two critical features missing from the Python standard library:
Connection re-using/pooling and file posting. It's not terribly hard to
implement these yourself, but it's much easier to use a module that already
did the work for you.

The Python standard libraries ``urllib`` and ``urllib2`` have little to do
with each other. They were designed to be independent and standalone, each
solving a different scope of problems, and ``urllib3`` follows in a similar
vein.

Why do I want to reuse connections?
===================================

Performance. When you normally do a urllib call, a separate socket
connection is created with each request. By reusing existing sockets
(supported since HTTP 1.1), the requests will take up less resources on the
server's end, and also provide a faster response time at the client's end.
With some simple benchmarks (see `test/benchmark.py
<https://github.com/shazow/urllib3/blob/master/test/benchmark.py>`_
), downloading 15 URLs from google.com is about twice as fast when using
HTTPConnectionPool (which uses 1 connection) than using plain urllib (which
uses 15 connections).

This library is perfect for:

- Talking to an API
- Crawling a website
- Any situation where being able to post files, handle redirection, and
  retrying is useful. It's relatively lightweight, so it can be used for
  anything!

Examples
========

Go to `urllib3.readthedocs.org <http://urllib3.readthedocs.org>`_
for more nice syntax-highlighted examples.

But, long story short::

  import urllib3

  http = urllib3.PoolManager()

  r = http.request('GET', 'http://google.com/')

  print r.status, r.data

The ``PoolManager`` will take care of reusing connections for you whenever
you request the same host. For more fine-grained control of your connection
pools, you should look at
`ConnectionPool <http://urllib3.readthedocs.org/#connectionpool>`_.


Run the tests
=============

We use some external dependencies, multiple interpreters and code coverage
analysis while running test suite. Easiest way to run the tests is thusly the
``tox`` utility: ::

  $ tox
  # [..]
  py26: commands succeeded
  py27: commands succeeded
  py32: commands succeeded
  py33: commands succeeded

Note that code coverage less than 100% is regarded as a failing run.


Contributing
============

#. `Check for open issues <https://github.com/shazow/urllib3/issues>`_ or open
   a fresh issue to start a discussion around a feature idea or a bug. There is
   a *Contributor Friendly* tag for issues that should be ideal for people who
   are not very familiar with the codebase yet.
#. Fork the `urllib3 repository on Github <https://github.com/shazow/urllib3>`_
   to start making your changes.
#. Write a test which shows that the bug was fixed or that the feature works
   as expected.
#. Send a pull request and bug the maintainer until it gets merged and published.
   :) Make sure to add yourself to ``CONTRIBUTORS.txt``.

This folder includes example applications for werkzeug.contrib

couchy README

Requirements :
- werkzeug : http://werkzeug.pocoo.org
- jinja : http://jinja.pocoo.org
- couchdb 0.72 & above : http://www.couchdb.org
- couchdb-python 0.3 & above : http://code.google.com/p/couchdb-python


This directory contains modules that have code but that are
not excutable.  For example routing definitions to play around
in the python interactive prompt.

=================
Werkzeug Examples
=================

This directory contains various example applications and example code of
Werkzeug powered applications.

Beside the proof of concept applications and code snippets in the partial
folder they all have external depencencies for template engines or database
adapters (SQLAlchemy only so far).


Full Example Applications
=========================

The following example applications are application types you would actually
find in real life :-)


`simplewiki`
    A simple Wiki implementation.

    Requirements:
    -   SQLAlchemy
    -   Creoleparser >= 0.3.3
    -   genshi

    You can obtain all packages in the Cheeseshop via easy_install.  You have
    to have at least version 0.3.3 of Creoleparser.

    Usage::

        ./manage-simplewiki.py initdb
        ./manage-simplewiki.py runserver

    Or of course you can just use the application object
    (`simplewiki.SimpleWiki`) and hook that into your favourite WSGI gateway.
    The constructor of the application object takes a single argument which is
    the SQLAlchemy URI for the database.

    The management script for the devserver looks up the an environment var
    called `SIMPLEWIKI_DATABASE_URI` and uses that for the database URI.  If
    no such variable is provided "sqlite:////tmp/simplewiki.db" is assumed.

`plnt`
    A planet called plnt, pronounce plant.

    Requirements:
    -   SQLAlchemy
    -   Jinja
    -   feedparser

    You can obtain all packages in the Cheeseshop via easy_install.

    Usage::

        ./manage-plnt.py initdb
        ./manage-plnt.py sync
        ./manage-plnt.py runserver

    The WSGI application is called `plnt.Plnt` which, like the simple wiki,
    accepts a database URI as first argument.  The environment variable for
    the database key is called `PLNT_DATABASE_URI` and the default is
    "sqlite:////tmp/plnt.db".

    Per default a few python related blogs are added to the database, you
    can add more in a python shell by playing with the `Blog` model.

`shorty`
    A tinyurl clone for the Werkzeug 0.2 tutorial.

    Requirements:
    -   SQLAlchemy
    -   Jinja2

    You can obtain all packages in the Cheeseshop via easy_install.

    Usage::

        ./manage-shorty.py initdb
        ./manage-shorty.py runserver

    The WSGI application is called `shorty.application.Shorty` which, like the
    simple wiki, accepts a database URI as first argument.

    The source code of the application is explained in detail in the Werkzeug
    tutorial.

`couchy`
    Like shorty, but implemented using CouchDB.

    Requirements :
    -   werkzeug : http://werkzeug.pocoo.org
    -   jinja : http://jinja.pocoo.org
    -   couchdb 0.72 & above : http://www.couchdb.org

`cupoftee`
    A `Teeworlds <http://www.teeworlds.com/>`_ server browser.  This application
    works best in a non forking environment and won't work for CGI.

    Usage::

        ./manage-cupoftee.py runserver

These files are for times when we need to automaticall set up a new
environment, and don't want to spend the time to download packages, or
want to be nice to the servers.

Currently this is limited to automated testing via TravisCI.

