__FILENAME__ = conftest
# -*- coding: utf-8 -*-
import pytest
import os
import json
import sys

if sys.version_info[0] == 2:
    from codecs import open

# This pair of generator expressions are pretty lame, but building lists is a
# bad idea as I plan to have a substantial number of tests here.
story_directories = (
    os.path.join('test_fixtures', d) for d in os.listdir('test_fixtures')
)
story_files = (
    os.path.join(storydir, name) for storydir in story_directories
                                 for name in os.listdir(storydir)
                                 if 'raw-data' not in storydir
)
raw_story_files = (
    os.path.join('test_fixtures/raw-data', name)
    for name in os.listdir('test_fixtures/raw-data')
)

@pytest.fixture(scope="class",
                params=story_files)
def story(request):
    """
    Provides a detailed HPACK story to test with.
    """
    path = request.param
    with open(path, 'r', encoding='utf-8') as f:
        details = json.loads(f.read())

    return details

@pytest.fixture(scope="class", params=raw_story_files)
def raw_story(request):
    """
    Provides a detailed HPACK story to test the encoder with.
    """
    path = request.param
    with open(path, 'r', encoding='utf-8') as f:
        details = json.loads(f.read())

    return details

########NEW FILE########
__FILENAME__ = conf
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# hyper documentation build configuration file, created by
# sphinx-quickstart on Mon Feb 10 21:05:53 2014.
#
# This file is execfile()d with the current directory set to its
# containing dir.
#
# Note that not all possible configuration values are present in this
# autogenerated file.
#
# All configuration values have a default; values that are commented out
# serve to show the default.

import sys
import os

# If extensions (or modules to document with autodoc) are in another directory,
# add these directories to sys.path here. If the directory is relative to the
# documentation root, use os.path.abspath to make it absolute, like shown here.
#sys.path.insert(0, os.path.abspath('.'))

# -- General configuration ------------------------------------------------

# If your documentation needs a minimal Sphinx version, state it here.
#needs_sphinx = '1.0'

# Add any Sphinx extension module names here, as strings. They can be
# extensions coming with Sphinx (named 'sphinx.ext.*') or your custom
# ones.
extensions = [
    'sphinx.ext.autodoc',
    'sphinx.ext.intersphinx',
]

# Add any paths that contain templates here, relative to this directory.
templates_path = ['_templates']

# The suffix of source filenames.
source_suffix = '.rst'

# The encoding of source files.
#source_encoding = 'utf-8-sig'

# The master toctree document.
master_doc = 'index'

# General information about the project.
project = 'hyper'
copyright = '2014, Cory Benfield'

# The version info for the project you're documenting, acts as replacement for
# |version| and |release|, also used in various other places throughout the
# built documents.
#
# The short X.Y version.
version = '0.0.4'
# The full version, including alpha/beta/rc tags.
release = '0.0.4'

# The language for content autogenerated by Sphinx. Refer to documentation
# for a list of supported languages.
#language = None

# There are two options for replacing |today|: either, you set today to some
# non-false value, then it is used:
#today = ''
# Else, today_fmt is used as the format for a strftime call.
#today_fmt = '%B %d, %Y'

# List of patterns, relative to source directory, that match files and
# directories to ignore when looking for source files.
exclude_patterns = []

# The reST default role (used for this markup: `text`) to use for all
# documents.
#default_role = None

# If true, '()' will be appended to :func: etc. cross-reference text.
#add_function_parentheses = True

# If true, the current module name will be prepended to all description
# unit titles (such as .. function::).
#add_module_names = True

# If true, sectionauthor and moduleauthor directives will be shown in the
# output. They are ignored by default.
#show_authors = False

# The name of the Pygments (syntax highlighting) style to use.
pygments_style = 'sphinx'

# A list of ignored prefixes for module index sorting.
#modindex_common_prefix = []

# If true, keep warnings as "system message" paragraphs in the built documents.
#keep_warnings = False


# -- Options for HTML output ----------------------------------------------

# The theme to use for HTML and HTML Help pages.  See the documentation for
# a list of builtin themes.
html_theme = 'default'

# Theme options are theme-specific and customize the look and feel of a theme
# further.  For a list of options available for each theme, see the
# documentation.
#html_theme_options = {}

# Add any paths that contain custom themes here, relative to this directory.
#html_theme_path = []

# The name for this set of Sphinx documents.  If None, it defaults to
# "<project> v<release> documentation".
#html_title = None

# A shorter title for the navigation bar.  Default is the same as html_title.
#html_short_title = None

# The name of an image file (relative to this directory) to place at the top
# of the sidebar.
#html_logo = None

# The name of an image file (within the static path) to use as favicon of the
# docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
# pixels large.
#html_favicon = None

# Add any paths that contain custom static files (such as style sheets) here,
# relative to this directory. They are copied after the builtin static files,
# so a file named "default.css" will overwrite the builtin "default.css".
html_static_path = ['_static']

# Add any extra paths that contain custom files (such as robots.txt or
# .htaccess) here, relative to this directory. These files are copied
# directly to the root of the documentation.
#html_extra_path = []

# If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
# using the given strftime format.
#html_last_updated_fmt = '%b %d, %Y'

# If true, SmartyPants will be used to convert quotes and dashes to
# typographically correct entities.
#html_use_smartypants = True

# Custom sidebar templates, maps document names to template names.
#html_sidebars = {}

# Additional templates that should be rendered to pages, maps page names to
# template names.
#html_additional_pages = {}

# If false, no module index is generated.
#html_domain_indices = True

# If false, no index is generated.
#html_use_index = True

# If true, the index is split into individual pages for each letter.
#html_split_index = False

# If true, links to the reST sources are added to the pages.
#html_show_sourcelink = True

# If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
#html_show_sphinx = True

# If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
#html_show_copyright = True

# If true, an OpenSearch description file will be output, and all pages will
# contain a <link> tag referring to it.  The value of this option must be the
# base URL from which the finished HTML is served.
#html_use_opensearch = ''

# This is the file name suffix for HTML files (e.g. ".xhtml").
#html_file_suffix = None

# Output file base name for HTML help builder.
htmlhelp_basename = 'hyperdoc'


# -- Options for LaTeX output ---------------------------------------------

latex_elements = {
# The paper size ('letterpaper' or 'a4paper').
#'papersize': 'letterpaper',

# The font size ('10pt', '11pt' or '12pt').
#'pointsize': '10pt',

# Additional stuff for the LaTeX preamble.
#'preamble': '',
}

# Grouping the document tree into LaTeX files. List of tuples
# (source start file, target name, title,
#  author, documentclass [howto, manual, or own class]).
latex_documents = [
  ('index', 'hyper.tex', 'hyper Documentation',
   'Cory Benfield', 'manual'),
]

# The name of an image file (relative to this directory) to place at the top of
# the title page.
#latex_logo = None

# For "manual" documents, if this is true, then toplevel headings are parts,
# not chapters.
#latex_use_parts = False

# If true, show page references after internal links.
#latex_show_pagerefs = False

# If true, show URL addresses after external links.
#latex_show_urls = False

# Documents to append as an appendix to all manuals.
#latex_appendices = []

# If false, no module index is generated.
#latex_domain_indices = True


# -- Options for manual page output ---------------------------------------

# One entry per manual page. List of tuples
# (source start file, name, description, authors, manual section).
man_pages = [
    ('index', 'hyper', 'hyper Documentation',
     ['Cory Benfield'], 1)
]

# If true, show URL addresses after external links.
#man_show_urls = False


# -- Options for Texinfo output -------------------------------------------

# Grouping the document tree into Texinfo files. List of tuples
# (source start file, target name, title, author,
#  dir menu entry, description, category)
texinfo_documents = [
  ('index', 'hyper', 'hyper Documentation',
   'Cory Benfield', 'hyper', 'One line description of project.',
   'Miscellaneous'),
]

# Documents to append as an appendix to all manuals.
#texinfo_appendices = []

# If false, no module index is generated.
#texinfo_domain_indices = True

# How to display URL addresses: 'footnote', 'no', or 'inline'.
#texinfo_show_urls = 'footnote'

# If true, do not generate a @detailmenu in the "Top" node's menu.
#texinfo_no_detailmenu = False


# Example configuration for intersphinx: refer to the Python standard library.
intersphinx_mapping = {'http://docs.python.org/': None}

########NEW FILE########
__FILENAME__ = compat
# -*- coding: utf-8 -*-
"""
hyper/compat
~~~~~~~~~

Normalizes the Python 2/3 API for internal use.
"""
import sys
import zlib

# Syntax sugar.
_ver = sys.version_info

#: Python 2.x?
is_py2 = (_ver[0] == 2)

#: Python 3.x?
is_py3 = (_ver[0] == 3)

if is_py2:
    from urlparse import urlparse

    def to_byte(char):
        return ord(char)

    def decode_hex(b):
        return b.decode('hex')

    # The standard zlib.compressobj() accepts only positional arguments.
    def zlib_compressobj(level=6, method=zlib.DEFLATED, wbits=15, memlevel=8,
                         strategy=zlib.Z_DEFAULT_STRATEGY):
        return zlib.compressobj(level, method, wbits, memlevel, strategy)

elif is_py3:
    from urllib.parse import urlparse

    def to_byte(char):
        return char

    def decode_hex(b):
        return bytes.fromhex(b)

    zlib_compressobj = zlib.compressobj

########NEW FILE########
__FILENAME__ = contrib
# -*- coding: utf-8 -*-
"""
hyper/contrib
~~~~~~~~~~~~~

Contains a few utilities for use with other HTTP libraries.
"""
try:
    from requests.adapters import HTTPAdapter
    from requests.models import Response
    from requests.structures import CaseInsensitiveDict
    from requests.utils import get_encoding_from_headers
    from requests.cookies import extract_cookies_to_jar
except ImportError:  # pragma: no cover
    HTTPAdapter = object

from hyper import HTTP20Connection
from hyper.compat import urlparse

class HTTP20Adapter(HTTPAdapter):
    """
    A Requests Transport Adapter that uses hyper to send requests over
    HTTP/2.0. This implements some degree of connection pooling to maximise the
    HTTP/2.0 gain.
    """
    def __init__(self, *args, **kwargs):
        #: A mapping between HTTP netlocs and ``HTTP20Connection`` objects.
        self.connections = {}

    def get_connection(self, netloc):
        """
        Gets an appropriate HTTP/2.0 connection object based on netloc.
        """
        try:
            conn = self.connections[netloc]
        except KeyError:
            conn = HTTP20Connection(netloc)
            self.connections[netloc] = conn

        return conn

    def send(self, request, stream=False, **kwargs):
        """
        Sends a HTTP message to the server.
        """
        parsed = urlparse(request.url)

        conn = self.get_connection(parsed.netloc)

        # Build the selector.
        selector = parsed.path
        selector += '?' + parsed.query if parsed.query else ''
        selector += '#' + parsed.fragment if parsed.fragment else ''

        stream_id = conn.request(
            request.method,
            selector,
            request.body,
            request.headers
        )
        resp = conn.getresponse(stream_id)

        r = self.build_response(request, resp)

        if not stream:
            r.content

        return r

    def build_response(self, request, resp):
        """
        Builds a Requests' response object.  This emulates most of the logic of
        the standard fuction but deals with the lack of the ``.headers``
        property on the HTTP20Response object.
        """
        response = Response()

        response.status_code = resp.status
        response.headers = CaseInsensitiveDict(resp.getheaders())
        response.raw = resp
        response.reason = resp.reason
        response.encoding = get_encoding_from_headers(response.headers)

        extract_cookies_to_jar(response.cookies, request, response)
        response.url = request.url

        response.request = request
        response.connection = self

        # One last horrible patch: Requests expects its raw responses to have a
        # release_conn method, which I don't. We should monkeypatch a no-op on.
        resp.release_conn = lambda: None

        return response

########NEW FILE########
__FILENAME__ = connection
# -*- coding: utf-8 -*-
"""
hyper/http20/connection
~~~~~~~~~~~~~~~~~~~~~~~

Objects that build hyper's connection-level HTTP/2.0 abstraction.
"""
from .hpack import Encoder, Decoder
from .stream import Stream
from .tls import wrap_socket
from .frame import (
    DataFrame, HeadersFrame, PushPromiseFrame, RstStreamFrame, SettingsFrame,
    Frame, WindowUpdateFrame, GoAwayFrame, PingFrame,
)
from .response import HTTP20Response, HTTP20Push
from .window import FlowControlManager
from .exceptions import ConnectionError

import errno
import logging
import socket

log = logging.getLogger(__name__)


class HTTP20Connection(object):
    """
    An object representing a single HTTP/2.0 connection to a server.

    This object behaves similarly to the Python standard library's
    HTTPConnection object, with a few critical differences.

    Most of the standard library's arguments to the constructor are irrelevant
    for HTTP/2.0 or not supported by hyper.

    :param host: The host to connect to. This may be an IP address or a
        hostname, and optionally may include a port: for example,
        ``'twitter.com'``, ``'twitter.com:443'`` or ``'127.0.0.1'``.
    :param port: (optional) The port to connect to. If not provided and one also
        isn't provided in the ``host`` parameter, defaults to 443.
    :param window_manager: (optional) The class to use to manage flow control
        windows. This needs to be a subclass of the
        :class:`BaseFlowControlManager <hyper.http20.window.BaseFlowControlManager>`.
        If not provided,
        :class:`FlowControlManager <hyper.http20.window.FlowControlManager>`
        will be used.
    :param enable_push: (optional) Whether the server is allowed to push
        resources to the client (see
        :meth:`getpushes() <hyper.HTTP20Connection.getpushes>`).
    """
    def __init__(self, host, port=None, window_manager=None, enable_push=False,
                 **kwargs):
        """
        Creates an HTTP/2.0 connection to a specific server.
        """
        if port is None:
            try:
                self.host, self.port = host.split(':')
                self.port = int(self.port)
            except ValueError:
                self.host, self.port = host, 443
        else:
            self.host, self.port = host, port

        self._enable_push = enable_push

        # Create the mutable state.
        self.__wm_class = window_manager or FlowControlManager
        self.__init_state()

        return

    def __init_state(self):
        """
        Initializes the 'mutable state' portions of the HTTP/2.0 connection
        object.

        This method exists to enable HTTP20Connection objects to be reused if
        they're closed, by resetting the connection object to its basic state
        whenever it ends up closed. Any situation that needs to recreate the
        connection can call this method and it will be done.

        This is one of the only methods in hyper that is truly private, as
        users should be strongly discouraged from messing about with connection
        objects themselves.
        """
        # Streams are stored in a dictionary keyed off their stream IDs. We
        # also save the most recent one for easy access without having to walk
        # the dictionary.
        self.streams = {}
        self.recent_stream = None
        self.next_stream_id = 1

        # Header encoding/decoding is at the connection scope, so we embed a
        # header encoder and a decoder. These get passed to child stream
        # objects.
        self.encoder = Encoder()
        self.decoder = Decoder()

        # Values for the settings used on an HTTP/2.0 connection.
        self._settings = {
            SettingsFrame.INITIAL_WINDOW_SIZE: 65535,
        }

        # The socket used to send data.
        self._sock = None

        # The inbound and outbound flow control windows.
        self._out_flow_control_window = 65535

        # Instantiate a window manager.
        self.window_manager = self.__wm_class(65535)

        return

    def request(self, method, url, body=None, headers={}):
        """
        This will send a request to the server using the HTTP request method
        ``method`` and the selector ``url``. If the ``body`` argument is
        present, it should be string or bytes object of data to send after the
        headers are finished. Strings are encoded as UTF-8. To use other
        encodings, pass a bytes object. The Content-Length header is set to the
        length of the body field.

        :returns: A stream ID for the request.
        :param method: The request method, e.g. ``'GET'``.
        :param url: The URL to contact, e.g. ``'/path/segment'``.
        :param body: (optional) The request body to send. Must be a bytestring
            or a file-like object.
        :param headers: (optional) The headers to send on the request.
        """
        stream_id = self.putrequest(method, url)

        for name, value in headers.items():
            self.putheader(name, value, stream_id)

        # Convert the body to bytes if needed.
        if isinstance(body, str):
            body = body.encode('utf-8')

        self.endheaders(message_body=body, final=True, stream_id=stream_id)

        return stream_id

    def _get_stream(self, stream_id):
        return (self.streams[stream_id] if stream_id is not None
                else self.recent_stream)

    def getresponse(self, stream_id=None):
        """
        Should be called after a request is sent to get a response from the
        server. If sending multiple parallel requests, pass the stream ID of
        the request whose response you want. Returns a HTTPResponse instance.
        If you pass no stream_id, you will receive the oldest HTTPResponse
        still outstanding.

        :param stream_id: (optional) The stream ID of the request for which to
            get a response.
        :returns: A HTTP response object.
        """
        stream = self._get_stream(stream_id)
        return HTTP20Response(stream.getheaders(), stream)

    def getpushes(self, stream_id=None, capture_all=False):
        """
        Returns a generator that yields push promises from the server. Note that
        this method is not idempotent; promises returned in one call will not be
        returned in subsequent calls. Iterating through generators returned by
        multiple calls to this method simultaneously results in undefined
        behavior.

        :param stream_id: (optional) The stream ID of the request for which to
            get push promises.
        :param capture_all: (optional) If ``False``, the generator will yield
            all buffered push promises without blocking. If ``True``, the
            generator will first yield all buffered push promises, then yield
            additional ones as they arrive, and terminate when the original
            stream closes.
        """
        stream = self._get_stream(stream_id)
        for promised_stream_id, headers in stream.getpushes(capture_all):
            yield HTTP20Push(headers, self.streams[promised_stream_id])

    def connect(self):
        """
        Connect to the server specified when the object was created. This is a
        no-op if we're already connected.

        :returns: Nothing.
        """
        if self._sock is None:
            sock = socket.create_connection((self.host, self.port), 5)
            sock = wrap_socket(sock, self.host)
            self._sock = sock

            # We need to send the connection header immediately on this
            # connection, followed by an initial settings frame.
            sock.send(b'PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n')
            f = SettingsFrame(0)
            f.settings[SettingsFrame.ENABLE_PUSH] = int(self._enable_push)
            self._send_cb(f)

            # The server will also send an initial settings frame, so get it.
            self._recv_cb()

        return

    def close(self):
        """
        Close the connection to the server.

        :returns: Nothing.
        """
        # Todo: we should actually clean ourselves up if possible by sending
        # GoAway frames and closing all outstanding streams. For now this will
        # do.
        if self._sock is not None:
            self._sock.close()
            self.__init_state()

    def putrequest(self, method, selector, **kwargs):
        """
        This should be the first call for sending a given HTTP request to a
        server. It returns a stream ID for the given connection that should be
        passed to all subsequent request building calls.

        :param method: The request method, e.g. ``'GET'``.
        :param selector: The path selector.
        :returns: A stream ID for the request.
        """
        # Create a new stream.
        s = self._new_stream()

        # To this stream we need to immediately add a few headers that are
        # HTTP/2.0 specific. These are: ":method", ":scheme", ":authority" and
        # ":path". We can set all of these now.
        s.add_header(":method", method)
        s.add_header(":scheme", "https")  # We only support HTTPS at this time.
        s.add_header(":authority", self.host)
        s.add_header(":path", selector)

        # Save the stream.
        self.recent_stream = s

        return s.stream_id

    def putheader(self, header, argument, stream_id=None):
        """
        Sends an HTTP header to the server, with name ``header`` and value
        ``argument``.

        Unlike the httplib version of this function, this version does not
        actually send anything when called. Instead, it queues the headers up
        to be sent when you call ``endheaders``.

        :param header: The name of the header.
        :param argument: The value of the header.
        :param stream_id: (optional) The stream ID of the request to add the
            header to.
        :returns: Nothing.
        """
        stream = self._get_stream(stream_id)
        stream.add_header(header, argument)

        return

    def endheaders(self, message_body=None, final=False, stream_id=None):
        """
        Sends the prepared headers to the server. If the ``message_body``
        argument is provided it will also be sent to the server as the body of
        the request, and the stream will immediately be closed. If the
        ``final`` argument is set to True, the stream will also immediately
        be closed: otherwise, the stream will be left open and subsequent calls
        to ``send()`` will be required.

        :param message_body: (optional) The body to send. May not be provided
            assuming that ``send()`` will be called.
        :param final: (optional) If the ``message_body`` parameter is provided,
            should be set to ``True`` if no further data will be provided via
            calls to ``send()``.
        :param stream_id: (optional) The stream ID of the request to finish
            sending the headers on.
        :returns: Nothing.
        """
        self.connect()

        stream = self._get_stream(stream_id)

        # Close this if we've been told no more data is coming and we don't
        # have any to send.
        stream.open(final and message_body is None)

        # Send whatever data we have.
        if message_body is not None:
            stream.send_data(message_body, final)

        return

    def send(self, data, final=False, stream_id=None):
        """
        Sends some data to the server. This data will be sent immediately
        (excluding the normal HTTP/2.0 flow control rules). If this is the last
        data that will be sent as part of this request, the ``final`` argument
        should be set to ``True``. This will cause the stream to be closed.

        :param data: The data to send.
        :param final: (optional) Whether this is the last bit of data to be
            sent on this request.
        :param stream_id: (optional) The stream ID of the request to send the
            data on.
        :returns: Nothing.
        """
        stream = self._get_stream(stream_id)
        stream.send_data(data, final)

        return

    def receive_frame(self, frame):
        """
        Handles receiving frames intended for the stream.
        """
        if isinstance(frame, WindowUpdateFrame):
            self._out_flow_control_window += frame.window_increment
        elif isinstance(frame, PingFrame):
            if 'ACK' not in frame.flags:
                # The spec requires us to reply with PING+ACK and identical data.
                p = PingFrame(0)
                p.flags.add('ACK')
                p.opaque_data = frame.opaque_data
                self._data_cb(p, True)
        elif isinstance(frame, SettingsFrame):
            if 'ACK' not in frame.flags:
                self._update_settings(frame)

                #Â Need to return an ack.
                f = SettingsFrame(0)
                f.flags.add('ACK')
                self._send_cb(f)
        elif isinstance(frame, GoAwayFrame):
            # If we get GoAway with error code zero, we are doing a graceful
            # shutdown and all is well. Otherwise, throw an exception.
            self.close()

            if frame.error_code != 0:
                raise ConnectionError(
                    "Encountered error %d, extra data %s." %
                    (frame.error_code, frame.additional_data)
                )
        else:
            raise ValueError("Unexpected frame %s." % frame)

    def _update_settings(self, frame):
        """
        Handles the data sent by a settings frame.
        """
        if SettingsFrame.HEADER_TABLE_SIZE in frame.settings:
            new_size = frame.settings[SettingsFrame.HEADER_TABLE_SIZE]

            self._settings[SettingsFrame.HEADER_TABLE_SIZE] = new_size
            self.encoder.header_table_size = new_size

        if SettingsFrame.INITIAL_WINDOW_SIZE in frame.settings:
            newsize = frame.settings[SettingsFrame.INITIAL_WINDOW_SIZE]
            oldsize = self._settings[SettingsFrame.INITIAL_WINDOW_SIZE]
            delta = newsize - oldsize

            for stream in self.streams.values():
                stream._out_flow_control_window += delta

            # Update the connection window size.
            self._out_flow_control_window += delta

            self._settings[SettingsFrame.INITIAL_WINDOW_SIZE] = newsize

    def _new_stream(self, stream_id=None, local_closed=False):
        """
        Returns a new stream object for this connection.
        """
        window_size = self._settings[SettingsFrame.INITIAL_WINDOW_SIZE]
        s = Stream(
            stream_id or self.next_stream_id, self._send_cb, self._recv_cb,
            self._close_stream, self.encoder, self.decoder,
            self.__wm_class(65535), local_closed
        )
        s._out_flow_control_window = self._out_flow_control_window
        self.streams[s.stream_id] = s
        self.next_stream_id += 2

        return s

    def _close_stream(self, stream_id, error_code=None):
        """
        Called by a stream when it would like to be 'closed'.
        """
        if error_code is not None:
            f = RstStreamFrame(stream_id)
            f.error_code = error_code
            self._send_cb(f)

        del self.streams[stream_id]

    def _send_cb(self, frame, tolerate_peer_gone=False):
        """
        This is the callback used by streams to send data on the connection.

        It expects to receive a single frame, and then to serialize that frame
        and send it on the connection. It does so obeying the connection-level
        flow-control principles of HTTP/2.0.
        """
        # Maintain our outgoing flow-control window.
        if (isinstance(frame, DataFrame) and
            not isinstance(frame, HeadersFrame)):

            # If we don't have room in the flow control window, we need to look
            # for a Window Update frame.
            while self._out_flow_control_window < len(frame.data):
                self._recv_cb()

            self._out_flow_control_window -= len(frame.data)

        data = frame.serialize()

        log.info(
            "Sending frame %s on stream %d",
            frame.__class__.__name__,
            frame.stream_id
        )

        try:
            self._sock.send(data)
        except socket.error as e:
            if not tolerate_peer_gone or e.errno not in (errno.EPIPE, errno.ECONNRESET):
                raise

    def _adjust_receive_window(self, frame_len):
        """
        Adjusts the window size in response to receiving a DATA frame of length
        ``frame_len``. May send a WINDOWUPDATE frame if necessary.
        """
        increment = self.window_manager._handle_frame(frame_len)

        if increment:
            f = WindowUpdateFrame(0)
            f.window_increment = increment
            self._send_cb(f, True)

        return

    def _recv_cb(self):
        """
        This is the callback used by streams to read data from the connection.

        It expects to read a single frame, and then to deserialize that frame
        and pass it to the relevant stream. This is generally called by a
        stream, not by the connection itself, and it's likely that streams will
        read a frame that doesn't belong to them. That's ok: streams need to
        make a decision to spin around again.
        """
        # Begin by reading 8 bytes from the socket.
        header = self._sock.recv(8)

        # Parse the header.
        frame, length = Frame.parse_frame_header(header)

        # Read the remaining data from the socket.
        if length:
            data = self._sock.recv(length)
        else:
            data = b''

        frame.parse_body(data)

        log.info(
            "Received frame %s on stream %d",
            frame.__class__.__name__,
            frame.stream_id
        )

        # Maintain our flow control window. We do this by delegating to the
        # chosen WindowManager.
        if (isinstance(frame, DataFrame) and
            not isinstance(frame, HeadersFrame)):
            # Inform the WindowManager of how much data was received. If the
            # manager tells us to increment the window, do so.
            self._adjust_receive_window(len(frame.data))
        elif isinstance(frame, PushPromiseFrame):
            if self._enable_push:
                self._new_stream(frame.promised_stream_id, local_closed=True)
            else:
                # Servers are forbidden from sending push promises when
                # the ENABLE_PUSH setting is 0, but the spec leaves the client
                # action undefined when they do it anyway. So we just refuse
                # the stream and go about our business.
                f = RstStreamFrame(frame.promised_stream_id)
                f.error_code = 7 # REFUSED_STREAM
                self._send_cb(f)

        # Work out to whom this frame should go.
        if frame.stream_id != 0:
            self.streams[frame.stream_id].receive_frame(frame)
        else:
            self.receive_frame(frame)


    # The following two methods are the implementation of the context manager
    # protocol.
    def __enter__(self):
        return self

    def __exit__(self, type, value, tb):
        self.close()
        return False  # Never swallow exceptions.

########NEW FILE########
__FILENAME__ = exceptions
# -*- coding: utf-8 -*-
"""
hyper/http20/exceptions
~~~~~~~~~~~~~~~~~~~~~~~

This defines exceptions used in the HTTP/2.0 portion of hyper.
"""
class HTTP20Error(Exception):
    """
    The base class for all of ``hyper``'s HTTP/2.0-related exceptions.
    """
    pass


class HPACKEncodingError(HTTP20Error):
    """
    An error has been encountered while performing HPACK encoding.
    """
    pass


class HPACKDecodingError(HTTP20Error):
    """
    An error has been encountered while performing HPACK decoding.
    """
    pass

class ConnectionError(HTTP20Error):
    """
    The remote party signalled an error affecting the entire HTTP/2.0
    connection, and the connection has been closed.
    """
    pass

########NEW FILE########
__FILENAME__ = frame
# -*- coding: utf-8 -*-
"""
hyper/http20/frame
~~~~~~~~~~~~~~~~~~

Defines framing logic for HTTP/2.0. Provides both classes to represent framed
data and logic for aiding the connection when it comes to reading from the
socket.
"""
import struct

# The maximum length of a frame. Some frames have shorter maximum lengths.
FRAME_MAX_LEN = (2 ** 14) - 1


class Frame(object):
    """
    The base class for all HTTP/2.0 frames.
    """
    # The flags defined on this type of frame.
    defined_flags = []

    # The type of the frame.
    type = -1

    def __init__(self, stream_id):
        self.stream_id = stream_id
        self.flags = set()

    @staticmethod
    def parse_frame_header(header):
        """
        Takes an 8-byte frame header and returns a tuple of the appropriate
        Frame object and the length that needs to be read from the socket.
        """
        fields = struct.unpack("!HBBL", header)
        length = fields[0] & 0x3FFF
        type = fields[1]
        flags = fields[2]
        stream_id = fields[3]

        frame = FRAMES[type](stream_id)
        frame.parse_flags(flags)
        return (frame, length)

    def parse_flags(self, flag_byte):
        for flag, flag_bit in self.defined_flags:
            if flag_byte & flag_bit:
                self.flags.add(flag)

        return self.flags

    def build_frame_header(self, length):
        # Build the common frame header.
        # First, get the flags.
        flags = 0

        for flag, flag_bit in self.defined_flags:
            if flag in self.flags:
                flags |= flag_bit

        header = struct.pack(
            "!HBBL",
            length & 0x3FFF,  # Length must have the top two bits unset.
            self.type,
            flags,
            self.stream_id & 0x7FFFFFFF  # Stream ID is 32 bits.
        )

        return header

    def serialize(self):
        raise NotImplementedError()

    def parse_body(self, data):
        raise NotImplementedError()


class DataFrame(Frame):
    """
    DATA frames convey arbitrary, variable-length sequences of octets
    associated with a stream. One or more DATA frames are used, for instance,
    to carry HTTP request or response payloads.
    """
    defined_flags = [('END_STREAM', 0x01)]

    type = 0

    def __init__(self, stream_id):
        super(DataFrame, self).__init__(stream_id)

        self.data = b''

        # Data frames may not be stream 0.
        if not self.stream_id:
            raise ValueError()

    def serialize(self):
        data = self.build_frame_header(len(self.data))
        data += self.data
        return data

    def parse_body(self, data):
        self.data = data


class PriorityFrame(Frame):
    """
    The PRIORITY frame specifies the sender-advised priority of a stream. It
    can be sent at any time for an existing stream. This enables
    reprioritisation of existing streams.
    """
    defined_flags = []

    type = 0x02

    def __init__(self, stream_id):
        super(PriorityFrame, self).__init__(stream_id)

        self.priority = 0

        if not stream_id:
            raise ValueError()

    def serialize(self):
        data = self.build_frame_header(4)
        data += struct.pack("!L", self.priority & 0x7FFFFFFF)
        return data

    def parse_body(self, data):
        if len(data) != 4:
            raise ValueError()

        self.priority = struct.unpack("!L", data)[0]


class RstStreamFrame(Frame):
    """
    The RST_STREAM frame allows for abnormal termination of a stream. When sent
    by the initiator of a stream, it indicates that they wish to cancel the
    stream or that an error condition has occurred. When sent by the receiver
    of a stream, it indicates that either the receiver is rejecting the stream,
    requesting that the stream be cancelled or that an error condition has
    occurred.
    """
    defined_flags = []

    type = 0x03

    def __init__(self, stream_id):
        super(RstStreamFrame, self).__init__(stream_id)

        self.error_code = 0

        if not stream_id:
            raise ValueError()

    def serialize(self):
        data = self.build_frame_header(4)
        data += struct.pack("!L", self.error_code)
        return data

    def parse_body(self, data):
        if len(data) != 4:
            raise ValueError()

        self.error_code = struct.unpack("!L", data)[0]


class SettingsFrame(Frame):
    """
    The SETTINGS frame conveys configuration parameters that affect how
    endpoints communicate. The parameters are either constraints on peer
    behavior or preferences.

    Settings are not negotiated. Settings describe characteristics of the
    sending peer, which are used by the receiving peer. Different values for
    the same setting can be advertised by each peer. For example, a client
    might set a high initial flow control window, whereas a server might set a
    lower value to conserve resources.
    """
    defined_flags = [('ACK', 0x01)]

    type = 0x04

    # We need to define the known settings, they may as well be class
    # attributes.
    HEADER_TABLE_SIZE      = 0x01
    ENABLE_PUSH            = 0x02
    MAX_CONCURRENT_STREAMS = 0x04
    INITIAL_WINDOW_SIZE    = 0x07
    FLOW_CONTROL_OPTIONS   = 0x0A

    def __init__(self, stream_id):
        super(SettingsFrame, self).__init__(stream_id)

        # A dictionary of the setting type byte to the value.
        self.settings = {}

        if stream_id:
            raise ValueError()

    def serialize(self):
        # Each setting consumes 8 bytes.
        length = len(self.settings) * 8

        data = self.build_frame_header(length)

        for setting, value in self.settings.items():
            data += struct.pack("!LL", setting & 0x00FFFFFF, value)

        return data

    def parse_body(self, data):
        for i in range(0, len(data), 8):
            name, value = struct.unpack("!LL", data[i:i+8])
            self.settings[name] = value


class PushPromiseFrame(Frame):
    """
    The PUSH_PROMISE frame is used to notify the peer endpoint in advance of
    streams the sender intends to initiate.
    """
    defined_flags = [('END_PUSH_PROMISE', 0x01)]

    type = 0x05

    def serialize(self):
        data = self.build_frame_header(len(self.data) + 4)
        data += struct.pack("!L", self.promised_stream_id)
        return b''.join([data, self.data])

    def parse_body(self, data):
        self.promised_stream_id, = struct.unpack("!L", data[:4])
        self.data = data[4:]


class PingFrame(Frame):
    """
    The PING frame is a mechanism for measuring a minimal round-trip time from
    the sender, as well as determining whether an idle connection is still
    functional. PING frames can be sent from any endpoint.
    """
    defined_flags = [('ACK', 0x01)]

    type = 0x06

    def __init__(self, stream_id):
        super(PingFrame, self).__init__(stream_id)

        self.opaque_data = b''

        if stream_id:
            raise ValueError()

    def serialize(self):
        if len(self.opaque_data) > 8:
            raise ValueError()

        data = self.build_frame_header(8)
        data += self.opaque_data
        data += b'\x00' * (8 - len(self.opaque_data))
        return data

    def parse_body(self, data):
        if len(data) > 8:
            raise ValueError()

        self.opaque_data = data


class GoAwayFrame(Frame):
    """
    The GOAWAY frame informs the remote peer to stop creating streams on this
    connection. It can be sent from the client or the server. Once sent, the
    sender will ignore frames sent on new streams for the remainder of the
    connection.
    """
    type = 0x07

    def __init__(self, stream_id):
        super(GoAwayFrame, self).__init__(stream_id)

        self.last_stream_id = 0
        self.error_code = 0
        self.additional_data = b''

        if stream_id:
            raise ValueError()

    def serialize(self):
        data = self.build_frame_header(8 + len(self.additional_data))
        data += struct.pack(
            "!LL",
            self.last_stream_id & 0x7FFFFFFF,
            self.error_code
        )
        data += self.additional_data

        return data

    def parse_body(self, data):
        self.last_stream_id, self.error_code = struct.unpack("!LL", data[:8])

        if len(data) > 8:
            self.additional_data = data[8:]


class WindowUpdateFrame(Frame):
    """
    The WINDOW_UPDATE frame is used to implement flow control.

    Flow control operates at two levels: on each individual stream and on the
    entire connection.

    Both types of flow control are hop by hop; that is, only between the two
    endpoints. Intermediaries do not forward WINDOW_UPDATE frames between
    dependent connections. However, throttling of data transfer by any receiver
    can indirectly cause the propagation of flow control information toward the
    original sender.
    """
    type = 0x09

    def __init__(self, stream_id):
        super(WindowUpdateFrame, self).__init__(stream_id)

        self.window_increment = 0

    def serialize(self):
        data = self.build_frame_header(4)
        data += struct.pack("!L", self.window_increment & 0x7FFFFFFF)

        return data

    def parse_body(self, data):
        self.window_increment = struct.unpack("!L", data)[0]


class HeadersFrame(DataFrame):
    """
    The HEADERS frame carries name-value pairs. It is used to open a stream.
    HEADERS frames can be sent on a stream in the "open" or "half closed
    (remote)" states.

    The HeadersFrame class is actually basically a data frame in this
    implementation, becuase of the requirement to control the sizes of frames.
    A header block fragment that doesn't fit in an entire HEADERS frame needs
    to be followed with CONTINUATION frames. From the perspective of the frame
    building code the header block is an opaque data segment.
    """
    type = 0x01

    defined_flags = [
        ('END_STREAM', 0x01),
        ('END_HEADERS', 0x04),
        ('PRIORITY', 0x08)
    ]

    def __init__(self, stream_id):
        super(HeadersFrame, self).__init__(stream_id)

        self.priority = None

    def serialize(self):
        if self.priority is None:
            data = self.build_frame_header(len(self.data))
        else:
            data = self.build_frame_header(len(self.data) + 4)
            data += struct.pack("!L", self.priority)

        data += self.data
        return data

    def parse_body(self, data):
        if 'PRIORITY' in self.flags:
            self.priority = struct.unpack("!L", data[:4])[0]
            data = data[4:]

        super(HeadersFrame, self).parse_body(data)


class ContinuationFrame(DataFrame):
    """
    The CONTINUATION frame is used to continue a sequence of header block
    fragments. Any number of CONTINUATION frames can be sent on an existing
    stream, as long as the preceding frame on the same stream is one of
    HEADERS, PUSH_PROMISE or CONTINUATION without the END_HEADERS or
    END_PUSH_PROMISE flag set.

    Much like the HEADERS frame, hyper treats this as an opaque data frame with
    different flags and a different type.
    """
    type = 0x0A

    defined_flags = [('END_HEADERS', 0x04)]


# A map of type byte to frame class.
FRAMES = {
    0x00: DataFrame,
    0x01: HeadersFrame,
    0x02: PriorityFrame,
    0x03: RstStreamFrame,
    0x04: SettingsFrame,
    0x05: PushPromiseFrame,
    0x06: PingFrame,
    0x07: GoAwayFrame,
    0x09: WindowUpdateFrame,
    0x0A: ContinuationFrame
}

########NEW FILE########
__FILENAME__ = hpack
# -*- coding: utf-8 -*-
"""
hyper/http20/hpack
~~~~~~~~~~~~~~~~~~

Implements the HPACK header compression algorithm as detailed by the IETF.

Implements the version dated January 9, 2014.
"""
import collections
import logging

from ..compat import to_byte
from .huffman import HuffmanDecoder, HuffmanEncoder
from hyper.http20.huffman_constants import (
    REQUEST_CODES, REQUEST_CODES_LENGTH, REQUEST_CODES, REQUEST_CODES_LENGTH
)
from .exceptions import HPACKEncodingError

log = logging.getLogger(__name__)


def encode_integer(integer, prefix_bits):
    """
    This encodes an integer according to the wacky integer encoding rules
    defined in the HPACK spec.
    """
    log.debug("Encoding %d with %d bits.", integer, prefix_bits)

    max_number = (2 ** prefix_bits) - 1

    if (integer < max_number):
        return bytearray([integer])  # Seriously?
    else:
        elements = [max_number]
        integer = integer - max_number

        while integer >= 128:
            elements.append((integer % 128) + 128)
            integer = integer // 128  # We need integer division

        elements.append(integer)

        return bytearray(elements)


def decode_integer(data, prefix_bits):
    """
    This decodes an integer according to the wacky integer encoding rules
    defined in the HPACK spec. Returns a tuple of the decoded integer and the
    number of bytes that were consumed from ``data`` in order to get that
    integer.
    """
    multiple = lambda index: 128 ** (index - 1)
    max_number = (2 ** prefix_bits) - 1
    mask = 0xFF >> (8 - prefix_bits)
    index = 0

    number = to_byte(data[index]) & mask

    if (number == max_number):

        while True:
            index += 1
            next_byte = to_byte(data[index])

            if next_byte >= 128:
                number += (next_byte - 128) * multiple(index)
            else:
                number += next_byte * multiple(index)
                break

    log.debug("Decoded %d consuming %d bytes.", number, index + 1)

    return (number, index + 1)


def _to_bytes(string):
    """
    Convert string to bytes.
    """
    if not isinstance(string, (str, bytes)):
        string = str(string)

    return string if isinstance(string, bytes) else string.encode('utf-8')


def header_table_size(table):
    """
    Calculates the 'size' of the header table as defined by the HTTP/2.0
    specification.
    """
    # It's phenomenally frustrating that the specification feels it is able to
    # tell me how large the header table is, considering that its calculations
    # assume a very particular layout that most implementations will not have.
    # I appreciate it's an attempt to prevent DoS attacks by sending lots of
    # large headers in the header table, but it seems like a better approach
    # would be to limit the size of headers. Ah well.
    return sum(32 + len(name) + len(value) for name, value in table)


class Encoder(object):
    """
    An HPACK encoder object. This object takes HTTP headers and emits encoded
    HTTP/2.0 header blocks.
    """
    # This is the static table of header fields.
    static_table = [
        (b':authority', b''),
        (b':method', b'GET'),
        (b':method', b'POST'),
        (b':path', b'/'),
        (b':path', b'/index.html'),
        (b':scheme', b'http'),
        (b':scheme', b'https'),
        (b':status', b'200'),
        (b':status', b'500'),
        (b':status', b'404'),
        (b':status', b'403'),
        (b':status', b'400'),
        (b':status', b'401'),
        (b'accept-charset', b''),
        (b'accept-encoding', b''),
        (b'accept-language', b''),
        (b'accept-ranges', b''),
        (b'accept', b''),
        (b'access-control-allow-origin', b''),
        (b'age', b''),
        (b'allow', b''),
        (b'authorization', b''),
        (b'cache-control', b''),
        (b'content-disposition', b''),
        (b'content-encoding', b''),
        (b'content-language', b''),
        (b'content-length', b''),
        (b'content-location', b''),
        (b'content-range', b''),
        (b'content-type', b''),
        (b'cookie', b''),
        (b'date', b''),
        (b'etag', b''),
        (b'expect', b''),
        (b'expires', b''),
        (b'from', b''),
        (b'host', b''),
        (b'if-match', b''),
        (b'if-modified-since', b''),
        (b'if-none-match', b''),
        (b'if-range', b''),
        (b'if-unmodified-since', b''),
        (b'last-modified', b''),
        (b'link', b''),
        (b'location', b''),
        (b'max-forwards', b''),
        (b'proxy-authenticate', b''),
        (b'proxy-authorization', b''),
        (b'range', b''),
        (b'referer', b''),
        (b'refresh', b''),
        (b'retry-after', b''),
        (b'server', b''),
        (b'set-cookie', b''),
        (b'strict-transport-security', b''),
        (b'transfer-encoding', b''),
        (b'user-agent', b''),
        (b'vary', b''),
        (b'via', b''),
        (b'www-authenticate', b''),
    ]

    def __init__(self):
        self.header_table = collections.deque()
        self.reference_set = set()
        self._header_table_size = 4096  # This value set by the standard.
        self.huffman_coder = HuffmanEncoder(
            REQUEST_CODES, REQUEST_CODES_LENGTH
        )

    @property
    def header_table_size(self):
        return self._header_table_size

    @header_table_size.setter
    def header_table_size(self, value):
        log.debug(
            "Setting header table size to %d from %d",
            value,
            self._header_table_size
        )

        # If the new value is larger than the current one, no worries!
        # Otherwise, we may need to shrink the header table.
        if value < self._header_table_size:
            current_size = header_table_size(self.header_table)

            while value < current_size:
                n, v = self.header_table.pop()
                current_size -= (
                    32 + len(n) + len(v)
                )

                # If something is removed from the header table, it also needs
                # to be removed from the reference set.
                self.reference_set.discard((n, v))

                log.debug(
                    "Removed %s: %s from the encoder header table", n, v
                )

        self._header_table_size = value

    def encode(self, headers, huffman=True):
        """
        Takes a set of headers and encodes them into a HPACK-encoded header
        block.

        Transforming the headers into a header block is a procedure that can
        be modeled as a chain or pipe. First, the headers are compared against
        the reference set. Any headers already in the reference set don't need
        to be emitted at all, they can be left alone. Headers not in the
        reference set need to be emitted. Headers in the reference set that
        need to be removed (potentially to be replaced) need to be emitted as
        well.

        Next, the headers are encoded. This encoding can be done a number of
        ways. If the header name-value pair are already in the header table we
        can represent them using the indexed representation: the same is true
        if they are in the static table. Otherwise, a literal representation
        will be used.

        Literal text values may optionally be Huffman encoded. For now we don't
        do that, because it's an extra bit of complication, but we will later.
        """
        log.debug("HPACK encoding %s", headers)

        # First, turn the headers into a list of tuples if possible. This is
        # the natural way to interact with them in HPACK.
        if isinstance(headers, dict):
            headers = headers.items()

        # Next, walk across the headers and turn them all into bytestrings.
        headers = [(_to_bytes(n), _to_bytes(v)) for n, v in headers]

        incoming_set = set(headers)

        # First, we need to determine what set of headers we need to emit.
        # We do this by comparing against the reference set.
        # Because the HPACK standard defines a header set as 'potentially
        # ordered', we should try to maintain their order. It's a hassle, but
        # there we go.
        to_add = (x for x in headers if x in incoming_set - self.reference_set)
        to_remove = (self.reference_set - incoming_set)

        # Now, serialize the headers. Do removal first.
        # If the list of headers we're removing is more than half of the
        # reference set, just emit an 'empty the reference set' message.
        if (len(self.reference_set - incoming_set) >
                                               (len(self.reference_set) // 2)):
            log.debug("Emptying the encoder reference set.")
            header_block = b'\x80\x80'  # Indexed representation of 0.

            # Remove everything from the reference set.
            self.reference_set = set()
        else:
            header_block = self.remove(to_remove)

        header_block += self.add(to_add, huffman)

        log.debug("Encoded header block to %s", header_block)

        return header_block

    def remove(self, to_remove):
        """
        This function takes a set of header key-value tuples and serializes
        them. These must be in the header table, so must be represented as
        their indexed form.
        """
        log.debug("Removing %s from the header table", to_remove)

        encoded = []

        for name, value in to_remove:
            try:
                index, perfect = self.matching_header(name, value)
            except TypeError:
                raise HPACKEncodingError(
                    '"%s: %s" not present in the header table' % (name, value)
                )

            # The header must be in the header block. That means that:
            # - perfect must be True
            # - index must be <= len(self.header_table)
            max_index = len(self.header_table)

            if (not perfect) or (index > max_index):
                raise HPACKEncodingError(
                    '"%s: %s" not present in the header table' % (name, value)
                )

            # We can safely encode this as the indexed representation.
            encoded.append(self._encode_indexed(index))

            # Having encoded it in the indexed form, we now remove it from the
            # reference set.
            self.reference_set.remove((name, value))

        return b''.join(encoded)

    def add(self, to_add, huffman=False):
        """
        This function takes a set of header key-value tuples and serializes
        them for adding to the header table.
        """
        log.debug("Adding %s to the header table", to_add)

        encoded = []

        for name, value in to_add:
            # Search for a matching header in the header table.
            match = self.matching_header(name, value)

            if match is None:
                # Not in the header table. Encode using the literal syntax,
                # and add it to the header table.
                s = self._encode_literal(name, value, True, huffman)
                encoded.append(s)
                self._add_to_header_table(name, value)
                self.reference_set.add((name, value))
                continue

            # The header is in the table, break out the values. If we matched
            # perfectly, we can use the indexed representation: otherwise we
            # can use the indexed literal.
            index, perfect = match

            if perfect:
                # Indexed representation. If the index is larger than the size
                # of the header table, also add to the header table.
                s = self._encode_indexed(index)
                encoded.append(s)

                if index > len(self.header_table):
                    self._add_to_header_table(name, value)

                self.reference_set.add((name, value))
            else:
                # Indexed literal. Since we have a partial match, don't add to
                # the header table, it won't help us.
                s = self._encode_indexed_literal(index, value, False, huffman)
                encoded.append(s)

        return b''.join(encoded)

    def matching_header(self, name, value):
        """
        Scans the header table and the static table. Returns a tuple, where the
        first value is the index of the match, and the second is whether there
        was a full match or not. Prefers full matches to partial ones.

        Upsettingly, the header table is one-indexed, not zero-indexed.
        """
        partial_match = None
        header_table_size = len(self.header_table)

        for (i, (n, v)) in enumerate(self.header_table):
            if n == name:
                if v == value:
                    return (i + 1, True)
                elif partial_match is None:
                    partial_match = (i + 1, False)

        for (i, (n, v)) in enumerate(Encoder.static_table):
            if n == name:
                if v == value:
                    return (i + header_table_size + 1, True)
                elif partial_match is None:
                    partial_match = (i + header_table_size + 1, False)

        return partial_match

    def _add_to_header_table(self, name, value):
        """
        Adds a header to the header table, evicting old ones if necessary.
        """
        # Be optimistic: add the header straight away.
        self.header_table.appendleft((name, value))

        # Now, work out how big the header table is.
        actual_size = header_table_size(self.header_table)

        # Loop and remove whatever we need to.
        while actual_size > self.header_table_size:
            n, v = self.header_table.pop()
            actual_size -= (
                32 + len(n) + len(v)
            )

            # If something is removed from the header table, it also needs to
            # be removed from the reference set.
            self.reference_set.discard((n, v))

            log.debug("Evicted %s: %s from the header table", n, v)

    def _encode_indexed(self, index):
        """
        Encodes a header using the indexed representation.
        """
        field = encode_integer(index, 7)
        field[0] = field[0] | 0x80  # we set the top bit
        return bytes(field)

    def _encode_literal(self, name, value, indexing, huffman=False):
        """
        Encodes a header with a literal name and literal value. If ``indexing``
        is True, the header will be added to the header table: otherwise it
        will not.
        """
        prefix = b'\x00' if indexing else b'\x40'

        if huffman:
            name = self.huffman_coder.encode(name)
            value = self.huffman_coder.encode(value)

        name_len = encode_integer(len(name), 7)
        value_len = encode_integer(len(value), 7)

        if huffman:
            name_len[0] |= 0x80
            value_len[0] |= 0x80

        return b''.join([prefix, bytes(name_len), name, bytes(value_len), value])

    def _encode_indexed_literal(self, index, value, indexing, huffman=False):
        """
        Encodes a header with an indexed name and a literal value. If
        ``indexing`` is True, the header will be added to the header table:
        otherwise it will not.
        """
        mask = 0x00 if indexing else 0x40

        name = encode_integer(index, 6)
        name[0] = name[0] | mask

        if huffman:
            value = self.huffman_coder.encode(value)

        value_len = encode_integer(len(value), 7)

        if huffman:
            value_len[0] |= 0x80

        return b''.join([bytes(name), bytes(value_len), value])


class Decoder(object):
    """
    An HPACK decoder object.
    """
    static_table = []    # This is the static table of header fields.
    static_table = [
        (b':authority', b''),
        (b':method', b'GET'),
        (b':method', b'POST'),
        (b':path', b'/'),
        (b':path', b'/index.html'),
        (b':scheme', b'http'),
        (b':scheme', b'https'),
        (b':status', b'200'),
        (b':status', b'500'),
        (b':status', b'404'),
        (b':status', b'403'),
        (b':status', b'400'),
        (b':status', b'401'),
        (b'accept-charset', b''),
        (b'accept-encoding', b''),
        (b'accept-language', b''),
        (b'accept-ranges', b''),
        (b'accept', b''),
        (b'access-control-allow-origin', b''),
        (b'age', b''),
        (b'allow', b''),
        (b'authorization', b''),
        (b'cache-control', b''),
        (b'content-disposition', b''),
        (b'content-encoding', b''),
        (b'content-language', b''),
        (b'content-length', b''),
        (b'content-location', b''),
        (b'content-range', b''),
        (b'content-type', b''),
        (b'cookie', b''),
        (b'date', b''),
        (b'etag', b''),
        (b'expect', b''),
        (b'expires', b''),
        (b'from', b''),
        (b'host', b''),
        (b'if-match', b''),
        (b'if-modified-since', b''),
        (b'if-none-match', b''),
        (b'if-range', b''),
        (b'if-unmodified-since', b''),
        (b'last-modified', b''),
        (b'link', b''),
        (b'location', b''),
        (b'max-forwards', b''),
        (b'proxy-authenticate', b''),
        (b'proxy-authorization', b''),
        (b'range', b''),
        (b'referer', b''),
        (b'refresh', b''),
        (b'retry-after', b''),
        (b'server', b''),
        (b'set-cookie', b''),
        (b'strict-transport-security', b''),
        (b'transfer-encoding', b''),
        (b'user-agent', b''),
        (b'vary', b''),
        (b'via', b''),
        (b'www-authenticate', b''),
    ]

    def __init__(self):
        self.header_table = collections.deque()
        self.reference_set = set()
        self._header_table_size = 4096  # This value set by the standard.
        self.huffman_coder = HuffmanDecoder(
            REQUEST_CODES, REQUEST_CODES_LENGTH
        )

    @property
    def header_table_size(self):
        return self._header_table_size

    @header_table_size.setter
    def header_table_size(self, value):
        log.debug(
            "Resizing decoder header table to %d from %d",
            value,
            self._header_table_size
        )

        # If the new value is larger than the current one, no worries!
        # Otherwise, we may need to shrink the header table.
        if value < self._header_table_size:
            current_size = header_table_size(self.header_table)

            while value < current_size:
                n, v = self.header_table.pop()
                current_size -= (
                    32 + len(n) + len(v)
                )

                # If something is removed from the header table, it also needs
                # to be removed from the reference set.
                self.reference_set.discard((n, v))

                log.debug("Evicting %s: %s from the header table", n, v)

        self._header_table_size = value

    def decode(self, data):
        """
        Takes an HPACK-encoded header block and decodes it into a header set.
        """
        log.debug("Decoding %s", data)

        headers = set()
        data_len = len(data)
        current_index = 0

        while current_index < data_len:
            # Work out what kind of header we're decoding.
            # If the high bit is 1, it's an indexed field.
            current = to_byte(data[current_index])
            indexed = bool(current & 0x80)

            # Otherwise, if the second-highest bit is 1 it's a field that
            # doesn't alter the header table.
            literal_no_index = bool(current & 0x40)

            if indexed:
                header, consumed = self._decode_indexed(data[current_index:])
            elif literal_no_index:
                header, consumed = self._decode_literal_no_index(
                    data[current_index:]
                )
            else:
                # It's a literal header that does affect the header table.
                header, consumed = self._decode_literal_index(
                    data[current_index:]
                )

            if header:
                headers.add(header)

            current_index += consumed

        # Now we're at the end, anything in the reference set that isn't in the
        # headers already gets added.
        headers = headers | self.reference_set

        return {(n.decode('utf-8'), v.decode('utf-8')) for n, v in headers}

    def _add_to_header_table(self, name, value):
        """
        Adds a header to the header table, evicting old ones if necessary.
        """
        # Be optimistic: add the header straight away.
        self.header_table.appendleft((name, value))

        # Now, work out how big the header table is.
        actual_size = header_table_size(self.header_table)

        # Loop and remove whatever we need to.
        while actual_size > self.header_table_size:
            n, v = self.header_table.pop()
            actual_size -= (
                32 + len(n) + len(v)
            )

            # If something is removed from the header table, it also needs to
            # be removed from the reference set.
            self.reference_set.discard((n, v))

            log.debug("Evicting %s: %s from the header table", n, v)

    def _decode_indexed(self, data):
        """
        Decodes a header represented using the indexed representation.
        """
        index, consumed = decode_integer(data, 7)

        # If we get an indexed representation of zero, check the next octet.
        # If the next octet is has its high bit set to 1, empty the reference
        # set. Otherwise, decode it as an integer with a 7-bit prefix: that's
        # our new header table max size.
        if not index:
            next_byte = to_byte(data[consumed])

            if next_byte & 0x80:
                self.reference_set = set()
                consumed += 1
            else:
                size, additional_consumed = decode_integer(data[consumed:], 7)
                consumed += additional_consumed
                self.header_table_size = size

            return None, consumed

        index -= 1  # Because this idiot table is 1-indexed. Ugh.

        if index > len(self.header_table):
            index -= len(self.header_table)
            header = Decoder.static_table[index]

            # If this came out of the static table, we need to add it to the
            #Â header table.
            self._add_to_header_table(*header)
        else:
            header = self.header_table[index]

        # If the header is in the reference set, remove it. Otherwise, add it.
        # Since this updates the reference set, don't bother returning the
        #Â header.
        if header in self.reference_set:
            log.debug(
                "Removed %s from the reference set, consumed %d",
                header,
                consumed
            )
            self.reference_set.remove(header)
            return None, consumed
        else:
            log.debug("Decoded %s, consumed %d", header, consumed)
            self.reference_set.add(header)
            return header, consumed


    def _decode_literal_no_index(self, data):
        return self._decode_literal(data, False)

    def _decode_literal_index(self, data):
        return self._decode_literal(data, True)

    def _decode_literal(self, data, should_index):
        """
        Decodes a header represented with a literal.
        """
        total_consumed = 0

        # If the low six bits of the first byte are nonzero, the header
        #Â name is indexed.
        first_byte = to_byte(data[0])

        if first_byte & 0x3F:
            # Indexed header name.
            index, consumed = decode_integer(data, 6)
            index -= 1

            if index >= len(self.header_table):
                index -= len(self.header_table)
                name = Decoder.static_table[index][0]
            else:
                name = self.header_table[index][0]

            total_consumed = consumed
            length = 0
        else:
            # Literal header name. The first byte was zero, so we need to
            # move forward.
            data = data[1:]

            length, consumed = decode_integer(data, 7)
            name = data[consumed:consumed + length]

            if to_byte(data[0]) & 0x80:
                name = self.huffman_coder.decode(name)
            total_consumed = consumed + length + 1  # Since we moved forward 1.

        data = data[consumed + length:]

        # The header value is definitely length-based.
        length, consumed = decode_integer(data, 7)
        value = data[consumed:consumed + length]

        if to_byte(data[0]) & 0x80:
            value = self.huffman_coder.decode(value)

        # Updated the total consumed length.
        total_consumed += length + consumed

        # If we've been asked to index this, add it to the header table and
        # the reference set.
        if should_index:
            self._add_to_header_table(name, value)
            self.reference_set.add((name, value))

        header = (name, value)

        log.debug(
            "Decoded %s, consumed %d, indexed %s",
            header,
            consumed,
            should_index
        )

        return header, total_consumed

########NEW FILE########
__FILENAME__ = huffman
# -*- coding: utf-8 -*-
"""
hyper/http20/huffman_decoder
~~~~~~~~~~~~~~~~~~~~~~~~~~~

An implementation of a bitwise prefix tree specially built for decoding
Huffman-coded content where we already know the Huffman table.
"""
from ..compat import to_byte, decode_hex
from .exceptions import HPACKDecodingError

def _pad_binary(bin_str, req_len=8):
    """
    Given a binary string (returned by bin()), pad it to a full byte length.
    """
    bin_str = bin_str[2:]  # Strip the 0b prefix
    return max(0, req_len - len(bin_str)) * '0' + bin_str

def _hex_to_bin_str(hex_string):
    """
    Given a Python bytestring, returns a string representing those bytes in
    unicode form.
    """
    unpadded_bin_string_list = (bin(to_byte(c)) for c in hex_string)
    padded_bin_string_list = map(_pad_binary, unpadded_bin_string_list)
    bitwise_message = "".join(padded_bin_string_list)
    return bitwise_message


class HuffmanDecoder(object):
    """
    Decodes a Huffman-coded bytestream according to the Huffman table laid out
    in the HPACK specification.
    """
    class _Node(object):
        def __init__(self, data):
            self.data = data
            self.mapping = {}

    def __init__(self, huffman_code_list, huffman_code_list_lengths):
        self.root = self._Node(None)
        for index, (huffman_code, code_length) in enumerate(zip(huffman_code_list, huffman_code_list_lengths)):
            self._insert(huffman_code, code_length, index)

    def _insert(self, hex_number, hex_length, letter):
        """
        Inserts a Huffman code point into the tree.
        """
        hex_number = _pad_binary(bin(hex_number), hex_length)
        cur_node = self.root
        for digit in hex_number:
            if digit not in cur_node.mapping:
                cur_node.mapping[digit] = self._Node(None)
            cur_node = cur_node.mapping[digit]
        cur_node.data = letter

    def decode(self, encoded_string):
        """
        Decode the given Huffman coded string.
        """
        number = _hex_to_bin_str(encoded_string)
        cur_node = self.root
        decoded_message = bytearray()

        try:
            for digit in number:
                cur_node = cur_node.mapping[digit]
                if cur_node.data is not None:
                    # If we get EOS, everything else is padding.
                    if cur_node.data == 256:
                        break

                    decoded_message.append(cur_node.data)
                    cur_node = self.root
        except KeyError:
            # We have a Huffman-coded string that doesn't match our trie. This
            # is pretty bad: raise a useful exception.
            raise HPACKDecodingError("Invalid Huffman-coded string received.")
        return bytes(decoded_message)


class HuffmanEncoder(object):
    """
    Encodes a string according to the Huffman encoding table defined in the
    HPACK specification.
    """
    def __init__(self, huffman_code_list, huffman_code_list_lengths):
        self.huffman_code_list = huffman_code_list
        self.huffman_code_list_lengths = huffman_code_list_lengths

    def encode(self, bytes_to_encode):
        """
        Given a string of bytes, encodes them according to the HPACK Huffman
        specification.
        """
        # If handed the empty string, just immediately return.
        if not bytes_to_encode:
            return b''

        final_num = 0
        final_int_len = 0

        # Turn each byte into its huffman code. These codes aren't necessarily
        # octet aligned, so keep track of how far through an octet we are. To
        # handle this cleanly, just use a single giant integer.
        for char in bytes_to_encode:
            byte = to_byte(char)
            bin_int_len = self.huffman_code_list_lengths[byte]
            bin_int = self.huffman_code_list[byte] & (2 ** (bin_int_len + 1) - 1)
            final_num <<= bin_int_len
            final_num |= bin_int
            final_int_len += bin_int_len

        # Pad out to an octet with ones.
        bits_to_be_padded = (8 - (final_int_len % 8)) % 8
        final_num <<= bits_to_be_padded
        final_num |= (1 << (bits_to_be_padded)) - 1

        # Convert the number to hex and strip off the leading '0x' and the
        # trailing 'L', if present.
        final_num = hex(final_num)[2:].rstrip('L')

        # If this is odd, prepend a zero.
        final_num = '0' + final_num if len(final_num) % 2 != 0 else final_num

        return decode_hex(final_num)

########NEW FILE########
__FILENAME__ = huffman_constants
# -*- coding: utf-8 -*-
"""
hyper/http20/huffman_constants
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Defines the constant Huffman table. This takes up an upsetting amount of space,
but c'est la vie.
"""

REQUEST_CODES = [
      0x7ffffba,
      0x7ffffbb,
      0x7ffffbc,
      0x7ffffbd,
      0x7ffffbe,
      0x7ffffbf,
      0x7ffffc0,
      0x7ffffc1,
      0x7ffffc2,
      0x7ffffc3,
      0x7ffffc4,
      0x7ffffc5,
      0x7ffffc6,
      0x7ffffc7,
      0x7ffffc8,
      0x7ffffc9,
      0x7ffffca,
      0x7ffffcb,
      0x7ffffcc,
      0x7ffffcd,
      0x7ffffce,
      0x7ffffcf,
      0x7ffffd0,
      0x7ffffd1,
      0x7ffffd2,
      0x7ffffd3,
      0x7ffffd4,
      0x7ffffd5,
      0x7ffffd6,
      0x7ffffd7,
      0x7ffffd8,
      0x7ffffd9,
      0xe8,
      0xffc,
      0x3ffa,
      0x7ffc,
      0x7ffd,
      0x24,
      0x6e,
      0x7ffe,
      0x7fa,
      0x7fb,
      0x3fa,
      0x7fc,
      0xe9,
      0x25,
      0x4,
      0x0,
      0x5,
      0x6,
      0x7,
      0x26,
      0x27,
      0x28,
      0x29,
      0x2a,
      0x2b,
      0x2c,
      0x1ec,
      0xea,
      0x3fffe,
      0x2d,
      0x1fffc,
      0x1ed,
      0x3ffb,
      0x6f,
      0xeb,
      0xec,
      0xed,
      0xee,
      0x70,
      0x1ee,
      0x1ef,
      0x1f0,
      0x1f1,
      0x3fb,
      0x1f2,
      0xef,
      0x1f3,
      0x1f4,
      0x1f5,
      0x1f6,
      0x1f7,
      0xf0,
      0xf1,
      0x1f8,
      0x1f9,
      0x1fa,
      0x1fb,
      0x1fc,
      0x3fc,
      0x3ffc,
      0x7ffffda,
      0x1ffc,
      0x3ffd,
      0x2e,
      0x7fffe,
      0x8,
      0x2f,
      0x9,
      0x30,
      0x1,
      0x31,
      0x32,
      0x33,
      0xa,
      0x71,
      0x72,
      0xb,
      0x34,
      0xc,
      0xd,
      0xe,
      0xf2,
      0xf,
      0x10,
      0x11,
      0x35,
      0x73,
      0x36,
      0xf3,
      0xf4,
      0xf5,
      0x1fffd,
      0x7fd,
      0x1fffe,
      0xffd,
      0x7ffffdb,
      0x7ffffdc,
      0x7ffffdd,
      0x7ffffde,
      0x7ffffdf,
      0x7ffffe0,
      0x7ffffe1,
      0x7ffffe2,
      0x7ffffe3,
      0x7ffffe4,
      0x7ffffe5,
      0x7ffffe6,
      0x7ffffe7,
      0x7ffffe8,
      0x7ffffe9,
      0x7ffffea,
      0x7ffffeb,
      0x7ffffec,
      0x7ffffed,
      0x7ffffee,
      0x7ffffef,
      0x7fffff0,
      0x7fffff1,
      0x7fffff2,
      0x7fffff3,
      0x7fffff4,
      0x7fffff5,
      0x7fffff6,
      0x7fffff7,
      0x7fffff8,
      0x7fffff9,
      0x7fffffa,
      0x7fffffb,
      0x7fffffc,
      0x7fffffd,
      0x7fffffe,
      0x7ffffff,
      0x3ffff80,
      0x3ffff81,
      0x3ffff82,
      0x3ffff83,
      0x3ffff84,
      0x3ffff85,
      0x3ffff86,
      0x3ffff87,
      0x3ffff88,
      0x3ffff89,
      0x3ffff8a,
      0x3ffff8b,
      0x3ffff8c,
      0x3ffff8d,
      0x3ffff8e,
      0x3ffff8f,
      0x3ffff90,
      0x3ffff91,
      0x3ffff92,
      0x3ffff93,
      0x3ffff94,
      0x3ffff95,
      0x3ffff96,
      0x3ffff97,
      0x3ffff98,
      0x3ffff99,
      0x3ffff9a,
      0x3ffff9b,
      0x3ffff9c,
      0x3ffff9d,
      0x3ffff9e,
      0x3ffff9f,
      0x3ffffa0,
      0x3ffffa1,
      0x3ffffa2,
      0x3ffffa3,
      0x3ffffa4,
      0x3ffffa5,
      0x3ffffa6,
      0x3ffffa7,
      0x3ffffa8,
      0x3ffffa9,
      0x3ffffaa,
      0x3ffffab,
      0x3ffffac,
      0x3ffffad,
      0x3ffffae,
      0x3ffffaf,
      0x3ffffb0,
      0x3ffffb1,
      0x3ffffb2,
      0x3ffffb3,
      0x3ffffb4,
      0x3ffffb5,
      0x3ffffb6,
      0x3ffffb7,
      0x3ffffb8,
      0x3ffffb9,
      0x3ffffba,
      0x3ffffbb,
      0x3ffffbc,
      0x3ffffbd,
      0x3ffffbe,
      0x3ffffbf,
      0x3ffffc0,
      0x3ffffc1,
      0x3ffffc2,
      0x3ffffc3,
      0x3ffffc4,
      0x3ffffc5,
      0x3ffffc6,
      0x3ffffc7,
      0x3ffffc8,
      0x3ffffc9,
      0x3ffffca,
      0x3ffffcb,
      0x3ffffcc,
      0x3ffffcd,
      0x3ffffce,
      0x3ffffcf,
      0x3ffffd0,
      0x3ffffd1,
      0x3ffffd2,
      0x3ffffd3,
      0x3ffffd4,
      0x3ffffd5,
      0x3ffffd6,
      0x3ffffd7,
      0x3ffffd8,
      0x3ffffd9,
      0x3ffffda,
      0x3ffffdb,
      0x3ffffdc,
]

REQUEST_CODES_LENGTH = [
      27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,
      27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,
       8, 12, 14, 15, 15,  6,  7, 15, 11, 11, 10, 11,  8,  6,  5,  4,
       5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  9,  8, 18,  6, 17,  9,
      14,  7,  8,  8,  8,  8,  7,  9,  9,  9,  9, 10,  9,  8,  9,  9,
       9,  9,  9,  8,  8,  9,  9,  9,  9,  9, 10, 14, 27, 13, 14,  6,
      19,  5,  6,  5,  6,  4,  6,  6,  6,  5,  7,  7,  5,  6,  5,  5,
       5,  8,  5,  5,  5,  6,  7,  6,  8,  8,  8, 17, 11, 17, 12, 27,
      27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,
      27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,
      27, 27, 27, 27, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,
      26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,
      26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,
      26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,
      26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,
      26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26,
      26,
]

########NEW FILE########
__FILENAME__ = response
# -*- coding: utf-8 -*-
"""
hyper/http20/response
~~~~~~~~~~~~~~~~~~~~~

Contains the HTTP/2.0 equivalent of the HTTPResponse object defined in
httplib/http.client.
"""
import zlib

from .util import pop_from_key_value_set


class DeflateDecoder(object):
    """
    This is a decoding object that wraps ``zlib`` and is used for decoding
    deflated content.

    This rationale for the existence of this object is pretty unpleasant.
    The HTTP RFC specifies that 'deflate' is a valid content encoding. However,
    the spec _meant_ the zlib encoding form. Unfortunately, people who didn't
    read the RFC very carefully actually implemented a different form of
    'deflate'. Insanely, ``zlib`` handles them using two wbits values. This is
    such a mess it's hard to adequately articulate.

    This class was lovingly borrowed from the excellent urllib3 library under
    license: see NOTICES. If you ever see @shazow, you should probably buy him
    a drink or something.
    """
    def __init__(self):
        self._first_try = True
        self._data = b''
        self._obj = zlib.decompressobj(zlib.MAX_WBITS)

    def __getattr__(self, name):
        return getattr(self._obj, name)

    def decompress(self, data):
        if not self._first_try:
            return self._obj.decompress(data)

        self._data += data
        try:
            return self._obj.decompress(data)
        except zlib.error:
            self._first_try = False
            self._obj = zlib.decompressobj(-zlib.MAX_WBITS)
            try:
                return self.decompress(self._data)
            finally:
                self._data = None


class Headers(object):
    def __init__(self, pairs):
        # This conversion to dictionary is unwise, as there may be repeated
        # keys, but it's acceptable for an early alpha.
        self._headers = dict(pairs)

    def getheader(self, name, default=None):
        return self._headers.get(name, default)

    def getheaders(self):
        return list(self._headers.items())

    def items(self):
        return self._headers.items()


class HTTP20Response(object):
    """
    An ``HTTP20Response`` wraps the HTTP/2.0 response from the server. It
    provides access to the response headers and the entity body. The response
    is an iterable object and can be used in a with statement (though due to
    the persistent connections used in HTTP/2.0 this has no effect, and is done
    soley for compatibility).
    """
    def __init__(self, headers, stream):
        #: The reason phrase returned by the server. This is not used in
        #: HTTP/2.0, and so is always the empty string.
        self.reason = ''

        status = pop_from_key_value_set(headers, ':status')[0]

        #: The status code returned by the server.
        self.status = int(status)

        # The response headers. These are determined upon creation, assigned
        # once, and never assigned again.
        self._headers = Headers(headers)

        # The stream this response is being sent over.
        self._stream = stream

        # We always read in one-data-frame increments from the stream, so we
        # may need to buffer some for incomplete reads.
        self._data_buffer = b''

        # This object is used for decompressing gzipped request bodies. Right
        # now we only support gzip because that's all the RFC mandates of us.
        # Later we'll add support for more encodings.
        # This 16 + MAX_WBITS nonsense is to force gzip. See this
        # Stack Overflow answer for more:
        # http://stackoverflow.com/a/2695466/1401686
        if self._headers.getheader('content-encoding') == 'gzip':
            self._decompressobj = zlib.decompressobj(16 + zlib.MAX_WBITS)
        elif self._headers.getheader('content-encoding') == 'deflate':
            self._decompressobj = DeflateDecoder()
        else:
            self._decompressobj = None

    def read(self, amt=None, decode_content=True):
        """
        Reads the response body, or up to the next ``amt`` bytes.

        :param amt: (optional) The amount of data to read. If not provided, all
            the data will be read from the response.
        :param decode_content: (optional) If ``True``, will transparently
            decode the response data.
        :returns: The read data. Note that if ``decode_content`` is set to
            ``True``, the actual amount of data returned may be different to
            the amount requested.
        """
        if amt is not None and amt <= len(self._data_buffer):
            data = self._data_buffer[:amt]
            self._data_buffer = self._data_buffer[amt:]
            response_complete = False
        elif amt is not None:
            read_amt = amt - len(self._data_buffer)
            self._data_buffer += self._stream._read(read_amt)
            data = self._data_buffer[:amt]
            self._data_buffer = self._data_buffer[amt:]
            response_complete = len(data) < amt
        else:
            data = b''.join([self._data_buffer, self._stream._read()])
            response_complete = True

        # We may need to decode the body.
        if decode_content and self._decompressobj and data:
            data = self._decompressobj.decompress(data)

        # If we're at the end of the request, we have some cleaning up to do.
        # Close the stream, and if necessary flush the buffer.
        if response_complete:
            if decode_content and self._decompressobj:
                data += self._decompressobj.flush()

        if not data:
            self.close()

        return data

    def getheader(self, name, default=None):
        """
        Return the value of the header ``name``, or ``default`` if there is no
        header matching ``name``. If there is more than one header with the
        value ``name``, return all of the values joined by ', '. If ``default``
        is any iterable other than a single string, its elements are similarly
        returned joined by commas.

        :param name: The name of the header to get the value of.
        :param default: (optional) The return value if the header wasn't sent.
        :returns: The value of the header.
        """
        return self._headers.getheader(name, default)

    def getheaders(self):
        """
        Get all the headers sent on the response.

        :returns: A list of (header, value) tuples.
        """
        return list(self._headers.items())

    def fileno(self):
        """
        Return the ``fileno`` of the underlying socket. This function is
        currently not implemented.
        """
        raise NotImplementedError("Not currently implemented.")

    def close(self):
        """
        Close the response. In effect this closes the backing HTTP/2.0 stream.

        :returns: Nothing.
        """
        self._stream.close()

    # The following methods implement the context manager protocol.
    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close()
        return False  # Never swallow exceptions.


class HTTP20Push(object):
    """
    Represents a request-response pair sent by the server through the server
    push mechanism.
    """
    def __init__(self, request_headers, stream):
        scheme, method, authority, path = (
            pop_from_key_value_set(request_headers,
                                   ':scheme', ':method', ':authority', ':path')
        )
        #: The scheme of the simulated request
        self.scheme = scheme
        #: The method of the simulated request (must be safe and cacheable, e.g. GET)
        self.method = method
        #: The authority of the simulated request (usually host:port)
        self.authority = authority
        #: The path of the simulated request
        self.path = path

        self._request_headers = Headers(request_headers)
        self._stream = stream

    def getrequestheader(self, name, default=None):
        """
        Return the value of the simulated request header ``name``, or ``default``
        if there is no header matching ``name``. If there is more than one header
        with the value ``name``, return all of the values joined by ', '. If
        ``default`` is any iterable other than a single string, its elements are
        similarly returned joined by commas.

        :param name: The name of the header to get the value of.
        :param default: (optional) The return value if the header wasn't sent.
        :returns: The value of the header.
        """
        return self._request_headers.getheader(name, default)

    def getrequestheaders(self):
        """
        Get all the simulated request headers.

        :returns: A list of (header, value) tuples.
        """
        return self._request_headers.getheaders()

    def getresponse(self):
        """
        Returns an :class:`HTTP20Response` object representing the pushed
        response.
        """
        return HTTP20Response(self._stream.getheaders(), self._stream)

    def cancel(self):
        """
        Cancel the pushed response and close the stream.
        """
        self._stream.close(8) # CANCEL

########NEW FILE########
__FILENAME__ = stream
# -*- coding: utf-8 -*-
"""
hyper/http20/stream
~~~~~~~~~~~~~~~~~~~

Objects that make up the stream-level abstraction of hyper's HTTP/2.0 support.

These objects are not expected to be part of the public HTTP/2.0 API: they're
intended purely for use inside hyper's HTTP/2.0 abstraction.

Conceptually, a single HTTP/2.0 connection is made up of many streams: each
stream is an independent, bi-directional sequence of HTTP headers and data.
Each stream is identified by a monotonically increasing integer, assigned to
the stream by the endpoint that initiated the stream.
"""
from .frame import (
    FRAME_MAX_LEN, HeadersFrame, DataFrame, PushPromiseFrame, WindowUpdateFrame,
    ContinuationFrame,
)
from .util import get_from_key_value_set
import collections


# Define a set of states for a HTTP/2.0 stream.
STATE_IDLE               = 0
STATE_OPEN               = 1
STATE_HALF_CLOSED_LOCAL  = 2
STATE_HALF_CLOSED_REMOTE = 3
STATE_CLOSED             = 4


# Define the largest chunk of data we'll send in one go. Realistically, we
# should take the MSS into account but that's pretty dull, so let's just say
# 1kB and call it a day.
MAX_CHUNK = 1024


class Stream(object):
    """
    A single HTTP/2.0 stream.

    A stream is an independent, bi-directional sequence of HTTP headers and
    data. Each stream is identified by a single integer. From a HTTP
    perspective, a stream _approximately_ matches a single request-response
    pair.
    """
    def __init__(self,
                 stream_id,
                 data_cb,
                 recv_cb,
                 close_cb,
                 header_encoder,
                 header_decoder,
                 window_manager,
                 local_closed=False):
        self.stream_id = stream_id
        self.state = STATE_HALF_CLOSED_LOCAL if local_closed else STATE_IDLE
        self.headers = []

        # Set to a key-value set of the response headers once their
        # HEADERS..CONTINUATION frame sequence finishes.
        self.response_headers = None

        # A dict mapping the promised stream ID of a pushed resource to a
        # key-value set of its request headers. Entries are added once their
        # PUSH_PROMISE..CONTINUATION frame sequence finishes.
        self.promised_headers = {}

        # Chunks of encoded header data from the current
        # (HEADERS|PUSH_PROMISE)..CONTINUATION frame sequence. Since sending any
        # frame other than a CONTINUATION is disallowed while a header block is
        # being transmitted, this and ``promised_stream_id`` are the only pieces
        # of state we have to track.
        self.header_data = []
        self.promised_stream_id = None

        # Unconsumed response data chunks. Empties after every call to _read().
        self.data = []

        # There are two flow control windows: one for data we're sending,
        # one for data being sent to us.
        self._in_window_manager = window_manager
        self._out_flow_control_window = 65535

        # This is the callback handed to the stream by its parent connection.
        # It is called when the stream wants to send data. It expects to
        # receive a list of frames that will be automatically serialized.
        self._data_cb = data_cb

        # Similarly, this is a callback that reads one frame off the
        # connection.
        self._recv_cb = recv_cb

        # This is the callback to be called when the stream is closed.
        self._close_cb = close_cb

        # A reference to the header encoder and decoder objects belonging to
        # the parent connection.
        self._encoder = header_encoder
        self._decoder = header_decoder

    def add_header(self, name, value):
        """
        Adds a single HTTP header to the headers to be sent on the request.
        """
        self.headers.append((name.lower(), value))

    def send_data(self, data, final):
        """
        Send some data on the stream. If this is the end of the data to be
        sent, the ``final`` flag _must_ be set to True. If no data is to be
        sent, set ``data`` to ``None``.
        """
        # Define a utility iterator for file objects.
        def file_iterator(fobj):
            while True:
                data = fobj.read(MAX_CHUNK)
                yield data
                if len(data) < MAX_CHUNK:
                    break

        # Build the appropriate iterator for the data, in chunks of CHUNK_SIZE.
        if hasattr(data, 'read'):
            chunks = file_iterator(data)
        else:
            chunks = (data[i:i+MAX_CHUNK]
                      for i in range(0, len(data), MAX_CHUNK))

        for chunk in chunks:
            self._send_chunk(chunk, final)

    @property
    def _local_closed(self):
        return self.state in (STATE_CLOSED, STATE_HALF_CLOSED_LOCAL)

    @property
    def _remote_closed(self):
        return self.state in (STATE_CLOSED, STATE_HALF_CLOSED_REMOTE)

    @property
    def _local_open(self):
        return self.state in (STATE_OPEN, STATE_HALF_CLOSED_REMOTE)

    def _close_local(self):
        self.state = (
            STATE_HALF_CLOSED_LOCAL if self.state == STATE_OPEN
            else STATE_CLOSED
        )

    def _close_remote(self):
        self.state = (
            STATE_HALF_CLOSED_REMOTE if self.state == STATE_OPEN
            else STATE_CLOSED
        )

    def _read(self, amt=None):
        """
        Read data from the stream. Unlike a normal read behaviour, this
        function returns _at least_ ``amt`` data, but may return more.
        """
        def listlen(list):
            return sum(map(len, list))

        # Keep reading until the stream is closed or we get enough data.
        while not self._remote_closed and (amt is None or listlen(self.data) < amt):
            self._recv_cb()

        result = b''.join(self.data)
        self.data = []
        return result

    def receive_frame(self, frame):
        """
        Handle a frame received on this stream.
        """
        if 'END_STREAM' in frame.flags:
            self._close_remote()

        if isinstance(frame, WindowUpdateFrame):
            self._out_flow_control_window += frame.window_increment
        elif isinstance(frame, HeadersFrame):
            # Begin the header block for the response headers.
            self.promised_stream_id = None
            self.header_data = [frame.data]
        elif isinstance(frame, PushPromiseFrame):
            # Begin a header block for the request headers of a pushed resource.
            self.promised_stream_id = frame.promised_stream_id
            self.header_data = [frame.data]
        elif isinstance(frame, ContinuationFrame):
            # Continue a header block begun with either HEADERS or PUSH_PROMISE.
            self.header_data.append(frame.data)
        elif isinstance(frame, DataFrame):
            # Append the data to the buffer.
            self.data.append(frame.data)

            # Increase the window size. Only do this if the data frame contains
            # actual data.
            increment = self._in_window_manager._handle_frame(len(frame.data))
            if increment and not self._remote_closed:
                w = WindowUpdateFrame(self.stream_id)
                w.window_increment = increment
                self._data_cb(w, True)
        else:
            raise ValueError('Unexpected frame type: %i' % frame.type)

        if 'END_HEADERS' in frame.flags or 'END_PUSH_PROMISE' in frame.flags:
            headers = self._decoder.decode(b''.join(self.header_data))
            if self.promised_stream_id is None:
                self.response_headers = headers
            else:
                self.promised_headers[self.promised_stream_id] = headers

    def open(self, end):
        """
        Open the stream. Does this by encoding and sending the headers: no more
        calls to ``add_header`` are allowed after this method is called.
        The `end` flag controls whether this will be the end of the stream, or
        whether data will follow.
        """
        # Encode the headers.
        encoded_headers = self._encoder.encode(self.headers)

        # It's possible that there is a substantial amount of data here. The
        # data needs to go into one HEADERS frame, followed by a number of
        # CONTINUATION frames. For now, for ease of implementation, let's just
        # assume that's never going to happen (16kB of headers is lots!).
        # Additionally, since this is so unlikely, there's no point writing a
        # test for this: it's just so simple.
        if len(encoded_headers) > FRAME_MAX_LEN:  # pragma: no cover
            raise ValueError("Header block too large.")

        header_frame = HeadersFrame(self.stream_id)
        header_frame.data = encoded_headers

        # If no data has been provided, this is the end of the stream. Either
        # way, due to the restriction above it's definitely the end of the
        # headers.
        header_frame.flags.add('END_HEADERS')

        if end:
            header_frame.flags.add('END_STREAM')

        # Send the header frame.
        self._data_cb(header_frame)

        # Transition the stream state appropriately.
        self.state = STATE_HALF_CLOSED_LOCAL if end else STATE_OPEN

        return

    def getheaders(self):
        """
        Once all data has been sent on this connection, returns a key-value set
        of the headers of the response to the original request.
        """
        assert self._local_closed

        # Keep reading until all headers are received.
        while self.response_headers is None:
            self._recv_cb()

        # Find the Content-Length header if present.
        self._in_window_manager.document_size = (
            int(get_from_key_value_set(self.response_headers, 'content-length', 0))
        )

        return self.response_headers

    def getpushes(self, capture_all=False):
        """
        Returns a generator that yields push promises from the server. Note that
        this method is not idempotent; promises returned in one call will not be
        returned in subsequent calls. Iterating through generators returned by
        multiple calls to this method simultaneously results in undefined
        behavior.

        :param capture_all: If ``False``, the generator will yield all buffered
            push promises without blocking. If ``True``, the generator will
            first yield all buffered push promises, then yield additional ones
            as they arrive, and terminate when the original stream closes.
        """
        while True:
            for pair in self.promised_headers.items():
                yield pair
            self.promised_headers = {}
            if not capture_all or self._remote_closed:
                break
            self._recv_cb()

    def close(self, error_code=None):
        """
        Closes the stream. If the stream is currently open, attempts to close
        it as gracefully as possible.

        :param error_code: (optional) The error code to reset the stream with.
        :returns: Nothing.
        """
        # Right now let's not bother with grace, let's just call close on the
        # connection.
        self._close_cb(self.stream_id, error_code)

    def _send_chunk(self, data, final):
        """
        Implements most of the sending logic.

        Takes a single chunk of size at most MAX_CHUNK, wraps it in a frame and
        sends it. Optionally sets the END_STREAM flag if this is the last chunk
        (determined by being of size less than MAX_CHUNK) and no more data is
        to be sent.
        """
        assert self._local_open

        f = DataFrame(self.stream_id)
        f.data = data

        # If the length of the data is less than MAX_CHUNK, we're probably
        # at the end of the file. If this is the end of the data, mark it
        # as END_STREAM.
        if len(data) < MAX_CHUNK and final:
            f.flags.add('END_STREAM')

        # If we don't fit in the connection window, try popping frames off the
        # connection in hope that one might be a Window Update frame.
        while len(data) > self._out_flow_control_window:
            self._recv_cb()

        # Send the frame and decrement the flow control window.
        self._data_cb(f)
        self._out_flow_control_window -= len(data)

        # If no more data is to be sent on this stream, transition our state.
        if len(data) < MAX_CHUNK and final:
            self._close_local()

########NEW FILE########
__FILENAME__ = tls
# -*- coding: utf-8 -*-
"""
hyper/tls
~~~~~~~~~

Contains the TLS/SSL logic for use in hyper.
"""
import ssl
import os.path as path

from ..compat import is_py3


# Right now we support draft 9.
SUPPORTED_PROTOCOLS = ['http/1.1', 'HTTP-draft-09/2.0']


# We have a singleton SSLContext object. There's no reason to be creating one
# per connection. We're using v23 right now until someone gives me a reason not
# to.
_context = None

# Exposed here so it can be monkey-patched in integration tests.
_verify_mode = ssl.CERT_REQUIRED


# Work out where our certificates are.
cert_loc = path.join(path.dirname(__file__), '..', 'certs.pem')


if is_py3: # pragma: no cover
    def wrap_socket(socket, server_hostname):
        """
        A vastly simplified SSL wrapping function. We'll probably extend this to
        do more things later.
        """
        global _context

        if _context is None:  # pragma: no cover
            _context = _init_context()

        if ssl.HAS_SNI:
            return _context.wrap_socket(socket, server_hostname=server_hostname)

        wrapped = _context.wrap_socket(socket)  # pragma: no cover
        assert wrapped.selected_npn_protocol() == 'HTTP-draft-09/2.0'
        return wrapped
else: # pragma: no cover
    def wrap_socket(socket, server_hostname):
        return ssl.wrap_socket(socket, ssl_version=ssl.PROTOCOL_SSLv23,
            ca_certs=cert_loc, cert_reqs=_verify_mode)


def _init_context(): # pragma: no cover
    """
    Creates the singleton SSLContext we use.
    """
    context = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
    context.set_default_verify_paths()
    context.load_verify_locations(cafile=cert_loc)
    context.verify_mode = _verify_mode

    try:
        context.set_npn_protocols(SUPPORTED_PROTOCOLS)
    except (AttributeError, NotImplementedError):  # pragma: no cover
        pass

    # We do our best to do better security
    try:
        context.options |= ssl.OP_NO_SSLv2
    except AttributeError:  # pragma: no cover
        pass

    try:
        context.options |= ssl.OP_NO_COMPRESSION
    except AttributeError:  # pragma: no cover
        pass

    return context

########NEW FILE########
__FILENAME__ = util
# -*- coding: utf-8 -*-
"""
hyper/http20/util
~~~~~~~~~~~~~~~~~

Utility functions for use with hyper.
"""
def get_from_key_value_set(kvset, key, default=None):
    """
    Returns a value from a key-value set, or the default if the value isn't
    present.
    """
    value = pop_from_key_value_set(kvset.copy(), key)[0]
    return value if value is not None else default

def pop_from_key_value_set(kvset, *keys):
    """
    Pops the values of ``keys`` from ``kvset`` and returns them as a tuple. If a
    key is not found in ``kvset``, ``None`` is used instead.

    >>> kvset = [('a',0), ('b',1), ('c',2)]
    >>> pop_from_key_value_set(kvset, 'a', 'foo', 'c')
    (0, None, 2)
    >>> kvset
    [('b', 1)]
    """
    extracted = [None] * len(keys)
    rest = set()
    for key, value in kvset:
        try:
            extracted[keys.index(key)] = value
        except ValueError:
            rest.add((key, value))
    kvset.intersection_update(rest)
    return tuple(extracted)

########NEW FILE########
__FILENAME__ = window
# -*- coding: utf-8 -*-
"""
hyper/http20/window
~~~~~~~~~~~~~~~~~~~

Objects that understand flow control in hyper.

HTTP/2.0 implements connection- and stream-level flow control. This flow
control is mandatory. Unfortunately, it's difficult for hyper to be
all that intelligent about how it manages flow control in a general case.

This module defines an interface for pluggable flow-control managers. These
managers will define a flow-control policy. This policy will determine when to
send WINDOWUPDATE frames.
"""
class BaseFlowControlManager(object):
    """
    The abstract base class for flow control managers.

    This class defines the interface for pluggable flow-control managers. A
    flow-control manager defines a flow-control policy, which basically boils
    down to deciding when to increase the flow control window.

    This decision can be based on a number of factors:

    - the initial window size,
    - the size of the document being retrieved,
    - the size of the received data frames,
    - any other information the manager can obtain

    A flow-control manager may be defined at the connection level or at the
    stream level. If no stream-level flow-control manager is defined, an
    instance of the connection-level flow control manager is used.

    A class that inherits from this one must not adjust the member variables
    defined in this class. They are updated and set by methods on this class.
    """
    def __init__(self, initial_window_size, document_size=None):
        #: The initial size of the connection window in bytes. This is set at
        #: creation time.
        self.initial_window_size = initial_window_size

        #: The current size of the connection window. Any methods overridden
        #: by the user must not adjust this value.
        self.window_size = initial_window_size

        #: The size of the document being retrieved, in bytes. This is
        #: retrieved from the Content-Length header, if provided. Note that
        #: the total number of bytes that will be received may be larger than
        #: this value due to HTTP/2.0 padding. It should not be assumed that
        #: simply because the the document size is smaller than the initial
        #: window size that there will never be a need to increase the window
        #: size.
        self.document_size = document_size

    def increase_window_size(self, frame_size):
        """
        Determine whether or not to emit a WINDOWUPDATE frame.

        This method should be overridden to determine, based on the state of
        the system and the size of the received frame, whether or not a
        WindowUpdate frame should be sent for the stream.

        This method should *not* adjust any of the member variables of this
        class.

        Note that this method is called before the window size is decremented
        as a result of the frame being handled.

        :param frame_size: The size of the received frame. Note that this *may*
          be zero. When this parameter is zero, it's possible that a
          WINDOWUPDATE frame may want to be emitted anyway. A zero-length frame
          size is usually associated with a change in the size of the receive
          window due to a SETTINGS frame.
        :returns: The amount to increase the receive window by. Return zero if
          the window should not be increased.
        """
        raise NotImplementedError(
            "FlowControlManager is an abstract base class"
        )

    def _handle_frame(self, frame_size):
        """
        This internal method is called by the connection or stream that owns
        the flow control manager. It handles the generic behaviour of flow
        control managers: namely, keeping track of the window size.
        """
        rc = self.increase_window_size(frame_size)
        self.window_size -= frame_size
        self.window_size += rc
        return rc


class FlowControlManager(BaseFlowControlManager):
    """
    ``hyper``'s default flow control manager.

    This implements hyper's flow control algorithms. This algorithm attempts to
    reduce the number of WINDOWUPDATE frames we send without blocking the remote
    endpoint behind the flow control window.

    This algorithm will become more complicated over time. In the current form,
    the algorithm is very simple:
        - When the flow control window gets less than 1/4 of the maximum size,
          increment back to the maximum.
        - Otherwise, if the flow control window gets to less than 1kB, increment
          back to the maximum.
    """
    def increase_window_size(self, frame_size):
        future_window_size = self.window_size - frame_size

        if ((future_window_size < (self.initial_window_size / 4)) or
            (future_window_size < 1000)):
            return self.initial_window_size - future_window_size

        return 0

########NEW FILE########
__FILENAME__ = httplib_compat
# -*- coding: utf-8 -*-
"""
hyper/httplib_compat
~~~~~~~~~~~~~~~~~~~~

This file defines the publicly-accessible API for hyper. This API also
constitutes the abstraction layer between HTTP/1.1 and HTTP/2.0.

This API doesn't currently work, and is a lower priority than the HTTP/2.0
stack at this time.
"""
import socket
try:
    import http.client as httplib
except ImportError:
    import httplib

import ssl
from .http20.tls import wrap_socket

# If there's no NPN support, we're going to drop all support for HTTP/2.0.
try:
    support_20 = ssl.HAS_NPN
except AttributeError:
    support_20 = False

# The HTTPConnection object is currently always the underlying one.
HTTPConnection = httplib.HTTPConnection
HTTPSConnection = httplib.HTTPSConnection

# If we have NPN support, define our custom one, otherwise just use the
# default.
if support_20:
    class HTTPSConnection(object):
        """
        An object representing a single HTTPS connection, whether HTTP/1.1 or
        HTTP/2.0.

        More specifically, this object represents an abstraction over the
        distinction. This object encapsulates a connection object for one of
        the specific types of connection, and delegates most of the work to
        that object.
        """
        def __init__(self, *args, **kwargs):
            # Whatever arguments and keyword arguments are passed to this
            # object need to be saved off for when we initialise one of our
            # subsidiary objects.
            self._original_args = args
            self._original_kwargs = kwargs

            # Set up some variables we're going to use later.
            self._sock = None
            self._conn = None

            # Prepare our backlog of method calls.
            self._call_queue = []

        def __getattr__(self, name):
            # Anything that can't be found on this instance is presumably a
            # property of underlying connection object.
            # We need to be a little bit careful here. There are a few methods
            # that can act on a HTTPSConnection before it actually connects to
            # the remote server. We don't want to change the semantics of the,
            # HTTPSConnection so we need to spot these and queue them up. When
            # we actually create the backing Connection, we'll apply them
            # immediately. These methods can't throw exceptions, so we should
            # be fine.
            delay_methods = ["set_tunnel", "set_debuglevel"]

            if self._conn is None and name in delay_methods:
                # Return a little closure that saves off the method call to
                # apply later.
                def capture(obj, *args, **kwargs):
                    self._call_queue.append((name, args, kwargs))
                return capture
            elif self._conn is None:
                # We're being told to do something! We can now connect to the
                # remote server and build the connection object.
                self._delayed_connect()

            # Call through to the underlying object.
            return getattr(self._conn, name)

        def _delayed_connect(self):
            """
            Called when we need to work out what kind of HTTPS connection we're
            actually going to use.
            """
            # Because we're ghetto, we're going to quickly create a
            # HTTPConnection object to parse the args and kwargs for us, and
            # grab the values out.
            tempconn = httplib.HTTPConnection(*self._original_args,
                                              **self._original_kwargs)
            host = tempconn.host
            port = tempconn.port
            timeout = tempconn.timeout
            source_address = tempconn.source_address

            # Connect to the remote server.
            sock = socket.create_connection(
                (host, port),
                timeout,
                source_address
            )

            # Wrap it in TLS. This needs to be looked at in future when I pull
            # in the TLS verification logic from urllib3, but right now we
            # accept insecurity because no-one's using this anyway.
            sock = wrap_socket(sock, host)

            # At this early stage the library can't do HTTP/2.0, so who cares?
            tempconn.sock = sock
            self._sock = sock
            self._conn = tempconn

            return

########NEW FILE########
__FILENAME__ = server
# -*- coding: utf-8 -*-
"""
test/server
~~~~~~~~~~~

This module defines some testing infrastructure that is very useful for
integration-type testing of hyper. It works by spinning up background threads
that run test-defined logic while listening to a background thread.

This very-clever idea and most of its implementation are ripped off from
Andrey Petrov's excellent urllib3 project. I owe him a substantial debt in
ingenuity and about a million beers. The license is available in NOTICES.
"""

import threading
import socket
import ssl
import sys

from hyper.compat import is_py3
from hyper.http20.hpack import Encoder
from hyper.http20.huffman import HuffmanEncoder
from hyper.http20.huffman_constants import (
    REQUEST_CODES, REQUEST_CODES_LENGTH
)

class _SocketServerThreadBase(threading.Thread):
    """
    This method stolen wholesale from shazow/urllib3 under license. See NOTICES.

    :param socket_handler: Callable which receives a socket argument for one
        request.
    :param ready_event: Event which gets set when the socket handler is
        ready to receive requests.
    """
    def __init__(self, socket_handler, host='localhost', ready_event=None):
        threading.Thread.__init__(self)

        self.socket_handler = socket_handler
        self.host = host
        self.ready_event = ready_event

    def _start_server(self):
        sock = socket.socket(socket.AF_INET6)
        if sys.platform != 'win32':
            sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        sock = self._wrap_socket(sock)
        sock.bind((self.host, 0))
        self.port = sock.getsockname()[1]

        # Once listen() returns, the server socket is ready
        sock.listen(1)

        if self.ready_event:
            self.ready_event.set()

        self.socket_handler(sock)
        sock.close()

    def _wrap_socket(self, sock):
        raise NotImplementedError()

    def run(self):
        self.server = self._start_server()


class _SocketServerThreadPy2(_SocketServerThreadBase):
    def _wrap_socket(self, sock):
        return ssl.wrap_socket(sock, server_side=True,
                               certfile='test/certs/server.crt',
                               keyfile='test/certs/server.key')


class _SocketServerThreadPy3(_SocketServerThreadBase):
    def __init__(self, socket_handler, host='localhost', ready_event=None):
        super().__init__(socket_handler, host, ready_event)
        self.cxt = ssl.SSLContext(ssl.PROTOCOL_SSLv23)
        self.cxt.set_npn_protocols(['HTTP-draft-09/2.0'])
        self.cxt.load_cert_chain(certfile='test/certs/server.crt',
                                 keyfile='test/certs/server.key')

    def _wrap_socket(self, sock):
        return self.cxt.wrap_socket(sock, server_side=True)


if is_py3:
    SocketServerThread = _SocketServerThreadPy3
else:
    SocketServerThread = _SocketServerThreadPy2


class SocketLevelTest(object):
    """
    A test-class that defines a few helper methods for running socket-level
    tests.
    """
    def set_up(self):
        self.host = None
        self.port = None
        self.server_thread = None

    def _start_server(self, socket_handler):
        """
        Starts a background thread that runs the given socket handler.
        """
        ready_event = threading.Event()
        self.server_thread = SocketServerThread(
            socket_handler=socket_handler,
            ready_event=ready_event
        )
        self.server_thread.start()
        ready_event.wait()
        self.host = self.server_thread.host
        self.port = self.server_thread.port

    def get_encoder(self):
        """
        Returns a HPACK encoder set up for responses.
        """
        e = Encoder()
        e.huffman_coder = HuffmanEncoder(REQUEST_CODES, REQUEST_CODES_LENGTH)
        return e

    def tear_down(self):
        """
        Tears down the testing thread.
        """
        self.server_thread.join(0.1)

########NEW FILE########
__FILENAME__ = test_hpack_integration
# -*- coding: utf-8 -*-
"""
This module defines substantial HPACK integration tests. These can take a very
long time to run, so they're outside the main test suite, but they need to be
run before every change to HPACK.
"""
from hyper.http20.hpack import Decoder, Encoder
from hyper.http20.huffman import HuffmanDecoder, HuffmanEncoder
from hyper.http20.huffman_constants import (
    REQUEST_CODES, REQUEST_CODES_LENGTH, REQUEST_CODES, REQUEST_CODES_LENGTH
)
from binascii import unhexlify

class TestHPACKDecoderIntegration(object):
    def test_can_decode_a_story(self, story):
        d = Decoder()

        # We support draft 6 of the HPACK spec.
        assert story['draft'] == 6

        for case in story['cases']:
            try:
                d.header_table_size = case['header_table_size']
            except KeyError:
                pass
            decoded_headers = d.decode(unhexlify(case['wire']))

            # The correct headers are a list of dicts, which is annoying.
            correct_headers = {(item[0], item[1]) for header in case['headers'] for item in header.items()}
            assert correct_headers == decoded_headers

    def test_can_encode_a_story_no_huffman(self, raw_story):
        d = Decoder()
        e = Encoder()

        for case in raw_story['cases']:
            # The input headers are a list of dicts, which is annoying.
            input_headers = {(item[0], item[1]) for header in case['headers'] for item in header.items()}

            encoded = e.encode(input_headers, huffman=False)
            decoded_headers = d.decode(encoded)

            assert input_headers == decoded_headers

    def test_can_encode_a_story_with_huffman(self, raw_story):
        d = Decoder()
        e = Encoder()

        for case in raw_story['cases']:
            # The input headers are a list of dicts, which is annoying.
            input_headers = {(item[0], item[1]) for header in case['headers'] for item in header.items()}

            encoded = e.encode(input_headers, huffman=True)
            decoded_headers = d.decode(encoded)

            assert input_headers == decoded_headers

########NEW FILE########
__FILENAME__ = test_huffman
from hyper.http20.huffman import HuffmanDecoder, HuffmanEncoder
from hyper.http20.huffman_constants import REQUEST_CODES,REQUEST_CODES_LENGTH,REQUEST_CODES,REQUEST_CODES_LENGTH


class TestHuffman(object):
    def test_request_huffman_decoder(self):
        decoder = HuffmanDecoder(REQUEST_CODES,REQUEST_CODES_LENGTH)
        assert decoder.decode(b'\xdb\x6d\x88\x3e\x68\xd1\xcb\x12\x25\xba\x7f') == b"www.example.com"
        assert decoder.decode(b'\x63\x65\x4a\x13\x98\xff') == b"no-cache"
        assert decoder.decode(b'\x4e\xb0\x8b\x74\x97\x90\xfa\x7f') == b"custom-key"
        assert decoder.decode(b'\x4e\xb0\x8b\x74\x97\x9a\x17\xa8\xff') == b"custom-value"

    def test_request_huffman_encode(self):
        encoder = HuffmanEncoder(REQUEST_CODES, REQUEST_CODES_LENGTH)
        assert encoder.encode(b"www.example.com") == (b'\xdb\x6d\x88\x3e\x68\xd1\xcb\x12\x25\xba\x7f')
        assert encoder.encode(b"no-cache") == (b'\x63\x65\x4a\x13\x98\xff')
        assert encoder.encode(b"custom-key") == (b'\x4e\xb0\x8b\x74\x97\x90\xfa\x7f')
        assert encoder.encode(b"custom-value") == (b'\x4e\xb0\x8b\x74\x97\x9a\x17\xa8\xff')

    def test_eos_terminates_decode_request(self):
        decoder = HuffmanDecoder(REQUEST_CODES,REQUEST_CODES_LENGTH)
        assert decoder.decode(b'\xff\xff\xf7\x00') == b''

########NEW FILE########
__FILENAME__ = test_hyper
# -*- coding: utf-8 -*-
from hyper.http20.frame import (
    Frame, DataFrame, PriorityFrame, RstStreamFrame, SettingsFrame,
    PushPromiseFrame, PingFrame, GoAwayFrame, WindowUpdateFrame, HeadersFrame,
    ContinuationFrame,
)
from hyper.http20.hpack import Encoder, Decoder, encode_integer, decode_integer
from hyper.http20.huffman import HuffmanDecoder
from hyper.http20.huffman_constants import REQUEST_CODES, REQUEST_CODES_LENGTH
from hyper.http20.connection import HTTP20Connection
from hyper.http20.stream import (
    Stream, STATE_HALF_CLOSED_LOCAL, STATE_OPEN, MAX_CHUNK, STATE_CLOSED
)
from hyper.http20.response import HTTP20Response
from hyper.http20.exceptions import HPACKDecodingError, HPACKEncodingError
from hyper.http20.window import FlowControlManager
from hyper.compat import zlib_compressobj
from hyper.contrib import HTTP20Adapter
import errno
import pytest
import socket
import zlib
from io import BytesIO


def decode_frame(frame_data):
    f, length = Frame.parse_frame_header(frame_data[:8])
    f.parse_body(frame_data[8:8 + length])
    assert 8 + length == len(frame_data)
    return f


class TestGeneralFrameBehaviour(object):
    def test_base_frame_ignores_flags(self):
        f = Frame(0)
        flags = f.parse_flags(0xFF)
        assert not flags
        assert isinstance(flags, set)

    def test_base_frame_cant_serialize(self):
        f = Frame(0)
        with pytest.raises(NotImplementedError):
            f.serialize()

    def test_base_frame_cant_parse_body(self):
        data = b''
        f = Frame(0)
        with pytest.raises(NotImplementedError):
            f.parse_body(data)


class TestDataFrame(object):
    def test_data_frame_has_only_one_flag(self):
        f = DataFrame(1)
        flags = f.parse_flags(0xFF)
        assert flags == set(['END_STREAM'])

    def test_data_frame_serializes_properly(self):
        f = DataFrame(1)
        f.flags = set(['END_STREAM'])
        f.data = b'testdata'

        s = f.serialize()
        assert s == b'\x00\x08\x00\x01\x00\x00\x00\x01testdata'

    def test_data_frame_parses_properly(self):
        s = b'\x00\x08\x00\x01\x00\x00\x00\x01testdata'
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, DataFrame)
        assert f.flags == set(['END_STREAM'])
        assert f.data == b'testdata'

    def test_data_frame_comes_on_a_stream(self):
        with pytest.raises(ValueError):
            DataFrame(0)


class TestPriorityFrame(object):
    def test_priority_frame_has_no_flags(self):
        f = PriorityFrame(1)
        flags = f.parse_flags(0xFF)
        assert not flags
        assert isinstance(flags, set)

    def test_priority_frame_serializes_properly(self):
        f = PriorityFrame(1)
        f.priority = 0xFF

        s = f.serialize()
        assert s == b'\x00\x04\x02\x00\x00\x00\x00\x01\x00\x00\x00\xff'

    def test_priority_frame_parses_properly(self):
        s = b'\x00\x04\x02\x00\x00\x00\x00\x01\x00\x00\x00\xff'
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, PriorityFrame)
        assert f.flags == set()
        assert f.priority == 0xFF

    def test_priority_frame_comes_on_a_stream(self):
        with pytest.raises(ValueError):
            PriorityFrame(0)

    def test_priority_frame_must_have_body_length_four(self):
        f = PriorityFrame(1)
        with pytest.raises(ValueError):
            f.parse_body(b'\x01')

class TestRstStreamFrame(object):
    def test_rst_stream_frame_has_no_flags(self):
        f = RstStreamFrame(1)
        flags = f.parse_flags(0xFF)
        assert not flags
        assert isinstance(flags, set)

    def test_rst_stream_frame_serializes_properly(self):
        f = RstStreamFrame(1)
        f.error_code = 420

        s = f.serialize()
        assert s == b'\x00\x04\x03\x00\x00\x00\x00\x01\x00\x00\x01\xa4'

    def test_rst_stream_frame_parses_properly(self):
        s = b'\x00\x04\x03\x00\x00\x00\x00\x01\x00\x00\x01\xa4'
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, RstStreamFrame)
        assert f.flags == set()
        assert f.error_code == 420

    def test_rst_stream_frame_comes_on_a_stream(self):
        with pytest.raises(ValueError):
            RstStreamFrame(0)

    def test_rst_stream_frame_must_have_body_length_four(self):
        f = RstStreamFrame(1)
        with pytest.raises(ValueError):
            f.parse_body(b'\x01')


class TestSettingsFrame(object):
    def test_settings_frame_has_only_one_flag(self):
        f = SettingsFrame(0)
        flags = f.parse_flags(0xFF)
        assert flags == set(['ACK'])

    def test_settings_frame_serializes_properly(self):
        f = SettingsFrame(0)
        f.parse_flags(0xFF)
        f.settings = {
            SettingsFrame.HEADER_TABLE_SIZE: 4096,
            SettingsFrame.ENABLE_PUSH: 0,
            SettingsFrame.MAX_CONCURRENT_STREAMS: 100,
            SettingsFrame.INITIAL_WINDOW_SIZE: 65535,
            SettingsFrame.FLOW_CONTROL_OPTIONS: 1,
        }

        s = f.serialize()
        assert s == (
            b'\x00\x28\x04\x01\x00\x00\x00\x00' +  # Frame header
            b'\x00\x00\x00\x01\x00\x00\x10\x00' +  # HEADER_TABLE_SIZE
            b'\x00\x00\x00\x02\x00\x00\x00\x00' +  # ENABLE_PUSH
            b'\x00\x00\x00\x04\x00\x00\x00\x64' +  # MAX_CONCURRENT_STREAMS
            b'\x00\x00\x00\x0A\x00\x00\x00\x01' +  # FLOW_CONTROL_OPTIONS
            b'\x00\x00\x00\x07\x00\x00\xFF\xFF'    # INITIAL_WINDOW_SIZE
        )

    def test_settings_frame_parses_properly(self):
        s = (
            b'\x00\x28\x04\x01\x00\x00\x00\x00' +  # Frame header
            b'\x00\x00\x00\x01\x00\x00\x10\x00' +  # HEADER_TABLE_SIZE
            b'\x00\x00\x00\x02\x00\x00\x00\x00' +  # ENABLE_PUSH
            b'\x00\x00\x00\x04\x00\x00\x00\x64' +  # MAX_CONCURRENT_STREAMS
            b'\x00\x00\x00\x0A\x00\x00\x00\x01' +  # FLOW_CONTROL_OPTIONS
            b'\x00\x00\x00\x07\x00\x00\xFF\xFF'    # INITIAL_WINDOW_SIZE
        )
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, SettingsFrame)
        assert f.flags == set(['ACK'])
        assert f.settings == {
            SettingsFrame.HEADER_TABLE_SIZE: 4096,
            SettingsFrame.ENABLE_PUSH: 0,
            SettingsFrame.MAX_CONCURRENT_STREAMS: 100,
            SettingsFrame.INITIAL_WINDOW_SIZE: 65535,
            SettingsFrame.FLOW_CONTROL_OPTIONS: 1,
        }

    def test_settings_frames_never_have_streams(self):
        with pytest.raises(ValueError):
            SettingsFrame(1)


class TestPushPromiseFrame(object):
    def test_push_promise_frame_flags(self):
        f = PushPromiseFrame(1)
        flags = f.parse_flags(0xFF)

        assert flags == set(['END_PUSH_PROMISE'])

    def test_push_promise_frame_serialize_with_priority_properly(self):
        f = PushPromiseFrame(1)
        f.parse_flags(0xFF)
        f.promised_stream_id = 4
        f.data = b'hello world'

        s = f.serialize()
        assert s == (
            b'\x00\x0F\x05\x01\x00\x00\x00\x01' +
            b'\x00\x00\x00\x04' +
            b'hello world'
        )

    def test_push_promise_frame_parses_properly(self):
        s = (
            b'\x00\x0F\x05\x0D\x00\x00\x00\x01' +
            b'\x00\x00\x00\x04' +
            b'hello world'
        )
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, PushPromiseFrame)
        assert f.flags == set(['END_PUSH_PROMISE'])
        assert f.promised_stream_id == 4
        assert f.data == b'hello world'


class TestPingFrame(object):
    def test_ping_frame_has_only_one_flag(self):
        f = PingFrame(0)
        flags = f.parse_flags(0xFF)

        assert flags == set(['ACK'])

    def test_ping_frame_serializes_properly(self):
        f = PingFrame(0)
        f.parse_flags(0xFF)
        f.opaque_data = b'\x01\x02'

        s = f.serialize()
        assert s == (
            b'\x00\x08\x06\x01\x00\x00\x00\x00\x01\x02\x00\x00\x00\x00\x00\x00'
        )

    def test_no_more_than_8_octets(self):
        f = PingFrame(0)
        f.opaque_data = b'\x01\x02\x03\x04\x05\x06\x07\x08\x09'

        with pytest.raises(ValueError):
            f.serialize()

    def test_ping_frame_parses_properly(self):
        s = b'\x00\x08\x06\x01\x00\x00\x00\x00\x01\x02\x00\x00\x00\x00\x00\x00'
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, PingFrame)
        assert f.flags == set(['ACK'])
        assert f.opaque_data == b'\x01\x02\x00\x00\x00\x00\x00\x00'

    def test_ping_frame_never_has_a_stream(self):
        with pytest.raises(ValueError):
            PingFrame(1)

    def test_ping_frame_has_no_more_than_body_length_8(self):
        f = PingFrame(0)
        with pytest.raises(ValueError):
            f.parse_body(b'\x01\x02\x03\x04\x05\x06\x07\x08\x09')


class TestGoAwayFrame(object):
    def test_go_away_has_no_flags(self):
        f = GoAwayFrame(0)
        flags = f.parse_flags(0xFF)

        assert not flags
        assert isinstance(flags, set)

    def test_goaway_serializes_properly(self):
        f = GoAwayFrame(0)
        f.last_stream_id = 64
        f.error_code = 32
        f.additional_data = b'hello'

        s = f.serialize()
        assert s == (
            b'\x00\x0D\x07\x00\x00\x00\x00\x00' +  # Frame header
            b'\x00\x00\x00\x40'                 +  # Last Stream ID
            b'\x00\x00\x00\x20'                 +  # Error Code
            b'hello'                               # Additional data
        )

    def test_goaway_frame_parses_properly(self):
        s = (
            b'\x00\x0D\x07\x00\x00\x00\x00\x00' +  # Frame header
            b'\x00\x00\x00\x40'                 +  # Last Stream ID
            b'\x00\x00\x00\x20'                 +  # Error Code
            b'hello'                               # Additional data
        )
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, GoAwayFrame)
        assert f.flags == set()
        assert f.additional_data == b'hello'

    def test_goaway_frame_never_has_a_stream(self):
        with pytest.raises(ValueError):
            GoAwayFrame(1)


class TestWindowUpdateFrame(object):
    def test_window_update_has_no_flags(self):
        f = WindowUpdateFrame(0)
        flags = f.parse_flags(0xFF)

        assert not flags
        assert isinstance(flags, set)

    def test_window_update_serializes_properly(self):
        f = WindowUpdateFrame(0)
        f.window_increment = 512

        s = f.serialize()
        assert s == b'\x00\x04\x09\x00\x00\x00\x00\x00\x00\x00\x02\x00'

    def test_windowupdate_frame_parses_properly(self):
        s = b'\x00\x04\x09\x00\x00\x00\x00\x00\x00\x00\x02\x00'
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, WindowUpdateFrame)
        assert f.flags == set()
        assert f.window_increment == 512


class TestHeadersFrame(object):
    def test_headers_frame_flags(self):
        f = HeadersFrame(1)
        flags = f.parse_flags(0xFF)

        assert flags == set(['END_STREAM', 'END_HEADERS', 'PRIORITY'])

    def test_headers_frame_serialize_with_priority_properly(self):
        f = HeadersFrame(1)
        f.parse_flags(0xFF)
        f.priority = (2 ** 30) + 1
        f.data = b'hello world'

        s = f.serialize()
        assert s == (
            b'\x00\x0F\x01\x0D\x00\x00\x00\x01' +
            b'\x40\x00\x00\x01' +
            b'hello world'
        )

    def test_headers_frame_serialize_without_priority_properly(self):
        f = HeadersFrame(1)
        f.parse_flags(0xFF)
        f.data = b'hello world'

        s = f.serialize()
        assert s == (
            b'\x00\x0B\x01\x0D\x00\x00\x00\x01' +
            b'hello world'
        )

    def test_headers_frame_parses_properly(self):
        s = (
            b'\x00\x0F\x01\x0D\x00\x00\x00\x01' +
            b'\x40\x00\x00\x01' +
            b'hello world'
        )
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, HeadersFrame)
        assert f.flags == set(['END_STREAM', 'END_HEADERS', 'PRIORITY'])
        assert f.priority == (2 ** 30) + 1
        assert f.data == b'hello world'


class TestContinuationFrame(object):
    def test_continuation_frame_flags(self):
        f = ContinuationFrame(1)
        flags = f.parse_flags(0xFF)

        assert flags == set(['END_HEADERS'])

    def test_continuation_frame_serializes(self):
        f = ContinuationFrame(1)
        f.parse_flags(0xFF)
        f.data = b'hello world'

        s = f.serialize()
        assert s == (
            b'\x00\x0B\x0A\x04\x00\x00\x00\x01' +
            b'hello world'
        )

    def test_continuation_frame_parses_properly(self):
        s = b'\x00\x0B\x0A\x04\x00\x00\x00\x01hello world'
        f, length = Frame.parse_frame_header(s[:8])
        f.parse_body(s[8:8 + length])

        assert isinstance(f, ContinuationFrame)
        assert f.flags == set(['END_HEADERS'])
        assert f.data == b'hello world'


class TestHuffmanDecoder(object):
    def test_huffman_decoder_throws_useful_exceptions(self):
        # Specify a HuffmanDecoder with no values in it, then attempt to decode
        # using it.
        d = HuffmanDecoder([], [])
        with pytest.raises(HPACKDecodingError):
            d.decode(b'test')


class TestHPACKEncoder(object):
    # These tests are stolen entirely from the IETF specification examples.
    def test_literal_header_field_with_indexing(self):
        """
        The header field representation uses a literal name and a literal
        value.
        """
        e = Encoder()
        header_set = {'custom-key': 'custom-header'}
        result = b'\x00\x0acustom-key\x0dcustom-header'

        assert e.encode(header_set, huffman=False) == result
        assert list(e.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in header_set.items()
        ]

    def test_literal_header_field_without_indexing(self):
        """
        The header field representation uses an indexed name and a literal
        value.
        """
        e = Encoder()
        header_set = {':path': '/sample/path'}
        result = b'\x44\x0c/sample/path'

        assert e.encode(header_set, huffman=False) == result
        assert list(e.header_table) == []

    def test_indexed_header_field(self):
        """
        The header field representation uses an indexed header field, from
        the static table.  Upon using it, the static table entry is copied
        into the header table.
        """
        e = Encoder()
        header_set = {':method': 'GET'}
        result = b'\x82'

        assert e.encode(header_set, huffman=False) == result
        assert list(e.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in header_set.items()
        ]

    def test_indexed_header_field_from_static_table(self):
        e = Encoder()
        e.header_table_size = 0
        header_set = {':method': 'GET'}
        result = b'\x82'

        assert e.encode(header_set, huffman=False) == result
        assert list(e.header_table) == []

    def test_request_examples_without_huffman(self):
        """
        This section shows several consecutive header sets, corresponding to
        HTTP requests, on the same connection.
        """
        e = Encoder()
        first_header_set = [
            (':method', 'GET',),
            (':scheme', 'http',),
            (':path', '/',),
            (':authority', 'www.example.com'),
        ]
        # The first_header_table doesn't contain 'authority'
        first_header_table = first_header_set[::-1][1:]
        first_result = b'\x82\x87\x86\x44\x0fwww.example.com'

        assert e.encode(first_header_set, huffman=False) == first_result
        assert list(e.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in first_header_table
        ]

        # This request takes advantage of the differential encoding of header
        # sets.
        second_header_set = [
            (':method', 'GET',),
            (':scheme', 'http',),
            (':path', '/',),
            (':authority', 'www.example.com',),
            ('cache-control', 'no-cache'),
        ]
        second_result = b'\x44\x0fwww.example.com\x5a\x08no-cache'

        assert e.encode(second_header_set, huffman=False) == second_result
        assert list(e.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in first_header_table
        ]

        # This request has not enough headers in common with the previous
        # request to take advantage of the differential encoding.  Therefore,
        # the reference set is emptied before encoding the header fields.
        third_header_set = [
            (':method', 'GET',),
            (':scheme', 'https',),
            (':path', '/index.html',),
            (':authority', 'www.example.com',),
            ('custom-key', 'custom-value'),
        ]
        third_result = (
            b'\x80\x80\x83\x8a\x89\x46\x0fwww.example.com' +
            b'\x00\x0acustom-key\x0ccustom-value'
        )

        assert e.encode(third_header_set, huffman=False) == third_result
        # Don't check the header table here, it's just too complex to be
        # reliable. Check its length though.
        assert len(e.header_table) == 6

    def test_request_examples_with_huffman(self):
        """
        This section shows the same examples as the previous section, but
        using Huffman encoding for the literal values.
        """
        e = Encoder()
        first_header_set = [
            (':method', 'GET',),
            (':scheme', 'http',),
            (':path', '/',),
            (':authority', 'www.example.com'),
        ]
        # The first_header_table doesn't contain 'authority'
        first_header_table = first_header_set[::-1][1:]
        first_result = (
            b'\x82\x87\x86\x44\x8b\xdb\x6d\x88\x3e\x68\xd1\xcb\x12\x25\xba\x7f'
        )

        assert e.encode(first_header_set, huffman=True) == first_result
        assert list(e.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in first_header_table
        ]

        # This request takes advantage of the differential encoding of header
        # sets.
        second_header_set = [
            (':method', 'GET',),
            (':scheme', 'http',),
            (':path', '/',),
            (':authority', 'www.example.com',),
            ('cache-control', 'no-cache'),
        ]
        second_result = b'\x44\x8b\xdb\x6d\x88\x3e\x68\xd1\xcb\x12\x25\xba\x7f\x5a\x86\x63\x65\x4a\x13\x98\xff'

        assert e.encode(second_header_set, huffman=True) == second_result
        assert list(e.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in first_header_table
        ]

        # This request has not enough headers in common with the previous
        # request to take advantage of the differential encoding.  Therefore,
        # the reference set is emptied before encoding the header fields.
        third_header_set = [
            (':method', 'GET',),
            (':scheme', 'https',),
            (':path', '/index.html',),
            (':authority', 'www.example.com',),
            ('custom-key', 'custom-value'),
        ]
        third_result = (
            b'\x80\x80\x83\x8a\x89F\x8b\xdbm\x88>h\xd1\xcb\x12%\xba\x7f\x00\x88'
            b'N\xb0\x8bt\x97\x90\xfa\x7f\x89N\xb0\x8bt\x97\x9a\x17\xa8\xff'
        )

        assert e.encode(third_header_set, huffman=True) == third_result
        # Don't check the header table here, it's just too complex to be
        # reliable. Check its length though.
        assert len(e.header_table) == 6

    # These tests are custom, for hyper.
    def test_resizing_header_table(self):
        # We need to encode a substantial number of headers, to populate the
        # header table.
        e = Encoder()
        header_set = [
            (':method', 'GET'),
            (':scheme', 'https'),
            (':path', '/some/path'),
            (':authority', 'www.example.com'),
            ('custom-key', 'custom-value'),
            ("user-agent", "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:16.0) Gecko/20100101 Firefox/16.0"),
            ("accept", "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8"),
            ('X-Lukasa-Test', '88989'),
        ]
        e.encode(header_set, huffman=True)

        # Resize the header table to a size so small that nothing can be in it.
        e.header_table_size = 40
        assert len(e.header_table) == 0

    def test_removing_header_partially_in_table(self):
        e = Encoder()
        e.encode([('no', 'value')])

        with pytest.raises(HPACKEncodingError):
            e.remove([(b'no', b'val')])

    def test_removing_header_not_in_table_at_all(self):
        e = Encoder()

        with pytest.raises(HPACKEncodingError):
            e.remove([(b'not', b'present')])


class TestHPACKDecoder(object):
    # These tests are stolen entirely from the IETF specification examples.
    def test_literal_header_field_with_indexing(self):
        """
        The header field representation uses a literal name and a literal
        value.
        """
        d = Decoder()
        header_set = set([('custom-key', 'custom-header')])
        data = b'\x00\x0acustom-key\x0dcustom-header'

        assert d.decode(data) == header_set
        assert list(d.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in header_set
        ]

    def test_literal_header_field_without_indexing(self):
        """
        The header field representation uses an indexed name and a literal
        value.
        """
        d = Decoder()
        header_set = set([(':path', '/sample/path')])
        data = b'\x44\x0c/sample/path'

        assert d.decode(data) == header_set
        assert list(d.header_table) == []

    def test_indexed_header_field(self):
        """
        The header field representation uses an indexed header field, from
        the static table.  Upon using it, the static table entry is copied
        into the header table.
        """
        d = Decoder()
        header_set = set([(':method', 'GET')])
        data = b'\x82'

        assert d.decode(data) == header_set
        assert list(d.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in header_set
        ]

    def test_request_examples_without_huffman(self):
        """
        This section shows several consecutive header sets, corresponding to
        HTTP requests, on the same connection.
        """
        d = Decoder()
        first_header_set = [
            (':method', 'GET',),
            (':scheme', 'http',),
            (':path', '/',),
            (':authority', 'www.example.com'),
        ]
        # The first_header_table doesn't contain 'authority'
        first_header_table = first_header_set[::-1][1:]
        first_data = b'\x82\x87\x86\x44\x0fwww.example.com'

        assert d.decode(first_data) == set(first_header_set)
        assert list(d.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in first_header_table
        ]

        # This request takes advantage of the differential encoding of header
        # sets.
        second_header_set = [
            (':method', 'GET',),
            (':scheme', 'http',),
            (':path', '/',),
            (':authority', 'www.example.com',),
            ('cache-control', 'no-cache'),
        ]
        second_data = b'\x44\x0fwww.example.com\x5a\x08no-cache'

        assert d.decode(second_data) == set(second_header_set)
        assert list(d.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in first_header_table
        ]

        # This request has not enough headers in common with the previous
        # request to take advantage of the differential encoding.  Therefore,
        # the reference set is emptied before encoding the header fields.
        third_header_set = [
            (':method', 'GET',),
            (':scheme', 'https',),
            (':path', '/index.html',),
            (':authority', 'www.example.com',),
            ('custom-key', 'custom-value'),
        ]
        third_data = (
            b'\x80\x80\x83\x8a\x89\x46\x0fwww.example.com' +
            b'\x00\x0acustom-key\x0ccustom-value'
        )

        assert d.decode(third_data) == set(third_header_set)
        # Don't check the header table here, it's just too complex to be
        # reliable. Check its length though.
        assert len(d.header_table) == 6

    def test_request_examples_with_huffman(self):
        """
        This section shows the same examples as the previous section, but
        using Huffman encoding for the literal values.
        """
        d = Decoder()

        # Patch the decoder to use the Request Huffman tables, not the Response
        # ones.
        d.huffman_coder = HuffmanDecoder(REQUEST_CODES, REQUEST_CODES_LENGTH)
        first_header_set = [
            (':method', 'GET',),
            (':scheme', 'http',),
            (':path', '/',),
            (':authority', 'www.example.com'),
        ]
        first_header_table = first_header_set[::-1]
        first_data = (
            b'\x82\x87\x86\x04\x8b\xdb\x6d\x88\x3e\x68\xd1\xcb\x12\x25\xba\x7f'
        )

        assert d.decode(first_data) == set(first_header_set)
        assert list(d.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in first_header_table
        ]

        # This request takes advantage of the differential encoding of header
        # sets.
        second_header_set = [
            (':method', 'GET',),
            (':scheme', 'http',),
            (':path', '/',),
            (':authority', 'www.example.com',),
            ('cache-control', 'no-cache'),
        ]
        second_header_table = second_header_set[::-1]
        second_data = b'\x1b\x86\x63\x65\x4a\x13\x98\xff'

        assert d.decode(second_data) == set(second_header_set)
        assert list(d.header_table) == [
            (n.encode('utf-8'), v.encode('utf-8')) for n, v in second_header_table
        ]

        # This request has not enough headers in common with the previous
        # request to take advantage of the differential encoding.  Therefore,
        # the reference set is emptied before encoding the header fields.
        third_header_set = [
            (':method', 'GET',),
            (':scheme', 'https',),
            (':path', '/index.html',),
            (':authority', 'www.example.com',),
            ('custom-key', 'custom-value'),
        ]
        third_data = (
            b'\x80\x80\x85\x8c\x8b\x84\x00\x88\x4e\xb0\x8b\x74\x97\x90\xfa\x7f\x89'
            b'\x4e\xb0\x8b\x74\x97\x9a\x17\xa8\xff'
        )

        assert d.decode(third_data) == set(third_header_set)
        # Don't check the header table here, it's just too complex to be
        # reliable. Check its length though.
        assert len(d.header_table) == 8

    # These tests are custom, for hyper.
    def test_resizing_header_table(self):
        # We need to decode a substantial number of headers, to populate the
        # header table. This string isn't magic: it's the output from the
        # equivalent test for the Encoder.
        d = Decoder()
        data = (
            b'\x82\x88F\x87\x087A\x07"9\xffC\x8b\xdbm\x88>h\xd1\xcb\x12%' +
            b'\xba\x7f\x00\x88N\xb0\x8bt\x97\x90\xfa\x7f\x89N\xb0\x8bt\x97\x9a' +
            b'\x17\xa8\xff|\xbe\xefo\xaa\x96\xb4\x05\x04/G\xfa\xefBT\xc8\xb6' +
            b'\x19\xf5t|\x19\x11_Gz\x13\xd1\xf4\xf0\xe8\xfd\xf4\x18\xa4\xaf' +
            b'\xab\xa1\xfc\xfd\x86\xa4\x85\xff}\x1e\xe1O&\x81\xcab\x94\xc57G' +
            b'\x05<qo\x98\x1a\x92\x17U\xaf\x88\xf9\xc43\x8e\x8b\xe9C\x9c\xb5' +
            b'%\x11SX\x1ey\xc7E\xff\xcf=\x17\xd2\x879jJ"\xa6\xb0<\xf4_W\x95' +
            b'\xa5%\x9d?\xd0\x7f]^V\x94\x95\xff\x00\x8a\xfd\xcb\xf2\xd7\x92 ' +
            b'\x89|F\x11\x84\xae\xbb+\xb3'
        )
        d.decode(data)

        # Resize the header table to a size so small that nothing can be in it.
        d.header_table_size = 40
        assert len(d.header_table) == 0


class TestIntegerEncoding(object):
    # These tests are stolen from the HPACK spec.
    def test_encoding_10_with_5_bit_prefix(self):
        val = encode_integer(10, 5)
        assert len(val) == 1
        assert val == bytearray(b'\x0a')

    def test_encoding_1337_with_5_bit_prefix(self):
        val = encode_integer(1337, 5)
        assert len(val) == 3
        assert val == bytearray(b'\x1f\x9a\x0a')

    def test_encoding_42_with_8_bit_prefix(self):
        val = encode_integer(42, 8)
        assert len(val) == 1
        assert val == bytearray(b'\x2a')


class TestIntegerDecoding(object):
    # These tests are stolen from the HPACK spec.
    def test_decoding_10_with_5_bit_prefix(self):
        val = decode_integer(b'\x0a', 5)
        assert val == (10, 1)

    def test_encoding_1337_with_5_bit_prefix(self):
        val = decode_integer(b'\x1f\x9a\x0a', 5)
        assert val == (1337, 3)

    def test_encoding_42_with_8_bit_prefix(self):
        val = decode_integer(b'\x2a', 8)
        assert val == (42, 1)


class TestHyperConnection(object):
    def test_connections_accept_hosts_and_ports(self):
        c = HTTP20Connection(host='www.google.com', port=8080)
        assert c.host =='www.google.com'
        assert c.port == 8080

    def test_connections_can_parse_hosts_and_ports(self):
        c = HTTP20Connection('www.google.com:8080')
        assert c.host == 'www.google.com'
        assert c.port == 8080

    def test_putrequest_establishes_new_stream(self):
        c = HTTP20Connection("www.google.com")

        stream_id = c.putrequest('GET', '/')
        stream = c.streams[stream_id]

        assert len(c.streams) == 1
        assert c.recent_stream is stream

    def test_putrequest_autosets_headers(self):
        c = HTTP20Connection("www.google.com")

        c.putrequest('GET', '/')
        s = c.recent_stream

        assert s.headers == [
            (':method', 'GET'),
            (':scheme', 'https'),
            (':authority', 'www.google.com'),
            (':path', '/'),
        ]

    def test_putheader_puts_headers(self):
        c = HTTP20Connection("www.google.com")

        c.putrequest('GET', '/')
        c.putheader('name', 'value')
        s = c.recent_stream

        assert s.headers == [
            (':method', 'GET'),
            (':scheme', 'https'),
            (':authority', 'www.google.com'),
            (':path', '/'),
            ('name', 'value'),
        ]

    def test_endheaders_sends_data(self):
        frames = []

        def data_callback(frame):
            frames.append(frame)

        c = HTTP20Connection('www.google.com')
        c._sock = DummySocket()
        c._send_cb = data_callback
        c.putrequest('GET', '/')
        c.endheaders()

        assert len(frames) == 1
        f = frames[0]
        assert isinstance(f, HeadersFrame)

    def test_we_can_send_data_using_endheaders(self):
        frames = []

        def data_callback(frame):
            frames.append(frame)

        c = HTTP20Connection('www.google.com')
        c._sock = DummySocket()
        c._send_cb = data_callback
        c.putrequest('GET', '/')
        c.endheaders(message_body=b'hello there', final=True)

        assert len(frames) == 2
        assert isinstance(frames[0], HeadersFrame)
        assert frames[0].flags == set(['END_HEADERS'])
        assert isinstance(frames[1], DataFrame)
        assert frames[1].data == b'hello there'
        assert frames[1].flags == set(['END_STREAM'])

    def test_that_we_correctly_send_over_the_socket(self):
        sock = DummySocket()
        c = HTTP20Connection('www.google.com')
        c._sock = sock
        c.putrequest('GET', '/')
        c.endheaders(message_body=b'hello there', final=True)

        # Don't bother testing that the serialization was ok, that should be
        # fine.
        assert len(sock.queue) == 2
        # Confirm the window got shrunk.
        assert c._out_flow_control_window == 65535 - len(b'hello there')

    def test_we_can_read_from_the_socket(self):
        sock = DummySocket()
        sock.buffer = BytesIO(b'\x00\x08\x00\x01\x00\x00\x00\x01testdata')

        c = HTTP20Connection('www.google.com')
        c._sock = sock
        c.putrequest('GET', '/')
        c.endheaders()
        c._recv_cb()

        s = c.recent_stream
        assert s.data == [b'testdata']

    def test_putrequest_sends_data(self):
        sock = DummySocket()

        c = HTTP20Connection('www.google.com')
        c._sock = sock
        c.request(
            'GET',
            '/',
            body='hello',
            headers={'Content-Type': 'application/json'}
        )

        # The socket should have received one headers frame and one body frame.
        assert len(sock.queue) == 2
        assert c._out_flow_control_window == 65535 - len(b'hello')

    def test_closed_connections_are_reset(self):
        c = HTTP20Connection('www.google.com')
        c._sock = DummySocket()
        encoder = c.encoder
        decoder = c.decoder
        wm = c.window_manager
        c.request('GET', '/')
        c.close()

        assert c._sock is None
        assert not c.streams
        assert c.recent_stream is None
        assert c.next_stream_id == 1
        assert c.encoder is not encoder
        assert c.decoder is not decoder
        assert c._settings == {
            SettingsFrame.INITIAL_WINDOW_SIZE: 65535,
        }
        assert c._out_flow_control_window == 65535
        assert c.window_manager is not wm

    def test_connection_doesnt_send_window_update_on_zero_length_data_frame(self):
        # Prepare a socket with a data frame in it that has no length.
        sock = DummySocket()
        sock.buffer = BytesIO(DataFrame(1).serialize())
        c = HTTP20Connection('www.google.com')
        c._sock = sock

        # We open a request here just to allocate a stream, but we throw away
        # the frames it sends.
        c.request('GET', '/')
        sock.queue = []

        # Read the frame.
        c._recv_cb()

        # No frame should have been sent on the connection.
        assert len(sock.queue) == 0

    def test_streams_are_cleared_from_connections_on_close(self):
        # Prepare a socket so we can open a stream.
        sock = DummySocket()
        c = HTTP20Connection('www.google.com')
        c._sock = sock

        # Open a request (which creates a stream)
        c.request('GET', '/')

        # Close the stream.
        c.streams[1].close()

        # There should be nothing left, but the next stream ID should be
        # unchanged.
        assert not c.streams
        assert c.next_stream_id == 3

    def test_connections_increment_send_window_properly(self):
        f = WindowUpdateFrame(0)
        f.window_increment = 1000
        c = HTTP20Connection('www.google.com')
        c._sock = DummySocket()

        # 'Receive' the WINDOWUPDATE frame.
        c.receive_frame(f)

        assert c._out_flow_control_window == 65535 + 1000

    def test_connections_handle_resizing_header_tables_properly(self):
        sock = DummySocket()
        f = SettingsFrame(0)
        f.settings[SettingsFrame.HEADER_TABLE_SIZE] = 1024
        c = HTTP20Connection('www.google.com')
        c._sock = sock

        # 'Receive' the SETTINGS frame.
        c.receive_frame(f)

        # Confirm that the setting is stored and the header table shrunk.
        assert c._settings[SettingsFrame.HEADER_TABLE_SIZE] == 1024
        assert c.encoder.header_table_size == 1024

        # Confirm we got a SETTINGS ACK.
        f2 = decode_frame(sock.queue[0])
        assert isinstance(f2, SettingsFrame)
        assert f2.stream_id == 0
        assert f2.flags == set(['ACK'])

    def test_read_headers_out_of_order(self):
        # If header blocks aren't decoded in the same order they're received,
        # regardless of the stream they belong to, the decoder state will become
        # corrupted.
        e = Encoder()
        h1 = HeadersFrame(1)
        h1.data = e.encode({':status': 200, 'content-type': 'foo/bar'})
        h1.flags |= set(['END_HEADERS', 'END_STREAM'])
        h3 = HeadersFrame(3)
        h3.data = e.encode({':status': 200, 'content-type': 'baz/qux'})
        h3.flags |= set(['END_HEADERS', 'END_STREAM'])
        sock = DummySocket()
        sock.buffer = BytesIO(h1.serialize() + h3.serialize())

        c = HTTP20Connection('www.google.com')
        c._sock = sock
        r1 = c.request('GET', '/a')
        r3 = c.request('GET', '/b')

        assert c.getresponse(r3).getheaders() == [('content-type', 'baz/qux')]
        assert c.getresponse(r1).getheaders() == [('content-type', 'foo/bar')]

    def test_headers_with_continuation(self):
        e = Encoder()
        h = HeadersFrame(1)
        h.data = e.encode({':status': 200, 'content-type': 'foo/bar'})
        c = ContinuationFrame(1)
        c.data = e.encode({'content-length': '0'})
        c.flags |= set(['END_HEADERS', 'END_STREAM'])
        sock = DummySocket()
        sock.buffer = BytesIO(h.serialize() + c.serialize())

        c = HTTP20Connection('www.google.com')
        c._sock = sock
        r = c.request('GET', '/')

        assert set(c.getresponse(r).getheaders()) == set([('content-type', 'foo/bar'), ('content-length', '0')])

    def test_receive_unexpected_frame(self):
        # RST_STREAM frames are never defined on connections, so send one of
        # those.
        c = HTTP20Connection('www.google.com')
        f = RstStreamFrame(1)

        with pytest.raises(ValueError):
            c.receive_frame(f)

    def test_send_tolerate_peer_gone(self):
        class ErrorSocket(DummySocket):
            def send(self, data):
                raise socket.error(errno.EPIPE)

        c = HTTP20Connection('www.google.com')
        c._sock = ErrorSocket()
        f = SettingsFrame(0)
        with pytest.raises(socket.error):
            c._send_cb(f, False)
        c._sock = DummySocket()
        c._send_cb(f, True) # shouldn't raise an error

    def test_window_increments_appropriately(self):
        e = Encoder()
        h = HeadersFrame(1)
        h.data = e.encode({':status': 200, 'content-type': 'foo/bar'})
        h.flags = set(['END_HEADERS'])
        d = DataFrame(1)
        d.data = b'hi there sir'
        d2 = DataFrame(1)
        d2.data = b'hi there sir again'
        d2.flags = set(['END_STREAM'])
        sock = DummySocket()
        sock.buffer = BytesIO(h.serialize() + d.serialize() + d2.serialize())

        c = HTTP20Connection('www.google.com')
        c._sock = sock
        c.window_manager.window_size = 1000
        c.window_manager.initial_window_size = 1000
        c.request('GET', '/')
        resp = c.getresponse()
        resp.read()

        queue = list(map(decode_frame, sock.queue))
        assert len(queue) == 3  # one headers frame, two window update frames.
        assert isinstance(queue[1], WindowUpdateFrame)
        assert queue[1].window_increment == len(b'hi there sir')
        assert isinstance(queue[2], WindowUpdateFrame)
        assert queue[2].window_increment == len(b'hi there sir again')

    def test_ping_with_ack_ignored(self):
        c = HTTP20Connection('www.google.com')
        f = PingFrame(0)
        f.flags = set(['ACK'])
        f.opaque_data = b'12345678'

        def data_cb(frame, tolerate_peer_gone=False):
            assert False, 'should not be called'
        c._data_cb = data_cb
        c.receive_frame(f)

    def test_ping_without_ack_gets_reply(self):
        c = HTTP20Connection('www.google.com')
        f = PingFrame(0)
        f.opaque_data = b'12345678'

        frames = []

        def data_cb(frame, tolerate_peer_gone=False):
            frames.append(frame)
        c._data_cb = data_cb
        c.receive_frame(f)

        assert len(frames) == 1
        assert frames[0].type == PingFrame.type
        assert frames[0].flags == set(['ACK'])
        assert frames[0].opaque_data == b'12345678'


class TestServerPush(object):
    def setup_method(self, method):
        self.frames = []
        self.encoder = Encoder()
        self.conn = None

    def add_push_frame(self, stream_id, promised_stream_id, headers, end_block=True):
        frame = PushPromiseFrame(stream_id)
        frame.promised_stream_id = promised_stream_id
        frame.data = self.encoder.encode(headers)
        if end_block:
            frame.flags.add('END_PUSH_PROMISE')
        self.frames.append(frame)

    def add_headers_frame(self, stream_id, headers, end_block=True, end_stream=False):
        frame = HeadersFrame(stream_id)
        frame.data = self.encoder.encode(headers)
        if end_block:
            frame.flags.add('END_HEADERS')
        if end_stream:
            frame.flags.add('END_STREAM')
        self.frames.append(frame)

    def add_data_frame(self, stream_id, data, end_stream=False):
        frame = DataFrame(stream_id)
        frame.data = data
        if end_stream:
            frame.flags.add('END_STREAM')
        self.frames.append(frame)

    def request(self):
        self.conn = HTTP20Connection('www.google.com', enable_push=True)
        self.conn._sock = DummySocket()
        self.conn._sock.buffer = BytesIO(b''.join([frame.serialize() for frame in self.frames]))
        self.conn.request('GET', '/')

    def assert_response(self):
        self.response = self.conn.getresponse()
        assert self.response.status == 200
        assert dict(self.response.getheaders()) == {'content-type': 'text/html'}

    def assert_pushes(self):
        self.pushes = list(self.conn.getpushes())
        assert len(self.pushes) == 1
        assert self.pushes[0].method == 'GET'
        assert self.pushes[0].scheme == 'https'
        assert self.pushes[0].authority == 'www.google.com'
        assert self.pushes[0].path == '/'
        expected_headers = {'accept-encoding': 'gzip'}
        for name, value in expected_headers.items():
            assert self.pushes[0].getrequestheader(name) == value
        assert dict(self.pushes[0].getrequestheaders()) == expected_headers

    def assert_push_response(self):
        push_response = self.pushes[0].getresponse()
        assert push_response.status == 200
        assert dict(push_response.getheaders()) == {'content-type': 'application/javascript'}
        assert push_response.read() == b'bar'

    def test_promise_before_headers(self):
        self.add_push_frame(1, 2, [(':method', 'GET'), (':path', '/'), (':authority', 'www.google.com'), (':scheme', 'https'), ('accept-encoding', 'gzip')])
        self.add_headers_frame(1, [(':status', '200'), ('content-type', 'text/html')])
        self.add_data_frame(1, b'foo', end_stream=True)
        self.add_headers_frame(2, [(':status', '200'), ('content-type', 'application/javascript')])
        self.add_data_frame(2, b'bar', end_stream=True)

        self.request()
        assert len(list(self.conn.getpushes())) == 0
        self.assert_response()
        self.assert_pushes()
        assert self.response.read() == b'foo'
        self.assert_push_response()

    def test_promise_after_headers(self):
        self.add_headers_frame(1, [(':status', '200'), ('content-type', 'text/html')])
        self.add_push_frame(1, 2, [(':method', 'GET'), (':path', '/'), (':authority', 'www.google.com'), (':scheme', 'https'), ('accept-encoding', 'gzip')])
        self.add_data_frame(1, b'foo', end_stream=True)
        self.add_headers_frame(2, [(':status', '200'), ('content-type', 'application/javascript')])
        self.add_data_frame(2, b'bar', end_stream=True)

        self.request()
        assert len(list(self.conn.getpushes())) == 0
        self.assert_response()
        assert len(list(self.conn.getpushes())) == 0
        assert self.response.read() == b'foo'
        self.assert_pushes()
        self.assert_push_response()

    def test_promise_after_data(self):
        self.add_headers_frame(1, [(':status', '200'), ('content-type', 'text/html')])
        self.add_data_frame(1, b'fo')
        self.add_push_frame(1, 2, [(':method', 'GET'), (':path', '/'), (':authority', 'www.google.com'), (':scheme', 'https'), ('accept-encoding', 'gzip')])
        self.add_data_frame(1, b'o', end_stream=True)
        self.add_headers_frame(2, [(':status', '200'), ('content-type', 'application/javascript')])
        self.add_data_frame(2, b'bar', end_stream=True)

        self.request()
        assert len(list(self.conn.getpushes())) == 0
        self.assert_response()
        assert len(list(self.conn.getpushes())) == 0
        assert self.response.read() == b'foo'
        self.assert_pushes()
        self.assert_push_response()

    def test_capture_all_promises(self):
        self.add_push_frame(1, 2, [(':method', 'GET'), (':path', '/one'), (':authority', 'www.google.com'), (':scheme', 'https'), ('accept-encoding', 'gzip')])
        self.add_headers_frame(1, [(':status', '200'), ('content-type', 'text/html')])
        self.add_push_frame(1, 4, [(':method', 'GET'), (':path', '/two'), (':authority', 'www.google.com'), (':scheme', 'https'), ('accept-encoding', 'gzip')])
        self.add_data_frame(1, b'foo', end_stream=True)
        self.add_headers_frame(4, [(':status', '200'), ('content-type', 'application/javascript')])
        self.add_headers_frame(2, [(':status', '200'), ('content-type', 'application/javascript')])
        self.add_data_frame(4, b'two', end_stream=True)
        self.add_data_frame(2, b'one', end_stream=True)

        self.request()
        assert len(list(self.conn.getpushes())) == 0
        pushes = list(self.conn.getpushes(capture_all=True))
        assert len(pushes) == 2
        assert pushes[0].path == '/one'
        assert pushes[1].path == '/two'
        assert pushes[0].getresponse().read() == b'one'
        assert pushes[1].getresponse().read() == b'two'
        self.assert_response()
        assert self.response.read() == b'foo'

    def test_cancel_push(self):
        self.add_push_frame(1, 2, [(':method', 'GET'), (':path', '/'), (':authority', 'www.google.com'), (':scheme', 'https'), ('accept-encoding', 'gzip')])
        self.add_headers_frame(1, [(':status', '200'), ('content-type', 'text/html')])

        self.request()
        self.conn.getresponse()
        list(self.conn.getpushes())[0].cancel()

        f = RstStreamFrame(2)
        f.error_code = 8
        assert self.conn._sock.queue[-1] == f.serialize()

    def test_reset_pushed_streams_when_push_disabled(self):
        self.add_push_frame(1, 2, [(':method', 'GET'), (':path', '/'), (':authority', 'www.google.com'), (':scheme', 'https'), ('accept-encoding', 'gzip')])
        self.add_headers_frame(1, [(':status', '200'), ('content-type', 'text/html')])

        self.request()
        self.conn._enable_push = False
        self.conn.getresponse()

        f = RstStreamFrame(2)
        f.error_code = 7
        assert self.conn._sock.queue[-1] == f.serialize()


class TestHyperStream(object):
    def test_streams_have_ids(self):
        s = Stream(1, None, None, None, None, None, None)
        assert s.stream_id == 1

    def test_streams_initially_have_no_headers(self):
        s = Stream(1, None, None, None, None, None, None)
        assert s.headers == []

    def test_streams_can_have_headers(self):
        s = Stream(1, None, None, None, None, None, None)
        s.add_header("name", "value")
        assert s.headers == [("name", "value")]

    def test_stream_opening_sends_headers(self):
        def data_callback(frame):
            assert isinstance(frame, HeadersFrame)
            assert frame.data == 'testkeyTestVal'
            assert frame.flags == set(['END_STREAM', 'END_HEADERS'])

        s = Stream(1, data_callback, None, None, NullEncoder, None, None)
        s.add_header("TestKey", "TestVal")
        s.open(True)

        assert s.state == STATE_HALF_CLOSED_LOCAL

    def test_file_objects_can_be_sent(self):
        def data_callback(frame):
            assert isinstance(frame, DataFrame)
            assert frame.data == b'Hi there!'
            assert frame.flags == set(['END_STREAM'])

        s = Stream(1, data_callback, None, None, NullEncoder, None, None)
        s.state = STATE_OPEN
        s.send_data(BytesIO(b'Hi there!'), True)

        assert s.state == STATE_HALF_CLOSED_LOCAL
        assert s._out_flow_control_window == 65535 - len(b'Hi there!')

    def test_large_file_objects_are_broken_into_chunks(self):
        frame_count = [0]
        recent_frame = [None]

        def data_callback(frame):
            assert isinstance(frame, DataFrame)
            assert len(frame.data) <= MAX_CHUNK
            frame_count[0] += 1
            recent_frame[0] = frame

        data = b'test' * (MAX_CHUNK + 1)

        s = Stream(1, data_callback, None, None, NullEncoder, None, None)
        s.state = STATE_OPEN
        s.send_data(BytesIO(data), True)

        assert s.state == STATE_HALF_CLOSED_LOCAL
        assert recent_frame[0].flags == set(['END_STREAM'])
        assert frame_count[0] == 5
        assert s._out_flow_control_window == 65535 - len(data)

    def test_bytestrings_can_be_sent(self):
        def data_callback(frame):
            assert isinstance(frame, DataFrame)
            assert frame.data == b'Hi there!'
            assert frame.flags == set(['END_STREAM'])

        s = Stream(1, data_callback, None, None, NullEncoder, None, None)
        s.state = STATE_OPEN
        s.send_data(b'Hi there!', True)

        assert s.state == STATE_HALF_CLOSED_LOCAL
        assert s._out_flow_control_window == 65535 - len(b'Hi there!')

    def test_long_bytestrings_are_split(self):
        frame_count = [0]
        recent_frame = [None]

        def data_callback(frame):
            assert isinstance(frame, DataFrame)
            assert len(frame.data) <= MAX_CHUNK
            frame_count[0] += 1
            recent_frame[0] = frame

        data = b'test' * (MAX_CHUNK + 1)

        s = Stream(1, data_callback, None, None, NullEncoder, None, None)
        s.state = STATE_OPEN
        s.send_data(data, True)

        assert s.state == STATE_HALF_CLOSED_LOCAL
        assert recent_frame[0].flags == set(['END_STREAM'])
        assert frame_count[0] == 5
        assert s._out_flow_control_window == 65535 - len(data)

    def test_windowupdate_frames_update_windows(self):
        s = Stream(1, None, None, None, None, None, None)
        f = WindowUpdateFrame(1)
        f.window_increment = 1000
        s.receive_frame(f)

        assert s._out_flow_control_window == 65535 + 1000

    def test_stream_reading_works(self):
        out_frames = []
        in_frames = []

        def send_cb(frame, tolerate_peer_gone=False):
            out_frames.append(frame)

        def recv_cb(s):
            def inner():
                s.receive_frame(in_frames.pop(0))
            return inner

        s = Stream(1, send_cb, None, None, None, None, FlowControlManager(65535))
        s._recv_cb = recv_cb(s)
        s.state = STATE_HALF_CLOSED_LOCAL

        # Provide a data frame to read.
        f = DataFrame(1)
        f.data = b'hi there!'
        f.flags.add('END_STREAM')
        in_frames.append(f)

        data = s._read()
        assert data == b'hi there!'
        assert len(out_frames) == 0

    def test_can_read_multiple_frames_from_streams(self):
        out_frames = []
        in_frames = []

        def send_cb(frame, tolerate_peer_gone=False):
            out_frames.append(frame)

        def recv_cb(s):
            def inner():
                s.receive_frame(in_frames.pop(0))
            return inner

        s = Stream(1, send_cb, None, None, None, None, FlowControlManager(800))
        s._recv_cb = recv_cb(s)
        s.state = STATE_HALF_CLOSED_LOCAL

        # Provide two data frames to read.
        f = DataFrame(1)
        f.data = b'hi there!'
        in_frames.append(f)

        f = DataFrame(1)
        f.data = b'hi there again!'
        f.flags.add('END_STREAM')
        in_frames.append(f)

        data = s._read()
        assert data == b'hi there!hi there again!'
        assert len(out_frames) == 1
        assert isinstance(out_frames[0], WindowUpdateFrame)
        assert out_frames[0].window_increment == len(b'hi there!')

    def test_partial_reads_from_streams(self):
        out_frames = []
        in_frames = []

        def send_cb(frame, tolerate_peer_gone=False):
            out_frames.append(frame)

        def recv_cb(s):
            def inner():
                s.receive_frame(in_frames.pop(0))
            return inner

        s = Stream(1, send_cb, None, None, None, None, FlowControlManager(800))
        s._recv_cb = recv_cb(s)
        s.state = STATE_HALF_CLOSED_LOCAL

        # Provide two data frames to read.
        f = DataFrame(1)
        f.data = b'hi there!'
        in_frames.append(f)

        f = DataFrame(1)
        f.data = b'hi there again!'
        f.flags.add('END_STREAM')
        in_frames.append(f)

        # We'll get the entire first frame.
        data = s._read(4)
        assert data == b'hi there!'
        assert len(out_frames) == 1

        # Now we'll get the entire of the second frame.
        data = s._read(4)
        assert data == b'hi there again!'
        assert len(out_frames) == 1
        assert s.state == STATE_CLOSED

    def test_receive_unexpected_frame(self):
        # SETTINGS frames are never defined on streams, so send one of those.
        s = Stream(1, None, None, None, None, None, None)
        f = SettingsFrame(0)

        with pytest.raises(ValueError):
            s.receive_frame(f)


class TestResponse(object):
    def test_status_is_stripped_from_headers(self):
        headers = set([(':status', '200')])
        resp = HTTP20Response(headers, None)

        assert resp.status == 200
        assert resp.getheaders() == []

    def test_response_transparently_decrypts_gzip(self):
        headers = set([(':status', '200'), ('content-encoding', 'gzip')])
        c = zlib_compressobj(wbits=24)
        body = c.compress(b'this is test data')
        body += c.flush()
        resp = HTTP20Response(headers, DummyStream(body))

        assert resp.read() == b'this is test data'

    def test_response_transparently_decrypts_real_deflate(self):
        headers = set([(':status', '200'), ('content-encoding', 'deflate')])
        c = zlib_compressobj(wbits=zlib.MAX_WBITS)
        body = c.compress(b'this is test data')
        body += c.flush()
        resp = HTTP20Response(headers, DummyStream(body))

        assert resp.read() == b'this is test data'

    def test_response_transparently_decrypts_wrong_deflate(self):
        headers = set([(':status', '200'), ('content-encoding', 'deflate')])
        c = zlib_compressobj(wbits=-zlib.MAX_WBITS)
        body = c.compress(b'this is test data')
        body += c.flush()
        resp = HTTP20Response(headers, DummyStream(body))

        assert resp.read() == b'this is test data'

    def test_response_calls_stream_close(self):
        stream = DummyStream('')
        resp = HTTP20Response(set([(':status', '200')]), stream)
        resp.close()

        assert stream.closed

    def test_responses_are_context_managers(self):
        stream = DummyStream('')

        with HTTP20Response(set([(':status', '200')]), stream) as resp:
            pass

        assert stream.closed

    def test_read_small_chunks(self):
        headers = set([(':status', '200')])
        stream = DummyStream(b'1234567890')
        chunks = [b'12', b'34', b'56', b'78', b'90']
        resp = HTTP20Response(headers, stream)

        for chunk in chunks:
            assert resp.read(2) == chunk

        assert resp.read() == b''

    def test_read_buffered(self):
        headers = set([(':status', '200')])
        stream = DummyStream(b'1234567890')
        chunks = [b'12', b'34', b'56', b'78', b'90'] * 2
        resp = HTTP20Response(headers, stream)
        resp._data_buffer = b'1234567890'

        for chunk in chunks:
            assert resp.read(2) == chunk

        assert resp.read() == b''

    def test_getheader(self):
        headers = set([(':status', '200'), ('content-type', 'application/json')])
        stream = DummyStream(b'')
        resp = HTTP20Response(headers, stream)

        assert resp.getheader('content-type') == 'application/json'

    def test_getheader_default(self):
        headers = set([(':status', '200')])
        stream = DummyStream(b'')
        resp = HTTP20Response(headers, stream)

        assert resp.getheader('content-type', 'text/html') == 'text/html'

    def test_fileno_not_implemented(self):
        resp = HTTP20Response(set([(':status', '200')]), DummyStream(b''))

        with pytest.raises(NotImplementedError):
            resp.fileno()


class TestHTTP20Adapter(object):
    def test_adapter_reuses_connections(self):
        a = HTTP20Adapter()
        conn1 = a.get_connection('twitter.com')
        conn2 = a.get_connection('twitter.com')

        assert conn1 is conn2


# Some utility classes for the tests.
class NullEncoder(object):
    @staticmethod
    def encode(headers):
        return '\n'.join("%s%s" % (name, val) for name, val in headers)

class DummySocket(object):
    def __init__(self):
        self.queue = []
        self.buffer = BytesIO()

    def send(self, data):
        self.queue.append(data)

    def recv(self, l):
        return self.buffer.read(l)

    def close(self):
        pass

class DummyStream(object):
    def __init__(self, data):
        self.data = data
        self.closed = False

    def _read(self, *args, **kwargs):
        try:
            read_len = min(args[0], len(self.data))
        except IndexError:
            read_len = len(self.data)

        d = self.data[:read_len]
        self.data = self.data[read_len:]
        return d

    def close(self):
        if not self.closed:
            self.closed = True
        else:
            assert False

########NEW FILE########
__FILENAME__ = test_import
import hyper
import imp
import pytest
import sys


class TestImportPython2(object):
    def test_cannot_import_python_2(self, monkeypatch):
        monkeypatch.setattr(sys, 'version_info', (2, 6, 5, 'final', 0))
        with pytest.raises(ImportError):
            imp.reload(hyper)


class TestImportPython3(object):
    def test_cannot_import_python_32(self, monkeypatch):
        monkeypatch.setattr(sys, 'version_info', (3, 2, 3, 'final', 0))
        with pytest.raises(ImportError):
            imp.reload(hyper)

########NEW FILE########
__FILENAME__ = test_integration
# -*- coding: utf-8 -*-
"""
test/integration
~~~~~~~~~~~~~~~~

This file defines integration-type tests for hyper. These are still not fully
hitting the network, so that's alright.
"""
import requests
import ssl
import threading
import hyper
import pytest
from hyper import HTTP20Connection
from hyper.compat import is_py3
from hyper.contrib import HTTP20Adapter
from hyper.http20.frame import (
    Frame, SettingsFrame, WindowUpdateFrame, DataFrame, HeadersFrame,
    GoAwayFrame,
)
from hyper.http20.hpack import Encoder
from hyper.http20.huffman import HuffmanEncoder
from hyper.http20.huffman_constants import (
    REQUEST_CODES, REQUEST_CODES_LENGTH
)
from hyper.http20.exceptions import ConnectionError
from server import SocketLevelTest

# Turn off certificate verification for the tests.
hyper.http20.tls._verify_mode = ssl.CERT_NONE
if is_py3:
    hyper.http20.tls._context = hyper.http20.tls._init_context()

def decode_frame(frame_data):
    f, length = Frame.parse_frame_header(frame_data[:8])
    f.parse_body(frame_data[8:8 + length])
    assert 8 + length == len(frame_data)
    return f


def build_headers_frame(headers):
    f = HeadersFrame(1)
    e = Encoder()
    e.huffman_coder = HuffmanEncoder(REQUEST_CODES, REQUEST_CODES_LENGTH)
    f.data = e.encode(headers)
    f.flags.add('END_HEADERS')
    return f


def receive_preamble(sock):
    # Receive the HTTP/2.0 'preamble'.
    sock.recv(65535)
    sock.recv(65535)
    sock.send(SettingsFrame(0).serialize())
    sock.recv(65535)
    return


class TestHyperIntegration(SocketLevelTest):
    def test_connection_string(self):
        self.set_up()

        # Confirm that we send the connection upgrade string and the initial
        # SettingsFrame.
        data = []
        send_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # We should get two packets: one connection header string, one
            # SettingsFrame.
            first = sock.recv(65535)
            second = sock.recv(65535)
            data.append(first)
            data.append(second)

            # We need to send back a SettingsFrame.
            f = SettingsFrame(0)
            sock.send(f.serialize())

            send_event.set()
            sock.close()

        self._start_server(socket_handler)
        conn = HTTP20Connection(self.host, self.port)
        conn.connect()
        send_event.wait()

        assert data[0] == b'PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n'

        self.tear_down()

    def test_initial_settings(self):
        self.set_up()

        # Confirm that we send the connection upgrade string and the initial
        # SettingsFrame.
        data = []
        send_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # We should get two packets: one connection header string, one
            # SettingsFrame.
            first = sock.recv(65535)
            second = sock.recv(65535)
            data.append(first)
            data.append(second)

            # We need to send back a SettingsFrame.
            f = SettingsFrame(0)
            sock.send(f.serialize())

            send_event.set()
            sock.close()

        self._start_server(socket_handler)
        conn = HTTP20Connection(self.host, self.port)
        conn.connect()
        send_event.wait()

        # Get the second chunk of data and decode it into a frame.
        data = data[1]
        f = decode_frame(data)

        assert isinstance(f, SettingsFrame)
        assert f.stream_id == 0
        assert f.settings == {SettingsFrame.ENABLE_PUSH: 0}

        self.tear_down()

    def test_stream_level_window_management(self):
        self.set_up()
        data = []
        send_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # Dispose of the first two packets.
            sock.recv(65535)
            sock.recv(65535)

            # Send a Settings frame that reduces the flow-control window to
            # 64 bytes.
            f = SettingsFrame(0)
            f.settings[SettingsFrame.INITIAL_WINDOW_SIZE] = 64
            sock.send(f.serialize())

            # Grab three frames, the settings ACK, the initial headers frame,
            # and the first data frame.
            for x in range(0, 3):
                data.append(sock.recv(65535))

            # Send a WindowUpdate giving more window room to the stream.
            f = WindowUpdateFrame(1)
            f.window_increment = 64
            sock.send(f.serialize())

            # Send one that gives more room to the connection.
            f = WindowUpdateFrame(0)
            f.window_increment = 64
            sock.send(f.serialize())

            # Reeive the remaining frame.
            data.append(sock.recv(65535))
            send_event.set()

            # We're done.
            sock.close()

        self._start_server(socket_handler)
        conn = HTTP20Connection(self.host, self.port)

        conn.putrequest('GET', '/')
        conn.endheaders()

        # Send the first data chunk. This is 32 bytes.
        sd = b'a' * 32
        conn.send(sd)

        # Send the second one. This should block until the WindowUpdate comes
        # in.
        sd = sd * 2
        conn.send(sd, final=True)
        assert send_event.wait(0.3)

        # Decode the frames.
        frames = [decode_frame(d) for d in data]

        # We care about the last two. The first should be a data frame
        # containing 32 bytes.
        assert (isinstance(frames[-2], DataFrame) and
                not isinstance(frames[-2], HeadersFrame))
        assert len(frames[-2].data) == 32

        # The second should be a data frame containing 64 bytes.
        assert isinstance(frames[-1], DataFrame)
        assert len(frames[-1].data) == 64

        self.tear_down()

    def test_connection_context_manager(self):
        self.set_up()

        data = []
        send_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # We should get two packets: one connection header string, one
            # SettingsFrame.
            first = sock.recv(65535)
            second = sock.recv(65535)
            data.append(first)
            data.append(second)

            # We need to send back a SettingsFrame.
            f = SettingsFrame(0)
            sock.send(f.serialize())

            send_event.set()
            sock.close()

        self._start_server(socket_handler)
        with HTTP20Connection(self.host, self.port) as conn:
            conn.connect()
            send_event.wait()

        # Check that we closed the connection.
        assert conn._sock == None

        self.tear_down()

    def test_closed_responses_remove_their_streams_from_conn(self):
        self.set_up()

        recv_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # We're going to get the two messages for the connection open, then
            # a headers frame.
            receive_preamble(sock)

            # Now, send the headers for the response.
            f = build_headers_frame([(':status', '200')])
            f.stream_id = 1
            sock.send(f.serialize())

            # Wait for the message from the main thread.
            recv_event.wait()
            sock.close()

        self._start_server(socket_handler)
        conn = HTTP20Connection(self.host, self.port)
        conn.request('GET', '/')
        resp = conn.getresponse()

        # Close the response.
        resp.close()

        recv_event.set()

        assert not conn.streams

        self.tear_down()

    def test_receiving_responses_with_no_body(self):
        self.set_up()

        recv_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # We get two messages for the connection open and then a HEADERS
            # frame.
            receive_preamble(sock)

            # Now, send the headers for the response. This response has no body.
            f = build_headers_frame([(':status', '204'), ('content-length', '0')])
            f.flags.add('END_STREAM')
            f.stream_id = 1
            sock.send(f.serialize())

            # Wait for the message from the main thread.
            recv_event.wait()
            sock.close()

        self._start_server(socket_handler)
        conn = HTTP20Connection(self.host, self.port)
        conn.request('GET', '/')
        resp = conn.getresponse()

        # Confirm the status code.
        assert resp.status == 204

        # Confirm that we can read this, but it has no body.
        assert resp.read() == b''
        assert resp._stream._in_window_manager.document_size == 0

        # Awesome, we're done now.
        recv_event.set()

        self.tear_down()

    def test_clean_shut_down(self):
        self.set_up()

        recv_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # We should get two packets: one connection header string, one
            # SettingsFrame. Rather than respond to the packets, send a GOAWAY
            # frame with error code 0 indicating clean shutdown.
            first = sock.recv(65535)
            second = sock.recv(65535)

            # Now, send the shut down.
            f = GoAwayFrame(0)
            f.error_code = 0
            sock.send(f.serialize())

            # Wait for the message from the main thread.
            recv_event.wait()
            sock.close()

        self._start_server(socket_handler)
        conn = HTTP20Connection(self.host, self.port)
        conn.connect()

        # Confirm the connection is closed.
        assert conn._sock is None

        # Awesome, we're done now.
        recv_event.set()

        self.tear_down()

    def test_unexpected_shut_down(self):
        self.set_up()

        recv_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # We should get two packets: one connection header string, one
            # SettingsFrame. Rather than respond to the packets, send a GOAWAY
            # frame with error code 0 indicating clean shutdown.
            first = sock.recv(65535)
            second = sock.recv(65535)

            # Now, send the shut down.
            f = GoAwayFrame(0)
            f.error_code = 1
            sock.send(f.serialize())

            # Wait for the message from the main thread.
            sock.close()
            recv_event.wait()

        self._start_server(socket_handler)
        conn = HTTP20Connection(self.host, self.port)

        with pytest.raises(ConnectionError):
            conn.connect()

        # Confirm the connection is closed.
        assert conn._sock is None

        # Awesome, we're done now.
        recv_event.set()

        self.tear_down()


class TestRequestsAdapter(SocketLevelTest):
    def test_adapter_received_values(self):
        self.set_up()

        data = []
        send_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # Do the handshake: conn header, settings, send settings, recv ack.
            receive_preamble(sock)

            # Now expect some data. One headers frame.
            data.append(sock.recv(65535))

            # Respond!
            h = HeadersFrame(1)
            h.data = self.get_encoder().encode({':status': 200, 'Content-Type': 'not/real', 'Content-Length': 20})
            h.flags.add('END_HEADERS')
            sock.send(h.serialize())
            d = DataFrame(1)
            d.data = b'1234567890' * 2
            d.flags.add('END_STREAM')
            sock.send(d.serialize())

            send_event.set()
            sock.close()

        self._start_server(socket_handler)

        s = requests.Session()
        s.mount('https://%s' % self.host, HTTP20Adapter())
        r = s.get('https://%s:%s/some/path' % (self.host, self.port))

        # Assert about the received values.
        assert r.status_code == 200
        assert r.headers['Content-Type'] == 'not/real'
        assert r.content == b'1234567890' * 2

        self.tear_down()

    def test_adapter_sending_values(self):
        self.set_up()

        data = []
        send_event = threading.Event()

        def socket_handler(listener):
            sock = listener.accept()[0]

            # Do the handshake: conn header, settings, send settings, recv ack.
            receive_preamble(sock)

            # Now expect some data. One headers frame and one data frame.
            data.append(sock.recv(65535))
            data.append(sock.recv(65535))

            # Respond!
            h = HeadersFrame(1)
            h.data = self.get_encoder().encode({':status': 200, 'Content-Type': 'not/real', 'Content-Length': 20})
            h.flags.add('END_HEADERS')
            sock.send(h.serialize())
            d = DataFrame(1)
            d.data = b'1234567890' * 2
            d.flags.add('END_STREAM')
            sock.send(d.serialize())

            send_event.set()
            sock.close()

        self._start_server(socket_handler)

        s = requests.Session()
        s.mount('https://%s' % self.host, HTTP20Adapter())
        r = s.post(
            'https://%s:%s/some/path' % (self.host, self.port),
            data='hi there',
        )

        # Assert about the sent values.
        assert r.status_code == 200

        f = decode_frame(data[0])
        assert isinstance(f, HeadersFrame)

        f = decode_frame(data[1])
        assert isinstance(f, DataFrame)
        assert f.data == b'hi there'

        self.tear_down()

########NEW FILE########
__FILENAME__ = test_windowmanager
# -*- coding: utf-8 -*-
"""
Tests the hyper window manager.
"""
from hyper.http20.window import BaseFlowControlManager, FlowControlManager
import pytest

class TestBaseFCM(object):
    """
    Tests the base flow control manager.
    """
    def test_base_manager_stores_data(self):
        b = BaseFlowControlManager(65535)
        assert b.initial_window_size == 65535
        assert b.window_size == 65535
        assert b.document_size is None

    def test_base_manager_stores_document_size(self):
        b = BaseFlowControlManager(0, 650)
        assert b.document_size == 650

    def test_base_manager_doesnt_function(self):
        b = BaseFlowControlManager(10, 10)
        with pytest.raises(NotImplementedError):
            b.increase_window_size(10)

    def test_base_manager_private_interface_doesnt_function(self):
        b = BaseFlowControlManager(10, 10)
        with pytest.raises(NotImplementedError):
            b._handle_frame(10)

    def test_base_manager_decrements_window_size(self):
        class TestFCM(BaseFlowControlManager):
            def increase_window_size(self, frame_size):
                return 0

        b = TestFCM(10, 10)
        b._handle_frame(5)
        assert b.initial_window_size == 10
        assert b.window_size == 5
        assert b.document_size == 10


class TestFCM(object):
    """
    Test's hyper's build-in Flow-Control Manager.
    """
    def test_fcm_emits_when_window_drops_below_one_quarter(self):
        b = FlowControlManager(65535)

        # Receive a frame slightly smaller than 3/4 of the size of the window.
        assert b._handle_frame(49000) == 0
        assert b.window_size == 65535 - 49000

        # Now push us over to 3/4.
        assert b._handle_frame(1000) == 50000
        assert b.window_size == 65535

    def test_fcm_emits_when_window_drops_below_1k(self):
        b = FlowControlManager(1500)

        # Receive a frame slightly smaller than 500 bytes.
        assert b._handle_frame(499) == 0
        assert b.window_size == 1001

        # Push us over to 1k.
        assert b._handle_frame(2) == 501
        assert b.window_size == 1500

########NEW FILE########
